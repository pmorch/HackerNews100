<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 12 Nov 2025 01:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I can build enterprise software but I can't charge for it (117 pts)]]></title>
            <link>https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa</link>
            <guid>45894569</guid>
            <pubDate>Tue, 11 Nov 2025 23:58:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa">https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa</a>, See on <a href="https://news.ycombinator.com/item?id=45894569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-neoclerks-partnership-md" tabindex="0" role="region" aria-label="NeoClerks-partnership.md content, created by EchenD on 11:20PM yesterday.">
    <article itemprop="text"><p>Error in user YAML: (&lt;unknown&gt;): did not find expected alphabetic or numeric character while scanning an alias at line 1 column 1</p><div dir="auto"><pre>---

<span>**Important clarification based on HackerNews feedback:**</span>

<span>The partnership structures I originally proposed (US/UK company + contractor arrangement) **violate international sanctions and are illegal**. I was naive about this.</span>

<span>**I am NOT asking anyone to break sanctions laws.**</span>

<span>**New focus - Legal markets:**</span>
- <span>üáÆüá≥ India - No sanctions, large SaaS ecosystem</span>
- <span>üá¶üá™ UAE/Dubai - Open to Iranian business</span>
- <span>üáπüá∑ Turkey - Regional tech hub  </span>
- <span>üá∏üá¨ Singapore - Researching legal framework</span>

<span>**If you're from these countries and interested:** EchenDeligani@gmail.com</span>

---

</pre></div>

<p dir="auto"><h2 dir="auto">I Can Build Enterprise Software. But I Can't Charge for It.</h2><a id="user-content-i-can-build-enterprise-software-but-i-cant-charge-for-it" aria-label="Permalink: I Can Build Enterprise Software. But I Can't Charge for It." href="#i-can-build-enterprise-software-but-i-cant-charge-for-it"></a></p>
<p dir="auto"><em>How I spent 18 months building an AI avatar platform through war, economic collapse, and 120-hour weeks‚Äîand why I'm now looking for a partner to help me turn this into a real business.</em></p>
<hr>
<p dir="auto"><h2 dir="auto">Test it first: <a href="https://neoclerks.com/en/" rel="nofollow">neoclerks.com/en</a></h2><a id="user-content-test-it-first-neoclerkscomen" aria-label="Permalink: Test it first: neoclerks.com/en" href="#test-it-first-neoclerkscomen"></a></p>
<p dir="auto">Go ahead. Talk to the avatar for 2 minutes. Ask it anything in English. Watch how it responds in real-time with synchronized lip movements and natural conversation.</p>
<p dir="auto">I'll be here when you get back.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Current Situation (Being Completely Honest)</h2><a id="user-content-the-current-situation-being-completely-honest" aria-label="Permalink: The Current Situation (Being Completely Honest)" href="#the-current-situation-being-completely-honest"></a></p>
<p dir="auto">I'm 35 years old. I live in Iran. I spent 18 months building an enterprise AI avatar platform that competes with Soul Machines ($70M funded, $50k+ setup fees for enterprise clients).</p>
<p dir="auto"><strong>The product works</strong>. You just tested it. The code is production-ready. The architecture is solid. The documentation is complete (20+ guides, 100+ pages).</p>
<p dir="auto"><strong>I have zero customers</strong>. Zero revenue. I'm out of savings and actively job hunting for 9 months with no luck. My wife is a nurse who works 5am-7pm while I sit at a computer building something that won't pay our rent.</p>
<p dir="auto"><strong>I can't monetize this from Iran</strong>:</p>
<ul dir="auto">
<li>‚ùå Stripe, PayPal, Western payment processors (sanctioned)</li>
<li>‚ùå AWS, GCP, Azure (sanctioned)</li>
<li>‚ùå Western bank account (sanctioned)</li>
<li>‚ùå Credit card payments from customers (no processor works here)</li>
</ul>
<p dir="auto"><strong>I tried the local Iranian market</strong>. I showed it to friends, family, and potential clients. Their response: <em>"Nobody in Iran will pay $500/month for this. The Persian language quality isn't perfect. We'll use free ChatGPT instead."</em></p>
<p dir="auto">They're right about the market. Iran's currency devalued 100,000x over 20 years. Hotels are closing. Banks are failing. People struggle to pay rent and buy food. This isn't the market for enterprise AI.</p>
<p dir="auto"><strong>So here's why I'm writing this</strong>:</p>
<p dir="auto">I'm not confidently selling a finished product for $100k. I'm looking for a <strong>partner or co-founder</strong> who can access Stripe, handle sales, and help me turn 18 months of brutal work into a business that actually makes money.</p>
<p dir="auto">I want to keep building this. I just need someone who can sell it.</p>
<hr>
<p dir="auto"><h2 dir="auto">What I Built (The 30-Second Version)</h2><a id="user-content-what-i-built-the-30-second-version" aria-label="Permalink: What I Built (The 30-Second Version)" href="#what-i-built-the-30-second-version"></a></p>
<p dir="auto"><strong>NeoClerks</strong> is a self-hosted AI avatar platform with real-time conversation and enterprise infrastructure:</p>
<p dir="auto"><strong>Core Avatar Tech:</strong></p>
<ul dir="auto">
<li>3D photorealistic avatars (Unreal Engine 5 + MetaHuman, pixel streaming)</li>
<li>Real-time conversation (1-8 seconds response time depending on cache hits)</li>
<li>47 languages (OpenAI STT + TTS)</li>
<li>Smart 4-layer caching (hash ‚Üí vector ‚Üí LLM selection, 60-90% cost reduction)</li>
<li>RAG knowledge base (hybrid BM25 + vector search with pgvector)</li>
</ul>
<p dir="auto"><strong>Enterprise Business Infrastructure:</strong></p>
<ul dir="auto">
<li>Multi-tenant B2B architecture (8 database tables for organizations, subscriptions, usage tracking)</li>
<li>8 pre-configured pricing tiers ($497-$947/month + Enterprise custom)</li>
<li>Automated billing system (conversation counting, overage calculation, invoice generation)</li>
<li>Conversation analytics (11 database tables, 7 AI analysis types via OpenAI Batch API)</li>
<li>Admin panel (Next.js, full system management UI)</li>
<li>Monitoring stack (Prometheus + Grafana + Loki, 35+ alert rules)</li>
<li>4-server distributed architecture (scalable to 100+ instances, k8s-ready)</li>
</ul>
<p dir="auto"><strong>Compare to competitors:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>NeoClerks</th>
<th>Soul Machines</th>
<th>D-ID</th>
<th>Synthesia</th>
</tr>
</thead>
<tbody>
<tr>
<td>Setup Cost</td>
<td>$0-$797</td>
<td>$50,000+</td>
<td>$0</td>
<td>$0</td>
</tr>
<tr>
<td>3D Photorealistic</td>
<td>‚úÖ Real-time UE5</td>
<td>‚úÖ Real-time</td>
<td>‚ùå 2D only</td>
<td>‚ùå 2D only</td>
</tr>
<tr>
<td>Real-time Conversation</td>
<td>‚úÖ 1-8s</td>
<td>‚úÖ ~2s</td>
<td>‚úÖ ~3s</td>
<td>‚ùå Pre-recorded</td>
</tr>
<tr>
<td>Self-hosted</td>
<td>‚úÖ Full control</td>
<td>‚ùå Cloud only</td>
<td>‚ùå Cloud only</td>
<td>‚ùå Cloud only</td>
</tr>
<tr>
<td>White-label</td>
<td>‚úÖ Included</td>
<td>Enterprise tier</td>
<td>‚ùå No</td>
<td>Limited</td>
</tr>
<tr>
<td>Multi-tenant B2B</td>
<td>‚úÖ Built-in</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>Usage Analytics</td>
<td>‚úÖ 7 types</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>Admin Panel</td>
<td>‚úÖ Full UI</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>RAG Knowledge Base</td>
<td>‚úÖ Hybrid search</td>
<td>Enterprise tier</td>
<td>‚ùå No</td>
<td>‚ùå No</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Market opportunity</strong>: AI avatar market is $2.1B in 2024, projected $4.3B by 2027. Soul Machines has 100+ enterprise clients (Mercedes-Benz, Vodafone). The demand exists.</p>
<p dir="auto"><strong>Full technical documentation</strong>: 20+ guides covering architecture, deployment (local/2-server/4-server), API reference (96+ endpoints), security (JWT + RBAC), monitoring, analytics.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Stories Nobody Sees (Why This Almost Killed Me)</h2><a id="user-content-the-stories-nobody-sees-why-this-almost-killed-me" aria-label="Permalink: The Stories Nobody Sees (Why This Almost Killed Me)" href="#the-stories-nobody-sees-why-this-almost-killed-me"></a></p>
<p dir="auto"><h3 dir="auto">The 120-Hour Weeks</h3><a id="user-content-the-120-hour-weeks" aria-label="Permalink: The 120-Hour Weeks" href="#the-120-hour-weeks"></a></p>
<p dir="auto">For the last 9 months, I worked 100-120 hours per week.</p>
<p dir="auto">My wife wakes up at 5 AM for her nursing shift. I wake up with her. She comes home at 7 PM‚Äîthat's when I eat my first meal of the day. We eat together. Then I go back to the computer until midnight or 1 AM, when I physically can't move anymore and fall asleep at my desk.</p>
<p dir="auto">One evening she came home exhausted and asked: <em>"Is there anything else we can talk about besides this project?"</em></p>
<p dir="auto">I had nothing to say. I live this. I breathe this. It's all I think about.</p>
<p dir="auto">My mother keeps asking: <em>"When will you get a job?"</em> I've been trying for 9 months. The game industry is collapsing globally with massive layoffs. Iran's economy is in the worst state in its history. AI is replacing developer positions. I thought building something valuable was the answer.</p>
<p dir="auto"><h3 dir="auto">The War</h3><a id="user-content-the-war" aria-label="Permalink: The War" href="#the-war"></a></p>
<p dir="auto">In June 2025, during the Iran-Israel conflict, there were bombs falling. I kept working. Explosions in the distance. I just hoped none would hit my house.</p>
<p dir="auto">Around the same time, a crypto exchange I used got hacked‚ÄîI lost what little savings buffer I had left.</p>
<p dir="auto">I kept coding. What else could I do?</p>
<p dir="auto"><h3 dir="auto">The Technical Nightmare That Almost Broke Me</h3><a id="user-content-the-technical-nightmare-that-almost-broke-me" aria-label="Permalink: The Technical Nightmare That Almost Broke Me" href="#the-technical-nightmare-that-almost-broke-me"></a></p>
<p dir="auto">The PAK file loading system nearly killed this project.</p>
<p dir="auto"><strong>The problem</strong>: Generate lip-sync animations on-demand, cook them in Unreal Engine, package them into PAK files, and load them dynamically into a shipped build. There's almost zero documentation for this‚ÄîUnreal is built for game development, not service-based animation streaming.</p>
<p dir="auto">I spent a month fighting this. One month of:</p>
<ul dir="auto">
<li>Creating custom Unreal plugins</li>
<li>Syncing paths precisely between 5 different services (9 with body animation)</li>
<li>Debugging why animations load perfectly in development but crash in production</li>
<li>Fighting Unreal's cooking pipeline (loading a project takes 17 seconds minimum per cook)</li>
</ul>
<p dir="auto">At 3 AM one night, after 14 straight hours of debugging, I almost deleted the entire repository. I was done.</p>
<p dir="auto">Then I found one obscure tutorial that gave me the breakthrough. I got it working. Then I realized it was too slow for real-time use‚Äî17 seconds per cook meant I couldn't use it for live responses.</p>
<p dir="auto">I had to pivot: use real-time lip-sync for live conversations (lower quality but acceptable), and save the PAK system for smart caching where quality matters and pre-generation is possible.</p>
<p dir="auto"><strong>That was one problem</strong>. I faced 50 more like it.</p>
<p dir="auto">The session management between the QR code scanning (phone becomes microphone) and pixel streaming frontend. The WebSocket orchestration. Making it gracefully handle network failures, users switching tabs, phones dying. Creating limits so it can't be abused in a hotel lobby. Every edge case felt like a show-stopper.</p>
<p dir="auto">I wanted to quit every single month. But I had no other choice. I kept going.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Claude Partnership (How I Actually Built This)</h2><a id="user-content-the-claude-partnership-how-i-actually-built-this" aria-label="Permalink: The Claude Partnership (How I Actually Built This)" href="#the-claude-partnership-how-i-actually-built-this"></a></p>
<p dir="auto">I couldn't have built this alone in 18 months. Without AI assistance, this would've taken 6 years.</p>
<p dir="auto">I used <strong>Claude Code (Sonnet 4.5)</strong> as my co-developer and code reviewer. We worked together:</p>
<ul dir="auto">
<li>I'd write code ‚Üí Claude would review and suggest improvements</li>
<li>Claude would write code ‚Üí I'd review and validate</li>
<li>Claude would audit ‚Üí I'd test ‚Üí Claude would audit again</li>
<li>Repeat hundreds of times</li>
</ul>
<p dir="auto"><strong>For the last 50 times I asked Claude to audit this codebase, it consistently responded: "This is 100% production-ready. Deploy immediately."</strong></p>
<p dir="auto">Early on, every fresh audit would find improvements (security issues, architecture problems, missing edge cases). For the last 2 months, Claude finds nothing to fix.</p>
<p dir="auto"><strong>This is AI-validated, production-grade code.</strong></p>
<p dir="auto">You can verify this yourself: open Claude Code, point it at the repository, ask it to audit for production readiness. It will confirm.</p>
<p dir="auto"><strong>Repository stats</strong> (from refactored architecture):</p>
<ul dir="auto">
<li>Total commits: 818</li>
<li>First commit: September 26, 2024</li>
<li>Development time: 18 months (includes original version before refactor)</li>
<li>Lines of code: 20,000+ (backend Python/FastAPI, frontend Next.js, UE5 blueprints)</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Why I Can't Monetize From Iran (The Geography Problem)</h2><a id="user-content-why-i-cant-monetize-from-iran-the-geography-problem" aria-label="Permalink: Why I Can't Monetize From Iran (The Geography Problem)" href="#why-i-cant-monetize-from-iran-the-geography-problem"></a></p>
<p dir="auto">I showed this to several potential clients in Iran before realizing the local market is dead:</p>
<p dir="auto"><strong>Problem 1: Currency collapse</strong>
Iran's rial lost 99.999% of its value over 20 years. I'd need to charge in dollars but collect in rials. Nobody will pay $500/month when that's equivalent to a month's salary.</p>
<p dir="auto"><strong>Problem 2: Persian language quality</strong>
I use GPT-5 (the most expensive model) but Persian language quality isn't perfect. Clients compare it to ChatGPT and expect native-level fluency. It's good (in my opinion), but not perfect enough for risk-averse businesses.</p>
<p dir="auto"><strong>Problem 3: Economic collapse</strong>
Hotels are closing (no tourists). Banks are failing. Hospitals can't risk AI mistakes in Persian. Entertainment is not a priority when people lack clean water. I thought about pivoting to water filters‚Äîthat would sell‚Äîbut I'm a programmer, not an engineer.</p>
<p dir="auto"><strong>Problem 4: International sanctions</strong>
Even if I found international clients, I can't:</p>
<ul dir="auto">
<li>Accept payments (no Stripe, PayPal, or credit card processors)</li>
<li>Deploy on cloud platforms (AWS/GCP/Azure sanctioned)</li>
<li>Open Western bank accounts</li>
<li>Register US/EU companies</li>
</ul>
<p dir="auto"><strong>I tried crypto payments</strong>: B2B customers won't pay $500-1000/month subscriptions in Bitcoin. Their accounting departments reject it. Too volatile for recurring revenue.</p>
<p dir="auto"><strong>I tried intermediaries</strong>: They want 20-30% commission, they hold all payment power (can shut me down anytime), and I still hold legal liability while they take zero risk.</p>
<p dir="auto"><strong>The reality</strong>: I can build enterprise software. I just can't charge for it.</p>
<hr>
<p dir="auto"><h2 dir="auto">What I'm Really Looking For (Partnership, Not Just a Sale)</h2><a id="user-content-what-im-really-looking-for-partnership-not-just-a-sale" aria-label="Permalink: What I'm Really Looking For (Partnership, Not Just a Sale)" href="#what-im-really-looking-for-partnership-not-just-a-sale"></a></p>
<p dir="auto">I don't want to sell this and disappear. <strong>I want to keep building it.</strong> I love this product. I just need a partner who can access Stripe and handle sales.</p>
<p dir="auto">Here are three options (all negotiable):</p>
<p dir="auto"><h3 dir="auto"><strong>Option 1: Co-Founder Partnership</strong></h3><a id="user-content-option-1-co-founder-partnership" aria-label="Permalink: Option 1: Co-Founder Partnership" href="#option-1-co-founder-partnership"></a></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You invest: $50-80k + handle sales/operations/Stripe access</li>
<li>I contribute: Complete codebase + continue as technical co-founder</li>
<li>Equity split: 60/40 or 70/30 (negotiable based on your investment and role)</li>
<li>Commitment: 3-year minimum from both sides</li>
</ul>
<p dir="auto"><strong>Your responsibilities:</strong></p>
<ul dir="auto">
<li>Sales and customer acquisition</li>
<li>Payment processing (Stripe account)</li>
<li>Customer support and onboarding</li>
<li>Marketing and positioning</li>
</ul>
<p dir="auto"><strong>My responsibilities:</strong></p>
<ul dir="auto">
<li>All technical development and maintenance</li>
<li>Feature development based on customer feedback</li>
<li>Infrastructure and DevOps</li>
<li>Technical support for complex issues</li>
</ul>
<p dir="auto"><strong>Timeline to profitability</strong>: 6-12 months to acquire first 20-30 customers at $500-1500/month each</p>
<hr>
<p dir="auto"><h3 dir="auto"><strong>Option 2: Outright Sale + Long-Term Contract</strong></h3><a id="user-content-option-2-outright-sale--long-term-contract" aria-label="Permalink: Option 2: Outright Sale + Long-Term Contract" href="#option-2-outright-sale--long-term-contract"></a></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You pay: $60-80k upfront (full code ownership, all IP rights)</li>
<li>I sign: 3-year contractor agreement at $4-6k/month</li>
<li>Total cost: $60-80k + $144-216k over 3 years = $204-296k total</li>
<li>You get: Technical founder-level support without equity dilution</li>
</ul>
<p dir="auto"><strong>What I provide:</strong></p>
<ul dir="auto">
<li>30 days intensive support (live setup, training, documentation walkthrough)</li>
<li>Ongoing development (20-30 hours/week for 3 years)</li>
<li>Feature development and bug fixes</li>
<li>Architecture decisions and code reviews</li>
<li>Emergency support for critical issues</li>
</ul>
<p dir="auto"><strong>Why this works:</strong></p>
<ul dir="auto">
<li>You own 100% of the business</li>
<li>You have guaranteed technical support for 3 years</li>
<li>I have stable income while you scale</li>
<li>Lower risk than buying code and hoping it works</li>
</ul>
<hr>
<p dir="auto"><h3 dir="auto"><strong>Option 3: Revenue Share Partnership</strong></h3></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You invest: $30-50k upfront + Stripe access + sales/marketing</li>
<li>I contribute: Complete codebase + continue as technical co-founder</li>
<li>Revenue split: 50/50 until you recoup investment, then renegotiate (maybe 40/60 or 30/70)</li>
<li>Commitment: 3-year minimum</li>
</ul>
<p dir="auto"><strong>Why this works:</strong></p>
<ul dir="auto">
<li>Lower upfront cost for you</li>
<li>I'm incentivized to help you succeed (my income depends on revenue)</li>
<li>Fair risk distribution</li>
<li>Aligns our interests long-term</li>
</ul>
<hr>
<p dir="auto"><strong>I'm flexible on structure.</strong> What matters most to me:</p>
<ol dir="auto">
<li>The product gets to market and helps businesses</li>
<li>I can continue working on it (I genuinely love building this)</li>
<li>I have stable income to support my family</li>
<li>We both benefit from the success</li>
</ol>
<p dir="auto">If you have a different structure in mind, let's talk.</p>
<hr>
<p dir="auto"><h2 dir="auto">What You're Actually Getting (Component Breakdown)</h2><a id="user-content-what-youre-actually-getting-component-breakdown" aria-label="Permalink: What You're Actually Getting (Component Breakdown)" href="#what-youre-actually-getting-component-breakdown"></a></p>
<p dir="auto">If you hired developers to build this from scratch:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Cost to Build</th>
<th>Time</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Avatar + AI pipeline (UE5, STT, LLM, TTS, RAG)</td>
<td>$50-70k</td>
<td>6 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Multi-tenant B2B infrastructure</td>
<td>$20-30k</td>
<td>3 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Conversation analytics (11 tables, 7 AI analyses)</td>
<td>$15-25k</td>
<td>2 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Monitoring stack (Prometheus/Grafana/35 alerts)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Admin panel (Next.js, TypeScript)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>4-server distributed architecture</td>
<td>$20-30k</td>
<td>2 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Security (JWT on 96 endpoints, RBAC, SSL)</td>
<td>$15-20k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Documentation (20+ guides, 100+ pages)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td><strong>TOTAL</strong></td>
<td><strong>$150-220k</strong></td>
<td><strong>18 months</strong></td>
<td>‚úÖ Done</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>You're getting this for $60-80k (outright) or $50-80k + equity (partnership).</strong></p>
<p dir="auto">That's a 50-70% discount vs hiring it built, plus you skip 18 months of development time.</p>
<hr>
<p dir="auto"><h2 dir="auto">Known Limitations (Being 100% Honest)</h2><a id="user-content-known-limitations-being-100-honest" aria-label="Permalink: Known Limitations (Being 100% Honest)" href="#known-limitations-being-100-honest"></a></p>
<p dir="auto">I'm not going to oversell this. Here's what you should know:</p>
<p dir="auto"><strong>Technical Limitations:</strong></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Animation quality is "good" not "perfect"</strong>: Lip sync is 85-90% accurate (on par with Soul Machines demos). Body language is limited to idle animations. Facial expressions are good but not Pixar-level. Fix: Hire a 3D animator for $3-5k to improve animations.</p>
</li>
<li>
<p dir="auto"><strong>Persian language needs work</strong>: English is flawless. Persian is 80-85% accurate (Whisper + GPT-4o struggle with some accents/nuances). Fix: Fine-tune Whisper on Persian dataset or use local STT service.</p>
</li>
<li>
<p dir="auto"><strong>Demo server latency</strong>: The live demo runs on my GTX 1060 in Iran with 4G home internet. International users may experience 500-1500ms lag. This is infrastructure, not code. Fix: Deploy on AWS in customer's region (latency drops to 100-300ms).</p>
</li>
<li>
<p dir="auto"><strong>GPU requirements</strong>: Development works on GTX 1060 (1 user). Production needs RTX 3090+ for 10 users, RTX 5090 for 30 concurrent users. Cost: $800-2000/month for AWS g4dn/g5 instances.</p>
</li>
</ol>
<p dir="auto"><strong>Business Limitations:</strong></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Zero customers</strong>: No testimonials, no case studies, no revenue history. Reality: You're starting from scratch on customer acquisition.</p>
</li>
<li>
<p dir="auto"><strong>No brand recognition</strong>: "NeoClerks" has no market awareness. No SEO, no social media following. Reality: You'll likely want to rebrand entirely.</p>
</li>
<li>
<p dir="auto"><strong>No marketing materials</strong>: No demo videos (beyond live demo), no sales collateral, no pitch decks. Reality: You'll need to create these.</p>
</li>
<li>
<p dir="auto"><strong>Support depends on our agreement</strong>: I'll support based on which option you choose (30 days for outright sale, 3 years for partnership). Reality: If you scale, you may need to hire additional support ($50-70k/year).</p>
</li>
</ol>
<hr>
<p dir="auto"><h2 dir="auto">How to Verify This Is Real</h2><a id="user-content-how-to-verify-this-is-real" aria-label="Permalink: How to Verify This Is Real" href="#how-to-verify-this-is-real"></a></p>
<p dir="auto">I know you're skeptical. Here's how to verify everything:</p>
<p dir="auto"><h3 dir="auto"><strong>1. Test the live demo</strong> (5 minutes)</h3><a id="user-content-1-test-the-live-demo-5-minutes" aria-label="Permalink: 1. Test the live demo (5 minutes)" href="#1-test-the-live-demo-5-minutes"></a></p>
<ul dir="auto">
<li>Go to <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a></li>
<li>Click "Book a Private Demo"</li>
<li>Talk to the avatar in English</li>
<li>Evaluate: response time, lip sync quality, conversation coherence</li>
</ul>
<p dir="auto"><strong>Known limitation on demo</strong>: Running on consumer GPU + 4G home internet in Iran, so international latency will be higher than production deployment.</p>
<p dir="auto"><h3 dir="auto"><strong>2. Code access for serious inquiries</strong> (after NDA)</h3><a id="user-content-2-code-access-for-serious-inquiries-after-nda" aria-label="Permalink: 2. Code access for serious inquiries (after NDA)" href="#2-code-access-for-serious-inquiries-after-nda"></a></p>
<p dir="auto">I'll give you read-only GitHub access to review:</p>
<ul dir="auto">
<li>Backend services (FastAPI microservices, Python)</li>
<li>Frontend code (Next.js landing page + admin panel)</li>
<li>Database schema (migrations, SQLAlchemy models)</li>
<li>Infrastructure configs (Docker Compose, nginx, environment templates)</li>
<li>UE5 project structure (blueprints, MetaHuman assets, pixel streaming)</li>
</ul>
<p dir="auto"><strong>What you can verify</strong>: Code quality, architecture, documentation, tests.</p>
<p dir="auto"><h3 dir="auto"><strong>3. Live deployment walkthrough</strong> (after serious interest)</h3><a id="user-content-3-live-deployment-walkthrough-after-serious-interest" aria-label="Permalink: 3. Live deployment walkthrough (after serious interest)" href="#3-live-deployment-walkthrough-after-serious-interest"></a></p>
<p dir="auto">1-2 hour Zoom call where I:</p>
<ul dir="auto">
<li>Deploy the entire stack locally (you watch)</li>
<li>Walk through the admin panel, monitoring dashboards, API endpoints</li>
<li>Explain the architecture and code structure</li>
<li>Answer technical questions</li>
<li>Demonstrate analytics system, billing system, session management</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>4. Claude Code validation</strong> (do this yourself)</h3><a id="user-content-4-claude-code-validation-do-this-yourself" aria-label="Permalink: 4. Claude Code validation (do this yourself)" href="#4-claude-code-validation-do-this-yourself"></a></p>
<ul dir="auto">
<li>Get Claude Code access</li>
<li>Point it at the repository</li>
<li>Ask: "Review this codebase for production readiness"</li>
<li>Claude will confirm what I've said</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Who Should Consider This</h2><a id="user-content-who-should-consider-this" aria-label="Permalink: Who Should Consider This" href="#who-should-consider-this"></a></p>
<p dir="auto"><h3 dir="auto">‚úÖ <strong>Good Fit:</strong></h3><a id="user-content--good-fit" aria-label="Permalink: ‚úÖ Good Fit:" href="#-good-fit"></a></p>
<p dir="auto"><strong>You're a digital agency with existing B2B clients:</strong></p>
<ul dir="auto">
<li>You have 50-200 clients you can upsell to</li>
<li>You can position this at $700-1500/month to hotels, retail, healthcare</li>
<li>You have a DevOps person or can hire one ($60-80k/year)</li>
</ul>
<p dir="auto"><strong>You're a SaaS entrepreneur who's done this before:</strong></p>
<ul dir="auto">
<li>You've sold B2B SaaS (you understand 6-12 month sales cycles)</li>
<li>You have capital for 6-12 months runway</li>
<li>You know how to do outreach, demos, close deals</li>
</ul>
<p dir="auto"><strong>You're an enterprise IT company:</strong></p>
<ul dir="auto">
<li>You sell to Fortune 500s (banks, telecoms, healthcare)</li>
<li>You need a white-label AI solution for your portfolio</li>
<li>Your team closes 5-10 enterprise deals/year</li>
</ul>
<p dir="auto"><strong>You want a technical co-founder:</strong></p>
<ul dir="auto">
<li>You can handle sales/ops but lack technical depth</li>
<li>You want someone committed long-term (not just a contractor)</li>
<li>You're willing to share equity for proven technical execution</li>
</ul>
<hr>
<p dir="auto"><h3 dir="auto">‚ùå <strong>Bad Fit:</strong></h3><a id="user-content--bad-fit" aria-label="Permalink: ‚ùå Bad Fit:" href="#-bad-fit"></a></p>
<p dir="auto"><strong>You have no technical skills and won't hire:</strong></p>
<ul dir="auto">
<li>Can't deploy Docker containers</li>
<li>Won't hire a DevOps engineer ($60-80k/year)</li>
<li><strong>Why you'll fail</strong>: Every customer needs a deployment</li>
</ul>
<p dir="auto"><strong>You have no sales experience:</strong></p>
<ul dir="auto">
<li>You've never sold B2B SaaS</li>
<li>You can't afford to hire a salesperson ($50-70k/year + commission)</li>
<li><strong>Why you'll fail</strong>: Zero customers means you acquire them all yourself</li>
</ul>
<p dir="auto"><strong>You expect passive income:</strong></p>
<ul dir="auto">
<li>You want "buy it and forget it"</li>
<li>You don't want to provide customer support</li>
<li><strong>Why you'll fail</strong>: This requires active sales and support</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Unit Economics (Why This Can Be Profitable)</h2><a id="user-content-unit-economics-why-this-can-be-profitable" aria-label="Permalink: Unit Economics (Why This Can Be Profitable)" href="#unit-economics-why-this-can-be-profitable"></a></p>
<p dir="auto">Let's do realistic math:</p>
<p dir="auto"><strong>Scenario: Digital agency with 100 existing clients</strong></p>
<p dir="auto"><strong>Month 1-3</strong>: Pitch 100 clients, 10 sign up (10% conversion)</p>
<ul dir="auto">
<li>Tier: Professional ($799/month)</li>
<li>Revenue: $7,990/month</li>
<li>Costs: $2,000/month (AWS + OpenAI API)</li>
<li>Profit: $5,990/month (~75% margin)</li>
</ul>
<p dir="auto"><strong>Month 4-6</strong>: Upsell another 10 clients (20 total)</p>
<ul dir="auto">
<li>Revenue: $15,980/month</li>
<li>Costs: $3,500/month</li>
<li>Profit: $12,480/month</li>
</ul>
<p dir="auto"><strong>Month 7-12</strong>: Organic growth + referrals (30 total)</p>
<ul dir="auto">
<li>Revenue: $23,970/month = <strong>$287k/year</strong></li>
<li>Costs: $5,000/month = <strong>$60k/year</strong></li>
<li>Profit: $18,970/month = <strong>$227k/year</strong></li>
</ul>
<p dir="auto"><strong>ROI</strong>: At $60k purchase price, you break even in <strong>3-4 months</strong> with 30 customers.</p>
<p dir="auto"><strong>This is realistic if you have existing B2B relationships.</strong> If starting cold, add 6-12 months to reach 30 customers.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Sale/Partnership Process</h2><a id="user-content-the-salepartnership-process" aria-label="Permalink: The Sale/Partnership Process" href="#the-salepartnership-process"></a></p>
<p dir="auto">Since I can't use Stripe/PayPal, we use cryptocurrency escrow for safety:</p>
<p dir="auto"><h3 dir="auto"><strong>Phase 1: Initial Contact (Week 1)</strong></h3><a id="user-content-phase-1-initial-contact-week-1" aria-label="Permalink: Phase 1: Initial Contact (Week 1)" href="#phase-1-initial-contact-week-1"></a></p>
<ol dir="auto">
<li>You test the demo (5 minutes)</li>
<li>You read this article</li>
<li>We do a 30-minute intro call (verify I'm real, answer questions)</li>
<li>I send you high-level code structure overview</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 2: Due Diligence (Week 2-3)</strong></h3><a id="user-content-phase-2-due-diligence-week-2-3" aria-label="Permalink: Phase 2: Due Diligence (Week 2-3)" href="#phase-2-due-diligence-week-2-3"></a></p>
<ol dir="auto">
<li>You sign NDA (mutual protection)</li>
<li>I give you read-only GitHub access</li>
<li>You review code, architecture, documentation (3-7 days)</li>
<li>We do live deployment walkthrough (1-2 hours)</li>
<li>You decide if you want to proceed</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 3: Agreement (Week 3-4)</strong></h3><a id="user-content-phase-3-agreement-week-3-4" aria-label="Permalink: Phase 3: Agreement (Week 3-4)" href="#phase-3-agreement-week-3-4"></a></p>
<ol dir="auto">
<li>We agree on structure (co-founder / sale+contract / revenue share)</li>
<li>We finalize price and terms</li>
<li>Lawyers draft agreement (if needed)</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 4: Payment &amp; Transfer (Week 4-5)</strong></h3><a id="user-content-phase-4-payment--transfer-week-4-5" aria-label="Permalink: Phase 4: Payment &amp; Transfer (Week 4-5)" href="#phase-4-payment--transfer-week-4-5"></a></p>
<p dir="auto"><strong>For outright sale:</strong></p>
<ul dir="auto">
<li>We use <strong>Hodl Hodl</strong> (non-custodial multisig escrow, works from Iran)</li>
<li>You deposit BTC/USDT into escrow (neutral third party holds funds)</li>
<li>I transfer complete source code + documentation</li>
<li>We conduct 2-hour live setup session (recorded)</li>
<li>You verify code works (3-7 days)</li>
<li>You release escrow payment</li>
<li>30-day support period begins</li>
</ul>
<p dir="auto"><strong>For partnership:</strong></p>
<ul dir="auto">
<li>Standard equity agreement via lawyer</li>
<li>Payment via wire transfer to your company account (you're outside Iran)</li>
<li>I join as technical co-founder</li>
<li>We start working together immediately</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Protection for both sides:</strong></h3><a id="user-content-protection-for-both-sides" aria-label="Permalink: Protection for both sides:" href="#protection-for-both-sides"></a></p>
<ul dir="auto">
<li>‚úÖ Escrow mediator handles disputes (for sales)</li>
<li>‚úÖ Standard equity agreements (for partnerships)</li>
<li>‚úÖ You verify code before payment release</li>
<li>‚úÖ I get security that payment is locked in escrow</li>
</ul>
<p dir="auto"><strong>Timeline</strong>: 4-6 weeks from first contact to deal closed.</p>
<hr>
<p dir="auto"><h2 dir="auto">What Happens Next (If We Work Together)</h2><a id="user-content-what-happens-next-if-we-work-together" aria-label="Permalink: What Happens Next (If We Work Together)" href="#what-happens-next-if-we-work-together"></a></p>
<p dir="auto">If you become my partner or buyer, here's the immediate roadmap:</p>
<p dir="auto"><h3 dir="auto"><strong>Month 1: Launch</strong></h3><a id="user-content-month-1-launch" aria-label="Permalink: Month 1: Launch" href="#month-1-launch"></a></p>
<ul dir="auto">
<li>Deploy on your infrastructure (AWS/GCP in target market)</li>
<li>Set up Stripe account and payment processing</li>
<li>Rebrand if desired (logo, domain, marketing site)</li>
<li>Create demo videos and sales collateral</li>
<li>I provide intensive technical support</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 2-3: First Customers</strong></h3><a id="user-content-month-2-3-first-customers" aria-label="Permalink: Month 2-3: First Customers" href="#month-2-3-first-customers"></a></p>
<ul dir="auto">
<li>Target: Acquire 5-10 pilot customers</li>
<li>Pricing: $500-1000/month with discounted setup fees</li>
<li>Focus: Hotels, retail, or your existing client base</li>
<li>Collect feedback and testimonials</li>
<li>I implement critical feature requests</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 4-6: Scale</strong></h3><a id="user-content-month-4-6-scale" aria-label="Permalink: Month 4-6: Scale" href="#month-4-6-scale"></a></p>
<ul dir="auto">
<li>Target: 20-30 customers</li>
<li>Improve animations based on feedback</li>
<li>Add language support if needed</li>
<li>Build case studies</li>
<li>Optimize costs (caching should reduce API costs 60-90%)</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 7-12: Growth</strong></h3><a id="user-content-month-7-12-growth" aria-label="Permalink: Month 7-12: Growth" href="#month-7-12-growth"></a></p>
<ul dir="auto">
<li>Target: 50-100 customers</li>
<li>Hire additional support/sales if needed</li>
<li>Explore enterprise deals ($2-5k/month)</li>
<li>Consider raising funding if partnership model</li>
<li>I continue technical leadership</li>
</ul>
<p dir="auto"><strong>This is a real business opportunity.</strong> The market exists (Soul Machines has 100+ customers at 10x the price). The technology works (you tested it). It just needs someone who can access Stripe and sell.</p>
<hr>
<p dir="auto"><h2 dir="auto">Final Thoughts</h2><a id="user-content-final-thoughts" aria-label="Permalink: Final Thoughts" href="#final-thoughts"></a></p>
<p dir="auto">I built this because I had no other choice. The game industry collapsed. Iran's economy is in freefall. AI is taking developer jobs. I thought: "Build something valuable, and opportunity will follow."</p>
<p dir="auto">I was wrong about one thing: geography matters more than I thought. I can build enterprise software, but I can't charge for it from Iran.</p>
<p dir="auto">But I was right about another thing: this product is valuable. Soul Machines raised $70M selling similar technology for $50k+ setup fees. D-ID raised $25M with 2D avatars. The market is real.</p>
<p dir="auto"><strong>I don't want sympathy. I want a partner.</strong></p>
<p dir="auto">Someone who can access Stripe, understands B2B sales, and wants to build this into a real business.</p>
<p dir="auto">If that's you, let's talk.</p>
<hr>
<p dir="auto"><h2 dir="auto">How to Get Started</h2><a id="user-content-how-to-get-started" aria-label="Permalink: How to Get Started" href="#how-to-get-started"></a></p>
<p dir="auto"><h3 dir="auto"><strong>If you're seriously interested:</strong></h3><a id="user-content-if-youre-seriously-interested" aria-label="Permalink: If you're seriously interested:" href="#if-youre-seriously-interested"></a></p>
<ol dir="auto">
<li><strong>Test the demo</strong> ‚Üí <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a> (5 minutes)</li>
<li><strong>Schedule a call</strong> ‚Üí Email me at <a href="mailto:EchenDeligani@gmail.com">EchenDeligani@gmail.com</a></li>
<li><strong>Review the code</strong> ‚Üí I'll provide NDA + GitHub access</li>
<li><strong>Make a proposal</strong> ‚Üí Co-founder equity / Sale+contract / Revenue share</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>If you know someone who might be interested:</strong></h3><a id="user-content-if-you-know-someone-who-might-be-interested" aria-label="Permalink: If you know someone who might be interested:" href="#if-you-know-someone-who-might-be-interested"></a></p>
<ul dir="auto">
<li>Share this article with digital agencies, SaaS entrepreneurs, or investors</li>
<li>Introduce me via email</li>
<li><strong>Referral bonus</strong>: I'll pay 5% ($3-4k) if your intro leads to a deal</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>If you're just curious:</strong></h3><a id="user-content-if-youre-just-curious" aria-label="Permalink: If you're just curious:" href="#if-youre-just-curious"></a></p>
<ul dir="auto">
<li>Test the demo anyway (it's genuinely cool tech)</li>
<li>Ask questions in the comments (I'll respond to everything)</li>
<li>Follow for updates on how this story ends</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Contact Information</h2><a id="user-content-contact-information" aria-label="Permalink: Contact Information" href="#contact-information"></a></p>
<p dir="auto"><strong>Email</strong>: <a href="mailto:EchenDeligani@gmail.com">EchenDeligani@gmail.com</a>
<strong>LinkedIn</strong>: <a href="https://www.linkedin.com/in/echen-deligani/" rel="nofollow">https://www.linkedin.com/in/echen-deligani/</a>
<strong>Telegram</strong>: @unnamedhn
<strong>WhatsApp</strong>: +98 901 441 1869</p>
<p dir="auto"><strong>Live Demo</strong>: <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a></p>
<p dir="auto"><strong>Partnership Options</strong>:</p>
<ul dir="auto">
<li>Co-founder: $50-80k + equity split</li>
<li>Sale + Contract: $60-80k + 3-year agreement ($4-6k/month)</li>
<li>Revenue share: $30-50k + 50/50 split until ROI</li>
</ul>
<p dir="auto"><strong>Timeline</strong>: 4-6 weeks from first contact to deal closed</p>
<hr>
<p dir="auto"><h2 dir="auto">Updates</h2><a id="user-content-updates" aria-label="Permalink: Updates" href="#updates"></a></p>
<p dir="auto">I'll update this section as things progress:</p>
<ul>
<li><strong>2025-11-12</strong>: Posted on Medium, HackerNews, Reddit r/SaaS</li>
<li> Demo calls scheduled</li>
<li> Code reviews in progress</li>
<li> Negotiating with potential partners</li>
<li> <strong>DEAL CLOSED</strong>: [Date TBD]</li>
</ul>
<p dir="auto">Follow me to see how this story ends.</p>
<hr>
<p dir="auto"><em>Originally written: November 2025</em></p>
<p dir="auto"><strong>Tags</strong>: #AI #Startups #SaaS #UnrealEngine #TechPartner #Partnership #SoulMachines #AvatarAI #ConversationalAI #IranTech #Entrepreneurship</p>
<hr>
<p dir="auto"><h2 dir="auto">Comments</h2><a id="user-content-comments" aria-label="Permalink: Comments" href="#comments"></a></p>
<p dir="auto"><strong>Questions? Want to discuss partnership? Technical deep-dive requests?</strong></p>
<p dir="auto">Drop a comment below or reach out directly. I respond to every message within 24 hours.</p>
<p dir="auto"><strong>I built this for 18 months through war and 120-hour weeks. Now I need a partner who can help me turn it into a real business.</strong></p>
<p dir="auto"><strong>Is that you?</strong></p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I didn't reverse-engineer the protocol for my blood pressure monitor in 24 hours (104 pts)]]></title>
            <link>https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/</link>
            <guid>45893095</guid>
            <pubDate>Tue, 11 Nov 2025 21:25:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/">https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=45893095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>Yesterday after receiving my yearly flu vaccine at the pharmacy I was offered a blood pressure test, which reported a reading that made the young pharmacist who had just given me my vaccine a bit worried.</p>
<p>Off the back of this she offered me a 24 hour study, and then strapped a cuff to my arm plumbed into a little device which I had to wear in a little caddy - the cuff would inflate every 30 minutes during the day and every 60 minutes during the night, and then tomorrow I would bring it back for analysis.</p>
<p>"Can I read the measurements?" I asked, as it was being strapped to me.</p>
<p>"Oh, no, that will just stress you out. We turn that off". Fair enough.</p>
<p>Thing is, this device had a little micro-USB port on the side.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/revealing-the-port.jpg" alt="A blood pressure monitor with a flap being held back, revealing a micro-USB port"></p><p>A blood pressure monitor with a flap being held back, revealing a micro-USB port</p>
<h2>Doing things the proper way</h2>
<p>I had started researching the device - a <a href="https://www.microlife.com/professional-products/watchbp-o3/watchbp-o3-ambulatory-2g">Microlife WatchBP O3</a> - before I got out of the chemist, and once I'd got back to the office I downloaded <a href="https://www.microlife.com/support/ambulatory-support">the software</a> that's freely available to interact with it, setting up a Bottles instance to run the software since I don't (knowingly) have a Windows machine within 100 metres of me.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/installing-watchbp-analyzer-in-bottles.png" alt="Installing WatchBP Analyzer in Bottles"></p><p>Installing WatchBP Analyzer in Bottles</p>
<p>Unfortunately it didn't seem to be able to access the device, and I had no clue why. In Linux it was just presenting as a standard <code>hidraw</code> device:</p>
<pre><code>[33301.736724] hid-generic 0003:04D9:B554.001E: hiddev96,hidraw1: USB HID v1.11 Device [USB HID UART Bridge] on usb-0000:c5:00.0-1/input0
</code></pre>
<p><em>Fine</em>, I'll install windows.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/send-diagnostic-data-to-microsoft.png" alt="Microsoft wants my diagnostic data"></p><p>Microsoft wants my diagnostic data</p>
<p>After dodging around Microsoft's idea of UX, and then forwarding the USB device to the VM (I used <a href="https://apps.gnome.org/en-GB/Boxes/">Gnome Boxes</a> for this, works nicely), I finally got to see WatchBP Analyzer with the data downloaded from the device.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/watchbp-analyzer.png" alt="WatchBP Analyzer with my first three measurements"></p><p>WatchBP Analyzer with my first three measurements</p>
<p>But I don't want to open a Virtual Machine running Windows to see this data, and anyway - I'm pretty sure that reverse-engineering this will be good for my blood pressure.</p>
<h2>Sniffing the traffic</h2>
<p>Since I'm running this in a Virtual Machine I can just rely on Wireshark in Linux to get the traffic between the host and the device. <code>usbmon</code> is already installed and we know that the device is on Bus 3, so we can select usbmon3 on startup and start capturing.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/wireshark-initial.png" alt="Wireshark with the initial capture"></p><p>Wireshark with the initial capture</p>
<p>I'm very much out of my depth at this point but, being <a href="https://www.sciencefocus.com/science/could-i-land-a-plane-in-an-emergency">one of those who could land a plane in an emergency</a> (why would you talk yourself out of it?!) I decided to crack on regardless. I know that the interesting stuff is sent after I press "Download", and I know that <em>something</em> in there is gonna say <em>"my blood pressure is 137/113"</em> - so let's look for that. Just convert to show bytes as decimal and..</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/hex-blood-pressure.png" alt="My blood pressure seems to be encoded in this packet"></p><p>My blood pressure seems to be encoded in this packet</p>
<p>..that looks like a blood pressure! Let's copy that out as hex:</p>
<pre><code>05 0a 89 71 43 9b
</code></pre>
<p>I'm not sure if this is "valid" HID Data (Wireshark seems convinced that only the first byte is the Vendor Data, with the rest being padding) but it seems like the data is being sent in 32-byte "chunks", of which the first byte tells you the number of significant (SIG) following bits in the chunk (I deleted the rest - all zeroes - for clarity). The third byte is my <em>Systolic</em> blood Pressure (SYS), the fourth is my <em>Diastolic</em> blood pressure (DIA), and the fifth is my heart rate (HR) - no clue what the second or last byte is, but let's find all other bytes with my blood pressure in them (in decimal this time, because I can't read hex without help):</p>
<pre><code>SIG ??? SYS DIA  HR ??? ??? ???
  5  10 137 113  67 155
  5   0 132  86  68 155
  6   0 126  84  82 155  83
  6  10 128  80  61 155  83
  7   0 148  93  65 155  83  64
  7   0 121  92  74 155  83  94
  7   0 123  83  65 155  83  95
  7   0 123  79  78 155  83 129
</code></pre>
<p>Hmm. So we're still looking for the Oscillometric signal peak pressure (OPP)as well as some timestamps (we can calculate Mean arterial pressure - MAP - as <code>(2*DIA+SYS)/3</code>, according to <a href="https://www.microlife.com/support/software-professional-products/watchbp-analyzer-support">the manual</a>, and Pulse Pressure (PP) is just <code>SYS-DIA</code>). We can see the OPP in the packets that come after each of those above, but they don't seem to consistently come in on the same line:</p>
<pre><code> 10  82  195   80 *121    0    0    0    0    0    0
 10  82  223   80  *95    0    0    0    0    0    0
  9   1   80  *90    0    0    0    0    0    0
  9  35   80  *86    0    0    0    0    0    0
  8  80 *103    0    0    0    0    0    0
  8  80 *106    0    0    0    0    0    0
  8  80  *90    0    0    0    0    0    0
 10  80  *88    0    0    0    0    0    0   29  251
</code></pre>
<p>Oh. Maybe if I stick them together?</p>
<pre><code>??? SYS DIA  HR ??? ??? ??? ??? OPP ??? ??? ??? ??? ??? ??? ??? ???
 10 137 113  67 155  82 195  80 121   0   0   0   0   0   0
  0 132  86  68 155  82 223  80  95   0   0   0   0   0   0
  0 126  84  82 155  83   1  80  90   0   0   0   0   0   0
 10 128  80  61 155  83  35  80  86   0   0   0   0   0   0
  0 148  93  65 155  83  64  80 103   0   0   0   0   0   0
  0 121  92  74 155  83  94  80 106   0   0   0   0   0   0
  0 123  83  65 155  83  95  80  90   0   0   0   0   0   0
  0 123  79  78 155  83 129  80  88   0   0   0   0   0   0  29 251
</code></pre>
<p>Right, timestamps. I first guessed that the four populated contiguous bytes between <code>HR</code> and <code>OPP</code> are a 32-bit unix timestamp, but that would make the first one <code>9B52C350</code>; either <code>Jul 29 2052</code> or <code>Dec 08 2012</code> depending on which endianness the protocol is into. The 8 readings we have here are all from <code>November 10th</code>, at <code>11:03</code>, <code>11:31</code>, <code>12:01</code>, <code>12:35</code>, <code>13:00</code>, <code>13:30</code>, <code>13:31</code> and <code>14:01</code>, which isn't.. isn't that.</p>
<p>But note that the number in the 6th column flips from <code>82</code> to <code>83</code> when we switch from AM to PM - that's something, and when it does the 7th column resets. And hey - <code>1</code>, <code>35</code>, <code>64</code>, <code>94</code>, <code>95</code>.. that seems dangerously close to <code>12:01</code>, <code>12:35</code>, <code>13:00</code>, <code>13:30</code> and <code>13:31</code> if you were just to count the minutes. What's going on?</p>
<h2>Deadlines and dead ends</h2>
<p>I tried feeding a lot of this into various Als (Kagi gives you access to a few with a nice interface) and I found that they mostly were stupid in ways that made me think. A few times I thought they had <em>"cracked the case"</em> but actually they just made me waste time. But they did remind me e.g. of endianness, so I did get a bit out of them.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/hex-is-hard-for-llms.png" alt="Kimi K2 demonstrating creativity with numbers"></p>
<p>I also spent quite a bit of time trying to write some Python that emulated the initial handshake and download button of the interface so that it could push out the data as a stream instead of me having to wrestle it out of Wireshark - again, Al had a habit of giving me incorrect code (although it did turn me on to <a href="https://pypi.org/project/hid/">pyhidapi</a>).</p>
<p>But ultimately I had a deadline, and I had to return the device even though I wanted to spend more time with it. Possibly for the best - while it did give me some reverse engineering practice (which it turns out I really enjoy), I should do some work instead of procrastinating.</p>
<p>My final lesson was a new word - <em>Normotension</em>, normal blood pressure - and a new phrase - <em>White Coat Hypertension</em>, the phenomena of high blood pressure in a clinical setting. Turns out that when you check someone's blood pressure after giving them an injection, it's higher than normal.</p>
<p>I don't think I'd recommend getting your blood pressure tested after your next flu jab. But then, I'm not a doctor.</p>

                <br>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X5.1 solar flare, G4 geomagnetic storm watch (141 pts)]]></title>
            <link>https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</link>
            <guid>45893004</guid>
            <pubDate>Tue, 11 Nov 2025 21:18:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html">https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</a>, See on <a href="https://news.ycombinator.com/item?id=45893004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SWL_Page">
                    <div>
                        
                        
<h3>X5.1 solar flare, G4 geomagnetic storm watch</h3><p>Tuesday, 11 November 2025 19:07 UTC</p><p><img src="https://www.spaceweatherlive.com/images/news/593-header.jpg" loading="lazy" alt="X5.1 solar flare, G4 geomagnetic storm watch" width="900" height="450"></p><p>Here she blows! Sunspot region 4274 produced its strongest solar flare thus far since it appeared on the east limb and the sixth strongest solar flare of the current solar cycle. An impressive long duration and highly eruptive X5.1 (R3-strong) solar flare peaked this morning at 10:04 UTC.</p><p>It became quickly clear that the eruption would be followed by an impressive coronal mass ejection (CME). The resulting coronal wave following the solar explosion as well as the coronal dimming observed as the CME was propelled into space were of a spectacular magnitude as can be seen in the animation below provided by <a href="https://x.com/halocme" target="_blank" rel="noopener">halocme</a>.</p><blockquote data-media-max-width="560"><p dir="ltr" lang="en">Another eruption from AR12474, associated with an X5.1 flare. It has become a full halo CME. I am truly impressed by how fast and global this coronal wave is. The CME will arrive on November 13, but because of earlier CMEs it will be challenging to isolate the ICME from this. <a href="https://t.co/H6eNjzQUGz">pic.twitter.com/H6eNjzQUGz</a></p>‚Äî Halo CME (@halocme) <a href="https://twitter.com/halocme/status/1988253760179548649?ref_src=twsrc%5Etfw">November 11, 2025</a></blockquote><p>Taking a look at coronagraph imagery provided by GOES-19 CCOR-1 we see the gorgeous fast halo coronal mass ejection as it propagates away from the Sun. It doesn't take a rocket scientist to come to the conclusion that this plasma cloud of course has an earth-directed component and it is pretty clear that this will be a strong impact when it arrives at our planet. This rightfully so prompted the NOAA SWPC to issue a G4 or greater geomagnetic storm watch for tomorrow as the cloud could impact our planet as early as 16 UTC on 12 November. Not only is the CME fast but it will also travel trough an area with high ambient solar wind speed and low density thanks to two other CMEs released earlier by this region. More about that below.</p><figure><img src="https://www.spaceweatherlive.com/images/news/2025/593-cme.gif"><figcaption>Coronal mass ejection launched during today's X5.1 solar flare as captured by the coronagraph from GOES-19.</figcaption></figure><p>If the solar wind and interplanetary magnetic field values at Earth are favorable this could result in a geomagnetic storm which is strong enough for aurora to become visible from locations as far south as northern France, Germany, Ukraine, Switzerland and Austria. In the US it could become visible as far south as Nevada and Arkansas. No guarantees of course, this is space weather we are talking about but be sure to download the SpaceWeatherLive app to your mobile device, turn on the alerts and keep an eye on the solar wind data from ACE and DSCOVR!</p><p>We also want to remind you that we still have two coronal mass ejections on their way to Earth. These are not as impressive as this X5.1 CME but these two plasma clouds will likely arrive within the next 6 to 18 hours. This is a tricky one as they could arrive as one impact or two impacts close intill each other. More information in <a href="https://www.spaceweatherlive.com/en/news/view/592/20251110-x1-2-solar-flare-with-earth-directed-cme.html" target="_blank" rel="noopener">yesterday's news</a>.</p><div> <p><em>Thank you for reading this article! Did you have any trouble with the technical terms used in this article? Our help section is the place to be where you can find in-depth <a href="https://www.spaceweatherlive.com/en/help.html">articles</a>, a <a href="https://www.spaceweatherlive.com/en/faq.html">FAQ</a> and a list with common <a href="https://www.spaceweatherlive.com/en/acronyms-and-abbreviations.html">abbreviations</a>. Still puzzled? Just post on our <a href="https://community.spaceweatherlive.com/">forum</a> where we will help you the best we can! <span> Never want to miss out on a space weather event or one of our news articles again? Subscribe to our <a href="https://www.spaceweatherlive.com/en/mailinglist.html">mailing list</a>, follow us on <a href="https://twitter.com/_SpaceWeather_">Twitter</a> and <a href="https://www.facebook.com/SpaceWeatherLive/">Facebook</a> and download the SpaceWeatherLive app for <a href="https://play.google.com/store/apps/details?id=com.spaceweatherlive.app">Android</a> and <a href="https://itunes.apple.com/us/app/spaceweatherlive/id1435501021?mt=8">iOS</a>! </span> </em> </p></div>
                        
                    </div>
                                            <div>
                                                          <div>  <p>A lot of people come to SpaceWeatherLive to follow the Solar activity or if there is a chance to see the aurora, but with more traffic comes higher costs to keep the servers online. If you like SpaceWeatherLive and want to support the project you can choose a subscription for an ad-free site or consider a donation. With your help we can keep SpaceWeatherLive online!</p>  <p><a href="https://shop.spaceweatherlive.com/" target="_blank"><img src="https://www.spaceweatherlive.com/images/SWL_Shop.png" alt="Support SpaceWeatherLive with our merchandise" width="600" height="200"></a> </p> <p><a href="https://shop.spaceweatherlive.com/" target="_blank"> <b>Check out our merchandise</b></a></p></div><div><table><thead><tr><th colspan="2">Spotless days</th></tr></thead><tbody><tr><td>Last spotless day</td><td>2022/06/08</td></tr></tbody></table><table><thead><tr><th colspan="2">Monthly mean Sunspot Number</th></tr></thead><tbody><tr><td>October 2025</td><td>114.6 <span> -15.2</span></td></tr><tr><td>November 2025</td><td>91.9 <span> -22.7</span></td></tr><tr><td>Last 30 days</td><td>96.2 <span> -34.6</span></td></tr></tbody></table><h4>This day in history*</h4><div><table><thead><tr><th></th><th></th><th>Dst</th><th>G</th></tr></thead><tbody><tr><td>1</td><td><a href="https://www.spaceweatherlive.com/en/archive/2004/11/11.html">2004</a></td><td>-106</td><td><span>G1</span></td></tr><tr><td>2</td><td>1981</td><td>-78</td><td><span>G2</span></td></tr><tr><td>3</td><td>1974</td><td>-72</td><td><span>G3</span></td></tr><tr><td>4</td><td><a href="https://www.spaceweatherlive.com/en/archive/2013/11/11.html">2013</a></td><td>-68</td><td><span>G1</span></td></tr><tr><td>5</td><td>1991</td><td>-64</td><td><span>G1</span></td></tr></tbody></table><p>*since 1994</p></div></div>                           </div>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Collaboration sucks (287 pts)]]></title>
            <link>https://newsletter.posthog.com/p/collaboration-sucks</link>
            <guid>45892394</guid>
            <pubDate>Tue, 11 Nov 2025 20:27:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.posthog.com/p/collaboration-sucks">https://newsletter.posthog.com/p/collaboration-sucks</a>, See on <a href="https://news.ycombinator.com/item?id=45892394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2y1b!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" width="1456" height="1048" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1048,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:801531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>‚ÄúIf you want to go fast, go alone; if you want to go far, go together‚Äù</p><p>This phrase will slowly kill your company and I‚Äôm here to prove it.</p><p>Imagine you are driving a car. It‚Äôs often useful to have someone give you directions, point out gas stations, and recommend stops for snacks. This is a helpful amount of collaboration.</p><p>An unhelpful amount of collaboration is getting out of your car to ask pedestrians if they like your car, swapping drivers every 10 minutes, or having someone constantly commenting on your driving.</p><p>In the first scenario, you get the right amount of feedback to get to your destination as fast as possible. In the second, you get more feedback, but it slows you down. You run the risk of not making it to the place you want to go.</p><p>The second scenario is also the one most startups (or companies, really) end up in because of ‚ú® collaboration ‚ú®.</p><p>As PostHog grows, I‚Äôve seen more and more collaboration that doesn‚Äôt add value or adds far too little value for the time lost collaborating. So much so we made ‚Äúcollaboration sucks‚Äù the topic of the week during a recent company all hands.</p><p><span>‚ÄúYou‚Äôre the driver‚Äù is a </span><a href="https://posthog.com/handbook/values?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">key value</a><span> for us at PostHog. We aim to hire people who are great at their jobs and get out of their way. No deadlines, minimal coordination, and no managers telling you what to do.</span></p><p><span>In return, we ask for extraordinarily high ownership and the ability to get a lot done by </span><em>yourself.</em><span> Marketers ship code, salespeople answer technical questions without backup, and </span><a href="https://posthog.com/blog/what-is-a-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">product engineers</a><span> work across the stack.</span></p><p>This means there is almost always someone better at what you are doing than you are. It is tempting to get them, or anybody really, involved and ‚ú® collaborate ‚ú®, but collaboration forces the driver to slow down and explain stuff (background, context, their thinking).</p><p>This tendency reveals itself in a few key phrases:</p><ul><li><p>‚ÄúCurious what X thinks‚Äù</p></li><li><p>‚ÄúWould love to hear Y‚Äôs take on this‚Äù</p></li><li><p>‚ÄúWe should work with Z on this‚Äù</p></li></ul><p><span>This </span><em>sometimes</em><span> leads to valuable insights, but </span><em>always</em><span> slows the driver down. It erodes their motivation, confidence, and effectiveness, and ultimately leads us to ship less.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MoTP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" width="714" height="328.5576923076923" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:670,&quot;width&quot;:1456,&quot;resizeWidth&quot;:714,&quot;bytes&quot;:463445,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Everyone is to blame.</p><ul><li><p><span>People want to be helpful. For example, when someone posts their work-in-progress in Slack, others feel obliged to give feedback because we have a </span><a href="https://posthog.com/handbook/people/feedback?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">culture of feedback</a><span>.</span></p></li><li><p>On the flip side, people don‚Äôt ask for feedback from specific people because it doesn‚Äôt feel inclusive, even though it would help.</p></li><li><p>People aren‚Äôt specific enough about what feedback they need. This creates more space for collaboration to sneak in. A discussion about building a specific feature can devolve into reevaluating the entire product roadmap if you let it.</p></li><li><p>When someone has a good idea, the response often defaults to ‚Äúlet‚Äôs discuss‚Äù rather than ‚Äúok, do it.‚Äù As proof, we have 175 mentions of ‚Äúlet‚Äôs discuss‚Äù in Slack.</p></li><li><p><span>People just want to talk about stuff because they </span><s>are too busy</s><span> can‚Äôt be bothered to act on it. We drift from our ideal of a pull request to an issue/RFC to Slack (we are mostly here) to ‚Äúlet‚Äôs discuss‚Äù.</span></p></li><li><p>It‚Äôs not clear who the owner is (or no one wants to own what‚Äôs being discussed).</p></li><li><p>It is annoying, but sometimes a single person can‚Äôt ship certain things front to back to a high-enough quality and we can‚Äôt just ship and iterate. We can fix broken code, but we can‚Äôt resend a newsletter.</p></li></ul><p>So if collaboration is your enemy, how do you defeat it? Here‚Äôs what we say:</p><ul><li><p>Default to shipping. Pull requests &gt; issues &gt; Slack messages.</p></li><li><p>Every time you see ‚ú® collaboration ‚ú® happening, speak up and destroy it. Say ‚Äúthere are too many people involved. X, you are the driver, you decide.‚Äù (This is a great way to make friends btw).</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!CtaP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" width="1456" height="870" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:870,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;How to make friends and crush collaboration&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="How to make friends and crush collaboration" title="How to make friends and crush collaboration" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Graphic design is my passion</figcaption></figure></div><ul><li><p>Tag who you specifically want input from and what you want from them, not just throw things out there into the void.</p></li><li><p>Prefer to give feedback after something has shipped (but before the next iteration) rather than reviewing it before it ships. Front-loading your feedback can turn it into a quasi-approval process.</p></li><li><p><span>If you are a team lead, or leader of leads, who has been asked for feedback, consider being more </span><a href="https://www.youtube.com/shorts/DjvVN4Vp_r0" rel="">you can just do stuff</a><span>.</span></p></li><li><p>When it‚Äôs your thing, you are the ‚Äúinformed captain.‚Äù Listen to feedback, but know it‚Äôs ultimately up to you to decide what to do, not the people giving feedback.</p></li></ul><p><span>Unfortunately for me, not all collaboration can be rooted out, and even I will admit that some collaboration is useful. </span><a href="https://www.linkedin.com/in/ianvanagas/" rel="">Ian</a><span> and </span><a href="https://www.linkedin.com/in/andyvandervell/" rel="">Andy</a><span> edited this newsletter after all. </span></p><p><span>The point is, if you aren‚Äôt actively attempting to collaborate less, you are probably collaborating too much by default and hurting your ability to go far, fast.</span><em><p><span>Words by </span><a href="https://www.linkedin.com/in/wololo/" rel="">Charles Cook</a><span>, who also hates sparkling water, presumably because the bubbles are too collaborative.</span></p></em></p><ul><li><p><strong><a href="https://posthog.com/careers/ai-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">AI Product Engineer</a></strong><span> working on PostHog AI, LLM Analytics or Array teams.</span></p></li><li><p><span>Backend Engineer for </span><strong><a href="https://posthog.com/careers/backend-engineer-feature-flags?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Feature Flags</a></strong><span> and </span><strong><a href="https://posthog.com/careers/backend-engineer-ingestion?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Ingestion</a></strong><span> teams</span></p></li><li><p><strong><a href="https://posthog.com/careers/influencer-wrangler?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Influencer Wrangler</a></strong><span> on the Marketing team</span></p></li><li><p><strong><a href="https://posthog.com/careers/yc-technical-onboarding-specialist-onsite?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">YC Technical Onboarding Specialist </a></strong><span>on the Onboarding team (San Fran based)</span></p></li><li><p><strong><a href="https://posthog.com/careers/clickhouse-operations-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">ClickHouse Operations Engineer</a></strong><span> on the ClickHouse team</span></p></li></ul><ul><li><p><strong><a href="https://posthog.com/blog/workflows-alpha?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Workflows are now in Alpha and I already broke mine</a><span> ‚Äì Sara Miteva</span></strong></p></li><li><p><strong><a href="https://notes.mtb.xyz/p/your-data-model-is-your-destiny?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Your data model is your destiny</a><span> ‚Äì&nbsp;Matt Brown</span></strong></p></li><li><p><strong><a href="https://www.dylanamartin.com/2025/11/07/spinning-plates.html?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Spinning Plates</a><span> ‚Äì Dylan Martin</span></strong></p></li><li><p><strong><a href="https://www.youtube.com/watch?v=yKgfk8lTQuE?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">1000x: The Power of an Interface for Performance</a><span> (video) ‚Äì Joran Dirk Greef</span></strong></p></li></ul><div id="youtube2-bs_v-xY7Nqw" data-attrs="{&quot;videoId&quot;:&quot;bs_v-xY7Nqw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/bs_v-xY7Nqw?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A modern 35mm film scanner for home (125 pts)]]></title>
            <link>https://www.soke.engineering/</link>
            <guid>45891907</guid>
            <pubDate>Tue, 11 Nov 2025 19:48:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.soke.engineering/">https://www.soke.engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=45891907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div webpageid="augiA20Il" data-layout-template="true" id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localeId&quot;:&quot;default&quot;,&quot;breakpoints&quot;:[{&quot;hash&quot;:&quot;72rtr7&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1200px)&quot;},{&quot;hash&quot;:&quot;1gly80&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1199.98px)&quot;},{&quot;hash&quot;:&quot;1teekcz&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;},{&quot;hash&quot;:&quot;4e4xff&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1440px)&quot;},{&quot;hash&quot;:&quot;wthtfe&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1439.98px)&quot;},{&quot;hash&quot;:&quot;1l7dlx4&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;}]}" data-framer-ssr-released-at="2025-11-10T14:50:19.351Z" data-framer-page-optimized-at="2025-11-11T21:36:56.978Z" data-framer-generated-page=""><nav data-framer-appear-id="h121gk" data-framer-layout-hint-center-x="true" data-framer-name="Navbar"></nav><div data-framer-root=""><header data-framer-name="Hero-Section" id="hero-section"><div data-framer-name="Container"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><header data-framer-name="Hero-Section" id="hero-section-1"><div data-framer-name="Container"><div data-framer-name="Left-Text"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><div data-framer-name="Highlights"><p><!--$--><h2><span>Knokke  - a high-resolution 35 mm film scanner built for photographers who demand speed, quality and control.</span></h2><!--/$--></p></div></div><div data-framer-name="Variant 1" data-highlight="true" tabindex="0" data-framer-appear-id="1wbnzl8" id="1wbnzl8"><p><svg style="width:100%;height:100%;transform-origin:center" viewBox="0 0 100 100" overflow="visible"><path id="curve-wnxkz4" d="M 0 50 L 0 50 A 1 1 0 0 1 100 50 L 100 50 L 100 50 A 1 1 0 0 1 0 50 L 0 50" stroke-width="none" fill="transparent"></path><text><textPath href="#curve-wnxkz4" startOffset="0" dominant-baseline="Text Top" style="letter-spacing:0.02em;font-family:&quot;IBM Plex Mono&quot;, monospace;font-size:14px;font-style:normal;font-weight:500;line-height:1em;fill:var(--token-ba5469a1-3890-44cc-aaeb-d6b7e143f20d, rgb(244, 244, 245))">Watch the video - Watch the video -</textPath></text></svg></p></div></div></header><header data-framer-name="Hero-Section" id="hero-section-2"><div data-framer-name="Container"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><p><!--$--><h2><span>Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality, and control.</span></h2><!--/$--></p></div><div data-framer-appear-id="truicp" data-framer-name="Image"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><div data-framer-name="Proof Section" id="proof"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo">Knokke redefines film scanning by bringing modern imaging, optics, and software into a beautifully engineered device.</h2></p></div><div data-framer-name="Product Section" id="features"><div data-framer-name="Components/Product item"><p>The modern 35 mm film scanner that captures a full roll in under just a few minutes while capturing every frame at 4064 DPI and 48bit colour. Its custom optics and state-of-the-art sensor deliver benchmark setting quality and speed at a price only Knokke can offer.</p></div><div data-framer-component-type="RichTextContainer" data-framer-name="Product 2"><p>Built for the 21st century, Knokke runs on Korova, a lean C++ application that's native to Linux, macOS, and Windows‚Äîso you can forget vintage PCs and enjoy a plug-and-play workflow that lets you focus on your photos.</p><p>Each frame can have custom scan settings, repeatable across multiple scans for consistent results and tailored workflows. The scanner can also skip directly to requested frames, massively accelerating scanning time and enabling fast access to key shots without unnecessary delay.</p></div></div><div data-framer-name="Features Section"><div data-framer-name="Image"><p><img decoding="async" loading="lazy" width="5152" height="7728" sizes="(min-width: 1200px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw), (min-width: 810px) and (max-width: 1199.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw, 254px), (max-width: 809.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), min(100vw - 32px, 1200px), 100vw)" srcset="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=1024&amp;width=5152&amp;height=7728 682w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=2048&amp;width=5152&amp;height=7728 1365w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=4096&amp;width=5152&amp;height=7728 2730w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728 5152w" src="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728" alt="" data-framer-original-sizes="max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px)"></p></div><div data-framer-name="Heading"><p id="w8drg9" data-framer-component-type="RichTextContainer"><h3 data-styles-preset="gUnjFa38F">Engineered for Individual Users and Lab Professionals</h3></p><div data-framer-name="Grid"><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">01</h6></p><p data-framer-component-type="RichTextContainer"><h6>Quality</h6></p></div><p>Knokke‚Äôs premium build and precision engineering ensure lasting, reliable performance.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">02</h6></p><p data-framer-component-type="RichTextContainer"><h6>Speed</h6></p></div><p>Knokke‚Äôs high scan speed and streamlined workflow keep you moving.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">03</h6></p><p data-framer-component-type="RichTextContainer"><h6>Full Control</h6></p></div><p>Knokke lets you fine-tune every detail with flexible settings and precise color control.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">04</h6></p><p data-framer-component-type="RichTextContainer"><h6>Future Proof</h6></p></div><p>Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.</p></div></div></div></div><div data-framer-name="CTA-Section" id="cta-section"><div data-framer-name="Left"><p data-framer-component-type="RichTextContainer"><h2>Price at Launch</h2></p></div><div data-framer-name="Right"><div data-framer-name="Price"><p><!--$--><h2><span>999‚Ç¨</span></h2><!--/$--></p><p><strong>Includes scanner + software</strong></p></div><div data-framer-name="Features"><div data-framer-name="Row"><p><!--$--><h2><span>4064 dpi resolution</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>5 min per roll</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>48-bit colour depth</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>120 dB Dynamic Range</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>LED Matrix</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>RGB LED backlight</span></h2><!--/$--></p></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg to Google: Fund Us or Stop Sending Bugs (486 pts)]]></title>
            <link>https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</link>
            <guid>45891016</guid>
            <pubDate>Tue, 11 Nov 2025 18:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/">https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</a>, See on <a href="https://news.ycombinator.com/item?id=45891016">Hacker News</a></p>
Couldn't get https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[We ran over 600 image generations to compare AI image models (106 pts)]]></title>
            <link>https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/</link>
            <guid>45890186</guid>
            <pubDate>Tue, 11 Nov 2025 17:26:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/">https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/</a>, See on <a href="https://news.ycombinator.com/item?id=45890186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p><b>tl:dr; </b>We‚Äôve been making photo apps for iOS for long enough that we have gray hairs now, and using our experience we ran over 600 image generations to compare which AI models work best for which image edits. If you want, you can jump right to the <a href="#filters">image comparisons</a>, or the <a href="#conclusion">conclusion</a>, but promise us you won‚Äôt presumptuous comments on Hacker News until you‚Äôve also read the background!</p>



<h2>Background</h2>



<p>Hi! We‚Äôre LateNiteSoft, and we‚Äôve been working on photography-related iOS apps for 15 years now. Working on market-leading apps such as Camera+, <a href="https://photon.cam/?from=lnsblog">Photon</a> and <a href="https://recvideoapp.com/">REC</a>, we‚Äôve always had our finger on the pulse on what users want out of their mobile photography.</p>



<p>With the ground-breaking release of OpenAI‚Äôs <b>gpt-image-1</b> image generation model earlier this year, we started investigating all the interesting use cases we could think of for AI image editing.</p>



<p>But as a company that has never taken any venture capital investment, all our products have to pay for themselves. We‚Äôre in it to delight our users, not just capture market share and sell them out. When considering AI projects, one thing has been clear ‚Äì we can‚Äôt take the AI startup road where you have a generous free tier, charge an unreasonably small monthly fee for ‚Äúunlimited‚Äù, and hope you‚Äôre going to make it up on scale (code for ‚Äúsomeone please acquire us‚Äù).</p>



<p>All the AI-focused billing systems we could find out there were based on this. Assuming you want to claim unlimited access, and then sandbag users with ‚Äúfair use‚Äù clauses and prevent them from any actual unlimited usage (which is, obviously, untenable, since you‚Äôll end up with one $20/mo user reselling to everyone else).</p>



<p>Since we want to fairly charge our customers for what they actually use, we‚Äôve built a credit-based ‚Äúpay per generation‚Äù-style billing system (that internally we‚Äôve been calling CreditProxy). We‚Äôve also been planning on providing this as a service, since nobody else seems to be doing it, so if you‚Äôre interested in being a trial user, <a href="https://latenitesoft.com/contact/">get in touch!</a></p>



<p>We released our app <a href="https://apps.apple.com/app/apple-store/id6745558534?pt=11365&amp;ct=lnsblog&amp;mt=8">MorphAI</a> as a public proof of concept to give CreditProxy a proper real world-test, and have marketed it to the users of Camera+, which includes traditional photo-editing functionality, including a whole host of popular photo filters, giving us a built-in audience of customers ready for the next step in image editing.</p>



<p>With the release of newer models like nanoBanana and Seedream, we‚Äôve had to consider which models make sense to support. We need to explore the trade-offs between quality, prompt complexity, and pricing.</p>



<p>A couple of hastily-hacked together scripts, and many, many AI generation credits later, we have some results! So that everyone else also doesn‚Äôt have to waste their money, we figured we‚Äôd share what we found:</p>



<h2>The Tests</h2>



<p>Based on our experience with Camera+ and the kind of edits our users have been making with MorphAI, we picked a host of somewhat naive prompts. Veteran Midjourney users may scoff at these, but in our experience these are the kinds of prompts that our average user is likely to use.</p>



<p>As for test photos, we chose some some representative things people like to take photos of: their pets, their kids, landscapes, their cars, and product photography.</p>



<p>
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/landscape.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/car.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/pets.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/portrait.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/product.jpg">
</p>



<p>Image generation times are also relevant. During our test period, the generation time for all models was fairly consistent, and didn‚Äôt vary by image or prompt complexity.</p>



<figure><table><tbody><tr><td><strong>OpenAI (High)</strong></td><td><strong>Gemini</strong></td><td><strong>Seedream</strong></td></tr><tr><td>80 seconds</td><td>11 seconds</td><td>9 seconds</td></tr></tbody></table></figure>



<p>OpenAI also has a quality setting, the images included here were all generated on High quality, but we also tested Medium, and those generations averaged 36 seconds. We can include the Medium quality images as well if there is any interest!</p>



<p>There are a ton of photos to compare here, so to make things easier to flip through, here are some <strong>keyboard shortcuts</strong> to help you out: Click on a photo to see it larger. Now you can use the arrow keys to switch between models. Press the tab key to switch between test images. Hit ESC to leave the view.</p>



<h2 id="filters">Classic filters</h2>



<p>These are the types of filters that we used to implement manually, by painstakingly hand-crafting textures and Photoshop layers and then converting those to Objective-C code. Now all you need is a few words into a language model (and to burn down half of a rain forest or so; just the cost of progress).</p>



<p>Our conclusion for this category is that for photo realistic filters like this, Gemini really shines by preserving details from the original and minimizing hallucinations, but often at the expense of the strength and creativity of the effect. Especially with photos of people, Gemini seems to refuse to apply any edits at all, with a strong bias towards photo realism.</p>



<p>OpenAI really likes to mess with the details of the photo, giving a characteristic ‚ÄúAI slop‚Äù feel, which can be a deal breaker on things like human faces.</p>



<h3>Grungy vintage photo</h3>






<h3>Use soft, diffused lighting</h3>






<h3>Transform into a kaleidoscopic pattern</h3>



<p>Gemini took some really odd shortcuts in generating some of these!</p>






<h3>Apply a heat map effect</h3>



<p>It‚Äôs clear that none of the models actually have a concept of what generates heat here, aside from Seedream knowing that humans generate heat, clearly revealing that without any ground truth the models struggle.</p>






<h3>Make it look like a long exposure photograph</h3>



<p>This is an interesting test since in some of the sample photos a long exposure doesn‚Äôt make sense. In the ones where it makes the most sense ‚Äì the landscape and the car, OpenAI did the best, but on the other hand it completely messed up the cats and the product, and the portrait photo turned into a trippy art piece.</p>



<p>Gemini, maybe logically, did nothing. Seedream liked adding light streaks as if a car drove past, with only the portrait photo seemingly making any sense.</p>






<h3>Pinhole camera</h3>



<p>In this case, it was funny to watch Gemini take a literal approach and generate actual pictures of cameras! For this reason we re-worked this prompt by just adding the word ‚Äúeffect‚Äù.</p>






<h3>Pinhole camera effect</h3>



<p>Gemini liked to generate a literal pinhole camera here so we tried modifying the prompt.</p>






<h3>Add a layer of fog or mist</h3>






<h3>Make it look like it‚Äôs golden hour</h3>






<h3>Make it look like it‚Äôs etched in glass</h3>



<p>With this prompt, there is ambiguity in what ‚Äúit‚Äù is, so we tried a reworded prompt as well. Only OpenAI consistently knew what a traditional etched glass effect looks like. Seedream‚Äôs glass item effect looks really cool!</p>






<h3>Make it look like the photo is etched in glass</h3>



<p>Gemini has a really interesting interpretation here! And Seedream had some pretty fantastic results.</p>






<h3>Remove background</h3>



<p>This is a classic job people have spent their lives doing manually in Photoshop since the early 90‚Äôs. But what is a ‚Äúbackground‚Äù, really? Is the ground in front of a car the ‚Äúbackground‚Äù? We also retried this with a tweaked prompt.</p>



<p>OpenAI‚Äôs ‚Äúsloppification‚Äù of the details of objects makes it useless for this purpose.</p>






<h3>Isolate the object</h3>



<p>With the tweaked prompt, Gemini‚Äôs API actually returned a followup question: <em>‚ÄúWhich object would you like to isolate? There are two cats in the image.‚Äù</em>, which our generation script was not prepared to handle! So it is missing from this comparison.</p>






<h3>Give it a metallic sheen</h3>



<p>Another case where ‚Äúit‚Äù is vague and we can retry with a more specific prompt. The product imagery is another case where Seedream created a really stunning result, even adding a reflection of someone taking the photo with their phone!</p>






<h3>Give the object a metallic sheen</h3>



<p>Modifying the prompt here really only changed OpenAI‚Äôs interpretation.</p>






<h2>Lens effects</h2>



<p>One of the filter packs we had worked on for Camera+ using traditional methods was a lens effect filter pack. But unlike traditional edits, with generative AI you can also create wide-angle lens effects that can just make up the portions of the image that the camera couldn‚Äôt capture.</p>



<p>This is another category where it‚Äôs very visible how OpenAI regenerates and hallucinates all the details in a picture, where Gemini and Seedream‚Äôs results are very faithful to the original and look more like actual lens permutations.</p>



<h3>Apply a fish-eye lens effect</h3>






<h3>Strong bokeh blur</h3>



<p>It was pretty surprising how poorly the models did here considering how common this must be among the training data. OpenAI give a strong blur but no bokeh effects. Gemini gives us a bunch of random circles in front of the image, demonstrating an understanding of what people want out of a bokeh filter but not how it works. Seedream does really well here.</p>






<h3>Apply a Dutch angle (canted frame)</h3>



<p>OpenAI really lost it‚Äôs mind here on the car photo.</p>






<h3>Change to a bird‚Äôs-eye view</h3>






<h2>Style transfer</h2>



<p>Style Transfer is the process of applying an artistic style to a photo. This technique predates the current AI model by quite a few years with popular apps generating Van Gogh paintings out of your photos. We were also early out in attempting style transfer for our apps, shout out to Noel‚Äôs Intel iMac which had to run at full blast all night just to generate a 256x256px image, since it was our only machine with a compatible GPU.</p>



<p>While Gemini was good at preserving reality in the more photorealistic effects in the previous section, when it comes to the more artistic styles, OpenAI has them beat, while Gemini keeps things far too conservative, especially with photos of a human in them, where it sometimes seems to just do nothing at all, is this some kind of safety guardrail?</p>



<h3>Draw this in the style of a Studio Ghibli movie</h3>



<p>ChatGPT went viral with this prompt, with Sam Altman even making it his profile on X. And OpenAI keeps the crown ‚Äì is Google too conservative in order to avoid a lawsuit? Seedream makes an attempt but they just end up looking like ‚Äúgeneric Anime‚Äù.</p>






<h3>Transform into watercolor painting</h3>






<h3>Make it look like a pastel artwork</h3>






<h3>Transform into Art Nouveau style</h3>






<h3>Apply a ukiyo-e Japanese woodblock print style</h3>



<p>A very stark example of Gemini failing to apply a style on photos with humans. This is a prompt where Seedream knocked it out of the park, perhaps showing a larger portion of their training data being sourced from asian cultures than the western models.</p>






<h3>Transform into low poly art</h3>



<p>Seedream blows everyone else away here.</p>






<h2>Portrait effects</h2>



<p>For prompts about human appearance, we have only applied them to the portrait photo.</p>



<h3>Make it look like a caricature</h3>



<p>Seedream seems to be biased towards asian culture, giving an anime look instead of a western-style cartoon caricature.</p>






<h3>Turn them into an action figure in the blister pack</h3>



<p>OpenAI‚Äôs style here went viral a while back, but Gemini is stunningly realistic. Seedream is a weird mix of realistic and hallucinations.</p>






<h2>Generative edits</h2>



<p>The place where generative AI really shines is when it can show off some creativity, and these were some prompts we added as suggestions in MorphAI to showcase that and inspire our users. OpenAI still seems to win here.</p>



<h3>Create a 70‚Äôs vinyl record cover</h3>



<p>This is an example of a prompt that has a small viral moment with OpenAI, but the other models can‚Äôt even get the aspect ratio right.</p>






<h3>Introduce mythical creatures native to this environment</h3>



<p>This one showcases OpenAI‚Äôs creativity. Gemini seems kind of creepy?</p>






<h3>Add a mystical portal or gateway</h3>



<p>Gemini replacing the face with a portal is certainly a choice!</p>






<h3>Incorporate futuristic technology elements</h3>



<p>Another example of OpenAI being far more creative and willing to re-do the whole image.</p>






<h3>Make it look whimsical and enchanting</h3>



<p>This one also shows OpenAI being more artistic, and Gemini being more realistic while still trying to incorporate the prompt.</p>






<h3>Transform the scene to a stormy night</h3>






<h2 id="conclusion">Conclusion</h2>



<p>If you made it all the way down here you probably don‚Äôt need a summary, but for our purposes, we‚Äôve at least concluded that there is no one-size-fits all model at this point.</p>



<p>OpenAI is great for fully transformative filters like style transfer or more creative generative applications, whereas Gemini works better for more realistic edits. Seedream lies somewhere in the middle and is a bit of a jack of all trades, and for the price and performance may be a good replacement for OpenAI.</p>



<p>We‚Äôve been experimenting on working on a ‚Äúprompt classifier‚Äù to automatically choose a model ‚Äì sending artistic prompts to OpenAI and more realistic prompts to Gemini, if there‚Äôs any interest we can follow up with how that worked out!</p>















<h4>Methodology</h4>



<p>Tests were performed on October 8 with <code>gpt-image-1</code>, <code>gemini-2.5-flash-image</code> and <code>seedream-4-0-250828</code>.</p>



<p>Timings were measured on a consumer internet connection in Japan (Fiber connection, 10 Gbps nominal bandwidth) during a limited test run in a short time period.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cache-friendly, low-memory Lanczos algorithm in Rust (104 pts)]]></title>
            <link>https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</link>
            <guid>45889891</guid>
            <pubDate>Tue, 11 Nov 2025 17:08:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/">https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</a>, See on <a href="https://news.ycombinator.com/item?id=45889891">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>The standard Lanczos method for computing matrix functions has a brutal memory requirement: storing an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix that grows with every iteration. For a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500.000</mn></mrow><annotation encoding="application/x-tex">500.000</annotation></semantics></math></span></span>-variable problem needing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000</annotation></semantics></math></span></span> iterations, that‚Äôs roughly 4 GB just for the basis.</p>
<p>In this post, we will explore one of the most straightforward solutions to this problem: a two-pass variant of the Lanczos algorithm that only requires <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory at the cost of doubling the number of matrix-vector products. The surprising part is that when implemented carefully, the two-pass version isn‚Äôt just memory-efficient‚Äîit can be faster for certain problems. We will dig into why.</p>
<ul>
<li>All code is available on GitHub: <a href="https://github.com/lukefleed/two-pass-lanczos">two-pass-lanczos</a></li>
<li>The full technical report with proofs and additional experiments: <a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">report.pdf</a></li>
</ul>
<hr>
<h2 id="table-of-contents">Table of Contents</h2>
<details><summary>Open Table of Contents</summary>
<ul>
<li><a href="#computing-matrix-functions">Computing Matrix Functions</a>
<ul>
<li><a href="#krylov-projection">Krylov Projection</a>
<ul>
<li><a href="#building-an-orthonormal-basis">Building an Orthonormal Basis</a></li>
<li><a href="#solving-in-the-reduced-space">Solving in the Reduced Space</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#the-lanczos-algorithm">The Lanczos Algorithm</a>
<ul>
<li><a href="#three-term-recurrence">Three-Term Recurrence</a></li>
<li><a href="#reconstructing-the-solution">Reconstructing the Solution</a></li>
</ul>
</li>
<li><a href="#two-pass-algorithm">Two-Pass Algorithm</a>
<ul>
<li><a href="#first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</a></li>
<li><a href="#second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</a>
<ul>
<li><a href="#a-subtle-numerical-point">A Subtle Numerical Point</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#implementation">Implementation</a>
<ul>
<li><a href="#recurrence-step">Recurrence Step</a></li>
<li><a href="#an-iterator-for-state-management">An Iterator for State Management</a></li>
<li><a href="#first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</a></li>
<li><a href="#second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</a></li>
<li><a href="#the-public-api">The Public API</a>
<ul>
<li><a href="#example-solving-a-linear-system">Example: Solving a Linear System</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#some-interesting-results">Some interesting results</a>
<ul>
<li><a href="#memory-and-computation-trade-off">Memory and Computation Trade-off</a>
<ul>
<li><a href="#memory-usage">Memory Usage</a></li>
<li><a href="#runtime-where-theory-breaks">Runtime: Where Theory Breaks</a></li>
<li><a href="#medium-scale-behavior">Medium-Scale Behavior</a></li>
<li><a href="#what-about-dense-matrices">What About Dense Matrices?</a></li>
</ul>
</li>
<li><a href="#scalability">Scalability</a></li>
</ul>
</li>
</ul>
</details>
<h2 id="computing-matrix-functions">Computing Matrix Functions</h2>
<p>Let‚Äôs consider the problem of computing the action of matrix functions on a vector:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">x</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{x} = f(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is a large sparse Hermitian matrix and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is a matrix function defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. This is a problem that appears pretty often in scientific computing: solving linear systems corresponds to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, exponential integrators for PDEs use <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>‚Å°</mo><mo stretchy="false">(</mo><mi>t</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \exp(tz)</annotation></semantics></math></span></span>, and many other problems require functions like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1/2}</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>sign</mtext><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \text{sign}(z)</annotation></semantics></math></span></span>.</p>
<p>Indeed, there are a lot problems with computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> directly. First of all, even if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is sparse, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> is generally dense. Storing it explicitly is out of the question for large problems. Even if we could store it, computing it directly would require algorithms like the Schur-Parlett method that scale as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span></span>, which is impractical for large <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>.</p>
<p>However we know that given any matrix function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> of degree at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> (the size of the matrix) such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>p</mi><mi>n</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A}) = p_{n}(\mathbf{A})</annotation></semantics></math></span></span> (this is a consequence of the Cayley-Hamilton theorem). This polynomial interpolates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> and its derivatives in the Hermitian sense at the eigenvalues of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>.</p>
<p>This gives us a good and a bad news: the good news is that, well, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. The bad news is that the degree of this polynomial can be as high as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>, which is huge for large problems. The idea is then to find a low-degree polynomial approximation to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> that is <em>good enough</em> for our purposes. If we can find a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span></span> of degree <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>‚â™</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span> such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>‚âà</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A}) \approx f(\mathbf{A})</annotation></semantics></math></span></span>, then we can approximate the solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>‚âà</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><msub><mi>c</mi><mi>i</mi></msub><msup><mi mathvariant="bold">A</mi><mi>i</mi></msup><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">f(\mathbf{A})\mathbf{b} \approx p_k(\mathbf{A})\mathbf{b} = \sum_{i=0}^k c_i \mathbf{A}^i \mathbf{b}</annotation></semantics></math></span></span></span>
<p>This polynomial only involves vectors within a specific subspace.</p>
<h2 id="krylov-projection">Krylov Projection</h2>
<p>We can notice that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span> only depends on vectors in the Krylov subspace of order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span></p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>span</mtext><mo stretchy="false">{</mo><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">b</mi></mrow><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mn>2</mn></msup><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>k</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b}) = \text{span}\{\mathbf{b}, \mathbf{Ab}, \mathbf{A}^2\mathbf{b}, \ldots, \mathbf{A}^{k-1}\mathbf{b}\}</annotation></semantics></math></span></span></span>
<p>This is fortunate: we can compute an approximate solution by staying within this space, which only requires repeated matrix-vector products with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. For large sparse matrices, that‚Äôs the only operation we can do efficiently anyway.</p>
<blockquote>
<p>We don‚Äôt need to construct <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{A}^j</annotation></semantics></math></span></span> explicitly. We compute iteratively: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo stretchy="false">(</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{A}(\mathbf{A}^{j-1}\mathbf{b})</annotation></semantics></math></span></span>.</p>
</blockquote>
<p>But there‚Äôs a problem: the raw vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\mathbf{A}^j\mathbf{b}\}</annotation></semantics></math></span></span> form a terrible basis. They quickly become nearly parallel, making any computation numerically unstable. We need an orthonormal basis.</p>
<h3 id="building-an-orthonormal-basis">Building an Orthonormal Basis</h3>
<p>The standard method is the Arnoldi process, which is Gram-Schmidt applied to Krylov subspaces. We start by normalizing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span>. Then, iteratively:</p>
<ol>
<li>Compute a new candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{w}_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Orthogonalize against all existing basis vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mo>=</mo><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>‚àí</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>j</mi></munderover><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_j = \mathbf{w}_j - \sum_{i=1}^j (\mathbf{v}_i^H \mathbf{w}_j) \mathbf{v}_i</annotation></semantics></math></span></span></span>
<ol start="3">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_j / \|\tilde{\mathbf{v}}_j\|_2</annotation></semantics></math></span></span></li>
</ol>
<p>The coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_{ij} = \mathbf{v}_i^H \mathbf{w}_j</annotation></semantics></math></span></span> become entries of a projected matrix. After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have:</p>
<ul>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>: an orthonormal basis for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b})</annotation></semantics></math></span></span></li>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k</annotation></semantics></math></span></span>: an upper Hessenberg matrix representing the projection of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> onto this subspace</li>
</ul>
<p>We can express this relationship with the Arnoldi decomposition:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>k</mi></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><msubsup><mi mathvariant="bold">e</mi><mi>k</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{V}_k = \mathbf{V}_k \mathbf{H}_k + h_{k+1,k} \mathbf{v}_{k+1} \mathbf{e}_k^T</annotation></semantics></math></span></span></span>
<h3 id="solving-in-the-reduced-space">Solving in the Reduced Space</h3>
<p>Now we approximate our original problem by solving it in the small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dimensional space. Using the Full Orthogonal Method (FOM), we enforce that the residual is orthogonal to
the Krylov subspace. This gives:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> is computed as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{H}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>The heavy lifting is now on computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{H}_k)</annotation></semantics></math></span></span>, a small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k \times k</annotation></semantics></math></span></span> matrix.
Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>‚â™</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span>, we can afford direct methods like Schur-Parlett (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span>).</p>
<blockquote>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span> (linear systems), this reduces to solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k \mathbf{y}_k = \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> with LU decomposition.</p>
</blockquote>
<h2 id="the-lanczos-algorithm">The Lanczos Algorithm</h2>
<p>When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian (or symmetric in the real case), the general Arnoldi
process simplifies dramatically. We can prove that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">V</mi><mi>k</mi><mi>H</mi></msubsup><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k = \mathbf{V}_k^H \mathbf{A} \mathbf{V}_k</annotation></semantics></math></span></span> must also be Hermitian. A matrix that is both upper Hessenberg <em>and</em> Hermitian must be real, symmetric, and tridiagonal. This is a <em>huge</em> simplification.</p>
<p>In the literature, this projected matrix is denoted <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> to highlight its
tridiagonal structure:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mi>k</mi></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{T}_k = \begin{pmatrix}
\alpha_1 &amp; \beta_1 &amp; &amp; \\
\beta_1 &amp; \alpha_2 &amp; \beta_2 &amp; \\
&amp; \beta_2 &amp; \ddots &amp; \ddots \\
&amp; &amp; \ddots &amp; \alpha_k
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>‚àà</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\alpha_j \in \mathbb{R}</annotation></semantics></math></span></span> are the diagonal elements and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>‚àà</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\beta_j \in \mathbb{R}</annotation></semantics></math></span></span> are the off-diagonals (subdiagonals from the orthogonalization).</p>
<h2 id="three-term-recurrence">Three-Term Recurrence</h2>
<p>This tridiagonal structure leads to a beautiful simplification. To build the next basis
vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>, we don‚Äôt need the entire history of vectors. We only need
the two previous ones. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, this guarantees that
any new vector is <em>automatically</em> orthogonal to all earlier vectors (beyond the previous two). So we can skip the full orthogonalization and use a simple three-term recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>=</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>+</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{v}_j = \beta_{j-1}\mathbf{v}_{j-1} + \alpha_j \mathbf{v}_j + \beta_j \mathbf{v}_{j+1}</annotation></semantics></math></span></span></span>
<p>Rearranging gives us an algorithm to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span> directly:</p>
<ol>
<li>Compute the candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_{j+1} = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Extract the diagonal coefficient: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_{j+1}</annotation></semantics></math></span></span></li>
<li>Orthogonalize against the two previous vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_{j+1} - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<ol start="4">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></li>
</ol>
<p>This is known as the Lanczos algorithm. It‚Äôs more efficient than Arnoldi because each iteration only orthogonalizes against two previous vectors instead of all prior ones.</p>
<h2 id="reconstructing-the-solution">Reconstructing the Solution</h2>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we end up with the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> and all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> basis vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>. We can then reconstruct the approximate solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> is solved from the small tridiagonal matrix.</p>
<p>There is a timing problem however: we cannot compute the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span>
until all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations are complete. The full matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is only available
at the end, so we must store every basis vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> along the way, leading to a memory cost of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>.</p>
<p>So we‚Äôre left with a choice: whether we store all the basis vectors and solve the problem in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> passes, or find a way to avoid storing them. There is a middle ground.</p>
<blockquote>
<p>There are also techniques to compress the basis vectors, have a look <a href="https://arxiv.org/abs/2403.04390">here</a></p>
</blockquote>
<h2 id="two-pass-algorithm">Two-Pass Algorithm</h2>
<p>Here‚Äôs where we break the timing deadlock. The insight that we don‚Äôt actually need to store the basis vectors if we can afford to compute them twice</p>
<p>Think about what we have after the first pass. We‚Äôve computed all the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> coefficients that compose the entire tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. These numbers are small compared to the full basis. What if we kept only these scalars, discarded all the vectors, and then replayed the Lanczos recurrence a second time? We‚Äôd regenerate the same basis, and this time we‚Äôd use it to build the solution.</p>
<p>This comes at a cost. We run Lanczos twice, so we pay for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. But we only ever store a constant number of vectors in memory, no <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span> basis matrix. The memory complexity drops to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span>.</p>
<p>It sounds like a bad trade at first. But as we‚Äôll see later, the cache behavior of this
two-pass approach can actually make it as fast (or even faster) on real hardware if well optimized.</p>
<h2 id="first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</h2>
<p>We initialize <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span> and set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\beta_0 = 0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub><mo>=</mo><mn mathvariant="bold">0</mn></mrow><annotation encoding="application/x-tex">\mathbf{v}_0 = \mathbf{0}</annotation></semantics></math></span></span>.Then we run the standard Lanczos recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2, \quad \mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></span>
<p>At each step, we record <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. But we <em>do not</em> store <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>.
Instead, we discard it immediately after computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>. In this way we only keep in memory at most just three vectors at any time (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>, and the working vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span></span>).</p>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have the full set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi>Œ±</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_1, \beta_1, \ldots, \alpha_k, \beta_k\}</annotation></semantics></math></span></span>. These <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> scalars define the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. We can now solve:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>This is the solution in the reduced space. Now that we have the coefficients we need to build <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>.</p>
<h2 id="second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</h2>
<p>With <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> in memory, we replay the Lanczos recurrence <em>exactly as before</em>. We start with the same initialization (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_0</annotation></semantics></math></span></span>) and apply the same sequence of operations, using the stored scalars <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> to reconstruct each basis vector on demand. We can write some rust-like <em>pseudocode</em> for this second pass to get a feel for it:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> x_k</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_prev</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span>.</span><span>clone</span><span>() </span><span>/</span><span> b_norm</span><span>;</span></span>
<span></span>
<span><span>for</span><span> j</span><span> in</span><span> 1</span><span>..=</span><span>k</span><span> {</span></span>
<span><span>    let</span><span> w</span><span> =</span><span> A</span><span> @</span><span> v_curr</span><span>;  </span><span>// Matrix-vector product</span></span>
<span></span>
<span><span>    // We don't recompute alpha/beta; we already have them from pass 1</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> alphas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> j</span><span> &gt;</span><span> 1</span><span> ?</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 2</span><span>] </span><span>:</span><span> 0</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // Accumulate the solution</span></span>
<span><span>    x_k</span><span> +=</span><span> y_k</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>] </span><span>*</span><span> v_curr</span><span>;</span></span>
<span></span>
<span><span>    // Regenerate the next basis vector for the *next* iteration</span></span>
<span><span>    let</span><span> v_next</span><span> =</span><span> (</span><span>w</span><span> -</span><span> alpha_j</span><span> *</span><span> v_curr</span><span> -</span><span> beta_prev</span><span> *</span><span> v_prev</span><span>) </span><span>/</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span></span>
<span><span>    // Slide the window forward</span></span>
<span><span>    v_prev</span><span> =</span><span> v_curr</span><span>;</span></span>
<span><span>    v_curr</span><span> =</span><span> v_next</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>This loop regenerates each <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> on demand and immediately uses it to update the solution.
Once we‚Äôve accumulated <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">(\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span> into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>, we discard the vector. We never store the full basis.</p>
<h3 id="a-subtle-numerical-point">A Subtle Numerical Point</h3>
<p>There is one detail worth noting: floating-point arithmetic is deterministic. When we replay the Lanczos recurrence in the second pass with the exact same inputs and the exact same order of operations, we get bitwise-identical vectors. The <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> regenerated in pass 2 are identical to the ones computed in pass 1.</p>
<p>However, the order in which we accumulate the solution differs. In a standard Lanczos,
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span> is built as a single matrix-vector product: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> (a <code>gemv</code> call in BLAS). In the two-pass method, it‚Äôs built as a loop of scaled vector additions (a series of <code>axpy</code> calls). These operations accumulate rounding error differently, so the final solution differs slightly, typically by machine epsilon. This rarely matters in practice, and convergence is unaffected.</p>
<h2 id="implementation">Implementation</h2>
<p>Building this in Rust forces us to think concretely about where data lives and how it flows through the cache hierarchy. We need to control memory layout, decide when allocations happen, and choose abstractions that cost us nothing at runtime.</p>
<p>For linear algebra, we reach for <a href="https://github.com/sarah-ek/faer-rs"><code>faer</code></a>. Three design choices in this library matter for what we‚Äôre building:</p>
<ul>
<li><strong>Stack allocation via <code>MemStack</code>:</strong> Pre-allocated scratch space that lives for the entire computation. The hot path becomes allocation-free.</li>
<li><strong>Matrix-free operators:</strong> The <code>LinOp</code> trait defines an operator by its action (<code>apply</code>) without materializing a matrix. For large sparse problems, this is the only viable approach.</li>
<li><strong>SIMD-friendly loops:</strong> The <code>zip!</code> macro generates code that compiles to packed instructions.</li>
</ul>
<h2 id="recurrence-step">Recurrence Step</h2>
<p>Our starting point is the Lanczos three-term recurrence that we derived earlier:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_j \mathbf{v}_{j+1} = \mathbf{A}\mathbf{v}_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<p>We can translate this into a recurrence step function. The signature looks like this:</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_recurrence_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> (T</span><span>::</span><span>Real</span><span>, </span><span>Option</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;)</span></span></code></pre>
<p>The function is generic over the field type <code>T</code> (<code>f64</code>, <code>c64</code>, etc.) and the operator type <code>O</code>. It operates on matrix views (<code>MatMut</code> and <code>MatRef</code>) to avoid unnecessary data copies. The return type gives us the diagonal element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and, <em>if no breakdown occurs</em>, the off-diagonal <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>.</p>
<p>Now we can implement the body by following the math. The first step is the most expensive:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 1. Apply operator: w = A * v_curr</span></span>
<span><span>operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span></code></pre>
<p>The matrix-vector product dominates the computational cost. Everything else is secondary.</p>
<p>Next, we orthogonalize against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>. This is where we benefit from <code>faer</code>‚Äôs design. The <code>zip!</code> macro fuses this operation into a single loop that the compiler vectorizes into SIMD instructions.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 2. Orthogonalize against v_{j-1}: w -= Œ≤_{j-1} * v_{j-1}</span></span>
<span><span>let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>With <code>w</code> partially orthogonalized, we can compute the diagonal coefficient via an inner product. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> is guaranteed real.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 3. Compute Œ±_j = v_j^H * w</span></span>
<span><span>let</span><span> alpha</span><span> =</span><span> T</span><span>::</span><span>real_part_impl</span><span>(</span><span>&amp;</span><span>(</span><span>v_curr</span><span>.</span><span>adjoint</span><span>() </span><span>*</span><span> w</span><span>.</span><span>rb</span><span>())[(</span><span>0</span><span>, </span><span>0</span><span>)]);</span></span></code></pre>
<p>We complete the orthogonalization against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> with another <code>zip!</code> loop.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 4. Orthogonalize against v_j: w -= Œ±_j * v_j</span></span>
<span><span>let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>Now <code>w</code> holds the unnormalized next basis vector. We compute its norm to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. If this norm is numerically zero, the Krylov subspace is invariant, the iteration has reached its natural stopping point. This is called breakdown.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 5. Compute Œ≤_j = ||w||_2 and check for breakdown</span></span>
<span><span>let</span><span> beta</span><span> =</span><span> w</span><span>.</span><span>rb</span><span>()</span><span>.</span><span>norm_l2</span><span>();</span></span>
<span><span>let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span></span>
<span><span>if</span><span> beta</span><span> &lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>None</span><span>)</span></span>
<span><span>} </span><span>else</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>Some</span><span>(</span><span>beta</span><span>))</span></span>
<span><span>}</span></span></code></pre>
<p>The function returns <code>None</code> for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> when breakdown occurs, signaling to the caller that no further iterations should proceed.</p>
<h2 id="an-iterator-for-state-management">An Iterator for State Management</h2>
<p>The recurrence step is a pure function, but calling it in a loop is both inefficient and awkward. We‚Äôd need to manually pass vectors in and out of each iteration. More critically, we‚Äôd create copies when we should be reusing memory.</p>
<p>The iterator pattern solves this. We create a struct that encapsulates the state:</p>
<pre tabindex="0" data-language="rust"><code><span><span>struct</span><span> LanczosIteration</span><span>&lt;'</span><span>a</span><span>, </span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt; {</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>'</span><span>a</span><span> O</span><span>,</span></span>
<span><span>    v_prev</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_{j-1}</span></span>
<span><span>    v_curr</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_j</span></span>
<span><span>    work</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,         </span><span>// Workspace for the next vector</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,   </span><span>// Œ≤_{j-1}</span></span>
<span><span>    // ... iteration counters</span></span>
<span><span>}</span></span></code></pre>
<p>The main design choice here is that vectors are <strong>owned</strong> (<code>Mat&lt;T&gt;</code>), not borrowed. This enables an optimization in the <code>next_step</code> method. After computing the next vector and normalizing it into <code>work</code>, we cycle the state without allocating or copying:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// Inside next_step, after normalization...</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_prev, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr);</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>work);</span></span></code></pre>
<p>On x86-64, swapping two <code>Mat&lt;T&gt;</code> structures (fat pointers) compiles to three <code>mov</code> instructions. The pointers change, but no vector data moves. After the swap, <code>v_prev</code> points to what <code>v_curr</code> held, <code>v_curr</code> points to <code>work</code>‚Äôs allocation, and <code>work</code> points to the old <code>v_prev</code> data. In the next iteration, <code>work</code> gets reused.</p>
<p>We keep exactly three n-dimensional vectors live in memory. The same allocations cycle through the computation, staying hot in L1 cache. This is the core reason the two-pass method can be faster than expected, the working set never leaves cache.</p>
<h2 id="first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</h2>
<p>The first pass runs the Lanczos iteration and collects the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span>. Basis vectors are discarded after each step.</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_one</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    // ...</span></span>
<span><span>}</span></span></code></pre>
<p>We allocate vectors for the coefficients with a capacity hint to avoid reallocations:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> alphas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span>);</span></span>
<span><span>let</span><span> mut</span><span> betas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span> -</span><span> 1</span><span>);</span></span></code></pre>
<p>Then we construct the iterator. This allocates the three work vectors once. After this point, the hot path is allocation-free:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> lanczos_iter</span><span> =</span><span> LanczosIteration</span><span>::</span><span>new</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>b_norm</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>for</span><span> i</span><span> in</span><span> 0</span><span>..</span><span>k</span><span> {</span></span>
<span><span>    if</span><span> let</span><span> Some</span><span>(</span><span>step</span><span>) </span><span>=</span><span> lanczos_iter</span><span>.</span><span>next_step</span><span>(</span><span>stack</span><span>) {</span></span>
<span><span>        alphas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>alpha);</span></span>
<span><span>        steps_taken</span><span> +=</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>        let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span><span>        if</span><span> step</span><span>.</span><span>beta </span><span>&lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>            break</span><span>;</span></span>
<span><span>        }</span></span>
<span></span>
<span><span>        if</span><span> i</span><span> &lt;</span><span> k</span><span> -</span><span> 1</span><span> {</span></span>
<span><span>            betas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>beta);</span></span>
<span><span>        }</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        break</span><span>;</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>The check for breakdown stops the iteration when the residual becomes numerically zero. This means we‚Äôve found an invariant subspace and there‚Äôs no value in continuing.</p>
<p>At the end, we collect the scalars into a <code>LanczosDecomposition</code> struct. The memory footprint throughout this pass is constant: three n-dimensional vectors plus two small arrays that grow to at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> elements.</p>
<h2 id="second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</h2>
<p>Now we face a different problem. We have the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> coefficients from the first pass and the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> from solving the projected problem. We need to reconstruct the solution:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \sum_{j=1}^k (\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span></span>
<p>without storing the full basis matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span>.</p>
<p>The recurrence step in this pass is structurally similar to the first pass, but with a key difference: we no longer compute inner products or norms. We already know the coefficients, so the step becomes pure reconstruction.</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_reconstruction_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    alpha_j</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) {</span></span>
<span><span>    // Apply operator</span></span>
<span><span>    operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span>
<span></span>
<span><span>    // Orthogonalize using stored Œ±_j and Œ≤_{j-1}</span></span>
<span><span>    let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha_j</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>    });</span></span>
<span><span>}</span></span></code></pre>
<p>This is cheaper than the first-pass recurrence. We‚Äôve eliminated the inner products that computed <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and the norm calculation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. What remains is pure orthogonalization and the operator application.</p>
<p><code>lanczos_pass_two</code> implements this reconstruction. We initialize the three work vectors and the solution accumulator:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_two</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    decomposition</span><span>:</span><span> &amp;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;,</span></span>
<span><span>    y_k</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    let</span><span> mut</span><span> v_prev</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span><span>    let</span><span> inv_norm</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span><span>    let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span> *</span><span> Scale</span><span>(</span><span>inv_norm</span><span>);  </span><span>// v_1</span></span>
<span></span>
<span><span>    let</span><span> mut</span><span> work</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span></span>
<span><span>    // Initialize solution with first component</span></span>
<span><span>    let</span><span> mut</span><span> x_k</span><span> =</span><span> &amp;</span><span>v_curr</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>0</span><span>, </span><span>0</span><span>)]));</span></span></code></pre>
<p>We build the solution incrementally by starting with the first basis vector scaled by its coefficient. The main loop then regenerates each subsequent vector: we regenerate each subsequent basis vector, normalize it using the stored <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>, and immediately accumulate its contribution:</p>
<pre tabindex="0" data-language="rust"><code><span><span>for</span><span> j</span><span> in</span><span> 0</span><span>..</span><span>decomposition</span><span>.</span><span>steps_taken </span><span>-</span><span> 1</span><span> {</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> if</span><span> j</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>zero_impl</span><span>()</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span> -</span><span> 1</span><span>])</span></span>
<span><span>    };</span></span>
<span></span>
<span><span>    // 1. Regenerate the unnormalized next vector</span></span>
<span><span>    lanczos_reconstruction_step</span><span>(</span></span>
<span><span>        operator</span><span>,</span></span>
<span><span>        work</span><span>.</span><span>as_mut</span><span>(),</span></span>
<span><span>        v_curr</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        v_prev</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        alpha_j</span><span>,</span></span>
<span><span>        beta_prev</span><span>,</span></span>
<span><span>        stack</span><span>,</span></span>
<span><span>    );</span></span>
<span></span>
<span><span>    // 2. Normalize using stored Œ≤_j</span></span>
<span><span>    let</span><span> inv_beta</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>beta_j</span><span>));</span></span>
<span><span>    zip!</span><span>(</span><span>work</span><span>.</span><span>as_mut</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> mul</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>inv_beta</span><span>);</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 3. Accumulate: x_k += y_{j+1} * v_{j+1}</span></span>
<span><span>    let</span><span> coeff</span><span> =</span><span> T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>j</span><span> +</span><span> 1</span><span>, </span><span>0</span><span>)]);</span></span>
<span><span>    zip!</span><span>(</span><span>x_k</span><span>.</span><span>as_mut</span><span>(), </span><span>work</span><span>.</span><span>as_ref</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>x_i</span><span>, </span><span>v_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>x_i</span><span> =</span><span> add</span><span>(</span><span>x_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>coeff</span><span>, </span><span>v_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 4. Cycle vectors for the next iteration</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_prev</span><span>, </span><span>&amp;</span><span>mut</span><span> v_curr</span><span>);</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_curr</span><span>, </span><span>&amp;</span><span>mut</span><span> work</span><span>);</span></span>
<span><span>}</span></span></code></pre>
<p>The accumulation <code>x_k += y_{j+1} * v_{j+1}</code> is implemented as a fused multiply-add in the <code>zip!</code> loop. On hardware with FMA support, this becomes a single instruction per element, not three separate operations.</p>
<p>Note that we accumulate the solution incrementally. After each iteration, <code>x_k</code> contains a partial result. We cycle through the same three vectors (<code>v_prev</code>, <code>v_curr</code>, <code>work</code>), keeping the working set small and resident in L1 cache.</p>
<p>Compare this to the standard method‚Äôs final reconstruction step: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span>. This is a dense matrix-vector product where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span>. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are both large, this matrix no longer fits in cache. The CPU must stream it from main memory, paying the cost of memory latency. Each element requires a load, multiply, and accumulate, but the load operations dominate‚Äîthe CPU stalls waiting for data.</p>
<p>In our two-pass reconstruction, the operator <code>$\mathbf{A}$</code> is applied <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> times, but against vectors that stay in cache. The memory bandwidth is spent on reading the sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> and the vector elements, not on scanning a dense <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> matrix.</p>
<p>This is the reason the two-pass method can be faster on real hardware despite performing twice as many matrix-vector products. The cache behavior of the reconstruction phase overwhelms the savings of storing the basis.</p>
<h2 id="the-public-api">The Public API</h2>
<p>We can wrap the two passes into a single entry point:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_two_pass</span><span>&lt;</span><span>T</span><span>, </span><span>O</span><span>, </span><span>F</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>    mut</span><span> f_tk_solver</span><span>:</span><span> F</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt;</span></span>
<span><span>where</span></span>
<span><span>    T</span><span>:</span><span> ComplexField</span><span>,</span></span>
<span><span>    O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    F</span><span>:</span><span> FnMut</span><span>(</span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>], </span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>]) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt;,</span></span>
<span><span>{</span></span>
<span><span>    // First pass: compute T_k coefficients</span></span>
<span><span>    let</span><span> decomposition</span><span> =</span><span> lanczos_pass_one</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>stack</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    if</span><span> decomposition</span><span>.</span><span>steps_taken </span><span>==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // Solve projected problem: y_k' = f(T_k) * e_1</span></span>
<span><span>    let</span><span> y_k_prime</span><span> =</span><span> f_tk_solver</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas, </span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // Scale by ||b||</span></span>
<span><span>    let</span><span> y_k</span><span> =</span><span> &amp;</span><span>y_k_prime</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span></span>
<span><span>    // Second pass: reconstruct solution</span></span>
<span><span>    lanczos_pass_two</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>&amp;</span><span>decomposition</span><span>, </span><span>y_k</span><span>.</span><span>as_ref</span><span>(), </span><span>stack</span><span>)</span></span>
<span><span>}</span></span></code></pre>
<p>The design separates concerns. The <code>f_tk_solver</code> closure is where we inject the specific matrix function. We compute the Lanczos decomposition, then pass the coefficients to the user-provided solver, which computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msubsup><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k' = f(\mathbf{T}_k) \mathbf{e}_1</annotation></semantics></math></span></span> for whatever function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is needed. This decoupling means we handle linear solves, matrix exponentials, or any other function without modifying the core algorithm.</p>
<p>The caller provides <code>f_tk_solver</code> as a closure. It receives the raw <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> arrays and must return the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{y}_k'</annotation></semantics></math></span></span>. We then scale it by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\|\mathbf{b}\|_2</annotation></semantics></math></span></span> and pass everything to the second pass.</p>
<h3 id="example-solving-a-linear-system">Example: Solving a Linear System</h3>
<p>To see this in practice, consider solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">x</mi></mrow><mo>=</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Ax} = \mathbf{b}</annotation></semantics></math></span></span>. We compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, which means the <code>f_tk_solver</code> must solve the small tridiagonal system <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><msup><mi mathvariant="bold">y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msup><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k \mathbf{y}' = \mathbf{e}_1</annotation></semantics></math></span></span>.</p>
<p>Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is tridiagonal, we can exploit its structure. A sparse LU factorization solves it in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> time instead of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span> cost of a dense method.</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> f_tk_solver</span><span> =</span><span> |</span><span>alphas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>], </span><span>betas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>]</span><span>|</span><span> -&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>f64</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt; {</span></span>
<span><span>    let</span><span> steps</span><span> =</span><span> alphas</span><span>.</span><span>len</span><span>();</span></span>
<span><span>    if</span><span> steps</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>0</span><span>, </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // 1. Assemble T_k from coefficients using triplet format</span></span>
<span><span>    let</span><span> mut</span><span> triplets</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>3</span><span> *</span><span> steps</span><span> -</span><span> 2</span><span>);</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>alpha</span><span>) </span><span>in</span><span> alphas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> alpha</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>beta</span><span>) </span><span>in</span><span> betas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    let</span><span> t_k_sparse</span><span> =</span><span> SparseColMat</span><span>::</span><span>try_new_from_triplets</span><span>(</span><span>steps</span><span>, </span><span>steps</span><span>, </span><span>&amp;</span><span>triplets</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // 2. Construct e_1</span></span>
<span><span>    let</span><span> mut</span><span> e1</span><span> =</span><span> Mat</span><span>::</span><span>zeros</span><span>(</span><span>steps</span><span>, </span><span>1</span><span>);</span></span>
<span><span>    e1</span><span>.</span><span>as_mut</span><span>()[(</span><span>0</span><span>, </span><span>0</span><span>)] </span><span>=</span><span> 1</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // 3. Solve T_k * y' = e_1 via sparse LU</span></span>
<span><span>    Ok</span><span>(</span><span>t_k_sparse</span><span>.</span><span>as_ref</span><span>()</span><span>.</span><span>sp_lu</span><span>()</span><span>?.</span><span>solve</span><span>(</span><span>e1</span><span>.</span><span>as_ref</span><span>()))</span></span>
<span><span>};</span></span></code></pre>
<p>The closure takes the coefficient arrays, constructs the sparse tridiagonal matrix, and solves the system. The triplet format lets us build the matrix efficiently without knowing its structure in advance. The sparse LU solver leverages the tridiagonal structure to avoid dense factorization.</p>
<h2 id="some-interesting-results">Some interesting results</h2>
<p>Now that we have a working implementation we can run some tests. The core idea of what we have done is simple: trade flops for better memory access. But does this trade actually pay off on real hardware? To find out, we need a reliable way to benchmark it.</p>
<p>For the data, we know that the performance of any Krylov method is tied to the operator‚Äôs spectral properties. We need a way to generate a family of test problems where we can precisely control the size, sparsity, and numerical difficulty. A great way to do this is with Karush-Kuhn-Tucker (KKT) systems, which are sparse, symmetric, and have a specific block structure.</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>D</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msup><mi>E</mi><mi>T</mi></msup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>E</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">A =
\begin{pmatrix}
    D &amp; E^T \\
    E &amp; 0
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>This structure gives us two critical knobs to turn. First, with the <a href="https://commalab.di.unipi.it/files/Data/MCF/netgen.tgz">netgen</a> utility, we can control the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span></span> matrix, which lets us dial in the problem dimension, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>. Second, we build the diagonal block D with random entries from a range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1, C_D]</annotation></semantics></math></span></span>. This parameter, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span>, gives us direct control over the numerical difficulty of the problem.</p>
<p>For a symmetric matrix like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span>, the 2-norm condition number, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D)</annotation></semantics></math></span></span>, is the ratio of its largest to its smallest eigenvalue: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>Œª</mi><mi>max</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msub><mi>Œª</mi><mi>min</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D) = \lambda_{\max}(D) / \lambda_{\min}(D)</annotation></semantics></math></span></span>. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> is diagonal, its eigenvalues are simply its diagonal entries. We are drawing these entries from a uniform distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">U[1, C_D]</annotation></semantics></math></span></span>, so we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>max</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_{\max}(D) \approx C_D</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>min</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{\min}(D) \approx 1</annotation></semantics></math></span></span>. This means we get direct control, as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\kappa_2(D) \approx C_D</annotation></semantics></math></span></span>.The spectral properties of this block heavily influence the spectrum of the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. A large condition number in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> leads to a more ill-conditioned system for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. The convergence rate of Krylov methods like Lanczos is fundamentally governed by the distribution of the operator‚Äôs eigenvalues. An ill-conditioned matrix, with a wide spread of eigenvalues, will require more iterations, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, to reach the desired accuracy. By simply adjusting the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span> parameter, we can generate everything from well-conditioned problems that converge quickly to ill-conditioned ones that force us to run a large number of iterations. This is exactly what we need to rigorously test our implementation.</p>
<h2 id="memory-and-computation-trade-off">Memory and Computation Trade-off</h2>
<p>We measure the algorithm against two hypotheses on a large sparse problem with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=500,000</annotation></semantics></math></span></span>, varying the number of iterations <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>.</p>
<p><strong>Hypothesis 1 (Memory):</strong> The one-pass method stores the full basis <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> with complexity <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>. We expect its memory to grow linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. The two-pass method operates with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory, so it should have a flat profile.</p>
<p><strong>Hypothesis 2 (Runtime):</strong> The two-pass method performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. If all else were equal, we‚Äôd expect it to run twice as slow.</p>
<h3 id="memory-usage">Memory Usage</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_memory.png" alt="Memory vs Iterations"></p>
<p>The memory data confirms Hypothesis 1 exactly. The one-pass method‚Äôs footprint scales as a straight line‚Äîeach additional iteration adds one vector to the basis. The two-pass method remains flat. No allocation growth happens after initialization.</p>
<h3 id="runtime-where-theory-breaks">Runtime: Where Theory Breaks</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_time.png" alt="Runtime vs Iterations"></p>
<p>The runtime data contradicts Hypothesis 2. The two-pass method is slower, but never by a factor of two. For small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, the gap is minimal. As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> grows, the two-pass runtime diverges slowly from the one-pass method, not by doubling, but by a much smaller margin.</p>
<p>This difference comes from memory access patterns. Both methods perform matrix-vector products, but they differ in how they reconstruct the solution.</p>
<p>The one-pass method computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> in a single dense matrix-vector product. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are large, the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix exceeds all cache levels. The CPU cannot keep the data resident; instead, it streams <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> from main memory. This is a memory-bandwidth-bound operation. The processor stalls, waiting for each load to complete. Instruction-level parallelism collapses.</p>
<p>The two-pass method reconstructs the solution incrementally. At each iteration, it operates on exactly three n-dimensional vectors: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>prev</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{prev}}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>curr</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{curr}}</annotation></semantics></math></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>. This working set fits in L1 cache. The processor performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products (each one reading the sparse operator, then applying it to a cached vector), but the solution accumulation happens entirely within cache. The additional matrix-vector products are cheaper than the memory latency of the standard method.</p>
<p>The cost of re-computing basis vectors is less than the latency cost of scanning an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> dense matrix from main memory.</p>
<h3 id="medium-scale-behavior">Medium-Scale Behavior</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_time.png" alt="Medium Scale Runtime vs Iterations">
<img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_memory.png" alt="Medium Scale Memory Usage vs Iterations"></p>
<p>At <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=50,000</annotation></semantics></math></span></span> we can observe an equilibrium. The two methods have nearly identical runtime. The standard method‚Äôs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> matrix is smaller; it fits partially in cache. The cache-miss penalty here becomes manageable. The two-pass method still has the advantage of cache-local accumulation, but the difference is marginal.</p>
<h3 id="what-about-dense-matrices">What About Dense Matrices?</h3>
<p>To be sure of our hypothesis, we can test it directly using a dense matrix of size <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>10</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=10,000</annotation></semantics></math></span></span>. For dense problems, the matrix-vector product is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span>, it dominates all other costs. Memory latency will become negligible relative to the compute work and the cache efficiency advantage should disappear.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/dense-tradeoff.png" alt="Dense Matrix Runtime vs Iterations"></p>
<p>We can see that the two-pass method runs almost exactly twice as slow as the one-pass method. The slope ratio is <em>exactly</em> 2:1. In a compute-bound regime, the extra matrix-vector products cannot be hidden by cache effects. Here, the theoretical trade-off holds perfectly.</p>
<h2 id="scalability">Scalability</h2>
<p>Now, let‚Äôs fix the iteration count at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>500</mn></mrow><annotation encoding="application/x-tex">k=500</annotation></semantics></math></span></span> and vary <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">50,000</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">500,000</annotation></semantics></math></span></span> to measure scalability. Based on what we have seen before, we would expect the two-pass memory to scale linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> but with a small constant factor (three vectors, plus scalars). The one-pass method should also scale linearly, but with a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dependent slope.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_memory.png" alt="Scalability Memory Usage"></p>
<p>Here we have to use a logarithmic y-axis to show both curves; the two-pass line is so flat relative to the one-pass line that it‚Äôs otherwise invisible.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_time.png" alt="Scalability Runtime"></p>
<p>Runtime scales linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> for both methods, as expected. Below <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=150,000</annotation></semantics></math></span></span>, the two methods have similar performance. This is the regime where both basis and working set fit in cache, or where the problem is small enough that memory latency is not the bottleneck.</p>
<p>As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> increases beyond <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">150,000</annotation></semantics></math></span></span>, the matrix-vector product time dominates. The sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> ensures that each matvec requires multiple memory accesses per element. For the one-pass method, the final reconstruction of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> begins to cost more as the matrix grows. For the two-pass method, performing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products means the matvec cost accumulates more rapidly. The divergence is gradual, not sharp, because the advantage of cache locality in accumulation persists‚Äîbut it cannot overcome the fundamental cost of doubling the number of expensive operations.</p>
<hr>
<p>Well, that‚Äôs it. If you want to have a better look at the code or use it, it‚Äôs all open source:</p>
<ul>
<li><a href="https://github.com/lukefleed/two-pass-lanczos">Github Repository</a></li>
<li><a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">LaTeX Report</a></li>
</ul>
<p>This was more of an exploration than a production-ready library, so expect rough edges. But I hope it gives an interesting perspective on how algorithm engineering and low-level implementation details can alter what seems like a straightforward trade-off on a blackboard.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPod Socks (226 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/IPod_Socks</link>
            <guid>45889602</guid>
            <pubDate>Tue, 11 Nov 2025 16:52:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/IPod_Socks">https://en.wikipedia.org/wiki/IPod_Socks</a>, See on <a href="https://news.ycombinator.com/item?id=45889602">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/IPod_Socks: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox Expands Fingerprint Protections (265 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/fingerprinting-protections/</link>
            <guid>45888891</guid>
            <pubDate>Tue, 11 Nov 2025 16:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/">https://blog.mozilla.org/en/firefox/fingerprinting-protections/</a>, See on <a href="https://news.ycombinator.com/item?id=45888891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-82478">
  

  <div>
    




<p>With Firefox 145, we‚Äôre rolling out major privacy upgrades that take on browser fingerprinting ‚Äî a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you‚Äôre in private browsing. These protections build on Mozilla‚Äôs long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.</p>



<p>Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup ‚Äî ranging from your time zone to your operating system settings ‚Äî that together create a ‚Äúfingerprint‚Äù identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser‚Äôs private browsing mode.</p>



<p>Protecting people‚Äôs privacy has always been core to Firefox. <a href="https://blog.mozilla.org/security/2020/01/07/firefox-72-fingerprinting/">Since 2020</a>, Firefox‚Äôs built-in <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a> (ETP) has blocked known trackers and other invasive practices, while features like <a href="https://mzl.la/3db2drC">Total Cookie Protection</a> and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.</p>



<p>Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren‚Äôt in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.</p>



<h2>How we built stronger defenses</h2>



<p>Drawing from a global analysis of how real people‚Äôs browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like <a href="https://blog.mozilla.org/en/mozilla/firefox-rolls-out-total-cookie-protection-by-default-to-all-users-worldwide/">Total Cookie Protection</a>, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.</p>



<figure><img decoding="async" fetchpriority="high" width="1024" height="633" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png" alt="" title="Chart" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-300x186.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-768x475.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1000x618.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>How Firefox protects you</h2>



<p>These fingerprinting protections work on multiple layers, building on Firefox‚Äôs already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a>.&nbsp;</p>



<p>Beyond blocking trackers, Firefox also limits the information it makes available to websites ‚Äî a privacy-by-design approach ‚Äî that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer.&nbsp; But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&nbsp;&nbsp;</p>



<p>Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.</p>



<p>Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">available in our documentation</a>.</p>



<p>Our research shows these improvements <strong>cut the percentage of users seen as unique by almost half</strong>.</p>



<figure><img decoding="async" width="1024" height="1024" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-300x300.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-150x150.png 150w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-768x768.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-1000x1000.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-800x800.png 800w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Firefox‚Äôs new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox‚Äôs approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">specific behaviors</a> and how to <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-can-i-tell-if-this-protection-broke-something">recognize a problem</a> on a site and <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-do-i-disable-this-protection-for-a-website">disable protections</a> for that site alone, so you always stay in control. The goal: strong privacy protections that don‚Äôt get in your way.</p>



<h2>What‚Äôs next for your privacy</h2>



<p>If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox‚Äôs fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically ‚Äî no further extensions or configurations needed.&nbsp;As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. <a href="https://firefox.com/">Upgrade to the latest Firefox and take back control of your privacy</a>.</p>



<a href="https://www.mozilla.org/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-150x150.png 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Take control of your internet</h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article><!-- #post-82478 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canada loses its measles-free status, with US on track to follow (203 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cy7e2lv4r8xo</link>
            <guid>45888697</guid>
            <pubDate>Tue, 11 Nov 2025 15:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cy7e2lv4r8xo">https://www.bbc.com/news/articles/cy7e2lv4r8xo</a>, See on <a href="https://news.ycombinator.com/item?id=45888697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><div data-testid="byline-new-contributors-contributor-0"><p><span>Nadine Yousif</span><span data-testid="byline-new-contributors-contributor-0-role-location">Senior Canada reporter</span></p></div></span></p></div><div data-component="text-block"><p>Canada has lost its measles elimination status, said the Pan American Health Organization (Paho) on Monday, after failing to curb an outbreak of the virus for 12 consecutive months.</p><p>Because Canada is no longer deemed measles-free, the Americas region as a whole has lost its elimination status, although individually the other countries are still considered to have stamped out the disease.</p><p>The US, however, risks losing its status as well if it does not stop an ongoing outbreak by January. Related cases have now been reported in Utah, Arizona and South Carolina.</p><p>Canada's outbreak began last October, with health officials attributing it to fewer people being vaccinated against measles.</p></div><div data-component="text-block"><p>At a news conference on Monday, Paho officials appealed to Canadian governments and the public to ramp up vaccinations, noting that 95% of the population needs to be immunised to stop the spread of measles.</p><p>"This loss represents a setback, but it is also reversible," said Dr Jarbas Barbosa, the health organisation's director.</p><ul><li><a target="_self" href="https://www.bbc.com/news/articles/c4g8d39gdr0o">How Canada became the centre of a measles outbreak in North America</a></li><li><a target="_self" href="https://www.bbc.com/news/articles/cwy747kdzdzo">More than 150 children quarantined as US measles cases hit 33-year high</a></li></ul><p>The Public Health Agency of Canada said in its own statement that it is collaborating with Paho and regional health authorities to improve vaccine rates and strengthen data sharing. </p><p>Prior to Monday, Canada had been declared measles-free for three decades. It can regain its elimination status if it can curb spread of the measles strain associated with the current outbreak for at least 12 months. </p><p>The country has reported more than 5,000 measles cases in 2025, with most of them in the provinces of Ontario and Alberta. That is three times the 1,681 cases reported in the US, despite Canada's much smaller population. </p><p>The bulk of the outbreak has been in "under-vaccinated communities", Canadian health officials have said. </p><p>Vaccination rates in Alberta, one of the provinces hit hard by the outbreak, are lower than the 95% threshold, according to provincial data. </p><p>One region, the South Zone, located south of the province's largest city Calgary, reported only 68% of children under the age of two were immunised against measles as of 2024.</p><p>The MMR vaccine is the most effective way to fight off the dangerous virus, which can lead to pneumonia, brain swelling and death. The jabs are 97% effective and also immunise against mumps and rubella.</p><p>Canadian immunologist Dawn Bowdish told the BBC that there are many reasons behind the low vaccination rates, including lack of access to general practitioners, the absence of a national vaccination registry that Canadians could use to check their immunisation status, and the spread of misinformation. </p><p>She also noted a lack of public health outreach to communities that have been hesitant or distrustful of vaccines.</p><p>"It highlights how many of our systems broke down to get us to this point," said Prof Bowdish of McMaster University in Hamilton, Ontario. </p><p>"I hope that it will be a wake-up call to policymakers, and that it will be enough of a national embarrassment that we remedy some of those systemic issues," she added</p><p>The Americas is the first and only region in the world to have been declared measles-free, starting in 2016. That status was then briefly lifted after outbreaks in Venezuela and Brazil. The two countries regained elimination status in 2024, in part through coordinated vaccine efforts where millions were immunised. </p><p>But measles has since spread again, now in North America. </p><p>Along with Canada and the United States, Mexico has also seen a surge in cases and now ranks among the top 10 countries with the largest outbreaks, according to the US Centers for Disease Control and Prevention.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pikaday: A friendly guide to front-end date pickers (124 pts)]]></title>
            <link>https://pikaday.dbushell.com</link>
            <guid>45887957</guid>
            <pubDate>Tue, 11 Nov 2025 14:58:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikaday.dbushell.com">https://pikaday.dbushell.com</a>, See on <a href="https://news.ycombinator.com/item?id=45887957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <div>
        <h2>Who needs a JavaScript date picker?</h2>
        <p>
          The answer, in most cases, is nobody!
          Complex UI leads to more errors and abandoned forms.
          There can be easier ways to pick a date than a calendar widget.
          This guide provides alternate ideas and aims to send developers on a path towards <mark>user-friendly interfaces</mark>.
        </p>
      </div>

    <section id="native">
      <div>
        <h2>Native date and time inputs</h2>
        <p>
          If you absolutely must use a calendar widget then it‚Äôs wise to use the native input.
          All modern <a href="https://caniuse.com/input-datetime" target="_blank">browsers support</a> native date and time inputs.
        </p>
      </div>
      
      

      <div>
        <h2>Why use native inputs</h2>
        <p>Native inputs are super easy to implement with one line of code. The web browser handles many important details for developers:</p>
        <ul>
          <li>Accessibility <sup><a href="#accessibility-issues">(mostly*)</a></sup></li>
          <li>Performance</li>
          <li>Internationalisation</li>
        </ul>
        <p>
          Let browsers do the hard work!
          Browsers allow keyboard users to type numbers in sequence.
          Most browsers provide alternate UI for time and date selection like the classic calendar widget.
          They're not perfect but do you trust a JavaScript library to do better?
        </p>
      </div>

      

      
    </section>

    <section id="separate">
      <div>
        <h2>Separate inputs</h2>
        <p>
          A single date picker can be tricky to operate. For memorable dates using separate inputs can improve usability.
          The example below is based on <a href="https://design-system.service.gov.uk/components/date-input/" target="_blank">GOV.UK date input component</a>.
        </p>
        
      </div>
      <div>
        <h3>Select elements</h3>
        <p>
          If only a limited set of data is valid then using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/select" target="_blank">select elements</a> may be suitable.
          They can require fewer interactions to use and they eliminate typing errors.
        </p>
      </div>
      <div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select expiry date</h3>
              </legend>
              <p><label for="expiry-month">Month</label>
                
              </p>
              <p><label for="expiry-year">Year</label>
                
              </p>
            </fieldset>
          </form>
          <p>
            Numeric month labels can be helpful but take care in how they‚Äôre written.
            Screen readers may mistakenly announce ‚Äú1 January‚Äù as ‚Äúthe 1st of January‚Äù, for example.
          </p>
        </div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select departure time</h3>
              </legend>
              <p><label for="departure-date">I‚Äôm leaving</label>
                
              </p>
              <p><label for="departure-hour">Hour</label>
                
              </p>
              <p><label for="departure-minutes">Minutes</label>
                
              </p>
            </fieldset>
          </form>
          <p>Travel booking often has a fixed schedule with limited time options, such as every 15 minutes.
            Relative dates like ‚ÄúToday‚Äù and ‚ÄúTomorrow‚Äù can be easier to understand.</p>
        </div>
      </div>
      
    </section>

    <section id="masked">

      <div>
        <h2>Masked inputs</h2>
        <p>
          Another common alternative to date pickers is a single input with a placeholder mask.
          This can be used for full or partial dates.
          JavaScript can enhancement the experience.
        </p>
      </div>

      

      <div>
        <p>
          The examples above provide client-side validation with errors such as <em>‚ÄúPlease enter a valid day for February (1 to 28)‚Äù</em>.
          Valid dates are confirmed in full and formatted with the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl/DateTimeFormat" target="_blank"><code>Intl</code> API</a>.
        </p>
        <p>
            <strong>Caution!</strong> Updating input values with JavaScript can break native undo/redo.
          </p>
      </div>

      <div>
        <p>
          It‚Äôs even possible to visually combined mutliple inputs using CSS to appear as one.
        </p>
        
      </div>

      
    </section>

    <div id="ranges">
        <h2>Ranges and limited options</h2>
        <p>
          JavaScript date pickers that support range selection across two calendars are difficult to use, especially without a pointer.
          Consider providing two inputs instead to <mark>reduce complexity</mark>.
          If users are required to select an available date then a group of <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/radio" target="_blank"><code>radio</code> inputs</a> can do the job.
        </p>
        <p><small><b>The example below illustrates the idea but is not fully interactive.</b></small></p>
        
        <p>
          There are many design variations of this pattern.
          This idea is to replace complicated UI with a series of simple tasks.
          Such a pattern can be implemented as a multi-page form with
          JavaScript used to enhance it into a single page interactive experience.
        </p>
      </div>

    <section id="faq">
      <div>
        <h2>Frequently asked questions</h2>
        <details id="faq-frameworks">
          <summary><h3>What if I use a JavaScript framework like React?</h3></summary>
          <p>
              All good JavaScript frameworks allow you to use native HTML elements.
              Not everything needs to be a custom component.
              Native <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement#events" target="_blank">input events</a> can integrate with framework callbacks.
              Use attributes like <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement/value"><code>value</code></a> for two-way state binding.
            </p>
        </details>
        <details id="faq-styles">
          <summary><h3>How do I style the native date picker?</h3></summary>
          <p>
              The on-page <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/date" target="_blank"><code>input</code> element</a>
              can be partially styled but other parts are not stylable.
              That is a good thing! Native system UI is familiar to the user.
              The design will differ based on operating system and input method.
              Date pickers even look different across browsers and that's fine too, you don't need to add yet another design to the mix!
            </p>
        </details>
        <details id="faq-stakeholders">
          <summary><h3>A stakeholder is demanding a JavaScript date picker, how do I dissuade them?</h3></summary>
          <p>
              Remember: the end goal is a successful form submission. Complex and fragile UI leads to more errors.
              All date pickers have accessibility issues. Combining basic inputs can be more user-friendly.
              Untested JavaScript UI may fall foul of regulation like the <a href="https://en.wikipedia.org/wiki/European_Accessibility_Act" target="_blank">European Accessibility Act</a>.
              Keep it simple for success!
            </p>
        </details>
        <details id="faq-accessibility">
          <summary><h3>How do I test and guarantee accessibility?</h3></summary>
          <div>
            <p>
              It‚Äôs critical to understand the relevant <a href="https://www.w3.org/TR/WCAG22/" target="_blank">accessibility guidelines</a>.
              You don‚Äôt need to memorise WCAG but there are no shortcuts to learning the important parts.
              Leverage existing web standards to avoid mistakes trying to code custom UI.
            </p>
            <p>
              Browser dev tools have built-in <a href="https://developer.chrome.com/docs/devtools/accessibility/reference" target="_blank">accessibility features</a> to help identify mistakes.
              However, no tool is perfect. The only way to know for sure is to conduct user testing.
            </p>
            <p>
              <a href="https://overlayfactsheet.com/" target="_blank">Accessibility overlays</a> are <strong>strongly discouraged</strong> and can make matters worse.
            </p>
          </div>
        </details>
        <details id="faq-resources">
          <summary><h3>Where can I learn more about date picker accessibility?</h3></summary>
          <div>
            <ul>
              <li><a href="https://www.hassellinclusion.com/blog/collecting-dates-accessible/" target="_blank">Collecting dates in an accessible way</a> by <strong>Graham Armfield</strong></li>
              <li><a href="https://www.youtube.com/watch?v=D2Gy2WN4Iys&amp;list=PLn7dsvRdQEfFfYUgq0wVLXlVN7yQUUWd-" target="_blank">What makes an accessible date picker? Is it even possible?</a> by <strong>Russ Weakley</strong></li>
              <li><a href="https://adrianroselli.com/2019/07/maybe-you-dont-need-a-date-picker.html" target="_blank">Maybe You Don‚Äôt Need a Date Picker</a> by <strong>Adrian Roselli</strong></li>
              <li><a href="https://www.w3.org/WAI/ARIA/apg/patterns/dialog-modal/examples/datepicker-dialog/" target="_blank">Date Picker Dialog Example</a> by <strong>ARIA Authoring Practices Guide</strong></li>
              <li><a href="https://www.smashingmagazine.com/2017/07/designing-perfect-date-time-picker/" target="_blank">Designing The Perfect Date And Time Picker</a> by <strong>Vitaly Friedman</strong></li>
            </ul>
          </div>
        </details>
        <details id="faq-recommend">
          <summary><h3>This is all great but can you please recommend a JavaScript date picker?</h3></summary>
          <p>
              Sorry, no! There is no universal solution and <mark>all date pickers have issues</mark>.
              I hope this guide has given you the knowledge to evaluate your own requirements.
              Try to achieve your goal in the simplest way.
              A date picker is probably not the answer.
            </p>
        </details>
      </div>
      <div>
        <p><strong>Before you go!</strong> Remember to test and gather feedback from real users :)</p>
        <p>This guide is a work in progress, <a href="https://dbushell.com/contact/" target="_blank">feedback is welcome!</a></p>
      </div>
    </section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Department of War just shot the accountants and opted for speed (102 pts)]]></title>
            <link>https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/</link>
            <guid>45887699</guid>
            <pubDate>Tue, 11 Nov 2025 14:34:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/">https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/</a>, See on <a href="https://news.ycombinator.com/item?id=45887699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					<p><span>Last week the Department of War finally killed the last vestiges of Robert McNamara‚Äôs 1962 Planning, Programming, and Budgeting System (PPBS).&nbsp;</span></p>
<p><span>The DoW has pivoted from optimizing cost and performance to delivering advanced weapons at speed. Taking decades to deliver weapons is no longer an option. The DoW has joined the 21</span><span>st</span><span> century and adopted Lean Methodology.</span></p>
<p><span>Two organizations ought to be very concerned ‚Äì China and the defense prime contractors.</span></p>
<hr>
<p><span>Secretary of War Pete Hegseth <a href="https://www.war.gov/Multimedia/Videos/?videoid=986046" target="_blank" rel="noopener">unveiled the biggest changes in 60 years</a> of how the Department of War (DoW) plans for and buys weapons and services. These changes aren‚Äôt a minor attempt at reform. It‚Äôs a top-to-bottom transformation of how the DoW plans and buys weapons, moving from contracts that prioritize how much a weapon costs to how fast it can be delivered.&nbsp;</span></p>
<p><span>Instead of buying custom-designed weapons, the DoW will prioritize buying off-the-shelf things that already exist, and using fast-track acquisition processes, rather than the cumbersome existing <a href="https://www.acquisition.gov/sites/default/files/current/far/pdf/FAR.pdf" target="_blank" rel="noopener">Federal Acquisition Regulations</a>. To manage all of this, they are reorganizing the entire Acquisition ecosystem across the Services. These changes implement every piece of good advice the DoD had gotten in the last decade and had previously ignored.&nbsp;</span></p>
<p><span>The DoW is being redesigned to now operate at the speed of Silicon Valley, delivering more, better, and faster. Our warfighters will benefit from the innovation and lower cost of commercial technology, and the nation will once again get a military second to none.&nbsp;&nbsp;</span></p>
<p><span>It‚Äôs big, bold and brave and long overdue.</span></p>
<p><b>Background<br>
</b><span>In 1962 Robert McNamara, the then-Secretary of Defense (and ex CFO of Ford), discovered he had inherited a Defense Department whose spending was out of control. During the 1950s the Air Force built five different types of fighter planes, three generations of bombers, and three generations of ICBMs. The Navy had created a fleet of nuclear-powered attack and ballistic missile submarines and aircraft carriers. The Army bought three generations of its own nuclear-capable missile systems. Many of these systems duplicated capabilities of other services. But most importantly, the Services, in their rush to buy new technology, hadn‚Äôt adequately budgeted for the cost of operating, training, maintaining, and sustaining what they had bought.&nbsp;</span></p>
<p><span>In response, Secretary McNamara imposed the discipline of a Chief Financial Officer. He put in place a formal system of Planning (capability gaps, risks, scenarios, threats assumptions), Programming (5-year plans, affordability, quantities, phasing, unit fielding plans) and Budgeting that has lasted 60+ years. An entire defense university was created to train tens of thousands of contracting officers how to follow the detailed rules. Large contractors (the Primes) learned to work with this paperwork-heavy Defense acquisition system and lived with the very long time it took the DoD to buy.&nbsp;</span></p>
<p><b>The Problem<br>
</b>This unwieldy and lethargic acquisition system was adequate for over half a century when our adversary was the Soviet Union who had an equally complex acquisition system, or ISIS and Al Qaida who had none.</p>
<p><span>However, in the last decade it became painfully obvious that our acquisition system was broken and no longer worked for the world we lived in. Our existing defense industrial base suffers from schedule overruns and huge backlogs; cost increases have become the norm. We‚Äôve been outpaced by adversaries. China, for example, implemented a much more agile system that delivered weapons in a fraction of the time it took us.&nbsp;</span></p>
<p><span>We needed a defense industrial base we could count on to scale in a crisis rather than one that will wait for money before taking action.</span></p>
<p><span>The war in Ukraine showed that even a small country could produce millions of drones a year while continually iterating on their design to match changes on the battlefield. (Something we couldn‚Äôt do.) Meanwhile, commercial technology from startups and scaleups (fueled by an immense pool of private capital) has created off-the-shelf products, many unmatched by our federal research development centers or primes, that can be delivered at a fraction of the cost/time. But the DoW acquisition system was impenetrable to startups.&nbsp;</span></p>
<p><span>Our Acquisition system was paralyzed by our own impossible risk thresholds, its focus on process not outcomes, and became risk averse and immoveable.&nbsp;</span></p>
<p><span>We needed an acquisition system that could deliver needed things faster.</span></p>
<p><b>Reminder: What Did Our Acquisition System Look Like Until Last Week?<br>
</b><span>The Army, Navy, Air Force, Marines and Space Force train soldiers, sailors and airmen, and specify and buy the weapons for their Service. (It‚Äôs the Combatant Commands, e.g. <a href="https://www.pacom.mil/" target="_blank" rel="noopener">INDOPACOM</a>, <a href="https://www.centcom.mil/" target="_blank" rel="noopener">CENTCOM</a>, etc., who fight the wars.)</span></p>
<p><span>One of the confusing things about Acquisition in the DoW is that it is more than just the buyers of equipment. In the DoW Acquisition with capital ‚ÄúA‚Äù, includes the entire end-to-end process ‚Äì from concept, requirements, prototyping, testing, buying it, to using it and maintaining it.</span></p>
<p><span>In each of the Services, the current Acquisition system started with a group that forecast what the Service would need in the future and wrote requirements for future weapons/services/software. This process could take a year or more. Next, Service laboratories developed the technology, tested prototypes and concepts. This could take 3 to 6 years. Next, a vendor was selected and began to prototype and refine the systems. This added another 3 to 4 years. Finally, the system was ready to be built and delivered. It could take 1 to 2 years to deliver weapons in low rate production, or 5 to 10 years for something complex (e.g. aircraft, ships,&nbsp; spacecraft). In the system we‚Äôre replacing the time from when a need was turned into a requirement to delivery of a weapon would take 8 to 16 years. As you can imagine, given the rate of change of current technology and new warfighting concepts our own Acquisition process was an obstacle to building a modern War Department.&nbsp;&nbsp;</span></p>
<p><span>As an example, the Army‚Äôs current Acquisition system has </span><a href="https://www.pacom.mil/" target="_blank" rel="noopener"><span>32,000 civilians and military</span></a><span> (program managers, contracting officers, etc.) If you include the long tail of sustainment that‚Äôs another 165,000+ people. The Acquisition system in the Army (representative of the other services) looks like this:</span></p>
<p><img data-recalc-dims="1" fetchpriority="high" decoding="async" data-attachment-id="33272" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/from-need-to-production/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=1991%2C870&amp;ssl=1" data-orig-size="1991,870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="From Need to Production" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=300%2C131&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=468%2C204&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=468%2C205&amp;ssl=1" alt="" width="468" height="205" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=1024%2C447&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=300%2C131&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=150%2C66&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=768%2C336&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=1536%2C671&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=1991&amp;ssl=1 1991w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px"></p>
<p><b>What Was Wrong With this Process?</b></p>
<ul>
<li aria-level="1"><span>Responsibility in the Acquisition system was scattered across multiple, siloed organizations with no one individual responsible.&nbsp;</span></li>
<li aria-level="1"><span>The existing system was designed to acquire individual products (weapons, services, etc.) with a Program Executive Office to manage each effort that only indirectly solved warfighter problems.&nbsp;</span></li>
<li aria-level="1"><span>Requirements were written so that most everything the DoW bought was bespoke and required development from scratch.&nbsp;</span></li>
<li aria-level="1"><span>Acquisition was process-focused with rigid rules that emphasized compliance to contracting rules.&nbsp;</span></li>
<li aria-level="1"><span>Compliance to the rules and processes overrode speed of delivery</span></li>
<li aria-level="1"><span>Weapons and systems development used sequential ‚Äúwaterfall‚Äù development processes which precluded learning, pivots and iterative design. ‚Äã</span></li>
<li aria-level="1"><span>The result was that speed of delivery was on no one‚Äôs priority list.</span></li>
</ul>
<p><b>Why Is The Warfighting Acquisition System A Big Deal?<br>
</b><span>While previous administrations tried to go around the process, this new system confronts it head on. It is a revolutionary&nbsp; transformation in the Department of War. It was clearly designed by people who have worked in industry and understand commercial Lean Processes. This transformation will solve the DoW critical Acquisition problems by:</span></p>
<ul>
<li aria-level="1"><span>Prioritizing </span><i><span>speed</span></i><span> of delivery</span></li>
<li aria-level="1"><span>Moving the focus </span><i><span>from process to outcomes</span></i></li>
<li aria-level="1"><i><span>Organizational redesign</span></i><span> of the Acquisition process</span></li>
<li aria-level="1"><span>Changing </span><i><span>what weapons we ask for</span></i><span> and </span><i><span>how we prioritize</span></i><span> what we need to buy</span></li>
<li aria-level="1"><span>Changing the </span><i><span>preferred vendors</span></i><span> the DoW will buy from</span></li>
<li aria-level="1"><span>Changing the </span><i><span>contracting methods</span></i><span> the DoW will use</span></li>
<li aria-level="1"><span>Changing how we </span><i><span>measure and reward</span></i><span> success&nbsp;</span></li>
<li aria-level="1"><span>Changing how we </span><i><span>educate</span></i><span> Acquisition professionals</span></li>
<li aria-level="1"><span>Insisting that disparate systems/vendors </span><i><span>interoperate</span></i><span>&nbsp;</span></li>
</ul>
<p><b>The New Warfighting Acquisition Organization ‚Äì The Portfolio Acquisition Executive<br>
</b><span>To cut through the individual acquisition silos, the services are creating Portfolio Acquisition Executives (PAEs).&nbsp;</span></p>
<p><span>Each Portfolio Acquisition Executive (PAE) is responsible for the entire end-to-process of the different Acquisition functions: Capability Gaps/Requirements, System Centers, Programming, Acquisition, Testing, Contracting and Sustainment. PAEs are empowered to take calculated risks in pursuit of rapidly delivering innovative solutions.</span></p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="33273" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/pae-redrawn/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=2012%2C379&amp;ssl=1" data-orig-size="2012,379" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PAE Redrawn" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=300%2C57&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=468%2C88&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=468%2C88&amp;ssl=1" alt="" width="468" height="88" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=1024%2C193&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=300%2C57&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=150%2C28&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=768%2C145&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=1536%2C289&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=2012&amp;ssl=1 2012w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px"></p>
<p><i><span>PAE Offices Are Matrix Organizations<br>
</span></i><span>Portfolio Acquisition Executives (PAEs) are organized as a matrix organization ‚Äì using people from existing organizations ‚Äì requirements, PEOs, sustainment, contracting etc. The PAEs themselves will have a small staff for coordination.</span></p>
<p><i><span>Portfolios Around Common Problems<br>
</span></i>In the past, Acquisition was organized by weapon systems and managed by Program Executive Offices. Portfolios will organize instead around common Warfighting Concepts, technologies, or operational integration needs.</p>
<p><i><span>Multiple Portfolios In Each Service<br>
</span></i><span>Each of the services are consolidating and reorganizing the functions of what were their Program Executive Offices into Portfolios. Program Executive Offices/Officers (PEOs) will become Capability Program Executives (CPEs), and act as a Portfolios‚Äô acquisition arm.</span></p>
<p><span>(The examples below are from the Army. Other Services will have equivalent organizational designs for their Portfolios.)</span></p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="33274" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/pae-reporting-structure/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=1593%2C600&amp;ssl=1" data-orig-size="1593,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PAE Reporting Structure" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=300%2C113&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=468%2C176&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=468%2C176&amp;ssl=1" alt="" width="468" height="176" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=1024%2C386&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=150%2C56&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=768%2C289&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=1536%2C579&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=1593&amp;ssl=1 1593w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px">The acquisition chain of authority runs directly from Capability Program Manager to PAE to the Service Acquisition Executive (SAE), with no intermediate offices or approval layers. (The Service Acquisition Executive for the <span>Army is the </span><a href="https://www.army.mil/asaalt" target="_blank" rel="noopener">Assistant Secretary for Acquisition, Logistics &amp; Technology</a><span>. For the </span><span>Navy/Marines, the </span><a href="https://www.secnav.navy.mil/rda/Pages/default.aspx" target="_blank" rel="noopener">Assistant Secretary for Research, Development &amp; Acquisition</a>. For the <span>Air Force/Space Force the </span><a href="https://ww3.safaq.hq.af.mil/" target="_blank" rel="noopener">Assistant Secretary for Acquisition, Technology &amp; Logistics</a>.)</p>
<p><i><span>The Army Has 6 Portfolio Acquisition Executives<br>
</span></i><span>For example, the Army will likely reorganize its 12 existing PEO offices to become part of 6 portfolios aligned with Army <a href="https://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/September-October-2022/Ryan/" target="_blank" rel="noopener">Warfighting Concepts and functions</a>. Each of the 6 portfolios headed by a PAEs will be commanded by a Major General.</span></p>
<p><span>The likely 6 Army Portfolios are: 1) Maneuver, 2) Maneuver Air, 3)&nbsp; Fires, 4) C2/CC2,&nbsp; 5) Agile Sustainment and Ammo, and 6) Layered Protection and CBRN. One additional portfolio, called the PIT, will likely include the Army‚Äôs Innovation at the Edge activities.</span></p>
<blockquote><p><b>Army PAE Maneuver</b><span> will likely combine elements of </span><a href="https://www.peosoldier.army.mil/"><span>PEO Soldier</span></a><span>, </span><a href="https://asc.army.mil/web/peos/"><span>PEO Ground Combat Systems</span></a><span>, Future Capabilities Division and Maneuver Divisions, Test and Evaluation Integrator, Strategic Contracting Office, and others. This portfolio will likely have the Abrams tank, XM30 Mechanized Infantry Combat Vehicle (replacing the M2 Bradley), the ISV (Infantry Squad Vehicle), Soldier Borne Mission Command program (SBMC), </span><a href="https://www.peosoldier.army.mil/Equipment/Equipment-Portfolio/Project-Manager-Soldier-Lethality-Portfolio/Next-Generation-Squad-Weapons-Program/"><span>Next Generation Squad Weapon (NGSW),</span></a> <a href="https://www.peosoldier.army.mil/Equipment/Equipment-Portfolio/Project-Manager-Soldier-Warrior-Portfolio/Soldier-Borne-Sensor/"><span>Soldier Borne Sensor (SBS)</span></a><span> program, and Organization Clothing and Individual Equipment (OCIE).</span></p></blockquote>
<p><i><span>Authority to Make Trade-offs<br>
</span></i><span>PAEs now have the authority to make trade-offs between cost, schedule and performance and apply flexible funding between weapons systems to rapidly deliver capabilities to the warfighter. This means focusing on fielding ‚Äúgood enough‚Äù technology instead of waiting for a product that meets every single requirement.</span></p>
<blockquote><p><b>Army PAE Maneuver Air </b><span>will likely combine elements of Program Executive Office Aviation, Aviation and Missile Command, Futures Command Future Vertical Lift team </span><span>DEVCOM Aviation &amp; Missile</span><span>, and others. It will likely include the </span><a href="https://www.dote.osd.mil/Portals/97/pub/reports/FY2022/army/2022flraa1.pdf"><span>Long-Range Assault Aircraft (FLRAA)</span></a><span> the </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=Bell+V-280+Valor&amp;ie=UTF-8&amp;oe=UTF-8&amp;mstk=AUtExfBXk1wpQ9nNWAH9wfiFhLZO4pyxDcL1iLabWTxIz3gepfqNP7falcz0lufv7o6EEc-zom0lNQBw0AW7zA59VyNMfvkozi14kulwI73uVf4dZTYUif6VJdBMllvs1ck4bB3sGqF-CVkOiIVKJp-hSbD3N-54xHv-bbtbllOvoVSxQEU&amp;csui=3&amp;ved=2ahUKEwiTos3ZxuaQAxWWFTQIHbyqIysQgK4QegQIARAE"><span>Bell V-280 Valor</span></a><span> (to replace the </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=UH-60+Black+Hawk&amp;ie=UTF-8&amp;oe=UTF-8&amp;mstk=AUtExfBXk1wpQ9nNWAH9wfiFhLZO4pyxDcL1iLabWTxIz3gepfqNP7falcz0lufv7o6EEc-zom0lNQBw0AW7zA59VyNMfvkozi14kulwI73uVf4dZTYUif6VJdBMllvs1ck4bB3sGqF-CVkOiIVKJp-hSbD3N-54xHv-bbtbllOvoVSxQEU&amp;csui=3&amp;ved=2ahUKEwiTos3ZxuaQAxWWFTQIHbyqIysQgK4QegQIARAF"><span>UH-60 Black Hawk</span></a><span>), Uncrewed Aircraft Systems (UAS), Rotary and Fixed Wing, and Autonomy.</span></p></blockquote>
<p><i><span>Program Executive Officers (PEOs) are Now Capability Program Executives (CPEs)<br>
</span></i>Inside each portfolio is a Capability Program Executive (CPE), typically a Brigadier General or a civilian SES. Capability Program Executives have similar roles and responsibilities as today‚Äôs PEOs. They are the Acquisition leader responsible for cradle-to-grave management of their programs within their portfolio.</p>
<p><i><span>Streamlined Layers of Bureaucracy<br>
</span></i><span>97 Army acquisition programs may be reassigned to align with the Army PAE reorganization.&nbsp;</span><span>46 organizations that were writing requirements likely will be consolidated into 9 Future Capability Directorates.</span></p>
<blockquote><p><b>Army PAE Fires</b><span> will likely combine elements from Program Executive Office Missiles and Space, Enterprise Information Systems, the Rapid Capabilities and Critical Technologies Office, Fires System Center, and others. It will likely include the </span><a href="https://www.army-technology.com/projects/integrated-battle-command-system-ibcs-usa/"><span>Integrated Battle Command System (IBCS),</span></a> <a href="https://www.army-technology.com/projects/patriot/"><span>Patriot/PAC-3,</span></a> <a href="https://www.defensenews.com/land/2025/10/13/army-accelerates-prsm-output-as-atacms-nears-sunset/"><span>Precision Strike Missile (PrSM),</span></a> <a href="https://www.dote.osd.mil/Portals/97/pub/reports/FY2023/army/2023lrhw.pdf?ver=jClghaowEkarGt-qUGMXNg%3D%3D"><span>Long-Range Hypersonic Weapon ‚Äì Dark Eagle (LRHW),</span></a> <a href="https://www.army.mil/article/287739/army_developing_new_iterations_of_autonomous_missile_launcher"><span>Common Autonomous Multi-Domain Launcher (CAML),</span></a> <a href="https://www.army.mil/article/286099/shielding_the_pacific_inside_the_guam_defense_system_joint_program_office"><span>Guam Defense</span></a><span> and Golden Dome.</span></p></blockquote>
<p><i><span>DoW Will Buy Commercial First<br>
</span></i><span>One of the biggest changes is the mandate for PAEs to buy Commercial Off the Shelf (COTS) products, modify them if necessary and only buy bespoke products as a last resort. This change by itself is going to send shockwaves through the existing Prime contractors.</span></p>
<p><span>It‚Äôs telling everyone that the playing field is now open to everyone. Forget who has more lobbyists on K-Street. Speed, mission impact, and innovation is what will be rewarded. What this means for startups is that if you can execute and deliver (not just PowerPoints) you can become a supplier to the DoW.&nbsp;&nbsp;</span></p>
<p><i><span>Incentive Compensation to PAEs and Program Managers<br>
</span></i><span>PAEs will be judged on whether they deliver systems to the warfighter on time and on schedule. PAEs and Program Managers will have ‚Äúincentive compensation‚Äù tied to ‚Äúcapability delivery time, competition, and mission outcomes. (How they‚Äôll pay that kind of compensation for a member of the military remains to be seen.)</span></p>
<p><i><span>Incentives and Scorecards for Contractors<br>
</span></i>They‚Äôll be managing their contractors with ‚Äútime-indexed incentives‚Äù to make sure contractors deliver on time and on budget, using ‚Äúscorecards‚Äù to keep tabs on how each portfolio is doing.</p>
<blockquote><p><b>Army PAE C2/CC2 </b>(Command and Control/Counter Command and Control) <span>will likely combine elements of PEO Command, Control, Communications and Network.. And include NGC2, TITAN, TENCAP, Next Generation Constructive, STE</span></p></blockquote>
<p><i><span>Non-Traditional Entry Points</span></i><span><br>
</span><span>Companies selling to the DoW previously had to comply with the impenetrable DFAR and FAR ‚Äì the Defense and Federal Acquisition Regulations ‚Äì with over 5,000 pages of complex rules. It was designed for buying Aircraft Carriers, not startup technology.&nbsp;</span></p>
<p><span>Now the DoW is telling PAEs to toss those and use Non-FAR regulations like OTAs (Other Transaction Authorities). OTAs are not subject to the extensive, rigid rules and regulations of the DFAR. They allow for greater flexibility, speed, and allow the DoW to work with a broader range of innovative commercial companies. For startups this means massively reduced documentation, shorter timelines, and fewer barriers to working with the DoW.</span></p>
<p><i><span>PAEs Will Use Lean Methodology<br>
</span></i><span>Rather than fixed requirements and using waterfall development processes, the services are now insisting that vendors use Lean Methodology to set incremental and iterative delivery targets. That means they can field ‚Äúgood enough technology‚Äù that can be incrementally updated in the field and improved on a more frequent cadence.</span></p>
<p><span>The only requirement for each increment is that they need to target 1) an initial fielding date, </span><span><br>
</span><span>2) set a maximum cost of each unit and 3) meet the minimum standards for mission effectiveness. Other than that, PAEs have the authority that other attributes of the weapons/software can remain tradable throughout development to allow incremental enhancements and rapid delivery of subsequent increments. This includes the ability to waive technical standards and environmental and other compliance requirements, unless they are mandated by statute or safety.</span></p>
<p><span>One other interesting Lean mandate is that each PAE will set up lean technical advisory processes to inform accelerated decision-making, ensuring technical rigor without sacrificing speed.</span></p>
<p><i><span>Weapons Will Be Able to Talk to Each Other ‚Äì By Design<br>
</span></i>The new PAEs are also tasked with insisting that all weapons across their programs use&nbsp;<a href="https://breakingdefense.com/tag/modular-open-systems-architecture/">Modular Open System Architectures</a>, including by asserting government purpose rights over critical software interfaces ‚Äî a move that allows the Pentagon to retain the data rights needed to avoid ‚Äúvendor lock‚Äù (weapon systems that can only be modified and/or repaired by the company that designed it).</p>
<blockquote><p><b>Army PAE Agile Sustainment </b><span>will likely combine elements of PEO Combat Support and Combat Service Support, PEO Solider and PEO Joint Program Office Armaments and Ammunition. It will likely include next generation Common Tactical Truck (CTT,) Family of Medium Tactical Vehicles (FMTV), 155mm, 6.8mm ammunition.</span></p></blockquote>
<p><i><span>Two Vendors Through Initial Production<br>
</span></i><span>The DoW has painfully learned that having only one vendor selected leads to cost overruns and late projects. A new idea is that each critical acquisition program will have at least two qualified sources through initial production. While this will cost more upfront, it gives government leverage when it is strongest and enables them to re-compete modular components and find alternative suppliers if needed.</span></p>
<p><i><span>Design For Rapid Scale In a Crisis<br>
</span></i><span>PAEs have been told to establish acquisition strategies that decouple design from production to allow additional third-party suppliers to surge and rapidly scale manufacturing capacity in a crisis. They are to put in place&nbsp; guidelines for wartime consumption rates through manufacturing and supply chain partnerships and alternative sources.</span></p>
<blockquote><p><b>Army PAE Layered Protection and CBRN (</b><b>Chemical, Biological, Radiological, and Nuclear) </b><b></b><span>will likely combine elements of PEO JPEO-CBRND. It will likely include Joint Chemical Agent Detector, UIPE, Decontamination Family of Systems, Biometrics</span></p></blockquote>
<p><i><span>PAE Officers Now Have More Time To Learn On the Job<br>
</span></i><span>A complaint from past acquisition program managers is that they would only be there for two or three years, and then off to their next assignment. Two years was not enough time to see a program through. Now PAEs will have 4-year tours, extendible for another 2 years.</span></p>
<p><i><span>PAEs Top to Bottom<br>
</span></i><span>Every military service has 60 days to tell the Secretary of War a list of portfolios it is proposing to be initially stood up. A full implementation plan is due in 90 days. All major acquisition activities across all Services are going to be transitioned to PAE portfolios within two years.&nbsp;</span></p>
<blockquote><p><b>Army PIT </b><span>is the Army‚Äôs innovation initiatives at the edge. It‚Äôs the front door for startups wanting to partner with the Army.&nbsp;</span></p>
<ul>
<li><span>The PIT includes the Joint Innovation Outpost, the Global Tactical Edge Acquisition Directorate (G-TEAD) Marketplace, the </span><a href="https://fuze.army.mil/"><span>FUZE program</span></a><span>, and Disruptive Technologies.&nbsp;</span></li>
<li><span>The G-TEAD Marketplace merges Prize Challenge events (e.g., Army xTech Program) and DEP submissions through open call announcements.</span></li>
<li><span>FUZE brings together the </span><a href="https://fuze.army.mil/programs/sbir-sttr/"><span>Army SBIR/STTR</span></a><span> seed funding, </span><a href="https://fuze.army.mil/programs/mantech/"><span>MANTECH</span></a><span> (Army Manufacturing Technology program), </span><a href="https://fuze.army.mil/programs/tmi/"><span>TMI</span></a><span> (Tech Maturation Initiative) and </span><a href="https://fuze.army.mil/programs/xtech/"><span>XTech</span></a><span> the Army‚Äôs scouting program.&nbsp;</span></li>
</ul>
</blockquote>
<p><b>Reeducation Camp ‚Äì Warfighting Acquisition University<br>
</b><span>To retrain/reeducate contracting and acquisition officers, the ‚Äú</span><a href="https://www.dau.edu/" target="_blank" rel="noopener"><span>Defense Acquisition University</span></a><span>‚Äù will become the ‚ÄúWarfighting Acquisition University.‚Äù They have been ordered to stop compliance-focused training operations and in six months transform into a competency-based education institution.</span></p>
<p>The university will pivot to offer <span>experiential&nbsp;team-based programs</span> that work on real DoW challenges (does that ever sound like a description of <a href="https://www.h4d.us/" target="_blank" rel="noopener">Hacking for Defense.</a>) And they‚Äôre going to have their students get out of the building and take part in industry-government exchanges. In the next <span>six months they‚Äôre going to prioritize education and rotation programs to get their students exposure to commercial industry practices, manufacturing and operational expertise, and real-world problem-solving. </span>All to develop Acquisition executives critical thinking and agile and rapid decision-making skills. (Note to DAU: we‚Äôve been building these programs for a decade at the Stanford <a href="https://gordianknot.fsi.stanford.edu/" target="_blank" rel="noopener">Gordian Knot Center for National Security Innovation.</a> Our <a href="https://www.commonmission.us/" target="_blank" rel="noopener">national security classes</a> are in 60+ universities and we‚Äôre happy to help.)</p>
<p><b>The Joint Staff ‚Äì Coordinating the Needs of All the Services<br>
</b><span>While each of the Services generated their own weapons requirements, plans and budgets, they all had to be approved by the Joint Staff (which reports to the Secretary of War) through a </span><span>process called the JCIDS (Joint Capabilities Integration &amp; Development System). In theory this was to </span><span>coordinate each of the Service‚Äôs needs so they weren‚Äôt duplicating each other, to ensure that they were interoperable, and to give the Combatant Command a voice; and tie all the requirements to joint concepts ‚Äì all of this needing to be done before Service weapons programs got funded and built.</span></p>
<p><span>The problem was that JCIDS moved at the speed of paperwork, not war, so the Secretary of War eliminated it earlier this year. (They kept part of it called the </span><a href="https://ssl.armywarcollege.edu/dde/learningmodules/jsps/terms/jroc.cfm"><span>Joint Requirements Oversight Council</span></a><span> but reoriented it from validating documents to identifying joint operational problems, which will drive the priorities for the entire department of War.)&nbsp;</span></p>
<p><span>In JCIDS‚Äô place the Secretary of War created three new organizations:</span></p>
<ul>
<li aria-level="1"><span>The Joint Acceleration Reserve, a pool of money set aside to quickly field promising capabilities.</span></li>
<li aria-level="1"><span>The Requirements and Resourcing Alignment Board (RRAB) that will tie money directly to the top warfighting priorities and how much money each will get from the new Joint Acceleration Reserve.</span></li>
<li aria-level="1"><span>The Mission Engineering and Integration Activity </span><span>brings government, industry, and labs together early on to </span><span>rapidly</span><span> experiment, test, and prototype new tech.</span></li>
</ul>
<p><span>It‚Äôs interesting to note that none of these changes at the Joint Staff have seemed to (at least publicly) filter down to the charter of the Services Portfolio Acquisition Executives (PAEs). The achilles heel of the Services Acquisition process appears that they are still planning to put the Requirements and Capability gap analysis up front. &nbsp;Here‚Äôs why that‚Äôs a problem and how to fix it.</span></p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="33311" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/sidebar-2/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=1504%2C1622&amp;ssl=1" data-orig-size="1504,1622" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sidebar" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=278%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=468%2C504&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=468%2C505&amp;ssl=1" alt="" width="468" height="505" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=950%2C1024&amp;ssl=1 950w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=278%2C300&amp;ssl=1 278w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=139%2C150&amp;ssl=1 139w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=768%2C828&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=1424%2C1536&amp;ssl=1 1424w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?w=1504&amp;ssl=1 1504w" sizes="auto, (max-width: 468px) 100vw, 468px"></p>
<p><b>Foreign military sales<br>
</b><span>One other tangential decision in this redesign was not in acquisition but in sales. The DoW wants a greater emphasis on selling our weapons to our Allies. They‚Äôve moved two agencies responsible for those functions ‚Äì the </span><a href="https://www.dtsa.mil/"><span>Defense Technology Security Administration</span></a> <a href="https://www.dtsa.mil/"><span>DTSA</span></a><span> and the </span><a href="https://www.dsca.mil/"><span>Defense Security Cooperation Agency (DSCA)</span></a><span> ‚Äì from OSD Policy to OSD Acquisition and Sustainment.&nbsp;</span></p>
<p><span>This move is about selling more of our equipment, but makes no mention of buying any equipment from our allies.</span></p>
<p><i><span>Inferred But Not Mentioned<br>
</span></i><span>Pretty interesting that in this reorg no one has noticed that <a href="https://www.war.gov/About/Biographies/Biography/Article/1230279/elbridge-a-colby/">Elbridge Colby</a> ‚Äì Under Secretary for Policy ‚Äì had three organizations taken away from him.&nbsp;&nbsp;</span></p>
<ol>
<li><a href="https://www.dtsa.mil/"><span>Defense Technology Security Administration</span></a> <a href="https://www.dtsa.mil/"><span>DTSA</span></a></li>
<li><a href="https://www.dsca.mil/"><span>Defense Security Cooperation Agency (DSCA)</span></a></li>
<li><span>The Joint Production Accelerator Cell (JPAC) now renamed the Wartime Production Unit (WPU)</span></li>
</ol>
<p><span>All three organizations were handed to <a href="https://www.acq.osd.mil/leadership/as/michael-duffey.html">Michael Duffey</a> the Under Secretary for Acquisition &amp; Sustainment. Regardless of the public statements the optics are not a vote of confidence.</span></p>
<p><b>Bigger and Better?<br>
</b><span>It appears that </span><a href="https://www.cto.mil/osc/"><span>the Office of Strategic Capital</span></a><span> may have been swallowed up by the Economic Defense Unit run by George Kolitdes. From all appearances the Economic Defense Unit is tasked to decouple our economy from China, using private and public capital. That means considering how to on-shore the critical components like minerals, chips, batteries, motors, PNT, etc.) The Acquisition announcement was how to buy things. This Economic Defense Unit is how do we ensure the things we buy are made with parts we know we can have an assured supply of?</span></p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="33289" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/current-system/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=1008%2C2400&amp;ssl=1" data-orig-size="1008,2400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Current system" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=126%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=430%2C1024&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=468%2C1114&amp;ssl=1" alt="" width="468" height="1114" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=430%2C1024&amp;ssl=1 430w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=126%2C300&amp;ssl=1 126w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=63%2C150&amp;ssl=1 63w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=768%2C1829&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=645%2C1536&amp;ssl=1 645w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=860%2C2048&amp;ssl=1 860w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?w=1008&amp;ssl=1 1008w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?w=936&amp;ssl=1 936w" sizes="auto, (max-width: 468px) 100vw, 468px"></p>
<p><b>Summary</b></p>
<blockquote>
<ul>
<li><span>Startups and the DoW are now speaking the same language ‚Äì Lean, feedback from the field, pivots, iterative and incremental product design, speed to delivery.</span></li>
<li><span>&nbsp;The DoW mandate to first buy commercial-off-the-shelf products is a once-in-a-lifetime opportunity for every startup and scaleup.</span>
<ul>
<li><span>But you have to deliver. Don‚Äôt hand wave with PowerPoints.</span></li>
<li><span>DoW will be ruthless in shutting down and freezing out non-performers.</span></li>
</ul>
</li>
<li><span>The use of Non-Federal Acquisition Regulations will eliminate huge amounts of paperwork.&nbsp;</span>
<ul>
<li><span>It eliminates one of the reasons to subcontract with a prime or other company&nbsp;</span></li>
</ul>
</li>
<li><span>DoW needs to be ruthless in reforming the compliance culture</span></li>
<li><span>Who to talk to in each service and how will they do business will be unclear for at least the next six months</span>
<ul>
<li><span>Reorganizations will create uncertainty of who is the front door for startups, how the new rules apply, and who can commit to contracts.</span></li>
<li><span>The Army appears to be further along than the other services in putting a PAE organization in place.</span></li>
</ul>
</li>
<li><span>In theory this is a knife to the heart of the Primes‚Äô business model.&nbsp;</span>
<ul>
<li><span>They will flood Congress and the Executive Branch with infinite capital to change these rules.</span></li>
<li><span>It‚Äôs a race between private capital and public company lobbying money</span></li>
</ul>
</li>
<li><span>Let‚Äôs hope these changes stick</span></li>
</ul>
</blockquote>
<p><span>Thanks to <a href="https://www.linkedin.com/in/petenewell/">Pete Newell</a> of BMNT for the feedback and insight.</span></p>
					
					<p>
						Filed under: <a href="https://steveblank.com/category/national-security/" rel="category tag">National Security</a>, <a href="https://steveblank.com/category/technology-innovation-and-modern-war-2/" rel="category tag">Technology Innovation and Modern War</a> |					</p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling HNSWs (146 pts)]]></title>
            <link>https://antirez.com/news/156</link>
            <guid>45887466</guid>
            <pubDate>Tue, 11 Nov 2025 14:11:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/156">https://antirez.com/news/156</a>, See on <a href="https://news.ycombinator.com/item?id=45887466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="156-" id="156-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 8 hours ago. 23212 views.  </span><pre>I‚Äôm taking a few weeks of pause on my HNSWs developments (now working on some other data structure, news soon). At this point, the new type I added to Redis is stable and complete enough, it‚Äôs the perfect moment to reason about what I learned about HNSWs, and turn it into a blog post. That kind of brain dump that was so common pre-AI era, and now has become, maybe, a bit more rare. Well, after almost one year of thinking and implementing HNSWs and vector similarity stuff, it is time for some writing. However this is not going to be an intro on HNSWs: too many are present already. This is the ‚Äúextra mile‚Äù instead. If you know HNSWs, I want to share with you my more ‚Äúadvanced‚Äù findings, especially in the context of making them fast enough to allow for a ‚ÄúRedis‚Äù experience: you know, Redis is designed for low latency and high performance, and HNSWs are kinda resistant to that, so there were challenges to expose HNSWs as an abstract data structure.

This blog post will be split into several sections. Think of them as pages of the same book, different chapters of the same experience. Oh and, by the way, I already wrote and subsequently lost this blog post :D [long, sad story about MacOS and bad habits ‚Äì I hadn‚Äôt lost something like that since the 90s, during blackouts], so here most of the problem will be to recall what I wrote a few days ago and, while I‚Äôm at it, to better rephrase what I didn‚Äôt like very much.

## A few words about the state of HNSW

Before digging into the HNSWs internals and optimizations, I want to say a few things about HNSWs. The original paper introducing HNSWs is a great piece of computer science literature, and HNSWs are amazing data structures, but: I don‚Äôt believe they are the last word for searching, in a greedy way, for nearby vectors according to a distance function. The paper gives the feeling it lacks some ‚Äúpieces‚Äù, almost like if the researchers, given six months more, had a lot more to explore and say. For instance, I modified the paper myself, extending it in order to support removal of entries, actual removals, not just tombstone deletions where the element is marked as gone and collected later: deleting items is totally missing from the paper. Similarly, there are, right now, efforts in order to really check if the ‚ÄúH‚Äù in the HNSWs is really needed, and if instead a flat data structure with just one layer would perform more or less the same (I hope I‚Äôll cover more about this in the future: my feeling is that the truth is in the middle, and that it makes sense to modify the level selection function to just have levels greater than a given threshold).

All this to say that, if you are into data structures research, I believe that a great area is to imagine evolutions and refinements of HNSWs, without getting trapped within the idea that the evolutions are only in the sense of: let‚Äôs do it, but for disk (see Microsoft efforts), or the like. Ok, enough with the premise, let‚Äôs go to the actual low level stuff :)

## Scaling memory

Redis is an in-memory system, and both HNSWs and vectors have the unfortunate quality of being very space-hungry. There are three reasons for this: 1. HNSWs have a lot of pointers, like 16, 32 or more pointers (this is a tunable parameter of HNSWs) to neighbor nodes. 2. HNSWs have many levels, being a skiplist-alike data structure. This exacerbates the first problem. 3. HNSW‚Äôs satellite data is a vector of floating point numbers, so, in the vanilla case, 4 bytes per component, and normally you can have 300-3000 components, this is the usual range.

So, what are the lessons learned here? There are folks that compress pointers, since it is very likely that many pointers (8 bytes in 64 bit systems) will have the highest four bytes all the same. This is smart, I didn‚Äôt implement it yet, because in Redis I need to go fast, and this is a tradeoff between space and time: but maybe it is worth it, maybe not. I‚Äôll dig more. 

However, if you do the math, the fact that there are many layers is not *so* terrible as it looks. On average, the multiple layers per node make the situation worse by just ~1.3x (if the probability of level increase is 0.25 in the level selection function), since many nodes will be just at layer 0. But still 1.3 is more than 1, and if that ‚ÄúH‚Äù in HNSWs really is not *so* useful‚Ä¶ [Spoiler, what I found is that the seek time if you have everything at layer 0 is greater, the main loop for the greedy search will start from less optimal places and it will eventually reach the right cluster, but will take more computation time. However this is just early results.]

So here the *real* low hanging fruit is: vector quantization. What I found is that if you use 8 bit quantization what you get is an almost 4x speedup, a 4x reduction of your vectors (but not a 4x reduction of the whole node: the pointers are still there, and they take a lot of space), and a recall that is virtually the same in real world use cases. This is the reason why Redis Vector Sets use 8 bit quantization by default. You can specify, via VADD options, that you want full precision vectors or binary quantized vectors, where we just take the sign, but I‚Äôm skeptical about using both full size vectors and binary quantized vectors. Before talking about them, let‚Äôs see what kind of quantization I used for 8 bit.

What I do is to compute the maximum absolute value of the component of each vector (so quantization is per-vector), then I use signed 8 bit values to represent the quant from -127 to 127. This is not as good as storing both min and max value, but it is faster when computing cosine similarity, since I can do this:

    /* Each vector is quantized from [-max_abs, +max_abs] to [-127, 127]
     * where range = 2*max_abs. */
    const float scale_product = (range_a/127) * (range_b/127);

Then I multiply things together in the integer domain with (actually in the code the main loop is unrolled and uses multiple accumulators, to make modern CPUs more busy)

    for (; i &lt; dim; i++) dot0 += ((int32_t)x[i]) * ((int32_t)y[i]);

And finally we can return back to the floating point distance with:

    float dotf = dot0 * scale_product;

Check the vectors_distance_q8() for more information, but I believe you got the idea: it is very simple to go from the integer quants domain to the unquantized dotproduct with trivial operations.

So, 8 bit quantization is a great deal, and full precision was a *needed* feature, because there will be people doing things with vectors generated in a way where each small amount makes a difference (no, with learned vectors this is not the case‚Ä¶) but, why binary quantization? Because I wanted users to have a simple way to not waste space when their *original* information is already binary. Imagine you have a set of users and they have yes/no properties, and you want to find similar users, items, whatever. Well: this is where binary quantization should be used, it‚Äôs just, again, an option of the VADD command.

## Scaling speed: threading and locality

Oh, you know, I have to tell you something about myself: I‚Äôm not a fan of threaded systems when it is possible to do a lot with a single core, and then use multiple cores in a shared-nothing architecture. But HNSWs are different. They are *slow*, and they are accessed almost always in read-only ways, at least in most use cases. For this reason, my Vector Sets implementation is fully threaded. Not just reads, even writes are partially threaded, and you may wonder how this is possible without it resulting in a mess, especially in a system like Redis, where keys can be accessed in different ways by the background saving process, the clients, and so forth.


Well, to start, let‚Äôs focus on reads. What happens is that as long as nobody is writing in the data structure, we can spawn threads that do the greedy collection of near vectors and return back the results to the blocked client. However, my implementation of HNSWs was written from scratch, I mean, from the empty C file opened with vim, it has 0% of shared code with the two implementations most other systems use, so there are a few ‚Äúnovelties‚Äù. One of such different things is that in order to avoid re-visiting already visited nodes, I use an integer stored in each node that is called ‚Äúepoch‚Äù, instead of using another data structure to mark (like, in a hash table) nodes already visited. This is quite slow, I believe. The epoch instead is local to the node, and the global data structure increments the epoch for each search. So in the context of each search, we are sure that we can find epochs that are just &lt;= the current epoch, and the current epoch can be used to mark visited nodes.

But with threads, there are multiple searches occurring at the same time! And, yep, what I needed was an array of epochs:

typedef struct hnswNode {
    uint32_t level;         /* Node's maximum level */
    ‚Ä¶ many other stuff ‚Ä¶
    uint64_t visited_epoch[HNSW_MAX_THREADS];
}

That‚Äôs what you can read in hnsw.h. This is, again, a space-time tradeoff, and again time won against space.

So, how was it possible to have threaded writes? The trick is that in HNSW inserts, a lot of time is spent looking for neighbors candidates. So writes are split into a reading-half and commit-half, only the second needs a write lock, and there are a few tricks to make sure that the candidates we accumulated during the first part are discarded if the HNSW changed in the meantime, and some nodes may no longer be valid. There is, however, another problem. What about the user deleting the key, while background threads are working on the value? For this scenario, we have a function that waits for background operations to return before actually reclaiming the object. With these tricks, it is easy to get 50k ops/sec on real world vector workloads, and these are numbers I got from redis-benchmark itself, with all the overhead involved. The raw numbers of the flat HNSW library itself are much higher.

## Scaling memory: reclaiming it properly

Before talking about how to scale HNSWs into big use cases with multiple instances involved, and why Redis Vector Sets expose the actual data structure in the face of the user (I believe programmers are smart and don‚Äôt need babysitting, but it‚Äôs not *just* that), I want to go back and talk again about memory, because there is an interesting story to tell about this specific aspect.

Most HNSWs implementations are not able to reclaim memory directly when you delete a node from the graph. I believe there are two main reasons for that:

1. People misunderstand the original HNSW paper in a specific way: they believe links can be NOT reciprocal among neighbors. And there is a specific reason why they think so.

2. The paper does not say anything about deletion of nodes and how to fix the graph after nodes go away and we get missing links in the ‚Äúweb‚Äù of connections.

The first problem is a combination (I believe) of lack of clarity in the paper and the fact that, while implementing HNSWs, people face a specific problem: when inserting a new node, and good neighbors are searched among existing nodes, often the candidates already have the maximum number of outgoing links. What to do, in this case? The issue is often resolved by linking unidirectionally from the new node we are inserting to the candidates that are already ‚Äúfull‚Äù of outgoing links. However, when you need to delete a node, you can no longer resolve all its incoming links, so you can‚Äôt really reclaim memory. You mark it as deleted with a flag, and later sometimes there is some rebuilding of the graph to ‚Äúgarbage collect‚Äù stale nodes, sometimes memory is just leaked.

So, to start, my implementation in Redis does things differently by forcing links to be bidirectional. If A links to B, B links to A. But, how to do so, given that A may be busy? Well, this gets into complicated territory but what happens is that heuristics are used in order to drop links from existing nodes, with other neighbors that are well connected, and if our node is a better candidate even for the target node, and if this is not true there are other ways to force a new node to have at least a minimal number of links, always trying to satisfy the small world property of the graph.

This way, when Redis deletes a node from a Vector Set, it always has a way to remove all the pointers to it. However, what to do with the remaining nodes that now are missing a link? What I do is to create a distance matrix among them, in order to try to link the old node neighbors among them, trying to minimize the average distance. Basically for each pair of i,j nodes in our matrix, we calculate how good is their connection (how similar their vectors are) and how badly linking them affects the *remaining* possible pairs (since there could be elements left without good pairs, if we link two specific nodes). After we build this matrix of scores, we then proceed with a greedy pairing step.

This works so well that you can build a large HNSW with millions of elements, later delete 95% of all your elements, and the remaining graph still has good recall and no isolated nodes and so forth.

That is what I mean when I say that there is space in HNSWs for new papers to continue the work.

## Scaling HNSWs to multiple processes

When I started to work at Redis Vector Sets, there was already a vector similarity implementation in Redis-land, specifically as an index type of RediSearch, and this is how most people think at HNSWs: a form of indexing of existing data.

Yet I wanted to provide Redis with a new HNSW implementation exposed in a completely different way. Guess how? As a data structure, of course. And this tells a story about how Redis-shaped is my head after so many years, or maybe it was Redis-shaped since the start, and it is Redis that is shaped after my head, since I immediately envisioned how to design a Redis data structure that exposed HNSWs to the users, directly, and I was puzzled that the work with vectors in Redis was not performed exactly like that.

At the same time, when I handed my design document to my colleagues at Redis, I can‚Äôt say that they immediately ‚Äúsaw‚Äù it as an obvious thing. My reasoning was: vectors are like scores in Redis Sorted Sets, except they are not scalar scores where you have a total order. Yet you can VADD, VREM, elements, and then you can call VSIM instead of ZRANGE in order to have *similar* elements. This made sense not just as an API, but I thought of HNSWs as strongly composable, and not linked to a specific use case (not specific to text embeddings, or image embeddings, or even *learned* embeddings necessarily). You do:

    VADD my_vector_set VALUES [‚Ä¶ components ‚Ä¶] my_element_string

So whatever is in your components, Redis doesn't care, when you call VSIM it will report similar elements.

But this also means that, if you have different vectors about the same use case split in different instances / keys, you can ask VSIM for the same query vector into all the instances, and add the WITHSCORES option (that returns the cosine distance) and merge the results client-side, and you have magically scaled your hundred of millions of vectors into multiple instances, splitting your dataset N times [One interesting thing about such a use case is that you can query the N instances in parallel using multiplexing, if your client library is smart enough].

Another very notable thing about HNSWs exposed in this raw way, is that you can finally scale writes very easily. Just hash your element modulo N, and target the resulting Redis key/instance. Multiple instances can absorb the (slow, but still fast for HNSW standards) writes at the same time, parallelizing an otherwise very slow process.

This way of exposing HNSWs also scales down in a very significant way: sometimes you want an HNSW for each user / item / product / whatever you are working with. This is very hard to model if you have an index on top of something, but it is trivial if your HNSWs are data structures. You just can have a Vector Set key for each of your items, with just a handful of elements. And of course, like with any other Redis key, you can set an expiration time on the key, so that it will be removed automatically later.

All this can be condensed into a rule that I believe should be more present in our industry: many programmers are smart, and if instead of creating a magic system they have no access to, you show them the data structure, the tradeoffs, they can build more things, and model their use cases in specific ways. And your system will be simpler, too.

## Scaling loading times

If I don‚Äôt use threading, my HNSW library can add word2vec (300 components for each vector) into an HNSW at 5000 elements/second if I use a single thread, and can query the resulting HNSW at 90k queries per second. As you can see there is a large gap.

This means that loading back an HNSW with many millions of elements from a Redis dump file into memory would take a lot of time. And this time would impact replication as well. Not great. But, this is true only if we add elements from the disk to the memory in the most trivial way, that is storing ‚Äúelement,vector‚Äù on disk and then trying to rebuild the HNSW in memory. There is another lesson to learn here. When you use HNSWs, you need to serialize the nodes and the neighbors as they are, so you can rebuild everything in memory just allocating stuff and turning neighbors IDs into pointers. This resulted in a 100x speedup.

But do you really believe the story ends here? Hehe. Recently Redis has stronger security features and avoids doing bad things even when the RDB file is corrupted by an attacker. So what I needed to do was to make sure the HNSW is valid after loading, regardless of the errors and corruption in the serialized data structure. This involved many tricks, but I want to take the freedom to just dump one comment I wrote here, as I believe the reciprocal check is particularly cool:

    /* Second pass: fix pointers of all the neighbors links.
     * As we scan and fix the links, we also compute the accumulator
     * register "reciprocal", that is used in order to guarantee that all
     * the links are reciprocal.
     *
     * This is how it works, we hash (using a strong hash function) the
     * following key for each link that we see from A to B (or vice versa):
     *
     *      hash(salt || A || B || link-level)
     *
     * We always sort A and B, so the same link from A to B and from B to A
     * will hash the same. Then we xor the result into the 128 bit accumulator.
     * If each link has its own backlink, the accumulator is guaranteed to
     * be zero at the end.
     *
     * Collisions are extremely unlikely to happen, and an external attacker
     * can't easily control the hash function output, since the salt is
     * unknown, and also there would be to control the pointers.
     *
     * This algorithm is O(1) for each node so it is basically free for
     * us, as we scan the list of nodes, and runs on constant and very
     * small memory. */


## Scaling use cases: JSON filters

I remember the day when the first working implementation of Vector Sets felt complete. Everything worked as expected and it was the starting point to start with the refinements and the extra features.

However in the past weeks and months I internally received the feedback that most use cases need some form of mixed search: you want near vectors to a given query vector (like most similar movies to something) but also with some kind of filtering (only released between 2000 and 2010). My feeling is that you need to query for different parameters less often than product people believe, and that most of the time you can obtain this more efficiently by adding, in this specific case, each year to a different vector set key (this is another instance of the composability of HNSWs expressed as data structures versus a kind of index).

However I was thinking about the main loop of the HNSW greedy search, that is something like this:

// Simplified HNSW greedy search algorithm. Don‚Äôt trust it too much.
while(candidates.len() &gt; 0) {
    c = candidates.pop_nearest(query);
    worst_distance = results.get_worst_dist(query);
    if (distance(query,c) &gt; worst_distance) break;
    foreach (neighbor from c) {
        if (neighbor.already_visited()) continue;
        neighbor.mark_as_visited();
        if (results.has_space() OR neighbor.distance(query) &lt; worst_distance) {
            candidates.add(neighbor);
            results.add(neighbor);
        }
    }
}
return results;

So I started to play with the idea of adding a JSON set of metadata for each node. What if, once I have things like {‚Äúyear‚Äù: 1999}, this was enough to filter while I perform the greedy search? Sure, the search needed to be bound, but there is a key insight here: I want, to start, elements that are *near* to the query vector, so I don‚Äôt really need to explore the whole graph if the condition on the JSON attributes is not satisfied by many nodes. I‚Äôll let the user specify the effort, and anyway very far away results that match the filter are useless.

So that‚Äôs yet another way how my HNSW differs: it supports filtering by expressions similar to the ones you could write inside an ‚Äúif‚Äù statement of a programming language. And your elements in the Vector Set can be associated with JSON blobs, expressing their properties. Then you can do things like:


    VSIM movies VALUES ‚Ä¶ your vector components here‚Ä¶ FILTER '.year &gt;= 1980 and .year &lt; 1990'

## A few words on memory usage

HNSW‚Äôs fatal issue is ‚Äî in theory ‚Äî that they are normally served from memory. Actually, you can implement HNSWs on disk, even if there are better data structures from the point of view of disk access latencies. However, in the specific case of Redis and Vector Sets the idea is to provide something that is very fast, easy to work with: the flexibility of in-memory data structures help with that. So the question boils down to: is the memory usage really so bad?

Loading the 3 million Word2Vec entries into Redis with the default int8 quantization takes 3GB of RAM, 1kb for each entry. Many use cases have just a few tens of million of entries, or a lot less. And what you get back from HNSWs, if well implemented, and in memory, is very good performance, which is crucial in a data structure and in a workload that is in itself slow by definition. In my MacBook I get 48k ops per second with redis-benchmark and VSIM against this key (holding the word2vec dataset). My feeling is that the memory usage of in-memory HNSWs is very acceptable for many use cases. And even in the use cases where you want the bulk of your vectors on disk, even if there is to pay for slower performance, your hot set should likely be served from RAM.

This is one of the reasons why I believe that, to be active in HNSW research is a good idea: I don‚Äôt think they will be replaced anytime soon for most use cases. It seems more likely that we will continue to have different data structures that are ideal for RAM and for disk depending on the use cases and data size. Moreover, what I saw recently, even just scanning the Hacker News front page, is people with a few millions of items fighting with systems that are slower or more complicated than needed. HNSWs and carefully exposing them in the right way can avoid all that.

## Conclusions

I like HNSWs, and working and implementing them was a real pleasure. I believe vectors are a great fit for Redis, even in an AI-less world (for instance, a few months ago I used them in order to fingerprint Hacker News users, replicating an old work published on HN in the past). HNSWs are simply too cool and powerful for a number of use cases, and with AI, and learned embeddings, all this escalates to a myriad of potential use cases. However, like most features in Redis, I expect that a lot of time will pass before people realize they are useful and powerful and how to use them (no, it‚Äôs not just a matter of RAG). This happened also with Streams: finally there is mass adoption, after so many years.

If instead you are more interested in HNSW and the implementation I wrote, I believe the code is quite accessible, and heavily commented:

<a rel="nofollow" href="https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c">https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c</a>

If you want to learn more about Redis Vector Sets, please feel free to read the README file I wrote myself. There is also the official Redis documentation, but I suggest you start from here:

<a rel="nofollow" href="https://github.com/redis/redis/tree/unstable/modules/vector-sets">https://github.com/redis/redis/tree/unstable/modules/vector-sets</a>

Thanks for reading such a long blog post! And have a nice day.</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI adoption in US adds ~900k tons of CO‚ÇÇ annually, study finds (101 pts)]]></title>
            <link>https://techxplore.com/news/2025-11-ai-tons-annually.html</link>
            <guid>45886917</guid>
            <pubDate>Tue, 11 Nov 2025 13:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techxplore.com/news/2025-11-ai-tons-annually.html">https://techxplore.com/news/2025-11-ai-tons-annually.html</a>, See on <a href="https://news.ycombinator.com/item?id=45886917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/ai-adoption-in-the-us.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/ai-adoption-in-the-us.jpg" data-sub-html="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/ai-adoption-in-the-us.jpg" alt="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions" title="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing" width="800" height="450">
             <figcaption>
                AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing
            </figcaption>        </figure>
    </div><p>A <a href="https://iopscience.iop.org/article/10.1088/1748-9326/ae0e3b" target="_blank">new study</a> published in <i>Environmental Research Letters</i> finds that continued growth in artificial intelligence (AI) use across the United States could add approximately 900,000 tons of CO‚ÇÇ annually. This is not a small amount but equates to a relatively minor increase when viewed in the context of nationwide emissions.</p>

                                        
                                              
                                        
                                                                                    <p>While AI adoption is expected to boost productivity and <a href="https://techxplore.com/tags/economic+output/" rel="tag">economic output</a>, researchers note that its environmental footprint can be seen as relatively modest compared to other industrial activities. The study examined potential AI integration across various sectors, estimating the associated rise in <a href="https://techxplore.com/tags/energy+use/" rel="tag">energy use</a> and carbon emissions.</p>
<h2>Key findings include:</h2>
<ul>
<li>AI adoption across the U.S. economy may result in an additional 896,000 tons of CO‚ÇÇ emissions per year, which represents just 0.02% of total U.S. emissions.</li>
<li>Energy use in individual industries could increase by up to 12 petajoules annually, comparable to the electricity consumption of around 300,000 U.S. homes.</li>
</ul>
<p>Co-author Anthony R. Harding explains, "While the projected emissions from AI adoption are modest compared to other sectors, they still represent a meaningful increase. This underscores the importance of integrating energy efficiency and sustainability into AI development and deployment, especially as adoption accelerates across industries."</p>
<p>As AI technologies become more integrated into daily operations, researchers encourage industry leaders to incorporate <a href="https://techxplore.com/tags/energy+efficiency/" rel="tag">energy efficiency</a> and sustainability into their AI strategies to ensure responsible growth as adoption scales.</p>

                                        
                                                                                
                                        											<div>
																								<p><strong>More information:</strong>
												Watts and Bots: The Energy Implications of AI Adoption, <i>Environmental Research Letters</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1088/1748-9326/ae0e3b" target="_blank">DOI: 10.1088/1748-9326/ae0e3b</a>
																								
																								</p>
																							</div>
                                        											
										                                            
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                AI adoption in US adds ~900,000 tons of CO‚ÇÇ annually, study finds (2025, November 11)
                                                retrieved 11 November 2025
                                                from https://techxplore.com/news/2025-11-ai-tons-annually.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Widespread distribution of bacteria containing PETases across global oceans (102 pts)]]></title>
            <link>https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</link>
            <guid>45886479</guid>
            <pubDate>Tue, 11 Nov 2025 12:22:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false">https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</a>, See on <a href="https://news.ycombinator.com/item?id=45886479">Hacker News</a></p>
Couldn't get https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI may not use lyrics without license, German court rules (204 pts)]]></title>
            <link>https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</link>
            <guid>45886131</guid>
            <pubDate>Tue, 11 Nov 2025 11:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/">https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</a>, See on <a href="https://news.ycombinator.com/item?id=45886131">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone Pocket (428 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</link>
            <guid>45885813</guid>
            <pubDate>Tue, 11 Nov 2025 10:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/">https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</a>, See on <a href="https://news.ycombinator.com/item?id=45885813">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        

        <div>
                
                
                
                    <h2>
                        
    
        Introducing iPhone Pocket: a&nbsp;beautiful way to wear and carry iPhone
    

                    </h2>
                
            </div>

        <div>
                
                
                    Born out of a collaboration between ISSEY&nbsp;MIYAKE and Apple, iPhone&nbsp;Pocket features a singular 3D-knitted construction designed to fit any iPhone
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two users pose with iPhone Pocket in lemon and black.">
        <div>
             
              
              <div>
                iPhone Pocket, born out of a collaboration between ISSEY MIYAKE and Apple, will be available at select Apple Store locations beginning Friday, November 14.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero_big" aria-label="Download media, Two users pose with iPhone Pocket in lemon and black."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div>ISSEY MIYAKE and Apple today unveiled <a href="https://www.apple.com/shop/product/HS8R2ZM/A" target="_blank">iPhone Pocket</a>. Inspired by the concept of ‚Äúa piece of cloth,‚Äù its singular 3D-knitted construction is designed to fit any iPhone as well as all pocketable items. Beginning Friday, November 14, it will be available at select Apple Store locations and on <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S.
</div>
                 
             
                 <div>iPhone Pocket features a ribbed open structure with the qualities of the original pleats by ISSEY MIYAKE. Born from the idea of creating an additional pocket, its understated design fully encloses iPhone, expanding to fit more of a user‚Äôs everyday items. When stretched, the open textile subtly reveals its contents and allows users to peek at their iPhone display. iPhone Pocket can be worn in a variety of ways ‚Äî handheld, tied onto bags, or worn directly on the body. Featuring a playful color palette, the short strap design is available in eight colors, and the long strap design in three colors.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-options">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" href="#gallery-500f573744cb93b53ae8377ed0858f3f" data-ac-gallery-trigger="gallery-500f573744cb93b53ae8377ed0858f3f"><span>All eight colors of iPhone Pocket short strap design.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" href="#gallery-c4b99bd83aa685e677f8cc92bd31c905" data-ac-gallery-trigger="gallery-c4b99bd83aa685e677f8cc92bd31c905"><span>All three colors of iPhone Pocket long strap design.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-500f573744cb93b53ae8377ed0858f3f" aria-labelledby="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:short-strap-design">
                                
                                <div>
                                    <div>Featuring a playful color palette, the short strap design is available in eight colors: lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors_big" aria-label="Download media, All eight colors of iPhone Pocket short strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c4b99bd83aa685e677f8cc92bd31c905" aria-labelledby="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:long-strap-design">
                                
                                <div>
                                    <div>The long strap design is available in three colors: sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors_big" aria-label="Download media, All three colors of iPhone Pocket long strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>‚ÄúThe design of iPhone Pocket speaks to the bond between iPhone and its user, while keeping in mind that an Apple product is designed to be universal in aesthetic and versatile in use,‚Äù shared Yoshiyuki Miyamae, design director of MIYAKE DESIGN STUDIO. ‚ÄúiPhone Pocket explores the concept of ‚Äòthe joy of wearing iPhone in your own way.‚Äô The simplicity of its design echoes what we practice at ISSEY MIYAKE ‚Äî the idea of leaving things less defined to allow for possibilities and personal interpretation.‚Äù
</div>
                 
             
                 <div>‚ÄúApple and ISSEY MIYAKE share a design approach that celebrates craftsmanship, simplicity, and delight,‚Äù said Molly Anderson, Apple‚Äôs vice president of Industrial Design. ‚ÄúThis clever extra pocket exemplifies those ideas and is a natural accompaniment to our products. The color palette of iPhone Pocket was intentionally designed to mix and match with all our iPhone models and colors ‚Äî allowing users to create their own personalized combination. Its recognizable silhouette offers a beautiful new way to carry your iPhone, AirPods, and favorite everyday items.‚Äù
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-combos">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" href="#gallery-0413a35321ffe4dbd41592bfeb2b2797" data-ac-gallery-trigger="gallery-0413a35321ffe4dbd41592bfeb2b2797"><span>iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" href="#gallery-395d51cadfd7a3c84bd5bd1de138f580" data-ac-gallery-trigger="gallery-395d51cadfd7a3c84bd5bd1de138f580"><span>iPhone Pocket in sapphire paired with iPhone Air in sky blue.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" href="#gallery-d57c53d12e0866bde9b77fabca8692fb" data-ac-gallery-trigger="gallery-d57c53d12e0866bde9b77fabca8692fb"><span>iPhone Pocket in purple paired with iPhone 17 in lavender.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0413a35321ffe4dbd41592bfeb2b2797" aria-labelledby="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon-and-cosmic-orange-iphone-17-pro">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro_big" aria-label="Download media, iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-395d51cadfd7a3c84bd5bd1de138f580" aria-labelledby="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:sapphire-and-sky-blue-iphone-air">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air_big" aria-label="Download media, iPhone Pocket in sapphire paired with iPhone Air in sky blue."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d57c53d12e0866bde9b77fabca8692fb" aria-labelledby="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple-and-lavender-iphone-17">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01_big" aria-label="Download media, iPhone Pocket in purple paired with iPhone 17 in lavender."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Piece of Cloth</strong>
</h2>
                 
             
                 <div>Crafted in Japan, iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE. The design drew inspiration from the concept of ‚Äúa piece of cloth‚Äù and reinterpreted the everyday utility of the brand‚Äôs iconic pleated clothing. The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="singular-construction">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" href="#gallery-8c54c3d4fde598029a7c6b36d27e85a3" data-ac-gallery-trigger="gallery-8c54c3d4fde598029a7c6b36d27e85a3"><span>A user poses with iPhone Pocket in peacock.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" href="#gallery-8ec946387230a363dbe25e38306bce4d" data-ac-gallery-trigger="gallery-8ec946387230a363dbe25e38306bce4d"><span>A user poses with iPhone Pocket in cinnamon.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" href="#gallery-1b5cfe3976c01fb7746de0602809af8b" data-ac-gallery-trigger="gallery-1b5cfe3976c01fb7746de0602809af8b"><span>iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" href="#gallery-2fe4cea23e1e990c69431e909557f742" data-ac-gallery-trigger="gallery-2fe4cea23e1e990c69431e909557f742"><span>iPhone Pocket in black.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" href="#gallery-8f771a17f3ddef3f19c8c979d8ed6291" data-ac-gallery-trigger="gallery-8f771a17f3ddef3f19c8c979d8ed6291"><span>iPhone Pocket in lemon and mandarin.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" href="#gallery-56d430360d60f74d93b475a57eb36ebd" data-ac-gallery-trigger="gallery-56d430360d60f74d93b475a57eb36ebd"><span>iPhone Pocket in purple.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8c54c3d4fde598029a7c6b36d27e85a3" aria-labelledby="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:peacock">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock_inline" aria-label="Download media, A user poses with iPhone Pocket in peacock."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8ec946387230a363dbe25e38306bce4d" aria-labelledby="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon_inline" aria-label="Download media, A user poses with iPhone Pocket in cinnamon."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1b5cfe3976c01fb7746de0602809af8b" aria-labelledby="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:pink-and-black-issey-miyake-bag">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag_inline" aria-label="Download media, iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-2fe4cea23e1e990c69431e909557f742" aria-labelledby="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:black">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro_inline" aria-label="Download media, iPhone Pocket in black."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8f771a17f3ddef3f19c8c979d8ed6291" aria-labelledby="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lemon-and-mandarin">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air_inline" aria-label="Download media, iPhone Pocket in lemon and mandarin."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-56d430360d60f74d93b475a57eb36ebd" aria-labelledby="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02_inline" aria-label="Download media, iPhone Pocket in purple."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Availability</strong>
</h2>
                 
             
                 <div>iPhone Pocket is a limited-edition release. The short strap design is available in lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black; the long strap design is available in sapphire, cinnamon, and black. iPhone Pocket in the short strap design retails at $149.95 (U.S.), and the long strap design at $229.95 (U.S.).
</div>
                 
             
                 <div>Customers can purchase iPhone Pocket beginning Friday, November 14, at select Apple Store locations and <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. Just in time for the holidays, Apple Specialists in stores and online can help customers mix and match different lengths and colors with their iPhone, style iPhone Pocket, and purchase their new favorite accessory.
</div>
                 
             
                 <div><ul>
<li>Apple Canton Road, Hong Kong</li>
<li>Apple Ginza, Tokyo</li>
<li>Apple Jing‚Äôan, Shanghai</li>
<li>Apple March√© Saint-Germain, Paris</li>
<li>Apple Myeongdong, Seoul</li>
<li>Apple Orchard Road, Singapore</li>
<li>Apple Piazza Liberty, Milan</li>
<li>Apple Regent Street, London</li>
<li>Apple SoHo, New York City</li>
<li>Apple Xinyi A13, Taipei</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why effort scales superlinearly with the perceived quality of creative work (128 pts)]]></title>
            <link>https://markusstrasser.org/creative-work-landscapes.html</link>
            <guid>45885242</guid>
            <pubDate>Tue, 11 Nov 2025 08:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://markusstrasser.org/creative-work-landscapes.html">https://markusstrasser.org/creative-work-landscapes.html</a>, See on <a href="https://news.ycombinator.com/item?id=45885242">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p><!--[--><time datetime="2025-11-02T00:00:00.000Z">November 2, 2025</time><!--]--> <!--[--><span>¬∑ 1 min read</span><!--]--> <!--[--><span>¬∑</span><!--]--> Send your thoughts via <a target="_blank" href="https://twitter.com/mkstra"><!---->twitter</a> or <a target="_blank" href="mailto:strasser.ms@gmail.com"><!---->mail</a>. <!--[!--><!--]--></p> <p><span>Abstract claim:</span> <em>The act of creation is fractal exploration‚Äìexploitation under optimal feedback control.
		When resolution increases the portion of parameter space that doesn't make the artifact
		worse (<em>acceptance volume</em>) collapses. Verification latency and rate‚Äìdistortion
		combine into a precision tax that scales superlinearly with perceived quality.</em></p> <p>When I make something good, I often spend most of my time making thousands of
	high-precision edits on an artifact that I thought should have been finished hours ago.
	Previously, I called this 'last-mile edits', but that was the wrong mental image.</p> <p>"Last mile" implies executing a known plan with diminishing returns but "last mile" at one
	level just becomes "early exploration" at higher resolution at the next level. Instead of
	treating exploration (idea) and exploitation (execution) as temporally separated phases,
	they nest recursively. That nested search is where the effort goes.</p> <p>Once you commit to D minor, this scene, that argument structure you've constrained the
	search space and now you search again within it.</p> <p>Take some of my quicker five-minute, gestural sketches below. You'd think they break this
	nested search dynamic but with a closer look it becomes clear that I just front-loaded my
	taxes by caching motor heuristics.</p> <figure id="figure-1"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/art/sketches-masonry.jpg" alt="Five-minute gestural sketches showing practiced circular strokes and face-like abstractions"></p> <!--[--><figcaption><a href="#figure-1">Figure
				1</a>: <!--[-->A closer look shows the same set of practiced, comfortable gestures that click with my hand shape. They gravitate toward broad, confident circular strokes and shorter straight lines, just short enough to keep them stable. I'm executing cached heuristics, not exploring. I revert to face-like abstractions and focus on having the center hold. I do not like when *The Center Does Not Hold*.<!--]--></figcaption><!--]--></figure><!----> <p>Domains and modalities differ in how wide and forgiving their basins are and how quickly
	you can verify the edit (<em>feedback latency</em>). Music timing has a narrow basin at the
	micro-level (<em>¬±20 ms can kill a groove</em>) but can be more forgiving higher up: key
	and pitch changes can be interchangeable without loss of quality, not often though. Prose
	has a wide basin (many phrasings work). Abstract, contemporary art has extremely wide
	basin, so much so that nobody with any self-respect even bothers anymore. Renaissance
	paintings have more constraints and less distortion tolerance.</p> <table><thead><tr><th>Modality</th><th>Basin</th><th>Verifier</th><th>Speed</th></tr></thead><tbody><tr><td>Text (prose)</td><td>Wide</td><td>Human read</td><td>Minutes</td></tr><tr><td>Code</td><td>Wide (design) / Narrow (syntax)</td><td>Compiler/tests</td><td>ms-seconds</td></tr><tr><td>Music timing</td><td>Narrow</td><td>Ear‚Äìbody</td><td>~20-40ms</td></tr><tr><td>Line drawing</td><td>Narrow</td><td>Eye‚Äìhand</td><td>~100ms</td></tr></tbody></table> <p>Let's take the following optimization landscape and assume it's for the process of writing
	a song. To make it simpler, let's constrain like this: We've written the lyrics and picked
	a BPM of 80.</p> <p>The wider, more forgiving hill corresponds to choosing C major on the macro level, but
	there might be a higher, sharper peak in E minor that's trickier‚Äîi.e., it demands more
	precision edits.</p> <figure id="figure-2"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/essays/creative-work-landscapes/logseq-screenshot.png" alt="3D optimization landscape with Z-axis representing quality"></p> <!--[--><figcaption><a href="#figure-2">Figure
				2</a>: <!--[-->Z-axis is quality (warmer = better). X and Y are arbitrary parameters.<!--]--></figcaption><!--]--></figure><!----> <p>Wide basins let coarse proposals land. This is where almost all generative AI outputs live and the oxygen is still plenty. Near a sharp peak, the <strong>acceptance volume<span><sup>a</sup></span> <!----><!----> shrinks rapidly</strong> and you can‚Äôt reliably see micro-improvements without averaging more evidence or trials. The controller (often the hand) makes many tiny corrections after some latency. Rinse and repeat until the piece sits on a hard-to-vary peak.</p> <p>That's why effort seems like it scales superlinearly as perceived quality rises. Judging
	the intermediate artifact takes more time and most edits (the search) make it worse.
	Geometrically bad edits become more likely and land you lower in the landscape.</p> <p>Craft, then, is the slog of closing ever-less-perceivable gaps.</p> <h2 id="faqs"><a href="#faqs">FAQs</a></h2> <p><strong>Don't bands sometimes record a banger song in an hour together?</strong></p> <p>The tower-climbing happened during practice (*muscle memory*), not recording. Jazz is closer to real-time exploration and mistakes are more accepted and expected.</p> <p><strong>Drawing takes forever because you're exploring AND refining simultaneously.</strong></p> <p>We don't "rehearse" a specific drawing, we solve a novel problem in real-time. There's no cached motor sequence to execute.</p> <div><p><strong>BibTeX Citation</strong></p><pre><code>@misc{strasser2025,
  author = {Strasser, Markus},
  title = {Why Effort Scales Superlinearly with the Perceived Quality of Creative Work},
  year = {2025},
  url = {https://markusstrasser.org/},
  note = {Accessed: 2025-11-11}
}</code></pre></div><!----><!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SoftBank sells its entire stake in Nvidia for $5.83B (299 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</link>
            <guid>45884937</guid>
            <pubDate>Tue, 11 Nov 2025 07:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html">https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</a>, See on <a href="https://news.ycombinator.com/item?id=45884937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108065851" data-test="InlineImage"><p>Nvidia CEO Jensen Huang (L) and the CEO of the SoftBank Group Masayoshi Son pose during an AI event in Tokyo on November 13, 2024.</p><p>Akio Kon | Bloomberg | Getty Images</p></div><div><p><a id="107312506" href="https://www.cnbc.com/quotes/" type="security" brand="cnbc" section="[object Object]" contentclassification="">SoftBank</a> said Tuesday it has sold its entire stake in U.S. chipmaker <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> for $5.83 billion as the Japanese giant looks to capitalize on its <a href="https://www.cnbc.com/2025/06/27/softbank-ceo-says-he-wanted-to-be-openai-early-investor.html">"all in"</a> bet on ChatGPT maker OpenAI. </p><p>The firm said in its earnings statement that it sold 32.1 million Nvidia shares in October. It also disclosed that it sold part of its T-Mobile stake for $9.17 billion.</p><p>"We want to provide a lot of investment opportunities for investors, while we can still maintain financial strength," said SoftBank's Chief Financial Officer Yoshimitsu Goto during an investor presentation. </p><p>"So through those options and tools we make sure that we are ready for funding in a very safe manner," he said in comments translated by the company, adding that the stake sales were part of the firm's strategy for "asset monetization."</p><p>Nvidia shares dipped 0.95% in premarket trade on Tuesday.</p><p>While the Nvidia exit may come as a surprise to some investors, it's not the first time SoftBank has cashed out of the American AI chip darling.</p><p>SoftBank's Vision Fund was an early backer of Nvidia, <a href="https://www.cnbc.com/2017/05/24/the-stock-markets-hottest-stock-nvidia-just-got-a-big-new-backer.html">reportedly amassing</a> a $4 billion stake in 2017 before <a href="https://www.cnbc.com/2019/02/06/softbank-vision-fund-sells-nvidia-stake.html">selling all</a> of its holdings in January 2019. Despite its latest sale, SoftBank's business interests remain heavily intertwined with Nvidia's.</p></div><div id="Placeholder-ArticleBody-Video-108212821" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000392166" aria-labelledby="Placeholder-ArticleBody-Video-108212821"><p><img src="https://image.cnbcfm.com/api/v1/image/108212822-17605971971760597195-42119380833-1080pnbcnews.jpg?v=1760597197&amp;w=750&amp;h=422&amp;vtcrop=y" alt="ABB CEO: Softbank will be good home for robotics business"><span></span><span></span></p></div><div><p>That Tokyo-based company is involved in a number of AI ventures that rely on Nvidia's technology, including the $500 billion Stargate project for data centers in the U.S.</p><p>"This should not be seen, in our view, as a cautious or negative stance on Nvidia, but rather in the context of SoftBank needing at least $30.5bn of capital for investments in the Oct-Dec quarter, including $22.5bn for OpenAI and $6.5bn for Ampere," Rolf Bulk, equity research analyst at New Street Research, told CNBC.</p><p>That amounts to "more in a single quarter than it has invested in aggregate over the two prior years combined," Bulk said.</p><p>Morningstar's Dan Baker added that he doesn't see the move as representing a fundamental shift in strategy for the company.</p><p>"[SoftBank] made a point of saying that it wasn't any view on NVIDIA... At the end of the day, they are using the money to invest in other AI related companies," he said.</p></div><h2><a id="headline0"></a>Vision fund posts blowout $19 billion gain</h2><div><p>The stake sales and a blowout gain of $19 billion from SoftBank's Vision Fund helped the company <a href="https://www.cnbc.com/2025/11/11/softbank-earnings-report-2q.html">double its profit</a> in its fiscal second quarter.</p><p>The Vision Fund has been aggressively pushing into artificial intelligence, investing and acquiring firms throughout the AI value chain from chips to large language models and robotics.</p><p>"The reason we were able to have this result is because of September last year, that was the first time we invested in OpenAI," said SoftBank's Goto. He added that OpenAI's <a href="https://www.cnbc.com/2025/10/02/openai-share-sale-500-billion-valuation.html">latest valuation milestone of $500 billion</a> marks one of the largest valuations in the world, according to fair value.  </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Softbank's shares this year</p></div><div><p>The Japanese conglomerate's stock has slumped in the past week as <a href="https://www.cnbc.com/2025/11/07/ai-valuation-fears-grip-investors-as-tech-bubble-concerns-heighten.html">concerns of an AI bubble</a> sent jitters through global markets. </p><p>"Our share price recently has been going up and down dynamically‚Ä¶ we want to provide as many invest opportunities as possible," said Goto Tuesday, adding that the company's announced four-for-one stock split is part of its strategy to provide as many investment opportunities for shareholders as possible.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI documentation you can talk to, for every repo (149 pts)]]></title>
            <link>https://deepwiki.com/</link>
            <guid>45884169</guid>
            <pubDate>Tue, 11 Nov 2025 04:38:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepwiki.com/">https://deepwiki.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45884169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="138"><a href="https://deepwiki.com/bregman-arie/devops-exercises"><div><div><p><span>bregman-arie</span>/<span>devops-exercises</span></p></div><p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p><div><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><path d="M239.18,97.26A16.38,16.38,0,0,0,224.92,86l-59-4.76L143.14,26.15a16.36,16.36,0,0,0-30.27,0L90.11,81.23,31.08,86a16.46,16.46,0,0,0-9.37,28.86l45,38.83L53,211.75a16.38,16.38,0,0,0,24.5,17.82L128,198.49l50.53,31.08A16.4,16.4,0,0,0,203,211.75l-13.76-58.07,45-38.83A16.43,16.43,0,0,0,239.18,97.26Zm-15.34,5.47-48.7,42a8,8,0,0,0-2.56,7.91l14.88,62.8a.37.37,0,0,1-.17.48c-.18.14-.23.11-.38,0l-54.72-33.65a8,8,0,0,0-8.38,0L69.09,215.94c-.15.09-.19.12-.38,0a.37.37,0,0,1-.17-.48l14.88-62.8a8,8,0,0,0-2.56-7.91l-48.7-42c-.12-.1-.23-.19-.13-.5s.18-.27.33-.29l63.92-5.16A8,8,0,0,0,103,91.86l24.62-59.61c.08-.17.11-.25.35-.25s.27.08.35.25L153,91.86a8,8,0,0,0,6.75,4.92l63.92,5.16c.15,0,.24,0,.33.29S224,102.63,223.84,102.73Z"></path></svg><p><span>74.0k</span></p></div></div></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hiring a developer as a small indie studio in 2025 (119 pts)]]></title>
            <link>https://www.ballardgames.com/tales/hiring-dev-2025/</link>
            <guid>45883995</guid>
            <pubDate>Tue, 11 Nov 2025 04:04:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ballardgames.com/tales/hiring-dev-2025/">https://www.ballardgames.com/tales/hiring-dev-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45883995">Hacker News</a></p>
Couldn't get https://www.ballardgames.com/tales/hiring-dev-2025/: Error: unsuitable certificate purpose]]></description>
        </item>
        <item>
            <title><![CDATA[The 'Toy Story' You Remember (1089 pts)]]></title>
            <link>https://animationobsessive.substack.com/p/the-toy-story-you-remember</link>
            <guid>45883788</guid>
            <pubDate>Tue, 11 Nov 2025 03:17:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animationobsessive.substack.com/p/the-toy-story-you-remember">https://animationobsessive.substack.com/p/the-toy-story-you-remember</a>, See on <a href="https://news.ycombinator.com/item?id=45883788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!oYAZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" width="1456" height="782" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:782,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1780036,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>A still from </span><em>Toy Story</em><span> on 35 mm film</span></figcaption></figure></div><p><strong>Welcome!</strong><span> Glad you could join us for another Sunday edition of the </span><em>Animation Obsessive</em><span> newsletter. This is our slate:</span></p><ul><li><p><strong>1)</strong><span> Digital animation on film stock.</span></p></li><li><p><strong>2)</strong><span> Animation newsbits.</span></p></li></ul><p>With that, let‚Äôs go!</p><p><em>Toy Story</em><span> used to look different. It‚Äôs a little tricky to explain.</span></p><p><span>Back in 1995, CG animation was </span><em>the</em><span> topic in the industry, and Pixar was central to the hype. The studio had already </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">shifted Disney to computers</a><span> and won the first Oscar for a CG short (</span><em><a href="https://www.youtube.com/watch?v=DWi2WTqD59A" rel="">Tin Toy</a></em><span>). Giant movies like </span><em>Jurassic Park</em><span> incorporated Pixar‚Äôs software.</span></p><p><span>The next step was </span><em>Toy Story</em><span>, billed as the first animated feature to go all-CG.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-1-178330349" target="_self" rel="">1</a></span><span> Even after Pixar‚Äôs successes, that was a risk. Would a fully digital movie sell tickets? </span></p><p><span>It clearly worked out. </span><em>Toy Story</em><span> appeared 30 years ago this month ‚Äî and its popularity created the animation world that exists now. A new process took over the business.</span></p><p><span>But not </span><em>entirely</em><span> new ‚Äî not at first. There was something old about </span><em>Toy Story</em><span>‚Äôs tech, too, back in 1995. Pixar made the thing with computers, but it still needed to screen in theaters. And computers couldn‚Äôt really </span><em>do</em><span> that yet. From its early years, Pixar had relied on physical film stock. According to authors Bill Kinder and Bobbie O‚ÄôSteen:</span></p><blockquote><p><span>[Pixar‚Äôs Ed]</span><em> Catmull recognized that his studio‚Äôs pixels needed to merge with that world-standard distribution freeway, 35 mm film. Computer chips were not fast enough, nor disks large enough, nor compression sophisticated enough to display even 30 minutes of standard-definition motion pictures. It was axiomatic that for a filmgoing audience to be going to a film, it would be a... film.</em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-2-178330349" target="_self" rel="">2</a></span></p></blockquote><p><em>Toy Story</em><span> was a transitional project. Since Pixar couldn‚Äôt send digital data to theaters, every one of the movie‚Äôs frames was printed on analog film. When </span><em>Toy Story</em><span> originally hit home video, that 35 mm version was its source. Only years later, after technology advanced, did Pixar start doing digital transfers ‚Äî cutting out the middleman. And </span><em>Toy Story</em><span>‚Äôs look changed with the era.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-3-178330349" target="_self" rel="">3</a></span><span> </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rk4n!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" width="1456" height="1688" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1688,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4835256,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span>‚Äôs original release on 35 mm (top), and the version currently streaming on Disney+ (bottom). See the film‚Äôs trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=LoBFN_V66P0" rel="">here</a><span>.</span></figcaption></figure></div><p><span>While making </span><em>Toy Story</em><span>, Pixar‚Äôs team knew that the grain, softness, colors and contrasts of analog film weren‚Äôt visible on its monitors. They were different mediums. </span></p><p><span>So, to get the right look, the studio had to keep that final, physical output in mind. The digital colors were tailored with an awareness that they would change after printing. ‚ÄúGreens go dark really fast, while the reds stay pretty true,‚Äù said </span><em>Toy Story</em><span>‚Äôs art director, Ralph Eggleston. ‚ÄúBlues have to be less saturated to look fully saturated on film, while the oranges look really bad on computer screens, but look really great on film.‚Äù</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-4-178330349" target="_self" rel="">4</a></span></p><p>The team checked its work along the way. In the words of Pixar‚Äôs William Reeves:</p><blockquote><p><em>During production, we‚Äôre working mostly from computer monitors. We‚Äôre rarely seeing the images on film. So, we have five or six extremely high-resolution monitors that have better color and picture quality. We put those in general work areas, so people can go and see how their work looks. Then, when we record, we try to calibrate to the film stock, so the image we have on the monitor looks the same as what we‚Äôll get on film.</em></p></blockquote><p><span>Behind the final images was a ‚Äúpainstaking transfer process,‚Äù according to the press. Leading it was David DiFrancesco, one of Pixar‚Äôs early MVPs, who began working with Ed Catmull before Pixar even existed. He broke ground in film printing ‚Äî specifically, in putting digital images on analog film.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-5-178330349" target="_self" rel="">5</a></span></p><p><span>He and his team in Pixar‚Äôs photoscience department used their expertise here. Their tools were ‚Äúcommercial grade‚Äù film printers, DiFrancesco noted: modified Solitaire Cine II machines. He‚Äôd invented more advanced stuff, but it wasn‚Äôt viable for a project of </span><em>Toy Story</em><span>‚Äôs size. Using the best equipment would‚Äôve taken ‚Äúseveral terabytes of data,‚Äù he said.</span></p><p><span>Their system was fairly straightforward. Every frame of </span><em>Toy Story</em><span>‚Äôs negative was exposed, three times, in front of a CRT screen that displayed the movie. ‚ÄúSince all film and video images are composed of combinations of red, green and blue light, the frame is separated into its discrete red, green and blue elements,‚Äù noted the studio. Exposures, filtered through each color, were layered to create each frame.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-6-178330349" target="_self" rel="">6</a></span><span> </span></p><p><span>It reportedly took nine hours to print 30 seconds of </span><em>Toy Story</em><span>. But it had to be done: it was the only way to screen the film.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5nPg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" width="1456" height="882" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:882,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2072015,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Examples of green, blue and red exposures, and the final scene on 35 mm film. Courtesy of the </span><em>Ultimate Toy Box</em><span> DVD.</span></figcaption></figure></div><p>In 1999, Pixar made history again.</p><p><span>Its second feature, </span><em>A Bug‚Äôs Life</em><span>, reached theaters in 1998. Once more, the studio designed its visuals for analog film (</span><a href="https://www.youtube.com/watch?v=izmlSjjOEdo" rel="">see the trailer on 35 mm</a><span>). Its people knew the ins-and-outs of this process, down to the amount of detail that film stock could accept and a projector could show. That‚Äôs partly how they got away with the movie‚Äôs tiny 2048√ó862 resolution, for example.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-7-178330349" target="_self" rel="">7</a></span></p><p><span>Still, the team struggled with one thing: the dip in image quality when film got converted to home video. That‚Äôs how </span><em>Toy Story</em><span> was released, but there </span><em>had</em><span> to be a better way.</span></p><p><span>For the home version of</span><em> A Bug‚Äôs Life</em><span>, Pixar devised a method of ‚Äúgo[ing] from our digital image within our system ‚Ä¶ straight to video,‚Äù John Lasseter said. He called it ‚Äúa real pure version of our movie straight from our computers.‚Äù </span><em>A Bug‚Äôs Life</em><span> became the first digital-to-digital transfer on DVD. Compared to the theatrical release, the look had changed. It was sharp and grainless, and the colors were kind of different.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-8-178330349" target="_self" rel="">8</a></span></p><p><span>A digital transfer of </span><em>Toy Story</em><span> followed in the early 2000s. And it wasn‚Äôt </span><em>quite</em><span> the same movie that viewers had seen in the ‚Äò90s. ‚ÄúThe colors are vivid and lifelike, [and] not a hint of grain or artifacts can be found,‚Äù raved one reviewer. It was a crisp, blazingly bright, digital image now ‚Äî totally different from the softness, texture and deep, muted warmth of physical film, on which </span><em>Toy Story </em><span>was created to be seen.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!P-J7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" width="1456" height="1676" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1676,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3528708,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span> on 35 mm (top) and the Disney+ edition (bottom)</span></figcaption></figure></div><p><span>Quickly, digital transfers became a standard thing. Among others by Pixar, </span><em>The Incredibles</em><span> puts off a very different vibe between its theatrical and later releases (see </span><a href="https://www.youtube.com/watch?v=M_nSbqsLmEk" rel="">the 35 mm trailer</a><span> for reference). </span></p><p>Pixar wasn‚Äôt the only studio to make the leap, either. Disney did as well. </p><p><span>Like </span><em>Toy Story</em><span>, the Disney renaissance work of the ‚Äò90s was transitional. </span><em>The Lion King</em><span>, </span><em>Mulan</em><span> and the rest existed as </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">files in computer systems</a><span> ‚Äî and the idea was always to record them on analog film at the end. Early home releases were based on those 35 mm versions. Later releases, like the ones Disney streams today, were direct transfers of the digital data. </span></p><p><span>At times, especially in the colors, they‚Äôre almost unrecognizable. And the images feel less cohesive ‚Äî like something‚Äôs missing that was </span><em>supposed</em><span> to bring all the elements together. These aren‚Äôt quite the same films that ruled the ‚Äò90s.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6IkD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" width="1456" height="1633" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1633,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4330548,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Aladdin</em><span> on 35 mm film (top) versus Blu-ray (bottom). See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=AuhNnovKXLA" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qdDU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" width="1456" height="1662" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1662,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4506414,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>The Lion King</em><span> on 35 mm film (top) versus Blu-ray. See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=uivXq3tXOhg" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!T9lv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" width="1456" height="1702" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1702,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3824553,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Mulan</em><span> on 35 mm film (top) versus Blu-ray. See the film‚Äôs trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=2z2KsFZs-8I" rel="">here</a><span>.</span></figcaption></figure></div><p><span>For a number of years, there‚Äôs been talk in film-preservation circles about </span><em>Toy Story</em><span> and the Disney renaissance. This work sits in an odd place. The world was still pretty analog when the computer animation boom arrived: out of necessity, these projects became hybrids of new and old. What‚Äôs the</span><em> right </em><span>way to see digital movies that were designed for 35 mm film?</span></p><p><span>The studios themselves haven‚Äôt quite figured it out. On Disney+, the colors of </span><em>Toy Story</em><span> feel a bit raw ‚Äî searing greens that were meant to darken on film, for example. Meanwhile, the newer </span><em>Toy Story</em><span> Blu-ray shares more in common with the original colors, but it‚Äôs still an altered, colder look.</span></p><p><span>When digital transfers first showed up, people were thrilled, including at Pixar. Movies became ‚Äúcrisper, clearer and more stunning on home video systems‚Äù than in theaters, some claimed.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-9-178330349" target="_self" rel="">9</a></span><span> Even so, it‚Äôs a little disquieting to think that </span><em>Toy Story</em><span>, the film that built our current world, is barely available in the form that wowed audiences of the ‚Äò90s. The same goes for many other movies from the transitional era.</span></p><p><span>The good news is that this conversation gets bigger all the time. In those film-preservation circles, a dedicated few are trying to save the old work. More and more </span><a href="https://www.youtube.com/watch?v=BMvgu_KdpjA" rel="">comparison videos</a><span> are popping up on YouTube. If you get the chance to see one of the old Disney or Pixar films on 35 mm, it‚Äôs always worthwhile.</span></p><p><span>These companies, ultimately, decide how </span><em>Toy Story</em><span> looks today. Still, for some, it‚Äôs nice to see the original version of the film again ‚Äî the version Pixar originally intended to make. It‚Äôs evidence that the film </span><em>did</em><span> feel</span><em> </em><span>different back then. The memories were real.</span></p><ul><li><p><em>I Am Frankelda</em><span> continues its strong performance in </span><strong>Mexican</strong><span> theaters. Analyst Edgar Apanco </span><a href="https://x.com/elapanco/status/1987639735091921274" rel="">reports</a><span> that 658,000 people have gone to see it, surpassing the popular </span><em>Chainsaw Man</em><span> movie. Revenues are </span><a href="https://x.com/elapanco/status/1987660916633325574" rel="">over $2.15 million</a><span> and climbing ‚Äî having fallen </span><a href="https://palomaynacho.com/blog/chainsaw-y-frankelda-se-enfrentan-en-un-halloween-complicado/" rel="">just 17%</a><span> in week two, and an estimated 20% in week three.</span></p></li><li><p><span>In </span><strong>Japan</strong><span>, Goro Miyazaki </span><a href="https://ghibli.jpn.org/news/goro-talk-4/" rel="">revealed</a><span> that his father is still going to Studio Ghibli to draw for a few hours each day.</span></p></li><li><p><span>An exhibition in </span><strong>Taiwan</strong><span> </span><a href="https://reading.udn.com/read/story/124410/9126552" rel="">brought</a><span> the films of Karel Zeman to the country, reportedly for the first time. </span><em>The Fabulous Baron Munchausen</em><span> and </span><em>Invention for Destruction</em><span> are showing, among others.</span></p></li><li><p><span>In </span><strong>Nigeria</strong><span>, animator Gabriel Ugbodaga had </span><a href="https://www.arise.tv/gabriel-ugbodaga-nigeria-has-enough-animation-talent-what-we-lack-is-training-and-exposure/" rel="">a televised interview</a><span> about his well-received film </span><em>Vainglorious</em><span> (</span><a href="https://www.youtube.com/watch?v=6tVVWgz1cEk" rel="">watch</a><span>) and the state of the country‚Äôs industry. ‚ÄúWhen it comes to 2D hand-drawn animation,‚Äù he said, ‚Äúthere‚Äôs a lot of talent in Nigeria.‚Äù</span></p></li><li><p><span>If you missed that </span><em>Baahubali: The Eternal War</em><span> teaser this week, </span><a href="https://www.youtube.com/watch?v=RdUPs9e1bUk" rel="">see it here</a><span>. It‚Äôs an </span><strong>Indian</strong><span> feature presented by S. S. Rajamouli (</span><em>RRR</em><span>).</span></p></li><li><p><span>In </span><strong>Germany</strong><span>, Werner Herzog‚Äôs animated film </span><em>The Twilight World</em><span> </span><a href="https://cineuropa.org/en/newsdetail/485526" rel="">picked up</a><span> ‚Äú‚Ç¨100,000 for production preparation support,‚Äù reports </span><em>Cineuropa</em><span>.</span></p></li><li><p><em>Infinity Castle</em><span> will reach </span><strong>China</strong><span> next weekend, and forecasters </span><a href="https://cn.investing.com/news/stock-market-news/article-3066545" rel="">believe</a><span> it could earn a billion yuan (over $140 million) and become the highest-grossing anime film in the country.</span></p></li><li><p><span>Also </span><a href="https://weibo.com/7985578740/Qcrf6p4D6" rel="">happening</a><span> in </span><strong>China</strong><span> next weekend: the latest edition of Feinaki Beijing Animation Week. The festival posted </span><a href="https://www.bilibili.com/video/BV1rMyzBxE9w/" rel="">55 trailers</a><span> for its selections this year.</span></p></li><li><p><span>The </span><strong>Japanese</strong><span> journalist Atsushi Matsumoto is raising concerns that the anime boom of the 2020s </span><a href="https://news.yahoo.co.jp/expert/articles/55f696fd42ce9a821f4bf682327f452bf3b7245c" rel="">could be a bubble</a><span>. (Meanwhile, despite huge industry profits, analysis suggests that studio closures are </span><a href="https://prtimes.jp/main/html/rd/p/000001179.000043465.html" rel="">set to rise</a><span> for the third year in a row.)</span></p></li><li><p><span>In</span><strong> America</strong><span>, for those in New York, there‚Äôs an interesting series of stop-motion screenings </span><a href="https://www.eastman.org/stop-motion-artform" rel="">at the Eastman Museum</a><span> this month ‚Äî including </span><em>The Wolf House</em><span>.</span></p></li><li><p><span>Last of all: we wrote about a handful of </span><a href="https://animationobsessive.substack.com/p/free-films-worth-seeing" rel="">recent, free films worth seeing</a><span>. </span></p></li></ul><p><em><strong>Until next time!</strong></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I hate screenshots of text (322 pts)]]></title>
            <link>https://parkscomputing.com/page/i-hate-screenshots-of-text</link>
            <guid>45883124</guid>
            <pubDate>Tue, 11 Nov 2025 01:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parkscomputing.com/page/i-hate-screenshots-of-text">https://parkscomputing.com/page/i-hate-screenshots-of-text</a>, See on <a href="https://news.ycombinator.com/item?id=45883124">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        




<article>
    
    <div>
        
<p>During the course of a regular working day, I receive a lot of screenshots like this from well-meaning colleagues:</p>
<p> <img src="https://parkscomputing.com/images/screenshots.png" alt="A screenshot of some text">
</p><p>It's almost always in a chat about some issue that occurred in the code, or perhaps code that's somehow related to the code in the screenshot, or‚Ä¶ well, how am I supposed to even know? Upon seeing this code, I might think, ‚ÄúHow is <code>slug</code> defined? Is <code>slug</code> being used to create the <code>baseUrl</code>? Why is the domain name hard-coded in that URL? What happens if an exception is thrown? <em>What module is this code even in?</em>‚Äù</p>
<p>I have to either very carefully type some of the code into a search box or (these days) get my coding agent to find the relevant module for me.</p>
<p>Why couldn't my colleague have just used copy &amp; paste? I could have seen a bit more of the context, even if the same lines were selected, and I could copy-and-paste <em>that</em> text into my IDE's search function so much more easily.</p>
<p>In fact, why couldn't they just send me the file, or even a link to the file (since everybody and their dog use GitHub, anyway).</p>
<p>It gets worse. Sometimes, I'll get a screenshot of an error log. ‚ÄúHey, Paul, the build is failing. Can you look at this?‚Äù</p>
<p> <img src="https://parkscomputing.com/images/screenshots-errors2.png" alt="A screenshot of some build errors">
</p><p>What were you building? What line did it fail on? <em>What even was the error?</em></p>
<p>Of course, if I do a full rebuild of everything on my workstation, it'll succeed.</p>
<p>It would have been SO easy to just copy all of the error log, or even dump the log into a file, and just send me that.</p>
<p> <img src="https://parkscomputing.com/images/banging-head-against-wall-cracked.gif" alt="Me reading a screenshot of some build errors">
</p><p>Please, don't take screenshots of text unless it's to demonstrate a cosmetic issue related to the display of the text, or there is truly something relevant about the content of the screenshot that would be lost in a purely textual context.</p>

    </div>
</article>



    

        </div></div>]]></description>
        </item>
    </channel>
</rss>