<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 06 Feb 2024 19:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA["Fake Chinese Income" Mortgages Fuel Toronto Real Estate Bubble: HSBC Bank Leaks (143 pts)]]></title>
            <link>https://www.thebureau.news/p/fake-chinese-income-mortgages-fuel</link>
            <guid>39277767</guid>
            <pubDate>Tue, 06 Feb 2024 17:52:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebureau.news/p/fake-chinese-income-mortgages-fuel">https://www.thebureau.news/p/fake-chinese-income-mortgages-fuel</a>, See on <a href="https://news.ycombinator.com/item?id=39277767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png" width="1456" height="1198" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1198,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4823278,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4443b67-56db-421c-a762-7803b6868b4e_2178x1792.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>PHOTO ILLUSTRATION: THE BUREAU INVESTIGATES TORONTO METHOD MORTGAGE LEAKS.</figcaption></figure></div><p>The whistleblower, a Canadian business school graduate, was staggered by the suspicious home loans he discovered in 2022 when he joined a mortgage approval team in a small HSBC branch on the outskirts of Toronto.&nbsp;</p><p>He knew of suspicions surrounding Chinese capital in British Columbia real estate, but had never witnessed shady lending while working at an HSBC branch in Campbell River, a bucolic town on the coast of Vancouver Island.</p><p>When he arrived at HSBC’s bank in Aurora, an affluent suburb north of Toronto, he discovered explosive growth in home loans to Chinese diaspora buyers during the Covid-19 pandemic.</p><p>Chinese migrants living across Toronto were obtaining mortgages from HSBC while supposedly earning extravagant salaries from remote-work jobs in China. In one example, an Ontario casino worker that owned three homes also claimed to earn $345,000 in 2020 analyzing data remotely for a Beijing company.&nbsp;</p><p>Before joining HSBC Canada, the whistleblower had studied fake-income mortgage frauds for his Business Masters degree at Vancouver Island University. After arriving at Aurora in February 2022, while digging into the branch’s loan books and interrogating his colleagues, he made mind-blowing assessments.</p><p>Since 2015, the whistleblower concluded, more than 10 Toronto-area HSBC branches had issued at least $500-million in home loans to diaspora buyers claiming exaggerated incomes or non-existent jobs in China.&nbsp;</p><p>These foreign-income scams spiked during the pandemic, the whistleblower believed, because borrowers could somewhat plausibly claim to be working remotely in other countries while riding out Covid-19 in Canada.</p><p>While a small bank of Aurora’s size was expected to issue about $23-million in residential loans every year, this branch had shovelled out $88-million in mortgages in 2020, according to the whistleblower, and over $50-million in 2021.</p><p><span>The whistleblower, whom</span><em>The Bureau</em><span> is calling D.M., immigrated to Canada as an international student from India, making him a minority among mostly Chinese-Canadian co-workers at the Aurora branch.&nbsp;</span></p><p><span>As D.M. probed his colleagues, his belief gained conviction, that HSBC Canada and other Canadian banks including </span><a href="https://betterdwelling.com/cibc-kills-foreign-income-program-makes-buying-canadian-real-estate-harder/" rel="">CIBC</a><span> had systemic problems with highly questionable mortgages issued to diaspora buyers with unverified sources of wealth in China.</span></p><p>Losing sleep, in April 2022, D.M. sent an audacious email to senior bank executives: “I am going to reveal potential mortgage fraud at HSBC Bank Canada and possibly some employees benefited from the fraud, financially pocketing thousands of dollars, which I call the proceeds of crime.”</p><p><span>D.M.’s explosive four-page complaint triggered an internal investigation that led to some reforms at HSBC Canada according to internal emails obtained by </span><em>The Bureau.</em></p><p>But more than a year later, D.M. was so dissatisfied with the bank’s response that he risked sharing his story and numerous internal documents for an unprecedented journalistic investigation into Canada’s housing affordability crisis.</p><blockquote><p><span>“I found out a huge mortgage fraud showing borrowers with exaggerated income from one specific country, China, pretending to be working remotely,” D.M. informed </span><em>The Bureau</em><span> in June 2023. “I believe the housing prices in Toronto are linked to this, because this is about income verification in banks, which is supposed to moderate demand.”</span></p></blockquote><p><em>The Bureau</em><span> asked HSBC Canada to review emailed information for this story and provide an appropriate manager for an interview regarding D.M. 's records and allegations.</span></p><p>“I won’t have anyone to speak with you directly,” Sharon Wilks, Head of Communications, responded. “But for context: As a global bank, HSBC is at the forefront of efforts to identify, prevent and deter financial crime … We will not do business with individuals or entities we believe are engaged in illicit conduct.”</p><p>Wilks added that HSBC Canada “can and do regularly exit relationships with clients whose activities we deem too risky.”</p><p><em>The Bureau’s</em><span> seven-month investigation into D.M.’s allegations suggests HSBC Canada and other Canadian banks could have issued many billions of dollars in questionable mortgages to Chinese diaspora buyers, and a significant cause of Canada’s real estate bubble is hundreds of billions in illicit fund transfers from China into Canada, and bank lending that amplifies its impacts, especially in Toronto and Vancouver home prices.</span></p><p>“There are thousands of these cases, large scale,” D.M. said in an interview. “Hardworking Canadians are denied mortgages and these Chinese residents forge documents and get mortgages approved, heating up the already hot Ontario real estate markets.”</p><p>“These people don’t have steady jobs or income in Canada,” he alleged, “but what they are doing is scams to launder money, and get mortgages using fake documents.”</p><p><em>The Bureau’s </em><span>investigation included asking seven prominent Canadian experts to assess some of D.M.’s documents, allegations and conclusions.</span></p><p>This investigation suggests D.M. 's calculation is plausible, that the Aurora branch and other Toronto-area HSBC branches have issued at least $500-million in questionable Chinese income loans since 2015.</p><p>But D.M’s findings could also change the public’s understanding of housing affordability in Toronto and Vancouver, a politically explosive issue expected to frame Canada’s upcoming federal election.&nbsp;&nbsp;</p><p><span>This is because, according to the academics and criminologists that reviewed D.M.’s documents with</span><em> The Bureau, </em><span>his evidence fits into FINTRAC’s much broader examinations of suspicious real estate and banking transactions.</span></p><p>In 2023, the anti-money laundering watchdog published a ground-breaking study into 48,000 Chinese diaspora banking transactions.</p><p>FINTRAC found that during the Covid-19 pandemic, because Canadian casinos were closed, Chinese underground banking schemes evolved, flooding electronic fund transfers from Hong Kong into Canadian bank accounts that served like corridors for murky real estate transactions.&nbsp;</p><p><em>The Bureau’</em><span>s analysis also finds that what D.M. discovered in Toronto banks, finally sheds light on mysterious capital flows discovered by a prominent Canadian academic in 2015, in a study of Vancouver land titles and mortgages. </span></p><p>That examination of $525-million worth of real estate purchases in a six-month period found 66 percent of buyers in several affluent neighbourhoods were recent Chinese diaspora migrants, and most mortgages went to buyers with little or no income in Canada.</p><p><span>Similarly, what D.M. found in his probe of pandemic-era loans could be called the evolving “Toronto Method” of an underground banking system discovered first in Vancouver, and </span><a href="https://cullencommission.ca/files/reports/CullenCommission-FinalReport-Full.pdf" rel="">found to be</a><span> laundering a stunning $1.2-billion in cash from Mainland China through British Columbia government casinos in 2014.</span></p><p><span>This system of shadowy transfers was dubbed the </span><a href="https://globalnews.ca/news/4658157/fentanyl-vancouver-real-estate-billion-money-laundering-police-study/" rel="">“Vancouver Model”</a><span> by an Australian professor, and brings together transnational organized crime, affluent Chinese nationals seeking to export their wealth abroad, and Canadian casinos, banks and real estate, in transactions that evade policing because the pivotal cash exchanges are done off the books by professional money launderers serving the global Chinese diaspora.</span></p><p>According to FINTRAC’s 2023 study of 48,000 pandemic-era transactions, this evolving Vancouver Model network&nbsp;“simultaneously facilitates money laundering and the circumvention of Chinese currency controls”</p><p>“As a result of the temporary closures of Canadian casinos due to the COVID-19 pandemic, professional money launderers began to diversify their money laundering methods,” FINTRAC’s study says. </p><p>“During this time, FINTRAC observed a rise in money laundering typologies involving transferring large sums of funds to Canada from foreign money services businesses, often located in China, notably Hong Kong, and the laundering of the funds primarily through the real estate, securities, automotive and legal professions.”</p><p>These wire transfers from China were routed into bank accounts of “multiple, unrelated individuals in Canada,” that served as “money mules” in byzantine networks involving Canada-based real estate developers, real estate agents, mortgage brokers and banks.</p><p>These Chinese diaspora bank account owners often claimed they were students, homemakers, office managers, or unemployed, FINTRAC reported.</p><p>They sometimes used their accounts to send bank drafts to others in Canada for home purchases, or served as “straw buyers” for offshore investors.</p><p>“Mortgage payments are sourced from incoming funds from China,” FINTRAC’s alert said.</p><div><figure><a target="_blank" href="https://fintrac-canafe.canada.ca/intel/operation/ml-rec-eng" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png" width="1456" height="940" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:940,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1047399,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://fintrac-canafe.canada.ca/intel/operation/ml-rec-eng&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3c1365-9abb-4827-82d7-bb89048db9f4_2276x1470.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>FINTRAC’s 2023 Project Athena alert on Chinese money laundering schemes using Canadian banks and real estate.</figcaption></figure></div><p>FINTRAC’s study doesn’t say that Canadian banks knowingly issued fake-income mortgages to Chinese diaspora buyers in Toronto.&nbsp;</p><p>But in an interview, D.M. said banking staff are trained to guard against fraud, and the loan application packages he reviewed in Aurora beggared belief.</p><p>“The bank found out that one lady works in a casino part-time but got a $1.4 million mortgage showing over $300,000 annual income,” he said. “Plus she takes money as benefits from the government, for her two kids.”</p><p>In other examples, an HSBC mortgage client claimed to earn $700,000 annually for remote work in China, while simultaneously living in Canada and paying off a $10,000 student loan.&nbsp;</p><p>Another woman who owned homes in Aurora, Markham and Scarborough, worked part-time as a hairdresser while also claiming to earn $536,280 at a “Business Manager” job in Guangzhou.&nbsp;</p><p>“Canadian workers have been put out of the real estate market by people working as a hairdresser that own a couple homes,” D.M. said in an interview. </p><p>“How is that fair?”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png" width="1456" height="773" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:773,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4345438,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7e29cf-ae2d-4037-a9bf-4be7956bcef3_2298x1220.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The most shocking case reviewed by </span><em>The Bureau</em><span>, shows that one woman that owns at least four Toronto properties opened her HSBC Aurora bank account in 2012, claiming to be a “Homemaker with no annual income.”&nbsp;</span></p><p>But her Toronto account soon received incredible amounts of wire transfers from HSBC China accounts, and paid out “high value cheques” to third parties for real estate purchases. </p><p>This case suggests “Toronto Method” shadow banking described in FINTRAC’s 2023 study has been seeping into Toronto real estate for about a decade.</p><p>And yet in 2020, this same woman applied for another HSBC Canada mortgage, claiming to earn $763,000 remotely from her job in China.</p><p>This evidence from the HSBC whistleblower complements the seminal investigations of Simon Fraser University academic Andy Yan, who examined sales from August 2014 to February 2015 in several communities on Vancouver’s westside. The average home price in Yan’s study was $3-million.</p><p><span>Looking back at his Vancouver findings in comparison to D.M.’s Toronto banking documents, Yan told </span><em>The Bureau</em><span> “I think this helps affirm some of my early work that I did, almost nine years ago.”</span></p><blockquote><p>“This goes to the core of our banking system,” he said, “and how are we verifying identities and how are we verifying incomes.”</p></blockquote><p>In Yan’s controversial study the vast majority of mortgages went to buyers listing their occupation as home-maker, followed by students, and managers. HSBC and CIBC were the dominant lenders. </p><p>Unlike the HSBC whistleblower, Yan had no access to internal banking data regarding the purported origin of funds behind these mortgages taken by Chinese diaspora buyers.&nbsp;</p><p><span>But in an interview, Yan said what he found most interesting back in 2015, was suspicions that Chinese migrants were often buying homes with </span><a href="https://www.ice.gov/partnerships-centers/bcsc/faq" rel="">bulk cash, </a><span>weren’t accurate. The truth was more </span><a href="https://globalnews.ca/news/4658158/fentanyl-kingpins-canada-big-circle-boys/" rel="">complex</a><span> and seems to be clarified by D.M.’s mortgage findings in Toronto.</span></p><p>“It's about that global flow of capital, and how it's multiplied by Canada’s mortgage and lending system,” Yan said. “Because you have to remember, one of the biggest conclusions about my study was that it wasn't bags of cash that were being used to purchase Vancouver homes outright. They were loans being used. So now, I’m thinking, this is where my study connects up to what you have discovered in Toronto.”</p><p>“The interesting story here,” Yan added,&nbsp;“is what happens in Toronto real estate may not repeat Vancouver, but it perhaps rhymes.”</p><p>Probably the most famous Chinese property owner from Yan’s 2015 study areas is Huawei executive Meng Wanzhou. In 2009 her family bought a home in Vancouver’s Dunbar neighborhood for $2.73 million, land titles show. In 1998, ten years before Vancouver Model transactions started to surge in Vancouver real estate, the home was sold for $370,000. The home is now valued at almost $6-million.</p><p><a href="https://summit.sfu.ca/item/37923" rel="">Ashleigh Gonzales</a><span>, a former RCMP data scientist who recently published a criminology thesis finding Chinese diaspora underground banking causes significantly more money laundering into Canada’s real estate than previously estimated, said that D.M.’s findings resemble her own Vancouver Model research.</span></p><p>“This whistleblower’s allegations of widespread mortgage fraud at HSBC Canada align with some of the first-hand accounts from staff of some Canadian financial institutions that I have come across in my research on money laundering in British Columbia,” Gonzales said. </p><p>Gonzales, who worked for RCMP’s anti-gang unit in British Columbia until 2023, says she found reports of mortgage fraud accelerated “during the uptick in the Canadian housing bubble after the Vancouver 2010 Olympics,” and continued to surge from 2015 to 2018.</p><p><span>With all this considered, and comparing data sources in this story with previous evidence confirmed in British Columbia’s </span><a href="https://cullencommission.ca/files/reports/CullenCommission-FinalReport-Full.pdf" rel="">Cullen Commission, </a><em>The Bureau </em><span>estimates that from 2014 to 2023, well over $200-Billion in Vancouver Model and Toronto Method funds could have poured through underground diaspora networks and Canadian financial institutions into Toronto and </span><a href="https://globalnews.ca/news/4658157/fentanyl-vancouver-real-estate-billion-money-laundering-police-study/" rel="">Vancouver’s real estate.</a></p><p><span>A federal official not authorized to comment publicly also examined D.M.’s banking leaks for </span><em>The Bureau,</em><span> and called this information “explosive.” </span></p><p>The official said money laundering is increasing in Canada, and D.M.’s belief that Chinese-income mortgage fraud has boosted home prices in Toronto is likely true, but also should apply for Vancouver and Montreal real estate prices. The official noted that other nations require tax agencies to verify incomes for mortgages, which isn’t the case in Canada.</p><p>“It matters for our next generation because of the impact on the housing market,” the official said.&nbsp;</p><p><span>Queen’s University professor Christian Leuprecht – editor of</span><em> Dirty Money</em><span>, a new academic text that probes how Ottawa’s weak regulation has “turned the Canadian federation into a destination of choice for global financial crime” – also reviewed some of D.M. 's leaks.</span></p><p>“It’s not a new problem, but you’re taking it to the next level,” Leuprecht said. </p><blockquote><p>“Why does this matter?&nbsp; Because organized crime isn’t just laundering their ill-gotten gains, like any good business person, when they buy real estate, they generate a down payment, then get a mortgage for the rest.&nbsp; Why buy one property when you can buy four?”</p></blockquote><p><em>The Bureau’s</em><span> review of HSBC Canada emails and D.M.’s text messages, shows he came to believe numerous employees at the Aurora branch had direct knowledge of faked Chinese income mortgages, and a veteran manager with oversight of more than 10 Greater Toronto branches knew about broad and questionable mortgage lending for Chinese diaspora clients.</span></p><p>Months after D.M. blew the whistle internally he exchanged texts with another employee, identifying colleagues that they believed had knowledge of diaspora mortgage scams. </p><p>The texts suggest D.M. believed HSBC Canada and other Canadian banks continued to hold vast amounts of suspicious foreign income mortgages, which could cause systemic loan quality risks if Toronto’s real estate prices decline.</p><p>“Do you know how many mortgage frauds we have in our books,” D.M. texted to his colleague. “It’s insane.”&nbsp;</p><p>“She told me,” the colleague replied, referring to an HSBC branch manager. </p><p>“She was like, if you do come, you gotta be prepared for the mortgage payout.”</p><p>“These people showed fake income and got mortgage,” D.M. continued. “Now interest rate is high, they can’t cope.”</p><p>“Other branches did the same thing too,” his co-worker replied. “I heard there’s a lot.”</p><p>“Absolutely,” D.M. texted. “All branches engaged in it.”</p><p>“This is like the unspoken secret,” his co-worker concluded. “I’m pretty sure other banks have it too. My Aunt have no income and got a mortgage for 700k. They just need a Covenanter from China.”</p><p>Generally, in mortgage contracts a covenanter takes responsibility for the loan if the primary borrower defaults.&nbsp;</p><p><span>Internal records reviewed by </span><em>The Bureau</em><span> confirm that on April 18, 2022, D.M. sent a lengthy complaint email to senior HSBC Canada executives, informing them of allegations he’d learned from his colleagues.&nbsp;</span></p><p>In it, he alleges that an Aurora manager had informed him of a complaint letter posted to the branch, that accused mortgage brokers and branch employees of colluding in scam mortgages emanating from Mainland China fraud networks.</p><p>Pointing to specific examples, D.M. claimed that another branch colleague had admitted processing numerous loan applications without meeting his clients, because a branch manager delivered her subordinates foreign income client applications so “they did not have to get sales themselves.”</p><p>&nbsp;“Surprisingly all these clients he would get will have foreign income most of the time very inflated like 400k or 670k a year,” D.M. wrote. “To me that’s suspicious, but he never questioned the branch manager because in Asian culture it’s disrespectful to question elders.”</p><p>D.M. also informs his bosses that one Aurora bank manager opened up to him, saying she believed allegations of mortgage fraud collusion involving some branch staff.</p><p>“She said yes, she knows specially in Mainland China there is a team who would even answer emails and phone calls verifying [Chinese income] but it’s a sophisticated and well organised scam,” D.M. 's email to HSBC Canada managers says.</p><p>His complaint explains that he continued to press an Aurora bank manager on her knowledge of fraud allegations.</p><p>“When I asked for such a serious issue if she raised a HSBC confidential [complaint] or not she evaded my question,” D.M. wrote. “Now we all love numbers, but I don't think the bank will like these kinds of numbers achieved through this way.”</p><p>Describing why he contacted HSBC Canada executives directly, the whistleblower’s complaint says he felt confused and isolated, but D.M. decided “local leadership if not participated, at least turned a blind eye,” to Chinese fake-income scams, forcing D.M. to “bring up a serious issue against people of superior positions.”</p><p>“I could not have stayed silent, in fact I could not sleep well thinking about it,” his April 2022 complaint says. “It reminds me to some extent what happened with the Home Capital Group.”</p><p>“The whole thing is wrong on so many grounds,” D.M. continued.</p><blockquote><p>“Now I know one more reason why Canadians and permanent residents are not getting into the housing market. It’s not only HSBC such things are happening across other Canadian banks as well.”</p></blockquote><p><span>In the</span><a href="https://www.osc.ca/sites/default/files/pdfs/proceedings/set_20170614_home-capital.pdf" rel=""> Home Capital case,</a><span> the Ontario Securities Commission fined the prominent Ontario-based subprime mortgage lender in 2017, alleging Home Capital failed to disclose several of its mortgage brokerages had major problems with faked-income mortgages.</span></p><p>D.M. concluded his four-page complaint to senior executives, writing: “I recommend all mortgage deals of this branch in the last 3 years at least if not longer with Foreign income be probed.”</p><p>“Bank statements can be verified directly with the foreign banks or use a reputable third party to verify,” he suggested. “When we find someone with Fake ID or trying to impersonate someone we call the cops. But these people, both staff nor clients who did fraud were reported.”</p><p>Hours later on April 18, 2022, an HSBC Canada executive emailed back: “I am going to refer this to our Fraud and Risk teams and they will investigate your concerns.”</p><p>The next day D.M. continued to hound HSBC Canada managers with emails to support his allegations, spotlighting the absurdity of massive Chinese remote incomes claimed by diaspora buyers.</p><p>He pointed to one woman with a $1.6-million HSBC Canada mortgage.</p><p>“The client claims to be in Canada but [is] a office supervisor in China. [In the] age of remote working in which country [does] a office supervisor makes 400k please tell me,” D.M. wrote.</p><p> “[W]hen I asked the co-worker she said her job is not to use the brain or be a police, when I asked do you think she makes that kind of money and how is she doing her job being in Canada to be an office supervisor in China[?]”</p><p>Pointing to another document,&nbsp;D.M. warned his managers about Ms. Chen, who claimed to make $721,000 annually as “project manager” for a Beijing telecommunications company, to secure a $1.89 million mortgage.&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png" width="1456" height="510" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:510,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1928546,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcc45270-172a-4e1a-a3f2-730bd8cb8e41_1782x624.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Again on May 4, 2022, D.M. emailed executives, suggesting internal records for an Aurora client named Ms. Jin had been altered soon after D.M. blew the whistle on fake Chinese income loans.</p><p>His email, which included Ms. Jin’s client profile, warned: “Something interesting happened yesterday, they added a China address to go with [the] story of working in China, please see below.”</p><p><span>The Aurora branch banking records disclosed to </span><em>The Bureau</em><span> show that Ms. Jin owns three homes in the blocks surrounding Pacific Mall in Markham.</span></p><p>“The client was onboarded on 24th March with Canada address only and Canadian tax residency,” D.M.’ s email continued.</p><p>“She claims to be working in China and have foreign income, so the story she is stuck in Canada due to Covid is very interesting. Suddenly yesterday she decided her address in China. Someone saw the discrepancies and the branch team decided to change it.”</p><p>“To me that's a red flag done to align with the story portrayed.”</p><p>Next, D.M. exposed Ms. Chen’s foreign income claim.</p><p>“She works for Food processing company, a logistics officer making 273k a year,” he wrote. “I don't know which logistics officer can work when physically in a different company and also who makes 273k working as a logistics officer.”</p><p>Citing another internal banking record, D.M.’s email pointed to Ms. Jin’s $273,000 income and said “it’s interesting how they did the verification.”</p><p>The email continues to explain that branch records showed Ms. Jin and her husband had a joint mortgage with a balance of $497,000 at CIBC. </p><p>But suddenly during Covid-19, Ms. Jin applied for a new mortgage for $1.2 million with HSBC Canada.</p><p>“When I see such things I can't stay quiet,” D.M.’s May 2022 email says. “[I] was assuming with the new rules things will stop, [but]&nbsp;declining the mortgage or retraining the staff is like treating the symptoms.”</p><p>He added that many suspicious Chinese income loans had been “flagged by our Fraud Team already.”</p><p>The whistleblower’s scathing assessment ends with the observation that D.M. didn’t believe “someone woke up and decided to scam the bank, but [worked with] a sophisticated network of agents who are training people what to say and answer.”</p><p>“The implications are broader and as a responsible bank and citizen we have to,” request investigations from the Canadian Revenue Agency or Ontario Provincial Police, D.M. asserted.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png" width="1456" height="982" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:982,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3900114,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a768b85-da71-4092-94ee-6e2dc0b3a464_1800x1214.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>D.M., who asked not to be named because he could face reprisals, filed a four-page whistleblower complaint with HSBC Canada managers in April 2022.</figcaption></figure></div><p><em>The Bureau</em><span> asked</span><a href="https://summit.sfu.ca/item/37923" rel=""> Ashleigh Gonzales</a><span>, the former RCMP data scientist, to review some of D.M.’s documents and conclusions.</span></p><p>“From what I have reviewed, D.M.’s findings align with what appear to have been commonplace practices by some groups of staff complicit from the front line, middle office, and back office and sanctioned by management,” Gonzales wrote, adding “whether knowingly or not depends on the individual work cultures.”</p><p><em>The Bureau</em><span> also asked Stephen Punwasi to review D.M. 's leaked banking documentation.</span></p><p><span>Punwasi is a financial expert who founded </span><em>Better Dwelling,</em><span> a real estate analysis website with a large following of young professionals trying to understand </span><a href="https://betterdwelling.com/canadas-real-estate-bubble-is-batsht-crazy-compared-to-other-g7s/" rel="">why they’re excluded </a><span>from home ownership in Canadian cities.</span></p><p>He also provided analysis for British Columbia’s 2018 report into Vancouver Model money laundering in casinos, real estate and luxury vehicles.&nbsp;</p><p>What Punwasi explained to the report’s author, former RCMP executive Peter German, is that even though Vancouver Model money launderers don’t comprise a majority of buyers in Vancouver, their willingness to overbid on home sales causes ripples that sends prices skyrocketing, especially during times when political turmoil inside China triggers increased capital flight.</p><p>“In 2015 and 2016 Ontario saw this flood of money from China, just like British Columbia, and it was not just to do with immigration, it was due to President Xi’s political crack down on corruption,” Punwasi said. “I think we’ve seen that capital flight in Ontario and B.C. in two big cycles, also including 2020 and 2021.”</p><p><em>The Bureau</em><span> asked Punwasi if the banking records disclosed by D.M. help to explain Toronto’s real estate price surges.</span></p><p>“Absolutely,” he said, pointing to the case of Ms. Jin (who claimed a $273,000 remote-work income in China) and her three homes surrounding Markham’s Pacific Mall. </p><p>Property buyers that aren’t shopping for shelter, but for capital flight or money laundering vehicles, are what Punwasi terms the “marginal buyer.”</p><blockquote><p>&nbsp;“The marginal buyer is like an exuberant buyer on crack, so if they are motivated to move as much money as possible,” he said, “the larger the mortgage they can get, it helps them to overpay for homes, and that can cause the price to launch.”</p></blockquote><p>“So if you see a townhome in Toronto going for $2-million, you don’t know if it is mortgage money laundering or someone buying a place to live. You just have to compete with the going price.”</p><p>Punwasi says housing prices are a powerful political issue that will shape the next federal election. </p><p><span>But at the same time, young generations are confused by competing explanations on the causes of Canada’s housing affordability crisis, Punwasi believes, whether its lack of housing supply due to restrictive zoning bylaws, or increased demand due to recent immigration surges, or other factors that make Canada’s </span><a href="https://betterdwelling.com/cibc-kills-foreign-income-program-makes-buying-canadian-real-estate-harder/" rel="">housing bubble </a><span>an outlier in the Western world.</span></p><p>“There are so many conflicting narratives right now that people find it hard to believe the scale of impact that money laundering can have on Toronto real estate prices,” Punwasi said. “But no one has thought it through, that having criminals run our renting stock is a liability.”</p><p>Punwasi also believes that Prime Minister Justin Trudeau’s government has decreased scrutiny of money laundering in recent years.</p><p><span>He points to new data uncovered in a ministerial inquiry from Conservative MP Adam Chambers, who is a proponent of </span><a href="https://www.adamchambersmp.ca/bill-c-289" rel="">tougher money</a><span> laundering laws, which found sharp declines in Canadian Revenue Agency audits of FINTRAC leads.</span></p><blockquote><p><span>“The systemic corruption in housing has been snowballing,” Punwasi said, “to where it's turned into, maybe the banks don’t need to check where the </span><a href="https://betterdwelling.com/cibc-kills-foreign-income-program-makes-buying-canadian-real-estate-harder/" rel="">incomes</a><span> are coming from, and now whole generations can’t find stable shelter.”</span></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png" width="1456" height="1103" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1103,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:237254,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53837cb-1742-46ff-b773-3ecee1451e3a_1494x1132.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Adam Chambers, a Toronto-area Conservative MP who unsuccessfully tabled a private members bill on stricter anti-money laundering laws, found CRA money laundering reviews are decreasing.</figcaption></figure></div><p><span>HSBC Canada emails reviewed by </span><em>The Bureau</em><span> show that while the bank appears to have responded to some of H.M. 's recommendations in 2022, troubling mortgage applications and problems with existing Chinese income loans continued.</span></p><p>A January 2023 email to an Aurora branch manager from HSBC Canada’s office in Montreal pointed to a client named Ms. B., who worked at an Ontario government casino, and owned homes across Toronto, in Richmond Hill, Newmarket and East York. </p><p>Documents show she obtained an HSBC Canada mortgage for $1.26 million in 2016, and that HSBC Canada staff&nbsp; “confirmed” in July 2021 that she was earning $345,000 with a remote work job in Beijing.&nbsp;</p><p>Despite her incredible claimed income, documents show, Ms. B. was having trouble paying at least one of her three mortgages.&nbsp;</p><p>An email from a “Senior Loss Mitigation” employee in Montreal to an Aurora branch employee says: “client is going through a tough time … her income is limited … I know she collect rent and she use it to pay her second mortgage. Please review the situation with the client to see if there is any special agreement available to her.”</p><p>But Aurora’s branch wrote back to the Montreal branch: “What we have told her is … if she really can’t pay, then she just have to put her house for sale … but she doesn’t want to do that.”</p><p><span>In an interview D.M. told </span><em>The Bureau</em><span> this case was typical.</span></p><p>“What they are doing is AirBnBing these properties,” he said. “But they can’t manage with higher interest rates.”</p><p>He said during mortgage application interviews at the Aurora branch he would often look across his desk and ask questions without letting clients know he was looking at their income claims from purported Chinese companies on his computer screen.&nbsp;</p><blockquote><p>“Most of these people don’t even know what type of company is in their job profile,” he said.</p></blockquote><p><span>And documents reviewed by </span><em>The Bureau</em><span> show that mortgage applications consistent with Fintrac’s 2023 Chinese money laundering report continued in Aurora.&nbsp;</span></p><p>In May 2023, D.M. emailed a senior HSBC Financial Crime Compliance investigator, writing “Just came across two profiles of clients and I have strong evidence these mortgages were also obtained with fake docs and fraudulently.”</p><p>When the investigator responded “I will take a look,” D.M. replied: “One had a CDA student loan of 10k and making 700k in China. Makes no sense, there are many other anomalies.”</p><p><span>In interviews,&nbsp;D.M. told </span><em>The Bureau</em><span> he waited “patiently for a year” after reporting his Chinese-income mortgage concerns to HSBC Canada managers, before concluding the bank’s response was insufficient.</span></p><p>“This has been going on for seven&nbsp;years and no one spoke up,” he said.&nbsp;“In my first meeting last year, they asked me a lot of questions, like why didn’t you use the normal channels? But I had no faith in the normal channels.”</p><p>“Many bank staff were obviously involved,” D.M. alleged. “It was not one or two employees turning the blind eye but the entire system, someone verifying those fake offer letters and pay stubs, or their bank statements from China.”</p><p>D.M. said his concerns also included HSBC Canada’s proposed sale to RBC, which was announced in 2022, about six months after D.M. 's April 2022 internal complaint. The sale was approved in December 2023 by Canada’s deputy Prime Minister Chrystia Freeland.</p><p>Christian Leuprecht, among other experts interviewed for this story, agreed that D.M.’s allegations of widespread Chinese-income frauds at HSBC Canada could raise questions about whether Freeland, Canada’s finance minister, had knowledge of mortgage lending investigations inside HSBC when she approved the sale.</p><p><span>Freeland directed RBC to “establish a new Global Banking Hub in Vancouver,” and “maintain Mandarin and Cantonese banking services at HSBC branch locations,” a Department of Finance </span><a href="https://www.canada.ca/en/department-finance/news/2023/12/government-of-canada-approves-sale-of-hsbc-bank-canada-to-the-royal-bank-of-canada-with-conditions.html" rel="">statement says.</a></p><p>Ultimately, D.M. says he chose to share his story with Canadian citizens partly because he felt pressured to erase evidence from his whistleblower complaint emails.</p><p>A June 2023 email from the bank’s personnel department says “we hereby demand that you immediately and permanently delete any and all HSBC information on any personal email accounts.”</p><p>“If you do not comply with these obligations,” the email warns, “HSBC also reserves the right to bring this matter to the attention of relevant law enforcement agencies.”</p><p>Another July 2023 email from senior management said: “I will reiterate how much we appreciate that you spoke up,” and confirmed that D.M.’s complaints to HSBC Canada resulted in “several enhancements to income verification procedures.”&nbsp;</p><p>The manager’s email continues, saying “as part of your escalation, you sent confidential information from the bank to your personal email account,” and asserts that D.M. had promised to delete the “confidential client information in your personal possession.”</p><p>“I could not sleep, and they were telling me delete, delete, delete,” D.M. recalled in an interview.</p><p><span>HSBC Canada did not respond to follow-up questions from </span><em>The Bureau</em><span> regarding D.M.’s specific allegations.</span></p><p>Now he is looking for accountability.</p><p>“There should be a thorough, retrospective audit of HSBC Bank mortgage deals and eventually all Canadian banks in Canada and stricter regulations when it comes to mortgage approval showing foreign income,” D.M. said, “because there are many skeletons in the cupboard.”</p><p><span>Garry Clement, a former RCMP anti-money laundering expert who also contributed to the Canadian academic text </span><em>Dirty Money, </em><span>reviewed some of D.M.’s Toronto Method documents, and commented “the best description of the bank’s actions, is willful blindness.”&nbsp;</span></p><blockquote><p>“This is one well-documented example of how banks are catering to Chinese citizens without following strict know your customer guidelines as they would for any Canadian,” Clement said.&nbsp; </p><p>“We must recognize that a lot of the loans occurred at a time when our political leaders catered to China with a naïve understanding.”</p></blockquote><p><span>Calvin Chrustie, a former RCMP transnational crime investigator </span><a href="https://nationalpost.com/news/canada/canada-a-safe-haven-for-transnational-crime-networks-and-their-dirty-money-u-s-report" rel="">whose recent  report</a><span> finds Canada’s weak regulations have made the nation a playground for underground banking linked to organized crime in China, Iran and Mexico, noted that in 2012, U.S. regulators hit HSBC with a $1.9 billion fine because of $881-million in suspicious transactions with Mexico’s Sinaloa cartel and Colombia’s Norte del Valle cartel.</span></p><p>“The bigger question in Canada now is why aren’t we looking at what is happening in the banks?” Chrustie said. “We haven’t looked at the complicit actions of financial institutions, while we rely on well-intended entities like FINTRAC, who like police are often restricted in what they can do, or say to the public.”</p><p><span>FINTRAC would not confirm or deny whether its recent fines on CIBC for failing to report suspicious</span><a href="https://fintrac-canafe.canada.ca/pen/amps/pen-2023-12-05-eng" rel=""> wire transactions</a><span> and a fine on RBC for failing to report suspicious transactions</span><a href="https://fintrac-canafe.canada.ca/pen/amps/pen-2023-12-05-eng" rel=""> related to frauds,</a><span> relate to FINTRAC’s 2023 report on Chinese shadow banking and pandemic-era bank account and real estate transactions. </span></p><p><span>FINTRAC also would not confirm whether a </span><em><a href="https://www.theglobeandmail.com/business/article-td-bank-fintrac-penalties-anti-money-laundering-controls/" rel="">Globe and Mail</a></em><a href="https://www.theglobeandmail.com/business/article-td-bank-fintrac-penalties-anti-money-laundering-controls/" rel=""> </a><span>report that TD Bank faces a money laundering compliance fine of more than $10-million is accurate, or relates to the Covid-19 shadow banking schemes.</span></p><p>Like the former RCMP experts interviewed for this story, Andy Yan says governments in Ottawa and British Columbia and Ontario are ultimately responsible for ushering mysterious wealth into Canada’s homes.</p><p>“It’s like, this isn’t entirely new, what you have found in Toronto,” Yan summed up. </p><blockquote><p>“When you have programs that are directly meant to domesticate foreign capital into local real estate markets, you start seeing these patterns or these incongruities between incomes and house values. And we have institutions that really are supposed to safeguard us in terms of transparency and accountability.”</p></blockquote><p>Meanwhile, a second property owned by Meng Wanzhou in Vancouver attests to the murkiness surrounding Chinese wealth, but also broader concerns of former RCMP experts interviewed for this story, on how and why Chinese state and non-state actors move funds globally.</p><p><span>In 2016 Meng, who held at least </span><a href="https://www.agpllp.ca/insights/the-many-passports-of-arrested-huawei-cfo-meng-wanzhou/" rel="">seven different</a><span> visas or passports, purchased a $15-million mansion with an </span><a href="https://www.straight.com/news/huaweis-meng-wanzhou-loved-vancouver-and-has-two-homes-worth-at-least-182-million" rel="">HSBC Canada </a><span>mortgage in Shaughnessy, a luxurious community just outside of Yan’s study areas. </span></p><p><span>Other mansions in Shaughnessy featured prominently in a confidential RCMP study of all homes sold for between $3-million and $30-million in 2016. That police intelligence study </span><a href="https://globalnews.ca/news/4658157/fentanyl-vancouver-real-estate-billion-money-laundering-police-study/" rel="">found Chinese transnational gangsters </a><span>and Vancouver Model suspects linked to over $1-Billion in property purchases in 2016.</span></p><p><span>Ironically — in the case that disrupted Canada’s warming relations with China under Justin Trudeau — Meng finally admitted to U.S. government </span><a href="https://www.justice.gov/opa/pr/huawei-cfo-wanzhou-meng-admits-misleading-global-financial-institution" rel="">financial fraud </a><span>charges that she misled HSBC about international transactions, and “Meng and her fellow Huawei employees engaged in a concerted effort to deceive global financial institutions, the U.S. government and the public about Huawei’s activities in Iran.” </span></p><p><em>sam@thebureau.news</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oceans May Have Already Seen 1.7°C of Warming (238 pts)]]></title>
            <link>https://eos.org/articles/oceans-may-have-already-seen-1-7c-of-warming</link>
            <guid>39275272</guid>
            <pubDate>Tue, 06 Feb 2024 15:29:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/articles/oceans-may-have-already-seen-1-7c-of-warming">https://eos.org/articles/oceans-may-have-already-seen-1-7c-of-warming</a>, See on <a href="https://news.ycombinator.com/item?id=39275272">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-220108">
	<div>

		
		
<p>Sponges from the Caribbean retain a record of ocean temperatures stretching back hundreds of years. These newly revealed paleoclimate records suggest that sea surface temperatures (SSTs) began rising in response to industrial era fossil fuel burning around 1860.</p>

<p>That’s 80 years earlier than SST measurements became common and predates the global warming start date used by the Intergovernmental Panel on Climate Change (IPCC). On the basis of these new sponge records, scientists think that temperatures are currently 1.7°C warmer than preindustrial levels.</p>

<figure><blockquote><p>“We’re further advanced in the global warming scenario, and the amount of time we have to take action to prevent it is seriously diminished.”</p></blockquote></figure>

<p>The study’s researchers argue that the world has already surpassed the goal of the 2015 <a href="https://eos.org/tag/paris-agreement" target="_blank" rel="noreferrer noopener">Paris Agreement</a> to limit atmospheric warming to less than 1.5°C above preindustrial temperatures and that we could reach 2°C of warming before 2030.</p>

<p>“We’re further advanced in the global warming scenario, and the amount of time we have to take action to prevent it is seriously diminished,” said <a href="https://research-repository.uwa.edu.au/en/persons/malcolm-mcculloch" target="_blank" rel="noreferrer noopener">Malcolm McCulloch</a>, a marine and coral geochemist at the University of Western Australia in Crawley and lead author on the new study. “We’ve got to start doing serious mitigation and serious reductions in emissions.”</p>

<p>These results were <a href="https://www.nature.com/articles/s41558-023-01919-7" target="_blank" rel="noreferrer noopener">published</a>&nbsp;in <em>Nature Climate Change</em>.</p>


<h3><strong>Old Sponges Fill Gaps</strong></h3>

<p>The sclerosponges studied (<em>Ceratoporella nicholsoni</em>) are a group of long-lived sponges that live exclusively in the Caribbean at depths with little variation in light or temperature. Like tree rings, a sponge’s skeleton retains a record of its environmental conditions throughout its lifetime.</p>

<p>“These sponges are extremely slow growing,” explained <a href="https://www.indstate.edu/faculty-staff/amos-winter" target="_blank" rel="noreferrer noopener">Amos Winter</a>, a study coauthor and paleoceanographer at Indiana State University in Terre Haute. “A 10-centimeter sponge, which isn’t very large, can go back 400 years.”</p>

<p>That longevity is key to the new study’s analysis of modern-day global warming.</p>

<p>The <a href="https://eos.org/tag/ipcc" target="_blank" rel="noreferrer noopener">IPCC</a> compares modern temperatures with the average temperature between 1850 and 1900 to define today’s warming relative to a preindustrial world.</p>

<p>However, “it’s well recognized that human emissions began increasing significantly in the 1750s,” said <a href="https://duochanatharvard.github.io/" target="_blank" rel="noreferrer noopener">Duo Chan</a>, a climate scientist at the University of Southampton in the United Kingdom who was not involved with the new study.</p>
<div>
<figure><img decoding="async" width="780" height="509" src="https://i0.wp.com/eos.org/wp-content/uploads/2024/02/icoads-measurements.gif?resize=780%2C509&amp;ssl=1" alt="This animation shows a map of the world overlain with rainbow-colored points indicating the distribution of sea surface temperatures since 1860 in 20-year increments." data-recalc-dims="1"><figcaption>The global distribution of sea surface temperature measurements in the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) since 1860. Warmer colors indicate more measurements at that location. Credit: McCulloch et al., 2024, <a href="https://doi.org/10.1038/s41558-023-01919-7" target="_blank" rel="noopener">https://doi.org/10.1038/s41558-023-01919-7</a>, <a href="https://creativecommons.org/licenses/by/4.0/legalcode.en" target="_blank" rel="noopener">CC BY 4.0</a>; animation by Kimberly M. S. Cartier</figcaption></figure></div>
<p>Ship-based measurements of SST go back only to around 1850. The records contain many inconsistencies and remain sparse until the mid-1900s, when modern instrumentation took over. Even then, there are <a href="https://eos.org/articles/crowdsourced-science-pulls-off-a-daring-wwii-data-rescue" target="_blank" rel="noreferrer noopener">notable data gaps</a> during such events as World War II. <a href="https://eos.org/tag/proxies" target="_blank" rel="noreferrer noopener">Paleoclimate proxies</a> such as those stored in sclerosponges can extend the record of SSTs back to truly preindustrial times and help fill gaps in shipboard measurements.</p>

<p>“The IPCC’s adoption of a later preindustrial reference period was a compromise, largely due to the lack of sufficient instrumental data for quantifying global temperatures before the 1850s,” Chan said.</p>

<p>These sclerosponge records can unravel the history of past sea surface temperatures, said <a href="https://thirumalai.geo.arizona.edu/" target="_blank" rel="noreferrer noopener">Kaustubh Thirumalai</a>, a paleoceanographer at the University of Arizona in Tucson who was not involved with this study. (Thirumalai is a science advisor for <em>Eos</em>.)</p>

<h3><strong>An 80-Year Head Start</strong></h3>

<p>With the help of local divers, the researchers collected six sclerosponges from 2007 to 2012 near Puerto Rico and St. Croix in the U.S. Virgin Islands. They used uranium-thorium radioisotope dating to construct a growth timeline for each sponge that goes back about 300 years.</p>

<p>Within each 2-year growth interval, they measured the ratio of strontium to calcium. Calcifying coral skeletons preferentially take in calcium over strontium as temperatures increase, so the ratio is a proxy for seawater temperature. They calibrated their sclerosponge temperature timeline against recent (1964–2012) instrumental measurements.</p>

<p><em>Ceratoporella nicholsoni</em> may be endemic to the Caribbean, but they can be used to understand globally averaged trends.</p>

<p>Scientists have found that <a href="https://doi.org/10.1038/s41586-018-0006-5" target="_blank" rel="noreferrer noopener">temperature trends in Caribbean waters</a> closely follow global mean SST trends. Sclerosponges live at depths within the <a href="https://en.wikipedia.org/wiki/Mixed_layer#Oceanic_mixed_layer" target="_blank" rel="noreferrer noopener">ocean mixed layer</a>, where temperatures are mostly the same from the surface to about 100 meters down. So the ambient seawater temperatures recorded by sclerosponges can be used to understand sea surface temperatures too.</p>

<p>The sclerosponges recorded some well-known global temperature anomalies, such as the cooling period after the <a href="https://eos.org/articles/centuries-old-archive-reveals-far-flung-impacts-of-major-eruptions" target="_blank" rel="noreferrer noopener">Tambora</a> eruption in 1815. Ocean temperatures were relatively steady from 1700 to 1790, followed by an era of volcanic cooling from 1790 to 1840 and then another steady but slightly warmer period from 1840 to the early 1860s. Researchers trace anthropogenic climate change to that period—about 80 years earlier than instrumental SST records show.</p>

<p>The sponges’ preindustrial starting line of about 1700 implies that Earth warmed by 1.7°C between then and about 2020, assuming that the land and ocean have warmed by the same amount. That’s about 0.5°C higher than IPCC estimates and suggests that the planet is on track to surpass 2°C of warming before 2030.</p>

<p>Thirumalai found the research to be “innovative and clever,” although he said the sclerosponge records might have too much uncertainty to sufficiently pinpoint events such as the 19th century volcanic cooling. Too, he wanted the researchers to have shown in more detail how temperature trends in the Caribbean were representative of global SST anomalies.</p>

<p>Nevertheless, he said, “it is always useful to generate new and independent paleotemperature records to help minimize uncertainties in our understanding of anthropogenic warming and the baseline of preindustrial conditions.”</p>

<h3><strong>Untangling the Cause of Warming</strong></h3>

<p>“Integrating these sclerosponge findings with corrected instrumental data could offer a more comprehensive view of historical SST evolution,” Chan said. However, he cautioned against immediately adopting the updated warming values.</p>

<p>The sclerosponge warming rates almost mirror modern instrumental records in a broad sense, but there are some differences, even when accounting for different starting lines, Chan said. Research is ongoing to correct some biases and errors in historic instrumental records, which might reconcile some of these differences.</p>

<figure><blockquote><p>“This distinction not only enhances our understanding of climate change but also has significant political implications, informing policy and target setting in the context of global warming.”</p></blockquote></figure>

<p>Too, when looking as far back as 1700, Earth’s climate might still have been rebounding from the <a href="https://www.britannica.com/science/Little-Ice-Age" target="_blank" rel="noreferrer noopener">Little Ice Age</a> (roughly 1300–1850). That might account for some of the warming during the early 19th century, Chan said, but definitely not all.</p>

<p>“It is essential to more accurately distinguish the anthropogenic component from other factors, particularly during the early industrial period,” Chan said. “This distinction not only enhances our understanding of climate change but also has significant political implications, informing policy and target setting in the context of global warming.”</p>

<p>McCulloch, Winter, and their colleagues urged IPCC scientists and climate modelers to consider this new preindustrial starting line. Whether it will be adopted is uncertain, but if the world has already surpassed 1.5°C of warming, the researchers argue that continued <a href="https://eos.org/tag/climate-action" target="_blank" rel="noreferrer noopener">climate action</a> is more important than ever.</p>

<p>—Kimberly M. S. Cartier (<a href="https://twitter.com/@AstroKimCartier" target="_blank" rel="noreferrer noopener">@AstroKimCartier</a>), Staff Writer</p>

<h5><strong>Citation:</strong>&nbsp;Cartier, K. M. S. (2024), Oceans may have already seen 1.7°C of warming,&nbsp;<em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240059" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2024EO240059</a>. Published on 5 February 2024.</h5>

<h6><strong>Text © 2024. The authors.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a></strong><br><strong>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</strong></h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky and the at Protocol (105 pts)]]></title>
            <link>https://arxiv.org/abs/2402.03239</link>
            <guid>39275203</guid>
            <pubDate>Tue, 06 Feb 2024 15:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2402.03239">https://arxiv.org/abs/2402.03239</a>, See on <a href="https://news.ycombinator.com/item?id=39275203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2402.03239.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 3 million registered users in the following year. In this paper we introduce the architecture of Bluesky and the AT Protocol, which is inspired by the web itself, but modernized to include streams of real-time updates and cryptographic authentication. We explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Martin Kleppmann [<a href="https://arxiv.org/show-email/f3ce74c0/2402.03239">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 5 Feb 2024 17:55:51 UTC (2,032 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Better Call GPT, Comparing Large Language Models Against Lawyers [pdf] (219 pts)]]></title>
            <link>https://arxiv.org/abs/2401.16212</link>
            <guid>39274918</guid>
            <pubDate>Tue, 06 Feb 2024 15:04:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2401.16212">https://arxiv.org/abs/2401.16212</a>, See on <a href="https://news.ycombinator.com/item?id=39274918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2401.16212.pdf">Download PDF</a>
    <a href="https://arxiv.org/html/2401.16212v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>This paper presents a groundbreaking comparison between Large Language Models and traditional legal contract reviewers, Junior Lawyers and Legal Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical analysis benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining legal issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in legal practice. LLMs stand poised to disrupt the legal industry, enhancing accessibility and efficiency of legal services. Our research asserts that the era of LLM dominance in legal contract review is upon us, challenging the status quo and calling for a reimagined future of legal workflows.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Rivindu Perera [<a href="https://arxiv.org/show-email/e9e4df27/2401.16212">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 24 Jan 2024 03:53:28 UTC (695 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky signups are now open to the public (234 pts)]]></title>
            <link>https://bsky.social/about/blog/02-06-2024-join-bluesky</link>
            <guid>39274882</guid>
            <pubDate>Tue, 06 Feb 2024 15:01:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.social/about/blog/02-06-2024-join-bluesky">https://bsky.social/about/blog/02-06-2024-join-bluesky</a>, See on <a href="https://news.ycombinator.com/item?id=39274882">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><header><section><a href="https://bsky.social/about/blog">Blog</a><svg width="8" height="12" viewBox="0 0 8 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 10L6 6L2 2" stroke="#667999" stroke-width="2" stroke-linecap="square"></path></svg><span>Join Bluesky Today (Bye, Invites!)</span></section><div><p>Feb 6, 2024</p><p><span>by <!-- -->The Bluesky Team</span></p></div></header><div><p>Bluesky is building an open social network where anyone can contribute, while still providing an easy-to-use experience for users. For the past year, we used invite codes to help us manage growth while we built features like moderation tooling, custom feeds, and more. Now, we’re ready for anyone to join.</p>

<p>Join more than three million people discussing news, sharing art, and just posting.</p>
<h2>What is Bluesky?</h2>
<p>To mark the occasion, we teamed up with <a href="https://bsky.app/profile/davis.social">Davis Bickford</a>, an artist on the network, to share why we’re excited about Bluesky.</p>
<p><img src="https://bsky.social/about/welcome-to-bluesky-comic-davis-bickford/page-1.jpg" alt="A multi-panel comic. Two characters stand amidst a pile of rubble. One says, 'I think it's time to leave old social. This keeps happening. I have to start over again. I'm tired.' The two characters board a boat. Jay says, 'Don't worry! Better things are ahead at Bluesky!' They arrive to a beautiful, festive area that has buildings labeled News, Discover, Art, Science, and more." classname="w-full">
<img src="https://bsky.social/about/welcome-to-bluesky-comic-davis-bickford/page-2.jpg" alt="A multi-panel comic. Jay says, 'At Bluesky, you choose what you want to see instead of being held to the whims of a blackbox algorithm. There are already tens of thousands of feeds! Anyone can make or subscribe to feeds!' A troll appears. Jay says, 'And for things you don't want to see, you can stack additional layers of moderation as easily as following a new account.' Poof! Fences go up and the troll disappears. Jay continues to describe Bluesky's open network. 'With Bluesky, everything is connected. Dock at any port — you can explore the entire network. And wherever you go, your whole network comes with you.'" classname="w-full">
<img src="https://bsky.social/about/welcome-to-bluesky-comic-davis-bickford/page-3.jpg" alt="A multi-panel comic. One character says, 'At Bluesky, I can customize my own experience and if I move, everything comes with me?!' Jay smiles and says, 'Yes, it's the last social account you'll ever have to create!' The two run across a bridge towards a magical mountainside. They say, 'Come on, let's go explore!'" classname="w-full"></p>
<p>To learn more about Bluesky and how to get started, read our <a href="https://bsky.social/about/blog/5-19-2023-user-faq">user FAQ here</a>.</p>
<p>And if deep dives are more your style, we worked with <a href="https://bsky.app/profile/martin.kleppmann.com">Martin Kleppman</a>, author of <em>Designing Data-Intensive Applications</em> and technical advisor to Bluesky, to write <a href="https://bsky.social/about/bluesky-and-the-at-protocol-usable-decentralized-social-media-martin-kleppmann.pdf">a paper that goes into more detail</a> about the technical underpinnings of Bluesky.</p>
<h2>Looking Forward</h2>
<p>We’ve been working on more features that put you in control of your social media experience. Here’s what you can expect to see soon:</p>
<h3>Stackable Moderation Services</h3>
<p>Safety is core to social media. Bluesky moderates the app according to our community guidelines, and our vision for <a href="https://bsky.social/about/blog/4-13-2023-moderation">composable moderation</a> allows users to stack more moderation services together, such as subscribable moderation lists.</p>
<p>In the coming weeks, we’re excited to release the labeling services which will allow users to stack more options on top of their existing moderation preferences. This will allow other organizations and people to run their own moderation services that can account for industry-specific knowledge or specific cultural norms, among other preferences.</p>
<p>One potential use case for labeling is fact-checking. For example, a fact-checking organization can run a labeling service and mark posts as “partially false,” “misleading,” or other categories. Then, users who trust this organization can subscribe to their labels. As the user scrolls through posts in the app, any labels that the fact-checking organization publishes will be visible on the post itself. This helps in the effective distribution of the fact-check and keeps users better informed.</p>
<p>We’ll be sharing more in the coming weeks. In the meantime, if you’re interested in partnering with Bluesky and setting up a labeling service, contact us at <a href="mailto:partnerships@blueskyweb.xyz">partnerships@blueskyweb.xyz</a>.</p>
<h3>An Open Social Network</h3>
<p>When you log in to Bluesky, it might look and feel familiar — the user experience should be straightforward. But under the hood, we’ve designed the app in a way that puts control back in your hands. Here, your experience online isn’t controlled by a single company. Whether it's your timeline or content filters, on Bluesky, you can easily customize your social experience.</p>
<p>This month, we’ll be rolling out an experimental early version of “federation,” or the feature that makes the network so open and customizable. On Bluesky, you’ll have the freedom to choose (and the right to leave) instead of being held to the whims of private companies or black box algorithms. And wherever you go, your friends and relationships can go with you.</p>
<p>For developers: We’ve already federated the network among multiple servers internally, and later this month, you’ll be able to self-host a server that connects to the main production network. You’ll be part of the first batch of servers that federate with the network, so expect to experiment alongside us! We’ll share more information on how to join the production network with your own server soon. In the meantime, you can test out your server set up via our developer sandbox. <a href="https://www.docs.bsky.app/blog/federation-sandbox">Find instructions here</a>.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla Monitor Plus: automatically remove your personal info from data brokers (128 pts)]]></title>
            <link>https://blog.mozilla.org/en/mozilla/introducing-mozilla-monitor-plus-a-new-tool-to-automatically-remove-your-personal-information-from-data-broker-sites/</link>
            <guid>39274631</guid>
            <pubDate>Tue, 06 Feb 2024 14:37:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/mozilla/introducing-mozilla-monitor-plus-a-new-tool-to-automatically-remove-your-personal-information-from-data-broker-sites/">https://blog.mozilla.org/en/mozilla/introducing-mozilla-monitor-plus-a-new-tool-to-automatically-remove-your-personal-information-from-data-broker-sites/</a>, See on <a href="https://news.ycombinator.com/item?id=39274631">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-74078">
  

  <div>
    
<p>Today,<a href="http://relay.firefox.com/"> </a><a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Mozilla Monitor</a> (previously called Firefox Monitor), a free service that notifies you when your email has been part of a breach, announced its new paid subscription service offering: automatic data removal and continuous monitoring of your exposed personal information.&nbsp;</p>



<figure><p>
<iframe title="Mozilla Monitor Plus | Product Walkthrough" width="640" height="360" src="https://www.youtube.com/embed/lT0u415in5Y?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p><figcaption><em>Introducing Mozilla Monitor Plus</em></figcaption></figure>



<p>There’s a growing interest among 42% of young adults – aged 18-24 – who want to learn more about the types of information that companies have about them, according to a <a href="https://blogs.cisco.com/security/generation-privacy">consumer privacy survey</a>. Yet, taking the steps to request changes or delete personal data can be a bit overwhelming. At Mozilla, we’re always looking for ways to <a href="https://www.mozilla.org/en-US/about/manifesto/">protect people’s privacy and give them greater control when they go online</a>. Enter <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a>.</p>



<p>“When we <a href="https://blog.mozilla.org/en/products/firefox/introducing-firefox-monitor-helping-people-take-control-after-a-data-breach/">launched</a> Monitor, our goal was to help people discover where their personal info may have been exposed. Now, with <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a>, we’ll help people take back their exposed data from data broker sites that are trying to sell it,” said Tony Amaral-Cinotto, Product Manager of <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Mozilla Monitor</a> at Mozilla. “Our long-standing commitment to put people’s needs first and our easy step-by-step process makes <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a> unique. Additionally, we combine breach alerts and data broker removal to offer an all-in-one protection tool and make it easier for people to feel and be safe online.”&nbsp;</p>



<h2>First step: Find out where your personal information has been exposed</h2>



<p>More than 10 million people have signed up with <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Mozilla Monitor</a> so they can be notified when their personal data has been involved in a data breach. Today, we are rolling out a new feature with a free one-time scan, where people can take the next step to see where their personal information has been exposed on sites selling it for profit. This could include information like your name, current and previous home addresses, and phone numbers. It could also go another layer deeper with information like family member names, criminal history, your kids’ school district, and even your hobbies.</p>



<p>To get your complimentary scan, you will need to provide your first and last name, the current city and state that you live in, your date of birth, and your email address. This information will be encrypted and follows <a href="https://www.mozilla.org/en-US/privacy/subscription-services/#">Mozilla’s privacy policy</a>, which always puts people first. This is the least amount of information we need to get the most accurate search results for you. From there, you can see where your personal info is exposed, either through a data breach or through broker sites. We also include high risk data breaches – exposures that may include social security numbers, credit card information, your bank account and pin numbers – that you’ve been exposed to and show how you can fix and resolve it.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/yCUt5bOi3hGj82IdNvhpBRn5JUvgHe12zyfOj0otRLhVSMxYZZlfaTbYz2d4Asli27Os6Pz-4SMFGa_QjoPjiY6fdxX95L-tBH-d0wU5xKxHnBQOo2vEK6PLECZzyQ1GQ8Jf4Za_YuKU85GjdCQ_SWg" alt="brief GIF showing the fields where you enter some personal data, then a screen showing &quot;scanning for exposure&quot;, then the dashboard where you can fix."><figcaption><em>Take the step to see where your personal info has been exposed</em></figcaption></figure>



<h2>Second step: Take back your personal information with <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a></h2>



<p>If you’re the type who wants to set it and forget it, because you know the work is happening behind the scenes, then we can automatically and continuously request to remove your personal information with an annual paid subscription of $8.99 per month ($107.88 a year). On your behalf, <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Mozilla Monitor</a> will start with data removal requests, then scan every month to make sure your personal information stays off data broker sites. <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a> will let you know once your personal information has been removed from more than 190+ data broker sites, twice the number of other competitors.&nbsp;</p>


<div>
<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/FxkxHE3KjEx8E5mWL1TMfLUo0iQgKfB2gmk7qZpmUQq238_CUKjTYderXtlrkcrOGFqt3FhnRd8NxuDx-Zy50DO7-Bz6H8xg1mzKWZkhOyZe_wcbHgGyeCpSQnTyCSI2wFgkptpfnP4zz89xh-e7BJI" alt=""><figcaption><em>See the actual sites where your personal info has been exposed</em></figcaption></figure></div>

<div>
<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/1XnRNUd8_tpwsfuriYyQD3ZcFf7XdhhGHukY_F0E1TqQv87tOmVHuHQgOdbcVGCZi1wpPfrrThcNPiQ_oGseKN_5aI0GQOUuLFZkPfvitg6bYacMF-pOG1X8_qr8zN5MZXQcecd0ehRhpF0pUvaUanE" alt=""><figcaption><em>Mark as fixed in the dashboard</em></figcaption></figure></div>


<p>At launch, the <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Monitor Plus</a> free scan and paid subscription service will be offered to people based in the United States.&nbsp;</p>



<h2>Privacy starts with a Mozilla Account</h2>



<p>Mozilla has built a reputation of creating and delivering products – <a href="https://www.mozilla.org/en-US/firefox/new/">Firefox</a> and <a href="https://www.mozilla.org/en-US/products/vpn/?entrypoint_experiment=vpn-pricing-position&amp;entrypoint_variation=1">Mozilla VPN</a> – that put people’s privacy needs first so you can count on <a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">Mozilla Monitor</a> as an ally in reclaiming your privacy. In order to get a free scan and sign up for the paid automated data removal, you’ll need to get a <a href="https://www.mozilla.org/en-US/firefox/accounts/">Mozilla Account </a>(previously known as a <a href="https://blog.mozilla.org/en/mozilla/firefox-accounts-transition-mozilla-accounts/">Firefox Account</a>). With a Mozilla Account, you’ll get security benefits such as two-factor authentication powered by Mozilla, as well as backed by Mozilla’s <a href="https://www.mozilla.org/en-US/about/legal/terms/services/">terms of service</a> and <a href="https://www.mozilla.org/en-US/privacy/mozilla-accounts/">privacy policy</a>. To learn about the benefits of having a Mozilla Account, <a href="https://blog.mozilla.org/en/products/firefox/firefox-tips/firefox-account-password-manager-bookmarks-credit-card-autofill/">click here</a>.</p>



<figure><p>
<iframe title="Take back your privacy with Mozilla Monitor Plus" width="640" height="360" src="https://www.youtube.com/embed/WOBGckoAgq8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>







<a href="https://monitor.firefox.com/?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_campaign=monitor-plus-launch-us&amp;utm_content=introduction-us">
  <p><img width="200" height="200" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/01/moz_monitor_mdn_ad_01_260x200-200x200.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/01/moz_monitor_mdn_ad_01_260x200-200x200.png 200w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/01/moz_monitor_mdn_ad_01_260x200-150x150.png 150w" sizes="(max-width: 200px) 100vw, 200px">  </p>
  <div>
     <h3>Find out where your private info is exposed – and take it back</h3>      <p><span>Try a free scan today with Mozilla Monitor!</span>   </p></div>
</a>












  </div>

</article><!-- #post-74078 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dean of Engineering at University of Nevada wrote a paper that’s bad (114 pts)]]></title>
            <link>https://statmodeling.stat.columbia.edu/2024/02/06/its-bezzle-time-the-dean-of-engineering-at-the-university-of-nevada-gets-paid-372127-a-year-and-wrote-a-paper-thats-so-bad-you-cant-believe-it-i-mean-really-you-have-to-take-a-look-at-t/</link>
            <guid>39274461</guid>
            <pubDate>Tue, 06 Feb 2024 14:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://statmodeling.stat.columbia.edu/2024/02/06/its-bezzle-time-the-dean-of-engineering-at-the-university-of-nevada-gets-paid-372127-a-year-and-wrote-a-paper-thats-so-bad-you-cant-believe-it-i-mean-really-you-have-to-take-a-look-at-t/">https://statmodeling.stat.columbia.edu/2024/02/06/its-bezzle-time-the-dean-of-engineering-at-the-university-of-nevada-gets-paid-372127-a-year-and-wrote-a-paper-thats-so-bad-you-cant-believe-it-i-mean-really-you-have-to-take-a-look-at-t/</a>, See on <a href="https://news.ycombinator.com/item?id=39274461">Hacker News</a></p>
Couldn't get https://statmodeling.stat.columbia.edu/2024/02/06/its-bezzle-time-the-dean-of-engineering-at-the-university-of-nevada-gets-paid-372127-a-year-and-wrote-a-paper-thats-so-bad-you-cant-believe-it-i-mean-really-you-have-to-take-a-look-at-t/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What Happened with the Web Monetization API? (109 pts)]]></title>
            <link>https://chriscoyier.net/2024/01/24/what-happened-with-the-web-monetization-api/</link>
            <guid>39274455</guid>
            <pubDate>Tue, 06 Feb 2024 14:23:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriscoyier.net/2024/01/24/what-happened-with-the-web-monetization-api/">https://chriscoyier.net/2024/01/24/what-happened-with-the-web-monetization-api/</a>, See on <a href="https://news.ycombinator.com/item?id=39274455">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I was <a href="https://css-tricks.com/more-people-dipping-toes-into-web-monetization/">pretty hot on it for a minute</a>. I wanted it to succeed and thought it had the bones to make it. Coil was the main startup trying to push it. They did the right thing by just making it work first, showing there is interest, then pushing to get it standardized. But <a href="https://www.coil.com/">Coil failed</a>. </p>
<blockquote>
<p>When we started Coil in 2018, Interledger was only an idea. Over the last five years we breathed life into the technology and sparked a vibrant ecosystem around it. Now it’s time to pass the torch to a neutral body in the form of the&nbsp;<a href="https://interledger.org/">Interledger&nbsp;Foundation</a>&nbsp;to steward the future development of Interledger.</p>
</blockquote>
<p>I don’t know much about Interledger. It seems alive-<em>ish</em>? They had a “Summit” recently and <a href="https://www.youtube.com/watch?v=qmjeQb79mwQ">I watched some of it</a> but it didn’t do much for my understanding.</p>
<p>Then recently I saw <a href="https://xoxo.zone/@sara/111774573812373512">a good thread</a> from <a href="https://sarafen.com/">Sara</a> including this:</p>
<figure><img fetchpriority="high" decoding="async" width="1024" height="768" data-attachment-id="11027" data-permalink="https://chriscoyier.net/2024/01/24/what-happened-with-the-web-monetization-api/958shots_so/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?fit=1920%2C1440&amp;ssl=1" data-orig-size="1920,1440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="958shots_so" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?fit=1024%2C768&amp;ssl=1" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2024/01/958shots_so.png?w=1920&amp;ssl=1 1920w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>
<p>Sara started it by saying that she just wants to “click a little button and send money from me to the person/org/persons operating a website”. Totally! I’m obsessed with that use case. It needs to be built into the browsers and web standards such that it’s incredibly smooth and fast. I wanna send $1 to a website, it happens instantly and anonymously, and the developer can do things around this. Like unlock features! For instance, stop showing ads, offer more complete downloads, unlock tutorial courses, etc. Make it <em>easier</em> and <em>faster</em> than using a credit card.</p>
<p>It appears that the Web Monetization API is up to the task. I friggin’ love the example of how to use it as a developer:</p>
<pre aria-describedby="shcb-language-1" data-shcb-language-name="HTML, XML" data-shcb-language-slug="xml"><span><code><span>&lt;!doctype <span>html</span>&gt;</span>
<span>&lt;<span>html</span> <span>lang</span>=<span>"en"</span>&gt;</span>
  <span>&lt;<span>head</span>&gt;</span>
    <span>&lt;<span>meta</span> <span>charset</span>=<span>"utf-8"</span> /&gt;</span>
    <span>&lt;<span>title</span>&gt;</span>My Blog<span>&lt;/<span>title</span>&gt;</span>
    <span>&lt;<span>link</span>
      <span>rel</span>=<span>"monetization"</span>
      <span>href</span>=<span>"https://example.com/pay"</span>
      <span>onmonetization</span>=<span>"sayThanks(this)"</span>
    /&gt;</span>
    <span>&lt;<span>script</span>&gt;</span><span>
      <span><span>function</span> <span>sayThanks</span><span>(monetizedLink)</span> </span>{
        <span>// Do something here</span>
      }
    </span><span>&lt;/<span>script</span>&gt;</span>
  <span>&lt;/<span>head</span>&gt;</span>
  <span>&lt;<span>body</span>&gt;</span><span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span></code></span><small id="shcb-language-1"><span>Code language:</span> <span>HTML, XML</span> <span>(</span><span>xml</span><span>)</span></small></pre>
<p>And of course there are more APIs, like for checking how much a user contributed, if they have already contributed, etc. </p>
<p>Does it have legs anymore? I just have no idea. Sorry if the title of the post led you to believe I might have an answer. I’m just <em>looking</em> for the answer.</p>
<p>Again though, poking a button to send a website bucks through web standards is a great idea. </p>
<p>I’ll leave it with my favorite use case (removing ads) and what I’ve written before, in hopes that this part can be done right:</p>
<blockquote>
<p>Removing ads is the most basic and obvious use case, and I hope some people give that a healthy try. […] I’d want to clearly be able to control the dollar-level of when you get that perk, but more importantly, in order to really make good on the promise of not delivering ads, you need to know very quickly if any given user is supporting you at the required level or not. For example, you can’t wait 2600 milliseconds to decide whether ads need to be requested. Well, you can, but you’ll wreck your ad revenue. And you can’t simply request the ads and hide them when you find out, lest you are not really making good on a promise, as trackers’n’stuff will have already done their thing.</p>
</blockquote>
<h2>Update: The Answer</h2>

<p><a href="https://www.quirksmode.org/about/">PPK</a> is now DevRel for the Interledger Foundation, so apparently it’s heating up again. The news is that the API will hook up to an online “wallet” powered by <a href="https://fynbos.app/">fynbos</a>. I’ve never heard of it, but it looks like it connects to banks and credit cards, not crypto. It’s not that I’m some big stan for Big Banks, but crypto was (is) just so absolutely riddled with scams and crime that I just can’t anymore. Decoupling the Web Payments API and crypto is certainly the right move right now.</p>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prisoners in the US are part of a hidden workforce linked to popular food brands (183 pts)]]></title>
            <link>https://english.elpais.com/usa/2024-01-29/prisoners-in-the-us-are-part-of-a-hidden-workforce-linked-to-hundreds-of-popular-food-brands.html</link>
            <guid>39274128</guid>
            <pubDate>Tue, 06 Feb 2024 13:50:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/usa/2024-01-29/prisoners-in-the-us-are-part-of-a-hidden-workforce-linked-to-hundreds-of-popular-food-brands.html">https://english.elpais.com/usa/2024-01-29/prisoners-in-the-us-are-part-of-a-hidden-workforce-linked-to-hundreds-of-popular-food-brands.html</a>, See on <a href="https://news.ycombinator.com/item?id=39274128">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>A hidden path to America’s dinner tables begins here, at an unlikely source – a former Southern slave plantation that is now the country’s largest maximum-security prison.</p><p>Unmarked trucks packed with prison-raised cattle roll out of the Louisiana State Penitentiary, where men are sentenced to hard labor and forced to work, for pennies an hour or sometimes nothing at all. After rumbling down a country road to an auction house, the cows are bought by a local rancher and then followed by The Associated Press another 600 miles to a Texas slaughterhouse that feeds into the supply chains of giants like McDonald’s, Walmart and Cargill.</p><p>Intricate, invisible webs, just like this one, link some of the world’s largest food companies and most popular brands to jobs performed by U.S. prisoners nationwide, according to a sweeping two-year AP investigation into<a href="https://english.elpais.com/international/2023-01-27/russia-plans-to-build-25-prisons-and-three-forced-labor-camps-in-occupied-areas-of-ukraine.html"> prison labor</a> that tied hundreds of millions of dollars’ worth of agricultural products to goods sold on the open market.</p><p>They are among America’s most <a href="https://english.elpais.com/usa/2023-08-15/advocates-sue-federal-government-for-failing-to-ban-imports-of-cocoa-harvested-by-children.html">vulnerable laborers</a>. If they refuse to work, some can jeopardize their chances of parole or face punishment like being sent to solitary confinement. They also are often excluded from protections guaranteed to almost all other full-time workers, even when they are seriously injured or killed on the job.</p><p>The goods these prisoners produce wind up in the supply chains of a dizzying array of products found in most American kitchens, from Frosted Flakes cereal and Ball Park hot dogs to Gold Medal flour, Coca-Cola and Riceland rice. They are on the shelves of virtually every supermarket in the country, including Kroger, Target, Aldi and Whole Foods. And some goods are exported, including to countries that have had products blocked from entering the U.S. for using forced or prison labor.</p><p>Many of the companies buying directly from prisons are violating their own policies against the use of such labor. But it’s completely legal, dating back largely to the need for labor to help rebuild the South’s shattered economy after the Civil War. Enshrined in the Constitution by the 13th Amendment, <a href="https://english.elpais.com/society/2023-01-03/the-dark-side-of-textiles-my-fingers-were-bleeding-but-they-forced-me-to-work.html">slavery</a> and involuntary servitude are banned – except as punishment for a crime.</p><p>That clause is currently being challenged on the federal level, and efforts to remove similar language from state constitutions are expected to reach the ballot in about a dozen states this year.</p><p>Some prisoners work on the same plantation soil where slaves harvested cotton, tobacco and sugarcane more than 150 years ago, with some present-day images looking eerily similar to the past. In Louisiana, which has one of the country’s highest incarceration rates, men working on the “farm line” still stoop over crops stretching far into the distance.</p><p>Willie Ingram picked everything from cotton to okra during his 51 years in the state penitentiary, better known as Angola.</p><p>During his time in the fields, he was overseen by armed guards on horseback and recalled seeing men, working with little or no water, passing out in triple-digit heat. Some days, he said, workers would throw their tools in the air to protest, despite knowing the potential consequences.</p><p>“They’d come, maybe four in the truck, shields over their face, billy clubs, and they’d beat you right there in the field. They beat you, handcuff you and beat you again,” said Ingram, who received a life sentence after pleading guilty to a crime he said he didn’t commit. He was told he would serve 10 ½ years and avoid a possible death penalty, but it wasn’t until 2021 that a sympathetic judge finally released him. He was 73.</p><p>The number of people behind bars in the United States started to soar in the 1970s just as Ingram entered the system, disproportionately hitting people of color. Now, with about 2 million people locked up, U.S. prison labor from all sectors has morphed into a multibillion-dollar empire, extending far beyond the classic images of prisoners stamping license plates, working on road crews or battling wildfires.</p><p>Though almost every state has some kind of farming program, agriculture represents only a small fraction of the overall prison workforce. Still, an analysis of data amassed by the AP from correctional facilities nationwide traced nearly $200 million worth of sales of farmed goods and livestock to businesses over the past six years – a conservative figure that does not include tens of millions more in sales to state and government entities. Much of the data provided was incomplete, though it was clear that the biggest revenues came from sprawling operations in the South and leasing out prisoners to companies.</p><p>Corrections officials and other proponents note that not all work is forced and that prison jobs save taxpayers money. For example, in some cases, the food produced is served in prison kitchens or donated to those in need outside. They also say workers are learning skills that can be used when they’re released and given a sense of purpose, which could help ward off repeat offenses. In some places, it allows prisoners to also shave time off their sentences. And the jobs provide a way to repay a debt to society, they say.</p><p>While most critics don’t believe all jobs should be eliminated, they say incarcerated people should be paid fairly, treated humanely and that all work should be voluntary. Some note that even when people get specialized training, like firefighting, their criminal records can make it almost impossible to get hired on the outside.</p><p>“They are largely uncompensated, they are being forced to work, and it’s unsafe. They also aren’t learning skills that will help them when they are released,” said law professor Andrea Armstrong, an expert on prison labor at Loyola University New Orleans. “It raises the question of why we are still forcing people to work in the fields.”</p><h3>A shadow workforce with few protections</h3><p>In addition to tapping a cheap, reliable workforce, companies sometimes get tax credits and other financial incentives. Incarcerated workers also typically aren’t covered by the most basic protections, including workers’ compensation and federal safety standards. In many cases, they cannot file official complaints about poor working conditions.</p><p>These prisoners often work in industries with severe labor shortages, doing some of the country’s dirtiest and most dangerous jobs.</p><p>The AP sifted through thousands of pages of documents and spoke to more than 80 current or formerly incarcerated people, including men and women convicted of crimes that ranged from murder to shoplifting, writing bad checks, theft or other illegal acts linked to drug use. Some were given long sentences for nonviolent offenses because they had previous convictions, while others were released after proving their innocence.</p><p>Reporters found people who were hurt or maimed on the job, and also interviewed women who were sexually harassed or abused, sometimes by their civilian supervisors or the correctional officers overseeing them. While it’s often nearly impossible for those involved in workplace accidents to sue, the AP examined dozens of cases that managed to make their way into the court system. Reporters also spoke to family members of prisoners who were killed.</p><p>One of those was Frank Dwayne Ellington, who was sentenced to life in prison with the possibility of parole after stealing a man’s wallet at gunpoint – a result of Alabama’s habitual offenders act. In 2017, Ellington, 33, was cleaning a machine near the chicken “kill line” in Ashland at Koch Foods – one of the country’s biggest poultry-processing companies – when its whirling teeth caught his arm and sucked him inside, crushing his skull. He died instantly.</p><p>During a yearslong legal battle, Koch Foods at first argued Ellington wasn’t technically an employee, and later said his family should be barred from filing for wrongful death because the company had paid his funeral expenses. The case eventually was settled under undisclosed terms. The Occupational Safety and Health Administration fined the company $19,500, saying workers had not been given proper training and that its machines had inadequate safety guards.</p><p>“It’s somebody’s child, it’s somebody’s dad, it’s somebody’s uncle, it’s somebody’s family,” said Ellington’s mother, Alishia Powell-Clark. “Yes, they did wrong, but they are paying for it.”</p><p>The AP found that U.S. prison labor is in the supply chains of goods being shipped all over the world via multinational companies, including to countries that have been slapped with import bans by Washington in recent years. For instance, the U.S. has blocked shipments of cotton coming from China, a top manufacturer of popular clothing brands, because it was produced by forced or prison labor. But crops harvested by U.S. prisoners have entered the supply chains of companies that export to China.</p><p>While prison labor seeps into the supply chains of some companies through third-party suppliers without them knowing, others buy direct. Mammoth commodity traders that are essential to feeding the globe like Cargill, Bunge, Louis Dreyfus, Archer Daniels Midland and Consolidated Grain and Barge – which together post annual revenues of more than $400 billion – have in recent years scooped up millions of dollars’ worth of soy, corn and wheat straight from prisons, which compete with local farmers.</p><p>The AP reached out for comment to the companies it identified as having connections to prison labor, but most did not respond.</p><p>Cargill acknowledged buying goods from prison farms in Tennessee, Arkansas and Ohio, saying they constituted only a small fraction of the company’s overall volume. It added that “we are now in the process of determining the appropriate remedial action.”</p><p>McDonald’s said it would investigate links to any such labor, while Archer Daniels Midland and General Mills, which produces Gold Medal flour, pointed to their policies in place restricting suppliers from using <a href="https://english.elpais.com/international/2023-10-24/forced-labor-concerns-prompt-us-lawmakers-to-demand-ban-on-seafood-from-two-chinese-provinces.html">forced labor</a>. Whole Foods responded flatly: “Whole Foods Market does not allow the use of prison labor in products sold at our stores.”</p><p>Bunge said it sold all facilities that were sourcing from correction departments in 2021, so they are “no longer part of Bunge’s footprint.”</p><p>Dairy Farmers of America, a cooperative that bills itself as the top supplier of raw milk worldwide, said that while it has been buying from correctional facilities, it now only has one “member dairy” at a prison, with most of that milk used inside.</p><p>To understand the business of prison labor and the complex movement of agricultural goods, the AP collected information from all 50 states, through public records requests and inquiries to corrections departments. Reporters also crisscrossed the country, following trucks transporting crops and livestock linked to prison work, and tailed transport vans from prisons and work-release sites heading to places such as poultry plants, egg farms and fast-food restaurants. A lack of transparency and, at times, baffling losses exposed in audits, added to the challenges of fully tracking the money.</p><p>Big-ticket items like row crops and livestock are sold on the open market, with profits fed back into agriculture programs. For instance, about a dozen state prison farms, including operations in Texas, Virginia, Kentucky and Montana, have sold more than $60 million worth of cattle since 2018.</p><p>As with other sales, the custody of cows can take a serpentine route. Because they often are sold online at auction houses or to stockyards, it can be almost impossible to determine where the beef eventually ends up.</p><p>Sometimes there’s only one way to know for sure. In Louisiana, an AP reporter watched as three long trailers loaded with more than 80 cattle left the state penitentiary. The cows raised by prisoners traveled for about an hour before being unloaded for sale at Dominique’s Livestock Market in Baton Rouge.</p><p>As they were shoved through a gate into a viewing pen, the auctioneer jokingly warned buyers “Watch out!” The cows, he said, had just broken out of prison.</p><p>Within minutes, the Angola lot was snapped up by a local livestock dealer, who then sold the cattle to a Texas beef processor that also buys cows directly from prisons in that state. Meat from the slaughterhouse winds up in the supply chains of some of the country’s biggest fast-food chains, supermarkets and meat exporters, including Burger King, Sam’s Club and Tyson Foods.</p><p>“It’s a real slap in the face, to hear where all those cattle are going,” said Jermaine Hudson, who served 22 years at Angola on a robbery conviction before he was exonerated.</p><p>He said it’s especially galling because the food served in prison tasted like slop. “Those were some of the most disrespectful meals,” Hudson said, “that I ever, in my life, had to endure.”</p><h3>The rise of prison labor</h3><p>Angola is imposing in its sheer scale. The so-called “Alcatraz of the South” is tucked far away, surrounded by crocodile-infested swamps in a bend of the Mississippi River. It spans 18,000 acres – an area bigger than the island of Manhattan – and has its own ZIP code.</p><p>The former 19th-century antebellum plantation once was owned by one of the largest slave traders in the U.S. Today, it houses some 3,800 men behind its razor-wire walls, about 65 percent of them Black. Within days of arrival, they typically head to the fields, sometimes using hoes and shovels or picking crops by hand. They initially work for free, but then can earn between 2 cents and 40 cents an hour.</p><p>Calvin Thomas, who spent more than 17 years at Angola, said anyone who refused to work, didn’t produce enough or just stepped outside the long straight rows knew there would be consequences.</p><p>“If he shoots the gun in the air because you done passed that line, that means you’re going to get locked up and you’re going to have to pay for that bullet that he shot,” said Thomas, adding that some days were so blistering hot the guards’ horses would collapse. “You can’t call it anything else,” he said. “<a href="https://english.elpais.com/usa/2023-09-22/the-emancipation-proclamation-the-first-step-towards-the-end-of-slavery-in-the-us.html">It’s just slavery.”</a></p><p>Louisiana corrections spokesman Ken Pastorick called that description “absurd.” He said the phrase “sentenced with hard labor” is a legal term referring to a prisoner with a felony conviction.</p><p>Pastorick said the department has transformed Angola from “the bloodiest prison in America” over the past several decades with “large-scale criminal justice reforms and reinvestment into the creation of rehabilitation, vocational and educational programs designed to help individuals better themselves and successfully return to communities.” He noted that pay rates are set by state statute.</p><p>Current and former prisoners in both Louisiana and Alabama have filed class-action lawsuits in the past four months saying they have been forced to provide cheap – or free – labor to those states and outside companies, a practice they also described as slavery.</p><p>Prisoners have been made to work since before emancipation, when slaves were at times imprisoned and then leased out by local authorities.</p><p>But after the Civil War, the 13th Amendment’s exception clause that allows for prison labor provided legal cover to round up thousands of mostly young Black men. Many were jailed for petty offenses like loitering and vagrancy. They then were leased out by states to plantations like Angola and some of the country’s biggest companies, including coal mines and railroads. They were routinely whipped for not meeting quotas while doing brutal and often deadly work.</p><p>The convict-leasing period, which officially ended in 1928, helped chart the path to America’s modern-day prison-industrial complex.</p><p>Incarceration was used not just for punishment or rehabilitation but for profit. A law passed a few years later made it illegal to knowingly transport or sell goods made by incarcerated workers across state lines, though an exception was made for agricultural products. Today, after years of efforts by lawmakers and businesses, corporations are setting up joint ventures with corrections agencies, enabling them to sell almost anything nationwide.</p><p>Civilian workers are guaranteed basic rights and protections by OSHA and laws like the Fair Labor Standards Act, but prisoners, who are often not legally considered employees, are denied many of those entitlements and cannot protest or form unions.</p><p>“They may be doing the exact same work as people who are not incarcerated, but they don’t have the training, they don’t have the experience, they don’t have the protective equipment,” said Jennifer Turner, lead author of a 2022 American Civil Liberties Union report on prison labor.</p><p>Almost all of the country’s state and federal adult prisons have some sort of work program, employing around 800,000 people, the report said. It noted the vast majority of those jobs are connected to tasks like maintaining prisons, laundry or kitchen work, which typically pay a few cents an hour if anything at all. And the few who land the highest-paying state industry jobs may earn only a dollar an hour.</p><p>Altogether, labor tied specifically to goods and services produced through state prison industries brought in more than $2 billion in 2021, the ACLU report said. That includes everything from making mattresses to solar panels, but does not account for work-release and other programs run through local jails, detention and immigration centers and even drug and alcohol rehabilitation facilities.</p><p>Some incarcerated workers with just a few months or years left on their sentences have been employed everywhere from popular restaurant chains like Burger King to major retail stores and meat-processing plants. Unlike work crews picking up litter in orange jumpsuits, they go largely unnoticed, often wearing the same uniforms as their civilian counterparts.</p><p>Outside jobs can be coveted because they typically pay more and some states deposit a small percentage earned into a savings account for prisoners’ eventual release. Though many companies pay minimum wage, some states garnish more than half their salaries for items such as room and board and court fees.</p><p>It’s a different story for those on prison farms. The biggest operations remain in the South and crops are still harvested on a number of former slave plantations, including in Arkansas, Texas and at Mississippi’s notorious Parchman Farm. Those states, along with Florida, Alabama, South Carolina and Georgia, pay nothing for most types of work.</p><p>Most big farms, including Angola, have largely mechanized many of their operations, using commercial-size tractors, trucks and combines for corn, soy, rice and other row crops. But prisoners in some places continue to do other work by hand, including clearing brush with swing blades.</p><p>“I was in a field with a hoe in my hand with maybe like a hundred other women. We were standing in a line very closely together, and we had to raise our hoes up at the exact same time and count ‘One, two, three, chop!’” said Faye Jacobs, who worked on prison farms in Arkansas.</p><p>Jacobs, who was released in 2018 after more than 26 years, said the only pay she received was two rolls of toilet paper a week, toothpaste and a few menstrual pads each month.</p><p>She recounted being made to carry rocks from one end of a field to the other and back again for hours, and said she also endured taunting from guards saying “Come on, hos, it’s hoe squad!” She said she later was sent back to the fields at another prison after women there complained of sexual harassment by staff inside the facility.</p><p>“We were like ‘Is this a punishment?’” she said. “‘We’re telling y’all that we’re being sexually harassed, and you come back and the first thing you want to do is just put us all on hoe squad.’”</p><p>David Farabough, who oversees the state’s 20,000 acres of prison farms, said Arkansas’ operations can help build character.</p><p>“A lot of these guys come from homes where they’ve never understood work and they’ve never understood the feeling at the end of the day for a job well-done,” he said. “We’re giving them purpose. … And then at the end of the day, they get the return by having better food in the kitchens.”</p><p>In addition to giant farms, at least 650 correctional facilities nationwide have prisoners doing jobs like landscaping, tending greenhouses and gardens, raising livestock, beekeeping and even fish farming, said Joshua Sbicca, director of the Prison Agriculture Lab at Colorado State University. He noted that corrections officials exert power by deciding who deserves trade-building jobs like welding, for example, and who works in the fields.</p><p>In several states, along with raising chickens, cows and hogs, corrections departments have their own processing plants, dairies and canneries. But many states also hire out prisoners to do that same work at big private companies.</p><p>The AP met women in Mississippi locked up at restitution centers, the equivalent of debtors’ prisons, to pay off court-mandated expenses. They worked at Popeyes Louisiana Kitchen and other fast-food chains and also have been hired out to individuals for work like lawn mowing or home repairs.</p><p>“There is nothing innovative or interesting about this system of forced labor as punishment for what in so many instances is an issue of poverty or substance abuse,” said Cliff Johnson, director of the MacArthur Justice Center at the University of Mississippi.</p><p>In Alabama, where prisoners are leased out by companies, AP reporters followed inmate transport vans to poultry plants run by Tyson Foods, which owns brands such as Hillshire Farms, Jimmy Dean and Sara Lee, along with a company that supplies beef, chicken and fish to McDonald’s. The vans also stopped at a chicken processor that’s part of a joint-venture with Cargill, which is America’s largest private company. It brought in a record $177 billion in revenue in fiscal year 2023 and supplies conglomerates like PepsiCo.</p><p>Though Tyson did not respond to questions about direct links to prison farms, it said that its work-release programs are voluntary and that incarcerated workers receive the same pay as their civilian colleagues.</p><p>Some people arrested in Alabama are put to work even before they’ve been convicted. An unusual work-release program accepts pre-trial defendants, allowing them to avoid jail while earning bond money. But with multiple fees deducted from their salaries, that can take time.</p><p>The AP went out on a work detail with a Florida chain gang wearing black-and-white striped uniforms and ankle shackles, created after Brevard County Sheriff Wayne Ivey took office in 2012. He said the unpaid work is voluntary and so popular that it has a waitlist.</p><p>“It’s a win-win,” he said. “The inmate that’s doing that is learning a skill set. … They are making time go by at a faster pace. The other side of the win-win is, it’s generally saving the taxpayers money.”</p><p>Ivey noted it’s one of the only remaining places in the country where a chain gang still operates. “I don’t feel like they should get paid,” he said. “They’re paying back their debt to society for violating the law.”</p><p>Elsewhere, several former prisoners spoke positively about their work experiences, even if they sometimes felt exploited.</p><p>“I didn’t really think about it until I got out, and I was like, ‘Wow, you know, I actually took something from there and applied it out here,’” said William “Buck” Saunders, adding he got certified to operate a forklift at his job stacking animal feed at Cargill while incarcerated in Arizona.</p><p>Companies that hire prisoners get a reliable, plentiful workforce even during unprecedented labor shortages stemming from immigration crackdowns and, more recently, the coronavirus pandemic.</p><p>In March 2020, though all other outside company jobs were halted, the Arizona corrections department announced about 140 women were being abruptly moved from their prison to a metal hangar-like warehouse on property owned by Hickman’s Family Farms, which pitches itself as the Southwest’s largest egg producer.</p><p>Hickman’s has employed prisoners for nearly 30 years and supplies many grocery stores, including Costco and Kroger, marketing brands such as Eggland’s Best and Land O’Lakes. It is the state corrections department’s largest labor contractor, bringing in nearly $35 million in revenue over the past six fiscal years.</p><p>“The only reason they had us out there was because they didn’t want to lose that contract because the prison makes so much money off of it,” said Brooke Counts, who lived at Hickman’s desert site, which operated for 14 months. She was serving a drug-related sentence and said she feared losing privileges or being transferred to a more secure prison yard if she refused to work.</p><p>Counts said she knew prisoners who were seriously hurt, including one woman who was impaled in the groin and required a helicopter flight to the hospital and another who lost part of a finger.</p><p>Hickman’s, which has faced a number of lawsuits stemming from inmate injuries, did not respond to emailed questions or phone messages seeking a response. Corrections department officials would not comment on why the women were moved off-site, saying it happened during a previous administration. But a statement at the time said the move was made to “ensure a stable food supply while also protecting public health and the health of those in our custody.”</p><p>Some women employed by Hickman’s earned less than $3 an hour after deductions, including 30 percent taken by the state for room and board, even though they were living in the makeshift dormitory.</p><p>“While we were out there, we were still paying the prison rent,” Counts said. “What for?”</p><h3>Following the money</h3><p>The business of prison labor is so vast and convoluted that tracing the money can be challenging. Some agricultural programs regularly go into the red, raising questions in state audits and prompting investigations into potential corruption, mismanagement or general inefficiency.</p><p>Nearly half the agricultural goods produced in Texas between 2014 and 2018 lost money, for example, and a similar report in Louisiana uncovered losses of around $3.8 million between fiscal years 2016 and 2018. A separate federal investigation into graft at the for-profit arm of Louisiana’s correctional department led to the jailing of two employees.</p><p>Correctional officials say steep farming expenditures and unpredictable variables like weather can eat into profits. And while some goods may do poorly, they note, others do well.</p><p>Prisons at times have generated revenue by tapping into niche markets or to their states’ signature foods.</p><p>During the six-year period the AP examined, surplus raw milk from a Wisconsin prison dairy went to BelGioioso Cheese, which makes Polly-O string cheese and other products that land in grocery stores nationwide like Whole Foods. A California prison provided almonds to Minturn Nut Company, a major producer and exporter. And until 2022, Colorado was raising water buffalo for milk that was sold to giant mozzarella cheesemaker Leprino Foods, which supplies major pizza companies like Domino’s, Pizza Hut and Papa John’s.</p><p>But for many states, it’s the work-release programs that have become the biggest cash generators, largely because of the low overhead. In Alabama, for instance, the state brought in more than $32 million in the past five fiscal years after garnishing 40 percent of prisoners’ wages.</p><p>In some states, work-release programs are run on the local level, with sheriffs frequently responsible for handling the books and awarding contracts. Even though the programs are widely praised – by the state, employers and often prisoners themselves – reports of abuse exist.</p><p>In Louisiana, where more than 1,200 companies hire prisoners through work release, sheriffs get anywhere from about $10 to $20 a day for each state prisoner they house in local jails to help ease overcrowding. And they can deduct more than half of the wages earned by those contracted out to companies – a huge revenue stream for small counties.</p><p>Jack Strain, a former longtime sheriff in the state’s St. Tammany Parish, pleaded guilty in 2021 in a scheme involving the privatization of a work-release program in which nearly $1.4 million was taken in and steered to Strain, close associates and family members. He was sentenced to 10 years in prison, which came on top of four consecutive life sentences for a broader sex scandal linked to that same program.</p><p>Incarcerated people also have been contracted to companies that partner with prisons. In Idaho, they’ve sorted and packed the state’s famous potatoes, which are exported and sold to companies nationwide. In Kansas, they’ve been employed at Russell Stover chocolates and Cal-Maine Foods, the country’s largest egg producer. Though the company has since stopped using them, in recent years they were hired in Arizona by Taylor Farms, which sells salad kits in many major grocery stores nationwide and supplies popular fast-food chains and restaurants like Chipotle Mexican Grill.</p><p>Some states would not provide the names of companies taking part in transitional prison work programs, citing security concerns. So AP reporters confirmed some prisoners’ private employers with officials running operations on the ground and also followed inmate transport vehicles as they zigzagged through cities and drove down country roads. The vans stopped everywhere from giant meat-processing plants to a chicken and daiquiri restaurant.</p><p>One pulled into the manicured grounds of a former slave plantation that has been transformed into a popular tourist site and hotel in St. Francisville, Louisiana, where visitors pose for wedding photos under old live oaks draped with Spanish moss.</p><p>As a reporter watched, a West Feliciana Parish van emblazoned with “Sheriff Transitional Work Program” pulled up. Two Black men hopped out and quickly walked through the restaurant’s back door. One said he was there to wash dishes before his boss called him back inside.</p><p>The Myrtles, as the antebellum home is known, sits just 20 miles away from where men toil in the fields of Angola.</p><p>“Slavery has not been abolished,” said Curtis Davis, who spent more than 25 years at the penitentiary and is now fighting to change state laws that allow for forced labor in prisons. “It is still operating in present tense,” he said. “Nothing has changed.”</p><p><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i>Sign up</i></a><i> for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NetBox.dev: the source of truth for everything on your network (134 pts)]]></title>
            <link>https://netbox.dev/</link>
            <guid>39274125</guid>
            <pubDate>Tue, 06 Feb 2024 13:49:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://netbox.dev/">https://netbox.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=39274125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>
        <div>

                    <article>
                        
                            <section><p>NetBox v3.7.2 is <a href="https://github.com/netbox-community/netbox/releases/tag/v3.7.2">now available</a>!</p>
<h3>Enhancements</h3>
<ul>
<li><a href="https://github.com/netbox-community/netbox/issues/13729">#13729</a> - Omit sensitive data source parameters from change log data</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14645">#14645</a> - Limit the number of assigned IP addresses displayed under interfaces list</li>
</ul>
<h3>Bug Fixes</h3>
<ul>
<li><a href="https://github.com/netbox-community/netbox/issues/14500">#14500</a> - Optimize calculation of available child prefixes &amp; ranges when viewing a prefix</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14511">#14511</a> - Fix GraphQL support for interfaces connected to provider networks</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14572">#14572</a> - Correct the number of jobs listed for individual report &amp; script modules</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14703">#14703</a> - Revert to the default layout when encountering a misconfigured dashboard</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14755">#14755</a> - Fix validation of choice values &amp; labels when creating a custom field choice set via the REST API</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14838">#14838</a> - Avoid corrupting JSON data when changing the action type while editing an event rule</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14839">#14839</a> - Fix form validation error when attempting to terminate a tunnel to a virtual machine interface</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14840">#14840</a> - Fix <code>NoReverseMatch</code> exception when rendering a custom field which references a user</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14847">#14847</a> - IKE policy mode may be set inly when IKEv1 is selected</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14851">#14851</a> - Automatically remove any associated bookmarks when deleting a user</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14879">#14879</a> - Include custom fields in REST API representation of data sources</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14885">#14885</a> - Add missing "group" field to VPN tunnel creation form</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14892">#14892</a> - Fix exception when running report/script via command line due to missing username</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14920">#14920</a> - Include button to display available status choices when bulk importing virtual device contexts</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14945">#14945</a> - Fix "select all" button for device type components</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14947">#14947</a> - Ensure that application &amp; removal of tags is always recorded in an object's change log</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14962">#14962</a> - Fix config context rendering for VMs assigned directly to a site (rather than via a cluster)</li>
<li><a href="https://github.com/netbox-community/netbox/issues/14999">#14999</a> - Fix "create &amp; add another" link for interface FHRP group assignment</li>
<li><a href="https://github.com/netbox-community/netbox/issues/15015">#15015</a> - Pre-populate assigned tenant when allocating next available IP address under prefix view</li>
<li><a href="https://github.com/netbox-community/netbox/issues/15020">#15020</a> - Automatically update all VMs when changing a cluster's assigned site</li>
<li><a href="https://github.com/netbox-community/netbox/issues/15025">#15025</a> - The <code>can_add()</code> template filter should accept a model (not an instance)</li>
</ul></section>
                        
                    </article>

                    

                    <h2>Older Posts</h2>
                    <p>
                    
                        
                            <a href="https://netbox.dev/blog/posts/netbox-v372-released/">NetBox v3.7.2 Released</a> - (Feb. 5, 2024)<br>
                        
                    
                        
                            <a href="https://netbox.dev/blog/posts/netbox-v371-released/">NetBox v3.7.1 Released</a> - (Jan. 17, 2024)<br>
                        
                    
                        
                            <a href="https://netbox.dev/blog/posts/netbox-v370-released/">NetBox v3.7.0 Released</a> - (Dec. 29, 2023)<br>
                        
                    
                        
                            <a href="https://netbox.dev/blog/posts/netbox-v369-released/">NetBox v3.6.9 Released</a> - (Dec. 28, 2023)<br>
                        
                    
                        
                            <a href="https://netbox.dev/blog/posts/netbox-v368-released/">NetBox v3.6.8 Released</a> - (Dec. 27, 2023)<br>
                        
                    
                    </p>

                </div>
    </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PostgreSQL is enough (298 pts)]]></title>
            <link>https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb</link>
            <guid>39273954</guid>
            <pubDate>Tue, 06 Feb 2024 13:28:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb">https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb</a>, See on <a href="https://news.ycombinator.com/item?id=39273954">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  

<div>
  <div>
      <p><a data-hovercard-type="user" data-hovercard-url="/users/cpursley/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://gist.github.com/cpursley"><img src="https://avatars.githubusercontent.com/u/1223773?s=64&amp;v=4" width="32" height="32" alt="@cpursley"></a>
      </p>
      
    </div>

  <ul>



      <li>
          <a id="gist-star-button-count" href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fcpursley%2Fc8fb81fe8a7e5df038158bdfe0f06dbb" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;gist star button&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f33ae6740decd55d0247778ab9d3c57c5e04bd18fd8ad90a7e91f4ec6b956b89" data-view-component="true">  <span>
      <span>
        
      </span>
    <span>Star</span>
      <span>
        <span title="132" data-view-component="true">132</span>
      </span>
  </span>
</a><tool-tip id="tooltip-3fb8c457-d86d-4885-9c5e-015af88ad9ea" for="gist-star-button-count" popover="manual" data-direction="n" data-type="description" data-view-component="true">You must be signed in to star a gist</tool-tip>

      </li>

        <li>
            <a id="gist-fork-button" href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fcpursley%2Fc8fb81fe8a7e5df038158bdfe0f06dbb" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;gist fork button&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="1c843e33ea868895c0cbfec380e36ebdb001a3774c1da8b3d3fe7726aba78288" data-view-component="true">  <span>
      <span>
        
      </span>
    <span>Fork</span>
      <span>
        <span title="10" data-view-component="true">10</span>
      </span>
  </span>
</a><tool-tip id="tooltip-6bfd51aa-75be-4839-8876-92564b76115c" for="gist-fork-button" popover="manual" data-direction="n" data-type="description" data-view-component="true">You must be signed in to fork a gist</tool-tip>

        </li>
  </ul>
</div>

  <div>
      <p><a id="gist-star-button-no-count" href="https://gist.github.com/login?return_to=https%3A%2F%2Fgist.github.com%2Fcpursley%2Fc8fb81fe8a7e5df038158bdfe0f06dbb" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;gist star button&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f33ae6740decd55d0247778ab9d3c57c5e04bd18fd8ad90a7e91f4ec6b956b89" data-view-component="true">  <span>
      <span>
        
      </span>
    <span>Star</span>
  </span>
</a></p><tool-tip id="tooltip-152ea89a-c0b2-481d-b903-82cb101adb1a" for="gist-star-button-no-count" popover="manual" data-direction="n" data-type="description" data-view-component="true">You must be signed in to star a gist</tool-tip>

  </div>

<div data-multiple="">

    <div data-view-component="true">
  <action-menu data-menu-input="gist-share-url" data-select-variant="single" data-dynamic-label="" data-view-component="true">
  <focus-group direction="vertical" mnemonics="" retain="">
    


  </focus-group>
</action-menu>    <primer-text-field>
      <label for="gist-share-url">
        Clone this repository at &amp;lt;script src=&amp;quot;https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
</label>    
  
      
    
</primer-text-field>
  <clipboard-copy id="clipboard-button" aria-label="Copy" for="gist-share-url" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;COPY_URL&quot;,&quot;git_repository_type&quot;:&quot;GIST&quot;,&quot;gist_id&quot;:124177998,&quot;originating_url&quot;:&quot;https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2b6b58b37cb1b078fd6ed83fa3dd7895477f941ed3eaa75bf4c3d052bfb99e42" type="button" data-view-component="true">
    
    
</clipboard-copy>

</div>

      <tool-tip id="tooltip-c9dfa042-3ae4-4184-8f84-091f39db4e0d" for="icon-button-c42a207d-3b68-4762-b6f3-eab9d7f9b27d" popover="manual" data-direction="s" data-type="label" data-view-component="true">Save cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb to your computer and use it in GitHub Desktop.</tool-tip>



    
  </div>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Command Line Interface Guidelines (230 pts)]]></title>
            <link>https://clig.dev/</link>
            <guid>39273932</guid>
            <pubDate>Tue, 06 Feb 2024 13:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clig.dev/">https://clig.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=39273932">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>An <a href="https://github.com/cli-guidelines/cli-guidelines">open-source</a> guide to help you write better command-line programs, taking traditional UNIX principles and updating them for the modern day.</p>

<p><strong>Aanand Prasad</strong><br>
Engineer at Squarespace, co-creator of Docker Compose.<br>
<a href="https://twitter.com/aanandprasad">@aanandprasad</a></p>
<p><strong>Ben Firshman</strong><br>
Co-creator <a href="https://replicate.ai/">Replicate</a>, co-creator of Docker Compose.<br>
<a href="https://twitter.com/bfirsh">@bfirsh</a></p>
<p><strong>Carl Tashian</strong><br>
Developer Advocate at <a href="https://smallstep.com/">Smallstep</a>, first engineer at Zipcar, co-founder Trove.<br>
<a href="https://tashian.com/">tashian.com</a> <a href="https://twitter.com/tashian">@tashian</a></p>
<p><strong>Eva Parish</strong><br>
Technical Writer at Squarespace, O’Reilly contributor.<br>
<a href="https://evaparish.com/">evaparish.com</a> <a href="https://twitter.com/evpari">@evpari</a></p>
<p>Design by <a href="https://mhurrell.co.uk/">Mark Hurrell</a>. Thanks to Andreas Jansson for early contributions, and Andrew Reitz, Ashley Williams, Brendan Falk, Chester Ramey, Dj Walker-Morgan, Jacob Maine, James Coglan, Michael Dwan, and Steve Klabnik for reviewing drafts.</p>

<p><a href="https://discord.gg/EbAW5rUCkE">Join us on Discord</a> if you want to discuss the guide or CLI design.</p>
<h2 id="foreword">Foreword</h2>
<p>In the 1980s, if you wanted a personal computer to do something for you, you needed to know what to type when confronted with <code>C:\&gt;</code> or <code>~$</code>.
Help came in the form of thick, spiral-bound manuals.
Error messages were opaque.
There was no Stack Overflow to save you.
But if you were lucky enough to have internet access, you could get help from Usenet—an early internet community filled with other people who were just as frustrated as you were.
They could either help you solve your problem, or at least provide some moral support and camaraderie.</p>
<p>Forty years later, computers have become so much more accessible to everyone, often at the expense of low-level end user control.
On many devices, there is no command-line access at all, in part because it goes against the corporate interests of walled gardens and app stores.</p>
<p>Most people today don’t know what the command line is, much less why they would want to bother with it.
As computing pioneer Alan Kay said in <a href="https://www.fastcompany.com/40435064/what-alan-kay-thinks-about-the-iphone-and-technology-now">a 2017 interview</a>, “Because people don’t understand what computing is about, they think they have it in the iPhone, and that illusion is as bad as the illusion that ‘Guitar Hero’ is the same as a real guitar.”</p>
<p>Kay’s “real guitar” isn’t the CLI—not exactly.
He was talking about ways of programming computers that offer the power of the CLI and that transcend writing software in text files.
There is a belief among Kay’s disciples that we need to break out of a text-based local maximum that we’ve been living in for decades.</p>
<p>It’s exciting to imagine a future where we program computers very differently.
Even today, spreadsheets are by far the most popular programming language, and the no-code movement is taking off quickly as it attempts to replace some of the intense demand for talented programmers.</p>
<p>Yet with its creaky, decades-old constraints and inexplicable quirks, the command line is still the most <em>versatile</em> corner of the computer.
It lets you pull back the curtain, see what’s really going on, and creatively interact with the machine at a level of sophistication and depth that GUIs cannot afford.
It’s available on almost any laptop, for anyone who wants to learn it.
It can be used interactively, or it can be automated.
And, it doesn’t change as fast as other parts of the system.
There is creative value in its stability.</p>
<p>So, while we still have it, we should try to maximize its utility and accessibility.</p>
<p>A lot has changed about how we program computers since those early days.
The command line of the past was <em>machine-first</em>: little more than a REPL on top of a scripting platform.
But as general-purpose interpreted languages have flourished, the role of the shell script has shrunk.
Today’s command line is <em>human-first</em>: a text-based UI that affords access to all kinds of tools, systems and platforms.
In the past, the editor was inside the terminal—today, the terminal is just as often a feature of the editor.
And there’s been a proliferation of <code>git</code>-like multi-tool commands.
Commands within commands, and high-level commands that perform entire workflows rather than atomic functions.</p>
<p>Inspired by traditional UNIX philosophy, driven by an interest in encouraging a more delightful and accessible CLI environment, and guided by our experiences as programmers, we decided it was time to revisit the best practices and design principles for building command-line programs.</p>
<p>Long live the command line!</p>
<h2 id="introduction">Introduction</h2>
<p>This document covers both high-level design philosophy, and concrete guidelines.
It’s heavier on the guidelines because our philosophy as practitioners is not to philosophize too much.
We believe in learning by example, so we’ve provided plenty of those.</p>
<p>This guide doesn’t cover full-screen terminal programs like emacs and vim.
Full-screen programs are niche projects—very few of us will ever be in the position to design one.</p>
<p>This guide is also agnostic about programming languages and tooling in general.</p>
<p>Who is this guide for?</p>
<ul>
<li>If you are creating a CLI program and you are looking for principles and concrete best practices for its UI design, this guide is for you.</li>
<li>If you are a professional “CLI UI designer,” that’s amazing—we’d love to learn from you.</li>
<li>If you’d like to avoid obvious missteps of the variety that go against 40 years of CLI design conventions, this guide is for you.</li>
<li>If you want to delight people with your program’s good design and helpful help, this guide is definitely for you.</li>
<li>If you are creating a GUI program, this guide is not for you—though you may learn some GUI anti-patterns if you decide to read it anyway.</li>
<li>If you are designing an immersive, full-screen CLI port of Minecraft, this guide isn’t for you.
(But we can’t wait to see it!)</li>
</ul>
<h2 id="philosophy">Philosophy</h2>
<p>These are what we consider to be the fundamental principles of good CLI design.</p>
<h3 id="human-first-design">Human-first design</h3>
<p>Traditionally, UNIX commands were written under the assumption they were going to be used primarily by other programs.
They had more in common with functions in a programming language than with graphical applications.</p>
<p>Today, even though many CLI programs are used primarily (or even exclusively) by humans, a lot of their interaction design still carries the baggage of the past.
It’s time to shed some of this baggage: if a command is going to be used primarily by humans, it should be designed for humans first.</p>
<h3 id="simple-parts-that-work-together">Simple parts that work&nbsp;together</h3>
<p>A core tenet of <a href="https://en.wikipedia.org/wiki/Unix_philosophy">the original UNIX philosophy</a> is the idea that small, simple programs with clean interfaces can be combined to build larger systems.
Rather than stuff more and more features into those programs, you make programs that are modular enough to be recombined as needed.</p>
<p>In the old days, pipes and shell scripts played a crucial role in the process of composing programs together.
Their role might have diminished with the rise of general-purpose interpreted languages, but they certainly haven’t gone away.
What’s more, large-scale automation—in the form of CI/CD, orchestration and configuration management—has flourished.
Making programs composable is just as important as ever.</p>
<p>Fortunately, the long-established conventions of the UNIX environment, designed for this exact purpose, still help us today.
Standard in/out/err, signals, exit codes and other mechanisms ensure that different programs click together nicely.
Plain, line-based text is easy to pipe between commands.
JSON, a much more recent invention, affords us more structure when we need it, and lets us more easily integrate command-line tools with the web.</p>
<p>Whatever software you’re building, you can be absolutely certain that people will use it in ways you didn’t anticipate.
Your software <em>will</em> become a part in a larger system—your only choice is over whether it will be a well-behaved part.</p>
<p>Most importantly, designing for composability does not need to be at odds with designing for humans first.
Much of the advice in this document is about how to achieve both.</p>
<h3 id="consistency-across-programs">Consistency across programs</h3>
<p>The terminal’s conventions are hardwired into our fingers.
We had to pay an upfront cost by learning about command line syntax, flags, environment variables and so on, but it pays off in long-term efficiency… as long as programs are consistent.</p>
<p>Where possible, a CLI should follow patterns that already exist.
That’s what makes CLIs intuitive and guessable; that’s what makes users efficient.</p>
<p>That being said, sometimes consistency conflicts with ease of use.
For example, many long-established UNIX commands don’t output much information by default, which can cause confusion or worry for people less familiar with the command line.</p>
<p>When following convention would compromise a program’s usability, it might be time to break with it—but such a decision should be made with care.</p>
<h3 id="saying-just-enough">Saying (just) enough</h3>
<p>The terminal is a world of pure information.
You could make an argument that information is the interface—and that, just like with any interface, there’s often too much or too little of it.</p>
<p>A command is saying too little when it hangs for several minutes and the user starts to wonder if it’s broken.
A command is saying too much when it dumps pages and pages of debugging output, drowning what’s truly important in an ocean of loose detritus.
The end result is the same: a lack of clarity, leaving the user confused and irritated.</p>
<p>It can be very difficult to get this balance right, but it’s absolutely crucial if software is to empower and serve its users.</p>
<h3 id="ease-of-discovery">Ease of discovery</h3>
<p>When it comes to making functionality discoverable, GUIs have the upper hand.
Everything you can do is laid out in front of you on the screen, so you can find what you need without having to learn anything, and perhaps even discover things you didn’t know were possible.</p>
<p>It is assumed that command-line interfaces are the opposite of this—that you have to remember how to do everything.
The original <a href="https://archive.org/details/applehumaninterf00appl">Macintosh Human Interface Guidelines</a>, published in 1987, recommend “See-and-point (instead of remember-and-type),” as if you could only choose one or the other.</p>
<p>These things needn’t be mutually exclusive.
The efficiency of using the command-line comes from remembering commands, but there’s no reason the commands can’t help you learn and remember.</p>
<p>Discoverable CLIs have comprehensive help texts, provide lots of examples, suggest what command to run next, suggest what to do when there is an error.
There are lots of ideas that can be stolen from GUIs to make CLIs easier to learn and use, even for power users.</p>
<p><em>Citation: The Design of Everyday Things (Don Norman), Macintosh Human Interface Guidelines</em></p>
<h3 id="conversation-as-the-norm">Conversation as the&nbsp;norm</h3>
<p>GUI design, particularly in its early days, made heavy use of <em>metaphor</em>: desktops, files, folders, recycle bins.
It made a lot of sense, because computers were still trying to bootstrap themselves into legitimacy.
The ease of implementation of metaphors was one of the huge advantages GUIs wielded over CLIs.
Ironically, though, the CLI has embodied an accidental metaphor all along: it’s a conversation.</p>
<p>Beyond the most utterly simple commands, running a program usually involves more than one invocation.
Usually, this is because it’s hard to get it right the first time: the user types a command, gets an error, changes the command, gets a different error, and so on, until it works.
This mode of learning through repeated failure is like a conversation the user is having with the program.</p>
<p>Trial-and-error isn’t the only type of conversational interaction, though.
There are others:</p>
<ul>
<li>Running one command to set up a tool and then learning what commands to run to actually start using it.</li>
<li>Running several commands to set up an operation, and then a final command to run it (e.g. multiple <code>git add</code>s, followed by a <code>git commit</code>).</li>
<li>Exploring a system—for example, doing a lot of <code>cd</code> and <code>ls</code> to get a sense of a directory structure, or <code>git log</code> and <code>git show</code> to explore the history of a file.</li>
<li>Doing a dry-run of a complex operation before running it for real.</li>
</ul>
<p>Acknowledging the conversational nature of command-line interaction means you can bring relevant techniques to bear on its design.
You can suggest possible corrections when user input is invalid, you can make the intermediate state clear when the user is going through a multi-step process, you can confirm for them that everything looks good before they do something scary.</p>
<p>The user is conversing with your software, whether you intended it or not.
At worst, it’s a hostile conversation which makes them feel stupid and resentful.
At best, it’s a pleasant exchange that speeds them on their way with newfound knowledge and a feeling of achievement.</p>
<p><em>Further reading: <a href="https://www.nngroup.com/articles/anti-mac-interface/">The Anti-Mac User Interface (Don Gentner and Jakob Nielsen)</a></em></p>
<h3 id="robustness-principle">Robustness</h3>
<p>Robustness is both an objective and a subjective property.
Software should <em>be</em> robust, of course: unexpected input should be handled gracefully, operations should be idempotent where possible, and so on.
But it should also <em>feel</em> robust.</p>
<p>You want your software to feel like it isn’t going to fall apart.
You want it to feel immediate and responsive, as if it were a big mechanical machine, not a flimsy plastic “soft switch.”</p>
<p>Subjective robustness requires attention to detail and thinking hard about what can go wrong.
It’s lots of little things: keeping the user informed about what’s happening, explaining what common errors mean, not printing scary-looking stack traces.</p>
<p>As a general rule, robustness can also come from keeping it simple.
Lots of special cases and complex code tend to make a program fragile.</p>
<h3 id="empathy">Empathy</h3>
<p>Command-line tools are a programmer’s creative toolkit, so they should be enjoyable to use.
This doesn’t mean turning them into a video game, or using lots of emoji (though there’s nothing inherently wrong with emoji 😉).
It means giving the user the feeling that you are on their side, that you want them to succeed, that you have thought carefully about their problems and how to solve them.</p>
<p>There’s no list of actions you can take that will ensure they feel this way, although we hope that following our advice will take you some of the way there.
Delighting the user means <em>exceeding their expectations</em> at every turn, and that starts with empathy.</p>
<h3 id="chaos">Chaos</h3>
<p>The world of the terminal is a mess.
Inconsistencies are everywhere, slowing us down and making us second-guess ourselves.</p>
<p>Yet it’s undeniable that this chaos has been a source of power.
The terminal, like the UNIX-descended computing environment in general, places very few constraints on what you can build.
In that space, all manner of invention has bloomed.</p>
<p>It’s ironic that this document implores you to follow existing patterns, right alongside advice that contradicts decades of command-line tradition.
We’re just as guilty of breaking the rules as anyone.</p>
<p>The time might come when you, too, have to break the rules.
Do so with intention and clarity of purpose.</p>
<blockquote>
<p>“Abandon a standard when it is demonstrably harmful to productivity or user satisfaction.” — Jef Raskin, <a href="https://en.wikipedia.org/wiki/The_Humane_Interface">The Humane Interface</a></p>
</blockquote>
<h2 id="guidelines">Guidelines</h2>
<p>This is a collection of specific things you can do to make your command-line program better.</p>
<p>The first section contains the essential things you need to follow.
Get these wrong, and your program will be either hard to use or a bad CLI citizen.</p>
<p>The rest are nice-to-haves.
If you have the time and energy to add these things, your program will be a lot better than the average program.</p>
<p>The idea is that, if you don’t want to think too hard about the design of your program, you don’t have to: just follow these rules and your program will probably be good.
On the other hand, if you’ve thought about it and determined that a rule is wrong for your program, that’s fine.
(There’s no central authority that will reject your program for not following arbitrary rules.)</p>
<p>Also—these rules aren’t written in stone.
If you disagree with a general rule for good reason, we hope you’ll <a href="https://github.com/cli-guidelines/cli-guidelines">propose a change</a>.</p>
<h3 id="the-basics">The Basics</h3>
<p>There are a few basic rules you need to follow.
Get these wrong, and your program will be either very hard to use, or flat-out broken.</p>
<p><strong>Use a command-line argument parsing library where you can.</strong>
Either your language’s built-in one, or a good third-party one.
They will normally handle arguments, flag parsing, help text, and even spelling suggestions in a sensible way.</p>
<p>Here are some that we like:</p>
<ul>
<li>Multi-platform: <a href="http://docopt.org/">docopt</a></li>
<li>Bash: <a href="https://argbash.io/">argbash</a></li>
<li>Go: <a href="https://github.com/spf13/cobra">Cobra</a>, <a href="https://github.com/urfave/cli">cli</a></li>
<li>Haskell: <a href="https://hackage.haskell.org/package/optparse-applicative">optparse-applicative</a></li>
<li>Java: <a href="https://picocli.info/">picocli</a></li>
<li>Node: <a href="https://oclif.io/">oclif</a></li>
<li>Deno: <a href="https://deno.land/std/flags">flags</a></li>
<li>Perl: <a href="https://metacpan.org/pod/Getopt::Long">Getopt::Long</a></li>
<li>PHP: <a href="https://github.com/symfony/console">console</a>, <a href="https://climate.thephpleague.com/">CLImate</a></li>
<li>Python: <a href="https://docs.python.org/3/library/argparse.html">Argparse</a>, <a href="https://click.palletsprojects.com/">Click</a>, <a href="https://github.com/tiangolo/typer">Typer</a></li>
<li>Ruby: <a href="https://ttytoolkit.org/">TTY</a></li>
<li>Rust: <a href="https://clap.rs/">clap</a>, <a href="https://github.com/TeXitoi/structopt">structopt</a></li>
<li>Swift: <a href="https://github.com/apple/swift-argument-parser">swift-argument-parser</a></li>
</ul>
<p><strong>Return zero exit code on success, non-zero on failure.</strong>
Exit codes are how scripts determine whether a program succeeded or failed, so you should report this correctly.
Map the non-zero exit codes to the most important failure modes.</p>
<p><strong>Send output to <code>stdout</code>.</strong>
The primary output for your command should go to <code>stdout</code>.
Anything that is machine readable should also go to <code>stdout</code>—this is where piping sends things by default.</p>
<p><strong>Send messaging to <code>stderr</code>.</strong>
Log messages, errors, and so on should all be sent to <code>stderr</code>.
This means that when commands are piped together, these messages are displayed to the user and not fed into the next command.</p>
<h3 id="help">Help</h3>
<p><strong>Display help text when passed no options, the <code>-h</code> flag, or the <code>--help</code> flag.</strong></p>
<p><strong>Display a concise help text by default.</strong>
If you can, display help by default when <code>myapp</code> or <code>myapp subcommand</code> is run.
Unless your program is very simple and does something obvious by default (e.g. <code>ls</code>), or your program reads input interactively (e.g. <code>cat</code>).</p>
<p>The concise help text should only include:</p>
<ul>
<li>A description of what your program does.</li>
<li>One or two example invocations.</li>
<li>Descriptions of flags, unless there are lots of them.</li>
<li>An instruction to pass the <code>--help</code> flag for more information.</li>
</ul>
<p><code>jq</code> does this well.
When you type <code>jq</code>, it displays an introductory description and an example, then prompts you to pass <code>jq --help</code> for the full listing of flags:</p>
<pre><code>$ jq
jq - commandline JSON processor [version 1.6]

Usage:    jq [options] &lt;jq filter&gt; [file...]
    jq [options] --args &lt;jq filter&gt; [strings...]
    jq [options] --jsonargs &lt;jq filter&gt; [JSON_TEXTS...]

jq is a tool for processing JSON inputs, applying the given filter to
its JSON text inputs and producing the filter's results as JSON on
standard output.

The simplest filter is ., which copies jq's input to its output
unmodified (except for formatting, but note that IEEE754 is used
for number representation internally, with all that that implies).

For more advanced filters see the jq(1) manpage ("man jq")
and/or https://stedolan.github.io/jq

Example:

    $ echo '{"foo": 0}' | jq .
    {
        "foo": 0
    }

For a listing of options, use jq --help.
</code></pre><p><strong>Show full help when <code>-h</code> and <code>--help</code> is passed.</strong>
All of these should show help:</p>
<pre><code>$ myapp
$ myapp --help
$ myapp -h
</code></pre><p>Ignore any other flags and arguments that are passed—you should be able to add <code>-h</code> to the end of anything and it should show help.
Don’t overload <code>-h</code>.</p>
<p>If your program is <code>git</code>-like, the following should also offer help:</p>
<pre><code>$ myapp help
$ myapp help subcommand
$ myapp subcommand --help
$ myapp subcommand -h
</code></pre><p><strong>Provide a support path for feedback and issues.</strong>
A website or GitHub link in the top-level help text is common.</p>
<p><strong>In help text, link to the web version of the documentation.</strong>
If you have a specific page or anchor for a subcommand, link directly to that.
This is particularly useful if there is more detailed documentation on the web, or further reading that might explain the behavior of something.</p>
<p><strong>Lead with examples.</strong>
Users tend to use examples over other forms of documentation, so show them first in the help page, particularly the common complex uses.
If it helps explain what it’s doing and it isn’t too long, show the actual output too.</p>
<p>You can tell a story with a series of examples, building your way toward complex uses.</p>
<!-- TK example? -->
<p><strong>If you’ve got loads of examples, put them somewhere else,</strong> in a cheat sheet command or a web page.
It’s useful to have exhaustive, advanced examples, but you don’t want to make your help text really long.</p>
<p>For more complex use cases, e.g. when integrating with another tool, it might be appropriate to write a fully-fledged tutorial.</p>
<p><strong>Display the most common flags and commands at the start of the help text.</strong>
It’s fine to have lots of flags, but if you’ve got some really common ones, display them first.
For example, the Git command displays the commands for getting started and the most commonly used subcommands first:</p>
<pre><code>$ git
usage: git [--version] [--help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]
           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]
           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]
           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]
           &lt;command&gt; [&lt;args&gt;]

These are common Git commands used in various situations:

start a working area (see also: git help tutorial)
   clone      Clone a repository into a new directory
   init       Create an empty Git repository or reinitialize an existing one

work on the current change (see also: git help everyday)
   add        Add file contents to the index
   mv         Move or rename a file, a directory, or a symlink
   reset      Reset current HEAD to the specified state
   rm         Remove files from the working tree and from the index

examine the history and state (see also: git help revisions)
   bisect     Use binary search to find the commit that introduced a bug
   grep       Print lines matching a pattern
   log        Show commit logs
   show       Show various types of objects
   status     Show the working tree status
…
</code></pre><p><strong>Use formatting in your help text.</strong>
Bold headings make it much easier to scan.
But, try to do it in a terminal-independent way so that your users aren’t staring down a wall of escape characters.</p>
<pre><code>
<strong>$ heroku apps --help</strong>
list your apps

<strong>USAGE</strong>
  $ heroku apps

<strong>OPTIONS</strong>
  -A, --all          include apps in all teams
  -p, --personal     list apps in personal account when a default team is set
  -s, --space=space  filter by space
  -t, --team=team    team to use
  --json             output in json format

<strong>EXAMPLES</strong>
  $ heroku apps
  === My Apps
  example
  example2

  === Collaborated Apps
  theirapp   other@owner.name

<strong>COMMANDS</strong>
  apps:create     creates a new app
  apps:destroy    permanently destroy an app
  apps:errors     view app errors
  apps:favorites  list favorited apps
  apps:info       show detailed app information
  apps:join       add yourself to a team app
  apps:leave      remove yourself from a team app
  apps:lock       prevent team members from joining an app
  apps:open       open the app in a web browser
  apps:rename     rename an app
  apps:stacks     show the list of available stacks
  apps:transfer   transfer applications to another user or team
  apps:unlock     unlock an app so any team member can join
</code>
</pre>
<p>Note: When <code>heroku apps --help</code> is piped through a pager, the command emits no escape characters.</p>
<p><strong>If the user did something wrong and you can guess what they meant, suggest it.</strong>
For example, <code>brew update jq</code> tells you that you should run <code>brew upgrade jq</code>.</p>
<p>You can ask if they want to run the suggested command, but don’t force it on them.
For example:</p>
<pre><code>$ heroku pss
 ›   Warning: pss is not a heroku command.
Did you mean ps? [y/n]:
</code></pre><p>Rather than suggesting the corrected syntax, you might be tempted to just run it for them, as if they’d typed it right in the first place.
Sometimes this is the right thing to do, but not always.</p>
<p>Firstly, invalid input doesn’t necessarily imply a simple typo—it can often mean the user has made a logical mistake, or misused a shell variable.
Assuming what they meant can be dangerous, especially if the resulting action modifies state.</p>
<p>Secondly, be aware that if you change what the user typed, they won’t learn the correct syntax.
In effect, you’re ruling that the way they typed it is valid and correct, and you’re committing to supporting that indefinitely.
Be intentional in making that decision, and document both syntaxes.</p>
<p><em>Further reading: <a href="http://www.catb.org/~esr/jargon/html/D/DWIM.html">“Do What I Mean”</a></em></p>
<p><strong>If your command is expecting to have something piped to it and <code>stdin</code> is an interactive terminal, display help immediately and quit.</strong>
This means it doesn’t just hang, like <code>cat</code>.
Alternatively, you could print a log message to <code>stderr</code>.</p>
<h3 id="documentation">Documentation</h3>
<p>The purpose of <a href="#help">help text</a> is to give a brief, immediate sense of what your tool is, what options are available, and how to perform the most common tasks.
Documentation, on the other hand, is where you go into full detail.
It’s where people go to understand what your tool is for, what it <em>isn’t</em> for, how it works and how to do everything they might need to do.</p>
<p><strong>Provide web-based documentation.</strong>
People need to be able to search online for your tool’s documentation, and to link other people to specific parts.
The web is the most inclusive documentation format available.</p>
<p><strong>Provide terminal-based documentation.</strong>
Documentation in the terminal has several nice properties: it’s fast to access, it stays in sync with the specific installed version of the tool, and it works without an internet connection.</p>
<p><strong>Consider providing man pages.</strong>
<a href="https://en.wikipedia.org/wiki/Man_page">man pages</a>, Unix’s original system of documentation, are still in use today, and many users will reflexively check <code>man mycmd</code> as a first step when trying to learn about your tool.
To make them easier to generate, you can use a tool like <a href="http://rtomayko.github.io/ronn/ronn.1.html">ronn</a> (which can also generate your web docs).</p>
<p>However, not everyone knows about <code>man</code>, and it doesn’t run on all platforms, so you should also make sure your terminal docs are accessible via your tool itself.
For example, <code>git</code> and <code>npm</code> make their man pages accessible via the <code>help</code> subcommand, so <code>npm help ls</code> is equivalent to <code>man npm-ls</code>.</p>
<pre><code>NPM-LS(1)                                                            NPM-LS(1)

NAME
       npm-ls - List installed packages

SYNOPSIS
         npm ls [[&lt;@scope&gt;/]&lt;pkg&gt; ...]

         aliases: list, la, ll

DESCRIPTION
       This command will print to stdout all the versions of packages that are
       installed, as well as their dependencies, in a tree-structure.

       ...
</code></pre><h3 id="output">Output</h3>
<p><strong>Human-readable output is paramount.</strong>
Humans come first, machines second.
The most simple and straightforward heuristic for whether a particular output stream (<code>stdout</code> or <code>stderr</code>) is being read by a human is <em>whether or not it’s a TTY</em>.
Whatever language you’re using, it will have a utility or library for doing this (e.g. <a href="https://stackoverflow.com/questions/858623/how-to-recognize-whether-a-script-is-running-on-a-tty">Python</a>, <a href="https://nodejs.org/api/process.html#process_a_note_on_process_i_o">Node</a>, <a href="https://github.com/mattn/go-isatty">Go</a>).</p>
<p><em>Further reading on <a href="https://unix.stackexchange.com/a/4132">what a TTY is</a>.</em></p>
<p><strong>Have machine-readable output where it does not impact usability.</strong>
Streams of text is the universal interface in UNIX.
Programs typically output lines of text, and programs typically expect lines of text as input,
therefore you can compose multiple programs together.
This is normally done to make it possible to write scripts,
but it can also help the usability for humans using programs.
For example, a user should be able to pipe output to <code>grep</code> and it should do what they expect.</p>
<blockquote>
<p>“Expect the output of every program to become the input to another, as yet unknown, program.”
— <a href="https://homepage.cs.uri.edu/~thenry/resources/unix_art/ch01s06.html">Doug McIlroy</a></p>
</blockquote>
<p><strong>If human-readable output breaks machine-readable output, use <code>--plain</code> to display output in plain, tabular text format for integration with tools like <code>grep</code> or <code>awk</code>.</strong>
In some cases, you might need to output information in a different way to make it human-readable.</p>
<!-- (TK example with and without --plain) -->
<p>For example, if you are displaying a line-based table, you might choose to split a cell into multiple lines, fitting in more information while keeping it within the width of the screen.
This breaks the expected behavior of there being one piece of data per line, so you should provide a <code>--plain</code> flag for scripts, which disables all such manipulation and outputs one record per line.</p>
<p><strong>Display output as formatted JSON if <code>--json</code> is passed.</strong>
JSON allows for more structure than plain text, so it makes it much easier to output and handle complex data structures.
<a href="https://stedolan.github.io/jq/"><code>jq</code></a> is a common tool for working with JSON on the command-line, and there is now a <a href="https://ilya-sher.org/2018/04/10/list-of-json-tools-for-command-line/">whole ecosystem of tools</a> that output and manipulate JSON.</p>
<p>It is also widely used on the web, so by using JSON as the input and output of programs, you can pipe directly to and from web services using <code>curl</code>.</p>
<p><strong>Display output on success, but keep it brief.</strong>
Traditionally, when nothing is wrong, UNIX commands display no output to the user.
This makes sense when they’re being used in scripts, but can make commands appear to be hanging or broken when used by humans.
For example, <code>cp</code> will not print anything, even if it takes a long time.</p>
<p>It’s rare that printing nothing at all is the best default behavior, but it’s usually best to err on the side of less.</p>
<p>For instances where you do want no output (for example, when used in shell scripts), to avoid clumsy redirection of <code>stderr</code> to <code>/dev/null</code>, you can provide a <code>-q</code> option to suppress all non-essential output.</p>
<p><strong>If you change state, tell the user.</strong>
When a command changes the state of a system, it’s especially valuable to explain what has just happened, so the user can model the state of the system in their head—particularly if the result doesn’t directly map to what the user requested.</p>
<p>For example, <code>git push</code> tells you exactly what it is doing, and what the new state of the remote branch is:</p>
<pre><code>$ git push
Enumerating objects: 18, done.
Counting objects: 100% (18/18), done.
Delta compression using up to 8 threads
Compressing objects: 100% (10/10), done.
Writing objects: 100% (10/10), 2.09 KiB | 2.09 MiB/s, done.
Total 10 (delta 8), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (8/8), completed with 8 local objects.
To github.com:replicate/replicate.git
 + 6c22c90...a2a5217 bfirsh/fix-delete -&gt; bfirsh/fix-delete
</code></pre><p><strong>Make it easy to see the current state of the system.</strong>
If your program does a lot of complex state changes and it is not immediately visible in the filesystem, make sure you make this easy to view.</p>
<p>For example, <code>git status</code> tells you as much information as possible about the current state of your Git repository, and some hints at how to modify the state:</p>
<pre><code>$ git status
On branch bfirsh/fix-delete
Your branch is up to date with 'origin/bfirsh/fix-delete'.

Changes not staged for commit:
  (use "git add &lt;file&gt;..." to update what will be committed)
  (use "git restore &lt;file&gt;..." to discard changes in working directory)
	modified:   cli/pkg/cli/rm.go

no changes added to commit (use "git add" and/or "git commit -a")
</code></pre><p><strong>Suggest commands the user should run.</strong>
When several commands form a workflow, suggesting to the user commands they can run next helps them learn how to use your program and discover new functionality.
For example, in the <code>git status</code> output above, it suggests commands you can run to modify the state you are viewing.</p>
<p><strong>Actions crossing the boundary of the program’s internal world should usually be explicit.</strong>
This includes things like:</p>
<ul>
<li>Reading or writing files that the user didn’t explicitly pass as arguments (unless those files are storing internal program state, such as a cache).</li>
<li>Talking to a remote server, e.g. to download a file.</li>
</ul>
<p><strong>Increase information density—with ASCII art!</strong>
For example, <code>ls</code> shows permissions in a scannable way.
When you first see it, you can ignore most of the information.
Then, as you learn how it works, you pick out more patterns over time.</p>
<pre><code>-rw-r--r-- 1 root root     68 Aug 22 23:20 resolv.conf
lrwxrwxrwx 1 root root     13 Mar 14 20:24 rmt -&gt; /usr/sbin/rmt
drwxr-xr-x 4 root root   4.0K Jul 20 14:51 security
drwxr-xr-x 2 root root   4.0K Jul 20 14:53 selinux
-rw-r----- 1 root shadow  501 Jul 20 14:44 shadow
-rw-r--r-- 1 root root    116 Jul 20 14:43 shells
drwxr-xr-x 2 root root   4.0K Jul 20 14:57 skel
-rw-r--r-- 1 root root      0 Jul 20 14:43 subgid
-rw-r--r-- 1 root root      0 Jul 20 14:43 subuid
</code></pre><p><strong>Use color with intention.</strong>
For example, you might want to highlight some text so the user notices it, or use red to indicate an error.
Don’t overuse it—if everything is a different color, then the color means nothing and only makes it harder to read.</p>
<p><strong>Disable color if your program is not in a terminal or the user requested it.</strong>
These things should disable colors:</p>
<ul>
<li><code>stdout</code> or <code>stderr</code> is not an interactive terminal (a TTY).
It’s best to individually check—if you’re piping <code>stdout</code> to another program, it’s still useful to get colors on <code>stderr</code>.</li>
<li>The <code>NO_COLOR</code> environment variable is set.</li>
<li>The <code>TERM</code> environment variable has the value <code>dumb</code>.</li>
<li>The user passes the option <code>--no-color</code>.</li>
<li>You may also want to add a <code>MYAPP_NO_COLOR</code> environment variable in case users want to disable color specifically for your program.</li>
</ul>
<p><em>Further reading: <a href="https://no-color.org/">no-color.org</a>, <a href="https://medium.com/@jdxcode/12-factor-cli-apps-dd3c227a0e46">12 Factor CLI Apps</a></em></p>
<p><strong>If <code>stdout</code> is not an interactive terminal, don’t display any animations.</strong>
This will stop progress bars turning into Christmas trees in CI log output.</p>
<p><strong>Use symbols and emoji where it makes things clearer.</strong>
Pictures can be better than words if you need to make several things distinct, catch the user’s attention, or just add a bit of character.
Be careful, though—it can be easy to overdo it and make your program look cluttered or feel like a toy.</p>
<p>For example, <a href="https://github.com/FiloSottile/yubikey-agent">yubikey-agent</a> uses emoji to add structure to the output so it isn’t just a wall of text, and a ❌ to draw your attention to an important piece of information:</p>
<pre><code data-lang="shell-session">$ yubikey-agent -setup
🔐 The PIN is up to 8 numbers, letters, or symbols. Not just numbers!
❌ The key will be lost if the PIN and PUK are locked after 3 incorrect tries.

Choose a new PIN/PUK: 
Repeat the PIN/PUK: 

🧪 Retriculating splines …

✅ Done! This YubiKey is secured and ready to go.
🤏 When the YubiKey blinks, touch it to authorize the login.

🔑 Here's your new shiny SSH public key:
ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBCEJ/
UwlHnUFXgENO3ifPZd8zoSKMxESxxot4tMgvfXjmRp5G3BGrAnonncE7Aj11pn3SSYgEcrrn2sMyLGpVS0=

💭 Remember: everything breaks, have a backup plan for when this YubiKey does.
</code></pre><p><strong>By default, don’t output information that’s only understandable by the creators of the software.</strong>
If a piece of output serves only to help you (the developer) understand what your software is doing, it almost certainly shouldn’t be displayed to normal users by default—only in verbose mode.</p>
<p>Invite usability feedback from outsiders and people who are new to your project.
They’ll help you see important issues that you are too close to the code to notice.</p>
<p><strong>Don’t treat <code>stderr</code> like a log file, at least not by default.</strong>
Don’t print log level labels (<code>ERR</code>, <code>WARN</code>, etc.) or extraneous contextual information, unless in verbose mode.</p>
<p><strong>Use a pager (e.g. <code>less</code>) if you are outputting a lot of text.</strong>
For example, <code>git diff</code> does this by default.
Using a pager can be error-prone, so be careful with your implementation such that you don’t make the experience worse for the user.
You shouldn’t use a pager if <code>stdin</code> or <code>stdout</code> is not an interactive terminal.</p>
<p>A good sensible set of options to use for <code>less</code> is <code>less -FIRX</code>.
This does not page if the content fills one screen, ignores case when you search, enables color and formatting, and leaves the contents on the screen when <code>less</code> quits.</p>
<p>There might be libraries in your language that are more robust than piping to <code>less</code>.
For example, <a href="https://github.com/prompt-toolkit/pypager">pypager</a> in Python.</p>
<h3 id="errors">Errors</h3>
<p>One of the most common reasons to consult documentation is to fix errors.
If you can make errors into documentation, then this will save the user loads of time.</p>
<p><strong>Catch errors and <a href="https://www.nngroup.com/articles/error-message-guidelines/">rewrite them for humans</a>.</strong>
If you’re expecting an error to happen, catch it and rewrite the error message to be useful.
Think of it like a conversation, where the user has done something wrong and the program is guiding them in the right direction.
Example: “Can’t write to file.txt. You might need to make it writable by running ‘chmod +w file.txt’.”</p>
<p><strong>Signal-to-noise ratio is crucial.</strong>
The more irrelevant output you produce, the longer it’s going to take the user to figure out what they did wrong.
If your program produces multiple errors of the same type, consider grouping them under a single explanatory header instead of printing many similar-looking lines.</p>
<p><strong>Consider where the user will look first.</strong>
Put the most important information at the end of the output.
The eye will be drawn to red text, so use it intentionally and sparingly.</p>
<p><strong>If there is an unexpected or unexplainable error, provide debug and traceback information, and instructions on how to submit a bug.</strong>
That said, don’t forget about the signal-to-noise ratio: you don’t want to overwhelm the user with information they don’t understand.
Consider writing the debug log to a file instead of printing it to the terminal.</p>
<p><strong>Make it effortless to submit bug reports.</strong>
One nice thing you can do is provide a URL and have it pre-populate as much information as possible.</p>
<h3 id="arguments-and-flags">Arguments and flags</h3>
<p>A note on terminology:</p>
<ul>
<li><em>Arguments</em>, or <em>args</em>, are positional parameters to a command.
For example, the file paths you provide to <code>cp</code> are args.
The order of args is often important: <code>cp foo bar</code> means something different from <code>cp bar foo</code>.</li>
<li><em>Flags</em> are named parameters, denoted with either a hyphen and a single-letter name (<code>-r</code>) or a double hyphen and a multiple-letter name (<code>--recursive</code>).
They may or may not also include a user-specified value (<code>--file foo.txt</code>, or <code>--file=foo.txt</code>).
The order of flags, generally speaking, does not affect program semantics.</li>
</ul>
<p><strong>Prefer flags to args.</strong>
It’s a bit more typing, but it makes it much clearer what is going on.
It also makes it easier to make changes to how you accept input in the future.
Sometimes when using args, it’s impossible to add new input without breaking existing behavior or creating ambiguity.</p>
<p><em>Citation: <a href="https://medium.com/@jdxcode/12-factor-cli-apps-dd3c227a0e46">12 Factor CLI Apps</a>.</em></p>
<p><strong>Have full-length versions of all flags.</strong>
For example, have both <code>-h</code> and <code>--help</code>.
Having the full version is useful in scripts where you want to be verbose and descriptive, and you don’t have to look up the meaning of flags everywhere.</p>
<p><em>Citation: <a href="https://www.gnu.org/prep/standards/html_node/Command_002dLine-Interfaces.html">GNU Coding Standards</a>.</em></p>
<p><strong>Only use one-letter flags for commonly used flags,</strong> particularly at the top-level when using subcommands.
That way you don’t “pollute” your namespace of short flags, forcing you to use convoluted letters and cases for flags you add in the future.</p>
<p><strong>Multiple arguments are fine for simple actions against multiple files.</strong>
For example, <code>rm file1.txt file2.txt file3.txt</code>.
This also makes it work with globbing: <code>rm *.txt</code>.</p>
<p><strong>If you’ve got two or more arguments for different things, you’re probably doing something wrong.</strong>
The exception is a common, primary action, where the brevity is worth memorizing.
For example, <code>cp &lt;source&gt; &lt;destination&gt;</code>.</p>
<p><em>Citation: <a href="https://medium.com/@jdxcode/12-factor-cli-apps-dd3c227a0e46">12 Factor CLI Apps</a>.</em></p>
<p><strong>Use standard names for flags, if there is a standard.</strong>
If another commonly used command uses a flag name, it’s best to follow that existing pattern.
That way, a user doesn’t have to remember two different options (and which command it applies to), and users can even guess an option without having to look at the help text.</p>
<p>Here’s a list of commonly used options:</p>
<ul>
<li><code>-a</code>, <code>--all</code>: All.
For example, <code>ps</code>, <code>fetchmail</code>.</li>
<li><code>-d</code>, <code>--debug</code>: Show debugging output.</li>
<li><code>-f</code>, <code>--force</code>: Force.
For example, <code>rm -f</code> will force the removal of files, even if it thinks it does not have permission to do it.
This is also useful for commands which are doing something destructive that usually require user confirmation, but you want to force it to do that destructive action in a script.</li>
<li><code>--json</code>: Display JSON output.
See the <a href="#output">output</a> section.</li>
<li><code>-h</code>, <code>--help</code>: Help.
This should only mean help.
See the <a href="#help">help</a> section.</li>
<li><code>--no-input</code>: See the <a href="#interactivity">interactivity</a> section.</li>
<li><code>-o</code>, <code>--output</code>: Output file.
For example, <code>sort</code>, <code>gcc</code>.</li>
<li><code>-p</code>, <code>--port</code>: Port.
For example, <code>psql</code>, <code>ssh</code>.</li>
<li><code>-q</code>, <code>--quiet</code>: Quiet.
Display less output.
This is particularly useful when displaying output for humans that you might want to hide when running in a script.</li>
<li><code>-u</code>, <code>--user</code>: User.
For example, <code>ps</code>, <code>ssh</code>.</li>
<li><code>--version</code>: Version.</li>
<li><code>-v</code>: This can often mean either verbose or version.
You might want to use <code>-d</code> for verbose and this for version, or for nothing to avoid confusion.</li>
</ul>
<p><strong>Make the default the right thing for most users.</strong>
Making things configurable is good, but most users are not going to find the right flag and remember to use it all the time (or alias it).
If it’s not the default, you’re making the experience worse for most of your users.</p>
<p>For example, <code>ls</code> has terse default output to optimize for scripts and other historical reasons, but if it were designed today, it would probably default to <code>ls -lhF</code>.</p>
<p><strong>Prompt for user input.</strong>
If a user doesn’t pass an argument or flag, prompt for it.
(See also: <a href="#interactivity">Interactivity</a>)</p>
<p><strong>Never <em>require</em> a prompt.</strong>
Always provide a way of passing input with flags or arguments.
If <code>stdin</code> is not an interactive terminal, skip prompting and just require those flags/args.</p>
<p><strong>Confirm before doing anything dangerous.</strong>
A common convention is to prompt for the user to type <code>y</code> or <code>yes</code> if running interactively, or requiring them to pass <code>-f</code> or <code>--force</code> otherwise.</p>
<p>“Dangerous” is a subjective term, and there are differing levels of danger:</p>
<ul>
<li><strong>Mild:</strong> A small, local change such as deleting a file.
You might want to prompt for confirmation, you might not.
For example, if the user is explicitly running a command called something like “delete,” you probably don’t need to ask.</li>
<li><strong>Moderate:</strong> A bigger local change like deleting a directory, a remote change like deleting a resource of some kind, or a complex bulk modification that can’t be easily undone.
You usually want to prompt for confirmation here.
Consider giving the user a way to “dry run” the operation so they can see what’ll happen before they commit to it.</li>
<li><strong>Severe:</strong> Deleting something complex, like an entire remote application or server.
You don’t just want to prompt for confirmation here—you want to make it hard to confirm by accident.
Consider asking them to type something non-trivial such as the name of the thing they’re deleting.
Let them alternatively pass a flag such as <code>--confirm="name-of-thing"</code>, so it’s still scriptable.</li>
</ul>
<p>Consider whether there are non-obvious ways to accidentally destroy things.
For example, imagine a situation where changing a number in a configuration file from 10 to 1 means that 9 things will be implicitly deleted—this should be considered a severe risk, and should be difficult to do by accident.</p>
<p><strong>If input or output is a file, support <code>-</code> to read from <code>stdin</code> or write to <code>stdout</code>.</strong>
This lets the output of another command be the input of your command and vice versa, without using a temporary file.
For example, <code>tar</code> can extract files from <code>stdin</code>:</p>
<pre><code>$ curl https://example.com/something.tar.gz | tar xvf -
</code></pre><p><strong>If a flag can accept an optional value, allow a special word like “none.”</strong>
For example, <code>ssh -F</code> takes an optional filename of an alternative <code>ssh_config</code> file, and <code>ssh -F none</code> runs SSH with no config file. Don’t just use a blank value—this can make it ambiguous whether arguments are flag values or arguments.</p>
<p><strong>If possible, make arguments, flags and subcommands order-independent.</strong>
A lot of CLIs, especially those with subcommands, have unspoken rules on where you can put various arguments.
For example a command might have a <code>--foo</code> flag that only works if you put it before the subcommand:</p>
<pre><code>mycmd --foo=1 subcmd
works

$ mycmd subcmd --foo=1
unknown flag: --foo
</code></pre><p>This can be very confusing for the user—especially given that one of the most common things users do when trying to get a command to work is to hit the up arrow to get the last invocation, stick another option on the end, and run it again.
If possible, try to make both forms equivalent, although you might run up against the limitations of your argument parser.</p>
<p><strong>Do not read secrets directly from flags.</strong>
When a command accepts a secret, eg. via a <code>--password</code> argument,
the argument value will leak the secret into <code>ps</code> output and potentially shell history.
And, this sort of flag encourages the use of insecure environment variables for secrets.</p>
<p>Consider accepting sensitive data only via files, e.g. with a <code>--password-file</code> argument, or via <code>stdin</code>.
A <code>--password-file</code> argument allows a secret to be passed in discreetly, in a wide variety of contexts.</p>
<p>(It’s possible to pass a file’s contents into an argument in Bash by using <code>--password $(&lt; password.txt)</code>.
This approach has the same security issue of leaking the file’s contents into the output of <code>ps</code>.
It’s best avoided.)</p>
<h3 id="interactivity">Interactivity</h3>
<p><strong>Only use prompts or interactive elements if <code>stdin</code> is an interactive terminal (a TTY).</strong>
This is a pretty reliable way to tell whether you’re piping data into a command or whether it’s being run in a script, in which case a prompt won’t work and you should throw an error telling the user what flag to pass.</p>
<p><strong>If <code>--no-input</code> is passed, don’t prompt or do anything interactive.</strong>
This allows users an explicit way to disable all prompts in commands.
If the command requires input, fail and tell the user how to pass the information as a flag.</p>
<p><strong>If you’re prompting for a password, don’t print it as the user types.</strong>
This is done by turning off echo in the terminal.
Your language should have helpers for this.</p>
<p><strong>Let the user escape.</strong>
Make it clear how to get out.
(Don’t do what vim does.)
If your program hangs on network I/O etc, always make Ctrl-C still work.
If it’s a wrapper around program execution where Ctrl-C can’t quit (SSH, tmux, telnet, etc), make it clear how to do that.
For example, SSH allows escape sequences with the <code>~</code> escape character.</p>
<h3 id="subcommands">Subcommands</h3>
<p>If you’ve got a tool that’s sufficiently complex, you can reduce its complexity by making a set of subcommands.
If you have several tools that are very closely related, you can make them easier to use and discover by combining them into a single command (for example, RCS vs. Git).</p>
<p>They’re useful for sharing stuff—global flags, help text, configuration, storage mechanisms.</p>
<p><strong>Be consistent across subcommands.</strong>
Use the same flag names for the same things, have similar output formatting, etc.</p>
<p><strong>Use consistent names for multiple levels of subcommand.</strong>
If a complex piece of software has lots of objects and operations that can be performed on those objects, it is a common pattern to use two levels of subcommand for this, where one is a noun and one is a verb.
For example, <code>docker container create</code>.
Be consistent with the verbs you use across different types of objects.</p>
<p>Either <code>noun verb</code> or <code>verb noun</code> ordering works, but <code>noun verb</code> seems to be more common.</p>
<p><em>Further reading: <a href="https://uxdesign.cc/user-experience-clis-and-breaking-the-world-baed8709244f">User experience, CLIs, and breaking the world, by John Starich</a>.</em></p>
<p><strong>Don’t have ambiguous or similarly-named commands.</strong>
For example, having two subcommands called “update” and “upgrade” is quite confusing.
You might want to use different words, or disambiguate with extra words.</p>
<h3 id="robustness-guidelines">Robustness</h3>
<p><strong>Validate user input.</strong>
Everywhere your program accepts data from the user, it will eventually be given bad data.
Check early and bail out before anything bad happens, and <a href="#errors">make the errors understandable</a>.</p>
<p><strong>Responsive is more important than fast.</strong>
Print something to the user in &lt;100ms.
If you’re making a network request, print something before you do it so it doesn’t hang and look broken.</p>
<p><strong>Show progress if something takes a long time.</strong>
If your program displays no output for a while, it will look broken.
A good spinner or progress indicator can make a program appear to be faster than it is.</p>
<p>Ubuntu 20.04 has a nice progress bar that sticks to the bottom of the terminal.</p>
<!-- (TK reproduce this as a code block or animated SVG) -->
<p>If the progress bar gets stuck in one place for a long time, the user won’t know if stuff is still happening or if the program’s crashed.
It’s good to show estimated time remaining, or even just have an animated component, to reassure them that you’re still working on it.</p>
<p>There are many good libraries for generating progress bars.
For example, <a href="https://github.com/tqdm/tqdm">tqdm</a> for Python, <a href="https://github.com/schollz/progressbar">schollz/progressbar</a> for Go, and <a href="https://github.com/visionmedia/node-progress">node-progress</a> for Node.js.</p>
<p><strong>Do stuff in parallel where you can, but be thoughtful about it.</strong>
It’s already difficult to report progress in the shell; doing it for parallel processes is ten times harder.
Make sure it’s robust, and that the output isn’t confusingly interleaved.
If you can use a library, do so—this is code you don’t want to write yourself.
Libraries like <a href="https://github.com/tqdm/tqdm">tqdm</a> for Python and <a href="https://github.com/schollz/progressbar">schollz/progressbar</a> for Go support multiple progress bars natively.</p>
<p>The upside is that it can be a huge usability gain.
For example, <code>docker pull</code>’s multiple progress bars offer crucial insight into what’s going on.</p>
<pre><code>$ docker image pull ruby
Using default tag: latest
latest: Pulling from library/ruby
6c33745f49b4: Pull complete 
ef072fc32a84: Extracting [================================================&gt;  ]  7.569MB/7.812MB
c0afb8e68e0b: Download complete 
d599c07d28e6: Download complete 
f2ecc74db11a: Downloading [=======================&gt;                           ]  89.11MB/192.3MB
3568445c8bf2: Download complete 
b0efebc74f25: Downloading [===========================================&gt;       ]  19.88MB/22.88MB
9cb1ba6838a0: Download complete 
</code></pre><p>One thing to be aware of: hiding logs behind progress bars when things go <em>well</em> makes it much easier for the user to understand what’s going on, but if there is an error, make sure you print out the logs.
Otherwise, it will be very hard to debug.</p>
<p><strong>Make things time out.</strong>
Allow network timeouts to be configured, and have a reasonable default so it doesn’t hang forever.</p>
<p><strong>Make it recoverable.</strong>
If the program fails for some transient reason (e.g. the internet connection went down), you should be able to hit <code>&lt;up&gt;</code> and <code>&lt;enter&gt;</code> and it should pick up from where it left off.</p>
<p><strong>Make it crash-only.</strong>
This is the next step up from idempotence.
If you can avoid needing to do any cleanup after operations, or you can defer that cleanup to the next run, your program can exit immediately on failure or interruption.
This makes it both more robust and more responsive.</p>
<p><em>Citation: <a href="https://lwn.net/Articles/191059/">Crash-only software: More than meets the eye</a>.</em></p>
<p><strong>People are going to misuse your program.</strong>
Be prepared for that.
They will wrap it in scripts, use it on bad internet connections, run many instances of it at once, and use it in environments you haven’t tested in, with quirks you didn’t anticipate.
(Did you know macOS filesystems are case-insensitive but also case-preserving?)</p>
<h3 id="future-proofing">Future-proofing</h3>
<p>In software of any kind, it’s crucial that interfaces don’t change without a lengthy and well-documented deprecation process.
Subcommands, arguments, flags, configuration files, environment variables: these are all interfaces, and you’re committing to keeping them working.
(<a href="https://semver.org/">Semantic versioning</a> can only excuse so much change; if you’re putting out a major version bump every month, it’s meaningless.)</p>
<p><strong>Keep changes additive where you can.</strong>
Rather than modify the behavior of a flag in a backwards-incompatible way, maybe you can add a new flag—as long as it doesn’t bloat the interface too much.
(See also: <a href="#arguments-and-flags">Prefer flags to args</a>.)</p>
<p><strong>Warn before you make a non-additive change.</strong>
Eventually, you’ll find that you can’t avoid breaking an interface.
Before you do, forewarn your users in the program itself: when they pass the flag you’re looking to deprecate, tell them it’s going to change soon.
Make sure there’s a way they can modify their usage today to make it future-proof, and tell them how to do it.</p>
<p>If possible, you should detect when they’ve changed their usage and not show the warning any more: now they won’t notice a thing when you finally roll out the change.</p>
<p><strong>Changing output for humans is usually OK.</strong>
The only way to make an interface easy to use is to iterate on it, and if the output is considered an interface, then you can’t iterate on it.
Encourage your users to use <code>--plain</code> or <code>--json</code> in scripts to keep output stable (see <a href="#output">Output</a>).</p>
<p><strong>Don’t have a catch-all subcommand.</strong>
If you have a subcommand that’s likely to be the most-used one, you might be tempted to let people omit it entirely for brevity’s sake.
For example, say you have a <code>run</code> command that wraps an arbitrary shell command:</p>
<pre><code>$ mycmd run echo "hello world"
</code></pre>
<p>You could make it so that if the first argument to <code>mycmd</code> isn’t the name of an existing subcommand, you assume the user means <code>run</code>, so they can just type this:</p>
<pre><code>$ mycmd echo "hello world"
</code></pre>
<p>This has a serious drawback, though: now you can never add a subcommand named <code>echo</code>—or <em>anything at all</em>—without risking breaking existing usages.
If there’s a script out there that uses <code>mycmd echo</code>, it will do something entirely different after that user upgrades to the new version of your tool.</p>
<p><strong>Don’t allow arbitrary abbreviations of subcommands.</strong>
For example, say your command has an <code>install</code> subcommand.
When you added it, you wanted to save users some typing, so you allowed them to type any non-ambiguous prefix, like <code>mycmd ins</code>, or even just <code>mycmd i</code>, and have it be an alias for <code>mycmd install</code>.
Now you’re stuck: you can’t add any more commands beginning with <code>i</code>, because there are scripts out there that assume <code>i</code> means <code>install</code>.</p>
<p>There’s nothing wrong with aliases—saving on typing is good—but they should be explicit and remain stable.</p>
<p><strong>Don’t create a “time bomb.”</strong>
Imagine it’s 20 years from now.
Will your command still run the same as it does today, or will it stop working because some external dependency on the internet has changed or is no longer maintained?
The server most likely to not exist in 20 years is the one that you are maintaining right now.
(But don’t build in a blocking call to Google Analytics either.)</p>
<h3 id="signals">Signals and control characters</h3>
<p><strong>If a user hits Ctrl-C (the INT signal), exit as soon as possible.</strong>
Say something immediately, before you start clean-up.
Add a timeout to any clean-up code so it can’t hang forever.</p>
<p><strong>If a user hits Ctrl-C during clean-up operations that might take a long time, skip them.</strong>
Tell the user what will happen when they hit Ctrl-C again, in case it is a destructive action.</p>
<p>For example, when quitting Docker Compose, you can hit Ctrl-C a second time to force your containers to stop immediately instead of shutting them down gracefully.</p>
<pre><code>$  docker-compose up
…
^CGracefully stopping... (press Ctrl+C again to force)
</code></pre><p>Your program should expect to be started in a situation where clean-up has not been run.
(See <a href="https://lwn.net/Articles/191059/">Crash-only software: More than meets the eye</a>.)</p>
<h3 id="configuration">Configuration</h3>
<p>Command-line tools have lots of different types of configuration, and lots of different ways to supply it (flags, environment variables, project-level config files).
The best way to supply each piece of configuration depends on a few factors, chief among them <em>specificity</em>, <em>stability</em> and <em>complexity</em>.</p>
<p>Configuration generally falls into a few categories:</p>
<ol>
<li>
<p>Likely to vary from one invocation of the command to the next.</p>
<p>Examples:</p>
<ul>
<li>Setting the level of debugging output</li>
<li>Enabling a safe mode or dry run of a program</li>
</ul>
<p>Recommendation: <strong>Use <a href="#arguments-and-flags">flags</a>.</strong>
<a href="#environment-variables">Environment variables</a> may or may not be useful as well.</p>
</li>
<li>
<p>Generally stable from one invocation to the next, but not always.
Might vary between projects.
Definitely varies between different users working on the same project.</p>
<p>This type of configuration is often specific to an individual computer.</p>
<p>Examples:</p>
<ul>
<li>Providing a non-default path to items needed for a program to start</li>
<li>Specifying how or whether color should appear in output</li>
<li>Specifying an HTTP proxy server to route all requests through</li>
</ul>
<p>Recommendation: <strong>Use <a href="#arguments-and-flags">flags</a> and probably <a href="#environment-variables">environment variables</a> too.</strong>
Users may want to set the variables in their shell profile so they apply globally, or in <code>.env</code> for a particular project.</p>
<p>If this configuration is sufficiently complex, it may warrant a configuration file of its own, but environment variables are usually good enough.</p>
</li>
<li>
<p>Stable within a project, for all users.</p>
<p>This is the type of configuration that belongs in version control.
Files like <code>Makefile</code>, <code>package.json</code> and <code>docker-compose.yml</code> are all examples of this.</p>
<p>Recommendation: <strong>Use a command-specific, version-controlled file.</strong></p>
</li>
</ol>
<p><strong>Follow the XDG-spec.</strong>
In 2010 the X Desktop Group, now <a href="https://freedesktop.org/">freedesktop.org</a>, developed a specification for the location of base directories where config files may be located.
One goal was to limit the proliferation of dotfiles in a user’s home directory by supporting a general-purpose <code>~/.config</code> folder.
The XDG Base Directory Specification (<a href="https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html">full spec</a>, <a href="https://wiki.archlinux.org/index.php/XDG_Base_Directory#Specification">summary</a>) is supported by yarn, fish, wireshark, emacs, neovim, tmux, and many other projects you know and love.</p>
<p><strong>If you automatically modify configuration that is not your program’s, ask the user for consent and tell them exactly what you’re doing.</strong>
Prefer creating a new config file (e.g. <code>/etc/cron.d/myapp</code>) rather than appending to an existing config file (e.g. <code>/etc/crontab</code>).
If you have to append or modify to a system-wide config file, use a dated comment in that file to delineate your additions.</p>
<p><strong>Apply configuration parameters in order of precedence.</strong>
Here is the precedence for config parameters, from highest to lowest:</p>
<ul>
<li>Flags</li>
<li>The running shell’s environment variables</li>
<li>Project-level configuration (eg. <code>.env</code>)</li>
<li>User-level configuration</li>
<li>System wide configuration</li>
</ul>
<h3 id="environment-variables">Environment variables</h3>
<p><strong>Environment variables are for behavior that <em>varies with the context</em> in which a command is run.</strong>
The “environment” of an environment variable is the terminal session—the context in which the command is running.
So, an env var might change each time a command runs, or between terminal sessions on one machine, or between instantiations of one project across several machines.</p>
<p>Environment variables may duplicate the functionality of flags or configuration parameters, or they may be distinct from those things.
See <a href="#configuration">Configuration</a> for a breakdown of common types of configuration and recommendations on when environment variables are most appropriate.</p>
<p><strong>For maximum portability, environment variable names must only contain uppercase letters, numbers, and underscores (and mustn’t start with a number).</strong>
Which means <code>O_O</code> and <code>OWO</code> are the only emoticons that are also valid environment variable names.</p>
<p><strong>Aim for single-line environment variable values.</strong>
While multi-line values are possible, they create usability issues with the <code>env</code> command.</p>
<p><strong>Avoid commandeering widely used names.</strong>
Here’s a <a href="https://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap08.html">list of POSIX standard env vars</a>.</p>
<p><strong>Check general-purpose environment variables for configuration values when possible:</strong></p>
<ul>
<li><code>NO_COLOR</code>, to disable color (see <a href="#output">Output</a>)</li>
<li><code>DEBUG</code>, to enable more verbose output</li>
<li><code>EDITOR</code>, if you need to prompt the user to edit a file or input more than a single line</li>
<li><code>HTTP_PROXY</code>, <code>HTTPS_PROXY</code>, <code>ALL_PROXY</code> and <code>NO_PROXY</code>, if you’re going to perform network operations
(The HTTP library you’re using might already check for these.)</li>
<li><code>SHELL</code>, if you need to open up an interactive session of the user’s preferred shell
(If you need to execute a shell script, use a specific interpreter like <code>/bin/sh</code>)</li>
<li><code>TERM</code>, <code>TERMINFO</code> and <code>TERMCAP</code>, if you’re going to use terminal-specific escape sequences</li>
<li><code>TMPDIR</code>, if you’re going to create temporary files</li>
<li><code>HOME</code>, for locating configuration files</li>
<li><code>PAGER</code>, if you want to automatically page output</li>
<li><code>LINES</code> and <code>COLUMNS</code>, for output that’s dependent on screen size (e.g. tables)</li>
</ul>
<p><strong>Read environment variables from <code>.env</code> where appropriate.</strong>
If a command defines environment variables that are unlikely to change as long as the user is working in a particular directory,
then it should also read them from a local <code>.env</code> file so users can configure it differently for different projects without having to specify them every time.
Many languages have libraries for reading <code>.env</code> files (<a href="https://crates.io/crates/dotenv">Rust</a>, <a href="https://www.npmjs.com/package/dotenv">Node</a>, <a href="https://github.com/bkeepers/dotenv">Ruby</a>).</p>
<p><strong>Don’t use <code>.env</code> as a substitute for a proper <a href="#configuration">configuration file</a>.</strong>
<code>.env</code> files have a lot of limitations:</p>
<ul>
<li>A <code>.env</code> file is not commonly stored in source control</li>
<li>(Therefore, any configuration stored in it has no history)</li>
<li>It has only one data type: string</li>
<li>It lends itself to being poorly organized</li>
<li>It makes encoding issues easy to introduce</li>
<li>It often contains sensitive credentials &amp; key material that would be better stored more securely</li>
</ul>
<p>If it seems like these limitations will hamper usability or security, then a dedicated config file might be more appropriate.</p>
<p><strong>Do not read secrets from environment variables.</strong>
While environment variables may be convenient for storing secrets, they have proven too prone to leakage:</p>
<ul>
<li>Exported environment variables are sent to every process, and from there can easily leak into logs or be exfiltrated</li>
<li>Shell substitutions like <code>curl -H "Authorization: Bearer $BEARER_TOKEN"</code> will leak into globally-readable process state.
(cURL offers the <code>-H @filename</code> alternative for reading sensitive headers from a file.)</li>
<li>Docker container environment variables can be viewed by anyone with Docker daemon access via <code>docker inspect</code></li>
<li>Environment variables in systemd units are globally readable via <code>systemctl show</code></li>
</ul>
<p>Secrets should only be accepted via credential files, pipes, <code>AF_UNIX</code> sockets, secret management services, or another IPC mechanism.</p>
<h3 id="naming">Naming</h3>
<p>The name of your program is particularly important on the CLI: your users will be typing it all the time, and it needs to be easy to remember and type.</p>
<p><strong>Make it a simple, memorable word.</strong>
But not too generic, or you’ll step on the toes of other commands and confuse users.
For example, both ImageMagick and Windows used the command <code>convert</code>.</p>
<p><strong>Use only lowercase letters, and dashes if you really need to.</strong>
<code>curl</code> is a good name, <code>DownloadURL</code> is not.</p>
<p><strong>Keep it short.</strong>
Users will be typing it all the time.
Don’t make it <em>too</em> short: the very shortest commands are best reserved for the common utilities used all the time, such as <code>cd</code>, <code>ls</code>, <code>ps</code>.</p>
<p><strong>Make it easy to type.</strong>
Some words flow across the QWERTY keyboard much more easily than others, and it’s not just about brevity.
<code>plum</code> may be short but it’s an awkward, angular dance.
<code>apple</code> trips you up with the double letter.
<code>orange</code> is longer than both, but flows much better.</p>
<p><em>Further reading: <a href="https://smallstep.com/blog/the-poetics-of-cli-command-names/">The Poetics of CLI Command Names</a></em></p>
<h3 id="distribution">Distribution</h3>
<p><strong>If possible, distribute as a single binary.</strong>
If your language doesn’t compile to binary executables as standard, see if it has something like <a href="https://www.pyinstaller.org/">PyInstaller</a>.
If you really can’t distribute as a single binary, use the platform’s native package installer so you aren’t scattering things on disk that can’t easily be removed.
Tread lightly on the user’s computer.</p>
<p>If you’re making a language-specific tool, such as a code linter, then this rule doesn’t apply—it’s safe to assume the user has an interpreter for that language installed on their computer.</p>
<p><strong>Make it easy to uninstall.</strong>
If it needs instructions, put them at the bottom of the install instructions—one of the most common times people want to uninstall software is right after installing it.</p>
<h3 id="analytics">Analytics</h3>
<p>Usage metrics can be helpful to understand how users are using your program, how to make it better, and where to focus effort.
But, unlike websites, users of the command-line expect to be in control of their environment, and it is surprising when programs do things in the background without telling them.</p>
<p><strong>Do not phone home usage or crash data without consent.</strong>
Users will find out, and they will be angry.
Be very explicit about what you collect, why you collect it, how anonymous it is and how you go about anonymizing it, and how long you retain it for.</p>
<p>Ideally, ask users whether they want to contribute data (“opt-in”).
If you choose to do it by default (“opt-out”), then clearly tell users about it on your website or first run, and make it easy to disable.</p>
<p>Examples of projects that collect usage statistics:</p>
<ul>
<li>Angular.js <a href="https://angular.io/analytics">collects detailed analytics using Google Analytics</a>, in the name of feature prioritization.
You have to explicitly opt in.
You can change the tracking ID to point to your own Google Analytics property if you want to track Angular usage inside your organization.</li>
<li>Homebrew sends metrics to Google Analytics and has <a href="https://docs.brew.sh/Analytics">a nice FAQ</a> detailing their practices.</li>
<li>Next.js <a href="https://nextjs.org/telemetry">collects anonymized usage statistics</a> and is enabled by default.</li>
</ul>
<p><strong>Consider alternatives to collecting analytics.</strong></p>
<ul>
<li>Instrument your web docs.
If you want to know how people are using your CLI tool, make a set of docs around the use cases you’d like to understand best, and see how they perform over time.
Look at what people search for within your docs.</li>
<li>Instrument your downloads.
This can be a rough metric to understand usage and what operating systems your users are running.</li>
<li>Talk to your users.
Reach out and ask people how they’re using your tool.
Encourage feedback and feature requests in your docs and repos, and try to draw out more context from those who submit feedback.</li>
</ul>
<p><em>Further reading: <a href="https://opensource.guide/metrics/">Open Source Metrics</a></em></p>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/The_Unix_Programming_Environment">The Unix Programming Environment</a>, Brian W. Kernighan and Rob Pike</li>
<li><a href="https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html">POSIX Utility Conventions</a></li>
<li><a href="https://www.gnu.org/prep/standards/html_node/Program-Behavior.html">Program Behavior for All Programs</a>, GNU Coding Standards</li>
<li><a href="https://medium.com/@jdxcode/12-factor-cli-apps-dd3c227a0e46">12 Factor CLI Apps</a>, Jeff Dickey</li>
<li><a href="https://devcenter.heroku.com/articles/cli-style-guide">CLI Style Guide</a>, Heroku</li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We might want to regularly keep track of how important each server is (160 pts)]]></title>
            <link>https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance</link>
            <guid>39272952</guid>
            <pubDate>Tue, 06 Feb 2024 10:51:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance">https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance</a>, See on <a href="https://news.ycombinator.com/item?id=39272952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>We might want to regularly keep track of how important each server is</h2>

	<p><small>February  5, 2024</small></p>
</div><div><p>Today <a href="https://mastodon.social/@cks/111881322231361439">we had a significant machine room air conditioning failure
in our main machine room</a>,
one that certainly couldn't be fixed on the spot ('glycol all over
the roof' is not a phrase you really want to hear about your AC's
chiller). To keep the machine room's temperature down, we had to
power off as many machines as possible without too badly affecting
the services we offer to people here, <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OurDifferentSysadminEnvironment">which are rather varied</a>. Some choices were obvious; all
of <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SlurmHowWeUseIt">our SLURM nodes</a> that were in the main machine
room got turned off right away. But others weren't things we
necessarily remembered right away or we weren't clear if they were
safe to turn off and what effects it would have. In the end we took
several rounds of turning servers off, looking at what was left,
spotting remaining machines, and turning more things off, and we're
probably not done yet.</p>

<p>(We have secondary machine room space and we're probably going to
have to evacuate servers into it, too.)</p>

<p>One thing we could do to avoid this flailing in the future is to
explicitly (try to) keep track of which machines are important and
which ones aren't, to pre-plan which machines we could shut down
if we had a limited amount of cooling or power. If we documented
this, we could avoid having to wrack our brains at the last minute
and worry about dependencies or uses that we'd forgotten. Of course
documentation isn't free; there's an ongoing amount of work to write
it and keep it up to date. But possibly we could do this work as
part of deploying machines or changing their configurations.</p>

<p>(This would also help identify machines that we didn't need any
more but hadn't gotten around to taking out of service, which we
found a couple of in this iteration.)</p>

<p>Writing all of this just in case of further AC failures is probably
not all that great a choice of where to spend our time. But writing
down this sort of thing can often help to clarify how your environment
is connected together in general, including things like what will
probably break or have problems if a specific machine (or service)
is out, and perhaps which people depend on what service. This can
be valuable information in general. The machine room archaeology
of 'what is this machine, why is it on, and who is using it' can
be fun occasionally, but you probably don't want to do it regularly.</p>

<p>(Will we actually do this? I suspect not. When we deploy and start
using a machine its purpose and so on feel obvious, because we have
all of the context.)</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Will Satellite Megaconstellations Weaken Earth's Magnetic Field? (105 pts)]]></title>
            <link>https://spaceweatherarchive.com/2024/02/01/will-satellite-megaconstellations-weaken-earths-magnetic-field/</link>
            <guid>39272884</guid>
            <pubDate>Tue, 06 Feb 2024 10:40:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spaceweatherarchive.com/2024/02/01/will-satellite-megaconstellations-weaken-earths-magnetic-field/">https://spaceweatherarchive.com/2024/02/01/will-satellite-megaconstellations-weaken-earths-magnetic-field/</a>, See on <a href="https://news.ycombinator.com/item?id=39272884">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<main id="main" role="main">

					
			
<article id="post-6655">
	<!-- .entry-header -->

	<div>
		
<div><p><strong>Feb. 1, 2024:</strong> Something unprecedented is happening in Earth orbit. In only a few short years, the satellite population has skyrocketed, more than doubling since 2020. In the past year alone, more satellites have been launched than during the first thirty years of the Space Age. Much of this activity is driven by SpaceX and its growing mega-constellation of Starlink internet satellites.</p><p>Environmentalists have raised many concerns about Starlink including <a href="https://cps.iau.org/">light-pollution</a> of the night sky, a potentially hazardous <a href="https://www.nytimes.com/interactive/2023/11/08/magazine/space-traffic-jam.html">traffic jam</a> in low-Earth orbit, and even <a href="https://www.space.com/starlink-satellite-reentry-ozone-depletion-atmosphere">ozone depletion</a>. Copycat mega-constellations by other companies and countries will only multiply these concerns.</p><p>Now there’s a new reason to worry. According to <a href="https://arxiv.org/abs/2312.09329">a new study</a> by Sierra Solter, megaconstellations could alter and weaken Earth’s magnetic field.</p></div>


<div>
<figure><img data-attachment-id="6658" data-permalink="https://spaceweatherarchive.com/2024/02/01/will-satellite-megaconstellations-weaken-earths-magnetic-field/figure1_crop/" data-orig-file="https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg" data-orig-size="560,399" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="figure1_crop" data-image-description="" data-image-caption="" data-medium-file="https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg?w=300" data-large-file="https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg?w=560" width="560" height="399" src="https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg?w=560" alt="" srcset="https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg 560w, https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg?w=150 150w, https://spaceweatherarchive.files.wordpress.com/2024/02/figure1_crop.jpg?w=300 300w" sizes="(max-width: 560px) 100vw, 560px"></figure></div>


<div><p>Solter is a graduate student at the University of Iceland, working on her PhD in plasma physics. She recently realized something overlooked by many senior colleagues: “More than 500,000 satellites are expected in decades ahead, primarily to build internet megaconstellations. Every satellite that goes up will eventually come down, disintegrating in Earth’s atmosphere. This will create a massive layer of conducting, electrically charged particles around our planet.”</p><p>To understand the scale of the problem, consider the following: If you gathered up every charged particle in Earth’s Van Allen Belts, their combined mass would be only <a href="https://spacemath.gsfc.nasa.gov/weekly/5Page46.pdf">0.00018 kg</a>. Other components of the magnetosphere such as the ring current and plasmasphere are even less massive. For comparison, “the mass of a second generation Starlink satellite is 1250 kilograms, all of which will become conductive debris when the satellite is eventually de-orbited,” says Solter.</p><p>Metal debris from a single deorbited Starlink satellite is <strong>7 million times</strong> more massive than the Van Allen Belts. An entire megaconstellation is <strong>billions of times</strong> more massive. These ratios point to a big problem.</p></div>



<p>“The space industry is adding enormous amounts of material to the magnetosphere in comparison to  natural levels of particulate matter,” says Solter. “Due to the conductive nature of the satellite debris, this may perturb or change things.”</p>



<p>There is already evidence of this process in action. <a href="https://www.pnas.org/doi/10.1073/pnas.2313374120">A 2023 study</a> by researchers using a high-altitude NASA aircraft found that 10% of aerosols in the stratosphere contain aluminum and other metals from disintegrating satellites and rocket stages. These particles are drifting down from “the ablation zone” 70 to 80 km above Earth’s surface where meteors and satellites burn up.</p>



<p>Solter decided to look for changes in the electrical properties of the ablation zone–and she found something. A NASA model of the upper atmosphere shows a sharp increase in the “Debye Length” just where satellites break apart when they deorbit:</p>



<figure><img data-attachment-id="6657" data-permalink="https://spaceweatherarchive.com/2024/02/01/will-satellite-megaconstellations-weaken-earths-magnetic-field/debyelength_crop/" data-orig-file="https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg" data-orig-size="573,432" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="debyelength_crop" data-image-description="" data-image-caption="" data-medium-file="https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg?w=300" data-large-file="https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg?w=573" width="573" height="432" src="https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg?w=573" alt="" srcset="https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg 573w, https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg?w=150 150w, https://spaceweatherarchive.files.wordpress.com/2024/02/debyelength_crop.jpg?w=300 300w" sizes="(max-width: 573px) 100vw, 573px"></figure>



<p>“Debye Length” is a number that tells researchers how far an unbalanced electrical charge can be felt in conducting plasmas. The fact that it changes abruptly in the same place satellites disintegrate may be significant.</p>



<p>Extrapolating into the future, Solter worries that satellite debris could weaken Earth’s magnetic field–the same magnetic field that protects us from cosmic rays and solar storms.</p>



<p>“It’s a textbook undergraduate physics problem,” she explains. “Suppose you put a conductive shell (satellite debris) around a spherical magnet (Earth). Outside the shell, the magnetic field goes to zero due to shielding effects. This is a highly simplified comparison, of course, but we might actually be doing this to our planet.”&nbsp;&nbsp;</p>



<p>Solter’s preliminary study appears to show that the space industry is indeed perturbing the environment.&nbsp; “It is very concerning,” she concludes. “We absolutely cannot dump endless amounts of conductive dust into the magnetosphere and not expect some kind of impact. Multidisciplinary studies of this pollution are urgently needed.”</p>



<p>For more information, you can read Solter’s original research <a href="https://arxiv.org/pdf/2312.09329.pdf">here</a>.</p>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Destruction of nuclear bombs using ultra-high energy neutrino beam (2003) [pdf] (128 pts)]]></title>
            <link>https://arxiv.org/pdf/hep-ph/0305062.pdf</link>
            <guid>39271472</guid>
            <pubDate>Tue, 06 Feb 2024 06:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/pdf/hep-ph/0305062.pdf">https://arxiv.org/pdf/hep-ph/0305062.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39271472">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OKRs Are Bullshit (265 pts)]]></title>
            <link>https://blog.appliedcomputing.io/p/okrs-are-bullshit</link>
            <guid>39271083</guid>
            <pubDate>Tue, 06 Feb 2024 05:25:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.appliedcomputing.io/p/okrs-are-bullshit">https://blog.appliedcomputing.io/p/okrs-are-bullshit</a>, See on <a href="https://news.ycombinator.com/item?id=39271083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg" width="735" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:735,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:72261,&quot;alt&quot;:&quot;Buzz and Woody meme; Buzz says \&quot;OKRs!  OKRs are everywhere!\&quot; and Woody looks terrified&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Buzz and Woody meme; Buzz says &quot;OKRs!  OKRs are everywhere!&quot; and Woody looks terrified" title="Buzz and Woody meme; Buzz says &quot;OKRs!  OKRs are everywhere!&quot; and Woody looks terrified" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>It's a new year, time for a new rant</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-1-141320305" target="_self" rel="">1</a></span><span>! And yes, before you ask, the post title is deliberately provocative. You might say this is my ploy to get more paid subscribers, because only paid subscribers can leave comments and I expect that the title alone will make many of you want to comment. 😝</span></p><p><span>Anyways, I expect that many of my readers just finished up their quarterly (and/or yearly) planning cycle, so I thought this would be a good time to remind you all that the process we've all settled on in the tech industry is nonsense: I am, of course, referring to the </span><a href="https://en.wikipedia.org/wiki/Objectives_and_key_results" rel="">Objectives and Key Results</a><span> framework. So let's talk about OKRs, what they are and where they come from, and why they're a terrible idea</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-2-141320305" target="_self" rel="">2</a></span><span>.</span></p><p>The OKR framework was originally developed by Google back in—</p><p>Wait a minute, I just read the Wikipedia article I linked in the previous section, and it turns out I'm starting this off not only by being rude, but also spreading misinformation! How could I. Let's try this again.</p><p><span>OKRs were introduced by Andrew Grove at Intel, all the way back in the 1970s! He wrote about them in a book on management in 1983, and later they were introduced at Google, I guess sometime in the early 2000s. And while Google didn't </span><em>invent</em><span> the concept of OKRs, Google certainly helped popularize them</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-3-141320305" target="_self" rel="">3</a></span><span>. Now it doesn't matter where you go, every company has OKRs. The term has become like "Kleenex"—it's used ubiquitously to mean "planning", regardless of how similar or not the planning process actually is to the original OKR framework</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-4-141320305" target="_self" rel="">4</a></span><span>.</span></p><p><span>So with the backstory out of the way, what </span><em>are</em><span> OKRs? In short, they're a way of goal-setting and then measuring your progress towards the goals. The "Objective" is your goal, and the "Key Results" are the things you need to accomplish to know whether you've hit your goal. Of course because we want to be data-driven organizations, the key results need to be measurable and metrics-based.</span></p><p>Typically, OKRs are supposed to be cascading. In other words, the CEO (or whoever's in charge) sets some OKRs for the organization as a whole, and then the individual business units set OKRs that support the global OKRs, and then each team sets OKRs that support the business unit's, and (potentially) each team member sets their own personal OKRs. At each level, you should have between one and three objectives, which are short statements about "what" you want to accomplish in the next quarter, or year, or whatever, and each objective should have between one and three key results which indicate the success or failure of the objective.</p><p><span>In addition to the core framework, there are a few guiding principles that organizations should use when setting OKRs. Most (in)famously, you should set your OKRs so you only achieve 70% of them. If you're consistently hitting 100% on your goals, that means you're not being ambitious enough. Secondly, you should avoid "binary" OKRs, that is, OKRs whose only metric is "I did the thing" or "I didn't do the thing". Thirdly, OKRs aren't supposed to encompass all of your organization's activities: normal, day-to-day maintenance work, on-call support, etc. are "extra" things that don't get captured by your OKRs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-5-141320305" target="_self" rel="">5</a></span><span>. And lastly, the only way to learn OKRs is by doing OKRs.</span></p><p><span>Now, some of you are all prepared to whip out your credit cards and subscribe so you that you can angrily tell me that I've got it all wrong and that I don't understand the framework at all. That's fine—I'm happy to have you as a subscriber, but I think gets at my fundamental complaint about the OKR framework: if the "only way to learn OKRs is by doing OKRs", then by definition everybody is gonna do OKRs differently, which means that in practice the framework becomes whatever you want it to become. But then, when anybody comes out with </span><em>any</em><span> criticism of the OKR process, the response is always, in classic "</span><a href="https://en.wikipedia.org/wiki/No_true_Scotsman" rel="">no true Scotsman</a><span>" style, "well, you're just not doing OKRs correctly." But I guess my question is: if nobody in the industry does OKRs "correctly", why are we still trying to do them at all?</span></p><p><span>Now look: I'm not arguing that we shouldn't have goals. I'm not arguing that we shouldn't make plans and try to hold ourselves accountable to those plans. We absolutely should! Engineers like to rage against process, bureaucracy, and friction, but I'll be the first to tell you that—especially in larger organizations—</span><em>some</em><span> process is important. My only point in this article is to hopefully convince you that OKRs ain't it.</span></p><p>So let's talk about the problems with OKRs. I want to preface this section by saying that my background is an infra engineer, and a lot of the points I make come from that perspective. But I've heard enough similar complaints from product people that I think my objections are valid in that setting as well.</p><p><span>First of all, let's start with the frankly ridiculous claim that you should target 70% completion for your OKRs. Setting aside the fact that this is very nebulous (should you complete 70% of your goals to 100%? Or should you complete 100% of your goals at 70%?) consider that much of the work we do doesn't actually have any value unless you do it </span><em>all the way</em><span>. Now maybe if your key result was "increase clickthrough rate by 100%" and you only increased it by 70%, you could argue that is still pretty good. But if your key result is "migrate 100% of users to the new system" and you only migrate 70%, guess what? Now you're stuck maintaining two systems in perpetuity. Fortunately, I haven't heard people espouse this tenet as much lately—I think people are realizing that it incentivizes the wrong things.</span></p><p><span>But this leads us straight into the second problem with OKRs: actually measuring things. Some people might argue that the migration example I used above is actually bad because it's a binary OKR—either you migrated or you didn't. This leads to all kinds of contortions to develop a metric that still says "I migrated the thing" but isn't binary. Maybe you interview your customers and you want 100% of them to be happy on the new thing, but you'll count it as a success if only 70% of them are happy. Or maybe you measure the number of outages caused by the new thing, and your goal is "zero outages"</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-6-141320305" target="_self" rel="">6</a></span><span>.</span></p><p><span>However, there are additional problems here: one is that you just invented a bunch of extra work for yourself, because chances are whatever metric you concocted to measure your migration success didn't exist before: so you have to go build some tooling to collect the metric before you can even start working on the actual thing you care about—tooling and metrics that will probably languish and be forgotten about in a quarter or two after priorities change. Another is that often, the metrics you invent have no relation to the work you're doing—the happiness (or not) of your users probably has between five and zero percent to do with how good a job you did on the migration, and is 90% related to whether or not the new system was well-designed by somebody else who probably isn't even at the company anymore. A third is that some of these metrics are really hard to reason about. For example, in the "number of outages" metric, your target value is 0, which means that if you have </span><em>any outages at all</em><span> your score for that key result is undefined. You have to divide the number of outages you had by zero to get your percentage. Congratulations! Your metric value is whatever you want it to be!</span></p><p><span>I think the biggest problem with OKR's laser focus on measurement, though, is that </span><em>not everything should be measured</em><span>, even if you can! Being "data-driven" is a huge buzzword in the industry. We want to improve, we want to see how much we improved by, and then we want to tell the world how much we improved by so our stock price goes up. But there's a tremendous amount of work that shouldn't or can't be measured, or is very easy to misinterpret even if you </span><em>can</em><span> measure it. I think this article by Richard Marmorstein sums it up really nicely: </span><a href="https://twitchard.github.io/posts/2022-08-26-metrics-schmetrics.html" rel="">be good-argument driven, not data-driven</a><span>. Being data-driven requires a) that you have the metrics, b) that you know enough statistics to interpret the metrics correctly, and c) that you don't care about anything that can't be measured.</span></p><p>The last complaint I have about OKRs comes from their cascading nature. As an industry, we mostly rejected waterfall-style development a long time ago, and then promptly introduced a planning framework that encourages waterfall-style development. There's no room in the OKR framework for research or experimentation (because how do you measure research?), so you have to know what you want to do in excruciating detail at the point when you write down your OKR, because otherwise something might come up that prevents you from completing (or even getting 70%) on your OKR. But raise your hand if you've ever written down all your OKRs and then two months into the cycle, something comes up that obsoletes all of your goals.</p><p><span>"But wait, you're just doing it wrong!" I can hear you exclaim from here. "You're supposed to be agile! OKRs can change! You should react to new information!" Right, yep, I've heard that one before. But I can guarantee you that come performance review time, the people who decide whether you're being successful or not as an engineer are going to grade you on your original goals for the year, and if you have to change them it's going to be viewed as a failure. I mean, maybe this doesn't happen </span><em>everywhere</em><span>, but it will require a significant amount of cultural backpressure to prevent this outcome. So maybe just let's use a planning process that actually has room for change built in, instead of trying to shoehorn in one that just doesn't work.</span></p><p>You know what I didn't talk about at all in this blog post? Spreadsheets. Nowhere in the OKR framework does it say that you should list all your objectives and key results in a spreadsheet, and then check in on the metrics every month by updating some values in the spreadsheet. Nobody ever said that you should have a JIRA epic for your objectives, and then track all your tickets by which OKR they belong to. Nobody ever said anything about "internal OKRs" versus "external OKRs" or roadmaps or planning meetings or… the list goes on.</p><p><span>And yet, my prediction is that every single manager in existence, as soon as they hear “OKR” will immediately think "spreadsheet"</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-7-141320305" target="_self" rel="">7</a></span><span>. And I think that's a problem too. See, as an industry, we've conflated "OKRs" with "planning", when I don't think they should be conflated at all. Even if you brush aside all the problems I pointed out with OKRs in the previous section, and go back to the original (or at least, "original" as "made popular by Google") definition, the purpose of OKRs is to be aspirational. That's where the whole 70% thing comes from in the first place. We want to set hard goals that will inspire people to do their best work, and then recognize that the goals were hard and not penalize people for failing to meet them 100% of the way.</span></p><p><span>And honestly? When taken through that lens, I love OKRs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-8-141320305" target="_self" rel="">8</a></span><span>! We </span><em>should</em><span> be trying to do hard things, and we shouldn't be punishing folks when they fail at them. And, also: we </span><em>should</em><span> have a plan, and we should understand the work that we're going to be doing over the next few weeks-to-months, and </span><em>maybe</em><span> we need a spreadsheet or something to help manage that plan. But please, for the love of god, let's stop trying to shove metrics into our goal-setting framework, let's stop shoving our goal-setting framework into our quarterly planning process, and let's stop spending months on end planning only to have the whole thing upended two days into the cycle.</span></p><p>Anyways, that's all I've got for now. I promise next week I'll be less inflammatory.</p><p>Thanks for reading,</p><p>~drmorr</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vision 1993 (103 pts)]]></title>
            <link>https://www.tbray.org/ongoing/When/202x/2024/02/02/Vision-1993</link>
            <guid>39270681</guid>
            <pubDate>Tue, 06 Feb 2024 04:09:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tbray.org/ongoing/When/202x/2024/02/02/Vision-1993">https://www.tbray.org/ongoing/When/202x/2024/02/02/Vision-1993</a>, See on <a href="https://news.ycombinator.com/item?id=39270681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="centercontent">
<p itemprop="description">I’ve plowed through the first wave of AVP (Apple Vision Pro) reviews, and it seems pretty obvious that, at the current price
    and form factor, it’s not gonna be a best-seller.  But I remain a strong believer in Augmented Reality (the AVP is
    VR not AR, for the moment). As I was diving into the reviews, a little voice in the back of my head kept saying “I once read about
    what this is trying to be.”</p>

<p><img alt="William Gibson’s Virtual Light" title="William Gibson’s Virtual Light" src="https://www.tbray.org/ongoing/When/202x/2024/02/02/original.png"></p><p>What I was remembering was
    <a href="https://en.wikipedia.org/wiki/Virtual_Light">Virtual Light</a>, a 1993 novel by William Gibson, allegedly set in
    2006. It paints a clear picture of a future that includes AVP’s descendants. So I re-read it. Maybe looking back is the way to
    look forward.</p>

<p id="p-1"><span>But first…</span> · 
I wanted to say: It’s a terrific book! If you haven’t read you might really like it. I hadn’t in years and I sure
    enjoyed the re-read. The people in it are charming, and it’s built around a fabulous physical artifact that drives the plot. No, I
    don’t mean AR goggles, I mean San Francisco’s Bay Bridge, which in <cite>Virtual Light</cite> and
    <a href="https://en.wikipedia.org/wiki/Bridge_trilogy">two subsequent novels</a>, has
    been wrecked by an earthquake and become a huge countercultural shantytown, one of the coolest venues Gibson has ever
    invented, and that’s a strong statement. Also, protagonists Chevette and Rydell are two of his best characters; another
    strong statement.</p>

<p><img alt="William Gibson’s Virtual Light" title="William Gibson’s Virtual Light" src="https://www.tbray.org/ongoing/When/202x/2024/02/02/pink-face.png"></p><p>Anyhow, I don’t think it’s much of a spoiler to say that the AR devices I’m writing about, despite being what the title
    refers to, are peripheral to the plot. It turns out that one such device contains information that’s secret enough to attract
    hired killers, skip tracers, and crooked Homicide cops to recover it when it gets stolen; plenty of plot fuel right there.</p>

<p id="p-2"><span>Quoting</span> · 
Here are a few out-takes from the book describing the titular technology.</p>

<p>Quote:</p>

<blockquote>
<p>Nothing in it but a pair of sunglasses, expensive-looking but so dark she hadn’t even been able to see through them last
      night.</p>

</blockquote>
<p>Quote:</p>

<blockquote>
<p>…she took that case out.</p>

<p>You couldn’t tell what it was made of, and that meant expensive. Something dark gray, like the lead in a pencil, thin as the
      shell of one of those eggs, but you could probably drive a truck over it… She’d figured out how you opened it the night
      before: finger here, thumb there. It opened. No catch or anything, no spring… Inside was like black suede, but it gave like
      foam under your finger.</p>

<p>Those glasses, nested there. Big and black. Like that Orbison in the poster… She pulled them from the black suede… They
      bothered her …&nbsp;they weighed too much. Way too heavy for what they were, even with the big earpieces. The frames looked as
      though they’d been carved from slabs of graphite.</p>

<p>She put them on. Black. Solid black.</p>

<p>“Katharine Hepburn.” Skinner said.</p>

</blockquote>
<p>Quote:</p>

<blockquote><p>Warbaby wore a black Stetson set dead level on his head, the brim turned up all the way around, and glasses with
    heavy black frames. Clear lenses, windowpane plain.</p>
</blockquote>
<p>Quote:</p>

<blockquote><p>“You date you some architects, some brain-surgeons, you’d know what those are… Those <em>VL</em> glasses. Virtual
    light.”</p>

<p>“They expensive, Sammy Sal?”</p>

<p>“Shit, yes. ’Bout as much as a Japanese car… Got these little EMP-drivers around the lenses, work your optic nerves
    direct. Friend of mine, he’d bring a pair home from the office where he worked. Landscape architects. Put ’em on, you go out
    walking, everything looks normal, but every plant you see, every tree, there’s this little label hanging there, what its name
    is. Latin under that…”</p>
</blockquote>
<p>Quote (at a crime scene with Warbaby and Freddie):</p>

<blockquote><p>Rydell noticed the weight as he slid them on. Pitch black. Then there was a stutter of soft fuzzy ball-lightning,
    like what you saw when you rubbed your eyes in the dark, and he was looking at Warbaby. Just behind Warbaby, hung on some
    invisible wall, were words, numbers, bright yellow. They came into focus as he looked at them, somehow losing Warbaby, and he
    saw that they were forensic stats.</p>

<p>“Or,” Freddie said, “you can just be here <em>now</em> —”</p>

<p>And the bed was back, sodden with blood, the man’s soft, heavy corpse splayed out like a frog. That thing beneath his chin,
    blue-black, bulbous.</p>

<p>Rydell’s stomach heaved, bile rose in his throat, and then a naked woman rolled up from another bed, in a different room, her
    hair like silver in some impossible moonlight—</p>

<p>Rydell yanked the glasses off…</p>
</blockquote>
<p>Quote:</p>

<blockquote><p>“Here. Check it out.” He put them on her.</p>

<p>She was facing the city when he did it. Financial district… “Fuck a <em>duck</em>,” she said, those towers blooming there,
    buildings bigger than anything, a stone regular grid of them, marching in from the hills. Each one maybe four blocks at the
    base, rising straight and featureless to spreading screens likke the colander she used to steam vegetables. Then Chinese writing
    filled the sky.</p>

</blockquote>
<p id="p-3"><span>Hmmm…</span> · 
What does Gibson’s 30-year-old vision teach us?</p>

<ul>
<li><p>The devices are still heavier than you’d like, but light enough to wear all the time out in the real world.</p>
</li>
<li><p>Still expensive.</p>
</li>
<li><p>They look super-cool.</p>
</li>
<li><p>They are transparent while in use.</p>
</li>
<li><p>You can use them to show pictures or share information the way you would today by handing over a phone or
      tablet.</p>
</li>
<li><p>How you get information <em>into</em> them was as un-solved in 1993 as it is today.</p>
</li>
<li><p>But the real core value is the “A” in “AR”<span> —</span> <em>augmenting</em> an aspect of the real
      world that you’re looking at. Even if only by hanging text labels on it.</p>
</li>
</ul>
<p>For me, that last point is at the center of everything. I want to be in a park at night and see fiery snakes climbing all the
    trees. I want to walk into a big-box store and have a huge glowing balloon appear over the Baking Supplies. I want floating
    labels to attach to all the different parts of the machine I’m trying to fix.</p>

<p>Watching TV, by yourself, on a huge screen, is not the future. Augmenting reality is.</p>

<p>The AVP? Some of its tech constitutes
    necessary but far from sufficient steps on the way from here to that 1993 vision.</p>

<hr>


<hr>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LineageOS is currently installed on 1.5M Android devices (213 pts)]]></title>
            <link>https://9to5google.com/2023/11/20/lineageos-number-of-devices/</link>
            <guid>39270215</guid>
            <pubDate>Tue, 06 Feb 2024 02:54:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2023/11/20/lineageos-number-of-devices/">https://9to5google.com/2023/11/20/lineageos-number-of-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=39270215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?quality=82&amp;strip=all&amp;w=1250" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1250" height="625" alt="" fetchpriority="high">
	
	</figure>

<p>The custom ROM scene for Android devices isn’t nearly what it once was, but down to today, 1.5 million devices are currently running on LineageOS.</p>



<p>LineageOS is the project that took up the work of the once-great CyanogenMod, with the custom ROM having debuted its first builds back in 2016 and still running down to today. LineageOS is available on a <a href="https://wiki.lineageos.org/devices/">variety of different devices</a> from different Android brands, including Google, Fairphone, Samsung, OnePlus, Xiaomi, and more. It even keeps some long-gone brands going, like Essential and LG.</p>



<p>But how popular is LineageOS <em>really</em>?</p>



<p>That’s a question we have an answer to, thanks to a recent podcast episode.</p>



<p>David Imel of MKBHD’s WVFRM podcast sat down with members of the LineageOS team recently in a special episode, which went over the history of custom ROMs on Android. The episode is a great watch/listen, but <a href="https://youtu.be/TDOMekBPR4U?t=5107">one stat</a> in particular that caught our attention was that LineageOS is currently installed on around 1.5 million devices. There’s no word on how active those devices are, what they consist of, or how many different users that entails, but it’s the first look we’ve had in a while into how popular LineageOS actually is in a world where ROMs just aren’t as popular or necessary as they once were.</p>



<p>You can tune into <a href="https://youtu.be/TDOMekBPR4U">the full episode</a> below. </p>



<figure><p>
<iframe id="post-youtube-video-1" title="CyanogenMod and the Death of the Android ROM" width="500" height="281" data-src="https://www.youtube.com/embed/TDOMekBPR4U?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<h2 id="h-more-on-android">More on Android:</h2>



<ul>
<li><a href="https://9to5google.com/2023/07/27/pixel-tablet-lineageos-20/">Google Pixel Tablet gets support for LineageOS</a></li>



<li><a href="https://9to5google.com/2023/11/19/android-iphone-bullying-rcs/">Will RCS be enough to end the Android vs iPhone peer pressure and bullying?</a></li>



<li><a href="https://9to5google.com/2023/11/17/link-to-windows-oneplus-oppo-realme/">Link to Windows on PC now compatible with OnePlus, Oppo, and Realme phones</a></li>
</ul>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/3SWmaVQ"><img src="https://9to5google.com/wp-content/uploads/sites/4/2023/11/ROBOROCK-BF-BANNER-on-all-3-sites-Nov-20-26-750x150-1.jpg?quality=82&amp;strip=all" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla's Abandoned Web Engine 'Servo' Project Is Getting a Well-Deserved Reboot (280 pts)]]></title>
            <link>https://news.itsfoss.com/servo-rust-web-engine/</link>
            <guid>39269949</guid>
            <pubDate>Tue, 06 Feb 2024 02:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.itsfoss.com/servo-rust-web-engine/">https://news.itsfoss.com/servo-rust-web-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=39269949">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <div>



      <p>The developers of Servo are starting 2024 by going all in. </p><p>Spotted by <a href="https://mstdn.io/@codewiz/111868362077005163?ref=news.itsfoss.com" rel="noreferrer">Bernie Innocenti</a> when he was visiting <a href="https://fosdem.org/2024/?ref=news.itsfoss.com" rel="noreferrer">FOSDEM 2024</a>, the Servo Project team were there showing off the work done so far.</p><figure><img src="https://news.itsfoss.com/content/images/2024/02/Servo_a-1.jpg" alt="a photo showing a servo project member presenting servo's journey so far" loading="lazy" width="2000" height="1278" srcset="https://news.itsfoss.com/content/images/size/w600/2024/02/Servo_a-1.jpg 600w, https://news.itsfoss.com/content/images/size/w1000/2024/02/Servo_a-1.jpg 1000w, https://news.itsfoss.com/content/images/size/w1600/2024/02/Servo_a-1.jpg 1600w, https://news.itsfoss.com/content/images/size/w2400/2024/02/Servo_a-1.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Pic Credits: </span><a href="https://mstdn.io/@codewiz/111868362077005163?ref=news.itsfoss.com" rel="noreferrer"><span>Bernie Innocenti</span></a></figcaption></figure><p>That got me wondering; <strong>What's the progress with Servo nowadays?</strong> 🤔</p><p>If you were not familiar, <a href="https://servo.org/?ref=news.itsfoss.com" rel="noreferrer">Servo</a> is <strong>an experimental browser engine</strong> that leverages the power of Rust to provide a memory-safe and modular experience that is highly adaptable.</p><p>After Mozilla created Servo back in 2012 as a research project, it saw its share of ups and downs over the years, with it <a href="https://news.itsfoss.com/mozilla-servo-web-engine/" rel="noreferrer">making a comeback</a> in 2023; thanks to a fresh approach by the developers on how Servo should move forward.</p><p>Even though there are plenty of <a href="https://itsfoss.com/open-source-browsers-linux/?ref=news.itsfoss.com" rel="noreferrer">open source Chrome alternatives</a>; With this, there's a chance that we will get some really cool options based on Servo that just might give Blink and Gecko a run for the money! 😃</p><p>Let's see how The Servo Project has fared so far, and what's in store for it in 2024.</p><div><p>📋</p><p><a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)?ref=news.itsfoss.com" rel="noreferrer">Blink</a> is used by Chromium, and other browsers based on it, whereas <a href="https://en.wikipedia.org/wiki/Gecko_(software)?ref=news.itsfoss.com" rel="noreferrer">Gecko</a> is used by Firefox and a few others.</p></div><h2 id="servo-what-to-expect">Servo: What to Expect?</h2><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/9lkIX5ryZZ4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Servo Web Rendering Engine Reboot - Manuel Rego, Igalia"></iframe></figure><p>Just a few months back, in September 2023, after The Servo Project <a href="https://www.igalia.com/2023/09/07/The-Servo-project-is-joining-Linux-Foundation-Europe.html?ref=news.itsfoss.com" rel="noreferrer">officially joined</a> Linux Foundation Europe, the existing contributors from <a href="https://www.igalia.com/?ref=news.itsfoss.com" rel="noreferrer">Igalia</a> stepped up their game by taking over the project maintenance.</p><p>To complement that, at Open Source Summit Europe last year, <a href="https://twitter.com/regocas?ref=news.itsfoss.com" rel="noreferrer">Manuel Rego</a> from Igalia shared some really <a href="https://www.youtube.com/watch?v=9lkIX5ryZZ4&amp;ref=news.itsfoss.com" rel="noreferrer">useful insights</a> when he presented.</p><p>He showcased stuff like the <strong>WebGL support</strong>, <strong>cross-platform support</strong> including <strong>mobile support</strong> for Android and Linux, among other things. </p><p>They have experimented with Servo for embedded applications use-cases (like running it on Raspberry Pi), and have plans to make advances on it. As far as I can see, it looks like, Servo is faster for Raspberry Pi compared to Chromium 🤩</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/oDqDrvxLxyI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Servo On Raspberry Pi"></iframe></figure><p>You can explore more such demos on <a href="https://demo.servo.org/?ref=news.itsfoss.com" rel="noreferrer">Servo's demo webpage</a>.</p><p>Not to forget, a new layout engine is also in the works, where new features and compatibility arrangements are being made within its development.</p><p><strong>Did you know that even though Mozilla dropped the experimental project, Firefox still utilizes some servo components in the browser? </strong>😉</p><p>Naturally, that makes us wonder if the newer Servo layout engine (or any other component) might make it into the Firefox (<em>never say never!</em>).</p><p>Back then, Servo was still considered experimental, and in 2024, I hope that progresses a bit further.</p><p>Seeing this is an independent project, <strong>the progress so far looks very promising</strong>, the official website <a href="https://servo.org/about/?ref=news.itsfoss.com" rel="noreferrer">now lists</a> an updated roadmap for 2024 that pretty much has the same things for all of 2024.</p><figure><img src="https://news.itsfoss.com/content/images/2024/02/Servo_b.png" alt="a screenshot of the 2024 roadmap for servo" loading="lazy" width="2000" height="449" srcset="https://news.itsfoss.com/content/images/size/w600/2024/02/Servo_b.png 600w, https://news.itsfoss.com/content/images/size/w1000/2024/02/Servo_b.png 1000w, https://news.itsfoss.com/content/images/size/w1600/2024/02/Servo_b.png 1600w, https://news.itsfoss.com/content/images/size/w2400/2024/02/Servo_b.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>There's <strong>project maintenance and outreach</strong> that will include the usual project maintenance tasks alongside community management, then there's the <strong>implementation of CSS support</strong> which will see work being done on providing basic CSS features for the Servo layout engine.</p><p>With <strong>embedding API definition</strong>, the Servo team will finish work on defining the Servo webview API in collaboration with <a href="https://tauri.app/?ref=news.itsfoss.com" rel="noreferrer">Tauri</a> while also implementing new features and requirements for the API.</p><p>And, finally, we have <strong>Initial Android support</strong>, that will see Servo being made to build on modern Android versions, with the developers publishing nightly APKs on the official website some time in the future.</p><p>For staying in sync with the Servo roadmap, you can follow the <a href="https://github.com/servo/servo/wiki/Roadmap?ref=news.itsfoss.com" rel="noreferrer">official roadmap</a>, and for more details regarding this project, you may head over to its <a href="https://github.com/servo/servo?ref=news.itsfoss.com" rel="noreferrer">GitHub repo</a> or its official <a href="https://servo.zulipchat.com/?ref=news.itsfoss.com" rel="noreferrer">Zulip chat</a>.</p><p><em>💬 What do you think of Servo? Will it rise to become a strong contender to the likes of Blink and Gecko?</em></p>

      <interaction data-token="63fb391e4c763100127fc03a" data-context="true" data-tags="" data-fallback="true"></interaction>

      <hr>
      
      <h2 id="more-from-its-foss">More from It's FOSS...</h2>
      <ul>
          <li>Learn Bash scripting for FREE with this <a href="https://itsfoss.com/bash-scripting-tutorial/">Bash Tutorial series</a>.</li>
          <li>Join our <a href="https://itsfoss.community/">community forum</a>.</li>
          <li>📩 Stay updated with the latest on Linux and Open Source. Get our <a href="https://itsfoss.com/newsletter/">weekly Newsletter</a>.</li>
      </ul>
      
    </div>


        

    
    

    

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New viruslike entities found in human gut microbes (144 pts)]]></title>
            <link>https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes</link>
            <guid>39269497</guid>
            <pubDate>Tue, 06 Feb 2024 01:10:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes">https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes</a>, See on <a href="https://news.ycombinator.com/item?id=39269497">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Companies embracing SMS for account logins should be blamed for SIM-swap attacks (416 pts)]]></title>
            <link>https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/</link>
            <guid>39269327</guid>
            <pubDate>Tue, 06 Feb 2024 00:48:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/">https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/</a>, See on <a href="https://news.ycombinator.com/item?id=39269327">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-823">
	<!-- .entry-header -->

	<div>
		
<p>SIM-swap attacks continue year after year because companies (that know better) <em>leaned into</em> the awful idea of using SMS for password resets and account logins. These companies include Apple, Dropbox, PayPal, Block, Google, and many others.</p>



<p>What is a SIM-swap attack? It’s where a bad guy asks a carrier to port your cell-phone number to their phone. (Carriers are required to port your number easily because of <a href="https://en.wikipedia.org/wiki/Local_number_portability#:~:text=In%20the%20United%20States%2C%2047,Federal%20Communications%20Commission%20(FCC).">pro-competition laws in the US</a>.) Then, the crook triggers and receives account login info via SMSes from companies and proceeds to steal money and sensitive info from the victim. It happens all the time… Here are just <a href="https://techmeme.com/search/query?q=sim&amp;wm=false">a few of the higher profile instances</a>:</p>



<figure><img fetchpriority="high" decoding="async" width="988" height="1024" src="https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-988x1024.png" alt="" srcset="https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-988x1024.png 988w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-289x300.png 289w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-768x796.png 768w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-1482x1536.png 1482w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-1976x2048.png 1976w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-982x1018.png 982w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-386x400.png 386w" sizes="(max-width: 988px) 100vw, 988px"></figure>



<p>Is there a way to stop SIM swap attacks? Yes, it’s simple: Companies SHOULD NOT LET CUSTOMERS LOG IN via SMS, or allow password resetting via SMS. If SMS 2FA is offered, it should <strong><em>only</em> be</strong> if they provide more secure options like Authy or Google Authenticator (and SMS should not serve as a fallback for account recovery).</p>



<p>For many years, people in the industry have invariably said something like: “Well… offering SMS-based authentication is better *overall* for customer security, because of its <em>convenience</em> (despite its shortcomings) vs other methods” (such as the far-more secure-able use of email for verification).  To that I say: “who are *YOU* to deprive your customers of security?” Defending against targeted attacks must be an integral part of any company’s defense posture. It’s so arrogant to say otherwise, and it boils my blood, it really does. Offering SMS-based logins is a bad idea, and it never had a chance of being a good one. </p>



<p>Sending an SMS to a customer is like sending a postcard through the mail. It’s plaintext (not encrypted), and anyone can open your mailbox and intercept/read it (which is what happens in a SIM-swap attack). The protocol was never designed to be secure.</p>



<p>Is SMS the best option for password resets? NO! Reseting passwords via an email is far more secure. Is SMS a good 2FA option? No! Apps like Authy or using email is better. Is logging your customer in via SMS ever acceptable? No! [After reading Hacker News comments, let me be clear – I’m not <em>just</em> talking about SMS 2FA, in fact I’m primarily talking about the ubiquitous state of SMS-based password reseting, user onboarding, and account recovery. All are varying degrees of weak. SMS-based 2FA is, when offered as an option alongside stronger 2FA, the least bad of the weak-security scenarios but is not the focus of the post.]</p>



<p>Much of the ire relating to SIM-swap attacks has, understandably, been directed at carriers. Indeed, carriers do a terrible job of securing customers’ phone numbers, and <a href="https://www.techmeme.com/190723/p15#a190723p15">may be liable for that shortcoming</a>. But here’s the thing: carriers’ security <em>has always</em> been bad, it has even been legislated into being bad, and other companies have still <strong>chosen</strong> to build mission-critical systems on top of that weak link.</p>



<p>Despite it being commonplace, it is important to remember that baking SMS into authentication flows was an awful, shortsighted <strong><em>choice</em></strong> made by companies. Despite offering poor security, SMS offers a nearly frictionless way to sign up new customers (think of Uber’s onboarding) and handle password resets, and companies felt they had to match competitors’ adoption of this technique. They dug the hole, pushed us in, and now they must get us out.</p>



<p>Companies adopt the naive outlook that, somehow, crooks won’t try hard enough to SIM swap individuals. Clearly the criminals will – even to the point of <a href="https://www.techmeme.com/240130/p39#a240130p39">pretending to be customers at physical store locations</a>. It’s time for them to call it on this experiment. It failed.</p>



<p>And I’m sorry, but after nearly a decade, we can call it: efforts to strengthen telephony protocols like SHAKEN/STIR, will never happen. If the willpower had existed in the industry, it would have happened 5 years ago. Promises of protocol upgrades never were (and certainly are not now) a satisfactory excuse to continue to send password reset codes over SMS. Nor would a stronger protocol even stop SIM swap attacks. People are being harmed day-in and day-out, while the industry equivocates. </p>



<p>While SIM-swapping attacks are prevalent and headline-grabbing, SMSes are also vulnerable to man-in-the-middle attacks. These are likely carried out frequently by nation states. The fact that nation states can abuse SMS verification may even explain some of the overall inertia in allowing a broken system to remain.</p>



<p>If I sound heated, it’s because I’ve been banging this drum for over 7 years. Others <a href="https://www.forbes.com/sites/zakdoffman/2020/10/11/apple-iphone-imessage-and-android-messages-sms-passcode-security-update/">have written</a> about it years ago, and yet SIM-swap attacks continue unabated. I’m frustrated because many of these companies talk a big game about putting their customers’ safety and security first. I’m mad because, with all the intractable problems facing tech nowadays like deepfakes (including audio deepfakes that <a href="https://keydiscussions.com/2021/12/07/despite-the-prevalence-of-deepfake-audio-tech-banks-and-isps-rush-ahead-with-voice-print-authentication-%f0%9f%92%80/">I wrote about here</a>) and disinformation, this is one that <em>can actually be solved</em>, and yet nothing (concrete) is being done. We need a win, and here’s one for the taking!</p>



<p>To repeat: If some random person convinces T-Mobile, AT&amp;T, Verizon, etc to port my number, MY DIGITAL SAFETY SHOULD NOT BE PORTED AS WELL.</p>



<h2>How companies embraced this broken tech</h2>



<p><strong>Apple</strong>:</p>



<p>Apple helped seal SMS’ role in password resets and account logins via its keyboard feature it announced in 2018: <a href="https://support.apple.com/guide/iphone/automatically-fill-in-sms-passcodes-iphc89a3a3af/ios">Automatically fill in SMS passcodes on iPhone</a> . It also allows scenarios where SMS <a href="https://twitter.com/SpencerDailey/status/855190987370618881">can be used</a> to reset your Apple account. </p>



<p><strong>Google</strong>:</p>



<p>In 2019, Google followed Apple’s bad idea with the same thing for Android, <a href="https://www.xda-developers.com/google-play-services-sms-code-auto-fill/">SMS autofill</a> for one time codes.</p>



<p><strong>Cloud providers like Twilio/Amazon/Microsoft/Google etc</strong>:</p>



<p>There is a large industrial complex behind SMS codes. Many companies have profit incentives to continue offering SMS one time codes to customers.   <a href="https://azure.microsoft.com/en-us/updates/generally-available-azure-communication-services-short-code-functionality-for-sms/">Azure</a>, <a href="https://docs.aws.amazon.com/pinpoint/latest/developerguide/send-validate-otp.html">AWS</a>, <a href="https://www.twilio.com/en-us/pricing">Twilio</a>, <a href="https://www.google.com/search?q=google+cloud+sms+codes&amp;rlz=1C5CHFA_enUS975US978&amp;oq=google+cloud+sms+codes&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhA0gEINTY2M2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8">Google</a>, etc. Selling these services is unethical.  It’s a fundamentally broken technology, sold as a secure solution.<br></p>



<p><strong>Money management services</strong></p>



<p>Unbelievably, SMS reset/account login functionality is completely ubiquitous even when it comes to your money: <a href="https://www.wellsfargo.com/privacy-security/advanced-access/">Wells Fargo</a>, <a href="https://www.reddit.com/r/Scams/comments/f0cuyq/cash_app_texting_me_with_signin_code_out_of_the/">Cash App (Block)</a>, <a href="https://robinhood.com/us/en/support/articles/verifying-its-you/">Robinhood</a>, <a href="https://www.schwab.com/legal/deviceid">Schwab</a>, <a href="https://www.paypal.com/us/cshelp/article/what-can-i-do-if-ive-changed-my-mobile-number-and-cant-log-in-help678">Paypal</a>, etc etc. Again, these are SMS options offered as a way of “verifying that it’s you”, something that SIM-swapping crooks love to hear. Also, never <a href="https://www.paypal.com/us/cshelp/article/what-can-i-do-if-ive-changed-my-mobile-number-and-cant-log-in-help678">carelessly change</a> your phone number, you’ll be locked out of your PayPal!</p>



<p><strong>Basically every</strong> other company at this point:</p>



<p>From food ordering services to <a href="https://www.techmeme.com/240122/p18#a240122p18">social <strong>networks</strong></a> and even data storage firms like <a href="https://help.dropbox.com/account-access/enable-two-step-verification"><strong>Dropbox</strong></a> — SMS is unfortunately, by default, a way to reset your account. If there’s even a way to turn it off, it’s incumbent upon <em>you the user</em>, to go in and opt out –service by service– and disable the crappy tech. Many services don’t offer an opt out.</p>



<h2>Customers think they like SMS reset options</h2>



<p>Customers don’t understand the broken nature of SMS resets. It’s not their job to. They appreciate that it’s more convenient than resets via email (an actually-secure option) or log in codes via 2FA apps like authenticator. iPhone’s SMS autofill is oftentimes (dubiously) <a href="https://journa.host/deck/@spencerdailey/111585692105278478">heralded</a> as the best thing in iOS. The issue is: it’s not the customer’s job to understand whether systems are secure, it’s tech companies’. </p>



<p>And tech companies have failed, leaving all of their customers exposed in the process. </p>



<p>Hopefully a combination of lawsuits and legislation will eventually change the status quo. In the meantime, <strong>companies need to be brave</strong> and call the situation for what it is: a complete shit show. And then roll back their support of SMS verification services.</p>



<h2><strong>A few more things:</strong> </h2>



<p><strong>Robust Identity services are more important than ever in the age of deepfakes.</strong></p>



<p>Moving away from telephone-number-based identity services is a major and necessary step in realizing robust means of customer identification, which is even more important these days. The era of old school KYC (Know Your Customer) enforcement is over, <a href="https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/">with fake ID AI services going mainstream</a>. We should move away from unencrypted, SIM-swap-prone verification identity services like SMS.</p>



<p><strong>Many ransomware attacks are downstream of SIM-swap attacks</strong></p>



<p>Another seemingly intractable problem facing IT around the world is <a href="https://www.theverge.com/2024/2/5/24059486/ransomware-victims-palo-alto-networks-unit-42">ransomware</a>. SIM-swapping attacks represent a significant vector for compromising a company’s network. Again, rolling back support for SMS logins could take a bite out of the ransomware scourge.</p>



<p><strong>One <a href="https://news.ycombinator.com/item?id=39269643">HN commenter mentioned</a> the <a href="https://www.sfrpay.fr/Nos-solutions/Mobile-ID/SIM-Verify">“SIM Verify” initiative in the EU</a>, </strong>where companies relying on SMS can at least check to see if a SIM had recently been ported. That’s something, and we’ll see if it goes anywhere, but if the SHAKEN/STIR rollout has taught me anything, changes like this may happen in a decade not a year.</p>



<p><strong>Finally, a dedicated home to this question</strong></p>



<p>I <a href="https://www.metafruit.com/smssecurity/">created a site at a permanent URL</a> that bluntly answers the question “Is using SMS for logins a good idea?”, for sharing with people in the industry.</p>








			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I worked 80 hour weeks to deliver a platform for a hedge fund,then they fired me (166 pts)]]></title>
            <link>https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me</link>
            <guid>39269284</guid>
            <pubDate>Tue, 06 Feb 2024 00:42:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me">https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me</a>, See on <a href="https://news.ycombinator.com/item?id=39269284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div _ngcontent-ng-c2603034510="" id="articleDetail" ngskiphydration=""><p>I built a systematic trading platform for a <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/finance/how-to-get-a-hedge-fund-job">hedge fund</a>. I delivered an excellent platform ahead of time, but then they fired me, and now I can’t find a new job in what's a very difficult employment market.</p><p><a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/myefc/preferences/subscribe?newsletter=network_newsletter">Get Morning Coffee&nbsp;</a><span>☕</span><a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/myefc/preferences/subscribe?newsletter=network_newsletter">&nbsp;in your inbox. Sign up here.</a><o:p></o:p></p><p>I shouldn’t even be looking for a job right now. I’m only on the market because I became surplus to requirements. Effectively, I was “fired” for being too effective in my previous role.<o:p></o:p></p><p>I joined the startup hedge fund last year. In the short period while I worked there, I built an order management system which allowed the firm to make its first eve trades. A typical week for me included working between 70 and 80 hours a week. I worked almost every weekend, and almost every day for the entire time, without a single day of holiday.<o:p></o:p></p><p>I did this for two reasons. Firstly, I was told repeatedly that the faster the firm was able to start trading, the faster I would start earning bonuses from the firm's PnL, assuming that the strategies indeed were profitable. (It is my understanding that they are highly profitable.)<o:p></o:p></p><p>Secondly, I loved my job. Every day, I got to build really cool stuff, all while learning a new language which was unfamiliar to me – <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/2023/03/rust-jobs-in-finance">Rust. </a>Every day, I was learning more about <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/2020/09/rust-vs-c-hedge-fund-jobs">Rust,</a> Kafka, and the range of other technologies which we were leveraging. It was pretty great.<o:p></o:p></p><p>After months of hard work, the system finally went into production, and trades started flowing around the system. Two days later I was let go. I arrived in the office the morning after 48 hours of profit making, and was called into a private office. I was told it was “with regret” that my contract would be terminated that day, and that the “substantial bonus” which would be paid to me was “thanks” for the critical role I played in starting the company.<o:p></o:p><o:p></o:p></p><p>While I in no way regret working for the fund, as I gained a fast amount of experience in a relatively short period of time, I do regret not being more tactical with my work. I could have simply worked 40 hours a week. Had I done so, it is likely I would still be employed, still building the platform today.<o:p></o:p></p><p>Since the day I left, I have been relentlessly job searching. But so far I have found nothing. I was told in an interview for a <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/jobs/quantitative-analyst">junior quant</a> position that it was “a bit of a red flag” that I worked somewhere for such a short period of time.&nbsp;<o:p></o:p></p><p>So is that it? I know the job market is tough right now, but have I snookered myself and made myself unemployable for working too effectively during my last role?&nbsp;<o:p></o:p></p><p>I think I have applied to every hedge fund and investment bank in London. My applications either received an automatic rejection, or simply no response in the majority of cases. In the handful of cases where I have been offered an interview, most have been initial conversations, followed by radio silence – not even a rejection email.<o:p></o:p></p><p>It seems that during such a dire economy, the dream of a junior quant role is out of reach, for now. Any advice would be greatly appreciated.&nbsp;</p><p><i>Milan Gill is a pseudonym&nbsp;</i></p><p>&nbsp;<i><strong>Have a confidential story, tip, or comment you’d like to share?&nbsp;Contact: +44&nbsp;7537 182250 (SMS, Whatsapp or voicemail).&nbsp;Telegram: @SarahButcher.&nbsp;</strong></i><a rel="noreferrer noopener" target="_blank" title="https://www.efinancialcareers.co.uk/about/editor-tips"><i><strong>Click here to fill in our anonymous form</strong></i></a><i><strong>, or email editortips@efinancialcareers.com. Signal also available.</strong></i></p><p><i>Bear with us if you leave a comment at the bottom of this article: all our comments are moderated by human beings. Sometimes these humans might be asleep, or away from their desks, so it may take a while for your comment to appear. Eventually it will – unless it’s offensive or libelous (in which case it won’t.)</i><span>.</span><o:p></o:p></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The little SSH that sometimes couldn't (2012) (178 pts)]]></title>
            <link>https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html</link>
            <guid>39268530</guid>
            <pubDate>Mon, 05 Feb 2024 23:14:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html">https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html</a>, See on <a href="https://news.ycombinator.com/item?id=39268530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h3 id="preface">Preface</h3>
<p>This is a technical article chronicling one of the most interesting bug hunts I’ve had the pleasure of chasing down.</p>
<p>At <a href="http://adgear.com/">AdGear Technologies Inc.</a> where I work, ssh is king.  We use it for management, monitoring, deployments, log file harvesting, even some event streaming.  It’s solid, reliable, has all the predictability of a native unix tool, and just works.</p>
<p>Until one day, random cron emails started flowing about it not working.</p>
<h3 id="the-timeout">The timeout</h3>
<p>The machines in our London data center were randomly failing to send their event log files to our data machines in our Montreal data center.  This job is initiated periodically from cron, and the failure manifested itself as:</p>
<ul>
<li>cron emails stating that the ssh was unsuccessful
<ul>
<li>Sometimes hangs</li>
<li>Sometimes exits with a timeout error</li>
</ul>
</li>
<li>monitoring warnings down the line for in-house sanity checks detecting the missing data in Montreal</li>
</ul>
<p>We logged into the London machines, manually ran the push command, and it worked successfully.  We brushed it off as temporary network partitions.</p>
<h3 id="the-timeouts">The timeouts</h3>
<p>But the failures kept popping up randomly.  Once a day, a couple of times a day, then one Friday morning, several times an hour.  It was clear something’s getting worse.  We kept up with manually pushing the files until we figure out what the problem was.</p>
<p>There were 17 hops between London and Montreal.  We built a profile of latency and packet loss for them, and found that a couple were losing 1-3% of packets.  We filed a ticket with our London DC ops to route away from them.</p>
<p>While London DC ops were verifying the packet loss, we started seeing random timeouts from London to our SECOND data center in Montreal, and hops to that data center did not share the same routes we observed the packet loss at.  We concluded packet loss is not the main problem around the same time London DC ops replied saying they’re not able to replicate the packet loss or timeouts and that everything looked healthy on their end.</p>
<h3 id="the-revelation">The revelation</h3>
<p>While manually keeping up with failed cron uploads, we noticed an interesting pattern.  A file transfer either succeeded at a high speed, or didn’t succeed at all and hung/timed out.  There were no instances of a file uploading slowly and finishing successfully.</p>
<p>Removing the large volume of data from the equation, we were able to recreate the scenario via simple vanilla ssh.  On a London machine an “ssh mtl-machine” would either work immediately, or hang and never establish a connection.  Eyebrows started going up.</p>
<h3 id="where-the-wild-packets-are">Where the wild packets are</h3>
<p>We triple-checked the ssh server configs and health in Montreal:</p>
<ul>
<li>The servers appeared healthy by all measures</li>
<li>SSHd DNS reverse lookup was not enabled</li>
<li>SSHd Maximum client connections was high enough</li>
<li>We were not under attack</li>
<li>Bandwidth usage was nowhere near saturation</li>
</ul>
<p>Besides, even if something was off, we were observing the hangs talking to 2 completely distinct data centers in Montreal.  Furthermore, our other data centers (non-London) were talking happily to Montreal.  Something about London was off.</p>
<p>We fired up tcpdump and started looking at the packets, both in summary and in captured pcaps loaded into wireshark.  We saw telltale signs of packet loss and retransmission, but it was minimal and not particularly worrisome.</p>
<p>We then captured full connections from cases where ssh established successfully, and full connections from cases where the ssh connection hung.</p>
<p>Here’s what we logically saw when a connection from London to Montreal hung:</p>
<ul>
<li>Normal TCP handshake</li>
<li>Bunch of ssh-specific back and forth, with normal TCP ACK packets where they should be</li>
<li>A particular packet sent from London and received in Montreal</li>
<li>The same packet re-sent (and re-sent, several times) from London and received in Montreal</li>
<li>Montreal’s just not responding to it!</li>
</ul>
<p>It didn’t make sense why Montreal was not responding (hence London re-transmitting it).  The connection was stalled at this point, as the layer 4 protocol was at a stalemate.  More infuriatingly, if you kill the ssh attempt in London and re-launched it immediately, odds are it worked successfully.  When it did, tcpdump showed Montreal receiving the packet but responding to it, and things moved on.</p>
<p>We enabled verbose debugging (-vvv) on the ssh client in London, and the hang occurred after it logged:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>debug2: kex_parse_kexinit: first_kex_follows 0 
</span></span><span><span>debug2: kex_parse_kexinit: reserved 0 
</span></span><span><span>debug2: mac_setup: found hmac-md5
</span></span><span><span>debug1: kex: server-&gt;client aes128-ctr hmac-md5 none
</span></span><span><span>debug2: mac_setup: found hmac-md5
</span></span><span><span>debug1: kex: client-&gt;server aes128-ctr hmac-md5 none
</span></span><span><span>debug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024&lt;1024&lt;8192) sent
</span></span><span><span>debug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP</span></span></code></pre></div>
<p>Googling “ssh hang SSH2_MSG_KEX_DH_GEX_GROUP” has many results - from bad WiFi, to windows TCP bugs, to buggy routers discarding TCP fragments.  One solution for LANs was to figure out the path’s MSS and set that as the MTU on both ends.</p>
<p>I kept decrementing the MTU on a London server down from 1500 - it didn’t help until I hit the magic value 576.  At that point, I was no longer able to get the ssh hanging behavior replicated.  I had an ssh loop script running, and it was on-demand that I could cause timeouts by bringing the MTU back up to 1500, or make them disappear by setting it to 576.</p>
<p>Unfortunately these are public web servers and globally setting the MTU to 576 won’t cut it, but the above did suggest that perhaps packet fragmentation or reassembly is broken somewhere.</p>
<p>Going back to check the received packets with tcpdump, there was no evidence of fragmentation.  The received packet size matched exactly the packet size sent.  If something did fragment the packet at byte 576+, something else reassembled it successfully.</p>
<h3 id="twinkle-twinkle-little-mis-shapen-star">Twinkle twinkle little mis-shapen star</h3>
<p>Digging in some more, I was now looking at full packet dumps (tcpdump -s 0 -X) instead of just the headers.  Comparing that magic packet in instances of ssh success vs ssh hang showed very little difference aside from TCP/IP header variations.  It was however clear that this is the first packet in the TCP connection that had enough data to bypass the 576-byte mark - all previous packets were much smaller.</p>
<p>Comparing the same packet, during a hanging instance, as it left London, and as captured in Montreal, something caught my eye.  Something very subtle, and I brushed it off as fatigue (it was late Friday at this point), but sure enough after a few refreshes and comparisons, I wasn’t imagining things.</p>
<p>Here’s the packet as it left London (minus the first few bytes identifying the IP addresses):</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0040:  0b7c aecc 1774 b770 ad92 0000 00b7 6563  .|...t.p......ec
</span></span><span><span>0x0050:  6468 2d73 6861 322d 6e69 7374 7032 3536  dh-sha2-nistp256
</span></span><span><span>0x0060:  2c65 6364 682d 7368 6132 2d6e 6973 7470  ,ecdh-sha2-nistp
</span></span><span><span>0x0070:  3338 342c 6563 6468 2d73 6861 322d 6e69  384,ecdh-sha2-ni
</span></span><span><span>0x0080:  7374 7035 3231 2c64 6966 6669 652d 6865  stp521,diffie-he
</span></span><span><span>0x0090:  6c6c 6d61 6e2d 6772 6f75 702d 6578 6368  llman-group-exch
</span></span><span><span>0x00a0:  616e 6765 2d73 6861 3235 362c 6469 6666  ange-sha256,diff
</span></span><span><span>0x00b0:  6965 2d68 656c 6c6d 616e 2d67 726f 7570  ie-hellman-group
</span></span><span><span>0x00c0:  2d65 7863 6861 6e67 652d 7368 6131 2c64  -exchange-sha1,d
</span></span><span><span>0x00d0:  6966 6669 652d 6865 6c6c 6d61 6e2d 6772  iffie-hellman-gr
</span></span><span><span>0x00e0:  6f75 7031 342d 7368 6131 2c64 6966 6669  oup14-sha1,diffi
</span></span><span><span>0x00f0:  652d 6865 6c6c 6d61 6e2d 6772 6f75 7031  e-hellman-group1
</span></span><span><span>0x0100:  2d73 6861 3100 0000 2373 7368 2d72 7361  -sha1...#ssh-rsa
</span></span><span><span>0x0110:  2c73 7368 2d64 7373 2c65 6364 7361 2d73  ,ssh-dss,ecdsa-s
</span></span><span><span>0x0120:  6861 322d 6e69 7374 7032 3536 0000 009d  ha2-nistp256....
</span></span><span><span>0x0130:  6165 7331 3238 2d63 7472 2c61 6573 3139  aes128-ctr,aes19
</span></span><span><span>0x0140:  322d 6374 722c 6165 7332 3536 2d63 7472  2-ctr,aes256-ctr
</span></span><span><span>0x0150:  2c61 7263 666f 7572 3235 362c 6172 6366  ,arcfour256,arcf
</span></span><span><span>0x0160:  6f75 7231 3238 2c61 6573 3132 382d 6362  our128,aes128-cb
</span></span><span><span>0x0170:  632c 3364 6573 2d63 6263 2c62 6c6f 7766  c,3des-cbc,blowf
</span></span><span><span>0x0180:  6973 682d 6362 632c 6361 7374 3132 382d  ish-cbc,cast128-
</span></span><span><span>0x0190:  6362 632c 6165 7331 3932 2d63 6263 2c61  cbc,aes192-cbc,a
</span></span><span><span>0x01a0:  6573 3235 362d 6362 632c 6172 6366 6f75  es256-cbc,arcfou
</span></span><span><span>0x01b0:  722c 7269 6a6e 6461 656c 2d63 6263 406c  r,rijndael-cbc@l
</span></span><span><span>0x01c0:  7973 6174 6f72 2e6c 6975 2e73 6500 0000  ysator.liu.se...
</span></span><span><span>0x01d0:  9d61 6573 3132 382d 6374 722c 6165 7331  .aes128-ctr,aes1
</span></span><span><span>0x01e0:  3932 2d63 7472 2c61 6573 3235 362d 6374  92-ctr,aes256-ct
</span></span><span><span>0x01f0:  722c 6172 6366 6f75 7232 3536 2c61 7263  r,arcfour256,arc
</span></span><span><span>0x0200:  666f 7572 3132 382c 6165 7331 3238 2d63  four128,aes128-c
</span></span><span><span>0x0210:  6263 2c33 6465 732d 6362 632c 626c 6f77  bc,3des-cbc,blow
</span></span><span><span>0x0220:  6669 7368 2d63 6263 2c63 6173 7431 3238  fish-cbc,cast128
</span></span><span><span>0x0230:  2d63 6263 2c61 6573 3139 322d 6362 632c  -cbc,aes192-cbc,
</span></span><span><span>0x0240:  6165 7332 3536 2d63 6263 2c61 7263 666f  aes256-cbc,arcfo
</span></span><span><span>0x0250:  7572 2c72 696a 6e64 6165 6c2d 6362 6340  ur,rijndael-cbc@
</span></span><span><span>0x0260:  6c79 7361 746f 722e 6c69 752e 7365 0000  lysator.liu.se..
</span></span><span><span>0x0270:  00a7 686d 6163 2d6d 6435 2c68 6d61 632d  ..hmac-md5,hmac-
</span></span><span><span>0x0280:  7368 6131 2c75 6d61 632d 3634 406f 7065  sha1,umac-64@ope
</span></span><span><span>0x0290:  6e73 7368 2e63 6f6d 2c68 6d61 632d 7368  nssh.com,hmac-sh
</span></span><span><span>0x02a0:  6132 2d32 3536 2c68 6d61 632d 7368 6132  a2-256,hmac-sha2
</span></span><span><span>0x02b0:  2d32 3536 2d39 362c 686d 6163 2d73 6861  -256-96,hmac-sha
</span></span><span><span>0x02c0:  322d 3531 322c 686d 6163 2d73 6861 322d  2-512,hmac-sha2-
</span></span><span><span>0x02d0:  3531 322d 3936 2c68 6d61 632d 7269 7065  512-96,hmac-ripe
</span></span><span><span>0x02e0:  6d64 3136 302c 686d 6163 2d72 6970 656d  md160,hmac-ripem
</span></span><span><span>0x02f0:  6431 3630 406f 7065 6e73 7368 2e63 6f6d  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="e98dd8dfd9a986998c879a9a81c78a8684">[email&nbsp;protected]</a>
</span></span><span><span>0x0300:  2c68 6d61 632d 7368 6131 2d39 362c 686d  ,hmac-sha1-96,hm
</span></span><span><span>0x0310:  6163 2d6d 6435 2d39 3600 0000 a768 6d61  ac-md5-96....hma
</span></span><span><span>0x0320:  632d 6d64 352c 686d 6163 2d73 6861 312c  c-md5,hmac-sha1,
</span></span><span><span>0x0330:  756d 6163 2d36 3440 6f70 656e 7373 682e  umac-64@openssh.
</span></span><span><span>0x0340:  636f 6d2c 686d 6163 2d73 6861 322d 3235  com,hmac-sha2-25
</span></span><span><span>0x0350:  362c 686d 6163 2d73 6861 322d 3235 362d  6,hmac-sha2-256-
</span></span><span><span>0x0360:  3936 2c68 6d61 632d 7368 6132 2d35 3132  96,hmac-sha2-512
</span></span><span><span>0x0370:  2c68 6d61 632d 7368 6132 2d35 3132 2d39  ,hmac-sha2-512-9
</span></span><span><span>0x0380:  362c 686d 6163 2d72 6970 656d 6431 3630  6,hmac-ripemd160
</span></span><span><span>0x0390:  2c68 6d61 632d 7269 7065 6d64 3136 3040  ,hmac-ripemd160@
</span></span><span><span>0x03a0:  6f70 656e 7373 682e 636f 6d2c 686d 6163  openssh.com,hmac
</span></span><span><span>0x03b0:  2d73 6861 312d 3936 2c68 6d61 632d 6d64  -sha1-96,hmac-md
</span></span><span><span>0x03c0:  352d 3936 0000 0015 6e6f 6e65 2c7a 6c69  5-96....none,zli
</span></span><span><span>0x03d0:  6240 6f70 656e 7373 682e 636f 6d00 0000  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="3153715e41545f4242591f525e5c">[email&nbsp;protected]</a>...
</span></span><span><span>0x03e0:  156e 6f6e 652c 7a6c 6962 406f 7065 6e73  .none,zlib@opens
</span></span><span><span>0x03f0:  7368 2e63 6f6d 0000 0000 0000 0000 0000  sh.com..........
</span></span><span><span>0x0400:  0000 0000 0000 0000 0000 0000            ............</span></span></code></pre></div>
<p>And here’s the same packet as it arrived in Montreal:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0040:  0b7c aecc 1774 b770 ad92 0000 00b7 6563  .|...t.p......ec
</span></span><span><span>0x0050:  6468 2d73 6861 322d 6e69 7374 7032 3536  dh-sha2-nistp256
</span></span><span><span>0x0060:  2c65 6364 682d 7368 6132 2d6e 6973 7470  ,ecdh-sha2-nistp
</span></span><span><span>0x0070:  3338 342c 6563 6468 2d73 6861 322d 6e69  384,ecdh-sha2-ni
</span></span><span><span>0x0080:  7374 7035 3231 2c64 6966 6669 652d 6865  stp521,diffie-he
</span></span><span><span>0x0090:  6c6c 6d61 6e2d 6772 6f75 702d 6578 6368  llman-group-exch
</span></span><span><span>0x00a0:  616e 6765 2d73 6861 3235 362c 6469 6666  ange-sha256,diff
</span></span><span><span>0x00b0:  6965 2d68 656c 6c6d 616e 2d67 726f 7570  ie-hellman-group
</span></span><span><span>0x00c0:  2d65 7863 6861 6e67 652d 7368 6131 2c64  -exchange-sha1,d
</span></span><span><span>0x00d0:  6966 6669 652d 6865 6c6c 6d61 6e2d 6772  iffie-hellman-gr
</span></span><span><span>0x00e0:  6f75 7031 342d 7368 6131 2c64 6966 6669  oup14-sha1,diffi
</span></span><span><span>0x00f0:  652d 6865 6c6c 6d61 6e2d 6772 6f75 7031  e-hellman-group1
</span></span><span><span>0x0100:  2d73 6861 3100 0000 2373 7368 2d72 7361  -sha1...#ssh-rsa
</span></span><span><span>0x0110:  2c73 7368 2d64 7373 2c65 6364 7361 2d73  ,ssh-dss,ecdsa-s
</span></span><span><span>0x0120:  6861 322d 6e69 7374 7032 3536 0000 009d  ha2-nistp256....
</span></span><span><span>0x0130:  6165 7331 3238 2d63 7472 2c61 6573 3139  aes128-ctr,aes19
</span></span><span><span>0x0140:  322d 6374 722c 6165 7332 3536 2d63 7472  2-ctr,aes256-ctr
</span></span><span><span>0x0150:  2c61 7263 666f 7572 3235 362c 6172 6366  ,arcfour256,arcf
</span></span><span><span>0x0160:  6f75 7231 3238 2c61 6573 3132 382d 6362  our128,aes128-cb
</span></span><span><span>0x0170:  632c 3364 6573 2d63 6263 2c62 6c6f 7766  c,3des-cbc,blowf
</span></span><span><span>0x0180:  6973 682d 6362 632c 6361 7374 3132 382d  ish-cbc,cast128-
</span></span><span><span>0x0190:  6362 632c 6165 7331 3932 2d63 6263 2c61  cbc,aes192-cbc,a
</span></span><span><span>0x01a0:  6573 3235 362d 6362 632c 6172 6366 6f75  es256-cbc,arcfou
</span></span><span><span>0x01b0:  722c 7269 6a6e 6461 656c 2d63 6263 406c  r,rijndael-cbc@l
</span></span><span><span>0x01c0:  7973 6174 6f72 2e6c 6975 2e73 6500 0000  ysator.liu.se...
</span></span><span><span>0x01d0:  9d61 6573 3132 382d 6374 722c 6165 7331  .aes128-ctr,aes1
</span></span><span><span>0x01e0:  3932 2d63 7472 2c61 6573 3235 362d 6374  92-ctr,aes256-ct
</span></span><span><span>0x01f0:  722c 6172 6366 6f75 7232 3536 2c61 7263  r,arcfour256,arc
</span></span><span><span>0x0200:  666f 7572 3132 382c 6165 7331 3238 2d63  four128,aes128-c
</span></span><span><span>0x0210:  6263 2c33 6465 732d 6362 632c 626c 6f77  bc,3des-cbc,blow
</span></span><span><span>0x0220:  6669 7368 2d63 6263 2c63 6173 7431 3238  fish-cbc,cast128
</span></span><span><span>0x0230:  2d63 6263 2c61 6573 3139 322d 6362 632c  -cbc,aes192-cbc,
</span></span><span><span>0x0240:  6165 7332 3536 2d63 6263 2c61 7263 666f  aes256-cbc,arcfo
</span></span><span><span>0x0250:  7572 2c72 696a 6e64 6165 6c2d 6362 7340  ur,rijndael-cbs@
</span></span><span><span>0x0260:  6c79 7361 746f 722e 6c69 752e 7365 1000  lysator.liu.se..
</span></span><span><span>0x0270:  00a7 686d 6163 2d6d 6435 2c68 6d61 732d  ..hmac-md5,hmas-
</span></span><span><span>0x0280:  7368 6131 2c75 6d61 632d 3634 406f 7065  sha1,umac-64@ope
</span></span><span><span>0x0290:  6e73 7368 2e63 6f6d 2c68 6d61 632d 7368  nssh.com,hmac-sh
</span></span><span><span>0x02a0:  6132 2d32 3536 2c68 6d61 632d 7368 7132  a2-256,hmac-shq2
</span></span><span><span>0x02b0:  2d32 3536 2d39 362c 686d 6163 2d73 7861  -256-96,hmac-sxa
</span></span><span><span>0x02c0:  322d 3531 322c 686d 6163 2d73 6861 322d  2-512,hmac-sha2-
</span></span><span><span>0x02d0:  3531 322d 3936 2c68 6d61 632d 7269 7065  512-96,hmac-ripe
</span></span><span><span>0x02e0:  6d64 3136 302c 686d 6163 2d72 6970 756d  md160,hmac-ripum
</span></span><span><span>0x02f0:  6431 3630 406f 7065 6e73 7368 2e63 7f6d  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="ddb9ecebed9db2adb8b3aeaeb5f3bef3b0">[email&nbsp;protected]</a>
</span></span><span><span>0x0300:  2c68 6d61 632d 7368 6131 2d39 362c 786d  ,hmac-sha1-96,xm
</span></span><span><span>0x0310:  6163 2d6d 6435 2d39 3600 0000 a768 7d61  ac-md5-96....h}a
</span></span><span><span>0x0320:  632d 6d64 352c 686d 6163 2d73 6861 312c  c-md5,hmac-sha1,
</span></span><span><span>0x0330:  756d 6163 2d36 3440 6f70 656e 7373 782e  umac-64@openssx.
</span></span><span><span>0x0340:  636f 6d2c 686d 6163 2d73 6861 322d 3235  com,hmac-sha2-25
</span></span><span><span>0x0350:  362c 686d 6163 2d73 6861 322d 3235 362d  6,hmac-sha2-256-
</span></span><span><span>0x0360:  3936 2c68 6d61 632d 7368 6132 2d35 3132  96,hmac-sha2-512
</span></span><span><span>0x0370:  2c68 6d61 632d 7368 6132 2d35 3132 3d39  ,hmac-sha2-512=9
</span></span><span><span>0x0380:  362c 686d 6163 2d72 6970 656d 6431 3630  6,hmac-ripemd160
</span></span><span><span>0x0390:  2c68 6d61 632d 7269 7065 6d64 3136 3040  ,hmac-ripemd160@
</span></span><span><span>0x03a0:  6f70 656e 7373 682e 636f 6d2c 686d 7163  openssh.com,hmqc
</span></span><span><span>0x03b0:  2d73 6861 312d 3936 2c68 6d61 632d 7d64  -sha1-96,hmac-}d
</span></span><span><span>0x03c0:  352d 3936 0000 0015 6e6f 6e65 2c7a 7c69  5-96....none,z|i
</span></span><span><span>0x03d0:  6240 6f70 656e 7373 682e 636f 6d00 0000  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="e183a18e91848f929289cf828e8c">[email&nbsp;protected]</a>...
</span></span><span><span>0x03e0:  156e 6f6e 652c 7a6c 6962 406f 7065 6e73  .none,zlib@opens
</span></span><span><span>0x03f0:  7368 2e63 6f6d 0000 0000 0000 0000 0000  sh.com..........
</span></span><span><span>0x0400:  0000 0000 0000 0000 0000 0000            ............</span></span></code></pre></div>
<p>Did something there catch your eye ?  If not, I don’t blame you.  Feel free to copy each into a text editor and rapidly switch back-and-forth to see some characters dance.  Here’s what it looks like when they’re placed in vimdiff:</p>
<p><img src="https://mina.naguib.ca/images/blog/vimdiff_packets.png" alt="Vim diff packet"></p>
<p>Well well well. It’s not packet loss, it’s packet corruption!  Very subtle, very predictable packet corruption.</p>
<p>Some interesting notes:</p>
<ul>
<li>The lower part of the packet (&lt;576 bytes) is unaffected</li>
<li>The affected portion is predictably corrupted on the 15th byte of every 16</li>
<li>The corruption is predictable.  All instances of “h” become “x”, all instances of “c” become “s”</li>
</ul>
<p>Some readers might have already checked ASCII charts and reached the conclusion:  There’s a single bit statically stuck at “1” somewhere.  Flipping the 4th bit in a byte to 1 would reliably corrupt the above letters on the left side to the value on the right side.</p>
<p>The obvious culprits within our control (NIC cards, receiving machines) are not suspect due to the pattern of failure observed (several London machines -&gt; Several Montreal data centers and machines).  It’s got to be something upstream and close to London.</p>
<p>Going back to validate, things started to make sense.  I also noticed a little hint in tcpdump verbose mode (tcp cksum bad) which was missed before.  A Montreal machine receiving this packet discarded it at the kernel level after realizing it’s corrupt, never passing it to the userland ssh daemon.  London then re-transmitted it, going through the same corruption, getting the same silent treatment.  From ssh and sshd’s perspective, the connection was at a stalemate.  From tcpdump’s perspective, there was no loss, and Montreal machines appeared to be just ignoring data.</p>
<p>We sent these findings to our London DC ops, and within a few minutes they changed outbound routes dramatically.  The first router hop, and most hops afterwards, were different.  The hanging problem disappeared.</p>
<p>Late Friday night fixes are nice because you can relax and not carry problems and support staff into the weekend :)</p>
<h3 id="wheres-waldo">Where’s Waldo</h3>
<p>Happy that we were no longer suffering from this problem and that our systems are caught up with the backlog, I decided I’d try my hand at actually finding the device causing the corruption.</p>
<p>Having the London routes updated to not go through the old path meant that I couldn’t reproduce the problem easily.  I asked around until I found a friend with a FreeBSD box in Montreal I could use, which was still accessed through the old routes from London.</p>
<p>Next, I wanted to make sure that the corruption is predictable even without ssh involvement.  This was trivially proven with a few pipes.</p>
<p>In Montreal:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>nc -l -p 4000 &gt; /dev/null</span></span></code></pre></div>
<p>Then in London:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>cat /dev/zero | nc mtl 4000</span></span></code></pre></div>
<p>Again, accounting for the randomness factor and settings things up in a retry loop, I got a few packets which remove any doubt about the previous conclusions.  Here’s part of one - remember that we’re sending just a stream of nulls(zeroes):</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0210  .....
</span></span><span><span>0x0220  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0230  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0240  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0250  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0260  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0270  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0280  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0290  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02a0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02b0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02c0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02d0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02e0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02f0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0300  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0310  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0320  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0330  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0340  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0350  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0360  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0370  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0380  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0390  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03a0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03b0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03c0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03d0  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x03e0  .....</span></span></code></pre></div>
<p>With the bug replicated, I needed to find a way to isolate which of the 17 hops along that path cause the corruption.  There was simply no way to call up the provider of each cluster to ask them to check their systems.</p>
<p>I decided pinging each router, incrementally, might be the way to go.  I crafted special ICMP packets that are large enough to go over the 576 safety margin, and filled entirely with NULLs.  Then pinged the Montreal machine with them from London.</p>
<p>They came back perfectly normal.  There was no corruption.</p>
<p>I tried all variations of speed, padding, size - to no avail.  I simply could not observe corruption in the returned ICMP ping packets.</p>
<p>I replaced the netcat pipes with UDP instead of TCP.  Again there was no corruption.</p>
<p>The corruption needed TCP to be reproducible - and TCP needs 2 cooperating endpoints.  I tried in vain to see if all 17 router hops had an open TCP port I can talk to directly, to no avail.</p>
<p>It seemed there was no easy way an external party can pinpoint the bad apple. Or was there ?</p>
<h3 id="mirror-mirror-on-the-wall">Mirror mirror on the wall</h3>
<p>To detect whether corruption occurred or not, we need one of these scenarios:</p>
<ul>
<li>Control over the TCP peer we’re talking to inspect the packet at the destination
<ul>
<li>Not just in userland, where the packet would not get delivered if the TCP checksum failed, but root + tcpdump to inspect it as it arrives</li>
</ul>
</li>
<li>A TCP peer that acts as an echo server to mirror back the data it received, so we get to inspect it at the sending node and detect corruption there</li>
</ul>
<p>It suddenly occurred to me that the second data point is available to us.  Not per-se, but consider this:  In our very first taste of the problem, we observed ssh clients hanging when talking to ssh servers over the corrupting hop.  This is a good passive signal that we can use instead of the active “echo” signal.</p>
<p>… and there are lots of open ssh servers out there on the internet to help us out.</p>
<p>We don’t need actual accounts on these servers - we just need to kickstart the ssh connection and see if the cipher exchange phase succeeds or hangs (with a reasonable number of retries to account for corruption randomness).</p>
<p>So this plan was hatched:</p>
<ul>
<li>Use the wonderful <strong>nmap</strong> tool - specifically - its “random IP” mode - to make a list of geographically distributed open ssh servers</li>
<li>Test each server to determine whether it is:
<ul>
<li>Unresponsive/unpredictable/firewalled -&gt; Ignore it</li>
<li>Negotiates successfully after being retried N times -&gt; mark as “good”</li>
<li>Negotiates with hangs at the telltale phase after being retried N times -&gt; mark as “bad”</li>
</ul>
</li>
<li>For both “good” and “bad” servers, remember the traceroute to them</li>
</ul>
<p>The idea was this:  All servers marked as “bad” will share a few hops in their traceroute.  We can then take that set of suspect hops, and subtract from it any that appear in the traceroutes of the “good” servers.  Hopefully what’s left is only one or two.</p>
<p>After spending an hour manually doing the above exercise, I stopped to inspect the data.  I had classified 16 servers as “BAD” and 25 servers as “GOOD”.</p>
<p>The first exercise was to find the list of hops that appear in all the traceroutes of the “BAD” servers.  As I cleaned and trimmed the list, I realized I won’t even need to get to the “GOOD” list to remove false positives.  Within the “BAD” lists alone, there remained only 1 that was common to all of them.</p>
<p>For what it’s worth, it was 2 providers away:  London -&gt; N hops upstream1 -&gt; Y hops upstream2</p>
<p>It was the first in Y hops of upstream2 - right at the edge between upstream1 and upstream2, corrupting random TCP packets, causing many retries, and, depending on the protocol’s logical back-and-forth, hangs, or reduced transmission rates.  You may have been a telephony provider who sufferred dropped calls, a retailer who lost a few customers or sales, the possibilities really are endless.</p>
<p>I followed up with our London DC ops with the single hop’s IP address.  Hopefully with their direct relationship with upstream1 they can escalate through there and get it fixed.</p>
<p>/filed under crazy devops war stories</p>
<h3 id="update">Update</h3>
<p>Through upstream1, I got confirmation that the hop I pointed out (first in upstream2) had an internal “management module failure” which affected BGP and routing between two internal networks.  It’s still down (they’ve routed around it) until they receive a replacement for the faulty module.</p>
<p>Thanks for the kind words and great comments here on Disqus, Reddit (<a href="http://www.reddit.com/r/linux/comments/11x7ld/the_little_ssh_that_sometimes_couldnt/">/r/linux</a> &amp; <a href="http://www.reddit.com/r/sysadmin/comments/129bpf/the_little_ssh_that_sometimes_couldnt/">/r/sysadmin</a>) and <a href="http://news.ycombinator.com/item?id=4709438">hacker news</a></p>
<h3 id="if-you-liked-this-you-might-also-like">If you liked this, you might also like</h3>
<ul>
<li><a href="http://www.fragmentationneeded.net/2012/01/dispatches-from-trading-floor-moldudp.html">Dispatches From The Trading Floor - MoldUDP</a></li>
<li><a href="http://blog.krisk.org/2013/02/packets-of-death.html">Packets of Death</a></li>
<li><a href="http://www.ibiblio.org/harris/500milemail.html">The case of the 500-mile email</a></li>
<li><a href="https://code.facebook.com/posts/1499322996995183/solving-the-mystery-of-link-imbalance-a-metastable-failure-state-at-scale/">Solving the Mystery of Link Imbalance: A Metastable Failure State at Scale</a></li>
<li><a href="http://www.pagerduty.com/blog/the-discovery-of-apache-zookeepers-poison-packet/">The Discovery of Apache ZooKeeper’s Poison Packet</a></li>
<li><a href="https://blog.cloudflare.com/the-story-of-one-latency-spike/">The story of one latency spike</a> &amp; <a href="https://blog.cloudflare.com/revenge-listening-sockets/">The revenge of the listening sockets</a></li>
<li><a href="https://mailman.nanog.org/pipermail/nanog/2018-September/096871.html">Service provider story about tracking down TCP RSTs</a></li>
<li><a href="https://cloud.google.com/blog/products/management-tools/sre-keeps-digging-to-prevent-problems">Finding a problem at the bottom of the Google stack</a></li>
<li><a href="https://news.sherlock.stanford.edu/posts/tracking-nfs-problems-down-to-the-sfp-level">Tracking NFS problems down to the SFP level</a></li>
<li><a href="https://engineering.skroutz.gr/blog/uncovering-a-24-year-old-bug-in-the-linux-kernel/">Uncovering a 24-year-old bug in the Linux Kernel</a></li>
<li><a href="https://dirtypipe.cm4all.com/">The Dirty Pipe Vulnerability</a></li>
<li><a href="https://blog.ando.fyi/posts/diagnosing-an-unsual-wifi-issue/">Resolving an unusual wifi issue</a></li>
<li><a href="https://patrickthomson.tumblr.com/post/2499755681/the-best-debugging-story-ive-ever-heard">The Best Debugging Story I’ve Ever Heard</a></li>
<li><a href="https://notes.valdikss.org.ru/jabber.ru-mitm/">Encrypted traffic interception on Hetzner and Linode targeting the largest Russian XMPP (Jabber) messaging service</a></li>
<li><a href="https://medium.com/adevinta-tech-blog/its-not-always-dns-unless-it-is-16858df17d3f">It’s not always DNS — unless it is</a></li>
<li><a href="https://www.youtube.com/watch?v=XrlrbfGZo2k">37C3 - Breaking “DRM” in Polish trains</a></li>
</ul>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My business card runs Linux and Ultrix (2022) (138 pts)]]></title>
            <link>https://dmitry.gr/?r=05.Projects&amp;proj=33.+LinuxCard</link>
            <guid>39268460</guid>
            <pubDate>Mon, 05 Feb 2024 23:06:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmitry.gr/?r=05.Projects&#x26;proj=33.+LinuxCard">https://dmitry.gr/?r=05.Projects&#x26;proj=33.+LinuxCard</a>, See on <a href="https://news.ycombinator.com/item?id=39268460">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><span>My business card runs Linux (and Ultrix), yours can too</span>

<b>UPDATES:</b>: See "<a href="#fwv2">Version 2</a>"</p><h2>Table of Contents</h2>
<p><img src="https://dmitry.gr/images/linuxCardPromo.jpg" alt="Linux card project cover image"></p><ol type="1"><li><a href="#_TOC_2673ce8234cc65bf5d5e81743172700b">Why?</a></li><li><a href="#_TOC_544a3f85f27429ab93dcd5ab2a63de0f">Parts selection</a></li><li><a href="#_TOC_7c1edc4d9290405fda54122244529141">What to emulate</a><ol type="a"><li><a href="#_TOC_d30f50757568b8cfaf8978a26d616b30">A MIPS primer</a></li><li><a href="#_TOC_1f0bd75c3792469488787400675c6973">What system?</a></li></ol></li><li><a href="#_TOC_7e76ca59b9efa6e1895f99d810e88da7">Let's emulate!</a><ol type="a"><li><a href="#_TOC_2e782d97f878671469dbb579dab9819e">The CPU</a></li><li><a href="#_TOC_d26852db28343b84596911de435caac9">The FPU</a></li><li><a href="#_TOC_5568f04140f1e9c2bde99c4e9c3572c9">The MMU</a><ol type="I"><li><a href="#_TOC_f05af7a1cabb44e206600aa7d7074fbc">MMU basics</a></li><li><a href="#_TOC_68fe0e8a8517a9a939dc8ad830f3ed3f">The MIPS MMU</a></li><li><a href="#_TOC_3ec65a91b377c508e2a27543e95858ca">Emulating the MMU efficiently</a></li></ol></li><li><a href="#_TOC_07a3dd247ad6bec7fe401aa11619959f">Communication</a></li><li><a href="#_TOC_3a173782d010897c6136c3b4ca51cd47">Hypercalls</a></li></ol></li><li><a href="#_TOC_d2ce354603c45f5e016fd47b9b5c8524">Bring on the hardware!</a><ol type="a"><li><a href="#_TOC_30aace8835696930f69a264dd89cbc60">The honeymoon period</a></li><li><a href="#_TOC_da93b232e827178270bfa561bdf6569c">How not to design a DMA unit</a></li><li><a href="#_TOC_e8ee65a238a03dd3a641faaff13a9c8a">Clocks again</a></li><li><a href="#_TOC_f53cca91f548c50486dcd52bac3efe7c">SD card support</a></li><li><a href="#_TOC_03751c187a665141b52e489852323619">Coolness enhancement</a></li></ol></li><li><a href="#_TOC_9ffdb95250e26c7a6b468126ac7c75b0">How it works</a><ol type="a"><li><a href="#_TOC_ddd6939c0f0cff6ceb8b36172e02b459">How a normal DECstation boots</a></li><li><a href="#_TOC_f9ff15b5ee1683a37691730e23cbd714">How uMIPS boots</a></li><li><a href="#_TOC_55a0a5396aa1bd6b11c6eb5f8ce8d62a">How uMIPS runs</a></li><li><a href="#_TOC_d70d07edc2b683000e09c709f5921fe9">Linux changes</a></li></ol></li><li><a href="#_TOC_9a98bd63857ec302fcec693aae109dde">Improving performance</a><ol type="a"><li><a href="#_TOC_0f63c0f6caf6daba30629abfa403d51a">Instruction cache</a></li><li><a href="#_TOC_fc5278bbec5501f7f5fe590fb59653f2">Improving CPU speed</a></li><li><a href="#_TOC_aee3d0e166f8b8358baf265cb949a756">Improving RAM bandwidth</a></li><li><a href="#_TOC_73dc18b03073c31c5a2bbf1264aff327">Dirty hacks specifically for Linux</a></li></ol></li><li><a href="#_TOC_23b5439c727c2e8557d28f8495da9977">How to build and use one</a><ol type="a"><li><a href="#_TOC_c39b56d4489fb2507289e7ae19567b80">Building</a></li><li><a href="#_TOC_b3abf203d70a08b6d9725f0000f27122">Building from source</a></li><li><a href="#_TOC_7b797cff6f4cf0ca82225d6125fe1861">If you are lazy</a></li><li><a href="#_TOC_3f05d6f38862a5b18b2eb4e867a61fb1">Using</a></li></ol></li><li><a href="#_TOC_425d8e1e777a03c3e220dfaac38dbf1f">Version 2</a><ol type="a"><li><a href="#_TOC_2b50d6628ed817de809605854d478f68">Booting Ultrix</a><ol type="I"><li><a href="#_TOC_2375a25fb86a26c24006ed1d6e2c1c47">About Ultrix</a></li><li><a href="#_TOC_c7bce03d32236f53d1a3d5c04e680838">First time booting Ultrix</a></li><li><a href="#_TOC_87e05c1a936fe8f08f1621e5cd10c534">SCSI</a></li><li><a href="#_TOC_938bce276b64c8ccdaeb079ff7a0bd84">LANCE</a></li><li><a href="#_TOC_2b0d0fb2ee0246234fe0fd9845b87021">ESAR</a></li><li><a href="#_TOC_73d22765ace36f09f4bab935a1608d3c">Memory probing &amp; proper PROM API</a></li><li><a href="#_TOC_c6323dca5b2dcaf05756b569ad13f4b9">Ultrix Loader</a></li></ol></li><li><a href="#_TOC_fd2d1e73f2cd71a4c375685b4abed537">Making Ultrix work</a><ol type="I"><li><a href="#_TOC_42badd9e49002a3cefeaaf28867add83">Framebuffer</a></li><li><a href="#_TOC_347b8386b145ced18ea02f2654e00883">Mouse, Keyboard, ... and Tablet</a></li><li><a href="#_TOC_c4d283323af70979073f5cb6145f3a4b">Patches</a></li></ol></li><li><a href="#_TOC_9f744f0f0ac29e818b7b95da8ad8ee40">Improvements in the emulator</a><ol type="I"><li><a href="#_TOC_7c775bb4800b345425796dce2acef3a8">USB improvements</a></li><li><a href="#_TOC_c5f0dc32adc4e66649115eef7e76f94f">More perf improvements</a></li><li><a href="#_TOC_819a79dcd016b5a99e05c56515825abb">Removing the TLB refill fast path</a></li><li><a href="#_TOC_dda4cbe5c1a77c2c9bf66b0adc6fff4b">Cache geometry changes</a></li><li><a href="#_TOC_b3c8fd852368b78e09e2fc8b39a6ea5c">Serial improvements</a></li></ol></li><li><a href="#_TOC_cb1862398dbf0b5f7d8a7dbe73bee626">More Floating Point Unit work</a></li><li><a href="#_TOC_244cd79fc0c2e4a295228e647cf88dbc">A bootloader</a></li><li><a href="#_TOC_7fa430e699655fa918b84f63d1c5fae5">Hardware improvements</a><ol type="I"><li><a href="#_TOC_9183d42e96c2104c27070b535e3793d9">v1.3 hardware</a></li><li><a href="#_TOC_8971392389323f2057db749c94dcba05">And old hardware too</a></li></ol></li><li><a href="#_TOC_1a574cfae32687e675d081616b06e0a0">Building from source (updated)</a><ol type="I"><li><a href="#_TOC_3d2780b0eeabee178926de36f72658b8">The emulator</a></li><li><a href="#_TOC_7213a2cd3fa80d577b3092f614b7fdb3">The loader</a></li></ol></li><li><a href="#_TOC_d8926db6c437f738792454ba22ec2755">Further Updates</a><ol type="I"><li><a href="#_TOC_52cbfe3bfc8a13d03124dd2283d83807">Firmware v2.1.1</a></li><li><a href="#_TOC_6b3ae1897005585fd36708ff39e693cf">Firmware v2.2.0</a></li></ol></li></ol></li><li><a href="#_TOC_3cd960e7edc378fd94d8777b595ea515">In conclusion</a><ol type="a"><li><a href="#_TOC_0407c27180c9b019e644e8ad4c6a9324">Acknowledgements</a></li><li><a href="#_TOC_c20c35ef53bf1b70789ce94e66800147">Downloads</a></li></ol></li><li><a href="#_TOC_7e1e75c32bc9b275daf70df8cba8efb5">Comments...</a></li></ol>







<h2>Why?</h2>
<p><a href="https://dmitry.gr/images/linuxCardWhole.jpg"><img src="https://dmitry.gr/images/linuxCardWholeSmall.jpg" alt="Linux card in action"></a></p><p>A long long time ago (in 2012) I <a href="https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">ran Linux on an 8-bit AVR</a>. It was kind of a cool record at the time. I do not think anyone has beaten it - nobody's managed to run Linux on a lower-end device than that 8-bit AVR. The main problem was that is was too slow to be practical. The effective speed was 10KHz, the boot time was 6 hours. Cool, but I doubt that any one of those people who built one of those devices based on my design ever waited for the device to boot more than once. It was time to improve it!
</p>
<p>So what could I improve? A number of things. First, I wanted the new design to be speedy enough to boot in a few minutes and reply to commands in seconds. This would make using the device practical and not a test of patience. Second, I wanted it to be easy to assemble for anyone. This meant no components with tight spacing, no components with too many pins, and no components with contacts hidden underneath them. A part of this wish was also that someone could <em>actually</em> assemble one, meaning that I had to select components that are <em>actually</em> buyable in the middle of the current ongoing shortage of, well, everything. Additionally, I wanted the device to be easy to interface with. The original project required a USB-to-serial adapter. This would not do. And, finally, I wanted the whole thing to be cheap and compact enough to serve as my business card.
</p>

<h2>Parts selection</h2>
<p><a href="https://dmitry.gr/images/linuxCardSchem.png"><img src="https://dmitry.gr/images/linuxCardSchemSmall.jpg" alt="Linux card schematics"></a></p><p>Some things were pretty easy to decide on. For storage, for example, microSD is perfect - easy to interface with, widely available, cheap. I picked a simple microSD slot that is easy to solder and easy to buy: <a href="https://octopart.com/1140084168-amphenol-25513977?r=sp">Amphenol 1140084168</a>.
</p>
<p>Some choices were a litle harder, but not too much so. For example, I was surely not going to use DRAM again. It requires too many pins, necessitating more soldering than I would consider acceptable, given that I wanted this device to be easy to assemble. SRAM in megabyte sizes does not really exist. But there is a cool thing called PSRAM. It is basically DRAM, but in easy mode. It itself takes care of all the refreshing and externally acts just like SRAM. Ok, cool, but still that would usually be a lot of pins. Right? Enter "AP Memory" and "ISSI". They make QSPI PSRAM chips in nice SOIC-8 packages. AP Memory has models with <a href="https://octopart.com/search?q=APS1604M-3&amp;currency=USD&amp;specs=0">2MB</a> and <a href="https://octopart.com/search?q=APS6404L-3&amp;currency=USD&amp;specs=0">8MB</a> of RAM per chip, ISSI has them in <a href="https://octopart.com/search?q=IS66WVS1M8BLL&amp;currency=USD&amp;specs=0">1MB</a>, <a href="https://octopart.com/search?q=IS66WVS2M8BLL&amp;currency=USD&amp;specs=0">2MB</a>, and <a href="https://octopart.com/search?q=IS66WVS4M8BLL&amp;currency=USD&amp;specs=0">4MB</a> sizes. I decided to use these. They are available and my code supports them all!
</p>
<p>There were some miscellaneous choices, like which regulator to use. I chose <a href="https://octopart.com/search?q=MIC5317-3.3YM5TR&amp;currency=USD&amp;specs=0">MIC5317-3.3YM5TR</a> due to having worked with it before and it being available in my "random chips" box. It is also easily available to buy.
</p>
<p>The USB connector was also a fun choice. I settled on: none. With the proper PCB thickness, one can lay out the board edge to fit into the end of a USB-C cable. I've seen this done before for micro-USB and figured it could be done for USB-C as well. At the end, though, I did not even need to do it, since <a href="https://github.com/Pinuct/Eagle_PCB_USB_connectors">someone else</a> already saved me the 30 minutes it would have taken. I just had to remember that the board thickness needs to be 0.8mm for this to work. 
</p>
<p>The last choice was the hardest - which microcontroller to use. The criteria were: built-in USB, no more than 32 pins with at least 0.65mm spacing, no pin-less packages, actually available to buy, QSPI support, as fast as possible. I did not get my last two wishes. After much searching and filtering for "in stock", I was forced to settle for an ATSAMD21 series chip, specifically the <a href="https://octopart.com/search?q=ATSAMDA1E16b-a&amp;currency=USD&amp;specs=0">ATSAMDA1E16</a>. It is not fast (specced to 48MHz, I clock it at 90MHz), it has many bugs (especially in its DMA engine), but it can be bought, it is easy to solder, and it'll have to do... <b>UPDATE</b>: another chip is now supported too, see later in this article.
</p>

<h2>What to emulate</h2>
<p><a href="https://dmitry.gr/images/linuxCardWholeBoot.png"><img src="https://dmitry.gr/images/linuxCardWholeBootSmall.png" alt="Linux card boot log"></a></p><p>I could have just taken my old ARM emulator (uARM) and used that. But what's the fun there? I decided to pick a new target. The ideal emulation target will: (1) be a RISC chip so that I have to spend fewer cycles on decoding instructions, (2) have no condition codes (like MIPS) or only set them on demand (like ARM), so that I am not wasting time calculating them every virtual cycle, (3) be 32-bit since 16-bit machines are all funky and 64 bit is a pain to emulate, (4) be known, and (5) have a workable set of GNU tools and Linux userspaces available. This set of requirements actually only leaves a few candidates: PowerPC, ARM, MIPS. I've done ARM, and I had no desire to mess with an endian-switchable CPU, so MIPS it was! This gives rise to the internal name of the project: uMIPS.
</p>
<h3>A MIPS primer</h3>
<p>MIPS is old - one of the original RISC designs. If you are a RISC-V fanboy(/girl/being), MIPS will look familiar - it is where 99.9994% of the initial RISC-V spec was copied from. The original MIPS was a 32-bit design, optimized for ease-of-designing-it. It has (and does not hide) a delay slot, has a lot of registers, including a hard-wired zero register, and does not use condition codes. The original design was R2000, back in 1986, followed soon by the improved R3000 in 1988. These were the last chips implementing the MIPS-I instruction set. MIPS-II was short lived and only included the R6000, which barely saw the light of day. The real successors were the MIPS-III R4000-series chips, released in 1991. These were 64-bit already in 1991! Clearly, the easiest target would be the R2000/R3000 chips with their simple MIPS-I instruction set.
</p>
<p>MIPS-I is a <a href="https://vhouten.home.xs4all.nl/mipsel/r3000-isa.html">rather simple instruction set</a>. So much so that a complete emulator of just the instructions can be written in under 1000 lines of C code without any dirty tricks. The floating point unit is optional, so it can be skipped (for now). The MMU is weird. It is just a TLB that the software must fill manually. This may seem like a rather unusual choice, but in reality it is a clever one, if you're in 1986 and tring to minimize the number of transistors in your chip. Why have a hardware pagetable walker, when you can make the software do it? You may ask how it handles the situation where the code that would do the walking is itself not mapped? Well, a part of physical memory is always hard-mapped at a certain address, and all exception handlers live there. Even if this were not the case, since the software manages the TLB, it would not be hard to reserve an entry for this purpose. The hardware even has support for some "wired" entries that are meant to be permanent. More on all of this later.
</p>
<h3>What system?</h3>
<p>MIPS R2000/R3000 is a processor. A processor does not a complete system make. What system to emulate? I searched around for a cool system and settled on DECstation2100 (or its big brother - DECstation3100). Why bother? It seemed like a simple system that Linux does support. Initially I was not planning to emulate the whole thing. Why? I had no plans to emulate the LANCE network adapter or the SII SCSI adapter. The last part might surprise you, since we will need a disk to use as our root fs. I did later add emulation of both of these parts, to make Ultrix happy.
</p>

<h2>Let's emulate!</h2>
<h3>The CPU</h3>
<p>MIPS is a rather old instruction set, which shows in a few places. The main one is that it attempts to prevent signed overflow. The normal instructions used for addition and subtraction will cause an actual exception if they cause an overflow. This does not map to how CPUs are used today, so nobody cares, but I still had to emulate it. There are "unsigned" versions of the instructions for addition and subtraction that do not do this, which is what all modern compilers will emit on MIPS.
</p>
<p>I wrote an emulator for the CPU in C first, to allow easy testing on my desktop, while the PCBs were being manufactured. It was not fast, nor meant to be, but it did allow for testing. You can see this emulator in <span>cpu.c</span>. Along the way here, I implemented some features of the R4000 CPU optionally. It turned out that to boot Linux compiled with modern compilers, this is necessary, as the compilers assume these instructions exist. Technically this is a bug. Realistically, I am likely the only person to ever notice. So, which features did I need to add? Likely branches (<span>BxxL</span> instructions), conditional traps (<span>Tcc/TccI</span> instructions), and atomics (<span>LL/CC</span> instructions).
</p>
<p>Of course, C is not the language one uses when one wants to go fast. I wrote an emulator in assembly too, targetting ARMv6-M (for the Cortex-M0 MCU I chose). I later added a sprinking of enhancements for ARMv7-M (in case I ever upgrade the project to a fancier CPU). This was tested on a Cortex-M7 and worked well too. The assembly emulator core is contained in <span>cpuAsm.S</span> and the ARMv6-M specific parts are in <span>cpuM0.inc</span>
</p>
<p>I mentioned delay slots earlier. What is a delay slot? Well, back in the day it was considered cool to expose your CPU's pipeline to the world. Just kiding, it was just a way to save some more transistors. Basically, the instruction after a jump will be executed even if the jump happens. This is called the delay slot. A naive way to avoid dealing with this is to place a <span>NOP</span> after each jump instruction. But with a good compiler, the delay slot can be put to a good use in almost all cases. Obviously one cannot place a jump instruction in the delay slot, since the CPU is already jumping somewhere. Doing this is illegal and undefined. An issue arises, however, if the instruction in the delay slot causes an exception of any sort. The CPU will record that the instruction was in the delay slot, and point the exception handler to the <em>jump</em> whose delay slot we're in. There is no way to return to this "in delay slot" state, so the exception handler is expected to take steps to somehow execute the delay-slot instruction and then complete the jump.
</p>

<h3>The FPU</h3>
<p>The DECstation came with an FPU, so that floating point operations would be fast. Back then this was a separate chip, which was optional in a MIPS R2000/R3000 system. Linux, in fact, will more-or-less corectly emulate the FPU if it is not present, but this is slow. I used this mode initially, and even fixed a few bugs in Linux's emulation, but, in the end, I implemented an FPU emulator. This was necessary since it seems like a lot of MIPS binaries I could find all assume the FPU is available and use it freely. I never reimplemented the FPU emulator in assembly, instead calling out to the C FPU emulator when needed. I figure that squeezing a few cycles out of each instruction is meaningless when the actual FPU operation takes hundreds. The code for this is in <span>fpu.c</span>. I include Linux patches to remove FPU emulation support from the kernel. This saves some RAM. Later, I also added support for a "minimal" FPU - it supports the registers but no operations. This is allowed by the spec, since the FPU may refuse to execute any operation it is not sure it cna di perfectly correctly, so ay compliant OS must implement a full FPU fallback anyways. Why? This saves 16K of code size in the binary, opening the possibility of running uMIPS on smaller devices yet.
</p>
<h3>The MMU</h3>
<h4>MMU basics</h4>
<p>(this is a <em>very</em> oversimplified summary, feel free to skip if you know this, and do not complain to me that it is not perfectly accurate!)
</p>
<p>Most CPUs access memory using virtual addresses (<span>VA</span>). The hardware works in terms of physical addresses (<span>PA</span>). Ability to map one to the other is the underpinning of memory safety in modern operating systems. The purpose of an <span>MMU</span> (Memory Management Unit) is to translate virtual addresses to physical addresses, to allow for this mapping. Normally this is done using a tree-like structure in RAM, called a <span>pagetable</span>. Most CPUs have a component whose job it is to walk that structure to resolve what physical address a given virtual address maps to. This component is a <span>pagetable walker</span>. In most cases the <span>pagetable</span> has 3 or 4 levels, which means that resolving a <span>VA</span> to a <span>PA</span> requires reading 3 or 4 words from main memory. Clearly you do not want to do 3 useless memory accesses for every useful one. So usually another component is included in an <span>MMU</span> - a <span>TLB</span> (Translation Lookaside Buffer). Basically you can think of a <span>TLB</span> as a cache of some of the current <span>pagetable</span>'s contents. The idea is that before you go off doing those 3-4 memory reads into the <span>pagetables</span>, you can check and see if the <span>TLB</span> has a matching entry. If so, you can skip the <span>pagetable walk</span>.
</p>
<p>Clearly, like any cache, the <span>TLB</span> needs to stay in sync with the things it caches (the current <span>pagetables</span>). So, if the OS changes the <span>pagetables</span>, it needs to flush the <span>TLB</span>, since it might have stale entries. Usually, <span>TLB</span>s expose very little interface to the CPU, so there isn't a way to go read all the entries and remove only the newly-invalid ones. Additionally, this would be slow, so this is not usually done. However, invalidating the entire <span>TLB</span> also has costs - it needs to be re-filled, at the cost of 3-4 memory accesses per entry. This could hurt performance. A solution commonly used is called an <span>ASID</span>.
</p>
<p>What are the four main cases when <span>pagetables</span> might be modified? (1) Adding a new mapping over a virtual address that previously was not mapped to anything, (2) changing permissions on on existing mapping, (3) removing a mapping, and (4) entirely changing the memory map (for example to switch to a completely different process). In case 1, no <span>TLB</span> flush is necessary, since no stale <span>TLB</span> entry can exist. Cases 2 and 3 do indeed require flushing the <span>TLB</span>, but they aren't that common. Case 4 is quite common, though. It is done at every context switch. One might point out that since we're changing the entire memory map, the entire <span>TLB</span> would be invalid, and thus flushing it isn't a problem. This is wrong. Besides mapping userspace things, the <span>MMU</span> also maps various kernel structures, and there is no point penalizing them.
</p>
<p>If we could somehow tag which entries in the <span>TLB</span> go with which process, and temporarily disable them when another process runs, we could avoid a lot of context-swich flushing and the performance costs imposed by it. It would also be cool if we could tag entires that belong to the kernel and are valid in every process. Well, this exact technology exists in many <span>MMU</span>s. The idea here is that each <span>pagetable</span> entry will have a bit marking it as "global" (valid in all memory maps) or not. There should also be a register in the CPU setting the current <span>ASID</span> (Address Space ID). When a <span>TLB</span> entry is populated from the <span>pagetables</span>, the current <span>ASID</span> is recorded in it. When a lookup in the <span>TLB</span> is done, only entries matching the current <span>ASID</span> or those marked "global" will match. Cool!
</p>
<h4>The MIPS MMU</h4>
<p>The idea at the time was to save transistors. Which of the above could be cut? Well, cutting out the <span>TLB</span> guarantees terrible performance in all cases. But that <span>pagetable walker</span>, do we really need it? What if we make the sotware do it? We can add a little bit of assistance, like ability to manage the <span>TLB</span> efficiently, but skip on the <span>pagetable walker</span> hardware. This is what MIPS did. Here is the MIPS virtual address space:
</p>
<p>Addresses               Name   Mapping
0x00000000..0x7fffffff  kuseg  mapped via MMU
0x80000000..0x9fffffff  kseg0  mapped to physical 0x00000000..0x1fffffff, cached if there is a cache, only accessible in priviledged mode
0xa0000000..0xbfffffff  kseg1  mapped to physical 0x00000000..0x1fffffff, not cached, only accessible in priviledged mode
0xc0000000..0xffffffff  kseg2  mapped via MMU, only accessible in priviledged mode
</p>
<p>So, as you can see, some <span>VA</span>s do not map via the <span>MMU</span> at all. This means that code living there is able to run no matter the state of the <span>MMU</span>. Linux and Ultrix, predictably, put the kernel in <span>kseg0</span>. The kernel does, however, need to be able to dynamically map things in as well. <span>kseg2</span> is one gigabyte of address space that is mappable via the <span>MMU</span> that the kernel can use. Memory-mapped devices will usually be accessed via <span>kseg1</span>. The 2 gigabytes at the bottom of the address range(<span>kuseg</span>) are for userspace tasks.
</p>
<p>What entry in a <span>TLB</span> should one replace when one needs to insert a new entry? An obvious answer might be "the one least recently used", but that would require tracking use, which costs transistors too. A simplification is "the one least recently added". This is easy, but it hides a fatal flaw. Imagine your <span>TLB</span> has N entries, and your workload sequentially uses N + 1 addresses, such that each would need a <span>TLB</span> entry. Now you'll always be replacing the entry you're about to need, guaranteeing that you <em>NEVER</em> hit the <span>TLB</span> and do a lot of pointless <span>pagetable</span> walks. How do we avoid this? The simplest method is replace a random entry. Sure, it might be the entry you're about to need, but for an N-entry <span>TLB</span> the chances are 1/N.
</p>
<p>Generating random numbers is slow in software, so MIPS R2000/R3000 provide some help. The CPU has a register called, literally <span>RANDOM</span> which is supposed to be constantly incrementing, every cycle. Since the "when" of "when will you next need a new <span>TLB</span> entry" is not predictable, this is as good as random, and requires very few transistors. The idea is that whenever you need to replace a <span>TLB</span> entry, you use a special instruction <span>TLBWR</span> to write to a random entry. I did not tell you about <span>ASID</span>s by accident either. The MIPS R3000 <span>MMU</span> implements a 6-bit <span>ASID</span>.
</p>
<h4>Emulating the MMU efficiently</h4>
<p>Emulating the R3000 <span>MMU</span> is a bit of a pain. Since any entry can be in any location, the proper way to do a lookup is to check each one. Doing a 64-cycle loop for every memory access is a non-starter speed-wise, of course. I use a hashtable indexed by the virtual address to keep all the TLB entries in buckets for faster checking. Using 128 buckets virtually guarantees that most buckets have zero or one entry in them, permitting much faster lookups. Initially this was a simple table of pointers, but this used too much RAM, so now it is a table of indices.
</p>
<h3>Communication</h3>
<p>The DECstation had a few ways to communicate with the outside world. It had a built-in network card<s>, which I do not emulate</s>. It was optional<s>, and I haven't found a use for it yet</s>. Maybe I will later - it does not look complex. It also had a SCSI controller which one could attach hard disks and other SCSI peripherals to. Emulating this would be a fun challenge, and I'll probably get to it later, but I did not do it now - it was not necessary - I wrote a paravirtualized disk driver for Linux using hypercalls, more on this later. There was also an optional framebuffer card one could install that added support for a monochrome or a color display. Emulating these would also not be too hard, but my business card lacks a display, <s>so I did not do it either</s> - plus I am not even sure that Linux can make a use of it.
</p>
<p>The last method of communications that the DECstation had was <span>DC7085</span> - a serial port controller that is basically a clone of a PDP11-era <a href="https://gunkies.org/wiki/DZ11_asynchronous_serial_line_interface"><span>DZ-11</span></a>. It supports four serial ports at a blistering 9,600bps speed (or any integer division thereof). Each serial port was allocated a purpose, and they were wired to different connectors indicating this purpose. #0 was for the keyboard, #1 for the mouse, #2 for modem, and #3 for printer. To the machine they are all the same, this was just the purpose DEC assigned to them. The stock <span>PROM</span> would use #3 as serial console instead if it did not detect a keyboard at #0, thus it is customary to use #3 as serial console for Linux on the DECstation. My <span>PROM</span> surrogate does not bother looking for or supporting external keyboard, and just defaults to serial console on #3. That being said, since it is cool to allow multiple login sessions, I also export <s>#0</s> #2 as a second virtual serial port, so that you may login from two serial consoles at once, and do two things at once. How cool is that?
</p>
<p>So, how do I export these serial ports? When you connect the card to a computer, it'll show up as a USB composite device comprised of two CDC-ACM virtual serial ports. One of them is port #3, another is port <s>#0</s> #2 on the virtual <span>DZ-11</span>. How will you know which is which? #3 has the boot console printing and will have the initial <span>sh</span> prompt. If you do not see this, try the other one, computers do not always number them in the order I export them.
</p>
<h3>Hypercalls</h3>
<p>In the real world the <span>PROM</span> had to probe the real hardware to detect what was present where. As my <span>PROM</span> is running in an emulator, there is no need for such mess. We can simply request things from the emulator in an agreed-upon way. That way is a <span>hypercall</span> - a special invalid instruction that, if encounted in supervisor mode, the emulator will treat as a request for some kind of service. The instruction I chose is <span>0x4f646776</span>, which is in the <span>COP3</span> (coprocessor 3) decode space that was not allocated to any real purpose in these chips. The calling convention is close to the normal C calling convention on MIPS: parameters are passed in <span>$a0</span>, <span>$a1</span>, <span>$a2</span>, and <span>$a3</span>, return values are in <span>$v0</span> and <span>$v1</span>. The <span>$at</span> register gets the "hypercall number" - the specific service we're requesting.
</p>
<p>A few hypercalls are implemented. #0 is used to get the memory map. The parameter is word index of the memory map to read. Word 0 is "how many bits the memory map bitmap contains", word 1 is "how many bytes of RAM each bit represents", words 2 and on are the bits of the map, up to the total specified in word 0. This can be used to build a memory map that the <span>PROM</span> can furnish to the running OS and allows me to have discontinuous RAM. Linux supports this and I tried it, but did not end up needing it. It is here in case I change my mind and need it again.
</p>
<p>Hypercall #1 outputs a single byte to the debug console (which is the same as <span>DZ-11</span> port 3). This is used by the <span>PROM</span> and <span>mbrboot</span> to output debug strings without needing to have a complete <span>DZ-11</span> driver in there. Hypercall #5 will terminate emulation. This can be used on the PC version of the emulator to quit peacefully.
</p>
<p>Hypercalls #2, #3, and #4 are used for SD card access. #2 will return card size in sectors, #3 will request a read of a given sector to a given physical RAM address and reply with a nonzero value if that worked. #4 will do the same for a card write.
</p>

<h2>Bring on the hardware!</h2>
<h3>The honeymoon period</h3>
<p><a href="https://dmitry.gr/images/linuxCardBoard.png"><img src="https://dmitry.gr/images/linuxCardBoardSmall.jpg" alt="Linux card board layout"></a></p><p>The first revision of this board came up well initially, after I sorted out the mess that is ATSAMD21's clocking system. I appreciate flexibility as much as the next guy, but this thing is <em>TOO</em> flexible. It took a lot longer than I'd care to admit to get this thing running at a sane speed and to enable some peripherals. The docs were too sparse to be of much use, too. Atmel, what happened to you? You used to have the best docs!
</p>
<p>The first revision of the board had two memory chips, each on their own SPI bus, an SD card on an SPI bus, and USB with the proper resistors. The USB was perfect. Unlike everyone and their grandmother (STMicro, I am glaring at you), Atmel did not license annoying Synopsis USB IP. They made their own. It is easy to use, elegant, and works well. Seriously, it just worked. In two days I got the hardware to work and wrote a USB device stack. I tip my hat to the team that worked on the USB controller. That being said, I have concerns. My main issue: USB descriptors aren't small. They are constant. I'd prefer to keep them in flash. I'd prefer to, but cannot. The USB unit uses a built-in DMA unit to read the data to send. This DMA unit <em>CAN</em> access flash, but if you have any flash wait states enabled, it sends garbage. I suspect that Atmel only tested it for reading from RAM, forgot that some memories have wait states, and did not account for that. Keeping all my descriptors in RAM is a colossal waste of RAM, which there is only 8KB of. Remember that tiped hat? I rescind it, Atmel. I had to work around the issue by sending the descriptors one piece at a time (rather than letting the hardware DMA it all automatically) just to save the valuable RAM.
</p>
<p>Using the SPI units directly worked well enough, until I tried to speed them up. Past about 18MHz The received data was garbled (missing a bit or two, all the following bits shifted). No amount of searching found an issue in my code, and all sample code did more or less the same things. My bus analyzer showed no issues. What gives? <a href="https://microchipsupport.force.com/s/article/SPI-max-clock-frequency-in-SAMD-SAMR-devices">THIS GIVES</a> (<a href="https://archive.ph/IJTHU">archived</a>)! I was beyond furious when I found this forum post. Here I was, trying to build a fast device, and my SPI bus was going to be limited to the speed of a tired snail calmly strolling through peanut butter! With some more testing I found that the SPI units will work fine to about 16MHz, which I'll have to live with.
</p>
<p>The SPI units have no FIFOs, so code must manually feed them one byte at a time and read one byte at a time. This means that there is space between bytes on the bus as code wrangles bytes in and out of registers and memory. This is a waste of potential speed. The solution is DMA. Luckily this chip has DMA. Unluckily, it is fucked beyond belief, to a point where I am beginning to suspect that it was designed by a sleep-deprived stark raving lunatic.
</p>
<h3>How not to design a DMA unit</h3>
<p>A normal garden-variety DMA unit has some minimal global configuration, and a few channels, each independent from the rest. Each channel will usually have a source address, a destination address, a length, and some configuration, to store things like transfer chunk size, trigger, interrupt enable bits, etc. Thus it is common in ARM MCUs to have each channel have precisely these 4 32-bit configuration registeres: SRC, DST, LEN, CFG. This is 16 bytes of SRAM per channel. ATSAMD21 has 12 DMA channels, so that would be 192 bytes of config data for the DMA unit as a whole. Not that much. Well, Atmel was having none of this! Instead, the unit itself only has a <em>POINTER</em> to where in the user RAM all this config data lives. For every transfer, the DMA unit will load its internal state for the active channel from this structure in RAM, and then operate on the channel. If another channel's data was already loaded, it will be written out to RAM first. Depending on your experience level, you may already be on your third or fourth "oh, hell fucking no" as you read this...
</p>
<p>Why is this bad? Let's imagine two SPI units being fed by DMA. Each one will have two DMA channels, one for receive, one for transmit. Four channels are active in total. Now what happens as both the SPI units are enabled? Two DMA channels (the transmit ones) will go active and attempt to send a byte. One will go first, then the second. This will generate <em>14</em>(!!) bus transactions to the RAM! Four to read config data for one channel, one to read the byte to send, four to write back this config data, four to read the config data for the next channel, and one more to read the byte to send. So in order to send 2 bytes, the DMA unit did 14 RAM accesses. Not great. But wait...there's more. Let's take a look what happens next, as the SPI units finish sending this byte and clocking in the received byte, but are also ready for the next byte to send! At this point in time, logically only four bytes need to be moved (two from the units into the receive buffers, two from the transmit buffers into the units). Let's see how this plays out. Remember the DMA unit's internal config data is currently loaded to the second transmit channel's. First, it'll have to do 4 writes to write that data out, then 4 reads to load the first receive channel's structures, one write to memory to write the received byte to RAM, 4 writes to write out this channel's structures out, 4 reads to load structures for receive channel number 2, one write of the received byte to RAM, 4 bytes to write out the config structure for this channel back out to RAM, and then the 14 we already discussed to send the next two bytes. That adds up to 36 RAM accesses to simply read two bytes and write two bytes. All this pain, simply to save the transistors on the 192 bytes of SRAM it would have taken for the DMA unit to store all the config data internally.
</p>
<p>So, why is this bad? Let's say our MCU is running at its designed speed of 48MHz, its SPI units running at their designed max speed of 12MHz. At the point the second bytes need to be sent and first received bytes need to be received, we'll need to perform 36 accesses to RAM, but also 4 accesses to the SPI unit. The SPI unit is on an APB bus, which means that any access to it takes at least 4 cycles. This means that in between each sent and received byte we'll need 36 + 4 * 4 = 52 cycles. If the SPI unit runs at 1/4 the CPU speed, then it will send/receive a byte every 8 * 4 = 32 cycles. So every 32 cycles we'll need to do 52 cycles' worth of work. When they do not get enough cycles, the DMA channels give up and stop working... Oops... 
</p>
<p>So, what can be done? I worked out a hybrid method where I send data using CPU writes and receive using DMA. This worked for two channels, but would not work for more. Once I got rev2 boards that had 4 RAM chips, even this failed, as just the 4 receive DMA units starved each other of bandwidth and got cancelled. Why was Atmel so damn stingy with internal SRAM? We'll probably never know. But they could have solved this exact issue simpler than with 192 bytes of SRAM in the DMA unit. Just adding a 4-byte FIFOs into the SPI units would do as well, then each DMA transaction could transfer more than a single byte, alleviating this traffic jam. Sadly, apparently nobody at Atmel has even tried to actually use their chip for anything. Atmel, what happened to you?
</p>
<h3>Clocks again</h3>
<p>My clocking woes were not over yet. This chip has a number of internal oscillators, one of which is supposed to be a rather precise 32KHz oscillator called <span>OSC32K</span>. I wanted to use that as a source clock for a timer to implement my virtual real time clock. Well, despite much pain and many tears, the damn clock would not start... ever. The code should be simple: <span>SYSCTRL-&gt;OSC32K.bit.EN32K = 1; SYSCTRL-&gt;OSC32K.bit.ENABLE = 1; while (!SYSCTRL-&gt;PCLKSR.bit.OSC32KRDY); </span> Yeah... that did not happen. At the end, I decided that I can use a less-precise <span>OSC32KULP</span> to clock my timer. That one did start and I was able to use it. By this point in the project I was worn out, desensitized to this chip's many faults, and completely out of WTFs, so I resigned myself to a slightly imprecise real-time clock and trudged on.
</p>
<h3>SD card support</h3>
<p>Not really much to say about SD card support. Been there, done that, got the t-shirt. My initial code for the prototype used multi-block reads and writes for better card access speed, but in the final prototype I was forced to abandon it since one of the RAM chips on the b2 boards shared the SPI bus with the SD card, so leaving the card selected was not an option. This was not that big a deal since SD access is rarely, if ever, a bottleneck here. Any card up to 2TB is supported.
</p>
<p>In the v2 revision of the board I wired up card detect pin to the MCU. It was not used, but I thought that I might find a use for it. I did not, so in v3 boards it was removed. I also added a card "activity" LED which lights up when card is accessed. It is simply a LED between the card's chip select line and Vcc. Whenever the card is selected, it is on. This LED also surves a second purpose. If at boot time the SD card or SPI SRAMs fail to initialize, it'll blink out an error code to help identify the problem.
</p>
<h3>Coolness enhancement</h3>
<p>Now that the prototype worked and I was doing the layout for the final version, I decided to do some things to make it look cool. I buried all the traces in layers 2 and 3, leaving layers 1 and 4 uninterrupted copper. It loooks super cool! Of course the top layer copper is interrupted for the actual SMT pads, but other than that, it is all perfectly smooth and looks amazing!
</p>

<h2>How it works</h2>
<h3>How a normal DECstation boots</h3>
<p>Normally there is a built in 256KB ROM (called <span>PROM</span> by DEC) at physical address <span>0x1fc00000</span> that contains enough code to show messages onscreen and accept keyboard input, talk to SCSI devices, load files from disk to RAM and jump to them. This <span>PROM</span> also provides a lot of services to the loaded operating system via an array of callbacks. This includes things like console logging, EEPROM-backed environment variables, memory mapping info, etc. This is rather similar to UEFI. Normally this <span>PROM</span> would read the environment variables from EEPROM that would tell it which device to boot, and then load a kernel and boot from that device if all goes well. This emulator does not boot this way
</p>
<h3>How uMIPS boots</h3>
<p>I had no desire to include a large ROM in the emulator, as the flash space in the microcontroller is limited. I also do not have a graphical console or a keyboard per se. That being said, I had to implement a sizeable subset of the <span>PROM</span> somehow, since MIPS Linux uses it. What to do? I decided to come up with my own boot process, which can still work just as well. There is indeed a ROM at <span>0x1fc00000</span>. This is necessary for rebooting to work from Linux. <s>That rom is tiny - 32 bytes</s>. Its source code is found in the "romboot" directory. It <s>merely</s> loads the first sector of the SD card to the start of RAM at <span>0x80000000</span> and jumps to it. The first sector of the SD card contains a standard MBR partition table and up to 446 bytes of code. The code that lives here can found in the "mbrboot" directory. It is also rather simple. It looks through the partition table for a partition with type byte of <span>0xBB</span>. If not found, an error is shown. Else, the partition in its entirety is read into RAM at <span>0x80001000</span>, and then jumped to. This partition can be arbitrarily large, and this is where my implementation of the "PROM" lives. The actual size limit on it is placed by the fact that MIPS Linux expects to be loaded at <span>0x80040000</span>. This is no accident - the first 192K of RAM is reserved for the <span>PROM</span> to use as long as the operating system expects to use <span>PROM</span>'s services. Thus the limit on the loader's size is 188K. 
</p>
<p>My <span>PROM</span> implementation's code can be found in the "loader" directory. It will search the SD card for a partition marked as active, attempt to mount it as FAT12/16/32, and look for a file called "VMLINUX" in the root directory. If found, it will be parsed as an ELF file, properly loaded, and run. Else an error will be shown. As this code has no serious size limits, it implements a proper ability to log to console, printf, and all sort of such creature comforts. As far as <span>PROM</span> services go, it provides console logging, memory mapping info, and reading environment variables, at least enough to make Linux happy. I have not tried to boot other operating systems on uMIPS (yet?).
</p>
<p>The kernel commandline I pass is rather simple: <span>earlyprintk=prom0 console=ttyS3 root=/dev/pvd3 rootfstype=ext4 rw init=/bin/sh</span>. The first parameter provides for early boot logging via the <span>PROM</span> console, which is useful to see. After the kernel is up, it'll use the third serial port for console. Originally for the DECstation that was the printer serial port, but Linux users on DECstation use that for serial console due to that being the easiest port to convert into a simple serial port. The rest just tells the kernel how to boot. I prefer to boot into sh, and then issue <span>exec init</span> myself, thus the <span>init=/bin/sh</span>
</p>
<h3>How uMIPS runs</h3>
<p>After all the optimizations (which I'll detail in a bit) the effective speed of my virtual MIPS R2000/R3000 on this infernal ATSAMD21 chip is around <s>900KHz</s> 1.2MHz. The CPU spends around 8% of its time handling timer interrupts, and thus around <s>0.83MIPS</s> 1.06MIPS of CPU cycles are left for useful work. With this, the kernel takes around 2 minutes to boot and run <span>sh</span>. Executing busybox's <span>init</span> and getting to the login prompt takes another minute. Overall not too bad. Commands reply instantly, or in a few seconds. It takes gcc around 2 minutes to compile a hello world C program, and I estimate that in a few days' time, one could rebuild the kernel on the device itself, copy it to <span>/boot</span>, and reboot into it. Yes, I <s>do intend to try this and time it</s> did do this and it worked!
</p>
<p>The emulated real time clock is actually real time, plus or minus the inaccuracies of ATSAMD21's ultra-low-power 32KHz timer. It is ok enough that you will not notice. Try the <span>uptime</span> command.
</p>
<p>There is just one thing I did not yet address concerning running Linux on uMIPS. The storage. I said that it is an SD card, but surely DECstation had no SD card slot. However, Linux is open source. I simply created my own very simple paravirtualized disk driver which uses a hypercall to talk directly to the emulator and request sectors to be read or written directly into the virtual RAM. To Linux, this looks just like DMA, except instant. The whole implementation of the driver is under 200 lines of code and can be seen in <span>pvd.patch</span>
</p>

<h3>Linux changes</h3>
<p>I made some changes to the kernel to make life easier. They are provided as patches against the 4.4.292 kernel, and as is a working kernel image. Why that version? Because when I started that project, it was an LTS version of the kernel, and since RAM is short, I wanted the smallest possible kernel, so this was preferable to a later version. The config I am using is available in <span>kernel_4.4.292.config</span>. A config for an even smaller kernel (that requires uMIPS to emulate the full FPU) is available in <span>kernel_4.4.292.config_nofpu</span>
</p>
<p>I did a lot of work making the kernel as small as possible. Since Linux does not support paging out pieces of the kernel, every byte of kernel code is one byte fewer available to use for user space. I ruthlessly removed options that were not needed. In the end I got the kernel down to just under 4MB, which is pretty damn good, considering that MIPS instructions are not very dense.
</p>
<p>As part of this work, I made a few code patches. For various reasons (cough..delay slots..cough) the kernel can find itself needing to interpret userspace code, or parse userspace instructions. No matter what kernel configs I gave, the code to handle microMIPS (a future MIPS expansion not known in the days of R2000/R3000) was present. It was wasting space and time trying to handle things that would never happen. The patch <span>useless_exc_code.patch</span> removes this code if the target CPU does not support microMIPS</p>
<p>Before I implemented my FPU emulator, I was using the kernel's FPU emulation code that traps and executes FPU instructions. It had a bug. If compiled for a 32-bit MIPS processor it did not properly emulate some FPU instructions that operate on the double type. I believe this is wrong. It was causing crashes in code compiled for R3000. The patch <span>fpu.patch</span> modifies the kernel's MIPS FPU emulator by adding a config option to enable the full FPU emulation even on MIPS-I chips.
</p>
<p>Due to the differences between the R2000/R3000 and the R4000 the kernel needs to know at build time which CPU it is being built for. If you attempt to run the wrong kind of kernel on the wrong kind of CPU, it only gets far enough to panic about it. Fine, OK, but then why does this flag not affect a lot of TLB-handling code. Both kinds are always compiled in, despite us knowing at build time with 100% certainty that at least half of it will not ever be of any use? The patch <span>tlbex_shrinkify.patch</span> wraps the useless code in checks for the compile-time-selected CPU type and thus removes some kernel code, saving valuable bytes.
</p>
<p>As uMIPS runs with a real real-time clock, I did not want Linux to spent too much time handling timer interrupts. Normally, a 128Hz timer is used on DECstations by Linux. I added options for 64Hz, 32Hz, and 16Hz timer ticks as well. This reduces effective timer resolution, but effectively unloads the virtual CPU from having to spend most of its time handling timer interrupts. The patch <span>clocksrc.patch</span> does this, and the one called <span>kill_clocksrc_warning.patch</span> silences a pointless warning about timer resolution.
</p>
<p>If you do build uMIPS with full FPU emulation, there is aso a patch to remove all of the FPU emulation code from the kernel to save a few KB of RAM: <span>fpu.patch</span>. 
</p>

<h2>Improving performance</h2>
<h3>Instruction cache</h3>
<p><a href="https://dmitry.gr/images/linuxCardCompileTime.png"><img src="https://dmitry.gr/images/linuxCardCompileTimeSmall.jpg" alt="Linux card board layout"></a></p><p>One thing the processor will surely do every cycle is fetch an instruction. This means that every cycle begins with a memory access. For us that is a painful subject thanks to Atmel's errata-ridden SPI unit. And not just that, memory translation also needs to happen, and that also takes time. A good way to avoid both of these problems is a VIVT instruction cache. It'll read instructions 32 bytes at a time, and allow us to hopefully often not need to translate addresses or reach for main memory. I allocated 2KB of RAM to this cache. It is 32 sets of 2 ways of 32 byte lines. Whenever memory mappings change, it needs to be invalidated. I do this automatically and thus the running code on the virtual MIPS CPU does not need to know about it. The measured hit rate while booting Linux is around 95%, which is pretty nice for such a small cache. The geometry was determined experimentally by profiling how long a boot takes with various cache geometries. This one was found to be the best.
</p>
<h3>Improving CPU speed</h3>
<p>ATSAMD21 series is specified to run at 48MHz. In my testing they run perfectly well up to 96MHz, with some specific chips able to hit 110MHz. I found no chip unstable at 96MHz, so I decided to just run at 90MHz, for some safety margin. This immediately got me a pretty serious performance uplift. No, it is not really 100%, since (1) SPI RAM is still limited by the SPI speed limit, and (2) flash memory has wait states which had to increase for the larger speed. But this did give me an honest 65% improvement. Still a good start. Now RAM SPI runs at CPU / 6 = 15MHz.
</p>
<h3>Improving RAM bandwidth</h3>
<p>Since I could not make the RAM SPI units go faster due to Atmel's incompetence, I decided to go wider! I can drive four units at once. Given, there is overhead to each read and write command, but still this is faster than one or two. <s>My code initially supported one, two, or four RAM chips, but for simplification I dropped that support and now only support four-channel RAM.</s> Quite the statement eh? This microcontroller has four-channel RAM! The emulator accesses RAM in increments of 32 bytes. The RAM read/write commands themselves are 4 bytes each. This means that for a single-RAM chip situation, reading 32 bytes takes (4 + 32) * 8 = 288 SPI bits. In dual-channel configuration it'll take (4 + 16) * 8 = 160 SPI bits, since the command is still 4 bytes long, but we only read 16 bytes from each RAM , for a total of 32. For quad-channel RAM, we thus have (4 + 8) * 8 = 96 SPI bits to read 32 bytes. This is a 66% improvement from the single-channel case! In reality the improvement is less, since quad-channel mode cannot use DMA at all, so it is a bit slower. Real-life measurement shows that quad-channel mode is a 50% improvement over the single-channel case. But still, given this damn chip, any improvement is an improvement I'll take.
</p>
<p>But, why are all the RAM acceses 32 bytes in size? Well, as you see RAM accesses are slow. A typical 32-byte access takes 140-ish SPI cycles, which is around 12 microseconds. If every access took that long, my emulated CPU would be limited to no more than 85,000 memory accesses per second. That is too slow to be practical. Something had to be done. I decided on a cache. Sadly, my microcontroller has a very limited amount of RAM, so the cache had to be small. I evaluated various cache geometries, and found that a 20-set 2-way cache with 32-byte lines produced the best performance uplift for the emulator. It gets a 91% hit rate while bootling the kernel, which is a pretty good payoff for 1.25KB of RAM. With a hit taking around half a microsecond and a miss taking around 12 microseconds, adding this cache improved the average memory access by 87%! Yes, this is effectively an L2 cache. Now, how many emulators do you know that have an L2 cache to paper over the terrible performance of their chosen host hardware, eh? The cache allocates on reads and writes, except for reads and writes of precisely 32 bytes in size. Those are passed through directly because they are either SD card access DMA or icache fetches that do not need to also be cached in this cache.
</p>
<p>After some more profiling, I rewrote the "hot" part of the memory access code in assembly for some more speed gain. GCC may have come a long way since a decade ago, but it still does not hold a candle up to hand-written assembly. I removed support I had for one and two-channel RAM to simplify the hot path as well. So now you need to populate all four RAM slots for the card to boot. If you populate different RAM sizes, the smallest one will dictate the final usable RAM size. The usable RAM size will always be four times the size of the smallest RAM chip. This isn't a big deal, the DECstation came with 4MB of RAM, and could be outfitted with a maximum of 24MB. This card can be outfitted with 32MB, so you'll be living like a king! That being said, due to the size of the Linux kernel, you're not going to get a successfull Linux boot unless you have at least 6MB of RAM<s>, and uMIPS will refuse to boot if that is the case (eg: if you populate 4x 1MB chip)</s>.
</p>
<h3>Dirty hacks specifically for Linux</h3>
<p><s>Remember how on MIPS the operating system must do its own pagetable walking and filling of the TLB? As you can imagine this happens often. Very often. How could I speed this up without causing any correctness issues? On taking the <span>TLB refill</span> exception, I verify the handler has not changed and matches the expected bytes, if so, I do what it would have done, but in native code, not emulated MIPS. This helps this particular code run quite a bit faster. Correctness is not compromised since this is only done if the handler matches what is expected, byte for byte.</s>
</p>
<p>I also mentioned that due to how delay slots work, if a CPU takes an exception on an instruction in the delay slot, the kernel must be able to completely emulate that instruction, or in other way execute it and then jump to the right place? Linux uses the fact that MIPS has no PC-relative instructions, except jumps, and it is illegal to place a jump in the delay slot. How? Instead of emulating the delay-slot instruction, Linux copies it out to a special page in memory, where it is followed by a trap. Linux then jumps there in user mode to let it execute, catches the trap, and then re-directs execution where it should go. Now, if this sounds like a giant hassle to you, you are right. What can we do? Well, if an instruction in a delay slot causes an actual exception (like an illegal access, or a TLB refill exception, or some such thing), not much can be done. But what we <em>CAN</em> do is not make things worse. uMIPS will not deliver IRQs before executing an instruction in the delay slot of a branch. At worst, this will delay an IRQ by a cycle, which makes no difference to correctness. The benefit is that this sort of instruction copying and juggling can be done less.
</p>

<h2>How to build and use one</h2>
<h3>Building</h3>

<p><a href="https://dmitry.gr/images/linuxCardPcb.jpg"><img src="https://dmitry.gr/images/linuxCardPcb.jpg" alt="Linux card PCBs"></a></p><p>Now, why you really came here. How do you get one? Well, you could try knowing me personally and asking for my business card, I have a few to give out, but other than that, here is how to do it.
</p>
<p>You'll need to order the board from a board fabrication place. I am a fan of <a href="https://jlcpcb.com/">JLPCB</a> and recommend them. The gerber files I provide come in two flavours. One as you see my card exactly, and one without my name and contact info :). This is a four-layer board, the board house will ask you for layer order, it is: GTL, G1, G2, GBL. At least JLPCB has options to also cover the edge connector in gold for better contact, called "gold fingers" and to grind the board edge to 45° for easier insertion. I suggest selecting both of these options - they are free. Remember to set the board thickness to 0.8mm.
</p>
<p>While you wait for the board to arrive, you'll want to order the parts. You'll need four of the same memory chip (I have the links above), an ATSAMDA1E16, an AMPHENOL 11400841 SD card slot, and a MIC5317-3.3YM5TR regulator. You'll also want to (optionally) order an 0603 sized blue or white LED for SD activity light. If you choose to have that LED, you'll also need a 430 ohm resistor in 0603 or 0805 size. Besides that, you'll need in 0603 or 0805 sizes: 2x 5.1Kohm resistor, 1x 1Kohm resistor, 3x 0.1uF capacitor, and 7x 1.0uF capacitor. You will also need an SD card and any SWD programmer capable of programming the ATSAMD chip. There are many out there. Pick your favourite.
</p>
<p>You'll need an SD card as well. 128MB is the bare minimum here if you want to fit the busybox-based rootfs in. To fit the debian or hybrid image I am providing, you'll want at least 512MB. You can write the image to the card using your favourite tool for that. On Linux and MacOS that is probably <span>dd</span>, on windows, <span>Win32DiskImager</span>.
</p>
<p>Once you've assembled the board, program the MCU with the provided binary <span>software/emu/uMIPS.bin</span> and you're done!
</p>
<h3>Building from source</h3>
<p>You'll want to build a few things. You'll need both an ARM (CodeSourcery) and a MIPS GCC toolchain (I used mips-mti-linux I found online). First, build "romboot", "mbrboot", and "loader". Then, build the kernel. I provided the config, patches, etc. Then you'll want to build the emulator. To build for the MCU, use <s><span>make CPU=atsamd21</span></s>(<b>UPDATE</b>: proper target name changed, see updates later in the article). To build for PC, try <span>make CPU=pc</span>. Then you can build the SD card image. You'll want to copy the MBR from one of mine and modify it, then use <span>mkdisk.sh</span> to embed your kernel, mbrboot, and loader. Use a loopback mount to copy in your rootfs.
</p>
<p>If you want to run the emulator on PC, there are a few things to note. First of all, Ctrl^C will kill it :). Second, unlike the MCU version, the PC version does not incorporate the rom loader in the binary, so you'll need to provide a pointer to it on the command line. A typical command line is <span>./uMIPS ../romboot/loader.bin ../disk.wheezy</span>
</p>

<h3>If you are lazy</h3>
<p>For the lazy ones I am trialing selling all the parts and the board together as a kit on tindie. I'll see how this goes. My suspicion is that it'll end up being a giant pain in my ass and not worth the time, but I am giving it a fair shot. <b>EDIT:</b> Apparently not, and not even with a good reason. I quote: <em>Please resubmit for admin approval once you have addressed: Other Reason.</em>. LOL, how about <em>NO</em>? As a sidenote, if anyone knows companies that do this sort of thing for me (sell a kit I designed), please drop me a line <a href="mailto:tips@dmitry.gr">by email</a>. If you are <em>really really</em> lazy, I might consider having a batch of these factory-assembled by JLPCB as well. If you are interested, click <a href="mailto:assembled_requests_linuxcard@dmitry.gr">here</a> and let me know. No promises yet.
</p>
<h3>Using</h3>
<p>I provide a few disk images. The smallest is the busybox-based one (disk.busybox) - it is small, fast, and cool. I built the busybox from source for MIPS-I with as many applets enabled as I could imagine being needed. The second image is a full debian wheezy (last version to support MIPS-I) rootfs. I should warn you that debian's "init" starts around 3000 processes while it boots, so that takes a long time. If you are using the debian disk image (disk.wheezy), I strongly suggest to just mount proc and sys, and do your things in "sh" without running "init", but it will work if you do ... eventually. I also provide a hybrid image (disk.hybrid). It has a busybox shell and init, but has all of the debian binaries, so things not provided by busybox are still there and work, like gcc and vim. This is the "hybrid" image.
</p>
<p>Using the LinuxCard is easy, insert the SD card, connect USB-C to a computer, and open your favourite serial console app (minicom, PuTTY, etc), if you do not see the boot log, try the other virtual serial port (two exist). In case of a boot error, the SD card LED will blink in an infinite pattern, you can see the code for details on what various numbers of blinks mean.
</p>
<p>Once you see the shell prompt, you can play around, or continue boot to login by typing <span>exec init</span>. After this you'll be able to login as "root" with the password of <s>"mips"</s> "mipsmips". There will also be a login prompt on the second serial port as well. So cool!
</p>


<h2>Version 2</h2>


<h3>Booting Ultrix</h3>
<h4>About Ultrix</h4>
<p>Ultrix is the period-correct UNIX for the DECstation2100/3100. The latest version is 4.5 and with some google-fu you can find ISOs of the install media. It supports the DECstation2100/3100 perfectly, and even has an X11-based UI! The goal of the v2 firmware was to properly run Ultrix on the card. This ended up requiring a lot of work. I had to improve emulation accuracy and implement more hardware. But it did work!
</p>
<h4>First time booting Ultrix</h4>
<p>My first attempts were simple - copy the kernel to my "boot" partition and attempt to load it. It would, of course, not find its root filesystem and panic, but I wanted to see how far I would get at all. The first roadblock was an obvious one - the kernel is not in the <span>ELF</span> format that the linux kernel uses and my loader expects. It is in an older format called <span>COFF</span>. I dug up docs and started working on a parser for <span>COFF</span>. After a little work, I was able to load the kernel and let it run, just to see how far it would go. To my susprise, it got far enough to log some messages to the console! It crashed soon after, when it asked my PROM code for an env variable that I did not know about "scsiid0". Not a bad start. At this point I figured that in a week or so I would have Ultrix booting. It took a little longer...
</p>
<p>Ultrix was designed for this machine, and it was designed to support all parts of it. It does not probe for hardware since it knows that a DECstation2100/3100 should have. It assumes that the requisite hardware is there and starts initializing it. This was a problem for me - I still was not emulating the graphics, SCSI, or the network card. Linux has no support for them so I had not bothered.
</p>
<h4>SCSI</h4>
<p>As this was my first time attempting to emulate SCSI, it took a while. SCSI is so over-engineered, the very word "overengineered" does not do justice to just how much so it it. There are messages, commands, statusses, selects and reselects, and oh so very much more. The SCSI chip in the DECstation2100/3100 is a very strange one that DEC designed just for this device. It is called SII or SMII and I found no docs for it other than the official summary in the <a href="http://www.bitsavers.org/pdf/dec/mips/DS3100_Functional_Specification_Rev3.1_Aug1990.pdf">DECstation3100 specification</a>. It was helpful, as it listed the register bits and values. It was a start. Watching the Ultrix kernel try to access it before it gave up and paniced provided some more help, and reading the SCSI-I and SCSI-II specs filled in the rest. After much work it seemed like the kernel was happy enough to try to enumerate the bus. It would try to select each device in order. Progress!
</p>
<p>From there, the next step was to write a virtual SCSI disk. If you haven't dealt with SCSI before, it is rather unlike most sane designs. A sane design would have a host controller be a heavy/expensive/complex machine that talks to cheap simple devices. This makes sense because typically one would have more devices than host controllers. Not here. A SCSI device drives the bus and determines what it does and when. The only thing the host can do is reqest attention from the device. This took a little while to wrap my head around as it is rather backwards. It is actually even more complex since the target device can disconnect from the bus to do things and later reconnect and continue a transaction. It <em>really</em> is quite complex. Luckily, some of that is optional. A device can also reply without disconnecting, and my virtual disk does that. With a lot of work, I was able to figure out the proper state machinery to make Ultrix indeed identify and talk to my virtual SCSI disk. I split the code into two layers. The bottom handles the basics of just being a SCSI device and the top handles actual disk-specific things.</p>
<p>The code later got expanded to support emulating a CDROM too, to allow me to do an Ultrix install from a virtual CDROM. While working on this, I noticed that the bus enumeration is slowing down the boot a lot. The issue is that there is no way to detect that "no device with this ID exists on the bus". One must attempt a select, and then wait for a timeout. This was taking a while since Ultrix implemented a timeout using a loop with a counter (not using the RTC), and at my virtal CPU speed it was taking seconds. The solution was a dummy SCSI device that does reply to some commands enough to be identified and tell the host that it has no media and is of an unknown type. This device is the "SCSI nothing".
</p>
<p>The SII controller has 128KB of SRAM for DMA-ing data to/from devices. The idea is that one schedules the transfer and it goes on at its pace, when done, an interrupt occurs and data can be copied in/out of this memory. On the PC, this is simple - i can allocate 128KB of RAM and be done with it. On the microcontroller, I do not have that much SRAM, so I steal some memory from my external memory for this, and present less than the full amount to the virtual OS. This works fine for Ultrix as it probes the memory amount page-by-page. Linux probes in 4MB increments, but I have a patch <span>allow_64K_memory_multiples.patch</span> that changes it to probe in smaller increments so that this memory stealing does not cost 4MB of usable RAM.
</p>
<p>Linux has no support for SII SCSI controller, so it continues to use the <span>pvd</span> device.
</p>
<h4>LANCE</h4>
<p>The network card in the DECstation2100/3100 is LANCE. It is somewhat documented in the DECstation2100/3100 specification sheet and I implemented it enought to please Ultrix. It never sends or receives any packets (I can add that later), but it does initialize and interrupt as needed. LANCE has a 64KB SRAM buffer for packets. The PC build of uMIPS fully supports this, the "micro" build of uMIPS will just ignore writes and produce zero reads of this area to avoid wasting 64KB of memory. This works well enough to please Ultrix. Linux has no support for LANCE, so I have no idea if it would be ok with this setup.
</p>
<h4>ESAR</h4>
<p>The MAC address for the network card is stored in a on-board EPROM called the "ESAR" (Ethernet Station AddRess). It lives at the same address as the real time clock, except it is wired to the upper byte of every word, while the DS1287 is wired to the bottom byte. This is a weird thing to do but it works. It does mean that some weird things are possible, like reading both the ESAR and the real time clock registers at once with one read. Luckily this is not usualy done. The ESAR data has some checksums and redundancy (so that its correctness is easy to verify). I implemented an ESAR for uMIPS, assigned the ethernet address <span>66:44:22:44:66:22</span> to the device, and provided for all the required redundancy and checksums. Ultrix is satisfied with this.
</p>
<h4>Memory probing &amp; proper PROM API</h4>
<p>While booting Ultrix I notied that it directly probed the amount of RAM in the system. This is strange since Linux simply queried the memory amount from a PROM API that conveniently exists for this. This was actually my mistake since I was emulating a much newer PROM iterface than the real DECstation2100/3100 had, and Linux was happy to use it. The newer standard (called REX) provides the OS a function pointer table with a lot of API. To signal REX support, a magic value is also passed. DECstation2100/3100 predate the REX API and used a different method of providing API to the OS - a table of jumps is placed at known offsets from the start of the PROM in the <span>0xbfcXXXXX</span> address space. This API is also more primitive, and lacks, for example, the ability to tell the OS how much RAM there is. The pieces now fall into place... My only problem is that I do not have an ability to have a huge PROM, as I wrote earlier. I needed another method to offer this API. I decided to indeed have this jump table, but redirect all the jumps to an address in the RAM area reserved for the PROM <span>0x80001000..0x8002ffff</span>. You'll recall that my OS loader loads there. Now it can provide this PROM API, just like it did the REX API. Cool! Testing Linux also shows that it happily uses this API properly as well. It is, of course, now also forced to <em>probe</em> the RAM amount. No big deal. I did find a bona fide bug in the kernel here! While it means (as per comments) to probe for a maximum of 480MB of RAM, but actually only probes for up to 30. The fix is in <span>fix_mem_limit.patch</span>.
</p>
<h4>Ultrix Loader</h4>
<p>At this point, the kernel was loading far enough to panic about not finding the root filesystem, so it was time to figure out a good way to make this work. The problem is that Ultrix uses a completely different partitioning system than the well-familiar MBR I had been using. The Ultrix "disklabel" allows for 8 "partitions" but with some assumptions, like that the first (caled "a") is always the rootfs, the second (called "b") is always swap, the third ("c") always covers the entire disk (yes it does and is expected to overlap others), and another one ("g") is <span>/usr</span>. Now, if this was not fun enough yet, the partition table itself is expected to be <em>inside</em> the rootfs partition, and a whole lot of tools (including the installer) assume that this all starts at sector zero. Fun, eh?
</p>
<p>I spent a lot of time trying to figure out how to make the installer be happy to not start the rootfs at the 0th sector, but this was a lost cause. A large number of scripts involved assume that both the "a" and the "c" partition start at zero. The kernel also has similar assumptions. With some patching, I got it to work with an offset, but this was not a good approach. I decided to see if I could live with how Ultrix does things, instead of trying to force it to do things my way. Even though the rootfs and the partition table both start at the 0th sector, they both reserve some space up front for "boot code". Specifically, the first 16 sectors (8KB) are always free. I decided to simply place my loader there and teach it how to understand the Ultrix disklabel. As part of this work, I refactored the loader into a few pieces. One part was a partition table handler. There is an option for MBR, one for Ultrix, and one for NetBSD disk labels. One of these (build-time determined) is linked in to the loader, as needed. Another module was a binary loader. Two exist: ELF for Linux and NetBSD, and COFF for Ultrix. Same as before, only one is linked into the loader, as needed. The third modue is the filesystem driver. There is one for FAT12/16/32 (used for my Linux boot sequence), one for old UFS (for Ultrix), and one for modern UFS (for NetBSD). Again, just one is linked in, as needed.
</p>
<p>The cool part now is that I can mix and match these pieces as needed to create a loader for the OS I want to boot. The Linux loader is thus <span>FAT + ELF + MBR</span>, for Ultrix, the loader is <span>UFS.old + COFF + Ultrix disklabel</span>, and for NetBSD, it is <span>UFS.new + ELF + NetBSD disklabel</span>. I was too lazy to implement proper CD-booting, so installing Ultrix is a bit weird. I make a disk image with just the installer kernel (extracted from the CD), in a FAT partition, attach the CDROM to the emulator, and then boot. The installer will then re-partition the disk. For this, yet another loader combination is used: <span>FAT + COFF + MBR</span>. The modularity pays for itself!
</p>
<h3>Making Ultrix work</h3>
<p><a href="https://dmitry.gr/images/linuxCardUltrixUiBig.png"><img src="https://dmitry.gr/images/linuxCardUltrixUiSmall.jpg" alt="Ultrix UI fully booted with a graphical paint program and a terminal open"></a>
<a name="_TOC_42badd9e49002a3cefeaaf28867add83"></a></p><h4>Framebuffer</h4>
<p>Once I had the Ultrix kernel booting properly, at least in the PC build of uMIPS, I <em>really</em> wanted to get the GUI working. Who wouldn't‽ The framebuffer came in two varieties for this machine. There was a monochrome one and a 8-bit color one. They both supported hardware cursor as well. I implemented most of the normally-used modes in the cursor hardware, but not any test modes. I emulated both the framebuffer types and they both work! The 8-bit framebuffer can display up to 259 colors onscreen at a time, out of a 24-bit palette. That is not a typo. The display itself can display 256 colors, and the cursor has its own 3-entry palette, which need not use any of the same colors. The resolution is 1024x1024 in memory, and 1024x864 onscreen. The remaining memory is free for the OS to use however it wishes. I steal memory from the main RAM, same as for the SII buffer. 128KB is used for the mono framebuffer, and a whole megabyte for the color one. The palette is also stored in stolen ram (just about a kilobyte).
</p>
<h4>Mouse, Keyboard, ... and Tablet</h4>
<p>Of course, to make this work, I also had to make the keyboard and mouse work. They talk to the DECstation via serial, and the protocol is somewhat known, from various shreds available online. I was able to put together a passable keyboard emulator rather quickly. It is <em>not</em> a dumb keyboard. It has regions of keys, a bell, some lights, and can support differing autorepeat settings per key group. It is actually pretty cool. The mouse is a pretty basic one, with three buttons. I got that working rather quickly. The problem with emulating mice is a well known one - they are relative device, and most OSs apply acceleration to the mouse as you keep moving it to allow for better reach. Now, if you are running another OS, and passing these accelerated movements to it, it will re-accelerate them even more. This ends up being a mess. This is why most virtualization solutions prefer to load an absolute-pointing-device driver into the guest. I was not prepared to hack up Ultrix or find a way to load a different mouse driver in it. But then I noticed that DEC wrote about a "graphical tablet" that they were selling, that hooked up to the mouse port. Could it be that Ultrix supports this? Yup... Ultrix does. I wrote an emulator for the tablet and it worked wondefully - no more over-accelerated mouse for me! Sweet!
</p>
<h4>Patches</h4>
<p>Ultrix assumes that it is booting on a real DECstation2100/3100, and that includes expecting the CPU to have caches. My virtual CPU does not expose caches to the guest OS, and while Linux handles that fine, Ultrix does not. It correctly probes the cache and finds its size as zero. But there is a logic bug in <span>r3_kn01flush_cache</span>, where if the cache size is zero, it gets into an almost-infinite loop. As uMIPS exposes no cache, it makes sense to patch the function away into just a return. There is another function of interest: <span>kn01delay</span>. It is used for short busy-wait delays when dealing with hardware. All of our virtual hardware is instant-fast, and thus no delays are needed. As long as I am patching a kernel, might as well make it faster. There is also a third area of interest - the periodic timer. In Linux, I was able to change the tick to 16Hz, but I cannot build Ultrix from source, so I cannot modify it easily. Ultrix uses a 256Hz tick. At that rate, on uMIPS hardware we'd never get any useful work done while only handling interrupts. I attempted to patch Ultrix to use a 16Hz timer and account for it correctly. This does not work - there are mathematical errors that happen. 64Hz works, but that is still too freqent for the uMIPS hardware to be usefully fast. I ended up patching the init code to set the timer to 16Hz, but accounting code to act like it is 64Hz. This means that "realtime" in Ultrix runs 4x slower than actual real time, but this is not really a big deal. Just keep in mind that a <span>sleep 1</span> will delay 4 seconds and not 1.
</p>
<p>So how does one even apply such patches? How does one find the proper places to patch? I spent a <em>LOT</em> of time learning about the barely-documented symbol format used in the Ultrix kernel. It worked! I made a working parser for it and was able to properly identify the symbols I needed and to patch the places that needed patching. This was good until I realized that while the installer kernel does ship with symbols, the kernel installed for first boot does not (after first boot, the kernel is recompiled again, with options you choose, and that version DOES have symbols). No symbols means that I cannot use them to find the proper locations to patch. I decided on a different method - binary matching. Look for the proper set of bytes in a row, it should be unique in the kernel. If you find just one case - it's the right one. To save space in the loader (as it is limited to 8KB), I compress the "pattern to look for" cleverly. Cool. This is the final approach I used and you can see it in <span>loadUltrix.c</span>.
</p>
<h3>Improvements in the emulator</h3>
<h4>USB improvements</h4>
<p>After a lot of googling, I learned about interface association descriptors. Turns out that without them, windows will not load the USB CDC-ACM drivers for a device. After adding them, Windows would properly load the driver and it would show up as a COM port. I also learned about the peculiar ways that Windows enumerates devices. Sometimes it'll ask for a descriptor, stating that it'll accept 64 bytes, but after receiving just one 8-byte packet it will reset the bus. This was breaking my USB code, and this is now fixed. Windows now properly supports uMIPS and shows it as two COM ports. Sweet!
</p>
<h4>More perf improvements</h4>
<p>At the end of emulating every instruction, the emulator jumps "to the top", fetching a new instruction to execute. In most cases before this a check is done for whether there is an interrupt pending. This jump was done using a <span>BL</span> - the only long-distance branch available on the Cortex-M0. It takes 3 cycles. The check involved loading a byte from memory (2 cycles), checking if it is zero (1 cycle), and jumping to the interrupt exception creation code if so (1 cycle if not - the common case). That means that the entire "jump and begin handling the next instruction" step took 6 cycles. I wanted to make it faster somehow. I decided that if I could free up a register, I could. Some reworking freed <span>r11</span>. There is a parameter you can pass to gcc to tell it to not use a given register in any C code it compiles: <span>--ffixed-r11</span>. Now that this register is not being used by anyone ever, we can do the clever thing. We keep the address of the "load next instruction and execute it" label in it. Now we can jump to it using just <span>bx r11</span>. This takes just 2 cycles - 4 cycles saved per virtual instruction - a significant speed up. But what if we do have a virtual interrupt to report? Whenever we have one to deliver, we just set <span>r11</span> to point to the "report a virtual interrupt" label, and whenever the current virtual instruction is done being emulated, the interrupt will be reported and <span>r11</span> will be reset. There is a bit more machinery needed to make this work, but this is it in general terms, and it does work!
</p>
<p>I also changed how the TLB hash works (from a table of 32-bit pointers to a table of 8-bit indices) to make the table and each entry smaller (from 24 bytes to 16). This saved a bit under a kilobyte of RAM, which I was able to allocate to the L2 cache. It has now grown from 1.25KB to a full 2KB for a measurable perf improvement!
</p>
<h4>Removing the TLB refill fast path</h4>
<p>For Linux, I had implemented a fast-path for the TLB refill code - it executed in native code what he TLB refill handler would do. In my measurements it slightly improved performance. With all the other performance improvements I had implemented, it no longer offered a measurable improvement. Plus, it did not help Ultrix at all, by definition. Removing it saved flash space and removed complexity. Less complexity is always better. It is gone.
</p>
<h4>Cache geometry changes</h4>
<p>Previously, when profiling to find the best L1i geometry, I used the Linux boot process. I decided to try harder. Now I profiled that, gcc compiling some code, a few other Linux binaries, Ultrix boot, and some Ultrix userspace utilities. The result of this investigation was that a direct-mapped L1i is slightly faster than a 2-way L1i cache. The hit rate goes down slightly, but checking only one cache line instead of two speeds up the checking enough to make up for it. I thus reconfigured the cache as a direct-mapped cache.
</p>
<h4>Serial improvements</h4>
<p>Previously, the emulator would wait a fixed 20ms to send a character to the PC before giving up. I changed this to a permanent wait for the main console. This allows the user to not miss any output if they close their terminal. The emulator also shows its version up front, since it will definitely not be missed now. As of firmware v2.1.1, uMIPS also shows the RAM configuration in terms of the number of chips, each chip's size, and the bit width of the per-chip interface.
</p>
<h3>More Floating Point Unit work</h3>
<p>I had already implemented a full virtual FPU, but now I wanted to see how necessary it really was. I knew that Linux would run if I emulated no FPU at all and would emulate it. I wanted to see if Ultrix would. It did not - it crashed with an invalid instruction trap in the kernel. This was not all that surprising. Once again, it was compiled for a particular machine - a machine that had an FPU. Its assumption that an FPU exists was sane. But there was still more to investigate. The MIPS spec says that the FPU may refuse to execute any instruction if it is not sure that it can perform it perfectly accurately. Since the spec is not clear on what that really means, basically any OS running on such a MIPS chip must implement a complete FPU fallback, capable of emulating any FPU instruction. But then why am I hitting an exception?
</p>
<p>The trick is that the FPU must still exist, it must refuse to do math. This is strictly different from not existing at all. I thus implemented a "minimal" FPU. It implements the instructions to identify itself, move data in and out of the floating point registers, and load and store floating point registers to memory. Any attempts to do actual floating point math report a "coprocessor usage exception" which is the proper way for the FPU to refuse to do math. This worked correctly for Ultrix - it now will not crash at boot, all applications that do floating point math still run, with the kernel emulating the math. I checked and Linux also supports this setup. Thus uMIPS now has three FPU configs that it can be built with: <span>full</span>, <span>minimal</span>, and <span>none</span>.
</p>
<h3>A bootloader</h3>
<p>As I handed out more and more of these cards, the update story needed to be improved. Not everyone has a <a href="https://cortexprog.com/">CortexProg</a> lying around to reflash the firmare. I decided to make it simple and require as little user interaction as possible. The bootloader is just under 3K, I allocated 4K of flash to it, and relocated the main firmware to start 4K into the flash. So, how does it work? At boot, the bootloader will minimally initialize the SD card, attempt to find a FAT16 partition on it, see if it contains a properly-sized file called <span>FIRMWARE.BIN</span> on it, and if so, the firmware will be flashed from this file. On error, the error number will be blinked out on the LED, repeatedly. On success, a varying-frequency pattern of the LED will be repeated forever.
</p>
<p>If the card fails to be initialized, if it fails to mount, if the update file does not exist, or if it is not correctly sized, the bootloader will continue to boot the existing firmware, if any exists (some sanity checking is peformed). This means that when you insert a card with my Linux image or the Ultrix image, all will work as expected. Only FAT16 is supported, so some partitioning may be required on larger cards. I can live with that.
</p>

<h3>Hardware improvements</h3>
<h4>v1.3 hardware</h4>
<p><a href="https://dmitry.gr/images/linuxCardSchem2.png"><img src="https://dmitry.gr/images/linuxCardSchemSmall2.jpg" alt="Linux card schematics"></a>
<a href="https://dmitry.gr/images/linuxCardBoard2.png"><img src="https://dmitry.gr/images/linuxCardBoardSmall2.jpg" alt="Linux card board layout"></a></p><p>After reading my original article, a few people wrote in (including in the comments section here, on twitter, and in email) to suggest that maybe I should entirely abandon the shitty SPI units in this chip. Initially I was worried that the SPI unit speed issue was really an IO port speed issue, but a quick test showed that I could toggle a pin at half my CPU clock reliably and get nice square edges. I prototyped bit-banging SPI on the existing board to see what speeds I could attain and it was promising. I then laid out a new board, with different wiring, to allow me to actually use QSPI mode. The images for the new schematics and the layouts are the ones you see here!
</p>
<p>The ATSAMD21 series features a single-cycle IO port. This optional Cortex-M0+ feature is pretty useful for bit-banging. It really is single-cycle-fast. Normal loads and stores take two cycles minimum on a Cortex-M0+, but ones targetting this kind of a unit take just one. That is <em>how</em> I could toggle a pin at half the cpu speed for my test that I had just mentioned.
</p>
<p>With big-banging, the trick is to do as few operations per cycle as possible. Given this, it would be ideal to do minimal bit-twiddling. It would be super-awesome if I could wire up the four QSPI chips to GPIOS numbered 0..15, allowing me to just read/write the bottom 16 bits of the GPIO port for simple access. Alas, this was not meant to be. This chip has no contiguous 16 GPIO pins wired to the physical pins, so I settled for wiring RAM0 to GPIO0..3, RAM1 to GPIO4..7, RAM2 to GPIO8..11, and RAM3 to GPIO14..17. Since I will be driving them all together, the clock and chip select lines are all wired together. After all was said and done, after the assembly was coded, and the dust settled, I was able to get around a 9MHz clock speed on average. Since the command and address are also sent 4-bits-wide, the speed increase is nice. Previously (using hardware SPI) it took around 8 microseconds to read/write 32 bytes, now it took just under 4 microseconds. A nice speedup.
</p>
<p>An astute reader might notice that the first three RAMS <em>ARE</em> on consecutive GPIO pins. Three is not of much use to us, as it is not a power of two, but <em>two</em>... Yes indeed using only two RAMs i can attain faster speeds (but at half the width). The actual time to read/write 32 bytes is around 5 microseconds. Given this, I decided to re-add the previously-removed support for using less than 4 RAMs on the board. And I did. The newest firmware now supports 1, 2, or 4 RAMs populated on the new boards. I then went futher, and re-added this support for the old boards. That is not as well optimized - it is in C, not ASM, but good enough to play with. This will allow assembling these boards cheaper. Plus, Ultrix happily boots and runs in 4MB (it does need 5MB to start the GUI though).
</p>
<h4>And old hardware too</h4>
<p>I did not want to maintain two separate-but-almost-equal branches of code for the older v1.2 hardware and the new v1.3 hardware. There was also no easy way to tell them apart in software from first glance. But a bit more investigation does provide an idea. The wiring for the RAMs is different enough that we can try each way and see if we detect a plausible RAM chip. It helps that not having RAM0 populated is never supported. This is precisely what I did, in fact. I tried both configs and see which produces a valid-looking ID from RAM0. From there, all four RAMs are probed, identified, and a configuration is picked.
</p>
<p>Support for less than 4 populated RAMs raises a few interesting questions. For speed, all RAMs are treated as if they are the same size, so the size of the smallest RAM determines the total amount of available RAM. This is because I stripe the data across them, of course. So, what if RAM0 is populated with 8MB, and RAM1 with 2MB? We could use just RAM0 and get 8MB of RAM or we could use both and get just 4MB, but faster, since more RAMs in parallel is always faster. I decided that more RAM is better than faster RAM, so in case of such conflicts, more RAM is always chosen. When there is a tie, the faster configuration is used, eg: 4MB, 1MB, 1MB, 1MB RAMs populated add up to 4MB in both the x1 and x4 configs. In this case the x4 config will be chosen and all the RAMs will be used.
</p>
<h3>Building from source (updated)</h3>
<h4>The emulator</h4>
<p>A new parameter called <span>FPU</span> is now passed to uMIPS build to specify the FPU type desired. Options are: <span>none</span> - no FPU at all, Ultrix will not like this but it makes the smallest image; <span>minimal</span> - an FPU that can store values but refuses to do math - Ultrix and Linux will support this, it is slightly larger; and <span>full</span> - a full FPU that does all the math - the fastest option that bloats the Cortex-M0 image by 17KB or so.
</p>
<h4>The loader</h4>
<p>To build the proper loader, pass the <span>BUILD</span> parameter to <span>make</span>. The options are <span>linux</span>, <span>ultrix</span>, <span>ultrix_install</span>, or <span>netbsd</span>. The install loader is just for clean installs, which you have no reason to do since I already did it for you. The netbsd one is to attempt boots of NetBSD on this machine, as it is supported by NetBSD. The proper loader needs to be built and integrated into a disk image for a working system.
</p>
<p>The integration step also changed, <span>mkdisk.sh</span> is gone, replaced by a number of different tools, depending on the intended system. They are: <span>mkdisk-linux.sh</span>, <span>mkdisk-netbsd.sh</span>, <span>mkdisk-unix.sh</span>, and <span>mkdisk-unixinstall.sh</span>. Unix here refers to Ultrix, of course. The scripts are small and self explanatory. Open them for more details. They all operate on a disk image called "disk"
</p>
<p>To enable GUI in Ultrix, the env variable "console" needs to be properly set. In <span>loader.c</span>, find it and set it to "0,0" for text mode or "1,0" for console mode.
</p>
<h3>Further Updates</h3>
<h4>Firmware v2.1.1</h4>
<p>In this version, BBQSPI memory access sped up by 11% for 4-chip case, 6% for others. Ram config shown on boot.
</p>
<h4>Firmware v2.2.0</h4>
<p>In this version, the bootloader was updated to better support other ATSAMD21 parts, including those with more flash &amp; RAM. It now also exposes a version byte at offset <span>0x08</span>. The previous bootloader was version <span>0x10</span>, making this one version <span>0x11</span>. The version will be shows on the serial console at boot now.
</p>
<p>Also, as ATSAMDA1E16 is now apparently out of stock everywhere, I added support for <a href="https://octopart.com/atsamd21e17a-au-microchip-77761547?r=sp">ATSAMD21E17A-AU</a>/<a href="https://octopart.com/atsamd21e17a-aut-microchip-77761548?r=sp">ATSAMD21E17A-AUT</a>. The sad news is that this non-automotive part does not overclock nearly as well. It gets unstable much past 76MHz, so I decided to clock it at 72MHz. It does have more RAM (16KB), which allowed me to allocate a lot more memory to L1i and L2 caches. In most measurements, the performance loss due to lower speed is papered over by the gains of larger caches.
</p>
<p>On the topic of performance, I also rewrote the L2 cache code in assembly for speed and size gains. The speed gains are significant. For extra speed, there is now an option to move the actual access functions to RAM (which is faster than flash). This gains an extra 8% speed, but at the cost of using RAM. On the old 8KB-of-RAM parts this is not always worth it, since it necessitates shrinking the L2 from 2KB to 1.625KB to make space. On the new 16KB-of-RAM parts, though, it is we;ll worth it. It should be noted that there are 6 variants of RAM access low level functions as there are 2 possible access types (SERCOM or bit-banged) and 3 possible chip counts (1, 2, or 4). Only the ones you plan to use need to be moved to RAM. Others will still work from flash, if you want to make a universal firmware. The firmware I provide now moves the 4-chip bit-banged functions to RAM for ATSAMD21E17. See <span>RAM_FUNCS_IN_RAM</span> in the Makefile and the contents of <span>spiRamAtsamd21.c</span>
</p>
<p>While moving functions to RAM, it is easy to accidentally use too much RAM and end up with random crashes as stack collides with data. These are a pain to debug, so I decided to improve this experience. As an option in the Makefile, there is now ability to enable <span>STACKGUARD</span>. What does this do? As the very last word in the pre-allocated RAM (and thus the very first one that stack would overflow over) the code will keep a magic cookie, whose value depends on the current <span>ticks.hi</span> value. This value is checked and updated in the <span>SysTick</span> interrupt which happens every 16 million cycles. If the check fails, an error will be blinked out the LED and the execution will be halted. 
</p>
<p>Starting with this version, the proper make incantations are now <span>make CPU=atsamda1e16</span> and <span>make CPU=atsamd21e17</span>
</p>
<p>The downloads have been updated with the new code and binaries for both chip types. They can be updated using the bootloader and an SD card
</p>





<h2>In conclusion</h2>
<h3>Acknowledgements</h3>
<p>I send a great many thanks to my cats for cutely lying under my table to keep me company during the many hours spent on this project. I send a giant, Mount Rushmore-sized middle finger to Atmel for this sorry excuse of a chip. <b>UPDATE:</b> I even gave up on using the SPI units here, so at this point, I send <em>two</em> of those fingers. Thanks for nothing, Atmel.
</p>
<h3>Downloads</h3>
<p>The source code, gerbers, schematics, and all else <em>except</em> the disk images can be downloaded [<a href="https://dmitry.gr/images/LinuxCard2.7z?v=220">here</a>]. The license on my code is simple: free for all non-commercial use, including using as your own business card. For commercial use (like if you wish to sell kits of this project), <a href="mailto:licensing@dmitry.gr">contact me</a>.
</p>
<p>The disk images (<b>updated</b>) are large so I have no desire to host them on my site, so: [<a href="https://drive.google.com/file/d/14fhdW4Vdz4-ZKucB-iIP4MLTk8OLB7dI/view?usp=sharing">Google Drive</a>] or [<a href="https://mega.nz/file/p9ZWzLrK#saRKVlgBthOFE4Cp-6sb2fMTM7JXtuXMlsYQaaWrEAI">MEGA</a>].
</p>


<!--- We do not show this to the user, but ToC system will index this and we'll get a link to comments in the ToC -->






					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Name That Nation (111 pts)]]></title>
            <link>https://www.namethatnation.com/</link>
            <guid>39268439</guid>
            <pubDate>Mon, 05 Feb 2024 23:04:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.namethatnation.com/">https://www.namethatnation.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39268439">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[We've already seen category 6 hurricanes – scientists want to make it official (240 pts)]]></title>
            <link>https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official</link>
            <guid>39268106</guid>
            <pubDate>Mon, 05 Feb 2024 22:27:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official">https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official</a>, See on <a href="https://news.ycombinator.com/item?id=39268106">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-220146">
	<div>

		
		
<p>Five tropical cyclones in the past 9 years have hit wind speeds far above the category 5 threshold, causing thousands of fatalities and billions of dollars of damage. Such ultrastrong, highly destructive hurricanes are becoming more likely as climate change increases the amount of energy available to storms.&nbsp;</p>

<figure><blockquote><p>“Storms are getting stronger and stronger, so category 5 underestimates actual risk.”</p></blockquote></figure>

<p>In a <a href="https://www.pnas.org/cgi/doi/10.1073/pnas.2308901121" target="_blank" rel="noreferrer noopener">new study</a> published in the <em>Proceedings of the National Academy of Sciences of the United States of America</em>, scientists suggest that the growing intensification of tropical cyclones may necessitate adding a sixth category to the <a href="https://www.weather.gov/hgx/tropical_scale" target="_blank" rel="noreferrer noopener">Saffir-Simpson Hurricane Wind Scale</a>. Doing so could be one useful tool not only to indicate hurricane risk but also to convey the increasing dangers of climate change.</p>

<p>“Storms are getting stronger and stronger, so category 5 underestimates actual risk,” said <a href="https://experts.news.wisc.edu/experts/james-kossin" target="_blank" rel="noreferrer noopener">James Kossin</a>, an author on the paper and an atmospheric scientist at the University of Wisconsin–Madison.</p>


<h3>Warming Winds</h3>

<p>The Saffir-Simpson scale is the most widely recognized hurricane intensity scale, ranking storms from “tropical depression,” at wind speeds less than 38 miles per hour (61 kilometers per hour), to “category 5 hurricane,” at wind speeds greater than 157 miles per hour (253 kilometers per hour).</p>

<p>That scale may <a href="https://eos.org/articles/probing-the-power-of-pacific-supertyphoons" target="_blank" rel="noreferrer noopener">not capture the risk posed by the most intense storms</a> as the world warms, the authors wrote. They suggest a sixth category that encompasses storms with winds greater than 192 miles per hour (309 kilometers per hour).</p>

<p>The authors used three lines of evidence to support the creation of a sixth category. First, multiple storms have already spilled over into the hypothetical category 6. <a href="https://www.climate.gov/news-features/understanding-climate/2013-state-climate-record-breaking-super-typhoon-haiyan" target="_blank" rel="noreferrer noopener">Typhoon Haiyan</a>, for example, made landfall in the Philippines in 2013 and had winds that reached 195 miles per hour (314 kilometers per hour). Haiyan was the costliest storm ever to hit the country and one of the deadliest, causing more than 6,000 fatalities. In 2015, <a href="https://en.wikipedia.org/wiki/Hurricane_Patricia" target="_blank" rel="noreferrer noopener">Hurricane Patricia</a>—considered the strongest hurricane ever recorded—brought winds of up to 215 miles per hour (346 kilometers per hour) to southwest Mexico.</p>

<p>Climate change has likely contributed to the intensification of tropical storms, <a href="https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter11.pdf" target="_blank" rel="noreferrer noopener">according to the Intergovernmental Panel on Climate Change</a>, the United Nations body that assesses climate science.</p>

<p>The authors also analyzed the maximum potential intensity of storms in recent decades. That metric refers to the highest wind speeds that are possible on a given day given that day’s weather conditions. They found that in the Gulf of Mexico between 1979 and 2019, conditions were conducive to category 6 hurricanes about 10 days a year.</p>

<p>The number of days conducive to category 6 wind speeds has increased because of climate change, said Kossin.</p>

<p>Last, the authors modeled future hurricanes under various climate change scenarios and found that under each possible scenario, the risk of a category 6 hurricane increased. “Over the next decade, there will be category 6 [hurricanes],” said <a href="https://crd.lbl.gov/divisions/amcr/computational-science-dept/acsd/staff/staff-members/michael-wehner/" target="_blank" rel="noreferrer noopener">Michael Wehner</a>, an author on the paper and a climate scientist at the Lawrence Berkeley National Laboratory.</p>

<h3>Communicating Climate Change</h3>

<p>Communication of risks shouldn’t focus only on the Saffir-Simpson scale, according to <a href="https://www.weather.gov/organization/michael-brennan" target="_blank" rel="noreferrer noopener">Michael Brennan</a>, the director of NOAA’s National Hurricane Center (NHC). Most fatalities caused by hurricanes occur not from wind but from water, including storm surges and rain.</p>

<p>“At NHC, we’ve tried to steer the focus toward the individual hazards, which include storm surge, wind, rainfall, tornadoes and rip currents, instead of the particular category of the storm,” he wrote in an email. “Category 5 on the Saffir-Simpson scale already captures ‘Catastrophic Damage’ from wind, so it’s not clear that there would be a need for another category even if storms were to get stronger.”</p>

<figure><blockquote><p>“The reality is that hurricanes have changed already. This creates the need to discuss whether the systems that we currently have in place are adequate for the future.”</p></blockquote></figure>

<p>The question of whether a category 6 would be an effective communication tool requires a larger discussion, with input from social scientists, psychologists, emergency managers, and city planners, Kossin said. He said he hopes the idea of a hypothetical category 6 will spark more discussion of how to warn people about all hurricane-related risks, including wind, storm surge, and rainfall, as hurricanes continue to intensify.</p>

<p>“What we’re trying to highlight is not the immediate danger of an impending storm,” Wehner said. “That kind of thing is already out there. What we’re trying to communicate is that the risk of the most intense storms is increasing because of climate change.”</p>

<p><a href="https://www.stonybrook.edu/commcms/somas/people/_profiles/kevin-reed" target="_blank" rel="noreferrer noopener">Kevin Reed</a>, a climate and atmospheric scientist at Stony Brook University who was not involved in the new study, said that expanding the Saffir-Simpson scale would not only indicate increased risks from individual storms but highlight the worsening risks of climate change in general.</p>

<p>“The reality is that hurricanes have changed already,” Reed said. “This creates the need to discuss whether the systems that we currently have in place are adequate for the future.”</p>

<p>—Grace van Deelen (<a href="https://twitter.com/GVD__" target="_blank" rel="noreferrer noopener">@GVD__</a>), Staff Writer</p>

<h5><strong>Citation:</strong>&nbsp;van Deelen, G. (2024), We’ve already seen category 6 hurricanes—now scientists want to make it official,&nbsp;<em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240060" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2024EO240060</a>. Published on 5 February 2024.</h5>

<h6>Text © 2024. AGU.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a><br>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chris Wanstrath "defunkt" GitHub cofounder and former CEO is banned on GitHub (111 pts)]]></title>
            <link>https://twitter.com/defunkt/status/1754610843361362360</link>
            <guid>39267200</guid>
            <pubDate>Mon, 05 Feb 2024 21:08:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/defunkt/status/1754610843361362360">https://twitter.com/defunkt/status/1754610843361362360</a>, See on <a href="https://news.ycombinator.com/item?id=39267200">Hacker News</a></p>
Couldn't get https://twitter.com/defunkt/status/1754610843361362360: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Meta cuts off third-party access to Facebook Groups (105 pts)]]></title>
            <link>https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/</link>
            <guid>39266874</guid>
            <pubDate>Mon, 05 Feb 2024 20:43:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/">https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/</a>, See on <a href="https://news.ycombinator.com/item?id=39266874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">The recent surprise announcement that Meta will soon be shutting down its Facebook Groups API is throwing some businesses and social media marketers into disarray.</p>
<p>On January 23, Meta <a href="https://developers.facebook.com/blog/post/2024/01/23/introducing-facebook-graph-and-marketing-api-v19/">announced the release</a> of its Facebook Graph API v19.0, which included the news that the company would be deprecating its existing Facebook Groups API. The latter, which is used by developers and businesses to schedule posts to Facebook Groups, will be removed within 90 days, Meta said. This includes all the Permissions and Reviewable Features associated with the API, it also noted.</p>
<p>Meta explained that a major use case for the API was a feature that <a href="https://developers.facebook.com/docs/messenger-platform/discovery/private-replies/">allowed developers to privately reply</a> in Facebook Groups. For example, a small business that wanted to send a single message to a person who posted on their Facebook Group or who had commented in the group could be messaged through the API. However, Meta said that another change in the new v19.0 API would enable this feature, without the need for the Groups API.</p>
<p>But developers told TechCrunch that the shutdown of the API would cause problems for companies that offer solutions to customers who want to schedule and automate their social media posts. For example, explained Adam Peterson, the CEO of <a href="https://vipecloud.com/">VipeCloud</a>, which provides a suite of tools for scheduling social media posts, the API’s closure will have a “noticeable impact” on his business, as about 8% of his total revenue is on the chopping block. His company serves some 5,000 Facebook accounts, primarily those belonging to female entrepreneurs, he noted.</p>
<p>These customers rely on VipeCloud’s access to Facebook’s APIs to publish publicly to their Facebook Pages, but also post privately to Groups to communicate with their team. The private groups are used as something of a Slack alternative by these small businesses, he says.</p>
<p>“Every single one of our customers is freaking out,” says Peterson.</p>
<p>Other customers of the Groups API may rely on automations that are scheduled by the business’s agency partners, some of which will be disproportionally impacted by the API’s closure.</p>
<p>Peterson explains that customers often rely on agencies to handle various aspects of their posting, like team building or team motivation. “Those agencies, this is their entire business. This is their livelihood,” he adds.</p>
<p>The move also impacts VipeCloud’s competitors, often non-venture-funded companies that build market-specific services and whose revenue may be in the single-digit millions to low double-digit millions.</p>
<p>“Some of these other companies — they’re going to be killed,” notes Peterson. “And that’s just never fun to watch, even if we compete with them. You’d rather win on service or product or something,” he continues. “This is platform risk in real time.”</p>
<p>A company by the name of<a href="https://postmyparty.com/"> PostMyParty</a>, which helps social sellers and others schedule and automate online parties, says the API’s closure will put the company out of business.</p>
<p>“I will lose seven years of work and over 10,000 customers,” owner Daniel Burge tells TechCrunch. “A multimillion-dollar loss. Let alone the impact on all of our customers that rely on our software,” he adds.</p>
<p>PostMyParty is used by small micro-businesses, including health and fitness coaches who do online boot camps in Facebook Groups, work-at-home moms engaged in social sales and others with coaching groups or customer groups, says Burge.</p>
<p>The entrepreneur pointed out this is not the first time Meta has done something like this.</p>
<p>“A number of years ago [Meta] abruptly ended their Events API, with zero notice,” Burge says. “We just came in one day and everything was broken, we had thousands of support requests open from our customers and it almost destroyed our business that time as well.”</p>
<p>What’s more, developers tell us that Meta’s motivation behind the API’s shutdown is unclear. On the one hand, it could be that Facebook Groups don’t generate ad revenue and the shutdown of the API will leave developers without a workaround. But Meta hasn’t clarified if that’s the case. Instead, Meta’s blog post only mentioned one use case that would be addressed through the new v.19.0 API.</p>
<p>Maurice W. Evans, a Meta Certified Community Manager, believes the move will pose challenges for small businesses, developers and digital markets, but also represents a “pivotal shift in Meta’s operational philosophy.”</p>
<p>“The removal of third-party access to Facebook Groups could significantly alter the digital landscape, creating both hurdles and opportunities for community managers and businesses alike. As a Meta Certified Community Manager, I’ve seen firsthand the value these tools bring to fostering vibrant, engaged online communities. This change underscores the need for adaptability and innovation in our strategies,” Evans tells TechCrunch.</p>
<p>Elsewhere on social media, website design firm Archer Web Design <a href="https://twitter.com/ArcherWebsites/status/1752687220639650066">called the news of the API’s closure “devastating</a>” and said that “businesses and social media marketers will be thrown into the stone age with this!,” they wrote in a post on X, formerly Twitter.</p>
<p>On Meta’s forum for developers, <a href="https://developers.facebook.com/community/threads/2076398286093257/">one developer says</a> they’re “pretty shocked” by the company’s announcement, noting their app relies on the Groups API and will essentially no longer work when the shutdown occurs.</p>
<p>Others are frustrated that Meta hasn’t clearly explained if posting on Groups will be done with a Page Access token going forward, as the way the announcement is worded it seems that part is only relevant for those posting private replies, not posting to the group as a whole. Burge, for instance, wonders if the whole thing could just be some messaging mistake — like Meta perhaps forgot to include the part where it was going to note what its new solution would be.</p>
<p>There is concern, however, that Meta is deprioritizing developers’ interests having recently shut down its <a href="https://developers.facebook.com/support/bugs/">developer bug portal</a> as well.</p>
<p>Reps from Facebook haven’t replied to the developers’ comments in its forums (as of the time of writing), leaving everyone in the dark.</p>
<p><a href="https://developers.facebook.com/community/threads/584177870580474/">Laments another developer</a> in the forum, “it affects my ongoing projects and projects that will be launched soon. I don’t know what to do.”</p>
<p><em>This story is developing. Meta has been asked for comment and we’ll update as we know more.&nbsp;</em></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Want to build a sequencer? 454.bio opens up their plans (133 pts)]]></title>
            <link>http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html</link>
            <guid>39266859</guid>
            <pubDate>Mon, 05 Feb 2024 20:41:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html">http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html</a>, See on <a href="https://news.ycombinator.com/item?id=39266859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-965125533024651667" itemprop="description articleBody">
<p>Just as the AGBT hype cycle was firing up (with me contributing multiple sparks), serial entrepreneur Jonathan Rothberg's latest sequencing startup 454.bio fully de-stealthed their technology this weekend, going so far as to release<a href="https://454.bio/docs/"> open source plans</a> to build an instrument prototype.&nbsp; 454.bio&nbsp; is aiming to build a Keurig-sized device to retail for $100, with sequencing runs in the $20 range.&nbsp; To accomplish this, they're attempting a novel twist on sequencing-by-synthesis.&nbsp; It's an unconventional strategy by someone who has succeeded twice before in DNA sequencing (454 and Ion Torrent) and has multiple other companies going (if I've counted correctly)&nbsp; - QuantumSI in protein sequencing (a future topic for this space, I promise!), ButterflyNetworks with inexpensive, compact diagnostics ultrasound and Hyperfine with inexpensive, compact MRI diagnostic devices.&nbsp; Then I went to the <a href="https://www.4catalyzer.com/">4Catalyzer site</a> - Rothberg's incubator - and discovered a bunch of companies I hadn't heard of or had forgotten about -- Protein Evolution in synthetic biology for plastics production, Detect for home-based diagnostics instruments, AI Therapeutics in the rare disease space and Liminal with what looks like consumer brain scanning.&nbsp; That's quite a series of companies!&nbsp; &nbsp;But the one closest to my heart (sorry QuantumSI :-) is&nbsp; 454.bio, and their announcements have many interesting facets which I'll dive into.</p><h2><span><a name="more"></a></span>New Wine in an Old Bottle</h2><p>Rothberg loves the 454 story and the 454 moniker, and so went and bought all the trademarks back from Roche.&nbsp; 454, after all, launched the first commercial post-Sanger sequencer and also generated the first genome of a previously-named individual, controversial DNA pioneer (and knucklehead) James D. Watson (yes, everybody knew Celera sequenced J.Craig Venter, but there was a claim of anonymity at first).&nbsp; &nbsp;Whether reviving the name was a great idea is good over-drinks conversation - already I've seen confusion as to why anyone would reboot 454 technology -- and 454.bio's approach has essentially nothing to do with 454's approach.&nbsp;&nbsp;</p><p>In the molecular biology analytics space, Rothberg has been responsible for founding 4&nbsp; companies before 454.bio, starting with what I'll refer to after this as 454 classic.</p><p>Raindance was the least successful, due to never finding a good market for their really cool picoliter droplet technology.&nbsp; They first tried to go after target enrichment for NGS, but soon were plowed over by in-solution technologies from Agilent and Nimblegen.&nbsp; Later they pivoted to digital PCR, but that market was still developing and the Raindance instrument was too big and expensive.&nbsp; Perhaps there was another product pivot or two in between.&nbsp; Eventually it was sold for IP to BioRad.</p><p>Ion Torrent did not achieve the lofty goals it set out to hit - we never saw a single chip generate an entire human genome - but did create a working sequencer and was enough of a threat that Illumina brought out MiSeq to compete with the PGM.&nbsp; Ion Torrent was also the first non-optical detection NGS instrument, and found at least some showcase uses (if not much market) in places where optical sequencers wouldn't perform well, such as on a boat.&nbsp; And Ion carved out a lucrative niche in genetic panel testing, driven by being paired with AmpliSeq multiplex PCR technology - another great example (like Nextera which I cited in my previous piece) of lock-down a complementary technology driving market share.&nbsp; But even that wasn't enough - eventually ThermoFisher capitulated and licensed AmpliSeq for Illumina platforms.&nbsp; Ion is still on the market, but hasn't innovated in years in terms of performance.&nbsp; Indeed, it was around the time Rothberg left that performance improvement tanked; he picked a good time to leave.</p><p>QuantumSI, which I'll cover sometime in the future, is the first (and so far only) entrant in next-gen protein sequencing.&nbsp; There's an important parallel between the technical approaches of QuantumSI and 454.bio: one pot operation.</p><h2>One Pot Sequencing</h2><p>Every short read sequencer to date has used a cyclic chemistry scheme.&nbsp; Each base (or series of the same base for flow chemistries such as 454classic, Ion Torrent, Genapsys and Ultima) requires adding reagents, and then there are stripping steps (for reversible terminator schemes) and washes.&nbsp; Then another cycle happens.&nbsp; Each cycle is distinct and requires fresh reagents.&nbsp;&nbsp;</p><p>Delivering those reagents requires microfluidic pumps and lines.&nbsp; Delivery to the flowcell can be dogged by challenges of even dispersal; Ion Torrent raw signals had patterns of light and dark looking like flow lines.&nbsp; The smaller Ion chips had almond-shaped gaskets which lost much surface area but had more uniform fluid flow.&nbsp; Later, higher capacity chips tried to go for something more like a square to maximize area, but the corners could be troublesome -- and if reagent from one cycle hung up there it would contaminate the next cycle.&nbsp;&nbsp;</p><p>Also troublesome is that the reagents are very highly concentrated, to drive the reaction to near completion.&nbsp; But only tiny amounts of the volume actually go anywhere useful and very little of those expensive reagents actually are consumed by the sequencing reactions; most are just flushed away each cycle.&nbsp; That adds to the expense.</p><p>454.bio is introducing "One Pot Sequencing" - there are no cycles of reagents.&nbsp; QuantumSI's chemistry has a similar notion, though that is a degradative not synthesis chemistry, but again no cycles -- the "one pot" of reagents runs the reactions continuously.&nbsp; &nbsp;454.bio is using a reversible terminator chemistry, except instead of using chemical cleavage to remove the terminator and fluorescent moieties, ultraviolet light is employed.&nbsp; These "Lightning Terminators" were once the basis of LaserGen - a company that was acquired by Agilent and then somewhat quietly shuttered.&nbsp; LaserGen was developing a more conventional cycling instrument, but with very fast cycle times.</p><p>Like all other optical readout short read sequencers (except 454!), 454.bio employs Total Internal Reflection Fluorescence (TIRF) microscopy.&nbsp; The basic idea of TIRF is that if you aim light at the right angle, by the precepts of conventional physics it will all reflect off the interface between the glass surface and the reagents above -- but in quantum land the light's field extends a bit beyond that surface - evanescent illumination.&nbsp; So only a tiny volume of reagent will give any signal - the tiny volume that contains polonies.&nbsp; PacBio uses a similar logic with Zero Mode Waveguides - when they are imaging fluorescence can only occur close to the surface and so the huge background of unincorporated nucleotides and released labels is essentially invisible.&nbsp;&nbsp;</p><p>For 454.bio, this is also how the removal of the fluorophore/terminating moiety occurs - a cycle of illumination with the appropriate wavelength of light to cleave the terminator moiety.&nbsp; Lighting Terminators are 3' unblocked; the 3' hydroxyl is always there but steric effects prevent the polymerase from accessing it.&nbsp; So the evanescent illumination is critical again - you don't want to be deblocking all the terminators that haven't been incorporated.&nbsp; Of course, there will be free terminators that do get into the critical zone -- such as blank areas with no polony or diffusion into the polony and so forth.&nbsp; So 454.bio will build up problematic unterminated nucleotide triphosphates after every deblock cycle.&nbsp;&nbsp;</p><p>And that is their current problem - read lengths are in the single digits because the polymerase they are using prefers the unterminated nucleotides to terminated ones, so after a few cycles of deblocking there's enough unterminated nucleotides to cause serious dephasing -- the molecules in the polony are no longer moving in lockstep.&nbsp; In one of their unconventional steps (more on this below), 454.bio has announced a contest for improving the discrimination of the polymerase.&nbsp; If you win by delivering a much improved polymerase a year from now, you get $200K&nbsp; and can patent and/or public - but grant 454.bio a royalty-free license to use your invention and they have the rights to further engineer based on your design.&nbsp;&nbsp;</p><p>Here's a plot of the <a href="https://454.bio/blog/2023/12/18/s0592-sequencing-results/">most recent sequencing run described on their blog</a>.&nbsp; I'd still prefer to see the error rate plotted log scale, but in this range it's not that important a point.&nbsp; Claim is those first five bases are in the phred 20-25 range.&nbsp; Plotting it log scale would help resolve to what degree is that jump from 4 to 5 truly a discontinuity or is it where the trend was going.&nbsp;&nbsp;</p><div><p><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjJu7bl8nCoH0HzxA06xxC8EkOlXqZQZVpMXYnN05jtX8yNxYVSUYRX06ay6FWSn_GA7EAaPksTrMDHG3liFjedlT-_4dXTvp1ZOe051G8_Z563K8Mvisc5iwebnCIVnS2sx3gaPNLfCUAogItEpPy7be7hNQgH2EUKNU1GT_l0I_moyApCs_P_lw"><img alt="" data-original-height="339" data-original-width="480" height="226" src="https://blogger.googleusercontent.com/img/a/AVvXsEjJu7bl8nCoH0HzxA06xxC8EkOlXqZQZVpMXYnN05jtX8yNxYVSUYRX06ay6FWSn_GA7EAaPksTrMDHG3liFjedlT-_4dXTvp1ZOe051G8_Z563K8Mvisc5iwebnCIVnS2sx3gaPNLfCUAogItEpPy7be7hNQgH2EUKNU1GT_l0I_moyApCs_P_lw" width="320"></a></p><p>And from the prior post we can see the degree of color chaos going on in a cluster.&nbsp; If I understand the note on the sequence of the templates, this should read TCAGG which appears to map to red, blue, green, yellow, yellow -- but the majority color here is red red green yellow yellow.&nbsp; So it would appear the deprotection of the cycle 1 T (red) did not go very well (again, I'd prefer to see a log plot of the intensities!!) as we see intense red in cycle 2 and still a bunch in cycle 3 and a bit in 4 and 5 -- and the next T in the template isn't until position 10!&nbsp; I'd be tempted to design the molecules at this point to go a really long ways before the first base shows up again, so could measure very carefully the degree of lagging phasing.&nbsp; We see the yellow prephasing as a blip in 2 but significant in 3 -- again, it would be interesting to design some libraries where there are more positions before the first instance of a given base.&nbsp; If I were working on this, I'd probably be designing a whole library of templates to use in given runs -- complexity of four in each run but various choices of design to stress-test various aspects of the chemistry.&nbsp; Okay, I'm getting sucked into the challenge here...</p></div><div><p><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjBrwdcerJnSkC9bY10hDUC8THFpSOM9BAL6WccajQ3qOExXl6fOkEbSaZgCmiWmZ3PKBpPNAeICeMSMLFNeJHNXilKIWeS-EVi5YkVUK2yMreUlLS5uqLkkxXgn-mtHPFM1H5Wv_zcDnX3Y8IOszeWWAqH6US8zQ10HpMRt1k-4UCtVQQZ91BwHw"><img alt="" data-original-height="180" data-original-width="475" height="121" src="https://blogger.googleusercontent.com/img/a/AVvXsEjBrwdcerJnSkC9bY10hDUC8THFpSOM9BAL6WccajQ3qOExXl6fOkEbSaZgCmiWmZ3PKBpPNAeICeMSMLFNeJHNXilKIWeS-EVi5YkVUK2yMreUlLS5uqLkkxXgn-mtHPFM1H5Wv_zcDnX3Y8IOszeWWAqH6US8zQ10HpMRt1k-4UCtVQQZ91BwHw" width="320"></a></p></div><p>By the way, how are polonies (or clusters, if you prefer) formed?&nbsp; 454.bio is using circular library molecules which are isothermally amplified by something I see as rolling circle amplification (RCA) crossed with bridge amplification.&nbsp; The surface has forward and reverse primers covalently bound, and initial amplification is by one of those primers driving an RCA reaction - but those products can now find other bound primers to drive more reactions and so on.&nbsp; The result is a hyperbranched structure.&nbsp; The reverse primers all contain deoxyuracil, so a USER reaction destroys these to loosen up the snarl.&nbsp; Note that because each cluster results from multiple priming events, this style of cluster generation will make copies of copies, unlike pure RCA cluster generation on platforms such as AVITI and Complete Genomics.</p><h2>Unconventional Company</h2><p>Going open source is certainly not the usual strategy for a company - most companies stay in stealth mode, then get some alpha sites without revealing much to the world - Ultima's technology first ran at the Broad in a locked room that only a select cadre of Broad employees had access to or even knew existed.&nbsp; Oxford Nanopore went a bit differently by <a href="https://omicsomics.blogspot.com/2012/02/oxford-nanopore-doesnt-disappoint.html">suddenly destealthing at AGBT 2012</a>, then going relatively quiet for two years, but then executing the MinION Access Program (MAP) for many researchers around the world.&nbsp;&nbsp;</p><p>Appealing to the idea of garage hobbyists has an almost romantic appeal.&nbsp; When I was about 8, my brother and father got a kit-based computer for a few hundred dollars when there were many such kits and no fully functional home computers yet.&nbsp; Ours was a <a href="http://retro.hansotten.nl/6502-sbc/datac-1000-a-tim-6502-sbc-from-1976/">DATAC-1000</a>, the input method was a series of metal pads and the only output device was a row of LEDs above the metal pads.&nbsp; Well, it had a cassette tape interface for storing programs.&nbsp; There were others like the KIM-1 and the Altair and some tree fruit named one we started hearing about.&nbsp; For at most a few thousand dollars you could flesh these out with calculator-style keypad+display or even simple video interfaces.&nbsp; From that era came many early programmers and hardware tinkerers -- big brother put together our video display (he may have even designed it).&nbsp; &nbsp;In terms of financial outlays, a serious computer building habit cost not much different than diving into 35mm photography.</p><p>Sequencing technology seems so digital and potentially as impactful, plus there is so much burnishing of the legend of the early computers or companies like Hewlett-Packard that started in garages.&nbsp; Ion Torrent tried to tap into this, but the catch was that their claimed price of $50K isn't hobbyist money - and the real upfront outlay was $100K.&nbsp; It's also a lot harder to get things running the first time - with some coaching an 8-year old me could write a simple 6502 machine code program to add two numbers but making a sequencing library is a much bigger lift.&nbsp; Plus all the accessories you need.&nbsp; Those old computing days you mostly got by with pliers and a soldering iron (we did have not one but two oscilloscopes - didn't everyone in the 1970s have one in their house?).&nbsp; But for even the most basic library prep, you must have temperature control of liquids, a complete set of pipettors, a minfuge and probably a few more bits.&nbsp;&nbsp;</p><p>There was a <a href="https://omicsomics.blogspot.com/2009/10/pondering-polonators.html">build-it-from-plans sequencer called the Polonator</a>, but at the time it cost around $200K to put one together.&nbsp; &nbsp;Some academics did so, but it never had a large user base - and then the supplier of reagents was bought by QIAGEN and that was the end of Polonator.&nbsp;</p><p>Oxford Nanopore tried to tap into the vibe with MinION, but discovered its not easy.&nbsp; They certainly reaped large dividends from the MAP getting MinIONs into the hands of many early career folks who didn't have a vested interest in sustaining the Illumina ecosystem and could make a name for themselves pioneering nanopore sequencing.&nbsp; So folks like Josh Quick, Nick Loman, Miten Jain, Matt Loose (and far too many I'll omit here - my apologies!) held on through ONT's initial unreliability and zigzagging platform changes and showed novel applications and strengths of nanopore sequencing and shared their protocols and software with the world.&nbsp; But for better or worse, you didn't actually build any of the hardware.</p><p>Mid last decade I did have one sequencer startup offer to send me plans to build a very low cost instrument -- they claimed around $1000 in parts.&nbsp; It never came to fruition - and I'm not sure sending me lab plans made much sense though I was game to try it out, but the idea has been out there before.&nbsp; The NDA I had with them is probably enforceable, so I won't spill who it was (sorry!).</p><p>Now 454.bio is really, truly releasing complete plans.&nbsp; I'm not sure I'm capable of quite following them and I would expect that early users will be sending in pointers about where they can be improved.&nbsp; But the directions are there as are the design files for the many 3D-printed parts in the instrument.&nbsp;&nbsp;</p><p>I tried my best to price out the most expensive components - it would have been nice if this happened about two years ago as I could have asked a favor of my nephew, who was in customer support at one of the optical houses listed in the parts inventory.&nbsp; So please check yourself.&nbsp; The biggest ticket item is the camera, which I have at $700 -- but the description in the parts brings up many variations with variation in price range -- perhaps one thing 454.bio could nail down a bit better.&nbsp; There's a positioning table for $300, four different bandpass filters for $1000 total ($250 each), and 16 UV LEDs that add up to $130.&nbsp; No other component seems to be more than $100, and my total is up to about $2500.&nbsp; That doesn't include things that look inexpensive like nuts and bolts and such or the 3D printing, but suppose that somehow added $500.&nbsp; $3K is less than it can be easy to spend on a mirrorless digital camera and a few lenses for it. So not unreasonable.</p><p>The announcement shows some signs of being rushed - one image talked about "complimentary strands" of DNA in two different locations. But worst, the original price in the store for the critical reversible terminator mix was $33,999!&nbsp; That's a hell of a lot more than I ever spent on film, photo prints or photo paper! After pushback, Rothberg declared "typo"&nbsp; and the price changed to $1299&nbsp; - the Levenshtein distance between that and 33,999 engenders skepticism of the typo explanation.&nbsp; That $1299 is said to enable 60 runs.&nbsp; That was the advantage of the old kit computers - once you bought them the only consumable was blank cassette tapes, which were cheap, reusable and you didn't need many.&nbsp;</p><p>You'll also need the sequencing reservoir components, $49.99 for a pack of 5.&nbsp; As my colleague (and synthetic biology legend) Tom Knight pointed out on X/Twitter, the finishing directions for the reservoirs aren't for amateurs, involving several solvents and something he called "piranha".&nbsp; Yikes!&nbsp; Rothberg responded that they'll work towards something more consumer friendly.&nbsp; &nbsp;So that brings running costs to about $33 per run - $23 dollars of terminators and $10 for the reservoir (note: unlike their store, I like to round!)</p><h2>What's The Market?</h2><p>In the short term, you'll need to be very interested in playing with a novel technology that doesn't really do very much.&nbsp; The early kit computers, and even the first all-in-one home computers such at PET and TRS-80, weren't much better - you could learn to program or you could play games, but not very much else no matter how many journalists tried to claim it could organize recipes or help prepare taxes -- that was all long in the future (and who organizes recipes when you can just google them?).&nbsp; With the current tiny readlength, you'll be very hard pressed to get much interesting biology out - though it will certainly be hyped as "go explore the biosphere".&nbsp; With custom sequencing primers, it should be possible to make those 5 or so bases count, but the current 454.bio don't make the process for designing such obvious.</p><p>It may well be that many people will be excited to through their machine learning skills at trying to improve the basecalling and deal with the rampant phasing.&nbsp; It sounds like some diversity of the initial bases is required for good cluster finding - a common aspect of systems using unpatterned flowcells - but it would seem that a set of templates could be cloned (don't want oligo synthesis errors confounding) and sequenced conventionally, then used as 454.bio targets.&nbsp; Each one should have the first 5 bases as a barcode that defines the rest of the sequence -- I'll leave figuring out the number of distinct barcodes with different Hamming or Levenshtein distances as an exercise for the reader..&nbsp; Perhaps some big open repositories will be built for 454.bio data, to increase the training set sizes.&nbsp; And perhaps an advanced machine learning algorithm could make the downstream snarl useful for some basic tasks like "which RNA virus" is this -- at least if you only want "flu A vs COVID vs RSV" level differentiation.</p><p>Longer term, if the phasing issue can be solved and reads could get in the 50 to 100 range, I could imagine diagnostics applications.&nbsp; Maybe.&nbsp;&nbsp;<span>It will depend in part on how many reads per floral - I didn’t see that described but it’s likely to change over the evolution of the chemistry and software. Clearly some evolution of the hardware will be required to get to the goal of $100 a box.&nbsp;</span></p><p><span id="docs-internal-guid-d87fd403-7fff-4b6c-efdd-e6c31220b180"><p dir="ltr"><span>The low end sequencing market has neither gotten much love nor been very successful. Ion Torrent pretended to go for this market, but an all-in upfront cost of $100K isn’t hobbyist territory. Genapsys officially launched their $20K solution, but I never saw one in the field nor ever heard from a customer - and they’re gone. Illumina has used, but that’s instrument has never seen upgrades and is all but ghosted by Illumina management</span></p><p dir="ltr"><span>But the market does have MinION, a fully functional sequencing device you can get for $2K (not a typo!) that’s really works now. In theory the Flongle (another $ for the adaptor) gets run costs in the low double digits. In the home computer market, the arrival of fully featured machines was the death knell of the kit computers, only much later revived with concepts like Raspberry Pi</span></p><p dir="ltr"><span>So how many people will buy in to the 454.bio concept early? During the MAP, ONT saw significant attrition in the user base because the platform was still very buggy and reagent availability was erratic. Others were hooked;&nbsp; for me it was seeing in our first run one very noisy but alignable 48 kilobase read with the entire lambda phage genome.&nbsp;Maybe some novices who build a 454.bio will have a similar epiphany with their first sequence data, but I'm skeptical it will be a wide-spread phenomenon -- though it would make be happy to be proved wrong on that point.</span></p><p dir="ltr"><span>Unconventional operations, an innovative technology at proof-of-concept and appealing to tech hobbyists -- 454.bio should be fun to watch even if they don't succeed in carving out a major presence in the sequencing technology landscape.</span></p></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Relativistic Spaceship (949 pts)]]></title>
            <link>https://dmytry.github.io/space/</link>
            <guid>39266396</guid>
            <pubDate>Mon, 05 Feb 2024 20:07:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmytry.github.io/space/">https://dmytry.github.io/space/</a>, See on <a href="https://news.ycombinator.com/item?id=39266396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="all_ui" ondblclick="toggleFullscreen()">
        <div id="info">
          <br>
          <div onclick="hide_button_click()"><p>The ship is flying at </p><p>0%</p><p> of the speed of light.</p></div>
            <div id="more_info">
              <div><p>γ = </p><p>1</p></div>
              <div><p>Distance (light years) = </p><p>0</p></div>
              <div><p>Screen center Doppler factor = </p><p>1</p></div>
              <div><p>Max Doppler factor = </p><p>1</p></div>
              <div><p>Ship time (years) = </p><p>0</p></div>
              <div><p>World time (years) = </p><p>0</p></div>
          </div>
        </div>
        <p>© 2020 Dmytry Lavrov.</p>

        <div id="acceleration">
        <p>
        A<br>C<br>C<br>E<br>L<br>E<br>R<br>A<br>T<br>I<br>O<br>N
        </p>
        
        <p>1</p>
        </div>

        <div id="exposure">
        <p>
        B<br>R<br>I<br>G<br>H<br>T<br>N<br>E<br>S<br>S<br>
        </p>
        
        <p>1</p>
        </div>

        <p>Relativistic flight visualizer by <a href="http://dmytry.com/">Dmytry Lavrov</a>.<br>
        This project is open source; you can obtain sources at<br>
        <a href="https://github.com/Dmytry/space">https://github.com/Dmytry/space</a><br>
        It uses Three.JS webgl framework; the three.js license is <a href="https://dmytry.github.io/space/three.js.LICENSE.txt">here</a>.
        </p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: CLI for generating PDFs for offline reading (148 pts)]]></title>
            <link>https://github.com/dvcoolarun/web2pdf</link>
            <guid>39265756</guid>
            <pubDate>Mon, 05 Feb 2024 19:24:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dvcoolarun/web2pdf">https://github.com/dvcoolarun/web2pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39265756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:dvcoolarun/web2pdf" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="eSSKYYS7EbGjjRguiBYjJ7lGbNj2aCgpxTlMxGQipBehPuU0dqDfTai8FxakWBA_zGZ8M6oRV9UnGKmgRMx0fw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="dvcoolarun/web2pdf" data-current-org="" data-current-owner="dvcoolarun" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=vAHFOlJTS%2FND5QxX4%2FYCR2C4tep%2FQNEU4ArCjHYR6O90hif61me8%2Fy6G%2FZEbaMs2gA9Scmr8wz6b%2FxHGF6%2Bi0A0Ci8mRWcU5gmTjnmC16KZqrhxwBQeBLeZXAE3yaTypvLyov7RuRGDNCqH%2BEsXN7h%2BnW7sRmUnz%2BC61KMbzRcEDONzpvanjbLrFfcO68aEGtjA99ESFdooupn%2BcQPYn8DoZU8E4tziT2XyxnBZDnC1uy2STcnFhtv57Ss4fNHJrxbgS4ctg3Q9lr4t%2FnqdUoTkxZTPeHTbinhxFrCsRCxXhuWCsmKdnD2PoWQYwwPGHTRo0Qf9VgiULSehrAVoH4QYXwE6%2BR5qYc6%2FWM0xlPsw8UV1pY7OhtJfgHFwvgCbTVlEONSy15ZBsWVNu7Du16PD1LimmWGQAg14zi4dsq7ZJCyRYBm8na7UgTDdiHdfONC0nMRF2MdlRnqiZwdPM5jy6PCINrMAsJZJu%2FTIGTgOpATBgpsVLDfd40orGAggUpA7jhxPgrTiaQVtxfaI%3D--qhW8IwPNQAp7LyH7--M2soVlKNT2NA6IRDQkxtjg%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=dvcoolarun%2Fweb2pdf" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/dvcoolarun/web2pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="69f6307eabf4b6a81ab42be9217bde61923dc50db6bdbf79021d2b7a2d74615c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
    </channel>
</rss>