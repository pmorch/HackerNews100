<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 02 Sep 2024 00:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Extreme Pi Boot Optimization (141 pts)]]></title>
            <link>https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/</link>
            <guid>41420597</guid>
            <pubDate>Sun, 01 Sep 2024 21:36:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/">https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/</a>, See on <a href="https://news.ycombinator.com/item?id=41420597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>üöÄ 3.5 sec to Linux userspace code</p><h3 id="motivation">Motivation<a href="#motivation" aria-label="Heading self-link"></a></h3><p>A while ago, the <a href="https://kittenlabs.de/solarcampi/">SolarCamPi</a> project, a off-grid solar-powered WiFi camera, was built.</p><p>In this project, a Raspberry Pi Zero 2 W is being booted into Linux, a picture is taken, WiFi connectivity is established and the Pi is shut down again (to save power).
This repeats every couple of minutes to always deliver a fresh image to a cloud service.</p><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/IMG_4607.jpg" width="49%" alt="Weatherproof enclosure, with 7.2Ah lead-gel battery and SolarCamPi inside"> <img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/IMG_4629.jpg" width="49%" alt="Mast, with solar panel, WiFi antenna and SolarCamPi enclosure mounted to it, in nature"></p><p>Each second the Pi Zero is powered up uses valuable electricity, which is a scarce resource in a solar-powered device (at least in West European winters‚Ä¶).<br>The user space application (server connection, picture upload, etc.) was already optimized as best as possible.<br>The electronics setup was also specifically designed to use as little power as possible while asleep.</p><p>There a 2 possible ways to reduce total energy consumption further:</p><ul><li>decrease power consumption / current</li><li>decrease time spent running</li></ul><p>However, in some situations a balance needs to be found between the two.
For example: Disabling CPU turbo just to save some current consumption is a bad choice, because the resulting extra time will use more energy than just getting the job done quickly and shutting off.
We want the least area under the graph (of current vs. time) possible.</p><h3 id="hardware-setup">Hardware setup<a href="#hardware-setup" aria-label="Heading self-link"></a></h3><p>Having a short cycle time between making a change and actually seeing it run is critical when optimizing embedded boot processes.
Swapping SD cards, messing with card readers and power supplies while working is distracting and annoying.</p><p>In order to avoid this, a number of useful tools exist:</p><ul><li><a href="https://www.nordicsemi.com/Products/Development-hardware/Power-Profiler-Kit-2" target="_blank">Nordic Power Profiler Kit II</a></li><li><a href="https://github.com/linux-automation/usbsdmux" target="_blank">USB-SD-Mux Fast</a></li><li>USB-UART converter</li></ul><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/featured-DSC01414.jpg" width="80%" alt="Hardware setup, Raspberry Pi Zero 2 W, USB-SD-Mux and PPK2"></p><h5 id="power-profiler-kit">Power Profiler Kit<a href="#power-profiler-kit" aria-label="Heading self-link"></a></h5><p>The Power Profiler Kit II (now called PPK) can supply power to a device-under-test (DUT) and will measure it accurately over time.
You can enable/disable the DUT, see the power consumption at any point and also see the status of 8 digital inputs!
We‚Äôll connect one of the digital inputs to a GPIO pin on the Raspberry Pi.</p><p>This way, the first action of ‚Äúour application‚Äù (aka the finish line) will be to toggle the GPIO pin.
We then just have to measure the time between power-up and GPIO toggle.</p><h5 id="usb-sd-mux">USB-SD-Mux<a href="#usb-sd-mux" aria-label="Heading self-link"></a></h5><p>The USB-SD-Mux is a very useful tool for hardware hackers - it‚Äôs an interposer between a microSD card and a DUT with a USB-C interface.
A computer can ‚Äústeal‚Äù the microSD card from the DUT, rewrite its contents and then plug the microSD card back into the DUT, without ever having to touch the device.</p><p>This makes the workflow of testing changes <em>much</em> easier and faster by avoiding unplugging the card, plugging it into a microSD reader, flashing it, plugging the card back into the DUT, etc. It can even be used to automate the reset or power of the DUT with on-board GPIOs.</p><h5 id="usb-uart-converter">USB-UART converter<a href="#usb-uart-converter" aria-label="Heading self-link"></a></h5><p>Some form of UART interface is pretty much required. These changes will break system boot, WiFi connectivity, etc. at some point and without a UART console we would be flying blind. A standard CP2102, FTDI, etc. will work well.</p><h3 id="measurement--test-setup">Measurement / Test setup<a href="#measurement--test-setup" aria-label="Heading self-link"></a></h3><p>On a clean Debian 12 (bookworm) arm64 Lite image, the <code>/boot/firmware/cmdline.txt</code> file was modified to include <code>init=/init.sh</code>.
This means that the kernel will execute the script at <code>/init.sh</code> as the very first thing in userspace (before running systemd or anything else).</p><p>Such an <code>init.sh</code> script might look like this:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/bin/bash
</span></span></span><span><span><span></span>
</span></span><span><span>gpioset <span>0</span> <span>4</span><span>=</span><span>0</span>
</span></span><span><span>sleep <span>1</span>
</span></span><span><span>gpioset <span>0</span> <span>4</span><span>=</span><span>1</span>
</span></span><span><span>sleep <span>1</span>
</span></span><span><span>gpioset <span>0</span> <span>4</span><span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span>exec</span> /sbin/init
</span></span></code></pre></div><p>which will toggle the GPIO4 and then resume normal boot by replacing itself with <code>/sbin/init</code> (aka systemd).</p><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/debian12-lite-arm64-initsh.png" alt="Power Profiler screenshot, showing GPIO4 going low after about 12s"></p><p>In this screenshot from Nordic‚Äôs Power Profiler software, you can see the current consumption of the Raspberry Pi (at 5V) while booting.
After about 12 seconds, digital input 0 is going low, showing that our <code>init.sh</code> was executed.</p><p>In doing so, a total charge of 1.90 coulomb (coulomb and ampere-seconds are equivalent) was used.<br>Calculating <code>1.9As * 5.0V</code> comes out to <code>9.5Ws</code> energy usage for this boot process.</p><p>For reference: A single AA-alkaline battery can deliver about 13500 Ws of energy.</p><h3 id="reducing-current">Reducing current<a href="#reducing-current" aria-label="Heading self-link"></a></h3><p>Let‚Äôs get the easy part out of the way first and reduce the operating current as much as possible.</p><h5 id="disabling-hdmi">Disabling HDMI<a href="#disabling-hdmi" aria-label="Heading self-link"></a></h5><p>We can disable the HDMI encoder entirely. Disabling the GPU is not possible, because we need it to encode our camera data.
If your application doesn‚Äôt require camera/GPU support, try disabling the GPU entirely.</p><p>This reduces the current consumption from 136.7mA down to 122.6mA (over 10%!).</p><p>Relevant config.txt parameters:</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># disable HDMI (saves power)</span>
</span></span><span><span><span>dtoverlay</span><span>=</span><span>vc4-kms-v3d,nohdmi</span>
</span></span><span><span><span>max_framebuffers</span><span>=</span><span>1</span>
</span></span><span><span><span>disable_fw_kms_setup</span><span>=</span><span>1</span>
</span></span><span><span><span>disable_overscan</span><span>=</span><span>1</span>
</span></span><span><span>
</span></span><span><span><span># disable composite video output</span>
</span></span><span><span><span>enable_tvout</span><span>=</span><span>0</span>
</span></span></code></pre></div><h5 id="disabling-activity-led">Disabling Activity LED<a href="#disabling-activity-led" aria-label="Heading self-link"></a></h5><p>Just by disabling the activity LED, we can save 2mA (122.6mA down to 120.6mA).</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span>dtparam</span><span>=</span><span>act_led_trigger=none</span>
</span></span><span><span><span>dtparam</span><span>=</span><span>act_led_activelow=on</span>
</span></span></code></pre></div><h5 id="disabling-camera-led">Disabling Camera LED<a href="#disabling-camera-led" aria-label="Heading self-link"></a></h5><p>Repeat the same for the camera LED (if present). It will also reduce the chance of the LED reflecting back into the image.</p><h4 id="turbo-tweaking">Turbo tweaking<a href="#turbo-tweaking" aria-label="Heading self-link"></a></h4><p>As mentioned before, saving current while wasting time might not be ideal.</p><p>With our current changes, the Pi can boot while using 1.62As.
<img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/turbo-defaults.png" alt="Power Profiler screenshot, showing a total current usage of 1.62C/As"></p><div><pre tabindex="0"><code data-lang="ini"><span><span><span>force_turbo</span><span>=</span><span>0</span>
</span></span><span><span><span>initial_turbo</span><span>=</span><span>10</span>
</span></span><span><span><span>arm_boost</span><span>=</span><span>0</span>
</span></span></code></pre></div><p>Without forced turbo mode, 1.58As were used:
<img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/turbo-disabled.png" alt="Power Profiler screenshot, showing a total current usage of 1.58C/As"></p><p>For some, unknown reason, disabling the turbo/boost mode also inverts the default state of GPIO4 (thus I‚Äôve switched the polarity in init.sh).</p><h3 id="reducing-time">Reducing time<a href="#reducing-time" aria-label="Heading self-link"></a></h3><p>The ~13% reduction in current is helpful, but there‚Äôs still a long way to go.</p><p>The Pi takes 8s (while consuming ~1As) before the first line of Linux output appears on the console.<br>Luckily, there a number of ways to get more info about those 8 seconds.</p><h4 id="debug-boot">Debug boot<a href="#debug-boot" aria-label="Heading self-link"></a></h4><p>In the boot process of the Raspberry Pi family, the GPU initializes first.<br>It talks to the SD card and looks for a <code>bootcode.bin</code> file (Pi 4 and newer use an EEPROM instead).</p><p>We can modify this bootcode.bin to <a href="https://www.raspberrypi.com/documentation/computers/raspberry-pi.html#bootcode-bin-uart-enable" target="_blank">enable detailed UART logging</a>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>sed -i -e <span>"s/BOOT_UART=0/BOOT_UART=1/"</span> /boot/firmware/bootcode.bin
</span></span></code></pre></div><p><strong>Backup the original bootcode.bin first, this process is potentially destructive.</strong></p><p>Rebooting with <code>BOOT_UART</code> enabled gives us loads of nice information:</p><pre tabindex="0"><code>Raspberry Pi Bootcode

Found SD card, config.txt = 1, start.elf = 1, recovery.elf = 0, timeout = 0
Read File: config.txt, 1322 (bytes)

Raspberry Pi Bootcode
Read File: config.txt, 1322
Read File: start.elf, 2981376 (bytes)
Read File: fixup.dat, 7303 (bytes)
MESS:00:00:01.295242:0: brfs: File read: /mfs/sd/config.txt
MESS:00:00:01.300131:0: brfs: File read: 1322 bytes
MESS:00:00:01.335680:0: HDMI0:EDID error reading EDID block 0 attempt 0
[..]
MESS:00:00:01.392537:0: HDMI0:EDID error reading EDID block 0 attempt 9
MESS:00:00:01.398632:0: HDMI0:EDID giving up on reading EDID block 0
MESS:00:00:01.406335:0: brfs: File read: /mfs/sd/config.txt
MESS:00:00:01.411272:0: gpioman: gpioman_get_pin_num: pin LEDS_PWR_OK not defined
MESS:00:00:01.918176:0: gpioman: gpioman_get_pin_num: pin LEDS_PWR_OK not defined
MESS:00:00:01.923999:0: *** Restart logging
MESS:00:00:01.927872:0: brfs: File read: 1322 bytes
MESS:00:00:01.933328:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 0
[..]
MESS:00:00:01.995436:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 9
MESS:00:00:02.002052:0: hdmi: HDMI0:EDID giving up on reading EDID block 0
MESS:00:00:02.007955:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 0
[..]
MESS:00:00:02.070610:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 9
MESS:00:00:02.077225:0: hdmi: HDMI0:EDID giving up on reading EDID block 0
MESS:00:00:02.082840:0: hdmi: HDMI:hdmi_get_state is deprecated, use hdmi_get_display_state instead
MESS:00:00:02.091586:0: HDMI0: hdmi_pixel_encoding: 162000000
MESS:00:00:02.799203:0: brfs: File read: /mfs/sd/initramfs8
MESS:00:00:02.803082:0: Loaded 'initramfs8' to 0x0 size 0xb0898e
MESS:00:00:02.821799:0: initramfs loaded to 0x1b4e7000 (size 0xb0898e)
MESS:00:00:02.836318:0: dtb_file 'bcm2710-rpi-zero-2-w.dtb'
MESS:00:00:02.840194:0: brfs: File read: 11569550 bytes
MESS:00:00:02.849171:0: brfs: File read: /mfs/sd/bcm2710-rpi-zero-2-w.dtb
MESS:00:00:02.854262:0: Loaded 'bcm2710-rpi-zero-2-w.dtb' to 0x100 size 0x8258
MESS:00:00:02.876038:0: brfs: File read: 33368 bytes
MESS:00:00:02.892755:0: brfs: File read: /mfs/sd/overlays/overlay_map.dtb
MESS:00:00:02.927145:0: brfs: File read: 5255 bytes
MESS:00:00:02.933541:0: brfs: File read: /mfs/sd/config.txt
MESS:00:00:02.937568:0: dtparam: audio=on
MESS:00:00:02.948005:0: brfs: File read: 1322 bytes
MESS:00:00:02.971952:0: brfs: File read: /mfs/sd/overlays/vc4-kms-v3d.dtbo
MESS:00:00:03.023016:0: Loaded overlay 'vc4-kms-v3d'
MESS:00:00:03.026278:0: dtparam: nohdmi=true
MESS:00:00:03.031105:0: dtparam: act_led_trigger=none
MESS:00:00:03.048180:0: dtparam: act_led_activelow=on
MESS:00:00:03.149316:0: brfs: File read: 2760 bytes
MESS:00:00:03.154502:0: brfs: File read: /mfs/sd/cmdline.txt
MESS:00:00:03.158504:0: Read command line from file 'cmdline.txt':
MESS:00:00:03.164369:0: 'console=serial0,115200 console=tty1 root=PARTUUID=26bbce6b-02 rootfstype=ext4 fsck.repair=yes rootwait cfg80211.ieee80211_regdom=DE init=/init.sh'
MESS:00:00:03.195926:0: gpioman: gpioman_get_pin_num: pin EMMC_ENABLE not defined
MESS:00:00:03.269361:0: brfs: File read: 146 bytes
MESS:00:00:03.812401:0: brfs: File read: /mfs/sd/kernel8.img
MESS:00:00:03.816343:0: Loaded 'kernel8.img' to 0x200000 size 0x8d8bd7
MESS:00:00:05.364579:0: Device tree loaded to 0x1b4de900 (size 0x8605)
MESS:00:00:05.370571:0: uart: Set PL011 baud rate to 103448.300000 Hz
MESS:00:00:05.377080:0: uart: Baud rate change done...
MESS:00:00:05.380495:0: uart: Baud rate[    0.000000] Booting Linux on physical CPU 0x0000000000 [0x410fd034]
</code></pre><h3 id="disabling-hdmi-probing">Disabling HDMI probing<a href="#disabling-hdmi-probing" aria-label="Heading self-link"></a></h3><p>The bootloader spends a lot of time trying to auto-detect video parameters for a possibly attached HDMI monitor.<br>We don‚Äôt have HDMI (it‚Äôs disabled anyway, remember?), so it doesn‚Äôt make much sense to wait for an I2C response with EDID (resolution, frame rate, etc.) information.</p><p>By simply hardcoding an EDID string, we can disable any probing:</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># don't try to read HDMI eeprom</span>
</span></span><span><span><span>hdmi_blanking</span><span>=</span><span>2</span>
</span></span><span><span><span>hdmi_ignore_edid</span><span>=</span><span>0xa5000080</span>
</span></span><span><span><span>hdmi_ignore_cec_init</span><span>=</span><span>1</span>
</span></span><span><span><span>hdmi_ignore_cec</span><span>=</span><span>1</span>
</span></span></code></pre></div><h3 id="disable-hat-poe-and-lcd-probing">Disable HAT, PoE and LCD probing<a href="#disable-hat-poe-and-lcd-probing" aria-label="Heading self-link"></a></h3><p>The boot process will additionally try to detect I2C EEPROMs on HATs, will try to detect a PoE hat (which needs a fan) and some other things.
We can safely disable those:</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># all these options cause a wait for an I2C bus response, we don't need any of them, so let's disable them.</span>
</span></span><span><span><span>force_eeprom_read</span><span>=</span><span>0</span>
</span></span><span><span><span>disable_poe_fan</span><span>=</span><span>1</span>
</span></span><span><span><span>ignore_lcd</span><span>=</span><span>1</span>
</span></span><span><span><span>disable_touchscreen</span><span>=</span><span>1</span>
</span></span><span><span><span>disable_fw_kms_setup</span><span>=</span><span>1</span>
</span></span></code></pre></div><h3 id="disable-camera--display-probing">Disable camera &amp; display probing<a href="#disable-camera--display-probing" aria-label="Heading self-link"></a></h3><p>Probing for an attached MIPI camera or display will also take some time.
We know which camera is attached (HQ Camera, IMX477 in this case), so let‚Äôs hardcode this:</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># no autodetection for anything (will wait for I2C answers)</span>
</span></span><span><span><span>camera_auto_detect</span><span>=</span><span>0</span>
</span></span><span><span><span>display_auto_detect</span><span>=</span><span>0</span>
</span></span><span><span>
</span></span><span><span><span># load HQ camera IMX477 sensor manually</span>
</span></span><span><span><span>dtoverlay</span><span>=</span><span>imx477</span>
</span></span></code></pre></div><h3 id="disabling-initramfs">Disabling initramfs<a href="#disabling-initramfs" aria-label="Heading self-link"></a></h3><p>The above changes brought the (self reported) boot time from 5.38s down to 4.75s.<br>We can disable the initramfs entirely by removing <code>auto_initramfs=1</code>.</p><p>Savings depend on the size of the initramfs of course, but this brings us down to 4.47s.</p><h3 id="tested-with-no-significant-difference">Tested, with no significant difference<a href="#tested-with-no-significant-difference" aria-label="Heading self-link"></a></h3><p>Overclocking the SD peripheral to 100 MHz is often recommended online but did not create a measurable difference in boot performance.</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># not recommended! data corruption risk!</span>
</span></span><span><span><span>dtoverlay</span><span>=</span><span>sdtweak,overclock_50=100</span>
</span></span></code></pre></div><p>Operating the SD peripheral at such high speeds also risks data corruption (on write accesses), which is very undesirable in remote IoT devices.</p><h3 id="kernel-load">Kernel load<a href="#kernel-load" aria-label="Heading self-link"></a></h3><p>At this point, loading the kernel is one of the slowest operations:</p><pre tabindex="0"><code>MESS:00:00:03.816343:0: Loaded 'kernel8.img' to 0x200000 size 0x8d8bd7
MESS:00:00:05.364579:0: Device tree loaded to 0x1b4de900 (size 0x8605)
</code></pre><p>Loading 9276375 Bytes takes about 1.54s -&gt; about 6 MiB/s transfer speed.</p><p>This load is being done by the GPU (!) with the internal, proprietary VideoCoreIV processor.<br>It‚Äôs possible that the loader code is just inefficient and slow, it‚Äôs also possible that it is using very conservative settings.<br>Sadly, it‚Äôs a black box and we can‚Äôt touch registers or mess with the parameters in any other useful way.</p><p>I haven‚Äôt found a good way to optimize this yet, so a smaller kernel is needed.</p><p>Overclocking the GPU processor core is theoretically possible with</p><div><pre tabindex="0"><code data-lang="ini"><span><span><span># Overclock GPU VideoCore IV processor (not recommended!)</span>
</span></span><span><span><span>core_freq_min</span><span>=</span><span>500</span>
</span></span><span><span><span>core_freq</span><span>=</span><span>550</span>
</span></span></code></pre></div><p>which does lead to a 20% reduction in kernel load time. The side effects (reliability, etc.) of this are unknown.</p><h3 id="buildroot--custom-kernel">Buildroot / Custom kernel<a href="#buildroot--custom-kernel" aria-label="Heading self-link"></a></h3><p>It‚Äôs time to migrate the system from Raspbian/Debian to a custom built Buildroot distro (especially to get the custom kernel).</p><p>Using buildroot 2024.02.1, a very stripped down system was configured.<br>Native aarch64 toolchain, still with full glibc and the Raspberry Pi userland tools (like camera utilities).</p><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/buildroot-menuconfig.png" alt="Buildroot ncurses menuconfig screenshot"></p><p>The kernel was configured:</p><ul><li>without sound support</li><li>without most of the block device &amp; filesystem drivers (except SD/MMC and ext4)</li><li>without RAID support</li><li>without USB support</li><li>without HID support</li><li>without DVB support</li><li>without video &amp; framebuffer support (HDMI is disabled anyway)</li><li>without advanced networking features (tunnels, bridging, firewalling, etc.)</li><li>uncompressed (not Gzip)</li><li>modules uncompressed (not Gzip)</li></ul><p>In testing, having both the kernel and the modules uncompressed results in a net-positive energy result (even if more time is spent in the GPU loading the kernel).
Decompressing Gzip takes a lot of energy (and effectively involves another relocation step).</p><p>A security feature called KASLR was also disabled.<br>KASLR randomizes the load address of the kernel in memory, making it harder to write exploit code (because the memory location of the kernel is unknown).
This requires the kernel to be re-located after it has been loaded by the GPU.</p><p>In our usecase, the network attack surface is very limited, so KASLR can be disabled (all application software runs as root anyway).
Mitigations for speculative execution vulnurabilies like Spectre were also disabled.</p><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/buildroot-linux-menuconfig.png" alt="Linux 6.6.26 menuconfig screenshot"></p><p>The resulting kernel is 8.5MiB (uncompressed) in size, 4.1MiB compressed as Gzip (which isn‚Äôt used here, just for comparison).<br>The original Raspbian kernel was 25 MiB (uncompressed), 8.9 MiB compressed as Gzip.</p><h3 id="final-result">Final result<a href="#final-result" aria-label="Heading self-link"></a></h3><p><img src="https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/buildroot-kernel.png" alt="Power Profiler screenshot, showing GPIO4 going low after 3.4s"></p><p><strong>We can now boot into a Linux user space program in less than 3.5s!</strong><br>~400ms is spent in the Linux kernel (difference between pin 0 and pin 1)</p><p>Total energy consumption: <strong>0.364 As * 5.0 V = 1.82 Ws</strong><br>We reduced the energy required by a factor of 5 (compared to stock Debian at 9.5 Ws until user space).</p><h3 id="links">Links<a href="#links" aria-label="Heading self-link"></a></h3><ul><li><a href="https://github.com/Manawyrm/SolarCamPi-Buildroot/blob/v2/buildroot/board/raspberrypi0w/config.txt" target="_blank">SolarCamPi config.txt</a>: Complete config.txt</li><li><a href="https://github.com/Manawyrm/SolarCamPi-Buildroot/blob/v2/buildroot/configs/linux_solarcampi_defconfig" target="_blank">SolarCamPi Linux kernel defconfig</a>: Stripped down kernel config</li><li><a href="https://github.com/Manawyrm/SolarCamPi-Buildroot/tree/v2" target="_blank">SolarCamPi-Buildroot (v2 branch)</a>: Full Buildroot tree (work-in-progress!)</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Americans' love affair with big cars is killing them (210 pts)]]></title>
            <link>https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them</link>
            <guid>41418562</guid>
            <pubDate>Sun, 01 Sep 2024 17:18:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them">https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them</a>, See on <a href="https://news.ycombinator.com/item?id=41418562">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>    <main>   <div><p><body-text><!-- HTML_TAG_START --><span data-caps="initial">W</span><small>itnesses said</small> the driver showed no signs of slowing down. On June 3rd Nicole Louthain and her six-year-old daughter were stopped at a red light in Grand Forks, North Dakota when they were struck from behind by Travis Bell. Such crashes are not uncommon‚Äîaround 10,000 rear-end collisions occur in America every day. What made this one noteworthy was that the vehicles involved were so unevenly matched. Ms Louthain was driving a Ford Focus, a compact car weighing around 3,000lb (1,360kg), whereas Mr Bell was in a 7,000lb Ram 3500 ‚Äúheavy duty‚Äù pickup. Alas, the disparity proved deadly. Although Mr Bell was not harmed, Ms Louthain suffered serious injuries. (Court documents later showed that Mr Bell had been drinking.) Her daughter Katarina was air-lifted to a nearby hospital where she died two days later.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->The crash in Grand Forks helps to illustrate a sad truth about America‚Äôs roads. For all the safety features available in cars today to help them avoid crashes, when they happen they are still often determined by the laws of physics. When two vehicles collide, it is usually the heavier one that prevails. This advantage has changed little over time. Thirty years ago when a passenger car crashed with a <a href="https://www.economist.com/united-states/2023/04/20/rural-americans-are-importing-tiny-japanese-pickup-trucks">pickup truck</a> or sport-utility vehicle (<small>SUV</small>), the driver of the car was roughly four times as likely to die; today this driver dies around three times as often. Critics say this is too high a price to pay for roomier interiors and more powerful engines. Carmakers insist they are giving consumers what they want. An analysis by <i>The Economist</i> shows that weight remains a critical factor in car crashes in America. Reining in <a href="https://www.economist.com/the-economist-explains/2024/03/11/why-american-cars-are-so-big">the heaviest vehicles</a> would save lives.<!-- HTML_TAG_END --> </body-text> </p> </div> <figure><ai2sveltewrap> </ai2sveltewrap>  </figure><div><p><body-text><!-- HTML_TAG_START -->Mismatches between big and small cars on America‚Äôs roads are not new. In the 1960s the 1,400lb Mini Cooper shared the road with the 5,000lb Cadillac Fleetwood and the 5,500lb Lincoln Continental. But whereas today heavier vehicles attract the bulk of the criticism, back then it was lighter ones that drew scrutiny. Indeed many cars of the time were woefully unsafe. In 1969 America‚Äôs National Highway Safety Bureau conducted crash tests on a Subaru 360 and a King Midget, two sub-1,000lb ‚Äúmini-cars‚Äù. When pitted against vehicles twice their size, the tiny cars crumpled like soda cans.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Over the years policymakers struggled to solve this mismatch, or ‚Äúincompatibility‚Äù, problem. Often, they made things worse. When Congress set fuel-efficiency standards in the wake of the oil shocks of the 1970s, cars were swiftly downsized. Within ten years cars shed 1,000lb; trucks dropped 500lb. Although these changes saved motorists money at the pump, they also led to more traffic fatalities. A paper published in 1989 by researchers at the Brookings Institution and the Harvard School of Public Health estimated that the shift towards smaller, lighter cars in the 1970s and 1980s boosted fatalities by 14-27%. A report released in 2002 by America‚Äôs National Research Council concluded that the downsizing of America‚Äôs fleet led to thousands of unnecessary deaths.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->As cars got bigger, regulators shifted their focus from the lightest vehicles to the heaviest ones. The impetus for this was the rise of <small>SUV</small>s. Between 1990 and 2005 the market share of such vehicles in America grew from 6% to 26%, pushing up the weight of an average new car from 3,400lb to nearly 4,100lb. As suburban soccer moms traded in their station wagons for Ford Expeditions, many felt safer. And they were right. ‚ÄúOne of the reasons the roads are much safer is because vehicles... [are] bigger and they‚Äôre heavier than they were,‚Äù Adrian Lund of the Insurance Institute for Highway Safety (<small>IIHS</small>), an industry research organisation, told conference-goers in 2011. The Competitive Enterprise Institute, a think-tank, even advocated supersizing America‚Äôs fleet to improve safety, writing in the <i>Wall Street Journal</i> that large vehicles are ‚Äúthe solution, not the problem‚Äù.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->But researchers quickly learned that the extra protection provided by heavier vehicles comes at the expense of others on the road. In a paper published in 2004 Michelle White of the University of California, San Diego estimated that for every deadly crash avoided by an <small>SUV</small> or pickup truck, there were an additional 4.3 among other drivers, pedestrians and cyclists. Another paper in 2012 by Shanjun Li of Resources for the Future, a think-tank, estimated that when a car crashes with an <small>SUV</small> or pickup, rather than another car, the driver‚Äôs fatality rate increased by 31%. In 2014 Michael Anderson and Maximilian Auffhammer of the University of California, Berkeley estimated that when two cars crash, a 1,000lb increase in the weight of one vehicle raised the fatality rate in the other by 47%.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Researchers also found that the safety benefits of vehicle weight suffer from diminishing returns. This means that, once vehicles reach a certain weight, packing on more pounds provides little additional safety, while inflicting more harm on others. ‚ÄúAt some point heavy vehicles cost more lives‚Ä¶than they save,‚Äù wrote Brian O‚ÄôNeill and Sergey Kyrychenko of the <small>IIHS</small> in 2004. This makes intuitive sense, says Mr Anderson of Berkeley. ‚ÄúOnce you outweigh the other guy by a factor of two times, is adding 200 pounds more really going to make a difference for you? Probably not. But it‚Äôll make sure that he gets completely destroyed.‚Äù<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->So how big is too big? At what point do the costs of the heaviest vehicles‚Äîmeasured in lives lost‚Äîvastly exceed their benefits? To answer this question, <i>The Economist</i> compiled ten years‚Äô worth of crash data from more than a dozen states. Like the data compiled by Messrs Anderson and Auffhammer, our figures come from reports filed by police officers, who are tasked with recording information about car crashes when called to the scene. Although all states collect such data, we focus on those that collect the most detailed figures and share them with researchers. The resulting dataset, which covers more than a third of America‚Äôs population, provides us with a sample that is both big and representative.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->In total, our dataset includes millions of crashes across 14 states between 2013 and 2023. Although accident reports vary from state to state, most of the crashes in our database include information about the location of the crash, the number of cars involved, each passenger‚Äôs age and gender, whether they were wearing seatbelts and the types of injuries that they suffered. To obtain the curb weight of each vehicle, we collected the vehicle identification numbers (<small>VINs</small>) included in each crash report, and then matched them to vehicle specs data from VinAudit, an auto-data provider. Combining these data yielded roughly 10m crashes. After dropping observations with missing data, we were left with around 7.5m two-vehicle crashes involving more than 15m cars.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->What do these data tell us about the relationship between vehicle weight and road safety?<!-- HTML_TAG_END --> </body-text> </p> </div> <div><p><body-text><!-- HTML_TAG_START -->The heaviest 1% of vehicles in our dataset‚Äîthose weighing around 6,800lb‚Äîsuffer 4.1 ‚Äúown-car deaths‚Äù per 10,000 crashes, on average, compared with around 6.6 for cars in the middle of our sample weighing 3,500lb, and 15.8 for the lightest 1% of vehicles weighing just 2,300lb. But heavy cars are also far more dangerous to other drivers. The heaviest vehicles in our data were responsible for 37 ‚Äúpartner-car deaths‚Äù per 10,000 crashes, on average, compared with 5.7 for median-weight cars and 2.6 for the lightest cars.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->To estimate this relationship more precisely, and control for potential sources of bias, we conducted a regression analysis of our sample of 7.5m two-vehicle crashes. We found that getting into a crash with a vehicle that is 1,000lb heavier is associated with a 0.06-percentage-point increase in the probability of suffering a fatality, even after controlling for the curb weight of one‚Äôs own car, the age and gender of the driver, the population density of the crash location and whether the passengers were wearing seatbelts. Given that the probability of suffering a fatality in a two-vehicle crash is 0.09%, on average, this suggests that getting hit by an additional 1,000lbs of steel and aluminium‚Äîroughly the difference between a Toyota Camry and a Ford Explorer‚Äîboosts the likelihood of death by 66%.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->As for the weight at which the social costs of driving a heavier vehicle exceed the benefits, the evidence is clear. Vehicles in the top 10% of our sample‚Äîthose weighing at least 5,000lb‚Äîare involved in roughly 26 deaths per 10,000 crashes, on average, including 5.9 in their own car and 20.2 in partner vehicles. For vehicles in the next-heaviest 10% of our sample‚Äîthose weighing between 4,500lb and 5,000lb‚Äîthe equivalent figures are 5.4 and 10.3 deaths per 10,000 crashes. A back-of-the-envelope estimate suggests that if the heaviest tenth of vehicles in America‚Äôs fleet were downsized to this lighter weight class, road fatalities in multi-car crashes‚Äîwhich totaled 19,081 in 2023‚Äîcould be reduced by 12%, or 2,300, without sacrificing the safety of any cars involved.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Given these figures, you might expect carmakers to be slamming the brakes on production of their heaviest <small>SUV</small>s and pickups. In fact, they are pressing on the accelerator. Official figures from the Environmental Protection Agency show that the average new car in America weighs more than 4,400lb (compared with 3,300lb in the European Union and 2,600lb in Japan). In 2023 vehicles weighing more than 5,000lb accounted for a whopping 31% of new cars, up from 22% five years earlier.<!-- HTML_TAG_END --> </body-text> </p> </div> <figure><ai2sveltewrap> </ai2sveltewrap>  </figure><div><p><body-text><!-- HTML_TAG_START -->It would be easy to blame car-buyers for this trend but Mr Anderson says that Americans looking for a new car face a cold-war-style ‚Äúarms race‚Äù. ‚ÄúAs you see the vehicle fleet around you getting heavier, then you want to protect yourself rationally by buying a bigger and heavier car.‚Äù Such rational individual decisions have led to a suboptimal outcome for society as a whole.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->When asked to comment on <i>The Economist</i>‚Äôs findings, representatives from the big three car manufacturers pointed to safety features that help drivers avoid crashes, rather than those that make them less deadly. ‚ÄúVehicle weight doesn‚Äôt solely determine crash performance,‚Äù Mike Levine, a Ford spokesman, wrote in an email, highlighting crash-avoidance technologies such as automatic emergency braking and front and rear ‚Äúbrake assist‚Äù. General Motors pointed out that carmakers have improved the compatibility of their vehicles over the years, citing a voluntary deal struck by manufacturers in 2003, more than twenty years ago. Stellantis (whose biggest shareholder part-owns <i>The Economist</i>‚Äôs parent company) declined to comment except to say that the company‚Äôs vehicles ‚Äúmeet or exceed all applicable federal safety standards‚Äù.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Regulators are ill-equipped to fix the problem. America‚Äôs tax system subsidises heavier vehicles by setting more lenient fuel-efficiency standards for light trucks, and allowing bosses who purchase heavy-duty vehicles for business purposes to deduct part of the cost from their taxable income. The National Highway Traffic Safety Administration (<small>NHTSA</small>), America‚Äôs top auto-safety agency, uses a five-star rating system to score crash performance, but only takes account of the safety of the occupants of the vehicle in question, not that of other drivers. ‚ÄúOur rating system reflects a bias towards the occupant,‚Äù explains Laura Sandt of the Highway Safety Research Centre at the University of North Carolina, ‚Äúit is not designed to rate the car in terms of its holistic safety effects.‚Äù The <small>NHTSA</small> declined to comment on <i>The Economist</i>‚Äôs findings.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->There are signs that Americans may be wising up. A survey conducted last year by YouGov, a pollster, found that 41% of Americans think that <small>SUV</small>s and pickup trucks have become too big; 49% said such vehicles are more dangerous for other cars and 50% said they endanger cyclists and pedestrians. Researchers are raising the alarm. Since 1989 the <small>IIHS</small> has regularly published the driver-fatality rates of popular car models. In 2023, for the first time, the group also estimated the rate at which cars kill drivers in other vehicles. Policymakers are starting to take notice too. ‚ÄúI‚Äôm concerned about the increased risk of severe injury and death for all road users from heavier curb weights,‚Äù Jennifer Homendy, chair of the National Transportation Safety Board, said in a speech last year.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->But the odds that carmakers curb their heaviest, most dangerous vehicles are slim. American car-buyers value safety, but mainly for themselves, not society as a whole. And although regulators are tasked with protecting consumers, they rarely do so at the expense of choice, no matter how deadly the consequences. ‚ÄúThere may be a certain point where you say, ‚ÄòYou know what, passenger vehicles shouldn't be weighing this much,‚Äô‚Äù says Raul Arbelaez of the <small>IIHS</small>‚Äôs Vehicle Research Centre. ‚ÄúBut it would, politically, be really hard to gain any momentum on that.‚Äù Finally the shift towards <a href="https://www.economist.com/business/2024/04/07/think-tesla-is-in-trouble-pity-even-more-its-wannabe-ev-rivals">electric power</a> is likely to increase their weight further, as battery-powered vehicles tend to be heavier than their internal-combustion equivalents.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->‚ÄúManufacturers are playing by the book,‚Äù says Mark Chung of the National Safety Council, a non-profit. ‚ÄúThey‚Äôre making a business decision, and it‚Äôs a rational decision. Unless they‚Äôre forced to think differently, they‚Äôre not going to. So I think this is where our federal partners really need to step up.‚Äù<span data-ornament="ufinish">‚ñ†</span><!-- HTML_TAG_END --> </body-text> </p> </div><div><p>Sources: </p><body-text><!-- HTML_TAG_START -->State governments; VinAudit; <i>The Economist</i><!-- HTML_TAG_END --> </body-text> </div>  </main>  
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple and Nvidia in talks to invest in ChatGPT (123 pts)]]></title>
            <link>https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</link>
            <guid>41418302</guid>
            <pubDate>Sun, 01 Sep 2024 16:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30">https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</a>, See on <a href="https://news.ycombinator.com/item?id=41418302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="descriptionStoryId"><p>Apple and Nvidia are reportedly in talks to invest in OpenAI, the company behind ChatGPT, as part of a new fundraising round. This round could potentially value OpenAI at over $100 billion, according to media reports.</p>

<p>The Wall Street Journal reported that Apple is exploring the possibility of joining the funding round, while Bloomberg News indicated Nvidia‚Äôs potential involvement. This comes after news that Thrive Capital, a venture capital firm, is planning to invest around $1 billion in OpenAI, leading the current fundraising efforts.</p><div><h4>Related Articles</h4><div><ul><li><a target="_blank" title="OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation" href="https://www.businesstoday.in/technology/news/story/openai-launches-fine-tuning-for-gpt-4o-unlocking-enhanced-performance-and-customisation-442518-2024-08-22">OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation</a></li><li><a target="_blank" title="Ex-Google CEO thinks company's ‚Äòwork-life balance‚Äô mentality is why it is losing AI race to startups like OpenAI" href="https://www.businesstoday.in/technology/news/story/ex-google-ceo-thinks-companys-work-life-balance-mentality-is-why-it-is-losing-ai-race-to-startups-like-openai-441535-2024-08-14">Ex-Google CEO thinks company's ‚Äòwork-life balance‚Äô mentality is why it is losing AI race to startups like OpenAI</a></li></ul></div></div>

<p>OpenAI has become increasingly integral to Apple‚Äôs AI strategy. In June, Apple introduced OpenAI‚Äôs chatbot, ChatGPT, to its devices under the initiative called ‚ÄúApple Intelligence.‚Äù Additionally, Apple is reportedly set to gain an observer role on OpenAI‚Äôs board, highlighting the deepening relationship between the two companies.</p>

<p>Microsoft, OpenAI‚Äôs largest investor with over $10 billion already committed, is also expected to participate in this new funding round. However, the specific amounts that Apple, Nvidia, and Microsoft are planning to invest have not been disclosed.</p>

<p>OpenAI‚Äôs rising valuation is a result of the intense competition in the AI sector, which intensified after the launch of ChatGPT in late 2022. This launch spurred companies across various industries to pour billions into AI technology to stay competitive. Earlier this year, OpenAI was valued at $80 billion following a tender offer led by Thrive Capital, where the firm sold existing shares.<br>
&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Pentium as a Navajo Weaving (112 pts)]]></title>
            <link>https://www.righto.com/2024/08/pentium-navajo-fairchild-shiprock.html</link>
            <guid>41418301</guid>
            <pubDate>Sun, 01 Sep 2024 16:46:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2024/08/pentium-navajo-fairchild-shiprock.html">https://www.righto.com/2024/08/pentium-navajo-fairchild-shiprock.html</a>, See on <a href="https://news.ycombinator.com/item?id=41418301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1847189222202375114" itemprop="description articleBody">
<p>Hurrying through the National Gallery of Art five minutes before closing, I passed a Navajo weaving with a complex abstract
pattern.
Suddenly, I realized the pattern was strangely familiar, so I stopped and looked closely.
The design turned out to be an image of Intel's Pentium chip, the start of the long-lived Pentium family.<span id="fnref:pentium"><a href="#fn:pentium">1</a></span>
The weaver, Marilou Schultz, created the artwork in 1994 using traditional materials and techniques.
The rug was commissioned by Intel as a gift to <a href="https://archive.org/details/ERIC_ED409127/page/n2/mode/1up">AISES</a> (American Indian Science &amp; Engineering Society) and
is currently part of an art exhibition‚Äî<a href="https://www.nga.gov/exhibitions/2024/woven-histories-textiles-modern-abstraction.html">Woven Histories: Textiles and Modern Abstraction</a>‚Äîfocusing on the intersection between abstract art and woven textiles.</p>
<p><a href="https://static.righto.com/images/pentium-rug/pentium-rug.jpg"><img alt="&quot;Replica of a Chip&quot;, created by Marilou Schultz, 1994. Wool. Photo taken at the National Gallery of Art, 2024." height="560" src="https://static.righto.com/images/pentium-rug/pentium-rug-w500.jpg" title="&quot;Replica of a Chip&quot;, created by Marilou Schultz, 1994. Wool. Photo taken at the National Gallery of Art, 2024." width="500"></a></p><p>"Replica of a Chip", created by Marilou Schultz, 1994. Wool. Photo taken at the National Gallery of Art, 2024.</p>
<p>I talked with Marilou Schultz, a Navajo/Din√© weaver and math teacher, to learn more about the artwork.
Schultz learned weaving as a child‚Äîpart of four generations of weavers‚Äîcarding the wool, spinning it into yarn, and then weaving it.
For the Intel project, she worked from a photograph of the die, marking it into 64 sections along each side so the die pattern could be
accurately transferred to the weaving.
Schultz used the "raised outline" technique, which gives a three-dimensional effect along borders.
One of the interesting characteristics of the Pentium from the weaving perspective is its lack of symmetry, unlike traditional rugs.
The Pentium weaving was colored with traditional plant dyes;
the cream regions are the natural color of the
wool from the long-horned Navajo-Churro sheep.<span id="fnref:sheep"><a href="#fn:sheep">2</a></span>
The yarn in the weaving is a bit finer than the yarn typically used for knitting.
Weaving was a slow process, with a day's work extending the rug by 1" to 1.5".</p>
<p>The Pentium die photo below shows the patterns and structures on the surface of the fingernail-sized silicon die, over
three million tiny transistors.
The weaving is a remarkably accurate representation of the die,
reproducing the processor's complex designs.
However, I noticed that the weaving was a mirror image of the physical Pentium die; I had to flip the rug image below to make them match.
I asked Ms. Schultz if this was an artistic decision and she explained that she wove the rug to match the photograph.
There is no specific front or back to a Navajo weaving because the design is similar on both sides,<span id="fnref:sides"><a href="#fn:sides">3</a></span>
so the gallery picked an arbitrary side to display.
Unfortunately, they picked the wrong side, resulting in a backward die image. This probably bothers nobody but me, but I
hope the gallery will correct this in future exhibits.
For the remainder of this article, I will mirror the rug to match the physical die.</p>
<p><a href="https://static.righto.com/images/pentium-rug/comparison.jpg"><img alt="Comparison of the Pentium weaving (flipped vertically) with a Pentium die photo. Original die photo from Intel." height="330" src="https://static.righto.com/images/pentium-rug/comparison-w600.jpg" title="Comparison of the Pentium weaving (flipped vertically) with a Pentium die photo. Original die photo from Intel." width="600"></a></p><p>Comparison of the Pentium weaving (flipped vertically) with a Pentium die photo. Original die photo from <a href="https://en.wikichip.org/wiki/File:pentium_die_shot.png">Intel</a>.</p>
<p>The rug is accurate enough that each region can be marked with its corresponding function in the real chip, as shown below.
Starting in the center, the section labeled "integer execution units" is the heart of the processor, performing
arithmetic operations and other functions on integer numbers.
The Pentium is a 32-bit processor, so the integer execution unit is a vertical rectangle, 32 bits wide.
The horizontal lines correspond to different types of circuitry such as adders, multipliers, shifters, and registers.
To the right, the "floating point unit" performs more complex arithmetic operations on floating-point numbers, 
numbers with a fractional part that are used in applications such as spreadsheets and CAD drawings.
Like the integer execution unit, the floating point unit has horizontal stripes corresponding to different functions.
Floating-point numbers are represented with more bits, so the stripes are wider.</p>
<p><a href="https://static.righto.com/images/pentium-rug/p54c-rug-floorplan2.jpg"><img alt="The Pentium weaving, flipped and marked with the chip floorplan." height="640" src="https://static.righto.com/images/pentium-rug/p54c-rug-floorplan2-w600.jpg" title="The Pentium weaving, flipped and marked with the chip floorplan." width="600"></a></p><p>The Pentium weaving, flipped and marked with the chip floorplan.</p>
<p>At the top, the "instruction fetch" section fetches the machine instructions that make up the software.
The "instruction decode" section analyzes each instruction to determine what operations to perform.
Simple operations, such as addition, are performed directly by the integer execution unit.
Complicated instructions (a hallmark of Intel's processors) are broken down into
smaller steps by the "complex instruction support" circuitry, with the steps held in the "microcode ROM".
The "branch prediction logic" improves performance when the processor must make a decision for a branch instruction.</p>
<p>The code and data caches provide a substantial performance boost.
The problem is that the processor is considerably faster than the computer's RAM memory, so the processor can end up sitting idle until program
code or data is provided by memory.
The solution is the cache, a small, fast memory that holds bytes that the processor is likely to need.
The Pentium processor had a small cache by modern standards, holding 8 kilobytes of code and 8 kilobytes of data.
(In comparison, modern processors have multiple caches, with hundreds of kilobytes in the fastest cache and megabytes in a slower
cache.)
Cache memories are built from an array of memory storage elements in a structured grid,
visible in the rug as uniform pink rectangles.
The TLB (Translation Lookaside Buffer) assists the cache.
Finally, the "bus interface logic" connects the processor to the computer's bus, providing access to memory and peripheral
devices.
Around the edges of the physical chip, tiny bond pads provide the connections between the silicon chip and the integrated circuit package.
In the weaving, these tiny pads have been abstracted into small black rectangles.</p>
<p>The weaving is accurate enough to determine that it represents a specific Pentium variant, called P54C.
The motivation for the P54C was that
the original Pentium chips (called P5) were not as fast as hoped and ran hot.
Intel fixed this by using a more advanced manufacturing process, reducing the feature size from 800 to 600 nanometers
and running the chip at 3.3 volts instead of 5 volts.
Intel also modified the chip so that when parts of the chip were idle, the clock signal could be stopped to
save power. (This is the "clock driver" circuitry at the top of the weaving.)
Finally, Intel added multiprocessor logic (adding 200,000 more transistors), allowing two processors to work together more
easily. 
The improved Pentium chip was smaller, faster, and used less power. This variant was called the P54C (for reasons I haven't
been able to determine).
The "multiprocessor logic" is visible in the Pentium rug, showing that it is the P54C Pentium (right) and not the P5 Pentium (left).</p>
<p><a href="https://static.righto.com/images/pentium-rug/pentiums.jpg"><img alt="The Pentium P5 on the left and the P54C on the right, showing the difference in die and package sizes. If you look closely, the P5 die on the left lacks the &quot;multiprocessor logic&quot; in the weaving, showing that the weaving is the P54C. I clipped the pins on the P5 to fit it under a microscope." height="270" src="https://static.righto.com/images/pentium-rug/pentiums-w600.jpg" title="The Pentium P5 on the left and the P54C on the right, showing the difference in die and package sizes. If you look closely, the P5 die on the left lacks the &quot;multiprocessor logic&quot; in the weaving, showing that the weaving is the P54C. I clipped the pins on the P5 to fit it under a microscope." width="600"></a></p><p>The Pentium P5 on the left and the P54C on the right, showing the difference in die and package sizes. If you look closely, the P5 die on the left lacks the "multiprocessor logic" in the weaving, showing that the weaving is the P54C. I clipped the pins on the P5 to fit it under a microscope.</p>
<p>Intel's connection with New Mexico started in 1980 when Intel opened a chip fabrication plant (fab) in Rio Rancho, a suburb north of Albuquerque.
At the time, this plant, Fab 7, was Intel's largest and produced <a href="https://archive.org/details/intelinsidenewme0000unse/page/11/mode/1up">70%</a> of Intel's profits.
Intel steadily grew the New Mexico facility, adding Fab 9 and then Fab 11, which <a href="https://www.nytimes.com/1995/12/03/business/suiting-up-for-america-s-high-tech-future.html">opened</a> in September 1995, building Pentium and Pentium Pro chips in a <a href="https://www.nytimes.com/1995/12/03/business/suiting-up-for-america-s-high-tech-future.html">140-step</a> manufacturing process.
Intel's investment in Rio Rancho has continued with a $4 billion project <a href="https://www.intel.com/content/www/us/en/newsroom/news/updates-intel-10-largest-construction-projects.html#gs.di125l">underway</a> for Fab 9 and Fab 11x.
Intel has been criticized for environmental issues in New Mexico, detailed in the book
<a href="https://archive.org/details/intelinsidenewme0000unse">Intel inside New Mexico: A case study of environmental and economic injustice</a>.
Intel, however, claims a <a href="https://download.intel.com/newsroom/2024/manufacturing/Intel-in-NM-Sustainability-Fact-Sheet.pdf">sustainable future</a> in New Mexico, restoring watersheds, using 100% renewable electricity, and recycling construction waste.</p>
<!--
Intel has continued to support Native American communities through scholarships and the [Next Generation of Native
American Coders program](https://woc.aises.org/content/intel-and-aises-history-engagement).
-->

<h2>Fairchild and Shiprock</h2>
<p>Marilou Schultz is currently creating another weaving based on an integrated circuit, shown below.
Although this chip, the Fairchild 9040, 
is much more obscure than the Pentium, it has important historical symbolism,
as it was built by Navajo workers at a plant on Navajo land.</p>
<p><a href="https://static.righto.com/images/pentium-rug/fairchild-rug.jpg"><img alt="Marilou Schultz's current weaving project. Photo provided by the artist." height="558" src="https://static.righto.com/images/pentium-rug/fairchild-rug-w400.jpg" title="Marilou Schultz's current weaving project. Photo provided by the artist." width="400"></a></p><p>Marilou Schultz's current weaving project. Photo provided by the artist.</p>
<p>In 1965, Fairchild started producing semiconductors in Shiprock, New Mexico, 
about 200 miles northwest of Intel's future facility.
Fairchild produced a <a href="https://archive.computerhistory.org/resources/access/text/2017/01/102770254-05-01-acc.pdf">brochure</a> in 1969 to commemorate the opening of a new plant. Two of the photos in that brochure compared a traditional Navajo weaving to the pattern of a chip, which happened to be the 9040.
Although Fairchild's Shiprock project started optimistically, it was suddenly
shut down a decade later after an armed takeover.
I'll discuss the complicated history of Fairchild in Shiprock and then describe the 9040 chip in more detail.</p>
<p><a href="https://static.righto.com/images/pentium-rug/rug-ic.jpg"><img alt="A Navajo rug and the die of a Fairchild 9040 integrated circuit. Images from Fairchild's commemorative brochure on the opening of a new plant at Shiprock." height="347" src="https://static.righto.com/images/pentium-rug/rug-ic-w600.jpg" title="A Navajo rug and the die of a Fairchild 9040 integrated circuit. Images from Fairchild's commemorative brochure on the opening of a new plant at Shiprock." width="600"></a></p><p>A Navajo rug and the die of a Fairchild 9040 integrated circuit. Images from Fairchild's <a href="https://archive.computerhistory.org/resources/access/text/2017/01/102770254-05-01-acc.pdf">commemorative brochure</a> on the opening of a new plant at Shiprock.</p>
<p>The story of Fairchild starts with William Shockley, who invented the junction transistor at Bell Labs, won the Nobel prize, and founded
Shockley Semiconductor Laboratory in 1957 to build transistors.
Unfortunately, although Shockley was brilliant,
he was said to be <a href="https://www.npr.org/2006/07/21/5573656/electronics-pioneer-william-shockleys-legacy">the worst manager in the history of electronics</a>, not to mention a notorious eugenicist and racist later in life.
Eight of his top employees‚Äîcalled the "traitorous eight"‚Äîleft Shockley's company in 1957 to found Fairchild Semiconductor.
(The traitorous eight included Gordon Moore and Robert Noyce who ended up founding Intel in 1968).
Noyce (co-)invented the integrated circuit in 1959 and Fairchild soon became a top semiconductor manufacturer, famous
for its foundational role in Silicon Valley.</p>
<p>The Shiprock project was part of an attempt in the 1960s to improve the economic situation of the Navajo through industrial development.
The Navajo had suffered a century of oppression including forced deportation from their land through the Long Walk (1864-1866).
The Navajo were suffering from 65% unemployment, a per-capita income of $300, and a lack
of basics such as roads, electricity, running water, and health care.
The Bureau of Indian Affairs was now trying to encourage economic
self-sufficiency by funding industrial projects on Indian land.<span id="fnref:economy"><a href="#fn:economy">4</a></span>
Navajo Tribal Chairman Raymond Nakai viewed industrialization as the only answer.
Called "<a href="https://books.google.com/books?id=aP4QyAXsnmkC&amp;lpg=PP1&amp;pg=PA228#v=onepage&amp;q&amp;f=false">the first modern Navajo political leader</a>", Nakai <a href="https://books.google.com/books?id=0y-8OOtshbAC&amp;pg=PA7#v=onepage&amp;q&amp;f=false">stated</a>,
"There are some would-be leaders of the tribe calling for the banishment of industry from the reservation and a return to the life of a century ago! But, it would not solve the problems. There is not sufficient grazing land on the reservation to support the population so industry must be brought in."
Finally, Fairchild was trying to escape the high cost of Silicon Valley labor by opening plants in low-cost locations such as Maine, Australia, and Hong Kong. <!-- https://archive.computerhistory.org/resources/access/text/2017/03/102770842-05-01-acc.pdf --></p>
<p>These factors led 
Fairchild to open a manufacturing facility on Navajo land in Shiprock, New Mexico.
The project started in 1965 with 50 Navajo workers in the Shiprock Community Center manufacturing transistors,
rapidly increasing to <a href="https://www.bia.gov/as-ia/opa/online-press-release/electronics-industry-expanding-navajo-reservation">366 Navajo workers</a>.</p>
<p><a href="https://static.righto.com/images/pentium-rug/shiprock.jpg"><img alt="Fairchild's manufacturing plant in Shiprock, NM, named after the Shiprock rock formation in the background. The formation is called Ts√© Bit ºa º√≠ in Navajo.
    From The Industrialization of a 'Sleeping Giant', Commerce Today, January 25, 1971." height="283" src="https://static.righto.com/images/pentium-rug/shiprock-w500.jpg" title="Fairchild's manufacturing plant in Shiprock, NM, named after the Shiprock rock formation in the background. The formation is called Ts√© Bit ºa º√≠ in Navajo.
    From The Industrialization of a 'Sleeping Giant', Commerce Today, January 25, 1971." width="500"></a></p><p>Fairchild's manufacturing plant in Shiprock, NM, named after the Shiprock rock formation in the background. The formation is called <i>Ts√© Bit ºa º√≠</i> in Navajo.
    From <a href="https://books.google.com/books?id=GddHAQAAIAAJ&amp;newbks=1&amp;newbks_redir=0&amp;pg=RA7-PA17#v=onepage&amp;q&amp;f=false">The Industrialization of a 'Sleeping Giant'</a>, Commerce Today, January 25, 1971.</p>
<p>By 1967, Robert Noyce, group vice-president of Fairchild, regarded the Shiprock plant as successful.
He <a href="https://bitsavers.org/magazines/Computers_And_Automation/196704.pdf">explained</a> that Fairchild
was motivated both by low labor costs and by social benefits, saying, "Probably nobody would
ever admit it, but I feel sure the Indians are the most underprivileged ethnic group in the United States."
Two years later, Lester Hogan, Fairchild's president,
<a href="https://www.worldradiohistory.com/Archive-Electronics/60s/69/Electronics-1969-03-17.pdf#page=55">stated</a>,
"I thought the Shiprock plant was one of Bob Noyce's philanthropies until I went there," but he was so impressed that
he decided to expand the plant.
Hogan also directed Fairchild to help build hundreds of houses for workers; since a traditional Navajo dwelling is called a hogan,
the houses were dubbed <a href="https://archive.computerhistory.org/resources/access/text/2021/08/102710155-05-01-acc.pdf">Hogan's hogans</a>.</p>
<p><a href="https://static.righto.com/images/pentium-rug/102785007-03-15-acc.jpg"><img alt="Workers in Fairchild's Shiprock plan, 1966. Photo by Jack Grimes. Photo courtesy of Computer History Museum, Henry Mahler collection of Fairchild Semiconductor photographs." height="399" src="https://static.righto.com/images/pentium-rug/102785007-03-15-acc-w500.jpg" title="Workers in Fairchild's Shiprock plan, 1966. Photo by Jack Grimes. Photo courtesy of Computer History Museum, Henry Mahler collection of Fairchild Semiconductor photographs." width="500"></a></p>
<p>In 1969, Fairchild opened its new facility at Shiprock and produced the <a href="https://www.computerhistory.org/collections/catalog/102770254">commemorative brochure</a> mentioned earlier.
As well as showing the striking visual similarity between the designs of traditional Navajo weavings and modern integrated circuits,
it stated that "Weaving, like all Navajo arts, is done with unique imagination and craftsmanship" and described
the "blending of innate Navajo skill and [Fairchild] Semiconductor's precision assembly techniques."
Fairchild later said that "rug weaving, for instance, provides an inherent
ability to recognize complex patterns, a skill which makes memorizing integrated circuit patterns a minimal problem."<span id="fnref:ncio"><a href="#fn:ncio">7</a></span></p>
<p>However, in <a href="https://lisanakamura.net/wp-content/uploads/2011/01/indigenous-circuits-nakamura-aq.pdf">Indigenous Circuits: Navajo Women and the Racialization of Early Electronic Manufacture</a>,
digital media theorist Lisa Nakamura critiques this language as
a process by which "electronics assembly work became both gendered and identified with specific racialized qualities".<span id="fnref:racialization"><a href="#fn:racialization">5</a></span>
Nakamura points out how "Navajo
women‚Äôs affinity for electronics manufacture [was described] as both reflecting and satisfying
an intrinsic gendered and racialized drive toward intricacy, detail, and quality."</p>
<p><a href="https://static.righto.com/images/pentium-rug/shiprock-plant.jpg"><img alt="Fairchild's Shiprock plant, 1966. From the patterns on the floor, this photo may show the time period when Fairchild set up manufacturing in the school gymnasium. Photo by Jack Grimes. Photo courtesy of Computer History Museum, Henry Mahler collection of Fairchild Semiconductor photographs." height="400" src="https://static.righto.com/images/pentium-rug/shiprock-plant-w500.jpg" title="Fairchild's Shiprock plant, 1966. From the patterns on the floor, this photo may show the time period when Fairchild set up manufacturing in the school gymnasium. Photo by Jack Grimes. Photo courtesy of Computer History Museum, Henry Mahler collection of Fairchild Semiconductor photographs." width="500"></a></p><p>Fairchild's Shiprock plant, 1966. From the patterns on the floor, this photo may show the time period when Fairchild set up manufacturing in the school gymnasium. Photo by Jack Grimes. Photo courtesy of Computer History Museum, <a href="https://www.computerhistory.org/collections/catalog/102785007">Henry Mahler collection of Fairchild Semiconductor photographs</a>.</p>
<p>At Shiprock, Fairchild employed 1200 workers,<span id="fnref:workers"><a href="#fn:workers">6</a></span> and all but 24 were Navajo, making Fairchild the nation's largest
non-government employer of American Indians. Of the 33 production supervisors, 30 were Navajo.
This project had extensive government involvement from the Bureau of Indian Affairs and the U.S. Public Health Service,
while the Economic Development Administration made business loans to Fairchild,
the Labor Department had job training programs, and Housing and Urban Development built housing at Shiprock<span id="fnref2:ncio"><a href="#fn:ncio">7</a></span>.</p>
<p>The Shiprock plant was considered a major success story at a meeting of the National Council on Indian Opportunity in 1971.<span id="fnref3:ncio"><a href="#fn:ncio">7</a></span>
US Vice President Agnew called the economic deprivation and
40-80% unemployment on Indian reservations "a problem of staggering magnitude" and encouraged more industrial development.
Fairchild President Hogan stated that "Fairchild's program at Shiprock has been one of the most rewarding in the history of our company, from the standpoint of a sound business as well as social responsibility."
He said that at first the plant was considered the "Shiprock experiment", but the plant
was "now among the most productive and efficient of any Fairchild operation in the world."
Peter MacDonald, Chairman of the Navajo Tribal Council and a World War II Navajo <a href="https://en.wikipedia.org/wiki/Code_talker">code talker</a>, discussed the extreme poverty and unemployment on the Navajo reservation, along with "inadequate housing,
inadequate health care and the lack of viable economic activities."
He referred to Fairchild as "one of the best arrangements we have ever had" providing not only employment but also supporting
housing through a non-profit.</p>
<p><a href="https://static.righto.com/images/pentium-rug/national-geographic.jpg"><img alt="Navajo workers using microscopes in Fairchild's Shiprock plant. From &quot;The Navajo Nation Looks Ahead&quot;, National Geographic, December 1972." height="407" src="https://static.righto.com/images/pentium-rug/national-geographic-w500.jpg" title="Navajo workers using microscopes in Fairchild's Shiprock plant. From &quot;The Navajo Nation Looks Ahead&quot;, National Geographic, December 1972." width="500"></a></p><p>Navajo workers using microscopes in Fairchild's Shiprock plant. From "The Navajo Nation Looks Ahead", National Geographic, December 1972.</p>
<p>In December 1972, National Geographic highlighted the Shiprock plant as "weaving for the Space Age", stating that the Fairchild plant was the tribe's most
successful economic project with Shiprock booming due to the 4.5-million-dollar annual payroll. The article states: "Though the plant runs happily today, it was at first a battleground of warring
cultures."
A new manager, Paul Driscoll, realized that strict "white man's rules" were counterproductive.
For instance, many employees couldn't phone in if they would be absent, as they didn't have telephones.
Another issue was the language barrier since many workers spoke only Navajo, not English.
So when technical words didn't exist in Navajo, substitutes were found: "aluminum" became "shiny metal".
Driscoll also realized that Fairchild needed to adapt to traditional nine-day religious ceremonies.
Soon the monthly turnover rate dropped from 12% to under 1%, better than Fairchild's other plants.</p>
<p>Unfortunately, the Fairchild-Navajo manufacturing partnership soon met a dramatic end.
In 1975, the semiconductor industry was suffering from the ongoing US recession. Fairchild was especially hard hit,
<a href="https://archive.computerhistory.org/resources/access/text/2023/07/102710181-05-01-acc.pdf#page=24">losing money</a> on its integrated circuits, and it shed over <a href="https://archive.computerhistory.org/resources/access/text/2023/07/102710181-05-01-acc.pdf#page=21">8000 employees</a> between 1973 and 1975.<span id="fnref:fairchild"><a href="#fn:fairchild">8</a></span>
At the Shiprock plant, Fairchild laid off<span id="fnref:laid-off"><a href="#fn:laid-off">9</a></span> 140 Navajo employees in February 1975, angering the community.
A group of 20 Indians armed with high-power rifles
<a href="https://www.nytimes.com/1975/03/02/archives/indians-vow-to-stay-in-fairchild-plant.html">took over</a> the plant, demanding that
Fairchild rehire the employees.
Fairchild portrayed the occupiers, part of the AIM (American Indian Movement), as an "<a href="https://archive.computerhistory.org/resources/access/text/2017/02/102770538-05-01-acc.pdf">outside group‚Äîrepresenting neither employees, tribal authorities nor the community</a>."
Peter MacDonald, chairman of the Navajo Nation, agreed with the AIM on many points but viewed the AIM occupiers as "foolish" with "little sense of Navajo history" and "no sense of the need for an Indian nation to grow" (<a href="https://archive.org/details/lastwarriorpeter0000macd/page/320/mode/1up">source</a>).
MacDonald negotiated with the occupiers and the occupation <a href="https://www.nytimes.com/1975/03/04/archives/40-indians-accept-amnesty-and-end-plant-occupation.html">ended</a> peacefully a week later, with <a href="https://www.nytimes.com/1975/03/04/archives/40-indians-accept-amnesty-and-end-plant-occupation.html">unconditional amnesty</a> granted to the occupiers.<span id="fnref:aim"><a href="#fn:aim">10</a></span>
However, concerned about future disruptions, Fairchild <a href="https://www.nytimes.com/1975/03/13/archives/plant-that-indians-seized-is-now-shut.html">permanently closed</a> the Shiprock plant and <a href="https://archive.computerhistory.org/resources/access/text/2015/07/102658280-05-01-acc.pdf#page=6">transferred</a> production to Southeast Asia.</p>
<p><a href="https://static.righto.com/images/pentium-rug/occupy.jpg"><img alt="An article entitled &quot;Navajos Occupy Plant&quot;. Contrary to the title, MacDonald stated that many of the occupiers were from other tribes and were not acting in the best interest of the Navajo. From Workers' Power, the biweekly newspaper of the International Socialists, March 13-26, 1975." height="481" src="https://static.righto.com/images/pentium-rug/occupy-w500.jpg" title="An article entitled &quot;Navajos Occupy Plant&quot;. Contrary to the title, MacDonald stated that many of the occupiers were from other tribes and were not acting in the best interest of the Navajo. From Workers' Power, the biweekly newspaper of the International Socialists, March 13-26, 1975." width="500"></a></p><p>An article entitled "Navajos Occupy Plant". Contrary to the title, MacDonald stated that many of the occupiers were from other tribes and were not acting in the best interest of the Navajo. From <a href="https://www.marxists.org/history/etol/newspape/workerspower/wp116.pdf">Workers' Power</a>, the biweekly newspaper of the International Socialists, March 13-26, 1975.</p>
<p>For the most part, the Fairchild plant was viewed as a success prior to its occupation and closure.
Navajo leader MacDonald looked back on the Fairchild plant as "a cooperative effort that was succeeding for everyone" (<a href="https://archive.org/details/lastwarriorpeter0000macd/page/318/mode/1up">link</a>).
Alice Funston, a Navajo forewoman at Shiprock said, "Fairchild has not only helped women get ahead, it has been good
for the entire Indian community in Shiprock."<span id="fnref:funston"><a href="#fn:funston">11</a></span>
On the other hand,
Fairchild general manager Charles Sporck had a negative view looking back:
"It [Shiprock] never worked out. We were really screwing up the whole societal structure of the Indian tribe.
You know, the women were making money and the guys were drinking it up.
We had a very major negative impact upon the Navajo tribe."<span id="fnref:sporck"><a href="#fn:sporck">12</a></span></p>
<p>Despite the stereotypes in Sporck's comments, he touches on important gender issues, both at Fairchild and in the electronics
industry as a whole.
Fairchild had long recognized the lack of jobs for men at Shiprock, despite attempts to create roles for men. In 1971, Fairchild President Hogan stated that
since "semiconductor assembly operation require a great amount of detail work with tiny components, [it] lends itself to
female workers. As a result, there are nearly three times as many Navajo women employed by Fairchild as men."<span id="fnref4:ncio"><a href="#fn:ncio">7</a></span></p>
<p>The role of women in fabricating and assembling electronics is often not recognized.
A <a href="https://fraser.stlouisfed.org/files/docs/publications/bls/bls_1363_1963.pdf#page=43">1963 report</a> on electronics manufacturing
estimated that women workers made up
41 percent of total employment in electronics manufacturing, largely in gendered roles.
The report suggested that 
microminiaturization of semiconductors gave women an advantage over men in assembly and production-line work;
women made up over 70% of semiconductor production-line workers, with
90-99% of inspecting and testing jobs.
and 90-100% of assembler jobs.
Women were largely locked out of non-production jobs;
although women held a few technician and drafting roles, the percentage of woman engineers was too low to measure.</p>
<p>The defense contractor General Dynamics also had Navajo plants, but with more success than Fairchild.
General Dynamics opened a Navajo Nation plant in Fort Defiance, Arizona in <a href="https://www.andrews.edu/~tidwell/bsad560/Navajo">1967</a> to make <a href="https://www.bia.gov/as-ia/opa/online-press-release/missile-parts-plant-set-navajo-area">missiles for the Navy</a>.
At the plant's opening, Navajo Tribal Chairman Raymond Nakai pushed for industrialization, <a href="https://archive.library.nau.edu/digital/collection/cpa/id/37191">stating</a>
that it was in "industrialization and the money and the jobs engendered thereby that the future of
the Navajo people will lie."
The plant started with 30 employees, growing to 224 by the end of 1969, but then dropping to 99 in 1971 due to
a <a href="https://books.google.com/books?id=0y-8OOtshbAC&amp;pg=PA196#v=onepage&amp;q&amp;f=false">slowdown in the electronics industry</a>.
General Dynamics opened another Navajo plant near Farmington NM in <a href="https://www.nytimes.com/1988/06/09/business/company-news-navajos-to-build-plant-for-dynamics.html">1988</a>.
Due to the <a href="https://books.google.com/books?id=DkIrAQAAIAAJ&amp;pg=PA231">end of the Cold War</a>,
Hughes acquired General Dynamics' missile business in 1991 before being
acquired by General Motors in 1985 and <a href="https://www.nytimes.com/1997/01/17/business/gm-to-sell-a-hughes-unit-to-raytheon.html">sold to Raytheon in 1997</a>.
The Fort Defiance facility was <a href="https://www.nhonews.com/opinion/ft-defiance-factory-to-close/article_4690c724-8082-5627-bdac-c001940e160b.html">closed in 2002</a> when its parent company, Delphi Automotive Systems, moved out of the military wiring business.
The Farmington plant remains open, now <a href="https://www.dws.state.nm.us/Portals/0/DM/Raytheon_Dine_Facility.pdf">Raytheon Din√©</a>, building
components for <a href="https://raytheon.mediaroom.com/2017-04-24-Raytheon-completes-new-5-million-warehouse-at-Dine-facility-near-Farmington">Tomahawk, Javelin, and AMRAMM missiles</a>.</p>
<!-- formerly Stinger 
https://books.google.com/books?id=jqCSmD9riiAC&pg=PA41&dq=Packard-Hughes+Interconnect+Fort+Defiance&hl=en&newbks=1&newbks_redir=0&sa=X&ved=2ahUKEwivzPX-7I6IAxU55ckDHWzALbAQuwV6BAgLEAc#v=onepage&q=Packard-Hughes%20Interconnect%20Fort%20Defiance&f=false
-->

<p><a href="https://static.righto.com/images/pentium-rug/general-dynamics.jpg"><img alt="Navajo workers at the General Dynamics plant in Fort Defiance, AZ. From the 1965 General Dynamics film &quot;The Navajo moves into the electronic age&quot;. From American Indian Film Gallery." height="446" src="https://static.righto.com/images/pentium-rug/general-dynamics-w500.jpg" title="Navajo workers at the General Dynamics plant in Fort Defiance, AZ. From the 1965 General Dynamics film &quot;The Navajo moves into the electronic age&quot;. From American Indian Film Gallery." width="500"></a></p><p>Navajo workers at the General Dynamics plant in Fort Defiance, AZ. From the 1965 General Dynamics film "The Navajo moves into the electronic age". From <a href="https://aifg.arizona.edu/film/navajo-moves-electronic-age">American Indian Film Gallery</a>.</p>
<h2>Inside the Fairchild 9040 integrated circuit</h2>
<p>The integrated circuit die image in
Fairchild's commemorative brochure has an exceptionally striking design and color scheme.
It's clear why this chip brings weaving to mind.
Studying the die photo of the 9040 carefully reveals some interesting characteristics of integrated circuit design, so
I will go into some detail.</p>
<p><a href="https://static.righto.com/images/pentium-rug/9040.jpg"><img alt="Die photo of the Fairchild 9040 flip-flop. From the commemorative brochure." height="500" src="https://static.righto.com/images/pentium-rug/9040-w500.jpg" title="Die photo of the Fairchild 9040 flip-flop. From the commemorative brochure." width="500"></a></p><p>Die photo of the Fairchild 9040 flip-flop. From the commemorative brochure.</p>
<p>The chip was fabricated from a tiny square of silicon, which appears purple in the photograph.
Different regions of the silicon die were treated (doped) with impurities to change the properties of the silicon and thus create
electronic devices. These doped regions appear as green or blue lines.
The white lines are the metal layer on top of the silicon, connecting the components. The 13 metal rectangles
around the border are the bond pads.
The chip was packaged in an unusual 13-pin flat-pack, as shown below.
Each of the 13 bond pads above was connected by a tiny wire to one
of the 13 external pins.</p>
<p><a href="https://static.righto.com/images/pentium-rug/flatpack.jpg"><img alt="The Fairchild 9040 packaged in a 13-pin flatpack integrated circuit. The chip was also available in a 14-pin DIP, a standard way of packaging chips. Photo from the commemorative brochure." height="97" src="https://static.righto.com/images/pentium-rug/flatpack-w250.jpg" title="The Fairchild 9040 packaged in a 13-pin flatpack integrated circuit. The chip was also available in a 14-pin DIP, a standard way of packaging chips. Photo from the commemorative brochure." width="250"></a></p><p>The Fairchild 9040 packaged in a 13-pin flatpack integrated circuit. The chip was also available in a 14-pin DIP, a standard way of packaging chips. Photo from the commemorative brochure.</p>
<p>The Fairchild 9040 was introduced in the mid-1960s as part of Fairchild's Micrologic family, a set of high-performance
integrated circuits that were designed to work together.<span id="fnref:dtl"><a href="#fn:dtl">13</a></span>
The 9040 chip was a "flip-flop", a circuit capable of storing a single bit, a 0 or 1. Flip-flops can be combined to
form counters, counting the number of pulses, for instance.</p>
<p>The most dramatic patterns on the chip are the intricate serpentine blue lines.
Each line forms a resistor, controlling the flow of electricity by impeding its path.
The lines must be long to provide the desired resistance, so they wind back and forth to fit into the available space.
Each end of a resistor is connected to the metal layer, wiring it to another part of the circuit.
Most of the die is occupied by resistors, which is a disadvantage of this type of circuit. Modern integrated circuits
use a different type of circuitry (CMOS), which is much more compact, partly because it doesn't need bulky resistors.</p>
<p><a href="https://static.righto.com/images/pentium-rug/resistors.jpg"><img alt="Resistors in the 9040 die." height="241" src="https://static.righto.com/images/pentium-rug/resistors-w500.jpg" title="Resistors in the 9040 die." width="500"></a></p><p>Resistors in the 9040 die.</p>
<p>Transistors are the main component of an integrated circuit. These tiny devices act as switches, turning signals on and off.
The photo below shows one of the transistors in the 9040.
It consists of three layers of silicon, with metal wiring connected to each layer. Note the blue region in the middle,
surrounded by a slightly darker purple region; these color changes indicate that the silicon has been doped to change
its properties.
The green region surrounding the transistor provides isolation between this transistor and the other circuitry, so
the transistors don't interfere with each other.
The chip also has many diodes, which look similar to transistors except a diode has two connections.</p>
<p><a href="https://static.righto.com/images/pentium-rug/transistor.jpg"><img alt="A transistor in the 9040 die. The three contacts are called the base, emitter, and collector." height="135" src="https://static.righto.com/images/pentium-rug/transistor-w200.jpg" title="A transistor in the 9040 die. The three contacts are called the base, emitter, and collector." width="200"></a></p><p>A transistor in the 9040 die. The three contacts are called the base, emitter, and collector.</p>
<p>These transistors with their three layers of silicon are a type known as bipolar. 
Modern computers use a different type of transistor, metal-oxide-semiconductor (MOS), which is much more compact and
efficient. 
One of Fairchild's major failures was staying with bipolar transistors too long, rather than moving to MOS.<span id="fnref:mos"><a href="#fn:mos">14</a></span>
In a sense, the photo of the 9040 die shows the seeds of Fairchild's failure.</p>
<p>The 9040 chip was constructed on a completely different scale from the Pentium, showing the rapid progress of the IC industry.
The 9040 contains just 16 transistors, while the Pentium contains 3.3 million transistors.
Thus, individual transistors can be seen in the 9040 image, while only large-scale functional blocks are visible in the Pentium.
This increasing transistor count illustrates the exponential growth
in integrated circuit capacity between the 9040 in the mid-1960s and the Pentium in 1993.
This growth pattern, with the number of transistors doubling about every two years, is known as Moore's law, since it
was first observed in 1965 by Gordon Moore (one of Fairchild's "traitorous eight", who later started Intel).</p>
<p>The schematic below shows the circuitry inside the 9040 chip, with its
16 transistors, 16 diodes, and 22 resistors.
The symmetry of the 9040 die photo makes it appealing, and that symmetry is reflected in the circuit below, with the left side and
the right side mirror images.
The idea behind a flip-flop is that it can hold either a 0 or a 1. In the chip, this is implemented by turning on the
right side of the chip to hold a 0, or the left side to hold a 1. If one side of the chip is on, it forces the other side
off, accomplished by the X-like crossings of signals in the center.<span id="fnref:schematic"><a href="#fn:schematic">15</a></span>
Thus, the symmetry is not arbitrary, but is critical to the operation of the circuit.</p>
<p><a href="https://static.righto.com/images/pentium-rug/schematic.jpg"><img alt="Schematic of the Fairchild 9040 flip-flop chip. From Fairchild 1970 Data Catalog." height="498" src="https://static.righto.com/images/pentium-rug/schematic-w600.jpg" title="Schematic of the Fairchild 9040 flip-flop chip. From Fairchild 1970 Data Catalog." width="600"></a></p>
<p>Despite the obscurity of the 9040, multiple 9040 chips are currently on the Moon.
The chip was
used in the Apollo Lunar Surface Experiments Package (ALSEP),<span id="fnref:apollo"><a href="#fn:apollo">16</a></span>
in particular, the Active Seismic Experiment on Apollo 14 and 16. This experiment detonated small explosives on the Moon
and measured the resulting seismic waves.
The photo below is a detail from a blueprint<span id="fnref:alsep"><a href="#fn:alsep">17</a></span>
that shows three of the nineteen 9040 flip-flops (labeled "FF") as well as two 9041 logic gates, a chip in the same family
as the 9040.</p>
<p><a href="https://static.righto.com/images/pentium-rug/ase.jpg"><img alt="Detail from Logic Schematic Type B Board No.4 ASE." height="261" src="https://static.righto.com/images/pentium-rug/ase-w400.jpg" title="Detail from Logic Schematic Type B Board No.4 ASE." width="400"></a></p><p>Detail from Logic Schematic Type B Board No.4 ASE.</p>
<h2>Conclusions</h2>
<p>The similarities between Navajo weavings and the patterns in integrated circuits have been described since the 1960s.
Marilou Schultz's weavings of integrated circuits make these visual metaphors into concrete works of art.
Although the Woven Histories exhibit at the National Gallery of Art is no longer on display,
the exhibit will be at the National Gallery of Canada (Ottawa) starting November 8, 2024, and the Museum of Modern Art (New York)
starting April 20, 2025
(full dates <a href="https://www.nga.gov/press/exhibitions/exhibitions-2024/5415.html">here</a>).
If you're in the area, I recommend viewing the exhibit, but don't make my mistake: leave more than
five minutes to see it!</p>
<p>Many thanks to Marilou Schultz for discussing her art with me.
For more on her art, see <a href="https://www.youtube.com/watch?v=lyVDvYURpqo">A Conversation with Marilou Schultz</a> on YouTube.<span id="fnref:amd"><a href="#fn:amd">18</a></span>
Follow me on Mastodon as <a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="c9a2aca7baa1a0bbbba0afaf89a6a5adabb0bdacbae7bab9a8aaac">[email&nbsp;protected]</span></a>
or <a href="https://www.righto.com/feeds/posts/default">RSS</a> for updates.</p>
<h2>Notes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using the moir√© effect to show different arrows to each observer (2018) (124 pts)]]></title>
            <link>https://www.popularmechanics.com/technology/infrastructure/a19091534/inogon-leading-mark-moire-effect-light/</link>
            <guid>41417997</guid>
            <pubDate>Sun, 01 Sep 2024 16:06:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.popularmechanics.com/technology/infrastructure/a19091534/inogon-leading-mark-moire-effect-light/">https://www.popularmechanics.com/technology/infrastructure/a19091534/inogon-leading-mark-moire-effect-light/</a>, See on <a href="https://news.ycombinator.com/item?id=41417997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-body="standard-article"><p data-journey-content="true" data-node-id="0">Imagine you're in charge of guiding ships into a harbor and you want to use a sign to direct them all to one specific point, perhaps a dock or a channel. How might you make a single signal light that always points to the right direction depending on the angle you look at it, to the right if you're too far left, and to the left if you're too far right? </p><p data-journey-content="true" data-node-id="1">Here in 2018, your mind might go to location tracking or some other high tech solution, but in 1982, some clever engineers had already figured out an answer with no electronics required. Well, other than a light. <a href="https://www.youtube.com/watch?v=d99_h30swtM" target="_blank" data-vars-ga-outbound-link="https://www.youtube.com/watch?v=d99_h30swtM" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Tom Scott explains">Tom Scott explains</a>: </p><p data-journey-content="true" data-node-id="3">The Inogon Leading Mark makes use of what's called the moir√© effect, that strange type of distortion you see when looking at a series of overlapping, not-quite-parallel lines. You may be familiar with it as a form of digital image artifacting, a strange jaggy cloudiness that can appear in certain images or video, like <a href="https://www.youtube.com/watch?v=jXEgnRWRJfg" target="_blank" data-vars-ga-outbound-link="https://www.youtube.com/watch?v=jXEgnRWRJfg" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="a clip of a striped shirt">a clip of a striped shirt</a>. <br></p><p data-journey-content="true" data-node-id="5">If you use this phenomenon cleverly, however,  you can create an image that can change depending on the angle its viewed from. In the case of the Inogon light, it will always display an arrow or series of arrows (sometimes strange, distorted ones) pointed in the direction you want them to go. It's like an optical illusion that's good for more than <a href="https://www.popularmechanics.com/science/a14400798/optical-illusion-new/" target="_blank" data-vars-ga-outbound-link="https://www.popularmechanics.com/science/a14400798/optical-illusion-new/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="just blowing your mind">just blowing your mind</a>.</p><p data-journey-content="true" data-node-id="6">Source: <a href="https://www.youtube.com/watch?v=d99_h30swtM" target="_blank" data-vars-ga-outbound-link="https://www.youtube.com/watch?v=d99_h30swtM" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Tom Scott">Tom Scott</a><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a Leading Chain of Psychiatric Hospitals Traps Patients (183 pts)]]></title>
            <link>https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</link>
            <guid>41417284</guid>
            <pubDate>Sun, 01 Sep 2024 14:33:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html">https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</a>, See on <a href="https://news.ycombinator.com/item?id=41417284">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Starliner crew reports hearing "sonar like noises" (101 pts)]]></title>
            <link>https://twitter.com/SpaceBasedFox/status/1830180273130242223</link>
            <guid>41416872</guid>
            <pubDate>Sun, 01 Sep 2024 13:36:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/SpaceBasedFox/status/1830180273130242223">https://twitter.com/SpaceBasedFox/status/1830180273130242223</a>, See on <a href="https://news.ycombinator.com/item?id=41416872">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Linkpreview, see how your sites looks in social media and chat apps (224 pts)]]></title>
            <link>https://linkpreview.xyz</link>
            <guid>41416714</guid>
            <pubDate>Sun, 01 Sep 2024 13:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linkpreview.xyz">https://linkpreview.xyz</a>, See on <a href="https://news.ycombinator.com/item?id=41416714">Hacker News</a></p>
<div id="readability-page-1" class="page"><!--teleport start anchor--><!--teleport anchor--><div id="__nuxt"><!--[--><div><!--[--><header><div><svg fill="none" height="48" viewBox="0 0 48 48" width="48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><filter id="a" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="54" width="48" x="0" y="-3"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" mode="normal" result="shape"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="-3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.1 0"></feColorMatrix><feBlend in2="shape" mode="normal" result="effect1_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0.1 0"></feColorMatrix><feBlend in2="effect1_innerShadow_3051_46941" mode="normal" result="effect2_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1" result="effect3_innerShadow_3051_46941"></feMorphology><feOffset></feOffset><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.0627451 0 0 0 0 0.0941176 0 0 0 0 0.156863 0 0 0 0.24 0"></feColorMatrix><feBlend in2="effect2_innerShadow_3051_46941" mode="normal" result="effect3_innerShadow_3051_46941"></feBlend></filter><filter id="b" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="42" width="36" x="6" y="5.25"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1.5" result="effect1_dropShadow_3051_46941"></feMorphology><feOffset dy="2.25"></feOffset><feGaussianBlur stdDeviation="2.25"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0.1 0"></feColorMatrix><feBlend in2="BackgroundImageFix" mode="normal" result="effect1_dropShadow_3051_46941"></feBlend><feBlend in="SourceGraphic" in2="effect1_dropShadow_3051_46941" mode="normal" result="shape"></feBlend></filter><linearGradient id="c" gradientUnits="userSpaceOnUse" x1="24" x2="26" y1=".000001" y2="48"><stop offset="0" stop-color="#fff" stop-opacity="0"></stop><stop offset="1" stop-color="#fff" stop-opacity=".12"></stop></linearGradient><linearGradient id="d" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="9" y2="39"><stop offset="0" stop-color="#fff" stop-opacity=".8"></stop><stop offset="1" stop-color="#fff" stop-opacity=".5"></stop></linearGradient><linearGradient id="e" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="0" y2="48"><stop offset="0" stop-color="#fff" stop-opacity=".12"></stop><stop offset="1" stop-color="#fff" stop-opacity="0"></stop></linearGradient><clipPath id="f"><rect height="48" rx="12" width="48"></rect></clipPath><g filter="url(#a)"><g clip-path="url(#f)"><rect fill="#0c111d" height="48" rx="12" width="48"></rect><path d="m0 0h48v48h-48z" fill="url(#c)"></path><g filter="url(#b)"><path clip-rule="evenodd" d="m15 9c-3.3137 0-6 2.6863-6 6v18c0 3.3137 2.6863 6 6 6h18c3.3137 0 6-2.6863 6-6v-18c0-3.3137-2.6863-6-6-6zm2.25 11.625h7.4733l-8.7991 8.7992 2.6516 2.6516 8.7992-8.7991v7.4733h3.75v-12c0-1.0355-.8395-1.875-1.875-1.875h-12z" fill="url(#d)" fill-rule="evenodd"></path></g></g><rect height="46" rx="11" stroke="url(#e)" stroke-width="2" width="46" x="1" y="1"></rect></g></svg><p>LinkPreview</p></div><div><!--[--><a href="https://supersaas.dev/" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!----><!--]--><!--[--><img src="https://supersaas.dev/logo.png" alt="Supersaas"><!--]--><!--[--><!----><!--]--><!--]--></a><!--]--><!--[--><!--]--></div></header><div><form data-n-ids="{&quot;np6cif8hBbo-0&quot;:&quot;np6cif8hBbo-0&quot;}"><!--[--><!--]--></form><!----></div><!--[--><p><a href="https://supersaas.dev/" target="_blank"><img src="https://essentials.supersaas.dev/supersaas-banner.png" alt="Supersaas"></a></p><!--]--><!--]--></div><!--]--><section aria-label="Notifications alt+T" tabindex="-1"><!--[--><ol data-sonner-toaster="" dir="ltr" tabindex="-1" data-theme="light" data-rich-colors="false" data-y-position="top" data-x-position="center"><!--[--><!--]--></ol><!--]--></section><!--teleport start--><!--teleport end--></div>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The web's clipboard, and how it stores data of different types (158 pts)]]></title>
            <link>https://alexharri.com/blog/clipboard</link>
            <guid>41415866</guid>
            <pubDate>Sun, 01 Sep 2024 11:02:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexharri.com/blog/clipboard">https://alexharri.com/blog/clipboard</a>, See on <a href="https://news.ycombinator.com/item?id=41415866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><p>If you've been using computers for a while, you probably know that the clipboard can store multiple types of data (images, rich text content, files, and so on). As a software developer, it started frustrating me that I didn't have a good understanding of how the clipboard stores and organizes data of different types.</p>
<p>I recently decided to unveil the mystery that is the clipboard and wrote this post using my learnings. We'll focus on the web clipboard and its APIs, though we'll also touch on how it interacts with operating system clipboards.</p>
<p>We'll start by exploring the web's clipboard APIs and their history. The clipboard APIs have some interesting limitations around data types, and we'll see how some companies have worked around those limitations. We'll also look at some proposals that aim to resolve those limitations (most notably, <a target="_blank" href="https://github.com/w3c/editing/blob/gh-pages/docs/clipboard-pickling/explainer.md">Web Custom Formats</a>).</p>
<p>If you've ever wondered how the web's clipboard works, this post is for you.</p>
<h2>Using the async Clipboard API</h2>
<p>If I copy some content from a website and paste it into Google Docs, some of its formatting is retained, such as links, font size, and color.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/copy-paste-rich-content.png"></p>
<p>But if I open VS Code and paste it there, only the raw text content is pasted.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/copy-paste-into-vscode.png"></p>
<p>The clipboard serves these two use cases by allowing information to be stored in multiple <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#list-of-representations"><em>representations</em></a> associated with MIME types. The W3C Clipboard spec <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandates</a> that for writing to and reading from the clipboard, these three data types must be supported:</p>
<ul>
<li><code>text/plain</code> for plain text.</li>
<li><code>text/html</code> for HTML.</li>
<li><code>image/png</code> for PNG images.</li>
</ul>
<p>So when I pasted before, Google Docs read the <code>text/html</code> representation and used that to retain the rich text formatting. VS Code only cares about the raw text and reads the <code>text/plain</code> representation. Makes sense.</p>
<p>Reading a specific representation via the async Clipboard API's <code>read</code> method is quite straightforward:</p>
<div><pre><p><span>const</span><span> items </span><span>=</span><span> </span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>read</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>item</span><span>.</span><span>types</span><span>.</span><span>includes</span><span>(</span><span>"text/html"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> blob </span><span>=</span><span> </span><span>await</span><span> item</span><span>.</span><span>getType</span><span>(</span><span>"text/html"</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> html </span><span>=</span><span> </span><span>await</span><span> blob</span><span>.</span><span>text</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Writing multiple representations to the clipboard via <code>write</code> is a bit more involved, but still relatively straightforward. First, we construct <code>Blob</code>s for each representation that we want to write to the clipboard:</p>
<div><pre><p><span>const</span><span> textBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>"Hello, world"</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"text/plain"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> htmlBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>"Hello, &lt;em&gt;world&lt;em&gt;"</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"text/html"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Once we have the blobs, we pass them to a new <code>ClipboardItem</code> in a key-value store with the data types as the keys and the blobs as the values:</p>
<div><pre><p><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span></span></p><p><span>  </span><span>[</span><span>textBlob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> textBlob</span><span>,</span><span></span></p><p><span>  </span><span>[</span><span>htmlBlob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> htmlBlob</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Note: <!-- -->I like that <code>ClipboardItem</code> accepts a key-value store. It nicely aligns with the idea of using a data structure that makes illegal states unrepresentable, as discussed in <a target="_blank" href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/#:~:text=Use%20a%20data%20structure%20that%20makes%20illegal%20states%20unrepresentable">Parse, don't validate</a>.</p>
<p>Finally, we invoke <code>write</code> with our newly constructed <code>ClipboardItem</code>:</p>
<div><pre><p><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<h3>What about other data types?</h3>
<p>HTML and images are cool, but what about general data interchange formats like JSON? If I were writing an application with copy-paste support, I could imagine wanting to write JSON or some binary data to the clipboard.</p>
<p>Let's try to write JSON data to the clipboard:</p>
<div><pre><p><span></span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> blob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>json</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"application/json"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span> </span><span>[</span><span>blob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> blob </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Upon running this, an exception is thrown:</p>
<div><pre><p><span>Failed to execute 'write' on 'Clipboard':</span></p><p><span>  Type application/json not supported on write.</span></p></pre></div>
<p>Hmm, what's up with that? Well, the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#dom-clipboard-write">spec</a> for <code>write</code> tells us that data types other than <code>text/plain</code>, <code>text/html</code>, and <code>image/png</code> must be rejected:</p>
<blockquote>
<p>If <em>type</em> is not in the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> list, then reject [...] and abort these steps.</p>
</blockquote>
<p>Interestingly, the <code>application/json</code> MIME type was in the mandatory data types list from <a target="_blank" href="https://www.w3.org/TR/2012/WD-clipboard-apis-20120223/#mandatory-data-types-1">2012</a> to <a target="_blank" href="https://www.w3.org/TR/2021/WD-clipboard-apis-20210806/#mandatory-data-types-x">2021</a> but was removed from the spec in <a target="_blank" href="https://github.com/w3c/clipboard-apis/pull/155">w3c/clipboard-apis#155</a>. Prior to that change, the lists of mandatory data types were much longer, with 16 mandatory data types for reading from the clipboard, and 8 for writing to it. After the change, only <code>text/plain</code>, <code>text/html</code>, and <code>image/png</code> remained.</p>
<p>This change was made after browsers opted not to support many of the mandatory types due to <a target="_blank" href="https://webkit.org/blog/8170/clipboard-api-improvements/#custom-mime-types:~:text=into%20web%20pages.-,Custom%20MIME%20Types,-Because%20the%20system">security concerns</a>. This is reflected by a warning in the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> section in the spec:</p>
<blockquote>
<p>Warning! The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.</p>
<p>Untrusted scripts can attempt to exploit security vulnerabilities in local software by placing data known to trigger those vulnerabilities on the clipboard.</p>
</blockquote>
<p>Okay, so we can only write a limited set of data types to the clipboard. But what's that about "<em>untrusted</em> scripts"? Can we somehow run code in a "trusted" script that lets us write other data types to the clipboard?</p>
<h3>The isTrusted property</h3>
<p>Perhaps the "trusted" part refers to the <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Event/isTrusted"><code>isTrusted</code> property on events</a>. <code>isTrusted</code> is a read-only property that is only set to true if the event was dispatched by the user agent.</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>e</span><span>.</span><span>isTrusted</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span></span></p></pre></div>
<p>Being "dispatched by the user agent" means that it was triggered by the user, such as a copy event triggered by the user pressing <span><span>Command</span><code title="Command"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.3 4V6.3H4C2.72975 6.3 1.7 5.27026 1.7 4C1.7 2.72975 2.72975 1.7 4 1.7C5.27026 1.7 6.3 2.72975 6.3 4Z" stroke="currentColor" stroke-width="1.4"></path><path d="M4 11.7H6.3V14C6.3 15.2703 5.27026 16.3 4 16.3C2.72975 16.3 1.7 15.2703 1.7 14C1.7 12.7297 2.72975 11.7 4 11.7Z" stroke="currentColor" stroke-width="1.4"></path><path d="M14 6.3H11.7V4C11.7 2.72975 12.7297 1.7 14 1.7C15.2703 1.7 16.3 2.72975 16.3 4C16.3 5.27026 15.2703 6.3 14 6.3Z" stroke="currentColor" stroke-width="1.4"></path><path d="M11.7 11.7H14C15.2703 11.7 16.3 12.7297 16.3 14C16.3 15.2703 15.2703 16.3 14 16.3C12.7297 16.3 11.7 15.2703 11.7 14V11.7Z" stroke="currentColor" stroke-width="1.4"></path><rect x="6.3" y="6.3" width="5.4" height="5.4" stroke="currentColor" stroke-width="1.4"></rect></svg></code>&nbsp;<code title="C">C</code></span>. This is in contrast to a synthetic event programmatically dispatched via <code>dispatchEvent()</code>:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"e.isTrusted is "</span><span> </span><span>+</span><span> e</span><span>.</span><span>isTrusted</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span><span> </span><span>ClipboardEvent</span><span>(</span><span>"copy"</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Let's look at the clipboard events and see whether they allow us to write arbitrary data types to the clipboard.</p>
<h2>The Clipboard Events API</h2>
<p>A <code>ClipboardEvent</code> is dispatched for copy, cut, and paste events, and it contains a <code>clipboardData</code> property of type <code>DataTransfer</code>. The <code>DataTransfer</code> object is used by the Clipboard Events API to hold multiple representations of data.</p>
<p>Writing to the clipboard in a <code>copy</code> event is very straightforward:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/html"</span><span>,</span><span> </span><span>"Hello, &lt;em&gt;world&lt;/em&gt;"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>And reading from the clipboard in a <code>paste</code> event is just as simple:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>const</span><span> html </span><span>=</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>getData</span><span>(</span><span>"text/html"</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>html</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Now for the big question: can we write JSON to the clipboard?</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"application/json"</span><span>,</span><span> json</span><span>)</span><span>;</span><span> </span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>No exception is thrown, but did this actually write the JSON to the clipboard? Let's verify that by writing a paste handler that iterates over all of the entries in the clipboard and logs them out:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>{</span><span> kind</span><span>,</span><span> type </span><span>}</span><span> </span><span>=</span><span> item</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>kind </span><span>===</span><span> </span><span>"string"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      item</span><span>.</span><span>getAsString</span><span>(</span><span>(</span><span>content</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>{</span><span> type</span><span>,</span><span> content </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Adding both of these handlers and invoking copy-paste results in the following being logged:</p>
<div><pre><p><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"application/json"</span><span>,</span><span> content</span><span>:</span><span> </span><span>"{\"message\":\"Hello\"}"</span><span> </span><span>}</span><span></span></p></pre></div>
<p>It works! It seems that <code>clipboardData.setData</code> does not restrict data types in the same manner as the async <code>write</code> method does.</p>
<p>But... why? Why can we read and write arbitrary data types using <code>clipboardData</code> but not when using the async Clipboard API?</p>
<h3>History of <code>clipboardData</code></h3>
<p>The relatively new async Clipboard API was added to the spec in <a target="_blank" href="https://www.w3.org/TR/2017/WD-clipboard-apis-20170929/">2017</a>, but <code>clipboardData</code> is <em>much</em> older than that. A W3C draft for the Clipboard API from <a target="_blank" href="https://www.w3.org/TR/2006/WD-clipboard-apis-20061115/">2006</a> defines <code>clipboardData</code> and its <code>setData</code> and <code>getData</code> methods (which shows us that MIME types were not being used at that point):</p>
<blockquote>
<p><code>setData()</code> This takes one or two parameters. The first must be set to either 'text' or 'URL' (case-insensitive).</p>
<p><code>getData()</code> This takes one parameter, that allows the target to request a specific type of data.</p>
</blockquote>
<p>But it turns out that <code>clipboardData</code> is even older than the 2006 draft. Look at this quote from the "Status of this Document" section:</p>
<blockquote>
<p>In large part [this document] describes the functionalities as implemented in Internet Explorer...</p>
<p>The intention of this document is [...] to specify what actually works in current browsers, or [be] a simple target for them to improve interoperability, rather than adding new features.</p>
</blockquote>
<p>This <a target="_blank" href="https://www.arstdesign.com/articles/clipboardexploit.html">2003 article</a> details how, at the time, in Internet Explorer 4 and above, you could use <code>clipboardData</code> to read the user's clipboard without their consent. Since Internet Explorer 4 was released in 1997 it seems that the <code>clipboardData</code> interface is at least 26 years old at the time of writing.</p>
<p>MIME types entered the <a target="_blank" href="https://www.w3.org/TR/2011/WD-clipboard-apis-20110412/">spec in 2011</a>:</p>
<blockquote>
<p>The <em>dataType</em> argument is a string, for example but not limited to a MIME type...</p>
</blockquote>
<blockquote>
<p>If a script calls getData('text/html')...</p>
</blockquote>
<p>At the time, the spec had not determined which data types should be used:</p>
<blockquote>
<p>While it is possible to use any string for setData()'s type argument, sticking to common types is recommended.</p>
<p>[Issue] Should we list some "common types"?</p>
</blockquote>
<p>Being able to use <em>any</em> string for <code>setData</code> and <code>getData</code> still holds today. This works perfectly fine:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"foo bar baz"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> content </span><span>=</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>getData</span><span>(</span><span>"foo bar baz"</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>content</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>content</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>If you paste this code snippet into your DevTools and then hit copy and paste, you will see the message "Hello, world" logged to your console.</p>
<p>The reason for the Clipboard Events API's <code>clipboardData</code> allowing us to use any data type seems to be a historical one. <em>"Don't break the web"</em>.</p>
<h3>Revisiting isTrusted</h3>
<p>Let's consider this sentence from the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> section again:</p>
<blockquote>
<p>The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.</p>
</blockquote>
<p>So what happens if we attempt to write to the clipboard in a synthetic (untrusted) clipboard event?</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span><span> </span><span>ClipboardEvent</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  clipboardData</span><span>:</span><span> </span><span>new</span><span> </span><span>DataTransfer</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>This runs successfully, but it doesn't modify the clipboard. This is the expected behavior <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#integration-with-other-scripts-and-events">as explained in the spec</a>:</p>
<blockquote>
<p>Synthetic cut and copy events <em>must not</em> modify data on the system clipboard.</p>
</blockquote>
<blockquote>
<p>Synthetic paste events <em>must not</em> give a script access to data on the real system clipboard.</p>
</blockquote>
<p>So only copy and paste events dispatched by the user agent are allowed to modify the clipboard. Makes total sense‚ÄîI wouldn't want websites to freely read my clipboard contents and steal my passwords.</p>
<hr>
<p>To summarize our findings so far:</p>
<ul>
<li>The async Clipboard API introduced in 2017 restricts which data types can be written to and read from the clipboard. However, it can read from and write to the clipboard at any time, given that the user has granted permission to do so (and the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#privacy-async">document is focused</a>).</li>
<li>The older Clipboard Events API has no real restrictions on which data types can be written to and read from the clipboard. However, it can only be used in copy and paste event handlers triggered by the user agent (i.e. when <code>isTrusted</code> is true).</li>
</ul>
<p>It seems that using the Clipboard Events API is the only way forward if you want to write data types to the clipboard that are not just plain text, HTML, or images. It's much less restrictive in that regard.</p>
<p>But what if you want to build a Copy button that writes non-standard data types to the clipboard? It doesn't seem like you'd be able to use the Clipboard Events API if the user did not trigger a copy event. Right?</p>
<h2>Building a copy button that writes arbitrary data types</h2>
<p>I went and tried out Copy buttons in different web applications and inspected what was written to the clipboard. It yielded interesting results.</p>
<p>Google Docs has a Copy button which can be found in their right-click menu.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-copy-button.png" width="480"></p>
<p>This copy button writes three representations to the clipboard:</p>
<ul>
<li><code>text/plain</code>,</li>
<li><code>text/html</code>, and</li>
<li><code>application/x-vnd.google-docs-document-slice-clip+wrapped</code></li>
</ul>
<p>Note: <!-- -->The third representation contains JSON data.</p>
<p>They're writing a custom data type to the clipboard, which means that they aren't using the async Clipboard API. How are they doing that through a click handler?</p>
<p>I ran the profiler, hit the copy button, and inspected the results. It turns out that clicking the copy button triggers a call to <code>document.execCommand("copy")</code>.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-exec-command.png"></p>
<p>This was surprising to me. My first thought was <em>"Isn't <code>execCommand</code> the old, deprecated way of copying text to the clipboard?"</em>.</p>
<p>Yes, it is, but Google uses it for a reason. <code>execCommand</code> is special in that it allows you to programmatically dispatch a trusted copy event <em>as if</em> the user invoked the copy command themselves.</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"e.isTrusted is "</span><span> </span><span>+</span><span> e</span><span>.</span><span>isTrusted</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>execCommand</span><span>(</span><span>"copy"</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Note: <!-- -->Safari requires an active selection for <code>execCommand("copy")</code> to dispatch a copy event. That selection can be faked by adding a non-empty input element to the DOM and selecting it prior to invoking <code>execCommand("copy")</code>, after which the input can be removed from the DOM.</p>
<p>Okay, so using <code>execCommand</code> allows us to write arbitrary data types to the clipboard in response to click events. Cool!</p>
<p>What about paste? Can we use <code>execCommand("paste")</code>?</p>
<h2>Building a paste button</h2>
<p>Let's try the Paste button in Google Docs and see what it does.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-button.png" width="480"></p>
<p>On my Macbook, I got a popup telling me that I need to install an extension to use the paste button.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-popup.png" width="650"></p>
<p>But oddly, on my Windows laptop, the paste button just worked.</p>
<p>Weird. Where does the inconsistency come from? Well, whether or not the paste button will work can be checked by running <code>queryCommandSupported("paste")</code>:</p>
<div><pre><p><span>document</span><span>.</span><span>queryCommandSupported</span><span>(</span><span>"paste"</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>On my Macbook, I got <code>false</code> on Chrome and Firefox, but <code>true</code> on Safari.</p>
<p>Safari, being privacy-conscious, required me to confirm the paste action. I think that's a really good idea. It makes it very explicit that the website will read from your clipboard.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-confirm.png" width="650"></p>
<p>On my Windows laptop, I got <code>true</code> on Chrome and Edge, but <code>false</code> on Firefox. The inconsistency with Chrome is surprising. Why does Chrome allow <code>execCommand("paste")</code> on Windows but not macOS? I wasn't able to find any info on this.</p>
<p>I find it surprising that Google doesn't attempt to fall back to the async Clipboard API when <code>execCommand("paste")</code> is unavailable. Even though they wouldn't be able to read the <code>application/x-vnd.google-[...]</code> representation using it, the HTML representation contains internal IDs that could be used.</p>
<div><pre><p><span></span><span>&lt;</span><span>meta</span><span> </span><span>charset</span><span>=</span><span>"</span><span>utf-8</span><span>"</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>b</span><span> </span><span>id</span><span>=</span><span>"</span><span>docs-internal-guid-[guid]</span><span>"</span><span> </span><span>style</span><span>=</span><span>"</span><span>...</span><span>"</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>style</span><span>=</span><span>"</span><span>...</span><span>"</span><span>&gt;</span><span>Copied text</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;/</span><span>b</span><span>&gt;</span><span></span></p></pre></div>
<hr>
<p>Another web application with a paste button is Figma, and they take a completely different approach. Let's see what they're doing.</p>
<h2>Copy and Paste in Figma</h2>
<p>Figma is a web-based application (their native app uses <a target="_blank" href="https://www.electronjs.org/">Electron</a>). Let's see what their copy button writes to the clipboard.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/figma-copy-button.png" width="480"></p>
<p>Figma's copy button writes two representations to the clipboard: <code>text/plain</code> and <code>text/html</code>. This was surprising to me at first. How would Figma represent their various layout and styling features in plain HTML?</p>
<p>But looking at the HTML, we see two empty <code>span</code> elements with <code>data-metadata</code> and <code>data-buffer</code> properties:</p>
<div><pre><p><span>&lt;</span><span>meta</span><span> </span><span>charset</span><span>=</span><span>"</span><span>utf-8</span><span>"</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>data-metadata</span><span>=</span><span>"</span><span>&lt;!--(figmeta)eyJma[...]9ifQo=(/figmeta)--&gt;</span><span>"</span><span>&gt;</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>data-buffer</span><span>=</span><span>"</span><span>&lt;!--(figma)ZmlnL[...]P/Ag==(/figma)--&gt;</span><span>"</span><span>&gt;</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>span</span><span> </span><span>style</span><span>=</span><span>"</span><span>white-space</span><span>:</span><span>pre-wrap</span><span>;</span><span>"</span><span>&gt;</span><span>Text</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p></pre></div>
<p>Note: <!-- -->The <code>data-buffer</code> string is ~26,000 characters for an empty frame. After that, the length of <code>data-buffer</code> seems to grow linearly with the amount of content that was copied.</p>
<p>Looks like base64. The <code>eyJ</code> start is a clear indication of <code>data-metadata</code> being a base64 encoded JSON string. Running <code>JSON.parse(atob())</code> on <code>data-metadata</code> yields:</p>
<div><pre><p><span>{</span><span></span></p><p><span>  </span><span>"fileKey"</span><span>:</span><span> </span><span>"4XvKUK38NtRPZASgUJiZ87"</span><span>,</span><span></span></p><p><span>  </span><span>"pasteID"</span><span>:</span><span> </span><span>1261442360</span><span>,</span><span></span></p><p><span>  </span><span>"dataType"</span><span>:</span><span> </span><span>"scene"</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Note: <!-- -->I've replaced the real <code>fileKey</code> and <code>pasteID</code>.</p>
<p>But what about the big <code>data-buffer</code> property? Base64 decoding it yields the following:</p>
<div><pre><p><span>fig-kiwiF\x00\x00\x00\x1CK\x00\x00¬µ¬Ω\v\x9CdI[...]\x197√ú\x83\x03</span></p></pre></div>
<p>Looks like a binary format. After a bit of digging‚Äîusing <code>fig-kiwi</code> as a clue‚ÄîI discovered that this is the <a target="_blank" href="https://github.com/evanw/kiwi">Kiwi message format</a> (created by Figma's co-founder and former CTO, <a target="_blank" href="https://github.com/evanw">Evan Wallace</a>), which is used to encode <code>.fig</code> files.</p>
<p>Since Kiwi is a schema-based format, it seemed like we wouldn't be able to parse this data without knowing the schema. However, lucky for us, Evan created a <a target="_blank" href="https://github.com/evanw/kiwi/issues/17#issuecomment-1937797254">public <code>.fig</code> file parser</a>. Let's try plugging the buffer into that!</p>
<p>To convert the buffer into a <code>.fig</code> file, I wrote a small script to generate a Blob URL:</p>
<div><pre><p><span>const</span><span> base64 </span><span>=</span><span> </span><span>"ZmlnL[...]P/Ag=="</span><span>;</span><span></span></p><p><span></span><span>const</span><span> blob </span><span>=</span><span> </span><span>base64toBlob</span><span>(</span><span>base64</span><span>,</span><span> </span><span>"application/octet-stream"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>URL</span><span>.</span><span>createObjectURL</span><span>(</span><span>blob</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>I then downloaded the resulting blob as a <code>.fig</code> file, uploaded that to the <code>.fig</code> file parser, and voil√†:</p>
<p><img src="https://alexharri.com/images/posts/clipboard/figma-data.png" width="620"></p>
<p>So copying in Figma works by creating a small Figma file, encoding that as a base64, placing the resulting base64 string into the <code>data-buffer</code> attribute of an empty HTML <code>span</code> element, and storing that in the user's clipboard.</p>
<h3>The benefits of copy-pasting HTML</h3>
<p>This seemed a bit silly to me at first, but there is a strong benefit to taking that approach. To understand why, consider how the web-based Clipboard API interacts with the various operating system Clipboard APIs.</p>
<p>Windows, macOS, and Linux all offer different formats for writing data to the clipboard. If you want to write HTML to the clipboard, <a target="_blank" href="https://learn.microsoft.com/en-us/windows/win32/dataxchg/html-clipboard-format">Windows has <code>CF_HTML</code></a> and <a target="_blank" href="https://developer.apple.com/documentation/appkit/nspasteboard/pasteboardtype/1529057-html">macOS has <code>NSPasteboard.PasteboardType.html</code></a>.</p>
<p>All of the operating systems offer types for "standard" formats (plain text, HTML, and PNG images). But which OS format should the browser use when the user attempts to write an arbitrary data type like <code>application/foo-bar</code> to the clipboard?</p>
<p>There isn't a good match, so the browser doesn't write that representation to common formats on the OS clipboard. Instead, that representation only exists within a custom browser-specific clipboard format on the OS clipboard. This results in being able to copy and paste arbitrary data types across browser tabs, but <em>not</em> across applications.</p>
<p>This is why using the common data types <code>text/plain</code>, <code>text/html</code> and <code>image/png</code> is so convenient. They are mapped to common OS clipboard formats and as such can be easily read by other applications, which makes copy/paste work across applications. In Figma's case, using <code>text/html</code> enables copying a Figma element from <code>figma.com</code> in the browser and then pasting it into the native Figma app, and vice versa.</p>
<h2>What do browsers write to the clipboard for custom data types?</h2>
<p>We've learned that we can write and read custom data types to and from the clipboard across browser tabs, but not across applications. But what exactly are browsers writing to the native OS clipboard when we write custom data types to the web clipboard?</p>
<p>I ran the following in a <code>copy</code> listener in each of the major browsers on my Macbook:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/html"</span><span>,</span><span> </span><span>"&lt;em&gt;Hello, world&lt;/em&gt;"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"application/json"</span><span>,</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> type</span><span>:</span><span> </span><span>"Hello, world"</span><span> </span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"foo bar baz"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>I then inspected the clipboard using <a target="_blank" href="https://apps.apple.com/us/app/pasteboard-viewer/id1499215709">Pasteboard Viewer</a>. Chrome adds four entries to the Pasteboard:</p>
<ul>
<li><code>public.html</code> contains the HTML representation.</li>
<li><code>public.utf8-plain-text</code> contains the plain text representation.</li>
<li><code>org.chromium.web-custom-data</code> contains the custom representations.</li>
<li><code>org.chromium.source-url</code> contains the URL of the web page where the copy was performed.</li>
</ul>
<p>Looking at the <code>org.chromium.web-custom-data</code>, we see the data we copied:</p>
<p><img src="https://alexharri.com/images/posts/clipboard/pasteboard-chrome.png"></p>
<p>I imagine the accented "√Æ" and inconsistent line breaks are the result of some delimiters being displayed incorrectly.</p>
<p>Firefox creates the <code>public.html</code> and <code>public.utf8-plain-text</code> entries as well, but writes the custom data to <code>org.mozilla.custom-clipdata</code>. It does not store the source URL like Chrome does.</p>
<p>Safari, as you might expect, also creates the <code>public.html</code> and <code>public.utf8-plain-text</code> entries. It writes the custom data to <code>com.apple.WebKit.custom-pasteboard-data</code> and, interestingly, it also stores the full list of representations (including plain text and HTML) and source URL there.</p>
<p>Note: <!-- -->Safari allows copy-pasting custom data types across browser tabs if the source URL (domain) is the same, but not across different domains. This limitation does not seem to be present in Chrome or Firefox (even though Chrome stores the source URL).</p>
<h2>Raw Clipboard Access for the Web</h2>
<p>A proposal for <a target="_blank" href="https://github.com/WICG/raw-clipboard-access/blob/f58f5cedc753d55c77994aa05e75d5d2ad7344a7/explainer.md">Raw Clipboard Access</a> was created in 2019, which proposed an API for giving web applications raw read and write access to the native OS clipboards.</p>
<p>This excerpt from the <a target="_blank" href="https://chromestatus.com/feature/5682768497344512">Motivation section on chromestatus.com</a> for the Raw Clipboard Access feature highlights the benefits rather succinctly:</p>
<blockquote>
<p>Without Raw Clipboard Access [...] web applications are generally limited to a small subset of formats, and are unable to interoperate with the long tail of formats. For example, Figma and Photopea are unable to interoperate with most image formats.</p>
</blockquote>
<p>However, the Raw Clipboard Access proposal ended up not being taken further due to <a target="_blank" href="https://github.com/WICG/raw-clipboard-access/blob/f58f5cedc753d55c77994aa05e75d5d2ad7344a7/explainer.md#stakeholder-feedback--opposition">security concerns</a> around exploits such as remote code execution in native applications.</p>
<p>The most recent proposal for writing custom data types to the clipboard is the Web Custom Formats proposal (often referred to as pickling).</p>
<h2>Web Custom Formats (Pickling)</h2>
<p>In 2022, Chromium implemented support for <a target="_blank" href="https://developer.chrome.com/blog/web-custom-formats-for-the-async-clipboard-api">Web Custom Formats</a> in the async Clipboard API.</p>
<p>It allows web applications to write custom data types via the async Clipboard API by prefixing the data type with <code>"web "</code>:</p>
<div><pre><p><span></span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello, world"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> jsonBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>json</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"application/json"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span></span></p><p><span>  </span><span>[</span><span>`</span><span>web </span><span>${</span><span>jsonBlob</span><span>.</span><span>type</span><span>}</span><span>`</span><span>]</span><span>:</span><span> jsonBlob</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>These are read using the async Clipboard API like any other data type:</p>
<div><pre><p><span>const</span><span> items </span><span>=</span><span> </span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>read</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>item</span><span>.</span><span>types</span><span>.</span><span>includes</span><span>(</span><span>"web application/json"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> blob </span><span>=</span><span> </span><span>await</span><span> item</span><span>.</span><span>getType</span><span>(</span><span>"web application/json"</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> json </span><span>=</span><span> </span><span>await</span><span> blob</span><span>.</span><span>text</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>What's more interesting is what is written to the native clipboard. When writing web custom formats, the following is written to the native OS clipboard:</p>
<ul>
<li>A mapping from the data types to clipboard entry names</li>
<li>Clipboard entries for each data type</li>
</ul>
<p>On macOS, the mapping is written to <code>org.w3.web-custom-format.map</code> and its content looks like so:</p>
<div><pre><p><span>{</span><span></span></p><p><span>  </span><span>"application/json"</span><span>:</span><span> </span><span>"org.w3.web-custom-format.type-0"</span><span>,</span><span></span></p><p><span>  </span><span>"application/octet-stream"</span><span>:</span><span> </span><span>"org.w3.web-custom-format.type-1"</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>The <code>org.w3.web-custom-format.type-[index]</code> keys correspond to entries on the OS clipboard containing the unsanitized data from the blobs. This allows native applications to look at the mapping to see if a given representation is available and then read the unsanitized content from the corresponding clipboard entry.</p>
<p>Note: <!-- -->Windows and Linux <a target="_blank" href="https://github.com/dway123/clipboard-pickling/blob/bce5101564d379f48f11839e2c141ee51438e13c/explainer.md#os-interaction-format-naming">use a different naming convention</a> for the mapping and clipboard entries.</p>
<p>This avoids the security issues around raw clipboard access since web applications cannot write unsanitized data to whatever OS clipboard format they want to. That comes with an interoperability trade-off that is explicitly listed in the <a target="_blank" href="https://github.com/dway123/clipboard-pickling/blob/bce5101564d379f48f11839e2c141ee51438e13c/explainer.md#non-goals">Pickling for Async Clipboard API spec</a>:</p>
<blockquote>
<h4>Non-goals</h4>
<p>Allow interoperability with legacy native applications, without update. This was explored in a raw clipboard proposal, and may be explored further in the future, but comes with significant security challenges (remote code execution in system native applications).</p>
</blockquote>
<p>This means that native applications need to be updated for clipboard interop with web applications when using custom data types.</p>
<p>Web Custom Formats have been available in Chromium-based browsers since 2022, but other browsers have not implemented this proposal yet.</p>
<h2>Final words</h2>
<p>As of right now, there isn't a great way to write custom data types to the clipboard that works across all browsers. Figma's approach of placing base64 strings into an HTML representation is crude but effective in that it circumvents the plethora of limitations around the clipboard API. It seems like a good approach to take if you need to transmit custom data types via the clipboard.</p>
<p>I find the Web Custom Formats proposal promising, and I hope it becomes implemented by all of the major browsers. It seems like it would enable writing custom data types to the clipboard in a secure and practical manner.</p>
<p>Thanks for reading! I hope this was interesting.</p>
<p>‚Äî Alex Harri</p><div><p>Mailing list</p><div><p>To be notified of new posts, subscribe to my mailing list.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anarchy in Sudan has spawned the world‚Äôs worst famine in 40 years (227 pts)]]></title>
            <link>https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</link>
            <guid>41415819</guid>
            <pubDate>Sun, 01 Sep 2024 10:48:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years">https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</a>, See on <a href="https://news.ycombinator.com/item?id=41415819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><p><span><a href="https://www.economist.com/briefing" data-analytics="sidebar:section"><span>Briefing</span></a></span><span> | <!-- -->An intensifying calamity</span></p><h2>Anarchy in Sudan has spawned the world‚Äôs worst famine in 40 years</h2><h2>Millions are likely to perish</h2></section><section><figure><img alt="Sudanese refugees wait for food distribution at a camp in Chad" fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg"><figcaption><span>Photograph: Panos Pictures/ Sven Torfinn</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">I</span><small>T IS OFFICIAL</small>: for only the third time in the past 20 years, the <small>UN</small> has declared a full-blown famine. The declaration concerns a refugee camp called Zamzam, on the outskirts of the city of el-Fasher in Sudan. As long ago as April, M√©decins Sans Fronti√®res, a charity, estimated that every two hours a child in the camp was dying from starvation or disease‚Äîand since then the situation has got worse.</p></section><p>This article appeared in the Briefing section of the print edition under the headline ‚ÄúAn intensifying calamity‚Äù</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Sudan: Why its catastrophic war is the world‚Äôs problem" loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the August 31st 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-08-31" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Einstein's Other Theory of Everything (147 pts)]]></title>
            <link>https://nautil.us/einsteins-other-theory-of-everything-823245/</link>
            <guid>41415647</guid>
            <pubDate>Sun, 01 Sep 2024 10:09:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/einsteins-other-theory-of-everything-823245/">https://nautil.us/einsteins-other-theory-of-everything-823245/</a>, See on <a href="https://news.ycombinator.com/item?id=41415647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>E</span>instein finished his masterwork, the theory of general relativity, in 1915. He was 37 years old and would live for another 40 years. He spent these decades in the attempt to explain that everything‚Äîmatter, energy, and even ourselves‚Äîwere simply deformations of spacetime.&nbsp;</p><p>Einstein, feeling that his theory of general relativity was incomplete, wanted to develop a unified field theory‚Äîa framework that would combine space and time with energy and matter. (Indeed, it was Einstein who coined the term ‚Äúunified theory.‚Äù) He ultimately failed. But I have begun to wonder if his idea, as ambitious as it was startling, isn‚Äôt worth revisiting.</p>
      
    <p>Einstein built his unified theory off of general relativity, which says that gravity is a property of spacetime. This is often depicted with a marble that weighs down a rubber sheet. The rubber sheet is spacetime, the marble‚Äôs mass provides gravity. If a smaller marble rolls by the larger one, it will not roll in a straight line. It will roll in a curve as if it was attracted to the bigger marble. You need that marble to cause the curvature in the first place. It‚Äôs the same in Einstein‚Äôs general relativity: You need spacetime <em>and</em> matter in it to describe what we see happening in the universe.</p><p>Einstein seems to have tried to find a theory in which there is <em>only</em> spacetime and <em>no</em> matter‚Äîand in which we only interpret some of the spacetime as matter. He wanted to find equations that would have solutions that correspond to the fundamental particles of nature, such as electrons.</p>
          <blockquote>
<p>Einstein and Rosen assumed the black hole has no inside and instead connects two universes.</p>
</blockquote><p>When Einstein set out to find this theory, in the first half of the 20th century, physicists‚Äô knowledge of the properties of matter and how it behaved were incomplete. Today, we know of four fundamental interactions. Beside gravity, there‚Äôs electromagnetism and the strong and weak nuclear interactions. But in the early 20th century, the strong nuclear interaction had not yet been discovered, and the theory for the weak nuclear interaction had not yet been developed. Einstein therefore really only had two interactions to work with to make sense of matter: gravity and electromagnetism. The gravitational force law, also known as Newton‚Äôs law, is similar to that for electric charges, known as Coulomb‚Äôs law. And because Einstein had been so successful with describing gravity as the curvature of space, he wondered whether electromagnetism could be described in much the same way.</p><p>In 1919, Einstein published a <a href="https://einsteinpapers.press.princeton.edu/vol7-trans/96" target="_blank" rel="noreferrer noopener">paper</a> titled ‚ÄúDo gravitational fields play an essential role in the structure of the elementary particles of matter?‚Äù The idea he pursued in the paper was to take a modified version of general relativity, with different field equations, then add electromagnetism and ask whether this would give rise to solutions that could be interpreted as particles.</p><p>The conclusion he arrived at is: No, this doesn‚Äôt work because the quantity that could be interpreted as mass could take on any value, whereas the particles that matter are made of have very specific values.</p>
          <p>In 1923, he published another paper in which he basically said that his previous idea to make matter from spacetime didn‚Äôt work because there were some equations missing. He then proposed some equations that might do the job ‚Ä¶ but again concluded that this doesn‚Äôt work</p><p>In 1925, he published yet <em>another</em> paper in which he said that he had been trying for two years to combine electromagnetism with gravity, and it didn‚Äôt work.&nbsp;</p><p>But Einstein had another clue for his unified theory: black holes.</p><p>You see, as soon as Einstein had finished his theory of general relativity, the German physicist and astronomer Karl Schwarzschild discovered a solution to Einstein‚Äôs equations that described what we now call black holes. But this solution has singularities, places where some quantities take on infinite values. Einstein thought that this couldn‚Äôt be right. Singularities shouldn‚Äôt happen in reality. And if his theory allowed those, then there was something wrong with it. He therefore tried to use the requirement that singularities should be absent to go back and find solutions that would describe elementary particles.</p>
          <p>But he made a mistake there. In Schwarzschild‚Äôs black hole solution, there isn‚Äôt just one singularity, but two. One is at the horizon of the black hole, the other in the center. We know today that the singularity at the horizon does not correspond to any physically measurable quantity. It‚Äôs a mathematical artifact that can be removed. Einstein tried to find a way to remove this singularity that wasn‚Äôt there. (You‚Äôd think that physicists would have learned from this that it‚Äôs a mistake to go on about the properties of unobservable quantities, but still, it‚Äôs the same mistake that led to all these wrong predictions for the Large Hadron Collider. But I digress.)</p><blockquote>
<p>I want to call this Einstein‚Äôs Other Theory of Everything: that matter is really just made of spacetime.</p>
</blockquote><div><p>Einstein‚Äôs quest to get rid of black hole singularities is what led to his famous paper with Nathan Rosen in 1935, in which they introduced what is now called an Einstein-Rosen bridge. They assumed the black hole has no inside and instead connects two universes. It‚Äôs the simplest known example of a wormhole.</p><p>But they didn‚Äôt write the paper to introduce wormholes. Einstein and Rosen thought these wormholes were elementary particles. After they‚Äôd constructed their bridge, they wrote very clearly, ‚ÄúWe see now in the given solution, free from singularities, the mathematical representation of an elementary particle (neutrons or neutrinos).‚Äù</p></div><div><p>They then went on to add electric charges and interpreted those as charged particles. Now, we know today that neutrons are not elementary particles, they are made of smaller particles (quarks and gluons). But this wasn‚Äôt the main problem with the idea. The main problem is that one can calculate the size of the bridge, or wormhole, or whatever you want to call it, from its mass. And that‚Äôd tell you that the ‚Äúsize‚Äù of a neutron would be about 10<sup>-52</sup> centimeters. That‚Äôs more than 30 orders of magnitude smaller than its actual size. For other elementary particles, this becomes even more extreme.</p><p>This means that if elementary particles were wormholes or black holes, they would be much smaller than the quantum uncertainty that we measure. (Stephen Hawking also taught us that they‚Äôd be unstable, but again, Einstein couldn‚Äôt have known this.)</p></div>
          <div><p>In any case, he didn‚Äôt pursue this idea further. Instead, he pursued a different direction which he had proposed in 1925: that the properties of matter are encoded in the relations between different locations in spacetime, an approach that he dubbed ‚Äútele-parallelism.‚Äù It is this tele-parallelism that later became known as Einstein‚Äôs unified field theory. It has, however, little to do with his original idea.</p><p>This teleparallel approach to a unified field theory was not pursued after Einstein‚Äôs death in 1955. Because by then it had become clear that it wasn‚Äôt compatible with the new things that physicists had discovered, such as the weak and strong nuclear forces.</p></div><p>That said, I find it somewhat surprising‚Äîand maybe even concerning‚Äîthat physicists have also thrown out Einstein‚Äôs original idea, that I want to call his Other Theory of Everything: that matter is really just made of spacetime, curved in a particular way. The notion has survived in some areas of physics, where such objects are known as ‚Äúsolitons‚Äù‚Äîor noise-free subsystems‚Äîbut mostly it‚Äôs been given up.&nbsp;</p><p>It has been replaced by a different idea of unification, that matter and spacetime are both made of something else, such as, for example, strings or loops or networks.</p><p>So why am I returning to this old story? Primarily because I think it‚Äôs interesting what Einstein, undoubtedly one of the most intelligent people to walk on this planet, did with much of his life. But also because I don‚Äôt want Einstein‚Äôs idea‚Äîabout what we and the universe might be made out of‚Äîto be forgotten. <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <p><em>Lead image: Muhammad suryanto / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Sabine Hossenfelder                        </h6>
                        <p>
                          Posted on <time datetime="2024-08-30T10:39:35-05:00">August 30, 2024</time>
                        </p>
                      </div>
                                                <p>
                            Sabine Hossenfelder is a theoretical physicist at the Munich Center for Mathematical Philosophy, in Germany, focusing on modifications of general relativity, phenomenological quantum gravity, and the foundations of quantum mechanics. She is the creative director of the YouTube channel <a href="https://www.youtube.com/channel/UC1yNl2E66ZzKApQdRuTQ4tw">‚ÄúScience without the gobbledygook‚Äù</a> where she talks about recent scientific developments and debunks hype. Her latest book is <i><a href="https://www.penguinrandomhouse.com/books/616868/existential-physics-by-sabine-hossenfelder/">Existential Physics: A Scientist‚Äôs Guide to Life‚Äôs Biggest Questions</a></i>. Follow her on X (formerly known as Twitter) <a href="https://twitter.com/skdh">@skdh</a>.                          </p>
                                            </li>
                                  </ul>
            <div>
  <p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Honey, I shrunk {fmt}: bringing binary size to 14k and ditching the C++ runtime (217 pts)]]></title>
            <link>https://vitaut.net/posts/2024/binary-size/</link>
            <guid>41415238</guid>
            <pubDate>Sun, 01 Sep 2024 08:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vitaut.net/posts/2024/binary-size/">https://vitaut.net/posts/2024/binary-size/</a>, See on <a href="https://news.ycombinator.com/item?id=41415238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div v-pre=""><p><img src="https://vitaut.net/img/kennedy.jpg#floatright" alt="" title="We do this not because it is easy, but because we thought it would be easy."></p><p><a href="https://github.com/fmtlib/fmt">The {fmt} formatting library</a> is known for its small binary footprint,
often producing code that is several times smaller per function call compared
to alternatives like IOStreams, Boost Format, or, somewhat ironically,
tinyformat. This is mainly achieved through careful application of type erasure
on various levels, which effectively minimizes template bloat.</p><p>Formatting arguments are passed via type-erased <code>format_args</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>vformat</span><span>(</span><span>string_view</span> <span>fmt</span><span>,</span> <span>format_args</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>template</span> <span>&lt;</span><span>typename</span><span>...</span> <span>T</span><span>&gt;</span>
</span></span><span><span><span>auto</span> <span>format</span><span>(</span><span>format_string</span><span>&lt;</span><span>T</span><span>...</span><span>&gt;</span> <span>fmt</span><span>,</span> <span>T</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span> <span>{</span>
</span></span><span><span>  <span>return</span> <span>vformat</span><span>(</span><span>fmt</span><span>,</span> <span>fmt</span><span>::</span><span>make_format_args</span><span>(</span><span>args</span><span>...));</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>As you can see, <code>format</code> delegates all its work to <code>vformat</code>, which is not a
template.</p><p>Output iterators and other output types are also type-erased through a specially
designed buffer API.</p><p>This approach confines template usage to a minimal top-level layer, leading to
both a smaller binary size and <a href="https://vitaut.net/posts/2024/faster-cpp-compile-times/">faster build times</a>.</p><p>For example, the following code:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>// test.cc
</span></span></span><span><span><span></span><span>#include</span> <span>&lt;fmt/base.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>fmt</span><span>::</span><span>print</span><span>(</span><span>"The answer is {}."</span><span>,</span> <span>42</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>compiles to just</p><pre tabindex="0"><code>.LC0:
        .string "The answer is {}."
main:
        sub     rsp, 24
        mov     eax, 1
        mov     edi, OFFSET FLAT:.LC0
        mov     esi, 17
        mov     rcx, rsp
        mov     rdx, rax
        mov     DWORD PTR [rsp], 42
        call    fmt::v11::vprint(fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;)
        xor     eax, eax
        add     rsp, 24
        ret
</code></pre><p><a href="https://godbolt.org/z/PMKdPPnYn">godbolt</a></p><p>It is much smaller than the equivalent IOStreams code and comparable to that
of <code>printf</code>:</p><pre tabindex="0"><code>.LC0:
        .string "The answer is %d."
main:
        sub     rsp, 8
        mov     esi, 42
        mov     edi, OFFSET FLAT:.LC0
        xor     eax, eax
        call    printf
        xor     eax, eax
        add     rsp, 8
        ret
</code></pre><p><a href="https://godbolt.org/z/soTjfno71">godbolt</a></p><p>Unlike <code>printf</code>, {fmt} offers full runtime type safety. Errors in format strings
can be caught at compile time, and even when the format string is determined at
runtime, errors are managed through exceptions, preventing undefined behavior,
memory corruption, and potential crashes. Additionally, {fmt} calls are
generally more efficient, particularly when using positional arguments, which C
varargs are not well-suited for.</p><p>Back in 2020, I dedicated some time to <a href="https://vitaut.net/posts/2020/reducing-library-size/">optimizing the library size</a>,
successfully reducing it to under 100kB (just ~57kB with <code>-Os -flto</code>).
A lot has changed since then. Most notably, {fmt} now uses the exceptional
<a href="https://github.com/jk-jeon/dragonbox">Dragonbox</a> algorithm for floating-point formatting, kindly
contributed by its author, Junekey Jeon. Let‚Äôs explore how these changes have
impacted the binary size and see if further reductions are possible.</p><p>But why, some say, the binary size? Why choose this as our goal?</p><p>There has been considerable interest in using {fmt} on memory-constrained
devices, see e.g. <a href="https://github.com/fmtlib/fmt/issues/758">#758</a> and <a href="https://github.com/fmtlib/fmt/issues/1226">#1226</a> for just two examples from
the distant past. A particularly intriguing use case is retro computing, with
people using {fmt} on systems like Amiga (<a href="https://github.com/fmtlib/fmt/issues/4054">#4054</a>).</p><p>We‚Äôll apply the same methodology as in <a href="https://vitaut.net/posts/2020/reducing-library-size/">previous work</a>, examining the
executable size of a program that uses {fmt}, as this is most relevant to end
users. All tests will be conducted on an aarch64 Ubuntu 22.04 system with GCC
11.4.0.</p><p>First, let‚Äôs establish the baseline: what is the binary size for the latest
version of {fmt} (11.0.2)?</p><pre tabindex="0"><code>$ git checkout 11.0.2
$ g++ -Os -flto -DNDEBUG -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 75K Aug 30 19:24 a.out
</code></pre><p>The resulting binary size is 75kB (stripped). The positive takeaway is that
despite numerous developments over the past four years, the size has not
significantly regressed.</p><p>Now, let‚Äôs explore potential optimizations. One of the first adjustments you
might consider is disabling locale support. All the formatting in {fmt} is
locale-independent by default (which breaks with the C++‚Äôs tradition of having
wrong defaults), but it is still available as an opt in via the <code>L</code> format
specifier. It can be disabled in a somewhat obscure way via the
<code>FMT_STATIC_THOUSANDS_SEPARATOR</code> macro:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 71K Aug 30 19:25 a.out
</code></pre><p>Disabling locale support reduces the binary size to 71kB.</p><p>Next, let‚Äôs examine the results using our trusty tool, <a href="https://github.com/google/bloaty">Bloaty</a>:</p><pre tabindex="0"><code>$ bloaty -d symbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  43.8%  41.1Ki  43.6%  29.0Ki    [121 Others]
   6.4%  6.04Ki   8.1%  5.42Ki    fmt::v11::detail::do_write_float&lt;&gt;()
   5.9%  5.50Ki   7.5%  4.98Ki    fmt::v11::detail::write_int_noinline&lt;&gt;()
   5.7%  5.32Ki   5.8%  3.88Ki    fmt::v11::detail::write&lt;&gt;()
   5.4%  5.02Ki   7.2%  4.81Ki    fmt::v11::detail::parse_replacement_field&lt;&gt;()
   3.9%  3.69Ki   3.7%  2.49Ki    fmt::v11::detail::format_uint&lt;&gt;()
   3.2%  3.00Ki   0.0%       0    [section .symtab]
   2.7%  2.50Ki   0.0%       0    [section .strtab]
   2.3%  2.12Ki   2.9%  1.93Ki    fmt::v11::detail::dragonbox::to_decimal&lt;&gt;()
   2.0%  1.89Ki   2.4%  1.61Ki    fmt::v11::detail::write_int&lt;&gt;()
   2.0%  1.88Ki   0.0%       0    [ELF Section Headers]
   1.9%  1.79Ki   2.5%  1.66Ki    fmt::v11::detail::write_float&lt;&gt;()
   1.9%  1.78Ki   2.7%  1.78Ki    [section .dynstr]
   1.8%  1.72Ki   2.4%  1.62Ki    fmt::v11::detail::format_dragon()
   1.8%  1.68Ki   1.5%    1016    fmt::v11::detail::format_decimal&lt;&gt;()
   1.6%  1.52Ki   2.1%  1.41Ki    fmt::v11::detail::format_float&lt;&gt;()
   1.6%  1.49Ki   0.0%       0    [Unmapped]
   1.5%  1.45Ki   2.2%  1.45Ki    [section .dynsym]
   1.5%  1.45Ki   2.0%  1.31Ki    fmt::v11::detail::write_loc()
   1.5%  1.44Ki   2.2%  1.44Ki    [section .rodata]
   1.5%  1.40Ki   1.1%     764    fmt::v11::detail::do_write_float&lt;&gt;()::{lambda()#2}::operator()()
 100.0%  93.8Ki 100.0%  66.6Ki    TOTAL
</code></pre><p>Unsurprisingly, a significant portion of the binary size is dedicated to numeric
formatting, particularly floating-point numbers. FP formatting also relies on
sizable tables, which aren‚Äôt shown here. But what if floating-point support
isn‚Äôt required? {fmt} provides a way to disable it, though the method is
somewhat ad hoc and doesn‚Äôt extend to other types.</p><p>The core issue is that formatting functions need to be aware of all formattable
types. Or do they? This is true for <code>printf</code> as defined by the C standard, but
not necessarily for {fmt}. {fmt} supports an extension API that allows
formatting arbitrary types without knowing the complete set of types in advance.
While built-in and string types are handled specially for performance reasons,
focusing on binary size might warrant a different approach. By removing this
special handling and routing every type through the extension API, you can avoid
paying for types you don‚Äôt use.</p><p>I did an experimental <a href="https://github.com/fmtlib/fmt/commit/377cf20">implementation of this idea</a>. With the
<code>FMT_BUILTIN_TYPES</code> macro set to 0, only <code>int</code> is handled specially, and all
other types go through the general extension API. We still need to know about
<code>int</code> for dynamic width and precision, for example</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>fmt</span><span>::</span><span>print</span><span>(</span><span>"{:{}}</span><span>\n</span><span>"</span><span>,</span> <span>"hello"</span><span>,</span> <span>10</span><span>);</span> <span>// prints "hello     "
</span></span></span></code></pre></div><p>This gives you the ‚Äúdon‚Äôt pay for what you don‚Äôt use‚Äù model, though it comes
with a slight increase in per-call binary size. If you do format floating-point
numbers or other types, the relevant code will still be included in the build.
While it‚Äôs possible to make the FP implementation smaller, we won‚Äôt delve into
that here.</p><p>With <code>FMT_BUILTIN_TYPES=0</code>, the binary size in our example reduced to 31kB,
representing a substantial improvement:</p><pre tabindex="0"><code>$ git checkout 377cf20
$ g++ -Os -flto -DNDEBUG \
      "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 31K Aug 30 19:37 a.out
</code></pre><p>However, the updated Bloaty results reveal some lingering locale artifacts,
such as <code>digit_grouping</code>:</p><pre tabindex="0"><code>$ bloaty -d fullsymbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  41.8%  18.0Ki  39.7%  11.0Ki    [84 Others]
   6.4%  2.77Ki   0.0%       0    [section .symtab]
   5.3%  2.28Ki   0.0%       0    [section .strtab]
   4.6%  1.99Ki   6.9%  1.90Ki    fmt::v11::detail::format_handler&lt;char&gt;::on_format_specs(int, char const*, char const*)
   4.4%  1.88Ki   0.0%       0    [ELF Section Headers]
   4.1%  1.78Ki   5.8%  1.61Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int_noinline&lt;char, fmt::v11::basic_appender&lt;char&gt;, unsigned int&gt;(fmt::v11::basic_appender&lt;char&gt;, fmt::v11::detail::write_int_arg&lt;unsigned int&gt;, fmt::v11::format_specs const&amp;, fmt::v11::detail::locale_ref) (.constprop.0)
   3.7%  1.60Ki   5.8%  1.60Ki    [section .dynstr]
   3.5%  1.50Ki   4.8%  1.34Ki    void fmt::v11::detail::vformat_to&lt;char&gt;(fmt::v11::detail::buffer&lt;char&gt;&amp;, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::detail::vformat_args&lt;char&gt;::type, fmt::v11::detail::locale_ref) (.constprop.0)
   3.5%  1.49Ki   4.9%  1.35Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
   3.1%  1.31Ki   4.7%  1.31Ki    [section .dynsym]
   3.0%  1.29Ki   4.2%  1.15Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned long, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned long, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
</code></pre><p>After disabling these artifacts in commits <a href="https://github.com/fmtlib/fmt/commit/e582d37">e582d37</a> and
<a href="https://github.com/fmtlib/fmt/commit/b3ccc2d">b3ccc2d</a>, and introducing a more user-friendly option to opt out via
the <code>FMT_USE_LOCALE</code> macro, the binary size drops to 27kB:</p><pre tabindex="0"><code>$ git checkout b3ccc2d
$ g++ -Os -flto -DNDEBUG -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 27K Aug 30 19:38 a.out
</code></pre><p>The library includes several areas where size is traded off for speed.
For example, consider this function used to compute the number of decimal
digits:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>do_count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>// An optimization by Kendall Willets from https://bit.ly/3uOIQrB.
</span></span></span><span><span><span>// This increments the upper 32 bits (log10(T) - 1) when &gt;= T is added.
</span></span></span><span><span><span></span><span>#  define FMT_INC(T) (((sizeof(#T) - 1ull) &lt;&lt; 32) - T)
</span></span></span><span><span><span></span>  <span>static</span> <span>constexpr</span> <span>uint64_t</span> <span>table</span><span>[]</span> <span>=</span> <span>{</span>
</span></span><span><span>      <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>           <span>// 8
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>          <span>// 64
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>         <span>// 512
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>        <span>// 4096
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>       <span>// 32k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>      <span>// 256k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>     <span>// 2048k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>    <span>// 16M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>   <span>// 128M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span>  <span>// 1024M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>)</span>                        <span>// 4B
</span></span></span><span><span><span></span>  <span>};</span>
</span></span><span><span>  <span>auto</span> <span>inc</span> <span>=</span> <span>table</span><span>[</span><span>__builtin_clz</span><span>(</span><span>n</span> <span>|</span> <span>1</span><span>)</span> <span>^</span> <span>31</span><span>];</span>
</span></span><span><span>  <span>return</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span><span>((</span><span>n</span> <span>+</span> <span>inc</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The table used here is 256 bytes. There isn‚Äôt a one-size-fits-all solution,
and changing it unconditionally might negatively impact other use cases.
Fortunately, we have a fallback implementation of this function for scenarios
where <code>__builtin_clz</code> is unavailable, such as with <code>constexpr</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>constexpr</span> <span>auto</span> <span>count_digits_fallback</span><span>(</span><span>T</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span>  <span>int</span> <span>count</span> <span>=</span> <span>1</span><span>;</span>
</span></span><span><span>  <span>for</span> <span>(;;)</span> <span>{</span>
</span></span><span><span>    <span>// Integer division is slow so do it for a group of four digits instead
</span></span></span><span><span><span></span>    <span>// of for every digit. The idea comes from the talk by Alexandrescu
</span></span></span><span><span><span></span>    <span>// "Three Optimization Tips for C++". See speed-test for a comparison.
</span></span></span><span><span><span></span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10</span><span>)</span> <span>return</span> <span>count</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>100</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>1</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>1000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>2</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>3</span><span>;</span>
</span></span><span><span>    <span>n</span> <span>/=</span> <span>10000u</span><span>;</span>
</span></span><span><span>    <span>count</span> <span>+=</span> <span>4</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>All that remains is to provide users with control over when to use the fallback
implementation via (you guessed it) another configuration macro,
<code>FMT_OPTIMIZE_SIZE</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>#ifdef FMT_BUILTIN_CLZ
</span></span></span><span><span><span></span>  <span>if</span> <span>(</span><span>!</span><span>is_constant_evaluated</span><span>()</span> <span>&amp;&amp;</span> <span>!</span><span>FMT_OPTIMIZE_SIZE</span><span>)</span> <span>return</span> <span>do_count_digits</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>#endif
</span></span></span><span><span><span></span>  <span>return</span> <span>count_digits_fallback</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>With this and a few similar adjustments, we reduced the binary size to 23kB:</p><pre tabindex="0"><code>$ git checkout 8e3da9d
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 23K Aug 30 19:41 a.out
</code></pre><p>We could likely reduce the binary size even further with additional tweaks,
but let‚Äôs address the elephant in the room which is, of course, the C++ standard
library. What‚Äôs the point of optimizing the size when you end up getting
a megabyte or two of the C++ runtime?</p><p>While {fmt} relies minimally on the standard library, is it possible to
remove it completely as a dependency? One obvious problem is exceptions and
those can be disabled via <code>FMT_THROW</code>, e.g. by defining it to <code>abort</code>.
In general it is not recommended but it might be OK for some use cases
especially considering that most errors are caught at compile time.</p><p>Let‚Äôs try it out and compile with <code>-nodefaultlibs</code> and exceptions disabled:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc

/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::basic_memory_buffer&lt;char, 500ul, std::allocator&lt;char&gt; &gt;::grow(fmt::v11::detail::buffer&lt;char&gt;&amp;, unsigned long)':
&lt;artificial&gt;:(.text+0xaa8): undefined reference to `std::__throw_bad_alloc()'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xab8): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xaf8): undefined reference to `operator delete(void*, unsigned long)'
/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::vprint_buffered(_IO_FILE*, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;) [clone .constprop.0]':
&lt;artificial&gt;:(.text+0x18c4): undefined reference to `operator delete(void*, unsigned long)'
collect2: error: ld returned 1 exit status
</code></pre><p>Amazingly, this approach mostly works. The only remaining dependency on the C++
runtime comes from <code>fmt::basic_memory_buffer</code>, which is a small stack-allocated
buffer that can grow into dynamic memory if necessary.</p><p><code>fmt::print</code> can write directly into the <code>FILE</code> buffer and generally
doesn‚Äôt require dynamic allocation. So we could remove the dependency on
<code>fmt::basic_memory_buffer</code> from <code>fmt::print</code>. However, since it may be used
elsewhere, a better solution is to replace the default allocator with one that
uses <code>malloc</code> and <code>free</code> instead of <code>new</code> and <code>delete</code>.</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>struct</span> <span>allocator</span> <span>{</span>
</span></span><span><span>  <span>using</span> <span>value_type</span> <span>=</span> <span>T</span><span>;</span>
</span></span><span><span>
</span></span><span><span>  <span>T</span><span>*</span> <span>allocate</span><span>(</span><span>size_t</span> <span>n</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>FMT_ASSERT</span><span>(</span><span>n</span> <span>&lt;=</span> <span>max_value</span><span>&lt;</span><span>size_t</span><span>&gt;</span><span>()</span> <span>/</span> <span>sizeof</span><span>(</span><span>T</span><span>),</span> <span>""</span><span>);</span>
</span></span><span><span>    <span>T</span><span>*</span> <span>p</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>T</span><span>*&gt;</span><span>(</span><span>malloc</span><span>(</span><span>n</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>)));</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>!</span><span>p</span><span>)</span> <span>FMT_THROW</span><span>(</span><span>std</span><span>::</span><span>bad_alloc</span><span>());</span>
</span></span><span><span>    <span>return</span> <span>p</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span>
</span></span><span><span>  <span>void</span> <span>deallocate</span><span>(</span><span>T</span><span>*</span> <span>p</span><span>,</span> <span>size_t</span><span>)</span> <span>{</span> <span>free</span><span>(</span><span>p</span><span>);</span> <span>}</span>
</span></span><span><span><span>};</span>
</span></span></code></pre></div><p>This reduces binary size to just 14kB:</p><pre tabindex="0"><code>$ git checkout c0fab5e
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 14K Aug 30 19:06 a.out
</code></pre><p>Considering that a C program with an empty <code>main</code> function is 6kB on this
system, {fmt} now adds less than 10kB to the binary.</p><p>We can also easily verify that it no longer depends on the C++ runtime:</p><pre tabindex="0"><code>$ ldd a.out
        linux-vdso.so.1 (0x0000ffffb0738000)
        libc.so.6 =&gt; /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffb0530000)
        /lib/ld-linux-aarch64.so.1 (0x0000ffffb06ff000)
</code></pre><p>Hope you found this interesting and happy embedded formatting!</p><hr id="EOF"><p>Last modified on 2024-08-30</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E Ink faces growing competition in the "paper-like" display space (137 pts)]]></title>
            <link>https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</link>
            <guid>41415144</guid>
            <pubDate>Sun, 01 Sep 2024 08:09:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/">https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</a>, See on <a href="https://news.ycombinator.com/item?id=41415144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="post-171433"><div><div><p><em><p>Disclosure: Some links on this page are monetized by the <a rel="nofollow" href="http://go.skimlinks.com/?id=32X105&amp;xs=1&amp;url=http://skimlinks.com">Skimlinks</a>, <a rel="nofollow" href="https://affiliate-program.amazon.com/welcome">Amazon</a>, <a rel="nofollow" href="https://rakutenadvertising.com/">Rakuten Advertising, and </a><a rel="no follow" href="https://partnernetwork.ebay.com/">eBay</a>, affiliate programs, and Liliputing may earn a commission if you make a purchase after clicking on those links. All prices are subject to change, and this article only reflects the prices available at time of publication.</p></em></p></div><p>For the past few decades, E Ink has dominated the market for the paper-like displays found in eBook readers and other devices. The screens are high-contrast, easy to view indoors or outdoors, don‚Äôt require a backlight, don‚Äôt reflect glare, and consume very little power.</p><p>But E Ink displays also have slow screen refresh rates, limited support for color (on models that support any color at all), and generally aren‚Äôt very useful for high-motion graphics like videos or games. So while there are a handful of companies producing <a href="https://liliputing.com/tag/e-ink-phone/">E Ink smartphones</a> and <a href="https://liliputing.com/tag/e-ink-tablet/">tablets</a>, they tend to be niche devices. And now we‚Äôre seeing a growing number of companies offering products with reflective LCD displays or similar technology that offer some of the paper-like qualities of E Ink, but which are more suitable for animation and video.</p><figure id="attachment_171436" aria-describedby="caption-attachment-171436"><img fetchpriority="high" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171436">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>Reflective LCD displays don‚Äôt have a backlight and instead reflect ambient light, allowing you to use them without any additional illumination as long as you‚Äôre in a brightly lit environment. If you want to make a tablet or another device with a reflective LCD that can be used in dimmer environments, you‚Äôll want to add some front-lights that shine onto the screen‚Ä¶ much the way most modern eReaders with E Ink displays have front lighting.</p><p>But while reflective LCD technology has been around for decades, the screens don‚Äôt tend to look as bright or vibrant as the transmissive LCDs (with backlights) or OLED screens that have become more common in recent years.</p><p>Recently several companies have decided to try to make&nbsp;<em>better</em> reflective screens though, in an effort to offer an alternative to E Ink that can be used as a paper-like screen for reading and writing, but which also supports full-motion graphics for video, smooth scrolling, and other applications.</p><p>One effort that‚Äôs gotten a lot of attention this year is the <a href="https://liliputing.com/daylight-computer-dc-1-is-a-799-tablet-with-a-live-paper-display-designed-to-be-easy-on-the-eyes-but-not-the-wallet/"><strong>Daylight Computer DC-1</strong></a>, which has a ‚ÄúLive Paper‚Äù display that‚Äôs a black and white IGZO LCD display with a 60 Hz refresh rate and an amber-colored backlight (that can be turned entirely off when you don‚Äôt need it).</p><p><img decoding="async" src="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg" alt="" width="762" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg 762w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-400x262.jpg 400w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-150x98.jpg 150w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-768x504.jpg 768w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02.jpg 1200w" sizes="(max-width: 762px) 100vw, 762px"></p><p><a href="https://daylightcomputer.com/" rel="nofollow"><strong>Daylight</strong></a> is a startup that‚Äôs pushing the DC-1 as a tablet that can do more than a typical eReader, while still offering a comfortable viewing experience indoors or outdoors. It has a 10.5 inch display with support for touch and Wacom EMR pen input and the tablet runs a custom version of Android. It‚Äôs also expensive, with <a href="https://daylightcomputer.com/cart" rel="nofollow">a $729 price tag</a>.</p><p>If that price tag seems too steep, there‚Äôs always TCL‚Äôs <a href="https://www.tcl.com/global/en/tcl-nxtpaper-technology" rel="nofollow"><strong>NXTPAPER</strong></a> display technology. The company has been using its full-color, glare-free matte displays on a handful of smartphones and tablets over the past few years. I‚Äôve seen mixed reports on whether this is technically a reflective LCD or not, but while TCL tends to use these displays on relatively affordable devices with budget or mid-range specs, the <a href="https://www.zdnet.com/article/i-gave-away-my-kindle-and-ipad-within-hours-of-testing-this-tablet/" rel="nofollow">screens tend to get positive reviews</a> from folks who are comparing them to E Ink.</p><figure id="attachment_165542" aria-describedby="caption-attachment-165542"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg" alt="" width="749" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg 749w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-400x267.jpg 400w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-150x100.jpg 150w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-768x513.jpg 768w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g.jpg 1200w" sizes="(max-width: 749px) 100vw, 749px"><figcaption id="caption-attachment-165542">TCL NXTPAPER 10 5G</figcaption></figure><p>A TCL NXTPAPER 5G Android tablet with a 10.4 inch display currently <a href="https://fave.co/3MtxTqI" rel="nofollow">sells for $240 at Verizon</a>, making it pricier than an <a href="https://amzn.to/3AKts8d" rel="nofollow">Amazon Kindle Paperwhite</a>, but comparable to the list price for an <a href="https://amzn.to/3yOsA20" rel="nofollow">Amazon Fire Max 11</a>.</p><p>One of the more recent entries into this space is HannSpree‚Äôs <strong><a href="https://www.hannspree.eu/about-ecovision-paper-display/" rel="nofollow">ecoVISION Paper Display</a></strong> technology, which also offers ‚Äúfast, full-colour performance,‚Äù energy efficiency, and ‚Äútrue 8-bit, non-FRC, flicker-free, and low blue light features‚Äù that are said to ‚Äúhelp reduce eye strain.‚Äù</p><p>One of the first devices featuring this display has the <a href="https://www.hannspree.com/hannsnote2" rel="nofollow"><strong>Hannspree HannsNote 2</strong></a>.&nbsp; It‚Äôs a device that the company is positioning as an eReader, but it‚Äôs basically an Android tablet with a 10 inch, 1600 x 1200 pixel (200 ppi), 60 Hz display and USI 2.0 stylus support.</p><figure id="attachment_171438" aria-describedby="caption-attachment-171438"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171438">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>It also has a Rockchip RK3566 quad-core ARM Cortex-A55 processor, 4GB of RAM, 64GB of storage, and an Android 13-based operating system. The Google Play store comes pre-loaded.</p><p>Interestingly one thing the HannsNote 2 lacks? A front-light. It‚Äôs meant to be used&nbsp;<em>only</em> with ambient lighting, which should make it easy to use outdoors or in brightly lit rooms. But if you want to read in the dark you‚Äôll probably need a clip-on booklight.</p><p>The tablet doesn‚Äôt seem to be available for purchase in the US, but it‚Äôs sold in Europe <a href="https://fave.co/4dK2vjM" rel="nofollow">for about 315‚Ç¨</a>.</p><p><iframe loading="lazy" title="RLCD Color E-Paper Tablet: HannsNote 2 First Look" width="780" height="439" src="https://www.youtube.com/embed/0d7gc8xflHI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p><p>HannSpree has also announced plans to launch a series of ‚Äú<a href="https://www.prnewswire.com/news-releases/hannspree-unveils-ecovision-paper-display-at-ifa-2024-302233719.html" rel="nofollow">next-generation e-readers</a>‚Äù soon, with ecoVISION displays, Android 14 software, and 10 inch or 7.8 inch displays, as well as other products including a 23.8 inch monitor digital signage featuring up to a 28-inch ecoVISION display.</p><div id="custom_html-9"><p>Liliputing's primary sources of revenue are advertising and affiliate links (if you click the "<a target="_blank" rel="nofollow noopener" href="https://www.amazon.com/Best-Sellers-Computers-Accessories/zgbs/pc/ref=as_li_ss_tl?_encoding=UTF8&amp;linkCode=ll2&amp;tag=liliputing_shop-20&amp;linkId=93aaf7ba4e36ed56d46003558471548d">Shop</a>" button at the top of the page and buy something on Amazon, for example, we'll get a small commission).</p><p>But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping.</p><h3>Contribute to our <a href="https://www.patreon.com/bradlinder">Patreon campaign</a></h3><p> <em>or...</em></p><h3>Contribute via <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=PTBQ9EKAYTZBS&amp;source=url">PayPal</a></h3><p> * If you <em>are</em> using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a <a target="blank_" href="https://liliputing.com/2020/09/ublock-origin-how-to-hide-googles-script-blocking-warning-for-websites-using-funding-choices.html" rel="noopener">guide that may help you disable it.</a></p></div><div id="blog_subscription-2"><p> Join 9,573 other subscribers</p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Godot on iPad, Toolbars, Importers, Embedding, Debugger (161 pts)]]></title>
            <link>https://blog.la-terminal.net/godot-on-ipad-summer-update/</link>
            <guid>41415077</guid>
            <pubDate>Sun, 01 Sep 2024 07:50:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.la-terminal.net/godot-on-ipad-summer-update/">https://blog.la-terminal.net/godot-on-ipad-summer-update/</a>, See on <a href="https://news.ycombinator.com/item?id=41415077">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>This is a long-due update on porting Godot to the iPad. &nbsp;Shortly after my last blog post covering the development work on May 29th, Apple held its WWDC 2024 conference. &nbsp; I went into the conference with gusto, expecting to fully embrace all the iOS 18 APIs. I already knew by then that I would not complete the port before iOS 18 became widely available.</p><p>One thing I was not counting on was Apple releasing FinalCut Pro for the iPad, a professional video editing tool. It looked nice on the videos, but I did not expect it to be such a revelation from a UX perspective. While I have been following the Apple Human Interface Guidelines guidance and trying to mimic what other iPad system applications do, FinalCut Pro is packed with small details that have informed Godot for iPad ever since. &nbsp;&nbsp;</p><p>The app itself is glorious and a delight to use, and not being a user interface designer, I did not quite understand what made the app feel so good. &nbsp; A few things were more or less obvious like the Final Cut Pro controls for selecting values:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137064781_image.png" alt="" loading="lazy" width="640" height="334"><figcaption><span>FinalCut Pro's numeric input.</span></figcaption></figure><p>On the surface, this property editor felt better. Most edits can be done with your finger by dragging the value, and fine editing is possible by tapping on the number, which would bring a text editor. While I already had a little popup that would come up when editing a number, my editor defaulted to having a TextField, so it would always trigger the keyboard to pop up to edit.</p><p>I had completely missed the now obvious benefit of using a custom data entry popup, which was to avoid getting a system keyboard, one that has all sorts of letters and takes a large chunk of the screen, purely to enter numbers. It is obvious in retrospect, but it was not obvious when I was coding it.</p><p>I fell in love with these slide controls. The above one can edit values on a fixed range, but some editors would scroll, and I spent a few weeks reimplementing them and getting the behavior to match it; here are a few of them:</p><figure data-kg-thumbnail="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2.mp4" poster="https://img.spacergif.org/v1/672x900/0a/spacer.png" width="672" height="900" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:15</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>My new data entry controls, attempting to follow the FinalCut Pro idioms.</span></p></figcaption>
        <img src="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2_thumb.jpg"></figure><p>But beyond these very obvious changes, something more subtle was going on. &nbsp; This is what my test code for a potpourri of properties looked like before I looked at Final Cut Pro:</p><figure><img src="https://files.mastodon.social/media_attachments/files/112/754/487/057/645/000/original/666868d31af3e7e3.png" alt="" loading="lazy" width="732" height="2112"></figure><p>What made Final Cut Pro look so much better was a combination of things:</p><ul><li>Font sizes for sections, labels and values</li><li>Color scheme used for labels and values</li><li>Tasteful grouping and padding of elements</li><li>Removal of the&nbsp;‚Äúlock‚Äù&nbsp;icon for linked properties from this screen and moving them directly to the data input</li></ul><p>So I set out with Preview and the Digital Color meter to match the colors, font sizes and spacing of the property editors to improve this user experience, and within a few days, I had something that looked a little bit better:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137815878_image.png" alt="" loading="lazy" width="812" height="1600"></figure><p>And now, rather than using a popup to edit each value, I now offer an editor that can take care of all the grouped values at once - and the value linkage is now done entirely on this editor. &nbsp; Additionally, a description is shown at the top, plus a ‚ÄúReset‚Äù&nbsp;option, similar to Final Cut Pro:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137940198_image.png" alt="" loading="lazy" width="838" height="1362"></figure><p>Then, I noticed that FinalCut Pro did not shy away from nesting values to edit, where I would try to flatten everything out. &nbsp; Here, I had to come up with my idiom, as I expect that some users would not want to dig deeper into the hierarchy to edit values, so I allow users to&nbsp;‚Äúpin‚Äù&nbsp;a subgroup&nbsp;(I&nbsp;hijack Godot‚Äôs existing system for expanding a subtree for this):</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725138413447_image.png" alt="" loading="lazy" width="742" height="368"></figure><p>Tapping the pin button would put that subgroup in the container.</p><p>The work on the new controls and the polishing of the property editor took about a month. &nbsp; I think that it was a worthwhile investment to make the user interface better suited for touch. &nbsp; What surprised me was how big of an upgrade using the proper font sizes, hierarchy of colors and accents brought to the app.</p><p>Another upgrade I did to the inspector during the summer is supporting nested property editing. &nbsp; Once I embraced the FinalCut Pro approach of navigation for properties, it came naturally, and now you can edit those properties by simply tapping on the object as well as rendering previews of some properties. In this case, you can see the material for the mesh:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725144211229_image.png" alt="" loading="lazy" width="1156" height="2066"><figcaption><span>Resource Previews in the Inspector</span></figcaption></figure><h2 id="embedded-windows">Embedded Windows</h2><p>As I have shared over the past year, Godot on iPad is made up of the Godot engine embedded inside SwiftUI, and it started looking like this:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725139189530_image.png" alt="" loading="lazy" width="2728" height="2038"><figcaption><span>An older version of Godot on iPad, showing the underlying editor running.</span></figcaption></figure><p>An older version of Godot on iPad shows the underlying editor running.Above, you can see that Godot is still running in full screen, but with a few of the Godot pads removed on both sides. The center of the screen still contains the Godot tab-based scene selector, the toolbar, the per-view menu&nbsp;(itsays‚ÄúPerspective‚Äù), and the bottom bar, which contains various tools.</p><p>While this works, I wanted more control over what would be displayed here, so rather than lay things on top of Godot, I wanted to extract a view and fully control it. &nbsp; In my case, I wanted the editor's surface but none of the additional elements. &nbsp; In other cases, I wanted to embed some property controls directly into the property editor.</p><p>The Migeran team developed a set of Godot patches that allow me to do this embedding, and I am using them to revamp the user interface.</p><p>The first use was to re-host the top editor and the bottom bar directly and then control their display as a group. &nbsp; Then, I graduated to rehosting every single tap on the bottom bar so I could start incrementally rewriting each of those tabs into SwiftUI.</p><p>First, I replaced the Output Pad, which looks like this on the desktop:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725139592542_image.png" alt="" loading="lazy" width="1228" height="498"><figcaption><span>Godot Desktop Output Pad</span></figcaption></figure><p>With this version:</p><figure><img src="https://blog.la-terminal.net/content/images/2024/08/F6iVjkNQ.jpg" alt="" loading="lazy" width="2000" height="591" srcset="https://blog.la-terminal.net/content/images/size/w600/2024/08/F6iVjkNQ.jpg 600w, https://blog.la-terminal.net/content/images/size/w1000/2024/08/F6iVjkNQ.jpg 1000w, https://blog.la-terminal.net/content/images/size/w1600/2024/08/F6iVjkNQ.jpg 1600w, https://blog.la-terminal.net/content/images/2024/08/F6iVjkNQ.jpg 2000w" sizes="(min-width: 1200px) 1200px"><figcaption><span>Godot on iPad Output Pad</span></figcaption></figure><p>To avoid taking up a whole row for text filtering, I allow each tab to have an optional tool that can be displayed on the right side of the user interface, like in this case.</p><p>It also shows some inspiration taken from LogicPro, another one of Apple‚Äôs professional tools for the iPad. &nbsp; In this case, I have replaced a difficult-to-grab&nbsp;‚Äúsplitter‚Äù&nbsp;common in Godot with an explicit handle that the user can drag to grow the region, tap to expand, or dismiss with a flick.</p><p>Similarly, the native Godot debugger went on a user interface diet, as I do not have the space available:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725140554713_image.png" alt="" loading="lazy" width="1454" height="588"></figure><p>This time, I drew inspiration from Xcode and Swift Playgrounds. In this case, I collapsed the thread selector to one Picker that allows you to jump to different threads. The entire stack frames pane is also replaced by a single picker&nbsp;(here,showing&nbsp;hello:10), and the variables are shown on the left side, similar to Xcode. &nbsp;&nbsp;</p><p>Another Xcode-inspired idea is that the variables and the output live side by side and can be toggled on and on using the small controls at the bottom of the screen:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725140664442_image.png" alt="" loading="lazy" width="2092" height="752"></figure><p>The next big chunk of work this summer was to provide alternatives to the toolbars and menus used in Godot 3D and 2D editors. I started with the same principle: to be in control of those user interface elements and make them suitable for use on the iPad&nbsp;(and&nbsp;soon on the VisionPro). &nbsp;&nbsp;</p><p>Initially, I felt like I could use the embedding technology to reuse the menus as-is because they were tappable enough. &nbsp; But once I looked at them, I realized they were too busy, had very long lists of data, and would work poorly on the iPad. &nbsp; This shows a partial view of the various toolbar elements for the 3D editor and what they unfold to:</p><figure><img src="https://files.mastodon.social/media_attachments/files/112/883/661/063/563/770/original/24dcab2a69e9306b.png" alt="" loading="lazy" width="2004" height="2076"><figcaption><span>The Godot Menus and Options for the 3D editor</span></figcaption></figure><p>This is what the toolbar looks like now after the iPad-ification was done:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725141991249_image.png" alt="" loading="lazy" width="1248" height="730"></figure><p>I enjoyed turning a modal settings box for the Field of View, Near Clip Distance and Far Clip Distance into a live setting, so you can immediately see the changes happen. &nbsp; This view is still using the old sliders, but will soon be replaced with the new sliders that I cooked up.</p><p>Merging the six different viewport options into a single line saved plenty of vertical space, and merging those settings into the general-purpose settings and letting the user configure them there saved two icon slots on the toolbar for Light and Environment.</p><p>Had I designed this six months ago, I would have made the configuration for Light and Environment a long-press action on the light and environment buttons. But the more I use the app and the more professional apps I use on the iPad, I realize that long-press actions are useful for power users, but they are just not discoverable. I am being more mindful and considerate about my users by moving away from this idiom. &nbsp;Very demure.</p><p>And this is what I did with the per-view menus:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142140383_image.png" alt="" loading="lazy" width="1382" height="1036"></figure><p>I might add some icons to the labels, but these look fine to me now.</p><p>A similar exercise was necessary for the 2D surface:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142451978_image.png" alt="" loading="lazy" width="1630" height="774"></figure><p>It did not seem like I could re-host those user interface elements, it just did not feel right after the 3D user interface had gotten that big upgrade.</p><p>So this is what the 2D toolbar turned into:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142787835_image.png" alt="" loading="lazy" width="1150" height="720"></figure><p>My goal was to preserve all the features available in Godot and surface them in an iPad-friendly way without sacrificing any functionality. If I had telemetry for which features users were using, I could have left a few things out, but generally, I erred on the side of not leaving things out. &nbsp;&nbsp;</p><p>There are two small exceptions, and I made them only after reading the commit that introduced the feature and the discussion on the GitHub issue‚Äîthey looked like relatively fringe features that had little use. But hopefully, during the public TestFlight, folks will inform me if I made a mistake.</p><p>You can tell that I worked hard to preserve all the functionality but also organize the features in a way that would be simpler to find:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142810630_image.png" alt="" loading="lazy" width="1508" height="1056"></figure><p>You might have noticed the&nbsp;‚ÄúControl:&nbsp;Anchors‚Äù toolbar there. It turns out that I got more than I bargained for. Godot has additional&nbsp;‚Äútoolbars‚Äù&nbsp;that can be loaded into the toolbar depending on the object that you are editing, so I had to support not only the basics but also other custom toolbars. &nbsp;&nbsp;</p><p>As Godot allows scripts and extensions to add elements to the Toolbar, I am replacing the known element toolbars with my own. If I encounter one kind that I do not support, I will merely&nbsp;‚Äúre-host‚Äù&nbsp;the Godot-native control in the user interface.</p><p>That said, my goal is to cover all the popular toolbars from the start so that none of the native ones are exposed and to fall back to the embedded situation when necessary.</p><p>I feel like I can do slightly better organization of these properties for Godot on iPad because of the additional user interface elements available at my disposal, like the Picker above or the visual cues for grouping. &nbsp; This is a feeling that I got repeatedly during this exercise. The spectrum of tools available in SwiftUI gave me a richer vocabulary to express the capabilities than the controls that come with Godot - I hope to publish a list of&nbsp;‚Äúnice&nbsp;to haves‚Äù so the Godot folks can bring that into mainline Godot.</p><p>Lastly, I realized that the toolbars are taking some precious space on the user interface, and they might get in the way of your work. &nbsp; I remembered that Apple had a talk some years ago about&nbsp;‚Äú<a href="https://developer.apple.com/videos/play/wwdc2018/803/?ref=blog.la-terminal.net" rel="noreferrer nofollow noopener">Fluid</a><a href="https://developer.apple.com/videos/play/wwdc2018/803/?ref=blog.la-terminal.net" rel="noreferrer nofollow noopener">&nbsp;Interfaces</a>‚Äù that covered this scenario, for what they called the&nbsp;‚ÄúPicture&nbsp;in Picture View‚Äù. &nbsp; The description starts after minute 41 of the talk.</p><p>So I brought that user interface idiom to the toolbars, allowing users to&nbsp;‚Äúflick‚Äù&nbsp;the toolbar to one of the four corners of the user interface to get out of the way:</p><figure data-kg-thumbnail="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1.MP4" poster="https://img.spacergif.org/v1/1920x1342/0a/spacer.png" width="1920" height="1342" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:13</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>Moving the toolbar around</span></p></figcaption>
        <img src="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1_thumb.jpg"></figure><h2 id="other-work">Other Work</h2><p>Miroslav has been an invaluable partner in this SwiftUI adventure, and while he had initially just focused on the SwiftUI components, he has recently taken over rewriting many of the full-screen importers for Godot. &nbsp; We realized early on that some of the importers in Godot were great, but again, they would take up all the space and did not fit at all in the iPad, it was not even possible to reach all the elements of the UI.</p><p>He rewrote the Scene Importer and the Audio Importer, which were large projects on their own:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725146091645_image.png" alt="" loading="lazy" width="2388" height="1668"><figcaption><span>Scene Importer, the sidebar is closed.</span></figcaption></figure><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725146031864_image.png" alt="" loading="lazy" width="2388" height="1668"><figcaption><span>Audio Importer</span></figcaption></figure><h2 id="next-steps">Next Steps</h2><p>One thing that has been bothering me is how to activate/deactivate panels on such a small screen, and I had my share of poor man‚Äôs hacks. &nbsp; Logic Pro introduced me to an idiom&nbsp;(and&nbsp;while it is in FinalCut Pro, I was not paying enough attention to see it): small icons at the bottom of the screen. &nbsp; I spent the last week redoing my bottom bar to incorporate this idiom.</p><p>I lack a&nbsp;‚ÄúScene&nbsp;Switcher‚Äù&nbsp;(what&nbsp;Godot has in tabs). &nbsp;The way to switch scenes is to select the file directly, but that feels clunky, so that is next.</p><p>In addition to these two high-level topics, I have some fifty-nine other small bugs that need to be fixed before this is suitable for a TestFlight, and I hope to finalize those in September.&nbsp;</p><p>My hope is that while I collect feedback for this beta and fix bugs, I can look into integrating Apple Pencil support, spend some quality time on the touch interactions for it, and make sure that Godot on iPad really shines as a touch-first experience.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Founder Mode (856 pts)]]></title>
            <link>https://paulgraham.com/foundermode.html</link>
            <guid>41415023</guid>
            <pubDate>Sun, 01 Sep 2024 07:35:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/foundermode.html">https://paulgraham.com/foundermode.html</a>, See on <a href="https://news.ycombinator.com/item?id=41415023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/founder-mode-1.gif" width="118" height="18" alt="Founder Mode"><span size="2" face="verdana">September 2024<p>At a YC event last week Brian Chesky gave a talk that everyone who
was there will remember. Most founders I talked to afterward said
it was the best they'd ever heard. Ron Conway, for the first time
in his life, forgot to take notes. I'm not going to try to reproduce
it here. Instead I want to talk about a question it raised.</p><p>The theme of Brian's talk was that the conventional wisdom about
how to run larger companies is mistaken. As Airbnb grew, well-meaning
people advised him that he had to run the company in a certain way
for it to scale. Their advice could be optimistically summarized
as "hire good people and give them room to do their jobs." He
followed this advice and the results were disastrous. So he had to
figure out a better way on his own, which he did partly by studying
how Steve Jobs ran Apple. So far it seems to be working. Airbnb's
free cash flow margin is now among the best in Silicon Valley.</p><p>The audience at this event included a lot of the most successful
founders we've funded, and one after another said that the same
thing had happened to them. They'd been given the same advice about
how to run their companies as they grew, but instead of helping
their companies, it had damaged them.</p><p>Why was everyone telling these founders the wrong thing? That was
the big mystery to me. And after mulling it over for a bit I figured
out the answer: what they were being told was how to run a company
you hadn't founded ‚Äî how to run a company if you're merely a
professional manager. But this m.o. is so much less effective that
to founders it feels broken. There are things founders can do that
managers can't, and not doing them feels wrong to founders, because
it is.</p><p>In effect there are two different ways to run a company: founder
mode and manager mode. Till now most people even in Silicon Valley
have implicitly assumed that scaling a startup meant switching to
manager mode. But we can infer the existence of another mode from
the dismay of founders who've tried it, and the success of their
attempts to escape from it.</p><p>There are as far as I know no books specifically about founder mode.
Business schools don't know it exists. All we have so far are the
experiments of individual founders who've been figuring it out for
themselves. But now that we know what we're looking for, we can
search for it. I hope in a few years founder mode will be as well
understood as manager mode. We can already guess at some of the
ways it will differ.</p><p>The way managers are taught to run companies seems to be like modular
design in the sense that you treat subtrees of the org chart as
black boxes. You tell your direct reports what to do, and it's up
to them to figure out how. But you don't get involved in the details
of what they do. That would be micromanaging them, which is bad.</p><p>Hire good people and give them room to do their jobs. Sounds great
when it's described that way, doesn't it? Except in practice, judging
from the report of founder after founder, what this often turns out
to mean is: hire professional fakers and let them drive the company
into the ground.</p><p>One theme I noticed both in Brian's talk and when talking to founders
afterward was the idea of being gaslit. Founders feel like they're
being gaslit from both sides ‚Äî by the people telling them they
have to run their companies like managers, and by the people working
for them when they do. Usually when everyone around you disagrees
with you, your default assumption should be that you're mistaken.
But this is one of the rare exceptions. VCs who haven't been founders
themselves don't know how founders should run companies, and C-level
execs, as a class, include some of the most skillful liars in the
world.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>Whatever founder mode consists of, it's pretty clear that it's going
to break the principle that the CEO should engage with the company
only via his or her direct reports. "Skip-level" meetings will
become the norm instead of a practice so unusual that there's a
name for it. And once you abandon that constraint there are a huge
number of permutations to choose from.</p><p>For example, Steve Jobs used to run an annual retreat for what he
considered the 100 most important people at Apple, and these were
not the 100 people highest on the org chart. Can you imagine the
force of will it would take to do this at the average company? And
yet imagine how useful such a thing could be. It could make a big
company feel like a startup. Steve presumably wouldn't have kept
having these retreats if they didn't work. But I've never heard of
another company doing this. So is it a good idea, or a bad one? We
still don't know. That's how little we know about founder mode.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Obviously founders can't keep running a 2000 person company the way
they ran it when it had 20. There's going to have to be some amount
of delegation. Where the borders of autonomy end up, and how sharp
they are, will probably vary from company to company. They'll even
vary from time to time within the same company, as managers earn
trust. So founder mode will be more complicated than manager mode.
But it will also work better. We already know that from the examples
of individual founders groping their way toward it.</p><p>Indeed, another prediction I'll make about founder mode is that
once we figure out what it is, we'll find that a number of individual
founders were already most of the way there ‚Äî except that in doing
what they did they were regarded by many as eccentric or worse.
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>Curiously enough it's an encouraging thought that we still know so
little about founder mode. Look at what founders have achieved
already, and yet they've achieved this against a headwind of bad
advice. Imagine what they'll do once we can tell them how to run
their companies like Steve Jobs instead of John Sculley.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
The more diplomatic way of phrasing this statement would be
to say that experienced C-level execs are often very skilled at
managing up. And I don't think anyone with knowledge of this world
would dispute that.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
If the practice of having such retreats became so widespread
that even mature companies dominated by politics started to do it,
we could quantify the senescence of companies by the average depth
on the org chart of those invited.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
I also have another less optimistic prediction: as soon as
the concept of founder mode becomes established, people will start
misusing it. Founders who are unable to delegate even things they
should will use founder mode as the excuse. Or managers who aren't
founders will decide they should try act like founders. That may
even work, to some extent, but the results will be messy when it
doesn't; the modular approach does at least limit the damage a bad
CEO can do.<span color="888888"><b>Thanks</b> to Brian Chesky, Patrick Collison, 
Ron Conway, Jessica
Livingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan
for reading drafts of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playstation 2 GS emulation ‚Äì the final frontier of Vulkan compute emulation (197 pts)]]></title>
            <link>https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</link>
            <guid>41413662</guid>
            <pubDate>Sun, 01 Sep 2024 02:14:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/">https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</a>, See on <a href="https://news.ycombinator.com/item?id=41413662">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-754">
	
	<!-- .entry-header -->

	<div>
		<p>As you may, or may not know, I wrote paraLLEl-RDP back in 2020. It aimed at implementing the N64 RDP in Vulkan compute. Lightning fast, and extremely accurate, plus the added support of up-scaling on top. I‚Äôm quite happy how it turned out. Of course, the extreme accuracy was due to Angrylion being used as reference and I could aim for bit-exactness against that implementation.</p>
<p>Since then, there‚Äôs been the lingering idea of doing the same thing, but for PlayStation 2. Until now, there‚Äôs really only been one implementation in town, GSdx, which has remained the state-of-the-art for 20 years.</p>
<p><a href="https://github.com/Arntzen-Software/parallel-gs">paraLLEl-GS</a> is actually not the first compute implementation of the PS2 GS. An attempt was made back in 2014 for OpenCL as far as I recall, but it was never completed. At the very least, I cannot find it in the current upstream repo anymore.</p>
<p>The argument for doing compute shader raster on PS2 is certainly weaker than on N64. Angrylion was ‚Äì and is ‚Äì extremely slow, and N64 is extremely sensitive to accuracy where hardware acceleration with graphics APIs is impossible without serious compromises. PCSX2 on the other hand has a well-optimized software renderer, and a pretty solid graphics-based renderer, but that doesn‚Äôt mean there aren‚Äôt issues. The software renderer does not support up-scaling for example, and there are a myriad bugs and glitches with the graphics-based renderer, especially with up-scaling. As we‚Äôll see, the PS2 GS is quite the nightmare to emulate in its own way.</p>
<p>My main motivation here is basically ‚Äúbecause I can‚Äù. I already had a project lying around that did ‚Äúgeneric‚Äù compute shader rasterization. I figured that maybe we could retro-fit this to support PS2 rendering.</p>
<p>I didn‚Äôt work on this project alone. My colleague, Runar Heyer, helped out a great deal in the beginning to get this started, doing all the leg-work to study the PS2 from various resources, doing the initial prototype implementation and fleshing out the Vulkan GLSL to emulate PS2 shading. Eventually, we hit some serious roadblocks in debugging various games, and the project was put on ice for a while since I was too drained dealing with horrible D3D12 game debugging day in and day out. The last months haven‚Äôt been a constant fire fight, so I‚Äôve finally had the mental energy to finish it.</p>
<p>My understanding of the GS is mostly based on what Runar figured out, and what I‚Äôve seen by debugging games. The GSdx software renderer does not seem like it‚Äôs hardware bit-accurate, so we were constantly second-guessing things when trying to compare output. This caused a major problem when we had the idea of writing detailed tests that directly compared against GSdx software renderer, and the test-driven approach fell flat very quickly. As a result, paraLLEl-GS isn‚Äôt really aiming for bit-accuracy against hardware, but it tries hard to avoid obvious accuracy issues at the very least.</p>
<h2>Basic GS overview</h2>
<p>Again, this is based on my understanding, and it might not be correct. üòÄ</p>
<h3>GS is a pixel-pushing monster</h3>
<p>The GS is infamous for its insane fill-rate and bandwidth. It could push over a billion pixels per second (in theory at least) back in 2000 which was nuts. While the VRAM is quite small (4 MiB), it was designed to be continuously streamed into using the various DMA engines.</p>
<p>Given the extreme fill-rate requirements, we have to design our renderer accordingly.</p>
<h3>GS pixel pipeline is very basic, but quirky</h3>
<p>In many ways, the GS is actually simpler than N64 RDP. Single texture, and a single cycle combiner, where N64 had a two stage combiner + two stage blender. Whatever AA support is there is extremely basic as well, where N64 is delightfully esoteric. The parts of the pixel pipeline that is painful to implement with traditional graphics APIs is:</p>
<h4>Blending goes beyond 1.0</h4>
<p>Inherited from PS1, 0x80 is treated as 1.0, and it can go all the way up to 0xff (almost 2). Shifting by 7 is easier than dividing by 255 I suppose. I‚Äôve seen some extremely ugly workarounds in PCSX2 before to try working around this since UNORM formats cannot support this as is. Textures are similar, where alpha &gt; 1.0 is representable.</p>
<p>There is also wrapping logic that can be used for when colors or alpha goes above 0xFF.</p>
<h4>Destination alpha testing</h4>
<p>The destination alpha can be used as a pseudo-stencil of sorts, and this is extremely painful without programmable blending. I suspect this was added as PS1 compatibility, since PS1 also had this strange feature.</p>
<h4>Conditional blending</h4>
<p>Based on the alpha, it‚Äôs possible to conditionally disable blending. Quite awkward without programmable blending ‚Ä¶ This is another PS1 compat feature. With PS1, it can be emulated by rendering every primitive twice with state changes in-between, but this quickly gets impractical with PS2.</p>
<h4>Alpha correction</h4>
<p>Before alpha is written out, it‚Äôs possible to OR in the MSB. Essentially forcing alpha to 1. It is not equivalent to alphaToOne however, since it‚Äôs a bit-wise OR of the MSB.</p>
<h4>Alpha test can partially discard</h4>
<p>A fun thing alpha tests can do is to partially discard. E.g. you can discard just color, but keep the depth write. Quite nutty.</p>
<h4>AA1 ‚Äì coverage-to-alpha ‚Äì can control depth write per pixel</h4>
<p>This is also kinda awkward. The only anti-alias PS2 has is AA1 which is a coverage-to-alpha feature. Supposedly, less than 100% coverage should disable depth writes (and blending is enabled), but the GSdx software renderer behavior here is extremely puzzling. I don‚Äôt really understand it yet.</p>
<h4>32-bit fixed-point Z</h4>
<p>I‚Äôve still yet to see any games actually using this, but technically, it has D32_UINT support. Fun! From what I could grasp, GSdx software renderer implements this with FP64 (one of the many reasons I refuse to believe GSdx is bit-accurate), but FP64 is completely impractical on GPUs. When I have to, I‚Äôll implement this with fixed-point math. 24-bit Z and 16-bit should be fine with FP32 interpolation I think.</p>
<h4>Pray you have programmable blending</h4>
<p>If you‚Äôre on a pure TBDR GPU most of this is quite doable, but immediate mode desktop GPUs quickly degenerates into ROV or per-pixel barriers after every primitive to emulate programmable blending, both which are horrifying for performance. Of course, with compute we can make our own TBDR to bypass all this. üôÇ</p>
<h3>D3D9-style raster rules</h3>
<p>Primitives are fortunately provided in a plain form in clip-space. No awkward N64 edge equations here. The VU1 unit is supposed to do transforms and clipping, and emit various per-vertex attributes:</p>
<p>X/Y: 12.4 unsigned fixed-point<br>
Z: 24-bit or 32-bit uint<br>
FOG: 8-bit uint<br>
RGBA: 8-bit, for per-vertex lighting<br>
STQ: For perspective correct texturing with normalized coordinates. Q = 1 / w, S = s * Q, T = t * Q. Apparently the lower 8-bits of the mantissa are clipped away, so bfloat24? Q can be negative, which is always fun. No idea how this interacts with Inf and NaN ‚Ä¶<br>
UV: For non-perspective correct texturing. 12.4 fixed-point un-normalized.</p>
<ul>
<li>Triangles are top-left raster, just like modern GPUs.</li>
<li>Pixel center is on integer coordinate, just like D3D9. (This is a common design mistake that D3D10+ and GL/Vulkan avoids).</li>
<li>Lines use Bresenham‚Äôs algorithm, which is not really feasible to upscale, so we have to fudge it with rect or parallelogram.</li>
<li>Points snap to nearest pixel. Unsure which rounding is used though ‚Ä¶ There is no interpolation ala gl_PointCoord.</li>
<li>Sprites are simple quads with two coordinates. STQ or UV can be interpolated and it seems to assume non-rotated coordinates. To support rotation, you‚Äôd need 3 coordinates to disambiguate.</li>
</ul>
<p>All of this can be implemented fairly easily in normal graphics APIs, as long as we don‚Äôt consider upscaling. We have to rely on implementation details in GL and Vulkan, since these APIs don‚Äôt technically guarantee top-left raster rules.</p>
<p>Since X/Y is unsigned, there is an XY offset that can be applied to center the viewport where you want. This means the effective range of X/Y is +/- 4k pixels, a healthy guard band for 640√ó448 resolutions.</p>
<h3>Vertex queue</h3>
<p>The GS feels very much like old school OpenGL 1.0 with glVertex3f and friends. It even supports TRIANGLE_FAN! Amazing ‚Ä¶ RGBA, STQ and various registers are set, and every XYZ register write forms a vertex ‚Äúkick‚Äù which latches vertex state and advances the queue. An XYZ register write may also be a drawing kick, which draws a primitive if the vertex queue is sufficiently filled. The vertex queue is managed differently depending on the topology. The semantics here seem to be pretty straight forward where strip primitives shift the queue by one, and list primitives clear the queue. Triangle fans keep the first element in the queue.</p>
<h3>Fun swizzling formats</h3>
<p>A clever idea is that while rendering to 24-bit color or 24-bit depth, there is 8 bits left unused in the MSBs. You can place textures there, because why not. 8H, 4HL, 4HH formats support 8-bit and 4-bit palettes nicely.</p>
<p>Pixel coordinates on PS2 are arranged into ‚Äúpages‚Äù, which are 8 KiB, then subdivided into 32 blocks, and then, the smaller blocks are swizzled into a layout that fits well with a DDA-style renderer. E.g. for 32-bit RGBA, a page is 64√ó32 pixels, and 32 8√ó8 blocks are Z-order swizzled into that page.</p>
<h3>Framebuffer cache and texture cache</h3>
<p>There is a dedicated cache for framebuffer rendering and textures, one page‚Äôs worth. Games often abuse this to perform feedback loops, where they render on top of the pixels being sampled from. This is the root cause of extreme pain. N64 avoided this problem by having explicit copies into TMEM (and not really having the bandwidth to do elaborate feedback effects), and other consoles rendered to embedded SRAM (ala a tiler GPU), so these feedbacks aren‚Äôt as painful, but the GS is complete YOLO. Dealing with this gracefully is probably the biggest challenge. Combined with the PS2 being a bandwidth monster, developers knew how to take advantage of copious blending and blurring passes ‚Ä¶</p>
<h3>Texturing</h3>
<p>Texturing on the GS is both very familar, and arcane.</p>
<p>On the plus side, the texel-center is at half-pixel, just like modern APIs. It seems like it has 4-bit sub-texel precision instead of 8 however. This is easily solved with some rounding. It also seems to have floor-rounding instead of nearest-rounding for bi-linear.</p>
<p>The bi-linear filter is a normal bi-linear. No weird 3-point N64 filter here.</p>
<p>On the weirder side, there are two special addressing modes.</p>
<p>REGION_CLAMP supports an arbitrary clamp inside a texture atlas (wouldn‚Äôt this be nice in normal graphics APIs? :D). It also works with REPEAT, so you can have REPEAT semantics on border, but then clamp slightly into the next ‚Äúwrap‚Äù. This is trivial to emulate.</p>
<p>REGION_REPEAT is ‚Ä¶ worse. Here we can have custom bit-wise computation per coordinate. So something like u‚Äô = (u &amp; MASK) | FIX. This is done per-coordinate in bi-linear filtering, which is ‚Ä¶ painful, but solvable. This is another weird PS1 feature that was likely inherited for compatibility. At least on PS1, there was no bi-linear filtering to complicate things üôÇ</p>
<p>Mip-mapping is also somewhat curious. Rather than relying on derivatives, the log2 of interpolated Q factor, along with some scaling factors are used to compute the LOD. This is quite clever, but I haven‚Äôt really seen any games use it. The down-side is that triangle-setup becomes rather complex if you want to account for correct tri-linear filtering, and it cannot support e.g. anisotropic filtering, but this is 2000, who cares! Not relying on derivatives is a huge boon for the compute implementation.</p>
<p>Formats are always ‚Äúnormalized‚Äù to RGBA8_UNORM. 5551 format is expanded to 8888 without bit-replication. There is no RGBA4444 format.</p>
<p>It‚Äôs quite feasible to implement the texturing with plain bindless.</p>
<h3>CLUT</h3>
<p>This is a 1 KiB cache that holds the current palette. There is an explicit copy step from VRAM into that CLUT cache before it can be used. Why hello there, N64 TMEM!</p>
<p>The CLUT is organized such that it can hold one full 256 color palette in 32-bit colors. On the other end, it can hold 32 palettes of 16 colors at 16 bpp.</p>
<h3>TEXFLUSH</h3>
<p>There is an explicit command that functions like a ‚Äúsync and invalidate texture cache‚Äù. In the beginning I was hoping to rely on this to guide the hazard tracking, but oh how naive I was. In the end, I simply had to ignore TEXFLUSH. Basically, there are two styles of caching we could take with GS.</p>
<p>With ‚Äúmaximal‚Äù caching, we can assume that frame buffer caches and texture caches are infinitely large. The only way a hazard needs to be considered is after an explicit flush. This ‚Ä¶ breaks hard. Either games forget to use TEXFLUSH (because it happened to work on real hardware), or they TEXFLUSH way too much.</p>
<p>With ‚Äúminimal‚Äù caching, we assume there is no caching and hazards are tracked directly. Some edge case handling is considered for feedback loops.</p>
<p>I went with ‚Äúminimal‚Äù, and I believe GSdx did too.</p>
<h3>Poking registers with style ‚Äì GIF</h3>
<p>The way to interact with the GS hardware is through the GIF, which is basically a unit that reads data and pokes the correct hardware registers. At the start of a GIF packet, there is a header which configures which registers should be written to, and how many ‚Äúloops‚Äù there are. This maps very well to mesh rendering. We can consider something like one ‚Äúloop‚Äù being:</p>
<ul>
<li>Write RGBA vertex color</li>
<li>Write texture coordinate</li>
<li>Write position with draw kick</li>
</ul>
<p>And if we have 300 vertices to render, we‚Äôd use 300 loops. State registers can be poked through the Address + Data pair, which just encodes target register + 64-bit payload. It‚Äôs possible to render this way too of course, but it‚Äôs just inefficient.</p>
<p>Textures are uploaded through the same mechanism. Various state registers are written to set up transfer destinations, formats, etc, and a special register is nudged to transfer 64-bit at a time to VRAM.</p>
<h2>Hello Trongle ‚Äì GS</h2>
<p>If you missed the brain-dead simplicity of OpenGL 1.0, this is the API for you! üòÄ</p>
<p>For testing purposes, I added a tool to generate a .gs dump format that PCSX2 can consume. This is handy for comparing implementation behavior.</p>
<p>First, we program the frame buffer and scissor:</p>
<pre>TESTBits test = {};
test.ZTE = TESTBits::ZTE_ENABLED;
test.ZTST = TESTBits::ZTST_GREATER; // Inverse Z, LESS is not supported.
iface.write_register(RegisterAddr::TEST_1, test);

FRAMEBits frame = {};
frame.FBP = 0x0 / PAGE_ALIGNMENT_BYTES;
frame.PSM = PSMCT32;
frame.FBW = 640 / BUFFER_WIDTH_SCALE;
iface.write_register(RegisterAddr::FRAME_1, frame);

ZBUFBits zbuf = {};
zbuf.ZMSK = 0; // Enable Z-write
zbuf.ZBP = 0x118000 / PAGE_ALIGNMENT_BYTES;
iface.write_register(RegisterAddr::ZBUF_1, zbuf);

SCISSORBits scissor = {};
scissor.SCAX0 = 0;
scissor.SCAY0 = 0;
scissor.SCAX1 = 640 - 1;
scissor.SCAY1 = 448 - 1;
iface.write_register(RegisterAddr::SCISSOR_1, scissor);</pre>
<p>Then we nudge some registers to draw:</p>
<pre>struct Vertex
{
    PackedRGBAQBits rgbaq;
    PackedXYZBits xyz;
} vertices[3] = {};

for (auto &amp;vert : vertices)
{
   vert.rgbaq.A = 0x80;
   vert.xyz.Z = 1;
}

vertices[0].rgbaq.R = 0xff;
vertices[1].rgbaq.G = 0xff;
vertices[2].rgbaq.B = 0xff;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.X = p2.x &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.Y = p2.y &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 0; // Turn off texturing.
prim.IIP = 1; // Interpolate RGBA (Gouraud shading)
prim.PRIM = int(PRIMType::TriangleList);

static const GIFAddr addr[] = { GIFAddr::RGBAQ, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>This draws a triangle. We provide coordinates directly in screen-space.</p>
<p>And finally, we need to program the CRTC. Most of this is just copy-pasta from whatever games tend to do.</p>
<pre>auto &amp;priv = iface.get_priv_register_state();

priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_ALP;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0x0;
priv.bgcolor.G = 0x0;
priv.bgcolor.B = 0x0;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.pmode.ALP = 0xff;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;

dump.write_vsync(0, iface);
dump.write_vsync(1, iface);</pre>
<p>When the GS is dumped, we can load it up in PCSX2 and voila:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png"><img fetchpriority="high" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>And here‚Äôs the same .gs dump is played through parallel-gs-replayer with RenderDoc. For debugging, I‚Äôve spent a lot of time making it reasonably convenient. The images are debug storage images where I can store before and after color, depth, debug values for interpolants, depth testing state, etc, etc. It‚Äôs super handy to narrow down problem cases. The render pass can be split into 1 or more triangle chunks as needed.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png" alt="" width="660" height="384" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-300x175.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-768x447.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1536x894.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-2048x1192.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To add some textures, and flex the capabilities of the CRTC a bit, we can try uploading a texture:</p>
<pre>int chan;
auto *buf = stbi_load("/tmp/test.png", &amp;w, &amp;h, &amp;chan, 4);
iface.write_image_upload(0x300000, PSMCT32, w, h, buf,
                         w * h * sizeof(uint32_t));
stbi_image_free(buf);

TEX0Bits tex0 = {};
tex0.PSM = PSMCT32;
tex0.TBP0 = 0x300000 / BLOCK_ALIGNMENT_BYTES;
tex0.TBW = (w + BUFFER_WIDTH_SCALE - 1) / BUFFER_WIDTH_SCALE;
tex0.TW = Util::floor_log2(w - 1) + 1;
tex0.TH = Util::floor_log2(h - 1) + 1;
tex0.TFX = COMBINER_DECAL;
tex0.TCC = 1; // Use texture alpha as blend alpha
iface.write_register(RegisterAddr::TEX0_1, tex0);

TEX1Bits tex1 = {};
tex1.MMIN = TEX1Bits::LINEAR;
tex1.MMAG = TEX1Bits::LINEAR;
iface.write_register(RegisterAddr::TEX1_1, tex1);

CLAMPBits clamp = {};
clamp.WMS = CLAMPBits::REGION_CLAMP;
clamp.WMT = CLAMPBits::REGION_CLAMP;
clamp.MINU = 0;
clamp.MAXU = w - 1;
clamp.MINV = 0;
clamp.MAXV = h - 1;
iface.write_register(RegisterAddr::CLAMP_1, clamp);</pre>
<p>While PS2 requires POT sizes for textures, REGION_CLAMP is handy for NPOT. Super useful for texture atlases.</p>
<pre>struct Vertex
{
    PackedUVBits uv;
    PackedXYZBits xyz;
} vertices[2] = {};

for (auto &amp;vert : vertices)
    vert.xyz.Z = 1;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.U = w &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.V = h &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 1; // Turn on texturing.
prim.IIP = 0;
prim.FST = 1; // Use unnormalized coordinates.
prim.PRIM = int(PRIMType::Sprite);

static const GIFAddr addr[] = { GIFAddr::UV, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>Here we render a sprite with un-normalized coordinates.</p>
<p>Finally, we use the CRTC to do blending against white background.</p>
<pre>priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_CIRCUIT1;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0xff;
priv.bgcolor.G = 0xff;
priv.bgcolor.B = 0xff;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;</pre>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/vk.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png" alt="" width="660" height="380" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-300x173.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-768x443.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-1536x886.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/vk.png 2005w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Glorious 256√ó179 logo üòÄ</p>
<h2>Implementation details</h2>
<h3>The rendering pipeline</h3>
<p>Before we get into the page tracker, it‚Äôs useful to define a rendering pipeline where synchronization is implied between each stage.</p>
<ul>
<li>Synchronize CPU copy of VRAM to GPU. This is mostly unused, but happens for save state load, or similar</li>
<li>Upload data to VRAM (or perform local-to-local copy)</li>
<li>Update CLUT cache from VRAM</li>
<li>Unswizzle VRAM into VkImages that can be sampled directly, and handle palettes as needed, sampling from CLUT cache</li>
<li>Perform rendering</li>
<li>Synchronize GPU copy of VRAM back to CPU. This will be useful for readbacks. Then CPU should be able to unswizzle directly from a HOST_CACHED_BIT buffer as needed</li>
</ul>
<p>This pipeline matches what we expect a game to do over and over:</p>
<ul>
<li>Upload texture to VRAM</li>
<li>Upload palette to VRAM</li>
<li>Update CLUT cache</li>
<li>Draw with texture
<ul>
<li>Trigger unswizzle from VRAM into VkImage if needed</li>
<li>Begins building a ‚Äúrender pass‚Äù, a batch of primitives</li>
</ul>
</li>
</ul>
<p>When there are no backwards hazards here, we can happily keep batching and defer any synchronization. This is critical to get any performance out of this style of renderer.</p>
<p>Some common hazards here include:</p>
<h4>Copy to VRAM which was already written by copy</h4>
<p>This is often a false positive, but we cannot track per-byte. This becomes a simple copy barrier and we move on.</p>
<h4>Copy to VRAM where a texture was sampled from, or CLUT cache read from</h4>
<p>Since the GS has a tiny 4 MiB VRAM, it‚Äôs very common that textures are continuously streamed in, sampled from, and thrown away. When this is detected, we have to submit all vram copy work, all texture unswizzle work and then begin a new batch. Primitive batches are not disrupted.</p>
<p>This means we‚Äôll often see:</p>
<ul>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Rendering</li>
</ul>
<h4>Sample texture that was rendered to</h4>
<p>Similar, but here we need to flush out everything. This basically breaks the render pass and we start another one. Too many of these is problematic for performance obviously.</p>
<h4>Copy to VRAM where rendering happened</h4>
<p>Basically same as sampling textures, this is a full flush.</p>
<p>Other hazards are ignored, since they are implicitly handled by our pipeline.</p>
<h3>Page tracker</h3>
<p>Arguably, the hardest part of GS emulation is dealing with hazards. VRAM is read and written to with reckless abandon and any potential read-after-write or write-after-write hazard needs to be dealt with. We cannot rely on any game doing this for us, since PS2 GS just deals with sync in most cases, and TEXFLUSH is the only real command games will use (or forget to use).</p>
<p>Tracking per byte is ridiculous, so my solution is to first subdivide the 4 MiB VRAM into pages. A page is the unit for frame buffers and depth buffers, so it is the most meaningful place to start.</p>
<h4>PageState</h4>
<p>On page granularity, we track:</p>
<ul>
<li>Pending frame buffer write?</li>
<li>Pending frame buffer read? (read-only depth)</li>
</ul>
<p>Textures and VRAM copies have 256 byte alignment, and to avoid a ton of false positives, we need to track on a per-block basis. There are 32 blocks per page, so a u32 bit-mask is okay.</p>
<ul>
<li>VRAM copy writes</li>
<li>VRAM copy reads</li>
<li>Pending read into CLUT cache or VkImage</li>
<li>Blocks which have been clobbered by any write, on next texture cache invalidate, throw away images that overlap</li>
</ul>
<p>As mentioned earlier, there are also cases where you can render to 24-bit color, while sampling from the upper 8-bits without hazard. We need to optimize for that case too, so there is also:</p>
<ul>
<li>A write mask for framebuffers</li>
<li>A read mask for textures</li>
</ul>
<p>In the example above, FB write mask is 0xffffff and texture cache mask is 0xff000000. No overlap, no invalidate üòÄ</p>
<p>For host access, there are also timeline semaphore values per page. These values state which sync point to wait for if the host desires mapped read or mapped write access. Mapped write access may require more sync than mapped read if there are pending reads on that page.</p>
<h4>Caching textures</h4>
<p>Every page contains a list of VkImages which have been associated with it. When a page‚Äôs textures has been invalidated, the image is destroyed and has to be unswizzled again from VRAM.</p>
<p>There is a one-to-many relationship with textures and pages. A texture may span more than one page, and it‚Äôs enough that only one page is clobbered before the texture is invalidated.</p>
<p>Overall, there are a lot of micro-details here, but the important things to note here is that conservative and simple tracking will not work on PS2 games. Tracking at a 256 byte block level and considering write/read masks is critical.</p>
<h4>Special cases</h4>
<p>There are various situations where we may have false positives due to how textures work. Since textures are POT sized, it‚Äôs fairly common for e.g. a 512√ó448 texture of a render target to be programmed as a 512√ó512 texture. The unused region should ideally be clamped out with REGION_CLAMP, but most games don‚Äôt. A render target might occupy those unused pages. As long as the game‚Äôs UV coordinates don‚Äôt extend into the unused red zone, there are no hazards, but this is very painful to track. We would have to analyze every single primitive to detect if it‚Äôs sampling into the red zone.</p>
<p>As a workaround, we ignore any potential hazard in that red zone, and just pray that a game isn‚Äôt somehow relying on ridiculous spooky-action-at-a-distance hazards to work in the game‚Äôs favor.</p>
<p>There are more spicy special cases, especially with texture sampling feedback, but that will be for later.</p>
<h3>Updating CLUT in a batched way</h3>
<p>Since we want to batch texture uploads, we have to batch CLUT uploads too. To make this work, we have 1024 copies of CLUT, a ring buffer of snapshots.</p>
<p>One workgroup loops through the updates and writes them to an SSBO. I did a similar thing for N64 RDP‚Äôs TMEM update, where TMEM was instanced. Fortunately, CLUT update is <strong>far</strong> simpler than TMEM update.</p>
<pre>shared uint tmp_clut[512];

// ...

// Copy from previous instance to allow a
// CLUT entry to be partially overwritten and used later
uint read_index = registers.read_index * CLUT_SIZE_16;
tmp_clut[gl_LocalInvocationIndex] =
    uint(clut16.data[read_index]);
tmp_clut[gl_LocalInvocationIndex + 256u] =
    uint(clut16.data[read_index + 256u]);
barrier();

for (uint i = 0; i &lt; registers.clut_count; i++)
{
  // ...
  if (active_lane)
  {
    // update tmp_clut. If 256 color, all threads participate.
    // 16 color update is a partial update.
  }

  // Flush current CLUT state to SSBO.
  barrier();
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex]);
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16 + 256u] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex + 256u]);
  barrier();
}</pre>
<p>One potential optimization is that for 256 color / 32 bpp updates, we can parallelize the CLUT update, since nothing from previous iterations will be preserved, but the CLUT update time is tiny anyway.</p>
<h3>Unswizzling textures from VRAM</h3>
<p>Since this is Vulkan, we can just allocate a new VkImage, suballocate it from VkDeviceMemory and blast it with a compute shader.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/upload.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Using Vulkan‚Äôs specialization constants, we specialize the texture format and all the swizzling logic becomes straight forward code.</p>
<p>REGION_REPEAT shenanigans is also resolved here, so that the ubershader doesn‚Äôt have to consider that case and do manual bilinear filtering.</p>
<p>Even for render targets, we roundtrip through the VRAM SSBO. There is not really a point going to the length of trying to forward render targets into textures. Way too many bugs to squash and edge cases to think about.</p>
<h3>Triangle setup and binning</h3>
<p>Like paraLLEl-RDP, paraLLEl-GS is a tile-based renderer. Before binning can happen, we need triangle setup. As inputs, we provide attributes in three arrays.</p>
<h5>Position</h5>
<pre>struct VertexPosition
{
  ivec2 pos;
  float z;     // TODO: Should be uint for 32-bit Z.
  int padding; // Free real-estate?
};</pre>
<h5>Per-Vertex attributes</h5>
<pre>struct VertexAttribute
{
  vec2 st;
  float q;
  uint rgba; // unpackUnorm4x8
  float fog; // overkill, but would be padding anyway
  u16vec2 uv;
};</pre>
<h5>Per-primitive attributes</h5>
<pre>struct PrimitiveAttribute
{
  i16vec4 bb; // Scissor
  // Index into state UBO, as well as misc state bits.
  uint state;
  // Texture state which should be scalarized. Affects code paths.
  // Also holds the texture index (for bindless).
  uint tex;
  // Texture state like lod scaling factors, etc.
  // Does not affect code paths.
  uint tex2;  
  uint alpha; // AFIX / AREF
  uint fbmsk;
  uint fogcol;
};</pre>
<p>For rasterization, we have a straight forward barycentric-based rasterizer. It is heavily inspired by <a href="https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/">https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/</a>, which in turn is based on <a href="https://www.cs.drexel.edu/~david/Classes/Papers/comp175-06-pineda.pdf">A Parallel Algorithm for Polygon Rasterization (Paneda, 1988)</a> and describes the ‚Äústandard‚Äù way to write a rasterizer with parallel hardware. Of course, the PS2 GS is DDA, i.e. a scanline rasterizer, but in practice, this is just a question of nudging ULPs of precision, and since I‚Äôm not aware of a bit-exact description of the GS‚Äôs DDA, this is fine. paraLLEl-RDP implements the raw DDA form for example. It‚Äôs certainly possible if we <strong>have</strong> to.</p>
<p>As an extension to a straight-forward triangle rasterizer, I also need to support parallelograms. This is used to implement wide-lines and sprites. Especially wide-line is kinda questionable, but I‚Äôm not sure it‚Äôs possible to fully solve up-scaling + Bresenham in the general case. At least I haven‚Äôt run into a case where this really matters.</p>
<p>Evaluating coverage and barycentric I/J turns into something like this:</p>
<pre>bool evaluate_coverage_single(PrimitiveSetup setup,
  bool parallelogram, 
  ivec2 parallelogram_offset,
  ivec2 coord, inout float i, inout float j)
{
  int a = idot3(setup.a, coord);
  int b = idot3(setup.b, coord);
  int c = idot3(setup.c, coord);

  precise float i_result = float(b) * setup.inv_area + setup.error_i;
  precise float j_result = float(c) * setup.inv_area + setup.error_j;
  i = i_result;
  j = j_result;

  if (parallelogram &amp;&amp; a.x &lt; 0)
  {
    b += a + parallelogram_offset.x;
    c += a + parallelogram_offset.y;
    a = 0;
  }

  return all(greaterThanEqual(ivec3(a, b, c), ivec3(0)));
}</pre>
<p>inv_area is computed in a custom fixed-point RCP, which is ~24.0 bit accurate. Using the standard GPU RCP would be bad since it‚Äôs just ~22.5 bit accurate and not consistent across implementations. There is no reason to skimp on reproducibility and accuracy, since we‚Äôre not doing work per-pixel.</p>
<p>error_i and error_j terms are caused by the downsampling of the edge equations and tie-break rules. As a side effect of the GS‚Äôs [-4k, +4k] pixel range, the range of the cross-product requires 33-bit in signed integers. By downsampling a bit, we can get 32-bit integer math to work just fine with 8 sub-pixel accuracy for super-sampling / multi-sampling. Theoretically, this means our upper up-sampling limit is 8√ó8, but that‚Äôs ridiculous anyway, so we‚Äôre good here.</p>
<p>The parallelogram offsets are very small numbers meant to nudge the tie-break rules in our favor as needed. The exact details of the implementation escape me. I wrote that code years ago. It‚Äôs not very hard to derive however.</p>
<p>Every primitive gets a struct of transformed attributes as well. This is only read if we actually end up shading a primitive, so it‚Äôs important to keep this separate to avoid polluting caches with too much garbage.</p>
<pre>struct TransformedAttributes
{
  vec4 stqf0;
  vec4 stqf1;
  vec4 stqf2;
  uint rgba0;
  uint rgba1;
  uint rgba2;
  uint padding;
  vec4 st_bb;
};</pre>
<p>Using I/J like this will lead to small inaccuracies when interpolating primitives which expect to land exactly on the top-left corner of a texel with NEAREST filtering. To combat this, a tiny epsilon offset is used when snapping texture coordinates. Very YOLO, but what can you do. As far as I know, hardware behavior is sub-texel floor, not sub-texel round.</p>
<pre>precise vec2 uv_1 = uv * scale_1;

// Want a soft-floor here, not round behavior.
const float UV_EPSILON_PRE_SNAP = 1.0 / 16.0;
// We need to bias less than 1 / 512th texel, so that linear filter will RTE to correct subpixel.
// This is a 1 / 1024th pixel bias to counter-act any non-POT inv_scale_1 causing a round-down event.
const float UV_EPSILON_POST_SNAP = 16.0 / 1024.0;

if (sampler_clamp_s)
  uv_1.x = texture_clamp(uv_1.x, region_coords.xz, LOD_1);
if (sampler_clamp_t)
  uv_1.y = texture_clamp(uv_1.y, region_coords.yw, LOD_1);

// Avoid micro-precision issues with UV and flooring + nearest.
// Exact rounding on hardware is somwhat unclear.
// SotC requires exact rounding precision and is hit particularly bad.
// If the epsilon is too high, then FF X save screen is screwed over,
// so ... uh, ye.
// We likely need a more principled approach that is actually HW accurate in fixed point.
uv_1 = (floor(uv_1 * 16.0 + UV_EPSILON_PRE_SNAP) + UV_EPSILON_POST_SNAP) *
       inv_scale_1 * 0.0625;</pre>
<h3>Binning</h3>
<p>This is mostly uninteresting. Every NxN pixel block gets an array of u16 primitive indices to shade. This makes the maximum number of primitives per render pass 64k, but that‚Äôs enough for PS2 games. Most games I‚Äôve seen so far tend to be between 10k and 30k primitives for the ‚Äúmain‚Äù render pass, but I haven‚Äôt tested the real juggernauts of primitive grunt yet, but even so, having to do a little bit of incremental rendering isn‚Äôt a big deal.</p>
<p>NxN is usually 32√ó32, but it can be dynamically changed depending on how heavy the geometry load is. For large resolutions and high primitive counts, the binning and memory cost is unacceptable if the resolution is just 16√ó16 for example. One subgroup is responsible for iterating through all primitives in a block.</p>
<p>Since binning and triangle is state-less, triangle-setup and binning for back-to-back passes are batched up nicely to avoid lots of silly barriers.</p>
<h3>The ubershader</h3>
<p>A key difference between N64 and PS2 is fill-rate and per-pixel complexity. For N64, the ideal approach is to specialize the rasterizing shader, write out per-pixel color + depth + coverage + etc, then merge that data in a much simpler ubershader that only needs to consider depth and blend state rather than full texturing state and combiner state. This is very bandwidth intensive on the GPU, but the alternative is the slowest ubershader written by man. We‚Äôre saved by the fact that N64 fill-rate is abysmal. <a href="https://www.youtube.com/watch?v=GC_jLsxZ7nw">Check out this video by Kaze to see how horrible it is</a>.</p>
<p>The GS is a quite different beast. Fill-rate is very high, and per-pixel complexity is fairly low, so a pure ubershader is viable. We can also rely on bindless this time around too, so texturing complexity becomes a fraction of what I had to deal with on N64.</p>
<h4>Fine-grained binning</h4>
<p>Every tile is 4√ó4, 4√ó8 and 8√ó8 for subgroup sizes 16, 32 and 64 respectively. For super-sampling it‚Äôs even smaller (it‚Äôs 4√ó4 / 4√ó8 / 8√ó8 in the higher resolution domain instead).</p>
<p>In the outer loop, we pull in up to SubgroupSize‚Äôs worth of primitives, and bin them in parallel.</p>
<pre>for (int i = 0; i &lt; tile.coarse_primitive_count;
     i += int(gl_SubgroupSize))
{
  int prim_index = i + int(gl_SubgroupInvocationID);
  bool is_last_iteration = i + int(gl_SubgroupSize) &gt;= 
                           tile.coarse_primitive_count;

  // Bin primitives to tile.
  bool binned_to_tile = false;
  uint bin_primitive_index;
  if (prim_index &lt; tile.coarse_primitive_count)
  {
    bin_primitive_index = 
      uint(coarse_primitive_list.data[
           tile.coarse_primitive_list_offset + prim_index]);
    binned_to_tile = primitive_intersects_tile(bin_primitive_index);
  }

  // Iterate per binned primitive, do per pixel work now.
  // Scalar loop.
  uvec4 work_ballot = subgroupBallot(binned_to_tile);</pre>
<p>In the inner loop, we can do a scalarized loop which checks coverage per-pixel, one primitive at a time.</p>
<pre>// Scalar data
uint bit = subgroupBallotFindLSB(work_ballot);

if (gl_SubgroupSize == 64)
{
  if (bit &gt;= 32)
    work_ballot.y &amp;= work_ballot.y - 1;
  else
    work_ballot.x &amp;= work_ballot.x - 1;
}
else
{
  work_ballot.x &amp;= work_ballot.x - 1;
}

shade_primitive_index = subgroupShuffle(bin_primitive_index, bit);</pre>
<h4>Early Z</h4>
<p>We can take advantage of early-Z testing of course, but we have to be careful if there are rasterized pixels we haven‚Äôt resolved yet, and there are Z-writes in flight. In this case we have to defer to late Z to perform test.</p>
<pre>// We might have to remove opaque flag.
bool pending_z_write_can_affect_result =
  (pixel.request.z_test || !pixel.request.z_write) &amp;&amp;
  pending_shade_request.z_write;

if (pending_z_write_can_affect_result)
{
  // Demote the pixel to late-Z,
  // it's no longer opaque and we cannot discard earlier pixels.
  // We need to somehow observe the previous results.
  pixel.opaque = false;
}</pre>
<h4>Deferred on-tile shading</h4>
<p>Since we‚Äôre an uber-shader, all pixels are ‚Äúon-chip‚Äù, i.e. in registers, so we can take advantage of culling pixels that won‚Äôt be visible anyway. The basic idea here is that after rasterization, if a pixel is considered opaque, it will simply replace the shading request that exists for that framebuffer coordinate. It won‚Äôt be visible at all anyway.</p>
<h4>Lazy pixel shading</h4>
<p>We only need to perform shading when we really have to, i.e., we‚Äôre shading a pixel that depends on the previous pixel‚Äôs results. This can happen for e.g. alpha test (if test fails, we preserve existing data), color write masks, or of course, alpha blending.</p>
<p>If our pixel remains opaque, we can just kill the pending pixel shade request. Very nice indeed. The gain here wasn‚Äôt as amazing as I had hoped since PS2 games love blending, but it helps culling out a lot of shading work.</p>
<pre>if (pixel.request.coverage &gt; 0)
{
  need_flush = !pixel.opaque &amp;&amp; pending_shade_request.coverage &gt; 0;

  // If there is no hazard, we can overwrite the pending pixel.
  // If not, defer the update until we run a loop iteration.
  if (!need_flush)
  {
    set_pending_shade_request(pixel.request, shade_primitive_index);
    pixel.request.coverage = 0;
    pixel.request.z_write = false;
  }
}</pre>
<p>If we have flushes that need to happen, we do so if one pixel needs it. It‚Äôs just as fast to resolve all pixels anyway.</p>
<pre>// Scalar branch
if (subgroupAny(need_flush))
{
  shade_resolve();
  if (has_work &amp;&amp; pixel.request.coverage &gt; 0)
    set_pending_shade_request(pixel.request, shade_primitive_index);
}</pre>
<p>The resolve is a straight forward waterfall loop that stays in uniform control flow to be well defined on devices without maximal reconvergence support.</p>
<pre>while (subgroupAny(has_work))
{
  if (has_work)
  {
    uint state_index =
      subgroupBroadcastFirst(pending_shade_request.state);
    uint tex = subgroupBroadcastFirst(prim_tex);
    if (state_index == pending_shade_request.state &amp;&amp; prim_tex == tex)
    {
      has_work = false;
      shade_resolve(pending_primitive_index, state_index, tex);
    }
  }
}</pre>
<p>This scalarization ensures that all branches on things like alpha test mode, blend modes, etc, are purely scalar, and GPUs like that. Scalarizing on the texture index is technically not that critical, but it means we end up hitting the same branches for filtering modes, UBOs for scaling factors are loaded uniformly, etc.</p>
<p>When everything is done, the resulting framebuffer color and depth is written out to SSBO. GPU bandwidth is kept to a minimum, just like a normal TBDR renderer.</p>
<h3>Super-sampling</h3>
<p>Just implementing single sampled rendering isn‚Äôt enough for this renderer to be really useful. The software renderer is certainly quite fast, but not fast enough to keep up with intense super-sampling. We can fix that now.</p>
<p>For e.g. 8x SSAA, we keep 10 versions of VRAM on the GPU.</p>
<ul>
<li>1 copy represents the single-sampled VRAM. It is super-sampled.</li>
<li>1 copy represents the reference value for single-sampled VRAM. This allows us to track when we should discard the super-samples and splat the single sample to all. This can happen if someone copies to VRAM over a render target for whatever reason.</li>
<li>8 copies which each represent the super-samples. Technically, we can reconstruct a higher resolution image from these samples if we really want to, but only the CRTC could easily do that.</li>
</ul>
<p>When rendering super-sampled, we load the single-sampled VRAM and reference. If they match, we load the super-sampled version. This is important for cases where we‚Äôre doing incremental rendering.</p>
<p>On tile completion we use clustered subgroup ops to do multi-sample resolve, then write out the super-samples, and the two single-sampled copies.</p>
<pre>uvec4 ballot_color = subgroupBallot(fb_color_dirty);
uvec4 ballot_depth = subgroupBallot(fb_depth_dirty);

// No need to mask, we only care about valid ballot for the
// first sample we write-back.
if (NUM_SAMPLES &gt;= 16)
{
  ballot_color |= ballot_color &gt;&gt; 8u;
  ballot_depth |= ballot_depth &gt;&gt; 8u;
}

if (NUM_SAMPLES &gt;= 8)
{
  ballot_color |= ballot_color &gt;&gt; 4u;
  ballot_depth |= ballot_depth &gt;&gt; 4u;
}

if (NUM_SAMPLES &gt;= 4)
{
  ballot_color |= ballot_color &gt;&gt; 2u;
  ballot_depth |= ballot_depth &gt;&gt; 2u;
}

ballot_color |= ballot_color &gt;&gt; 1u;
ballot_depth |= ballot_depth &gt;&gt; 1u;

// GLSL does not accept cluster reduction as spec constant.
if (NUM_SAMPLES == 16)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 16) / 16.0);
else if (NUM_SAMPLES == 8)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 8) / 8.0);
else if (NUM_SAMPLES == 4)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 4) / 4.0);
else
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 2) / 2.0);

fb_color_dirty = subgroupInverseBallot(ballot_color);
fb_depth_dirty = subgroupInverseBallot(ballot_depth);</pre>
<p>The main advantage of super-sampling over straight up-scaling is that up-scaling will still have jagged edges, and super-sampling retains a coherent visual look where 3D elements have similar resolution as UI elements. One of my pet peeves is when UI elements have a significantly different resolution from 3D objects and textures. HD texture packs can of course alleviate that, but that‚Äôs a very different beast.</p>
<p>Super-sampling also lends itself very well to CRT post-processing shading, which is also a nice bonus.</p>
<h3>Dealing with super-sampling artifacts</h3>
<p>It‚Äôs a fact of life that super-sampling always introduces horrible artifacts if not handled with utmost care. Mitigating this is arguably easier with software renderers over traditional graphics APIs, since we‚Äôre not limited by the fixed function interpolators. These tricks won‚Äôt make it perfect by any means, but it greatly mitigates jank in my experience, and I already fixed many upscaling bugs that GSdx Vulkan backend does not solve as we shall see later.</p>
<h4>Sprite primitives should always render at single-rate</h4>
<p>Sprites are always UI elements or similar, and games do not expect us to up-scale them. Doing so either results in artifacts where we sample outside the intended rect, or we risk overblurring the image if bilinear filtering is used.</p>
<p>The trick here is just to force-snap the pixel coordinate we use when rasterizing and interpolating. This is very inefficient of course, but UI shouldn‚Äôt take up the entire screen. And if it does (like in a menu), the GPU load is tiny anyway.</p>
<pre>const uint SNAP_RASTER_BIT = (1u &lt;&lt; STATE_BIT_SNAP_RASTER);
const uint SNAP_ATTR_BIT = (1u &lt;&lt; STATE_BIT_SNAP_ATTRIBUTE);

if (SUPER_SAMPLE &amp;&amp; (prim_state &amp; SNAP_RASTER_BIT) != 0)
  fb_pixel = tile.fb_pixel_single_rate;

res.request.coverage = evaluate_coverage(
  prim, fb_pixel, i, j,
  res.request.multisample, SAMPLING_RATE_DIM_LOG2);</pre>
<h4>Flat primitives should interpolate at single-pixel coordinate</h4>
<p>Going further, we can demote SSAA interpolation to MSAA center interpolation dynamically. Many UI elements are unfortunately rendered with normal triangles, so we have to be a bit more careful. This snap only affects attribute interpolation, not Z of course.</p>
<pre>res.request.st_bb = false;
if (SUPER_SAMPLE &amp;&amp;
    (prim_state &amp; (SNAP_RASTER_BIT | SNAP_ATTR_BIT)) == SNAP_ATTR_BIT)
{
  vec2 snap_ij = evaluate_barycentric_ij(
    prim.b, prim.c, prim.inv_area,
    prim.error_i, prim.error_j, tile.fb_pixel_single_rate,
    SAMPLING_RATE_DIM_LOG2);

  i = snap_ij.x;
  j = snap_ij.y;
  res.request.st_bb = true;
}</pre>
<p>Here, we snap interpolation to the top-left pixel. This fixes any artifacts for primitives which align their rendering to a pixel center, but some games are mis-aligned, so this snapping can cause texture coordinates to go outside the expected area. To clean this up, we compute a bounding box of final texture coordinates. Adding bounding boxes can technically cause notorious block-edge artifacts, but that was mostly a thing on PS1 since emulators like to convert nearest sampling to bilinear.</p>
<p>The heuristic for this is fairly simple. If perspective is used, if all vertices in a triangle have exact same Q, we assume it‚Äôs a flat UI primitive. The primitive‚Äôs Z coordinates must also match. This is done during triangle setup on the GPU. There can of course be false positives here, but it should be rare. In my experience this hack works well enough in the games I tried.</p>
<h2>Results</h2>
<p>Here‚Äôs a good example of up-sampling going awry in PCSX2. This is with Vulkan backend:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-300x198.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-768x506.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1536x1012.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Notice the bloom on the glass being mis-aligned and a subtle (?) rectangular pattern being overlaid over the image. This is caused by a post-processing pass rendering in a page-like pattern, presumably to optimize for GS caching behavior.</p>

<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>With 8x SSAA in paraLLEl-GS it looks like this instead. There is FSR1 post-upscale in effect here which changes the look a bit, but the usual trappings of bad upscale cannot be observed here. This is another reason to do super-sample; texture mis-alignment has a tendency to fix itself.</p>
<p>Also, if you‚Äôre staring at the perf numbers, this is RX 7600 in a low power state :‚Äô)</p>
<p>Typical UI issues can be seen in games as well. Here‚Äôs native resolution:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>and 4x upscale, which ‚Ä¶ does not look acceptable.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This UI is tricky to render in upscaled mode, since it uses triangles, but the MSAA snap trick above works well and avoids all artifacts. With straight upscale, this is hard to achieve in normal graphics APIs since you‚Äôd need interpolateAtOffset beyond 0.5 pixels, which isn‚Äôt supported. Perhaps you could do custom interpolation with derivatives or something like that, but either way, this glitch can be avoided. The core message is basically to never upscale UI beyond plain nearest neighbor integer scale. It just looks bad.</p>
<p>There are cases where PCSX2 asks for high blending accuracy. One example is MGS2, and I found a spot where GPU perf is murdered. My desktop GPU cannot keep 60 FPS here at 4x upscale. PCSX2 asks you to turn up blend-accuracy for this game, but ‚Ä¶</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>What happens here is we hit the programmable blending path with barrier between every primitive. Ouch! This wouldn‚Äôt be bad for the tiler mobile GPUs, but for a desktop GPU, it is where perf goes to die. The shader in question does subpassLoad and does programmable blending as expected. Barrier, tiny triangle, barrier, tiny triangle, hnnnnnnng.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/ouch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>paraLLEl-GS on the other hand always runs with 100% blend accuracy (assuming no bugs of course). Here‚Äôs 16xSSAA (equivalent to 4x upscale). This is just 25 W and 17% GPU utilization on RX 7600. Not bad.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Other difficult cases include texture sampling feedback. One particular case I found was in Valkyrie Profile 2.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This game has a case where it‚Äôs sampling it‚Äôs own pixel‚Äôs alpha as a palette index. Quirky as all hell, and similar to MGS2 there‚Äôs a barrier between every pixel.</p>
<p>In paraLLEl-GS, this case is detected, and we emit a magical texture index, which resolved to just looking at in-register framebuffer color instead. Programmable blending go brr. These cases have to be checked per primitive, which is quite rough on CPU time, but it is what it is. If we don‚Äôt hit the good path, GPU performance completely tanks.</p>
<p>The trick here is to analyze the effective UV coordinates, and see if UV == framebuffer position. If we fall off this path, we have to go via texture uploads, which is bad.</p>
<pre>ivec2 uv0_delta = uv0 - pos[0].pos;
ivec2 uv1_delta = uv1 - pos[1].pos;
ivec2 min_delta = min(uv0_delta, uv1_delta);
ivec2 max_delta = max(uv0_delta, uv1_delta);

if (!quad)
{
  ivec2 uv2_delta = uv2 - pos[2].pos;
  min_delta = min(min_delta, uv2_delta);
  max_delta = max(max_delta, uv2_delta);
}

int min_delta2 = min(min_delta.x, min_delta.y);
int max_delta2 = max(max_delta.x, max_delta.y);

// The UV offset must be in range of [0, 2^SUBPIXEL_BITS - 1].
// This guarantees snapping with NEAREST.
// 8 is ideal. That means pixel centers during interpolation
// will land exactly in the center of the texel.
// In theory we could allow LINEAR if uv delta was
// exactly 8 for all vertices.
if (min_delta2 &lt; 0 || max_delta2 &gt;= (1 &lt;&lt; SUBPIXEL_BITS))
  return ColorFeedbackMode::Sliced;

// Perf go brrrrrrr.
return ColorFeedbackMode::Pixel;</pre>
<pre>if (feedback_mode == ColorFeedbackMode::Pixel)
{
  mark_render_pass_has_texture_feedback(ctx.tex0.desc);
  // Special index indicating on-tile feedback.
  // We could add a different sentinel for depth feedback.
  // 1024k CLUT instances and 32 sub-banks. Fits in 15 bits.
  // Use bit 15 MSB to mark feedback texture.
  return (1u &lt;&lt; (TEX_TEXTURE_INDEX_BITS - 1u)) |
         (render_pass.clut_instance * 32 + uint32_t(ctx.tex0.desc.CSA));
}</pre>
<p>It‚Äôs comfortably full-speed on PCSX2 here, despite the copious number of barriers, but paraLLEl-GS is reasonably close perf-wise, actually. At 8x SSAA.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg" alt="" width="660" height="457" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-300x208.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-768x532.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1536x1064.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg 1708w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Overall, we get away with 18 render pass barriers instead of 500+ which was the case without this optimization. You may notice the interlacing artifacts on the swirlies. Silly game has a progressive scan output, but downsamples it on its own to a field before hitting CRTC, hnnnnng üôÅ Redirecting framebuffer locations in CRTC might work as a per-game hack, but either way, I still need to consider a better de-interlacer. Some games actually render explicitly in fields (640√ó224), which is very annoying.</p>
<p>This scene in the MGS2 intro also exposes some funny edge cases with sampling.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To get the camo effect, it‚Äôs sampling its own framebuffer as a texture, with overlapping coordinates, but not pixel aligned, so this raises some serious questions about caching behavior. PCSX2 doesn‚Äôt seem to add any barriers here, and I kinda had to do the same thing. It looks fine to me compared to software renderer at least.</p>
<pre>if (feedback_mode == ColorFeedbackMode::Sliced)
{
  // If game explicitly clamps the rect to a small region,
  // it's likely doing well-defined feedbacks.
  // E.g. Tales of Abyss main menu ping-pong blurs.
  // This code is quite flawed,
  // and I'm not sure what the correct solution is yet.
  if (desc.clamp.desc.WMS == CLAMPBits::REGION_CLAMP &amp;&amp;
      desc.clamp.desc.WMT == CLAMPBits::REGION_CLAMP)
  {
    ivec4 clamped_uv_bb(
      int(desc.clamp.desc.MINU),
      int(desc.clamp.desc.MINV),
      int(desc.clamp.desc.MAXU),
      int(desc.clamp.desc.MAXV));

    ivec4 hazard_bb(
      std::max&lt;int&gt;(clamped_uv_bb.x, bb.x),
      std::max&lt;int&gt;(clamped_uv_bb.y, bb.y),
      std::min&lt;int&gt;(clamped_uv_bb.z, bb.z),
      std::min&lt;int&gt;(clamped_uv_bb.w, bb.w));

    cache_texture = hazard_bb.x &gt; hazard_bb.z ||
                    hazard_bb.y &gt; hazard_bb.w;
  }
  else
  {
    // Questionable,
    // but it seems almost impossible to do this correctly and fast.
    // Need to emulate the PS2 texture cache exactly,
    // which is just insane.
    // This should be fine.
    cache_texture = false;
  }
}</pre>
<p>If we‚Äôre in a mode where texture points directly to the frame buffer we should relax the hazard tracking a bit to avoid 2000+ barriers. This is clearly spooky since Tales of Abyss‚Äôs bloom effect as shown earlier depends on this to be well behaved, but in that case, at least it uses REGION_CLAMP to explicitly mark the ping-pong behavior. I‚Äôm not sure what the proper solution is here.</p>
<p>The only plausible solution to true bit-accuracy with real hardware is to emulate the caches directly, one pixel at a time. You can kiss performance good bye in that case.</p>
<p>One of the worst stress tests I‚Äôve found so far has to be Shadow of the Collosus. Just in the intro, we can make the GPU kneel down to 24 FPS with maximum blend accuracy on PCSX2, at just 2x upscale! Even with normal blending accuracy, it is extremely heavy during the intro cinematic.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>At 8x SSAA, perf is still looking pretty good for paraLLEl-GS, but it‚Äôs clearly sweating now.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg" alt="" width="660" height="462" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-300x210.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-768x538.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>We‚Äôre actually still CPU bound on the geometry processing. Optimizing the CPU code hasn‚Äôt been a huge priority yet. There‚Äôs unfortunately a lot of code that has to run per-primitive, where hazards can happen around every corner that has to be dealt with somehow. I do some obvious optimizations, but it‚Äôs obviously not as well-oiled as PCSX2 in that regard.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png" alt="" width="660" height="394" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-300x179.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-768x458.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1536x917.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png 1766w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<h3>Deck?</h3>
<p>It seems fast enough to comfortably do 4x SSAA. Maybe not in SotC, but ‚Ä¶ hey. üòÄ</p>
<h2>What now?</h2>
<p>For now, the only real way to test this is through GS dumps. <a href="https://github.com/Arntzen-Software/parallel-gs/blob/main/misc/0001-Add-an-ad-hoc-GS-stream-format.patch">There‚Äôs a hack-patch for PCSX2</a> that lets you dump out a raw GS trace, which can be replayed. This works via mkfifo as a crude hack to test in real-time, but some kind of integration into an emulator needs to happen at some point if this is to turn into something that‚Äôs useful for end users.</p>
<p>There‚Äôs guaranteed to be a million bugs lurking since the PS2 library is ridiculously large and there‚Äôs only so much I can be arsed to test myself. At least, paraLLEl-GS has now become my preferred way to play PS2 games, so I can say mission complete.</p>
<p>A potential use case for this is due to its standalone library nature, it may be useful as very old-school rendering API for the old greybeards around that still yearn for the day of PS2 programming for whatever reason :p</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taming the beast that is the Django ORM ‚Äì An introduction (139 pts)]]></title>
            <link>https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</link>
            <guid>41413641</guid>
            <pubDate>Sun, 01 Sep 2024 02:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/">https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</a>, See on <a href="https://news.ycombinator.com/item?id=41413641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><img src="https://www.davidhang.com/_astro/1.UiFfZ6wR_IHH0Y.webp" alt="man fighting dragon which represents the django orm" width="1024" height="1024" loading="lazy" decoding="async"></p>
<p>The material this blog post was originally developed from was a bunch of slides
used for a skill share presentation I gave at my workplace <span>@</span> <a href="https://coreplan.io/">coreplan.io</a>.</p>
<p>I have 3+ years of experience with Django, with it being the main framework that
underpins the backend of CorePlan‚Äôs main SaaS product. It is a mature, batteries
included framework that has been around for a while now. One particular powerful
yet dangerous feature of Django is the ORM. This is a Django specific ORM which
cannot be separated from the rest of the framework. The other major python ORM
is SQLAlchemy which can be used with other python web frameworks, but is an
independent tool.</p>
<p>Below are some of the things that I have learned about the Django ORM, how it
compares to raw SQL and gotchas that you should be aware of when using it.</p>
<hr>
<h2 id="what-is-an-orm-object-relational-mapper">What is an ORM (Object Relational Mapper)?</h2>
<ul>
<li>Abstraction over SQL to interact with databases</li>
</ul>
<p>Code -&gt; SQL</p>
<pre tabindex="0" data-language="python"><code><span><span>Hole.objects.all()</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<hr>
<h2 id="why-use-an-orm---pros">Why use an ORM? - Pros</h2>
<ul>
<li>Abstraction over SQL, no need to write raw SQL (plus and minus)</li>
<li>Portability - Can change out database engines easily !?
<ul>
<li>Probably not true, often will rely on db specific features e.g. postgres jsonb, triggers, etc</li>
</ul>
</li>
<li>Direct mapping from db to models</li>
<li>Automatic schema generation
<ul>
<li>Migrations are automatically generated</li>
</ul>
</li>
<li>Security
<ul>
<li>abstracts away enough that sql injection is less likely</li>
</ul>
</li>
</ul>
<hr>
<h2 id="why-use-an-orm---cons">Why use an ORM? - Cons</h2>
<ul>
<li>Abstraction over SQL‚Ä¶
<ul>
<li>Hides the underlying SQL</li>
<li>Can be difficult to debug</li>
<li>Lazy loading can cause N+1 queries without the developer realising</li>
<li>Harder to onboard new developers if they haven‚Äôt used Django before</li>
</ul>
</li>
<li>Performance
<ul>
<li>Generated sql be slower than crafted SQL</li>
</ul>
</li>
</ul>
<hr>
<h2 id="fundamentals">Fundamentals</h2>
<ul>
<li>Models = Tables</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span># drilling/models.py</span></span>
<span></span>
<span><span>from</span><span> django.db </span><span>import</span><span> models</span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>    name </span><span>=</span><span> models.TextField()</span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>CREATE</span><span> TABLE</span><span> drilling_hole</span><span> (</span></span>
<span><span>    id </span><span>SERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span><span>    name</span><span> VARCHAR</span><span>(</span><span>100</span><span>)</span></span>
<span><span>);</span></span>
<span></span></code></pre>
<hr>
<h2 id="migrations">Migrations</h2>
<pre tabindex="0" data-language="bash"><code><span><span>python</span><span> manage.py</span><span> makemigrations</span><span> # generate migration files</span></span>
<span><span>python</span><span> manage.py</span><span> migrate</span><span> # apply migrations</span></span>
<span></span>
<span><span>python</span><span> manage.py</span><span> drilling</span><span> --empty</span><span> # generate empty file for data migration</span></span>
<span></span></code></pre>
<p><a href="https://docs.djangoproject.com/en/dev/topics/migrations/">https://docs.djangoproject.com/en/dev/topics/migrations/</a></p>
<hr>

<h2 id="querying">Querying</h2>
<ul>
<li><code>ActiveRecord</code> pattern - ala Ruby on Rails style</li>
<li>QuerySets (<code>Hole.objects.all()</code>)
<ul>
<li>lazy</li>
<li>chainable</li>
<li>cached when iterated over multiple times <a href="https://docs.djangoproject.com/en/dev/topics/db/queries/#caching-and-querysets">!?</a>
<ul>
<li>I would not recommend relying on this because it hard to comprehend when it is cached and when it is not when you are reading code</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>) </span><span># not evaluated yet</span></span>
<span><span>holes_qs </span><span>=</span><span> holes_qs.filter(</span><span>depth__gt</span><span>=</span><span>100</span><span>) </span><span># still not evaluated</span></span>
<span></span>
<span><span>list</span><span>(holes_qs) </span><span># evaluated</span></span>
<span><span>list</span><span>(holes_qs) </span><span># cached</span></span>
<span></span>
<span><span>holes_qs[</span><span>2</span><span>] </span><span># not cached</span></span>
<span><span>holes_qs.first() </span><span># not cached</span></span>
<span><span>holes_qs.get(</span><span>id</span><span>=</span><span>1</span><span>) </span><span># not cached</span></span>
<span></span></code></pre>
<hr>
<h2 id="where">WHERE</h2>
<ul>
<li><code>WHERE</code> clause ‚âà <code>filter()</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_hole</span><span>.</span><span>name</span><span> =</span><span> 'cheese'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-across-tables">WHERE across tables?</h2>
<ul>
<li>But how do you do a left/inner join? With the ORM it isn‚Äôt done declaratively, but implicitly</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>pad__name</span><span>=</span><span>"cheese board"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> drilling_pad </span><span>ON</span><span> drilling_hole</span><span>.</span><span>pad_id</span><span> =</span><span> drilling_pad</span><span>.</span><span>id</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-other-conditionals">WHERE other conditionals</h2>
<ul>
<li><code>filter(name="cheese")</code> -&gt; <code>filter(name__exact="cheese")</code> -&gt; <code>WHERE name = 'cheese'</code></li>
<li><code>filter(name__iexact="cheese")</code> -&gt; <code>WHERE name ILIKE 'cheese'</code></li>
<li><code>filter(name__contains="cheese")</code> -&gt; <code>WHERE name LIKE '%cheese%'</code></li>
<li><code>filter(name__icontains="cheese")</code> -&gt; <code>WHERE name ILIKE '%cheese%'</code></li>
<li><code>filter(name__in=["cheese", "board"])</code> -&gt; <code>WHERE name IN ('cheese', 'board')</code></li>
<li><code>filter(name__gt=100)</code> -&gt; <code>WHERE name &gt; 100</code> etc</li>
<li><code>filter(name__isnull=True)</code> -&gt; <code>WHERE name IS NULL</code>
<ul>
<li>At least for postgres shouldn‚Äôt <code>name = None</code>, <a href="https://www.postgresql.org/docs/current/functions-comparison.html">null != null</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="as">AS</h2>
<ul>
<li><code>annotate</code> ‚âà <code>AS</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>))</span></span>
<span><span>hole </span><span>=</span><span> holes_qs.first()</span></span>
<span><span>print</span><span>(hole.this_thang)</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  *</span><span> , </span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> "drilling_pad"</span><span> ON</span><span> (</span><span>"drilling_hole"</span><span>.</span><span>"pad_id"</span><span> =</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<hr>
<h2 id="subqueries">Subqueries</h2>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Project</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  project </span><span>=</span><span> models.ForeignKey(Project, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># find pads that are on project_id=1</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>project_id</span><span>=</span><span>1</span><span>).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.filter(</span><span>hole__in</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span><span> INNER JOIN</span><span> "drilling_hole"</span><span> ON</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span> =</span><span> "drilling_hole"</span><span>.</span><span>"pad_id"</span><span>)</span></span>
<span><span>WHERE</span><span> "drilling_hole"</span><span>.</span><span>"id"</span><span> IN</span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"project_id"</span><span> =</span><span> 1</span></span>
<span><span> )</span></span>
<span></span></code></pre>
<hr>

<p>Correlated subqueries are where the inner query depends on outer query</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># include the hole id of any hole that has a foreign key to the pad</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>pad_id</span><span>=</span><span>OuterRef(</span><span>"pk"</span><span>)).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.annotate(</span><span>hole_id</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span><span>,</span></span>
<span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"pad_id"</span><span> =</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span> ) </span><span>AS</span><span> "hole_id"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span></span></code></pre>
<hr>
<h2 id="performance-improvements">Performance improvements</h2>
<ul>
<li>Reduce N+1
<ul>
<li>You typically want to reduce N+1 queries because they have communication
overhead</li>
<li><code>select_related</code></li>
<li><code>prefetch_related</code></li>
<li>You also might choose to use <code>annotate()</code> instead of <code>select_related</code>
because select related pulls all the data for the associated table when you
might only need one column. That associated might have a jsonb column which
contains a lot of unnecessary data that you don‚Äôt need.</li>
</ul>
</li>
</ul>
<hr>

<pre tabindex="0" data-language="python"><code><span><span>holes </span><span>=</span><span> Hole.objects.all()</span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># N+1 queries</span></span>
<span></span>
<span><span>holes </span><span>=</span><span> Hole.objects.select_related(</span><span>"pad"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># no extra query</span></span>
<span></span>
<span></span></code></pre>
<hr>

<p>You would use prefetch related when you are not pulling a direct foreign key
such a many-to-many relationship like below.</p>
<p><img src="https://www.davidhang.com/_astro/2.Cd5VA_n2_Z22TJnn.svg" alt="width:400px" width="340" height="465" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span></span>
<span><span>class</span><span> Faculty</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Course</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  faculty </span><span>=</span><span> models.ForeignKey(Faculty, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Student</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  courses </span><span>=</span><span> models.ManyToManyField(Course, </span><span>through</span><span>=</span><span>"Enrolment"</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span><span>"courses"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># extra query</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "courses"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.select_related(</span><span>"faculty"</span><span>)</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># no extra query</span></span>
<span></span></code></pre>
<hr>
<h2 id="to_attr">to_attr</h2>
<p><code>to_attr</code> can be used to make ‚Äúfiltered‚Äù relationships available on the instance.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "course"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.filter(</span><span>grade__gt</span><span>=</span><span>80.0</span><span>).select_related(</span><span>"faculty"</span><span>), </span><span>to_attr</span><span>=</span><span>"hd_courses"</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.hd_courses.all():</span></span>
<span><span>    ...</span></span>
<span></span></code></pre>
<hr>
<h2 id="multiple-instances-when-filtering-across-many-to-many">Multiple instances when filtering across many-to-many</h2>
<p>One gotcha is selecting across a many-to-many relationship can return multiple of the same instances.</p>
<p><img src="https://www.davidhang.com/_astro/3.DMAdguVG_TLkyj.webp" alt="data model showing many to many relationship" width="530" height="810" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>) </span><span># inner join returns duplicated rows</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>, </span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>).distinct()</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span></span>
<span><span>  "testing_student"</span><span>.</span><span>"id"</span><span>, </span></span>
<span><span>  "testing_student"</span><span>.</span><span>"name"</span><span> </span></span>
<span><span>FROM</span><span> </span></span>
<span><span>  "testing_student"</span><span> </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_enrolment"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_student"</span><span>.</span><span>"id"</span><span> =</span><span> "testing_enrolment"</span><span>.</span><span>"student_id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_course"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_enrolment"</span><span>.</span><span>"course_id"</span><span> =</span><span> "testing_course"</span><span>.</span><span>"id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_faculty"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_course"</span><span>.</span><span>"faculty_id"</span><span> =</span><span> "testing_faculty"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span>WHERE</span><span> </span></span>
<span><span>  "testing_faculty"</span><span>.</span><span>"name"</span><span> =</span><span> 'Science'</span></span>
<span></span></code></pre>
<hr>
<h2 id="gotchas-and-other-funky-stuff">Gotchas and other Funky stuff</h2>
<ul>
<li>Model instances when retrieved will try to populate all columns, if column
removed in migration, and the worker still up exception occurs
<ul>
<li><code>get()</code> or <code>first()</code></li>
<li><code>for hole in Hole.objects.all()</code></li>
</ul>
</li>
<li>This can make migrations hard, as older workers will be requesting columns that might have been removed or renamed which will cause errors</li>
<li>There are ways to do down-timeless migrations but are bit <a href="https://hackernoon.com/deleting-a-column-from-a-django-model-on-production">funky and multi
step</a></li>
<li>Recommendation is to avoid deleting or renaming columns</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>)).get()</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- pulls all columns </span></span>
<span><span>  drilling_hole</span><span>.</span><span>pad_id</span><span>,</span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span><span>LIMIT</span><span> 1</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="values">Values</h2>
<ul>
<li>So how do you to only retrieve certain columns?</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.values(</span><span>"name"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(</span><span>type</span><span>(hole)) </span><span># dict</span></span>
<span><span>  # not `Hole` object, hence no class functions, no lazy loading e.g. can't access `hole.pad.name`</span></span>
<span></span></code></pre>
<p>‚¨áÔ∏è</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- only pulls name and maps it to a python dictionary object</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<ul>
<li>Less data sent down the wire, but no lazy loading and no class functions as
the data is a python dictionary</li>
</ul>
<hr>
<h2 id="other-options">Other options</h2>
<ul>
<li><code>only()</code> and <code>defer()</code></li>
<li>Will retrieve model instances, but won‚Äôt retrieve all fields</li>
<li>Values not declared when accessed on the model are lazy loaded</li>
<li>Would not recommend to be used regularly, very high chance of N+1</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.only(</span><span>"pad_id"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(hole.pad_id) </span><span># no extra query</span></span>
<span><span>  print</span><span>(hole.name) </span><span># name will be lazy loaded, N+1 queries</span></span>
<span></span></code></pre>
<hr>
<h3 id="how-do-you-know-what-sql-is-being-generated">How do you know what SQL is being generated?</h3>
<ul>
<li><code>print(queryset.query)</code></li>
<li><a href="https://github.com/jazzband/django-debug-toolbar">Django Debug Toolbar</a></li>
<li><a href="https://kolo.app/">Kolo</a></li>
</ul>
<hr>
<h2 id="updating-rows">Updating rows</h2>
<p>There are three typical ways to update a row in the database.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>instance </span><span>=</span><span> Hole.objects.create(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span>
<span><span># save()</span></span>
<span><span>instance.name </span><span>=</span><span> "board"</span></span>
<span><span>instance.save()</span></span>
<span></span>
<span><span># update()</span></span>
<span><span>Model.objects.filter(</span><span>name</span><span>=</span><span>"board"</span><span>).update(</span><span>name</span><span>=</span><span>"board2"</span><span>)</span></span>
<span></span>
<span><span># bulk_update()</span></span>
<span><span>instance.name </span><span>=</span><span> "board3"</span></span>
<span><span>instances_to_update </span><span>=</span><span> [instance]</span></span>
<span><span>Model.objects.bulk_update(instances_to_update, [</span><span>"name"</span><span>])</span></span>
<span></span></code></pre>
<hr>
<h2 id="problems-with-updates">Problems with updates</h2>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger <code>save()</code> method on the model</li>
<li>built in django signals (publish/subscribe pattern), there are post_save and pre_save signals which can be triggered when calling <code>save()</code>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger those signals‚Ä¶</li>
</ul>
</li>
<li><code>updated_at</code> column would not normally be updated when calling <code>update()</code> or
<code>bulk_update()</code> but if queryset is a descendant of <code>CoreplanQuerySet</code> then it will.</li>
</ul>
<hr>

<ul>
<li>Pagination / order_by
<ul>
<li>Not a Django ORM thing, but a Django ORM hides the implementation detail,
which may lead to unexpected result</li>
<li>Page pagination is default in DRF list views and implemented with <code>LIMIT</code> and <code>OFFSET</code> in SQL</li>
</ul>
</li>
</ul>
<p><code>?page_size=10&amp;page=3</code></p>
<pre tabindex="0" data-language="plaintext"><code><span><span>SELECT * </span></span>
<span><span>FROM drilling_hole </span></span>
<span><span>LIMIT 10 </span></span>
<span><span>OFFSET 20;</span></span>
<span><span></span></span></code></pre>
<p>Anything wrong with this query?</p>
<ul>
<li>There is no deterministic guarantee that the same 10 rows will be returned each time.</li>
<li>A plain <code>SELECT</code> in postgres (may be different in different dbs) provides no
guarantee of order, unless <code>ORDER BY</code> is specified</li>
<li>It often appears to return in insertion/<code>id</code> order, but that is not guaranteed
in postgres</li>
<li>Model Meta <code>ordering</code> may set a default order, but sometimes tht is <a href="https://docs.djangoproject.com/en/dev/releases/2.2/#features-deprecated-in-2-2">ignored</a></li>
<li>For list views you should to provide a deterministic order_by</li>
<li><code>order_by(name)</code> is not enough if name is not unique
<ul>
<li><code>order_by(name, id)</code> is required, because id is unique</li>
</ul>
</li>
<li>This can been the the cause of some flaky tests issues where lists are
returned seemingly in insertion order and asserted to return in id order</li>
</ul>
<hr>
<p>Thanks for reading! I hope this has been useful to you. There are definitely
more particularities and gotchas to be aware of when using the Django ORM and
Django in general but I think these are the most common ones.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AirTags key to discovery of Houston's plastic recycling deception (147 pts)]]></title>
            <link>https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</link>
            <guid>41413174</guid>
            <pubDate>Sun, 01 Sep 2024 00:38:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception">https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</a>, See on <a href="https://news.ycombinator.com/item?id=41413174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-hero" aria-labelledby="hero-cap" role="figure">
                          <p id="hero-cap" title="Apple employs an advanced robot named Daisy to disassemble old iPhones.">Apple employs an advanced robot named Daisy to disassemble old iPhones.</p>
                                    <p><a href="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg">
              <img fetchpriority="high" src="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg" alt="">
            </a>
                      </p></div><div>
          <p>One Houston resident was suspicious of the city's "all plastic accepted" recycling program, and used <a href="https://appleinsider.com/inside/airtags" title="AirTag" data-kpt="1">AirTags</a> to discover where the plastic waste actually ended up.
</p><p>Deason, who regularly recycles her packaging and other waste, began to have doubts about the city's plastic recycling program. Houston's program boasted of being able to accept even types of plastic that aren't normally considered recyclable.
</p><p>Curious as to where the plastic was going, she bought a set of AirTags, and included them in various bags of her plastic recycling. Of the bags she tracked, nearly all of them went to a company called Wright Waste Management, located in nearby Harris County.
</p><p>The company is not approved to store plastic waste, and has failed three fire inspections.
</p><p>CBS News correspondent Ben Tracy <a href="https://www.khou.com/article/news/local/houston-recycling-tracking-device-plastic/">referred</a> to Deason as "the James Bond of plastic recycling" for her initiative. Aerial footage showed that the facility had large piles of plastic waste as tall as 10 feet high.
</p><p>Deason said she thought that the company simply storing the unrecyclable plastic waste was "kind of strange." She later contacted Houston's Director of Solid Waste Management Mark Wilfalk, to ask about the discrepancy.
</p><p>When shown the drone footage, Wilfalk admitted "it's not the most desirable-looking site." He promised Deason he'd investigate the problems that caused Wright Waste Management to fail the fire inspections.
</p><p>Wilfalk later acknowledged that the city had collected some 250 tons of plastic since the end of 2022. He revealed that none of it had been recycled as of yet.
</p><p>"We're gonna stockpile it for now," he admitted. "We're gonna see what happens."
</p><p>By contrast, Apple has been an <a href="https://appleinsider.com/articles/24/04/16/apple-highlights-device-recycling-iphone-trade-in-and-the-removal-of-leather-for-earth-day" title="Apple's environmental efforts">industry leader</a> in reducing its use of plastic. It uses paper for packaging, and metal rather than plastic for its computer line.
</p><p>It does use some plastic for products such as its <a href="https://appleinsider.com/inside/airpods" title="AirPods" data-kpt="1">AirPods</a> earbuds. It has invested in robotics to help recycle old Apple products.
</p><p>Houston, as it turns out, is waiting on a promised sorting facility to open, where the stored recycling will be sorted and treated. The company behind the sorting facility, Cyclix, says it has developed a method to create recyclable pellets out of the plastic waste.
</p><p>However, only a fraction of these pellets can be made into new plastic. Most will be melted and turned into fuel that is burned, adding to carbon emissions.
</p><p>California Attorney General Rob Bonta has been investigating Cyclix owner and plastic manufacturer ExxonMobil's claims regarding plastic recycling in that state. He has characterized Cyclix's claims of plastic recycling are largely fictional.</p>

        </div></div>]]></description>
        </item>
    </channel>
</rss>