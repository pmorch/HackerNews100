<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 26 Jan 2026 21:30:15 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[When AI 'builds a browser,' check the repo before believing the hype (130 pts)]]></title>
            <link>https://www.theregister.com/2026/01/26/cursor_opinion/</link>
            <guid>46769965</guid>
            <pubDate>Mon, 26 Jan 2026 18:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/26/cursor_opinion/">https://www.theregister.com/2026/01/26/cursor_opinion/</a>, See on <a href="https://news.ycombinator.com/item?id=46769965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> AI-integrated development environment (IDE) company Cursor recently <a target="_blank" rel="nofollow" href="https://cursor.com/blog/scaling-agents">implied</a> it had built a working web browser almost entirely with its AI agents. I won't say they lied, but CEO Michael Truell certainly <a target="_blank" rel="nofollow" href="https://x.com/mntruell/status/2011562190286045552">tweeted</a>: "We built a browser with GPT-5.2 in Cursor."</p>
<p>He followed up with: "It's 3M+ lines of code across thousands of files. The rendering engine is from-scratch in Rust with HTML parsing, CSS cascade, layout, text shaping, paint, and a custom JS VM."</p>
<p>That sounds impressive, doesn't it? He also added: "It *kind of* works," which is not the most ringing endorsement. Still, numerous news sources and social media chatterboxes ran with the news that <a target="_blank" rel="nofollow" href="https://medium.com/write-a-catalyst/ai-agents-built-a-web-browser-in-one-week-and-that-should-make-us-pause-1be4fab67d03">AI built a web browser in a week</a>.</p>

    

<p>Too bad it wasn't true. If you actually looked at Cursor engineer Wilson Lin's blog post about <a target="_blank" rel="nofollow" href="https://github.com/wilsonzlin/fastrender">FastRender</a>, the AI-created web browser, you won't see much boasting about a working web browser. Instead, there's a video of a web browser sort of working, and a much less positive note that "building a browser from scratch is extremely difficult."</p>

        


        

<p>The thing about making such a software announcement on GitHub is that while the headlines are proclaiming another AI victory, developers have this nasty trick. They actually git the code and try it out.</p>
<p><a target="_blank" rel="nofollow" href="https://emsh.cat/cursor-implied-success-without-evidence/">Developers quickly discovered the "browser" barely compiles</a>, often does not run, and was heavily misrepresented in marketing.</p>

        

<p>As a techie, the actual blog post about how they tried and didn't really succeed was much more interesting. Of course, that Cursor sicced hundreds of GPT-5.2-style agents which ran for a week to produce three million lines of new code, to produce, at best, a semi-functional web browser from scratch, doesn't make for a good headline.</p>
<p>According to Perplexity, my AI chatbot of choice, this week‑long autonomous browser experiment consumed in the order of 10-20 trillion tokens and would have cost several million dollars at then‑current list prices for frontier models.</p>
<p>I'd just cloned a copy of Chromium myself, and for all that time and money, independent developers who cloned the repo reported that the codebase is very far from a functional browser. Recent commits do not compile cleanly, GitHub Actions runs on <code>main</code> are failing, and reviewers could not find a single recent commit that was built without errors.</p>

        

<p>Where builds succeeded after manual patching, performance was abysmal, with reports of pages taking around a minute to load and a heavy reliance on existing projects like <a target="_blank" rel="nofollow" href="https://servo.org/">Servo</a>, a Rust-based web rendering engine, and QuickJS, a JavaScript engine, despite "from scratch" claims.</p>
<p>Lin defended the project on Y Combinator, <a target="_blank" rel="nofollow" href="https://news.ycombinator.com/item?id=46650998">saying</a>, for instance: "The JS engine used a custom JS VM being developed in vendor/ecma-rs as part of the browser, which is a copy of my personal JS parser project vendored to make it easier to commit to." If it's derived from his personal JavaScript parser, that's not really from scratch, is it? Nor is it, from the sound of the argument, written by AI.</p>
<ul>

<li><a href="https://www.theregister.com/2026/01/16/linus_torvalds_vibe_coding/">Just because Linus Torvalds vibe codes doesn't mean it's a good idea</a></li>

<li><a href="https://www.theregister.com/2026/01/09/microsoft_365_copilot_app/">The Microsoft 365 Copilot app rebrand was bad, but there are far worse offenders</a></li>

<li><a href="https://www.theregister.com/2025/12/31/long_lived_tech/">The most durable tech is boring, old, and everywhere</a></li>

<li><a href="https://www.theregister.com/2025/12/22/what_linux_desktop_really_needs/">What the Linux desktop really needs to challenge Windows</a></li>
</ul>
<p>Gregory Terzian, a Servo maintainer, <a target="_blank" rel="nofollow" href="https://news.ycombinator.com/item?id=46709191">responded</a>: "The actual code is worse; I can only describe it as a tangle of spaghetti... I can't make much, if anything, out of it." He then gave the backhanded compliment: "So I agree this isn't just wiring up of dependencies, and neither is it copied from existing implementations: it's a uniquely bad design that could never support anything resembling a real-world web engine." Now that's a burn.</p>
<p>From where I sit, what makes the Cursor case more dangerous than just a failed hack‑week project is that the hype is baked into its methodology. The "experiment" wasn't presented as what it really was: an interesting, but messy, internal learning exercise. No, it was rolled out as a milestone that conveniently confirmed the company's long‑running autonomous agent advertising. Missing from the story were basics any senior engineer would demand: passing Continuous Integration (CI), reproducible builds, and real benchmarks that show the browser doing more than limping through a hello-world page.</p>
<p>Zoom out, and CEOs are still predicting that AI will write 90 percent of code in a year, while most enterprise AI pilots still fail to deliver meaningful return on investment.</p>
<p>We're now in a kind of AI uncanny valley for developers. Sure, tools like Cursor can be genuinely helpful as glorified autocomplete and refactoring assistants, but marketing keeps insisting junior engineers can take whole projects from spec to shipping. When you start believing your own sizzle reel, you stop doing the tedious validation work that separates a demo from a deliverable.</p>
<p>Enough already. The hype has grown cold. Sarah Friar, OpenAI's CFO, recently blogged that in 2026, its focus would be on "<a target="_blank" href="https://www.theregister.com/2026/01/20/openai_money/">practical adoption</a>." Let's see real-world practical results first, and then we can talk about practical AI adoption. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Books removed all search functions for any books with previews (127 pts)]]></title>
            <link>https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/</link>
            <guid>46769201</guid>
            <pubDate>Mon, 26 Jan 2026 18:05:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/">https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/</a>, See on <a href="https://news.ycombinator.com/item?id=46769201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Title. A few people have posted about this, but I figured out precisely what they did.</p>

<p>There are three kinds of view on google books: full view, snippet view and preview view. Full view is only for public domain books. For in copyright works, you have preview and snippet. Preview lets you see some full pages while snippet view lets you see a chunk and some sentences.</p>

<p>There was some change a month ago that knocked out a lot of books from search, and I am not entirely sure what that change was. But a few days ago they removed ALL search functions for any books with previews, which are disproportionately modern books. This has made Google Books effectively useless. Snippet view remains and is still searchable.</p>

<p>Bizarrely, if you check the individual books that used to have search function enabled - the previews are still there! You can read full pages! However, the search/OCR is completely turned off. You can search a word while staring at a page that has that word and it will tell you 0 results. They also did not turn off OCR/search for snippet view AND completely locked books.</p>

<p>I think this is extremely terrible as it makes finding books to buy extremely difficult. It also clearly isn't for copyright, as the previews are still there. I have no clue why they did this.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fedora Asahi Remix is now working on Apple M3 (316 pts)]]></title>
            <link>https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o</link>
            <guid>46769051</guid>
            <pubDate>Mon, 26 Jan 2026 17:54:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o">https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o</a>, See on <a href="https://news.ycombinator.com/item?id=46769051">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[JuiceSSH – Give me my pro features back (137 pts)]]></title>
            <link>https://nproject.io/blog/juicessh-give-me-back-my-pro-features/</link>
            <guid>46768909</guid>
            <pubDate>Mon, 26 Jan 2026 17:46:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nproject.io/blog/juicessh-give-me-back-my-pro-features/">https://nproject.io/blog/juicessh-give-me-back-my-pro-features/</a>, See on <a href="https://news.ycombinator.com/item?id=46768909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              <p>JuiceSSH used to be the best SSH client available on Android until December 2025.</p><p>Since then, the purchase made in 2019 is not recognized anymore, and the price went up by 20$. Some users complain in review that after buying it again, the application doesn't get activated. Support is unresponsive, this looks like an exit scam.</p><p>Below is a way to make the application work again. This required <a href="https://github.com/skylot/jadx" rel="noreferrer">jadx</a> to understand smali, and will require you <a href="https://github.com/iBotPeaches/Apktool" rel="noreferrer">ApkTool</a> and jarsigner, which is part of OpenJDK, and you that can install on Windows using <code>choco install openjdk</code>.</p><p>You'll also need a JuiceSSH apk, I downloaded one from <a href="https://apkpure.com/fr/juicessh-ssh-client/com.sonelli.juicessh/download" rel="noreferrer">PureAPK</a>, but feel free to dump your own from your device using adb if you cannot find it. Make sure to verify the hash using virus total/sha256sum if downloading from internet, which should be <code>d1ee811bcd82f25aea0bdc568896d82017ee174d9c4631c123a9d9173c748232</code> for the last version available, version 3.2.2.</p><p>Below are powershell version of the command lines, but you get the idea.</p><h2 id="decompile">Decompile</h2><p>The first step is to decompile the dex packed code from the apk.</p><pre><code>&amp; "C:\Program Files\OpenJDK\jdk-25\bin\java.exe" -jar d juicessh.apk
</code></pre><h2 id="modify-smali">Modify smali</h2><p>You then need to modify the smali of three files, which are detailed below.</p><h3 id="smalicomsonellijuicesshmodelsusersmali">smali/com/sonelli/juicessh/models/User.smali</h3><p>In this file, we'll patch the purchase validation and signature validation, done by the <code>public boolean H()</code> function.</p><p>Here is the original version.</p><pre><code>public boolean H() {
    try {
        String str = "";
        ArrayList arrayList = new ArrayList();
        for (Purchase purchase : this.purchases) {
            if (!arrayList.contains(purchase.order)) {
                str = str + purchase.product + purchase.state;
                arrayList.add(purchase.order);
            }
        }
        return vg0.b(this.signature, this.sessionIdentifier + this.name + this.email + str + this.disabled.toString());
    } catch (IllegalStateException e) {
        e.printStackTrace();
        return false;
    }
}</code></pre><p>Which we'll simply change into</p><pre><code>public boolean H() {
    return true;
}</code></pre><pre><code># virtual methods
.method public H()Z
    .locals 1

    const/4 v0, 0x1
    return v0
.end method</code></pre><h3 id="smalicomsonellioi0smali">smali/com/sonelli/oi0.smali</h3><p>In this one, we'll patch the <code>public static boolean d(Object obj)</code> function, who calls the H() function we modified above, which now returns true, filters product matching JuiceSSH in purchases list, and check if it the purchase is valid. We'll simply make it return true in any case.</p><p>Here is the original version:</p><pre><code>public static boolean d(Object obj) {
    if (!obj.getClass().getName().equals(User.class.getName())) {
        return false;
    }
    try {
        if (!((User) obj).H()) {
            return false;
        }
        ArrayList arrayList = new ArrayList();
        for (Purchase purchase : ((User) obj).purchases) {
            if (purchase.product.equals(a())) {
                arrayList.add(purchase);
            }
        }
        Collections.sort(arrayList, new a());
        if (arrayList.size() &gt; 0) {
            if (((Purchase) arrayList.get(arrayList.size() - 1)).state.intValue() == 0) {
                return true;
            }
        }
        return false;
    } catch (NullPointerException e) {
        e.printStackTrace();
        return false;
    }
}</code></pre><p>Here is the patched one:</p><pre><code>public static boolean d(Object obj) {
    return obj.getClass().getName().equals(User.class.getName());
}</code></pre><pre><code>.method public static d(Ljava/lang/Object;)Z
    .locals 3

    # obj.getClass()
    invoke-virtual {p0}, Ljava/lang/Object;-&gt;getClass()Ljava/lang/Class;
    move-result-object v0

    # obj.getClass().getName()
    invoke-virtual {v0}, Ljava/lang/Class;-&gt;getName()Ljava/lang/String;
    move-result-object v0

    # User.class
    const-class v1, Lcom/sonelli/juicessh/models/User;

    # User.class.getName()
    invoke-virtual {v1}, Ljava/lang/Class;-&gt;getName()Ljava/lang/String;
    move-result-object v1

    # compare strings
    invoke-virtual {v0, v1}, Ljava/lang/String;-&gt;equals(Ljava/lang/Object;)Z
    move-result v2

    if-nez v2, :cond_true

    const/4 v0, 0x0
    return v0

    :cond_true
    const/4 v0, 0x1
    return v0
.end method</code></pre><h3 id="smalicomsonellipi0smali">smali/com/sonelli/pi0.smali</h3><p>Finally, we'll patch the central part of the authentication, which is called each time a pro-feature is triggered to ensure user has valid license, the <code>public static void j(Context context, p pVar)</code> function.</p><p>Here is the original version:</p><pre><code>public static void j(Context context, p pVar) {
    User user;
    User user2;
    String strS = User.s(context);
    if (strS == null) {
        pVar.a(context.getString(R$string.authentication_failure));
        return;
    }
    if (strS.equals("New User")) {
        pVar.a("New User");
        return;
    }
    User user3 = b;
    if (user3 != null &amp;&amp; !user3.disabled.booleanValue()) {
        long jCurrentTimeMillis = System.currentTimeMillis() - b.modified;
        DateUtils.getRelativeTimeSpanString(System.currentTimeMillis() + (b.w() * 1000), System.currentTimeMillis(), 0L, 0);
        DateUtils.getRelativeTimeSpanString(System.currentTimeMillis() + (3600000 - jCurrentTimeMillis), System.currentTimeMillis(), 0L, 0);
        if (b.w() &lt;= 0) {
            gj0.b("API", "Cached user's API session has expired - refreshing session...");
            e(context, null, b.sessionIdentifier, pVar);
            return;
        }
        pVar.b(b);
        if (jCurrentTimeMillis &lt;= 3600000 || context == null || (user2 = b) == null) {
            return;
        }
        e(context, null, user2.sessionIdentifier, null);
        return;
    }
    User userA = User.A(context);
    if (userA == null || userA.disabled.booleanValue() || !userA.H()) {
        e(context, null, null, pVar);
        return;
    }
    b = userA;
    if (userA.w() &lt;= 0) {
        e(context, null, b.sessionIdentifier, pVar);
        return;
    }
    pVar.b(b);
    if (context == null || (user = b) == null) {
        return;
    }
    e(context, null, user.sessionIdentifier, null);
}</code></pre><p><code>pVar.b()</code> is the success callback we'll call while <code>e()</code> is called in case of error. b is the globally stored user we'll have to set. To patch this, we'll simply craft a User with meaningless data, a session expire always in future, save the user in b, and call the success callback every time.</p><pre><code>public static void j(Context context, p pVar) {
    User user = new User();
    user.email = "myemail@google.com";
    user.name = "hello";
    user.given_name = "hello";
    user.sessionExpires = System.currentTimeMillis() + (86400000 * 365);
    user.sessionIdentifier = "";
    b = user;
    pVar.b(user);
}</code></pre><pre><code>.method public static j(Landroid/content/Context;Lcom/sonelli/pi0$p;)V
    .locals 8

    # User u = new User();
    new-instance v0, Lcom/sonelli/juicessh/models/User;
    invoke-direct {v0}, Lcom/sonelli/juicessh/models/User;-&gt;&lt;init&gt;()V

    # u.email = "myemail@google.com";
    const-string v1, "myemail@google.com"
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;email:Ljava/lang/String;

    # u.name = "hello";
    const-string v1, "hello"
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;name:Ljava/lang/String;

    # u.given_name = "hello";
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;given_name:Ljava/lang/String;

    # long now = System.currentTimeMillis();
    invoke-static {}, Ljava/lang/System;-&gt;currentTimeMillis()J
    move-result-wide v2

    # yearMillis = 86400000L * 365L
    const-wide/32 v4, 0x05265c00      # 86400000
    const-wide/16 v6, 0x016d          # 365
    mul-long/2addr v4, v6

    # u.sessionExpires = now + yearMillis;
    add-long/2addr v2, v4
    iput-wide v2, v0, Lcom/sonelli/juicessh/models/User;-&gt;sessionExpires:J

    # u.sessionIdentifier = ""
    const-string v1, ""
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;sessionIdentifier:Ljava/lang/String;

    # pi0.b = u;
    sput-object v0, Lcom/sonelli/pi0;-&gt;b:Lcom/sonelli/juicessh/models/User;

    # pVar.b(b);
    invoke-virtual {p1, v0}, Lcom/sonelli/pi0$p;-&gt;b(Lcom/sonelli/juicessh/models/User;)V

    return-void</code></pre><h2 id="recompile">Recompile</h2><pre><code>&amp; "C:\Program Files\OpenJDK\jdk-25\bin\java.exe" -jar .\apktool_2.12.1.jar juicessh</code></pre><h2 id="sign-the-apk">Sign the apk</h2><pre><code># Create a keystore if needed to self sign the APK
keytool -genkey -v -keystore k.keystore -alias a -keyalg RSA -keysize 2048 -validity 50000

# Sign the APK
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore k.keystore ./juicessh/dist/juicessh.apk a</code></pre><h2 id="done">Done</h2><p>You can install this apk, ignore the security warning because it is self signed, and enjoy JuiceSSH with its pro features again.</p><p>I don't think the cloud sync will work anymore, but that's a minor inconvenience. The plugins don't work anymore too, which is really a joke.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DHS keeps trying and failing to unmask anonymous ICE critics online (142 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/</link>
            <guid>46768081</guid>
            <pubDate>Mon, 26 Jan 2026 16:58:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/">https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/</a>, See on <a href="https://news.ycombinator.com/item?id=46768081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>The Department of Homeland Security (DHS) has backed down from a <a href="https://arstechnica.com/tech-policy/2026/01/instagram-user-fights-dhs-for-the-right-to-post-ice-sightings-anonymously/">fight to unmask the owners of Instagram and Facebook accounts</a> monitoring Immigration and Customs Enforcement (ICE) activity in Pennsylvania.</p>
<p>One of the anonymous account holders, John Doe, sued to block ICE from identifying him and other critics online through summonses to Meta that he claimed infringed on core First Amendment-protected activity.</p>
<p>DHS initially fought Doe’s motion to quash the summonses, arguing that the community watch groups endangered ICE agents by posting “pictures and videos of agents’ faces, license plates, and weapons, among other things.” This was akin to “threatening ICE agents to impede the performance of their duties,” DHS alleged. DHS’s arguments echoed DHS Secretary Kristi Noem, who has claimed that identifying ICE agents is a crime, even though <a href="https://www.wired.com/story/ice-agents-are-doxing-themselves/">Wired noted</a> that ICE employees often post easily discoverable LinkedIn profiles.</p>
<p>To Doe, the agency seemed intent on testing the waters to see if it could seize authority to unmask all critics online by invoking a customs statute that allows agents to subpoena information on goods entering or leaving the US.</p>
<p>But then, on January 16, DHS abruptly reversed course, withdrawing its summonses from Meta.</p>
<p>A <a href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Doe-v-DHA-Notice-to-Withdraw-Summonses-1-21-26.pdf">court filing </a>confirmed that DHS dropped its requests for subscriber information last week, after initially demanding Doe’s “postal code, country, all email address(es) on file, date of account creation, registered telephone numbers, IP address at account signup, and logs showing IP address and date stamps for account accesses.”</p>
<p>The filing does not explain why DHS decided to withdraw its requests.</p>
<p>However, previously, DHS requested similar information from Meta about six Instagram community watch groups that shared information about ICE activity in Los Angeles and other locations. DHS withdrew those requests, too, after account holders defended their First Amendment rights and filed motions to quash their summonses, Doe’s court filing said.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France Aiming to Replace Zoom, Google Meet, Microsoft Teams, etc. (384 pts)]]></title>
            <link>https://twitter.com/lellouchenico/status/2015775970330882319</link>
            <guid>46767668</guid>
            <pubDate>Mon, 26 Jan 2026 16:27:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lellouchenico/status/2015775970330882319">https://twitter.com/lellouchenico/status/2015775970330882319</a>, See on <a href="https://news.ycombinator.com/item?id=46767668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3-Max-Thinking (369 pts)]]></title>
            <link>https://qwen.ai/blog?id=qwen3-max-thinking</link>
            <guid>46766741</guid>
            <pubDate>Mon, 26 Jan 2026 15:23:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwen.ai/blog?id=qwen3-max-thinking">https://qwen.ai/blog?id=qwen3-max-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=46766741">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Television is 100 years old today (315 pts)]]></title>
            <link>https://diamondgeezer.blogspot.com/2026/01/tv100.html</link>
            <guid>46766188</guid>
            <pubDate>Mon, 26 Jan 2026 14:41:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diamondgeezer.blogspot.com/2026/01/tv100.html">https://diamondgeezer.blogspot.com/2026/01/tv100.html</a>, See on <a href="https://news.ycombinator.com/item?id=46766188">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <a name="8509262236011018867"></a>    
          Television is 100 years old today.<br>
And it was born here, above an Italian cafe in Soho.
<p>
<a href="https://www.flickr.com/photos/dgeezer/55061003800" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXqV7ltRB4YYaaIxwsMylYD1d_CIPQ022BNjjYsJ3keOV3IQsYkTT8DLRN8koR32gbI6ZGu3QyLlmy7Q8vKVE8Gev6cbYNSuwSkUbaEzkDstTV02ePtkuNmZ5vGfXo695_AkqZD4li4E6psk6nKH6bg-p8NftvwbR6auHwdOY-d2sk_g4dGj9aQA/s1600/barital.jpg" title="22 Frith Street, Soho" data-original-height="375" data-original-width="500"></a></p><p>
The man who first demonstrated television was <a href="https://en.wikipedia.org/wiki/John_Logie_Baird" target="_blank">John Logie Baird</a>, a former engineering apprentice from Helensburgh. And although there are other places that can plausibly claim to be TV's birthplace, including a terraced street in Hastings, a hill in north London and Selfridges, most people agree that the decisive moment was a demonstration given to journalists in Frith Street on 26th January 1926.
</p><p>
Baird might never have made it to London had he not been a sickly boy. When WW1 broke out he wanted to enlist but was refused due to ill health, so took a job with the Clyde Valley Electrical Power Company helping to make munitions instead. In 1923 he moved to the south coast for the good of his health because it had a warmer climate, renting rooms at <a href="https://www.flickr.com/photos/dgeezer/6905677144/in/album-72157629755731497" target="_blank">21 Linton Crescent</a> in Hastings. Here the first television signal transmitting equipment was constructed, with component parts including a hatbox, tea chest, darning needles and bicycle light lenses. The first image to be transmitted was the shadow of a St Johns Ambulance medal with a distinctive spiky outline, an item still on display at <a href="https://www.hmag.org.uk/see-and-do/digital-museum/shadow-dreams/" target="_blank">Hastings Museum</a>. But his tinkering proved dangerous, and although a 1000-volt electric shock thankfully resulted in nothing worse than a burnt hand, his landlord duly asked him to vacate the premises.
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/6905677144/in/album-72157629755731497" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3VKB5mqH-e80jvaqxMLpheO6EmRBNU9XcVsBH5MSZU5ELXhZgjZWeDXgNf0mfrdM5PFIZbb4Ozs1IUCYYz7YShQWK_YjqvhzhZdSHX566l9gv0XRQCvZhMyKJ6qNoOYbOPWMPJfCizd3cXrtSy0_x-nf5ShGpBn1QYkiUzU1KoZpSGshyphenhyphenqJDRzQ/s1600/hastins.jpg" title="21 Linton Crescent, Hastings" data-original-height="375" data-original-width="500"></a></p><p>
Baird moved to London in November 1924 in the hope of showing off his burgeoning invention, setting up a workshop in the attic at <a href="https://osm.org/go/euu4hRekU-?m=" target="_blank">22 Frith Street</a>. Amongst those who dropped by was Gordon Selfridge who invited Baird to give <a href="https://www.bairdtelevision.com/selfridges.html" target="_blank">demonstrations of his device</a> in the Palm Court during his store's upcoming Birthday Week celebrations. He gave three shows a day to long queues of spectators, each invited to peer down a funnel at outlines of shapes transmitted from a separate device a few yards away, including a paper mask which Baird would make 'wink' by covering the eyehole. At this stage Baird's 'Televisor' was still electro-mechanical, the images formed by <a href="https://ieeexplore.ieee.org/document/9779318" target="_blank">spinning discs</a> with doubled-up lenses and perforated rectangular holes. But spectators were impressed, and Baird earned a much-needed £60 to plough back into his enterprise.
</p><p>
By October 1925 Baird had honed his processes sufficiently to be able to transmit an image with gradations of light and shade. Initially he used a ventriloquist's dummy called <a href="https://en.wikipedia.org/wiki/Stooky_Bill" target="_blank">Stooky Bill</a>, this because it had greater contrast than a human face and also because it wouldn't be harmed by intense heat or possible exploding glass. Later, somewhat over-excitedly, he invited a 20 year-old office worker called William Taynton to come upstairs and become TV's first human subject. <a href="https://www.bbc.co.uk/culture/article/20250925-the-office-worker-who-became-the-first-person-ever-to-appear-on-tv" target="_blank">William wasn't keen</a> but an appearance fee of half a crown persuaded him to pick through a jungle of wires, sit in front of blazing hot lamps and stick his tongue out, for just long enough that Baird exclaimed  "I've seen you, William, I've seen you. I've got television at last!" When the time came for a <a href="https://www.english-heritage.org.uk/visit/blue-plaques/john-logie-baird-television/" target="_blank">blue plaque</a> to be unveiled outside 22 Frith Street in 1951, it was William they invited back to do the honours.
</p><p>
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOZWftzsxiNzDnss7Ng4k5nj4ije60e3ORtaOMFhozYY23JkjgZtXWswkSgxwgx6N-8w5rdfYrnNkN1wuU1HF5zpRcizdMDBm4kQZ72tKIOULbuKdHdpHj1y-kA4XL_qikuFdEloeJNsbKU78fJd_A03ZHwv7wxM5kWAAWRFa9-Dd8V8mM2xUwJg/s1600/1926plaq.jpg" title="blue plaque at 22 Frith Street" data-original-height="375" data-original-width="500"></p><p>
Then on 26th January 1926 came the first <a href="https://theconversation.com/a-century-ago-john-logie-baird-achieved-a-landmark-moment-in-television-history-the-viewers-werent-convinced-274089" target="_blank">official demonstration</a> to members of the press. Journalists and guests from the Royal Institution were invited into Baird's workshop in small groups and first shown the dummy on screen, then each other's faces transmitted from a separate room. Only one visitor got too close to the discs and ended up with a sliced beard. Most of those present weren't especially impressed and failed to realise the significance of what they'd just seen, but <a href="https://www.bairdtelevision.com/the-televisor-successful-test-of-new-apparatus-1926.html" target="_blank">The Times</a> followed up with a short article two days later.
</p><blockquote><span>Members of the Royal Institution and other visitors to a laboratory in an upper room in Frith-Street, Soho, on Tuesday saw a demonstration of apparatus invented by Mr. J.L. Baird, who claims to have solved the problem of television. They were shown a transmitting machine, consisting of a large wooden revolving disc containing lenses, behind which was a revolving shutter and a light sensitive cell. It was explained that by means of the shutter and lens disc an image of articles or persons standing in front of the machine could be made to pass over the light sensitive cell at high speed. The current in the cell varies in proportion to the light falling on it, and this varying current is transmitted to a receiver where it controls a light behind an optical arrangement similar to that at the sending end. By this means a point of light is caused to traverse a ground glass screen. The light is dim at the shadows and bright at the high lights, and crosses the screen so rapidly that the whole image appears simultaneously to the eye. <i><span size="1"><a href="https://www.bairdtelevision.com/the-televisor-successful-test-of-new-apparatus-1926.html" target="_blank">(The Times, 28th January 1926)</a></span></i></span>
</blockquote>
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhLidBUcZj-9IW0uPsufQsMSLWbfmR8_lphR-i8uV4ddWfaMtyvfq5g3b80s_BYnZWMnHLlKiK53t_T6Zq0TllMjypukVFsdnWU9b-s3s1hzjdmY5uq3DglQYVA6HxIe8ekHCxBRMQgqs9Uj9jgQR1FRptsU_7prWxa-2_CesqjMDktCoCT5_WpeA/s1600/baritali.jpg" title="22 Frith Street, Soho" data-original-height="375" data-original-width="500"><p>
These days 22 Frith Street is home to retro cafe <a href="https://www.flickr.com/photos/dgeezer/55061003800" target="_blank">Bar Italia</a>. It's been owned and run by the Polledri family <a href="https://web.archive.org/web/20150222075356/http://www.baritaliasoho.co.uk:80/history/" target="_blank">since 1949</a>, a coffee-squirting dynasty who also run the Little Italy restaurant nextdoor. The stone floor was laid by their uncle Torino, a terrazzo mosaic specialist, and the counter was one of the first in London to be graced by an original Gaggia machine. Once a magnet for mods on scooters Bar Italia has attracted many famous names over the years, notably Rocky Marciano whose huge poster has pride of place behind the counter. You could thus celebrate today's centenary with an espresso and a slice of pizza in the photo-bedecked interior, or risk sitting outside below the neon sign with a froth and cheesecake combo.
</p><p>
Number 22 also displays a Milestone <a href="https://www.londonremembers.com/memorials/john-logie-baird-frith-street-ieee" target="_blank">plaque</a> erected by The Institution of Electrical Engineers citing "the world's first public demonstration of live television". Below is a <a href="https://worldoriginsite.org/television-john-logie-baird/" target="_blank">much newer plaque</a> citing this as an accredited <a href="https://worldoriginsite.org/" target="_blank">World Origin Site</a>. I first saw one of these <a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5nNQ1ehgF54vVy2dNmP76XdDcSV3tAKKvEn00GaPvcrmPJP0qM2wNkn4P7MpTxJej68Ywvy6ZuNw672QYUMCW_JYBWKejqp5K7vwMTGhVk72-467w_DbZ4x7nTCc_D4dtjusbJTuXTPnD5RkNQDlLTvJErLeMtvgS_WcN6_ej6fd-2AnLoaSHbg/s1600/penicillin0001.jpg" target="_blank">inside</a> the Alexander Fleming Laboratory Museum earlier in the month, earned for the discovery of penicillin, but whereas that was designated WOS 0001 the invention of television only ranks 0037. I believe they're unveiling it <a href="https://worldoriginsite.org/wp-content/uploads/Image-09-12-2025-at-08.45.jpg" target="_blank">officially</a> at 2pm this afternoon, even though it was perfectly visible over the weekend.
</p><p>
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEittOtedoEQKDIyIulqT2FijzkmZysCWcwmLGh94ksOq_VljN7CQoqrQFJXnzK1Hhzp2EXj0BPFQ5AS41E5yaj0rAqf4hweHG4haqe1TvfL0Fwr2KhfFOgS6Cr6JziW9H2CXO1DDXN9NyGaiLGqd1mfqBcOefKznWhT62APIx3-3v9jmbM0lvyQjQ/s1600/worldorig.jpg" title="World Origin Site 0037" data-original-height="375" data-original-width="500"></p><p>
Baird was a highly driven inventor and entrepreneur and went on to develop prototypes for <a href="https://blog.scienceandmediamuseum.org.uk/history-of-british-television-timeline/" target="_blank">all sorts</a> of forward-looking formats. In 1927 he came up with ‘Phonovision’ (image recordings onto 78 rpm gramophone records) and ‘Noctovision’ (infra-red TV). In 1928, amazingly, he demonstrated both colour television and stereoscopic (3D) television. His ultimate aim was television broadcasting via the BBC, beginning experimental transmissions of 30-line television in 1930 and delivering the first outside broadcast (from the Derby) in 1931, not that anyone was yet watching.
</p><p>
But in 1932 EMI started to provide serious competition, developing their own pioneering electronic television camera called the <a href="https://collection.sciencemuseumgroup.org.uk/objects/co241682/marconi-emi-television-camera" target="_blank">Emitron</a>. The government's Television Advisory Committee ultimately recommended that both Baird's 240-line mechanical system and Marconi-EMI's 405-line electronic system be developed as alternatives for the proposed new London television station. And so it was that when broadcast TV first launched at Alexandra Palace on <a href="https://diamondgeezer.blogspot.com/2011/11/bbc75.html" target="_blank">2nd November 1936</a> the two systems alternated one week each... Baird second.
</p><p>
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUMKlzdQnGb6SgCi4U41nL3CcRcvp6XqNHMsKJ08y8_S0AVfc3uS2QVnn_7t646BKwBMhv3IBn7jyS8WKCKjDa8DL7VjB8xmBIQAZjGfCHjPtCEHjp0rJrURP5tlIQkt3DQG4djDhbIzx6-2Ms-HYglUdjgZOpGSYfu8lQlKLk0ptNOFGcfo1w7A/s1600/1936plaq.jpg" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4Q0FgjL7J_5dvIXCko_SiHkT1Ga370BIJUzRpBXITulmjgTsyaZXpqj8YcccuoOXxDvVoC50sMP0-viDAdhBa6-6Fbj5GG2ifVGUqMn_y0j4aWx8nCQXGOCb9eLjf-fY_fXYu9fszLGvsI2V-GbNVfCARTH22P0c3uOz2EPTMLBKdVtV1SGT6Iw/s1600/allipalli.jpg" title="TV display at Alexandra Palace" data-original-height="375" data-original-width="500"></a></p><p>
It rapidly became clear that the Marconi system was far superior and Baird's was dropped after just three months. Baird also suffered when his studios were burned in the fire that destroyed the Crystal Palace, and his company went into receivership when all TV broadcasting was suspended at the start of WW2. He carried on inventing at home in <a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizMlXQIo9On3DxmkHARco76k-QWxHvE3s0LY6c0okLadKGn_Qw35AL6Mbuaj_QeRLXivRfn2h6LJy8Yfsp6OXSim1EnBUW8DxA87XaJfMnTUwJ4HU3BGaF8maeE7EsM6QHd4lHHdZqCwt0YMqXjzDs1fRxM-K1bhMLcVYbB0EwnHXad3-g9-9iOA/s1600/se26.jpg" target="_blank">Sydenham</a>, vastly improving his system for colour television, until his laboratory was made unusable by bomb damage. Alas ill health <a href="https://www.bairdtelevision.com/final.html" target="_blank">caught up with him</a> and he died after a stroke at the age of 57, just one week after the BBC restarted television broadcasts in 1946. You can't see his final home in Bexhill because it was replaced by a block of flats in <a href="http://news.bbc.co.uk/1/hi/england/southern_counties/4330160.stm" target="_blank">2005</a>, but Baird does have an impressive number of plaques across <a href="https://londonist.com/london/history/john-logie-baird-why-so-many-plaques" target="_blank">central London</a> and <a href="http://diamondgeezer.blogspot.com/2026/01/26-things-to-see-in-se26.html" target="_blank">SE26</a>.
</p><p>
It's not always easy being first, and after early televisual success <a href="https://www.bairdtelevision.com/mobileindex.html" target="_blank">John Logie Baird</a> saw his star wane and fade. But it's still him we remember for making possible one of the key transformative inventions of the 20th century, even though barely anyone watched his first efforts. It took ten years to get from Stooky Bill to BBC TV's opening night, then another two decades before the widespread adoption of TV sets in British households and two more until colour television took hold. But 100 years on almost all of us have a TV set at home and effectively another in our pocket, and all because a Scotsman came to London and cleverly spun some discs.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google AI Overviews cite YouTube more than any medical site for health queries (309 pts)]]></title>
            <link>https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study</link>
            <guid>46766031</guid>
            <pubDate>Mon, 26 Jan 2026 14:27:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study">https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study</a>, See on <a href="https://news.ycombinator.com/item?id=46766031">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Google’s search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that <a href="https://www.theguardian.com/technology/ng-interactive/2026/jan/24/how-the-confident-authority-of-google-ai-overviews-is-putting-public-health-at-risk" data-link-name="in body link">raises fresh questions</a> about a tool seen by 2 billion people each month.</p><p>The company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are <a href="https://search.google/intl/en-GB/ways-to-search/ai-overviews/" data-link-name="in body link">“reliable”</a> and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.</p><p>However, a study that analysed responses to more than 50,000 health queries, captured using Google searches from Berlin, found the top cited source was <a href="https://www.theguardian.com/technology/youtube" data-link-name="in body link" data-component="auto-linked-tag">YouTube</a>. The video-sharing platform is the world’s second most visited website, after Google itself, and is owned by Google.</p><p>Researchers at SE Ranking, a search engine optimisation platform, found YouTube made up 4.43% of all AI Overview citations. No hospital network, government health portal, medical association or academic institution came close to that number, they said.</p><p>“This matters because YouTube is not a medical publisher,” <a href="https://seranking.com/blog/health-ai-overviews-youtube-vs-medical-sites/" data-link-name="in body link">the researchers wrote</a>. “It is a general-purpose video platform. Anyone can upload content there (eg board-certified physicians, hospital channels, but also wellness influencers, life coaches, and creators with no medical training at all).”</p><p>Google told the Guardian that AI Overviews was designed to surface high-quality content from reputable sources, regardless of format, and a variety of credible health authorities and licensed medical professionals created content on YouTube. The study’s findings could not be extrapolated to other regions as it was conducted using German-language queries in Germany, it said.</p><p>The research comes after <a href="https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information" data-link-name="in body link">a Guardian investigation</a> found people were being put at risk of harm by false and misleading health information in Google AI Overviews responses.</p><p>In one case that experts said was “dangerous” and “alarming”, Google provided bogus information about crucial liver function tests that could have left people with serious liver disease wrongly thinking they were healthy. The company later <a href="https://www.theguardian.com/technology/2026/jan/11/google-ai-overviews-health-guardian-investigation" data-link-name="in body link">removed AI Overviews</a> for some but not all medical searches.</p><p>The SE Ranking study analysed 50,807 healthcare-related prompts and keywords to see which sources AI Overviews relied on when generating answers.</p><p>They chose Germany because its healthcare system is strictly regulated by a mix of German and EU directives, standards and safety regulations. “If AI systems rely heavily on non-medical or non-authoritative sources even in such an environment, it suggests the issue may extend beyond any single country,” <a href="https://seranking.com/blog/health-ai-overviews-youtube-vs-medical-sites/" data-link-name="in body link">they wrote</a>.</p><p>AI Overviews surfaced on more than 82% of health searches, the researchers said. When they looked at which sources AI Overviews relied on most often for health-related answers, one result stood out immediately, they said. The single most cited domain was YouTube with 20,621 citations out of a total of 465,823.</p><figure id="185bbe1c-e0e1-4cd8-8c9e-da694e2068bd" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="YouTube logo displayed on a mobile phone and on a laptop screen" src="https://i.guim.co.uk/img/media/8bbe1e1007327f2ddc6b4b808fea51afcfa8b317/0_0_4888_3259/master/4888.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="296.6970130932897" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Researchers at SE Ranking found YouTube made up 4.43% of all AI Overview citations. </span> Photograph: Adam Vaughan/EPA</figcaption></figure><p>The next most cited source was <a href="https://ndr.de/" data-link-name="in body link">NDR.de</a>, with 14,158 citations (3.04%). The German public broadcaster produces health-related content alongside news, documentaries and entertainment. In third place was a medical reference site, <a href="https://msdmanuals.com/" data-link-name="in body link">Msdmanuals.com</a> with 9,711 citations (2.08%).</p><p>The fourth most cited source was Germany’s largest consumer health portal, <a href="https://netdoktor.de/" data-link-name="in body link">Netdoktor.de</a>, with 7,519 citations (1.61%). The fifth most cited source was a career platform for doctors, <a href="https://praktischarzt.de/" data-link-name="in body link">Praktischarzt.de</a>, with 7,145 citations (1.53%).</p><p>The researchers acknowledged limitations to their study. It was conducted as a one-time snapshot in December 2025, using German-language queries that reflected how users in Germany typically search for health information.</p><p>Results could vary over time, by region, and by the phrasing of questions. However, even with those caveats, the findings still prompted alarm.</p><p>Hannah van Kolfschooten, a researcher specialising in AI, health and law at the University of Basel who was not involved with the research, said: “This study provides empirical evidence that the risks posed by AI Overviews for health are structural, not anecdotal. It becomes difficult for Google to argue that misleading or harmful health outputs are rare cases.</p><p>“Instead, the findings show that these risks are embedded in the way AI Overviews are designed. In particular, the heavy reliance on YouTube rather than on public health authorities or medical institutions suggests that visibility and popularity, rather than medical reliability, is the central driver for health knowledge.”</p><p>A Google spokesperson said: “The implication that AI Overviews provide unreliable information is refuted by the report’s own data, which shows that the most cited domains in AI Overviews are reputable websites. And from what we’ve seen in the published findings, AI Overviews cite expert YouTube content from hospitals and clinics.”</p><p>Google said the study showed that of the 25 most cited YouTube videos, 96% were from medical channels. However, the researchers cautioned that these videos represented fewer than 1% of all the YouTube links cited by AI Overviews on health.</p><p>“Most of them (24 out of 25) come from medical-related channels like hospitals, clinics and health organisations,” <a href="https://seranking.com/blog/health-ai-overviews-youtube-vs-medical-sites/" data-link-name="in body link">the researchers wrote</a>. “On top of that, 21 of the 25 videos clearly note that the content was created by a licensed or trusted source.</p><p>“So at first glance it looks pretty reassuring. But it’s important to remember that these 25 videos are just a tiny slice (less than 1% of all YouTube links AI Overviews actually cite). With the rest of the videos, the situation could be very different.”</p><figure id="a038a8db-db52-4588-9d3c-8353144d84f0" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.GuideAtomBlockElement"><gu-island name="GuideAtomWrapper" priority="feature" deferuntil="visible" props="{&quot;id&quot;:&quot;ea05a110-2f0f-41ea-ba0a-8d9189dbddb7&quot;,&quot;title&quot;:&quot;Contact us about this story&quot;,&quot;html&quot;:&quot;<p><strong></strong></p><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p></p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p></p><p>If you don't already have the Guardian app, download it (<a href=\&quot;https://apps.apple.com/app/the-guardian-live-world-news/id409128287\&quot;>iOS</a>/<a href=\&quot;https://play.google.com/store/apps/details?id=com.guardian\&quot;>Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href=\&quot;https://www.theguardian.com/securedrop\&quot;>SecureDrop platform</a>.</p><p></p><p>Finally, our guide at <a href=\&quot;https://www.theguardian.com/tips\&quot;>theguardian.com/tips</a>&amp;nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&amp;nbsp;</p>&quot;,&quot;image&quot;:&quot;https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452&quot;,&quot;credit&quot;:&quot;Illustration: Guardian Design / Rich Cousins&quot;}"><div data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"><details data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-snippet-type="guide"><summary><span>Quick Guide</span><h4>Contact us about this story</h4><span><span><span></span>Show</span></span></summary><div><p><img src="https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452" alt=""></p><div><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p><p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p></div><div><p>Illustration: Guardian Design / Rich Cousins</p></div></div></details></div></gu-island></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple introduces new AirTag with longer range and improved findability (179 pts)]]></title>
            <link>https://www.apple.com/newsroom/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/</link>
            <guid>46765819</guid>
            <pubDate>Mon, 26 Jan 2026 14:10:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/">https://www.apple.com/newsroom/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/</a>, See on <a href="https://news.ycombinator.com/item?id=46765819">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        

        <div>
                
                
                
                    <h2>
                        
    
        Apple introduces new <p>AirTag with expanded </p><p>connectivity range </p><p>and improved findability
    

                    </p></h2>
                
            </div>

        <div>
                
                
                    The next generation of AirTag — the bestselling item finder — is even easier to locate with more powerful Precision Finding, a&nbsp;longer Bluetooth range, and a louder speaker
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    


    
        
        
        
        
            <figure aria-label="Media, The new AirTag with the FineWoven Key Ring in fox orange.">
                <div>
                         
                            
                            <div>
                                Apple introduced the new AirTag, now with an expanded finding range and a louder speaker.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-FineWoven-Key-Ring.zip" download="" data-analytics-title="download image - Apple-AirTag-FineWoven-Key-Ring_inline" aria-label="Download media, The new AirTag with the FineWoven Key Ring in fox orange."></a>
                    </div>
            </figure>
        
    












    
    
    


     
     
    
    
        <div>Apple today unveiled the new <a href="https://www.apple.com/airtag/" target="_blank">AirTag</a>, a powerful accessory that helps users keep track of and find the items that matter most with Apple’s Find My app — now with an expanded finding range and a louder speaker. Powered by the strength of the Find My network, AirTag allows users to keep tabs on their belongings every single day. Since the launch of AirTag in 2021, users from around the world have shared stories of being reunited with lost luggage, keys, bicycles, bags, and more. With the help of AirTag placed inside an instrument case, a musician was able to locate their lost instrument and perform that evening, while another user was able to find lost luggage that contained a lifesaving medication. AirTag is designed exclusively for tracking objects and offers industry-leading protections against unwanted tracking. It is available today for the same price as its predecessor: $29 for a single AirTag and $99 for a four-pack, with free personalized engraving available on <a href="http://apple.com/" target="_blank">apple.com</a> and the Apple Store app.
</div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="airtag-find-my">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-15e93aecec99c44fef2edbf1688e8d91" href="#gallery-15e93aecec99c44fef2edbf1688e8d91" data-ac-gallery-trigger="gallery-15e93aecec99c44fef2edbf1688e8d91"><span>iPhone 17 Pro shows a list of a user’s items alongside a map.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1e02922a91356997ffdc0be2fa25a7cd" href="#gallery-1e02922a91356997ffdc0be2fa25a7cd" data-ac-gallery-trigger="gallery-1e02922a91356997ffdc0be2fa25a7cd"><span>iPhone 17 Pro shows an overview of a user named Royce’s backpack, including its location on a map.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-15e93aecec99c44fef2edbf1688e8d91" aria-labelledby="gallery-dotnav-15e93aecec99c44fef2edbf1688e8d91" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:items">
                                
                                <div>
                                    <div>Powered by the strength of the Find My network, AirTag allows users to keep tabs on their belongings every single day, from keys and wallets to backpacks, luggage, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-items-01.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-items-01_inline" aria-label="Download media, iPhone 17 Pro shows a list of a user’s items alongside a map."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1e02922a91356997ffdc0be2fa25a7cd" aria-labelledby="gallery-dotnav-1e02922a91356997ffdc0be2fa25a7cd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:royces-backpack">
                                
                                <div>
                                    <div>Powered by the strength of the Find My network, AirTag allows users to keep tabs on their belongings every single day, from keys and wallets to backpacks, luggage, and more.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-items-02.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-items-02_inline" aria-label="Download media, iPhone 17 Pro shows an overview of a user named Royce’s backpack, including its location on a map."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Enhanced Range and Findability</strong>
</h2>
                 
             
                 <div>Apple’s second-generation Ultra Wideband chip — the same chip found in the iPhone 17 lineup, iPhone Air, Apple Watch Ultra 3, and Apple Watch Series 11 — powers the new AirTag, making it easier to locate than ever before. Using haptic, visual, and audio feedback, Precision Finding guides users to their lost items from up to 50 percent farther away than the previous generation.<sup>1</sup> And an upgraded Bluetooth chip expands the range at which items can be located. For the first time, users can use Precision Finding on Apple Watch Series 9 or later, or Apple Watch Ultra 2 or later, to find their AirTag, bringing a powerful experience to the wrist.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="enhanced-range-findability">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-cd66f894227af0cb51e48153763fb4a7" href="#gallery-cd66f894227af0cb51e48153763fb4a7" data-ac-gallery-trigger="gallery-cd66f894227af0cb51e48153763fb4a7"><span>A user’s Apple Watch shows an item labeled “Debra’s Keys” is 20 feet away.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-e6dbfac545be2b80d70b52c772139a7d" href="#gallery-e6dbfac545be2b80d70b52c772139a7d" data-ac-gallery-trigger="gallery-e6dbfac545be2b80d70b52c772139a7d"><span>A user’s Apple Watch shows a green screen shows that the user is four feet away from an item labeled “Family Car Keys.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-cd66f894227af0cb51e48153763fb4a7" aria-labelledby="gallery-dotnav-cd66f894227af0cb51e48153763fb4a7" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:twenty-feet">
                                
                                <div>
                                    <div>Precision Finding guides users through haptic, visual, and audio feedback to their lost items from up to 50 percent farther away than the previous generation, and an updated Bluetooth chip expands the range at which items can be located.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-Precision-Finding-01.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-Precision-Finding-01_inline" aria-label="Download media, A user’s Apple Watch shows an item labeled “Debra’s Keys” is 20 feet away."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-e6dbfac545be2b80d70b52c772139a7d" aria-labelledby="gallery-dotnav-e6dbfac545be2b80d70b52c772139a7d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:four-feet">
                                
                                <div>
                                    <div>Precision Finding guides users through haptic, visual, and audio feedback to their lost items from up to 50 percent farther away than the previous generation, and an updated Bluetooth chip expands the range at which items can be located.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-Precision-Finding-02.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-Precision-Finding-02_inline" aria-label="Download media, A user’s Apple Watch shows a green screen shows that the user is four feet away from an item labeled “Family Car Keys.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>With its updated internal design, the new AirTag is 50 percent louder than the previous generation, enabling users to hear their AirTag from up to 2x farther than before. Paired with its enhanced Precision Finding capabilities and distinctive new chime, AirTag now makes it easier for users to find their important items, such as keys hidden deep in between couch cushions or a wallet as they head out the door.
</div>
                 
             
                 <h2><strong>The Find My Network and Share Item Location</strong>
</h2>
                 
             
                 <div>Find My makes it easy to locate AirTag, Apple devices, and compatible third-party devices, as well as keep up with friends and family, all while protecting user privacy. If AirTag is out of range of its paired iPhone, the Find My network can help track it down. The Find My network is a crowdsourced network of Apple devices that use Bluetooth technology to detect the location of an accessory or device, and report their approximate location back to the owner.
</div>
                 
             
         </div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, A user’s iPhone 17 Pro shows a screen that reads “Share Item Location” and gives instructions for finding a lost AirTag. A button at the bottom of the screen reads “Continue.”">
                <div>
                         
                            
                            <div>
                                Find My makes it easy to locate AirTag, Apple devices, and compatible third-party devices, as well as keep up with friends and family, all while protecting user privacy.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Share-Item-Location.zip" download="" data-analytics-title="download image - Apple-AirTag-Share-Item-Location_inline" aria-label="Download media, A user’s iPhone 17 Pro shows a screen that reads “Share Item Location” and gives instructions for finding a lost AirTag. A button at the bottom of the screen reads “Continue.”"></a>
                    </div>
            </figure>
        
    












    
    
    


     
     
    
    
        <div>
             
                 <div>The new AirTag integrates seamlessly with Share Item Location, an iOS feature designed to help users recover a misplaced item by temporarily and securely sharing its location with trusted third parties, such as airlines, so they can assist in recovering delayed luggage or other lost items. Apple has partnered directly with more than 50 airlines to privately and securely accept Share Item Location links.
</div>
                 
             
                 <div>With Share Item Location, users can share the location of a misplaced item with a participating airline’s customer service team. <a href="https://www.sita.aero/pressroom/news-releases/one-year-later-sita-shows-how-integration-of-apples-find-my-share-item-location-can-strengthen-baggage-operations-for-airports-and-airlines/" target="_blank" rel="nofollow" data-analytics-exit-link="">According to SITA</a>, a leading IT provider for airlines, carriers report that using Share Item Location has reduced baggage delays by 26 percent and reduced incidences of “truly lost” or unrecoverable luggage by 90 percent. Access is granted only to authorized personnel via secure Apple Account or partner authentication. The shared location will be disabled as soon as a user is reunited with their item, can be stopped by the owner at any time, and will automatically expire after seven days.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="share-item-location">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-4fc5a46ffe921ab48b4c2b45aff20aa1" href="#gallery-4fc5a46ffe921ab48b4c2b45aff20aa1" data-ac-gallery-trigger="gallery-4fc5a46ffe921ab48b4c2b45aff20aa1"><span>iPhone 17 Pro shows a map and a screen that reads “With You,” and contains a list of items that includes “Guillermo’s Umbrella” and “Family Car Keys.”</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-522e01b80cafc6c8228290e040d39ad8" href="#gallery-522e01b80cafc6c8228290e040d39ad8" data-ac-gallery-trigger="gallery-522e01b80cafc6c8228290e040d39ad8"><span>iPhone 17 Pro shows an screen that reads “Family Car Keys” and offers information on sharing the AirTag’s location. Two buttons at the bottom of the screen read “Continue” and “Not Now.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-4fc5a46ffe921ab48b4c2b45aff20aa1" aria-labelledby="gallery-dotnav-4fc5a46ffe921ab48b4c2b45aff20aa1" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:with-you">
                                
                                <div>
                                    <div>Share Item Location is an iOS feature that helps users locate and recover misplaced items by easily and securely sharing the location of an AirTag or Find My network accessory with third parties such as airlines.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-items-share.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-items-share_inline" aria-label="Download media, iPhone 17 Pro shows a map and a screen that reads “With You,” and contains a list of items that includes “Guillermo’s Umbrella” and “Family Car Keys.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-522e01b80cafc6c8228290e040d39ad8" aria-labelledby="gallery-dotnav-522e01b80cafc6c8228290e040d39ad8" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:family-car-keys">
                                
                                <div>
                                    <div>Share Item Location is an iOS feature that helps users locate and recover misplaced items by easily and securely sharing the location of an AirTag or Find My network accessory with third parties such as airlines.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-Airtag-share.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-Airtag-share_inline" aria-label="Download media, iPhone 17 Pro shows an screen that reads “Family Car Keys” and offers information on sharing the AirTag’s location. Two buttons at the bottom of the screen read “Continue” and “Not Now.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Industry-Leading Security Features</strong>
</h2>
                 
             
                 <div>The new AirTag is designed from the ground up to keep location data private and secure. AirTag doesn’t physically store location data or history on device, and end-to-end encryption protects all communication with the Find My network, ensuring that only the owner of a device can access its location data. No one, including Apple, knows the identity or location of any device that helped find it. Designed exclusively for tracking objects, and not people or pets, the new AirTag incorporates a suite of industry-first protections against unwanted tracking, including cross-platform alerts and unique Bluetooth identifiers that change frequently.
</div>
                 
             
         </div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, A user’s iPhone 17 Pro shows an alert that reads, “AirTag Detected Near You,” alongside a map and more details on the tracking notification.">
                <div>
                         
                            
                            <div>
                                The new AirTag incorporates a suite of industry-first protections against unwanted tracking, including cross-platform alerts and unique Bluetooth identifiers that change frequently.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/article/Apple-AirTag-Find-My-Airtag-detected.zip" download="" data-analytics-title="download image - Apple-AirTag-Find-My-Airtag-detected_inline" aria-label="Download media, A user’s iPhone 17 Pro shows an alert that reads, “AirTag Detected Near You,” alongside a map and more details on the tracking notification."></a>
                    </div>
            </figure>
        
    












    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Environmental Responsibility and Accessory Compatibility</strong>
</h2>
                 
             
                 <div>Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The new AirTag is designed with the environment in mind, with 85 percent recycled plastic in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled gold plating in all Apple-designed printed circuit boards. The paper packaging is 100 percent fiber-based and can be easily recycled. Maintaining the same form factor as the original, the new AirTag is compatible with all existing AirTag accessories, including the FineWoven Key Ring, which is made from 68 percent recycled content and available in five beautiful colors.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>The new AirTag is available to order on <a href="http://apple.com/" target="_blank">apple.com</a> and in the Apple Store app today, and will be available at Apple Store locations later this week. The new AirTag will also be available at Apple Authorized Resellers.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers can add a personalized engraving to the new AirTag for free during checkout on <a href="https://www.apple.com/" target="_blank">apple.com</a> and the Apple Store app.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AirTag is available in one- and four-packs for <strong>$29</strong> (U.S.) and <strong>$99</strong> (U.S.), respectively.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The Apple-designed AirTag FineWoven Key Ring is available in fox orange, midnight purple, navy, moss, and black for <strong>$35 </strong>(U.S.).<sup>2</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The new AirTag requires a compatible iPhone with iOS 26 or later, or iPad with iPadOS 26 or later. Customers must have an Apple Account and be signed into their iCloud account. Certain features require Find My to be enabled in iCloud settings.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Precision Finding on Apple Watch requires Apple Watch Series 9 or later, or Apple Ultra 2 or later, with watchOS 26.2.1.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Precision Finding is not available in countries and regions where Ultra Wideband technology is restricted. For more information, visit <a href="https://www.apple.com/uwb/" target="_blank">apple.com/uwb</a>.</li>
<li>AirTag accessories, including the AirTag FineWoven Key Ring, are sold separately.</li>
</ol>

        </div>



    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porting 100k lines from TypeScript to Rust using Claude Code in a month (124 pts)]]></title>
            <link>https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html</link>
            <guid>46765694</guid>
            <pubDate>Mon, 26 Jan 2026 13:58:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html">https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html</a>, See on <a href="https://news.ycombinator.com/item?id=46765694">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>I read <a href="https://www.linkedin.com/posts/galenh_principal-software-engineer-coreai-microsoft-activity-7407863239289729024-WTzf/">this post</a> “Our strategy is to combine AI <em>and</em> Algorithms to rewrite Microsoft’s largest codebases [from C++ to Rust]. Our North Star is ‘1 engineer, 1 month, 1 million lines of code.” and it got me curious, how difficult is it really?</p>



<p>I've long wanted to build a competitive Pokemon battle AI after watching a lot of <a href="https://www.youtube.com/watch?v=qR9nMPr7o5Q">WolfeyVGC</a> and following the <a href="https://pokeagent.github.io/">PokéAgent challenge</a> at NeurIPS. Thankfully there's an open source project called "<a href="https://github.com/smogon/pokemon-showdown">Pokemon Showdown</a>" that implements all the rules but it's written in JavaScript which is quite slow to run in a training loop. So my holiday project came to life: let's convert it to Rust using Claude!</p>



<h2>Escaping the sandbox</h2>



<p>Having the AI able to run arbitrary code on your machine is dangerous, so there's a lot of safeguards put in place. But... at the same time, this is what I want to do in this case. So let me walk through the ways I escaped the various sandboxes.</p>



<h3>git push</h3>



<p>Claude runs in a sandbox that limits some operations like ssh access. You need ssh access in order to publish to GitHub. This is very important as I want to be able to check how the AI is doing from my phone while I do some other activities 😉</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-1.png" alt=""></figure>



<p>What I realized is that I can run the code on my terminal but Claude cannot do it from its own terminal. So what I did was to ask Claude to write a nodejs script that opens an http server on a local port that executes the git commands from the url. Now I just need to keep a tab open on my terminal with this server active and ask Claude to write instructions in Claude.md for it to interact with it.</p>



<h3>rustc</h3>



<p>There's an antivirus on my computer that requires a human interaction when an unknown binary is being ran. Since every time we compile it's a new unknown binary, this wasn't going to work.</p>



<p>What I found is that I can setup a local docker instance and compile + run the code inside of docker which doesn't trigger the antivirus. Again, I asked Claude to generate the right instructions in Claude.md and problem solved.</p>



<p>The next hurdle was to figure out how to let Claude Code for hours without any human intervention.</p>



<h3>--yes</h3>



<p>Claude keeps asking for permission to do things. I tried adding a bunch of things to the allowed commands file and <code>--allow-dangerously-skip-permissions --dangerously-skip-permissions</code>was disabled in my environment (it has now been resolved).</p>



<p>I realized that I could run an AppleScript that presses enter every few seconds in another tab. This way it's going to say Yes to everything Claude asks to do. So far it hasn't decided to hack my computer...</p>



<pre><code>#!/bin/bash

osascript -e \
'tell application "System Events"
    repeat
        delay 5
        key code 36
    end repeat
end tell'</code></pre>



<h3>Never give up</h3>



<p>Claude after working for some time seem to always stop to recap things. I tried prompting it to never do, even threatening it to no avail.</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-2.png" alt=""></figure>



<p>I tried using the Ralph Wiggum loop but it <a href="https://x.com/Vjeux/status/2007545697193890024">couldn't get it to work</a> and apparently I'm not alone.</p>



<p>What ended up working is to copy in my clipboard the task I wanted it to do and to tweak the script above to hit the keys "cmd-v" after pressing enter. This way in case it asks a question the "enter" is being used and in case it's not it's queuing the prompt for when Claude is giving back control.</p>



<h3>Auto-updates</h3>



<p>There are programs on the computer like software updater that can steal the focus from the terminal window, for example showing a modal. Once that happens, then the cmd-v / enter are no longer sent to the terminal and the execution stops.</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2025/12/image.png" alt=""><figcaption><br></figcaption></figure>



<p>I used my trusty Auto Clicker by MurGaa from Minecraft days to simulate a left click every few seconds. I place my terminal on the edge of the screen and same for my mouse so that when a modal appears in the middle, it refocuses the terminal correctly.</p>



<p>It also prevents the computer from going to sleep so that it can run even when I'm not using the laptop or at night.</p>



<h3>Bugs 🐜</h3>



<p>Reliability when running things for a long period of time is paramount. Overall it's been a pretty smooth ride but I ran into this specific error during a handful of nights which stopped the process. I hope they get to the bottom of it and solve it as I'm not the only one to <a href="https://github.com/anthropics/claude-code/issues/16368">report it</a>!</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-3.png" alt=""></figure>



<p>This setup is far from optimal but has worked so far. Hopefully this gets streamlined in the future!</p>



<h2>Porting Pokemon</h2>



<h3>One Shot</h3>



<p>At the very beginning, I started with a simple prompt asking Claude to port the codebase and make sure that things are done line by line. At first it felt extremely impressive, it generated thousands of lines of Rust that was compiling.</p>



<p>Sadly it was only an appearance as it took a lot of shortcuts. For example, it created two different structures for what a move is in two different files so that they would both compile independently but didn't work when integrated together. It ported all the functions very loosely where anything that was remotely complicated would not be ported but instead "simplified".</p>



<p>I didn't realize it yet, I got the loop working to have it port more and more code. The issue is that it created wrong abstractions all over the place and kept adding hardcoded code to make whatever it was supposed to fix work. This wasn't going to go anywhere.</p>



<h3>Giving it structure</h3>



<p>At this point I knew that I needed to be a lot more prescriptive for what I wanted out of it. Taking a step back, the end result should have every JavaScript file and every method inside to have a Rust equivalent.</p>



<p>So I asked Claude to write a script that takes all the files and methods in the JavaScript codebase and put comments in the rust codebase with the JavaScript source, next to the Rust methods.</p>



<p>It was really important for it to be a script as even when instructed to copy code over, it would mistranslate JavaScript code. Being deterministic here greatly increased the odds of getting the right results.</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-4.png" alt=""></figure>



<h3>Litte Islands</h3>



<p>The next challenge is that the original files were thousands of lines long, double it with source comments we got to files more than 10k lines long. This causes a ton of issues with the context window where Claude straight up refuses to open the file. So it started reading the file in chunks but without a ton of precision. Also the context grew a lot quicker and compaction became way more frequent.</p>



<p>So I went ahead and split every method into its own file for the Rust version. This dramatically improved the results. For maximal efficiency I would need to do the same for the JavaScript codebase as well but I was too afraid to do it and accidentally change the behavior so decided not to.</p>



<div><figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-5.png" alt="" width="143" height="305"></figure></div>



<h3>Cleanup</h3>



<p>The process of porting went through two repeating phases. I would give a large task to Claude to do in a loop that would churn on it for a day, and then I would need to spend time cleaning up the places where it went into the wrong direction.</p>



<p>For the cleanup, I still used Claude but gave a lot more specific recommendations. For example, I noticed that it would hardcode moves/abilities/items/... behaviors everywhere in the code when left unchecked, even after explicitly telling it not to. So I would manually look for all these and tell it to move them into the right places.</p>



<p>This is where engineering skills come into play, all my experience building software let me figure out what went wrong and how to fix it. The good part is that I didn't have to do the cleanup myself, Claude was able to do it just fine when directed to.</p>



<h2>Integration</h2>



<h3>Build everything before testing</h3>



<p>So far, I just made sure that the code compiled, but have never actually put all the pieces together to ensure it actually worked. What Claude really wanted was to do a traditional software building strategy where you make "simple" implementations of all of the pieces and then build them up as time goes.</p>



<p>But in our case, all this iteration has already happened for 10 years on the pokemon-showdown codebase. It's counter productive to try and re-learn all these lessons and will unlikely converge the same way. What works better is to port everything at once, and then do the integration at the end once.</p>



<p>I've learned this strategy from working on Skip, a compiler. For years all the building blocks were built independently and then it all came together with nothing to show for but within a month at the end it all worked. I was so shocked.</p>



<h3>End-to-end test</h3>



<p>Once most of the codebase was ported one to one, I started putting it all together. The good thing is that we can run and edit the code in JavaScript and in Rust, and the input/output is very simple and standardized: list of pokemons with their options (moves, items, nature, iv/ev spread...) and then the list of actions at each step (moves and switches). Given the same random sequence, it'll advance the state the same way.</p>



<p>Now I can let Claude generate this testing harness and go through all the issues one by one. Impressively, it was able to figure out all issues and fix them.</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image.png" alt=""></figure>



<p>Over the course of 3 weeks it averaged fixing one issue every 20 minutes or so. It fixed hundreds of issues on its own. I never intervened, it was only a matter of time before it fixed every issue that it encountered.</p>



<div><figure><img src="https://pbs.twimg.com/media/G-rvZkbXYAAoWbm?format=jpg&amp;name=large" alt="Image" width="259" height="529"></figure></div>



<h3>Giving it structure</h3>



<p>At the beginning, this process was extremely slow. Every time a compaction happened, Claude became "dumb" again and reinvented the wheel, writing down tons of markdown files and test scripts along the way. Or Claude decided to take the easy way out and just generate tons of tests but never actually making them match with JavaScript.</p>



<p>So, I started looking at what it did well and encoding it. For example, it added a lot of debugging around the PRNG steps and what actions happened at every turn with all the debugging metadata. So I asked it to create a single test script to print down this information for a single step and to print stack traces. Then add instruction to the Claude.md file. This way every investigation started right away.</p>



<h3>The long slog</h3>



<p>I built used the existing random number generator to generate battles and could put in a number as a seed. This let me generate consistent battles at an increasing size.</p>



<p>I started fixing the first 100 battles, then 1000, 10k, 100k and I'm almost done solving all the issues for the first 2.4 million battles! I'm not sure how many more issues there are but the good thing is that they are getting smaller and smaller as the batch size increases.</p>



<figure><img src="https://blog.vjeux.com/wp-content/uploads/2026/01/image-6.png" alt=""></figure>



<h3>Types of issues</h3>



<p>There are two broad classes of issues that were fixed. The first one that I expected is that Rust has different constraints than JavaScript which need to be taken into account and lead to bugs:</p>



<ul><li>Rust has the "borrow checker" where a mutable variable cannot be passed in two different contexts at once. The problem is that "Pokemon" and "Battle" have references to each others. So there's a lot of workarounds like doing copies, passing indices instead of the object, providing functions with mutable object as callback...</li><li>The JavaScript codebase uses dynamism heavily where some function return '', undefined, null, 0, 1, 5.2, Pokemon... which all are handled with different behaviors. At first the rust port started using Option&lt;&gt; to handle many of them but then moved to structs with all these variants.</li><li>Rust doesn't support optional arguments so every argument has to be spelled out literally.</li></ul>



<p>But the second one are due to itself... Claude Code is like a smart student that is trying to find every opportunity to avoid doing the hard work and take the easy way out if it thinks it can get away with it.</p>



<ul><li>If a fix requires changing more than one or two files, this is a "significant infrastructure" and Claude Code will refuse to do it unless explicitly prompted and will put in whatever hacks it can to make the specific test work.</li><li>Along the same lines, it is going to implement "simplified" versions of things. For some methods, it was better to delete everything and asking it to port it over from scratch than trying to fix all the existing code it created.</li><li>The JavaScript comments are supposed to be the source of truth. But Claude is not above changing the original code if it feels like this is the way to solve the problem...</li><li>If given a list of tasks, it's going to avoid doing the ones that seem difficult until it is absolutely forced to. This is inefficient if not careful as it's going to keep spending time investigating and then skipping all the "hard" ones. Compaction is basically wiping all its memory.</li></ul>



<h2>Prompts</h2>



<p>I didn't write a single line of code myself in this project. I alternated between "co-op" where I work with Claude interactively during the day and creating a job for it to run overnight. I'll focus on the night ones for this section.</p>



<h3>Conversion</h3>



<p>For the first phase of the project, I mostly used variations of this one. Asking it to go through all the big files one by one and implement them faithfully (it didn't really follow instructions as we've seen later...)</p>



<blockquote><p>Open BATTLE_TODO.md to get the list of all the methods in both battle*.rs.<br>Inspect every single one of them and make sure that they are a direct translation the JavaScript file. If there's a method with the same name, the JavaScript definition will be in the comment.<br>If there's no JavaScript definition, question whether this method should be there in the rust version. Our goal is to follow as closely as possible the JavaScript version to avoid any bugs in translation. If you notice that the implementation doesn't match, do all the refactoring needed to match 1 to 1.<br>This will be a complex project. You need to go through all the methods one by one, IN ORDER. YOU CANNOT skip a method because it is too hard or would requiring building new infrastructure. We will call this in a loop so spend as much time as you need building the proper infrastructure to make it 1 to 1 with the JavaScript equivalent. Do not give up.<br>Update BATTLE_TODO.md and do a git commit after each unit of work.<br></p></blockquote>



<h3>Todos</h3>



<p>Claude Code while porting the methods one by one often decided to write a "simplified" version or add a "TODO" for later. I also found it to be useful when generating work to add the instructions in the codebase itself via a TODO comment, so I don't need to wish that it's going to be read from the context.</p>



<p>The master md file in practice didn't really work, it quickly became too big to be useful and Claude started creating a bunch more littering the repo with them. Instead I gave it a deterministic way to go through then by calling grep on the codebase, so it knew when to find them.</p>



<blockquote><p>We want to fix every TODO in the codebase. <code>TODO</code> or <code>simplif</code> in pokemon-showdown-rs/.<br>There are hundreds of them, so go diligently one by one. Do not skip them even if they are difficult. I will call this prompt again and again so you don't need to worry about taking too long on any single one.<br>The port must be exactly one to one. If the infrastructure doesn't exist, please implement it. Do not invent anything.<br>Make sure it still compiles after each addition and commit and push to git.</p></blockquote>



<p>At some point the context was poisoned where a TODO was inside of the original js codebase so it changed it to something else which made sense. But then it did the same for all the subsequent TODOs which didn't... Thankfully I could just revert all these commits.</p>



<h3>Fixing</h3>



<p>I put in all the instructions to debug in Claude.md and a script to run all the tests which outputs a txt file with progress report. This way Claude was able to just keep going fixing issues after issues.</p>



<blockquote><p>We want to fix all the divergences in battles. Please look at 500-seeds-results.txt and fix them one by one. The only way you can fix is by making sure that the differences between javascript and rust are explained by language differences and not logic. Every line between the two must match one by one. If you fixed something specific, it's probably a larger issue, spend the time to figure out if other similar things are broken and do the work to do the larger infrastructure fixes. Make sure it still compiles after each addition and commit and push to git. Check if there are other parts of the codebase that make this mistake.</p></blockquote>



<p>This is really useful to have this txt file diff committed to GitHub to get a sense of progress on the go!</p>



<div><figure><img src="https://pbs.twimg.com/media/G-cKrxvaoAAGAYA?format=jpg&amp;name=large" alt="Image" width="231" height="499"></figure></div>



<h2>Epilogue</h2>



<h3>It works 🤯</h3>



<p>I didn't quite know what to expect coming into this project. They usually tend to die due to the sheer amount of work needed to get anywhere close to something complete. But not this time!</p>



<p>We have a complete implementation of Pokemon battle system that produces the same results as the existing JavaScript codebase*. This was done through 5000 commits in 4 weeks and the Rust codebase is around 100k lines of code.</p>



<p>*I wish we had 0 divergences but right now there are 80 out of the first 2.4 million seeds or 0.003%. I need to run it for longer to solve these.</p>



<h3>Is it fast?</h3>



<p>The whole point of the project was for it to be faster than the initial JavaScript implementation. Only towards the end of the project where we had a sizable amount of battles running perfectly I felt like it would be a fair time to do a performance comparison.</p>



<p>I asked Claude Code to parallelize both implementations and was relieved by the results, the Rust port is actually significantly faster, I didn't spend all this time for nothing!</p>



<figure><img src="https://pbs.twimg.com/media/G-zV6MgWAAAQMt4?format=jpg&amp;name=large" alt="Image"></figure>



<p>I've tried asking Claude to optimize it further, it created <a href="https://github.com/vjeux/pokemon-showdown-rs/blob/master/PERFORMANCE.md">a plan that looks reasonable</a> (I've never interacted with Rust in my life) and it spent a day building many of these optimizations but at the end of the day, none of them actually improved the runtime and some even made it way worse.</p>



<p>This is a good example of how experience and expertise is still very required in order to get the best out of LLMs.</p>



<h2>Conclusion</h2>



<p>This is pretty wild that I was able to port a ~100k lines codebase from JavaScript to Rust in two weeks on my own with Claude Code running 24 hours a day for a month <a href="https://github.com/vjeux/pokemon-showdown-rs/commits/master/">creating 5k commits</a>! I have never written any line of Rust before in my life.</p>



<p>LLM-based coding agents are such a great new tool for engineers, there's no way I would have been able to do that without Claude Code. That said, it still feels like a tool that requires my engineering expertise and constant babysitting to produce these results.</p>



<p>Sadly I didn't get to build the Pokemon Battle AI and the winter break is over, so if anybody wants to do it, please <a href="https://github.com/vjeux/pokemon-showdown-rs/commits/master/">have fun with the codebase</a>!</p>
			  
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After two years of vibecoding, I'm back to writing by hand (566 pts)]]></title>
            <link>https://atmoio.substack.com/p/after-two-years-of-vibecoding-im</link>
            <guid>46765460</guid>
            <pubDate>Mon, 26 Jan 2026 13:36:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://atmoio.substack.com/p/after-two-years-of-vibecoding-im">https://atmoio.substack.com/p/after-two-years-of-vibecoding-im</a>, See on <a href="https://news.ycombinator.com/item?id=46765460">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Most people’s journey with AI coding starts the same: you give it a simple task. You’re impressed. So you give it a large task. You’re even more impressed.</p><p>You open X and draft up a rant on job displacement.</p><p>If you’ve persisted past this point: congratulations, you understand AI coding better than 99% of people.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Mwtn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Mwtn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Mwtn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:302809,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://atmoio.substack.com/i/185837386?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!Mwtn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!Mwtn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbc2a288-45bf-4d42-b61d-07f5678d260f_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Serious engineers using AI to do real work and not just weekend projects largely also follow a predictable development arc.</p><p>Still amazed at the big task you gave it, you wonder if you can keep giving it bigger and bigger tasks. Maybe even that haunting refactor no one wants to take on?</p><p>But here’s where the curtain starts to crinkle.</p><p>On the one hand, you’re amazed at how well it seems to understand you. On the other hand, it makes frustrating errors and decisions that clearly go against the shared understanding you’ve developed.</p><p>You quickly learn that being angry at the model serves no purpose, so you begin to internalize any unsatisfactory output.</p><p>“It’s me. My prompt sucked. It was under-specified.”  </p><p>“If I can specify it, it can build it. The sky’s the limit,” you think.</p><p>So you open Obsidian and begin drafting beefy spec docs that describe the feature in your head with impressive detail. Maybe you’ve put together a full page of a prompt, and spent half an hour doing so.</p><p><span>But you find that spec-driven development doesn’t work either. In real life, design docs and specs are </span><strong>living </strong><span>documents that evolve in a volatile manner through discovery and implementation. Imagine if in a real company you wrote a design doc in 1 hour for a complex architecture, handed it off to a mid-level engineer (and told him not to discuss the doc with anyone), and took off on vacation.</span></p><p>Not only does an agent not have the ability to evolve a specification over a multi-week period as it builds out its lower components, it also makes decisions upfront that it later doesn’t deviate from. And most agents simply surrender once they feel the problem and solution has gotten away from them (though this rarely happens anymore, since agents will just force themselves through the walls of the maze.)</p><p>What’s worse is code that agents write looks plausible and impressive while it’s being written and presented to you. It even looks good in pull requests (as both you and the agent are well trained in what a “good” pull request looks like).</p><p>It’s not until I opened up the full codebase and read its latest state cover to cover that I began to see what we theorized and hoped was only a diminishing artifact of earlier models: slop.</p><p>It was pure, unadulterated slop. I was bewildered. Had I not reviewed every line of code before admitting it? Where did all this...gunk..come from?</p><p>In retrospect, it made sense. Agents write units of changes that look good in isolation. They are consistent with themselves and your prompt. But respect for the whole, there is not. Respect for structural integrity there is not. Respect even for neighboring patterns there was not.</p><p>The AI had simply told me a good story. Like vibewriting a novel, the agent showed me a good couple paragraphs that sure enough made sense and were structurally and syntactically correct. Hell, it even picked up on the idiosyncrasies of the various characters. But for whatever reason, when you read the whole chapter, it’s a mess. It makes no sense in the overall context of the book and the preceding and proceeding chapters.</p><p>After reading months of cumulative highly-specified agentic code, I said to myself: I’m not shipping this shit. I’m not gonna charge users for this. And I’m not going to promise users to protect their data with this.</p><p>I’m not going to lie to my users with this.</p><p><span>So I’m back to writing by hand for most things. Amazingly, I’m faster, more accurate, more creative, more productive, and more efficient than AI, when you price </span><em>everything </em><span>in, and not just code tokens per hour.</span></p><p><span>You can follow me on X </span><a href="https://x.com/atmoio" rel="nofollow ugc noopener">@atmoio</a><span>, where I post a few times a week about agentic coding.</span></p><p>You can watch the video counterpart to this essay on YouTube: </p><div id="youtube2-SKTsNV41DYg" data-attrs="{&quot;videoId&quot;:&quot;SKTsNV41DYg&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/SKTsNV41DYg?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vibe Coding Kills Open Source (282 pts)]]></title>
            <link>https://arxiv.org/abs/2601.15494</link>
            <guid>46765120</guid>
            <pubDate>Mon, 26 Jan 2026 13:01:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2601.15494">https://arxiv.org/abs/2601.15494</a>, See on <a href="https://news.ycombinator.com/item?id=46765120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2601.15494">View PDF</a>
    <a href="https://arxiv.org/html/2601.15494v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Generative AI is changing how software is produced and used. In vibe coding, an AI agent builds software by selecting and assembling open-source software (OSS), often without users directly reading documentation, reporting bugs, or otherwise engaging with maintainers. We study the equilibrium effects of vibe coding on the OSS ecosystem. We develop a model with endogenous entry and heterogeneous project quality in which OSS is a scalable input into producing more software. Users choose whether to use OSS directly or through vibe coding. Vibe coding raises productivity by lowering the cost of using and building on existing code, but it also weakens the user engagement through which many maintainers earn returns. When OSS is monetized only through direct user engagement, greater adoption of vibe coding lowers entry and sharing, reduces the availability and quality of OSS, and reduces welfare despite higher productivity. Sustaining OSS at its current scale under widespread vibe coding requires major changes in how maintainers are paid.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Miklos Koren [<a href="https://arxiv.org/show-email/6310d1fe/2601.15494" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 21 Jan 2026 21:54:59 UTC (642 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC Risk (122 pts)]]></title>
            <link>https://stratechery.com/2026/tsmc-risk/</link>
            <guid>46764223</guid>
            <pubDate>Mon, 26 Jan 2026 11:07:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stratechery.com/2026/tsmc-risk/">https://stratechery.com/2026/tsmc-risk/</a>, See on <a href="https://news.ycombinator.com/item?id=46764223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<p>You probably think, given this title, you know what this Article is about. The most advanced semiconductors are made by TSMC in Taiwan,<sup id="rf1-18153"><a href="#fn1-18153" title="Yes, there are chips made in Arizona, but only a portion, and they need to be sent back to Taiwan for packaging and testing." rel="footnote">1</a></sup> and Taiwan is claimed by China, which has not and will not take reunification-by-force off of the table.</p>



<p>Relatedly, AI obviously has significant national security implications; at Davos, Anthropic CEO Dario Amodei reiterated his objection to the U.S. allowing the sale of Nvidia chips to China. <a href="https://www.bloomberg.com/news/articles/2026-01-20/anthropic-ceo-says-selling-advanced-ai-chips-to-china-is-crazy">From Bloomberg</a>:</p>



<blockquote>
<p>Anthropic Chief Executive Officer Dario Amodei said selling advanced artificial intelligence chips to China is a blunder with “incredible national security implications” as the US moves to allow Nvidia Corp. to sell its H200 processors to Beijing. “It would be a big mistake to ship these chips,” Amodei said in an interview with Bloomberg Editor-in-Chief John Micklethwait at the World Economic Forum in Davos, Switzerland. “I think this is crazy. It’s a bit like selling nuclear weapons to North Korea.”</p>
</blockquote>



<p>The nuclear weapon analogy is an interesting one: a lot of game theory was developed to manage the risk of nuclear weapons, particularly once the U.S.S.R. gained/stole nuclear capability, ending the U.S.’s brief monopoly on the technology. Before that happened, however, the U.S. had a dominant military position, given we had nuclear weapons and no one else did. Perhaps Amodei believes the U.S. should have advanced AI and China should not, giving us a dominant military position?</p>



<p>The problem with that reality, however, is Taiwan, as I explained in <a href="https://stratechery.com/2025/ai-promise-and-chip-precariousness/">AI Promise and Chip Precariousness</a>. AI, in contrast to nuclear weapons, has a physical dependency in Taiwan that can be easily destroyed by Chinese missiles, even without an invasion; if we got to a situation where only the U.S. had the sort of AI that would give us an unassailable advantage militarily, then the optimal strategy for China would change to taking TSMC off of the board.</p>



<p>Given this dependency, my recommendations in the Article run counter to Amodei: I want China dependent on not just U.S. chips but also on TSMC directly, which is why I argued in favor of selling Nvidia chips to China, and further believe that Huawei and other Chinese companies ought to be able to source from TSMC (on the flip side, I would ban the sale of semiconductor manufacturing equipment to Chinese fabs). <a href="https://stratechery.com/2025/trump-allows-h200-sales-to-china-the-sliding-scale-a-good-decision/">I think it’s a good thing</a> the Trump administration moved on the first point, at least.</p>



<p>However, this risk is not what this Article is about: there is another TSMC risk facing the entire AI industry in particular; moreover, it’s a risk the downside of which is already being realized.</p>



<h3>The TSMC Brake</h3>



<p>There was one refrain that was common across Big Tech earnings last quarter: demand for AI exceeds supply. Here was Amazon CEO Andy Jassy on <a href="https://seekingalpha.com/article/4835958-amazon-com-inc-amzn-q3-2025-earnings-call-transcript">the company’s earnings call</a>:</p>



<blockquote>
<p>You’re going to see us continue to be very aggressive investing in capacity because we see the demand. As fast as we’re adding capacity right now, we’re monetizing it.</p>
</blockquote>



<p>Here was Microsoft CFO Amy Hood on <a href="https://seekingalpha.com/article/4835092-microsoft-corporation-msft-q1-2026-earnings-call-transcript">the company’s earnings call</a>:</p>



<blockquote>
<p>Azure AI services revenue was generally in line with expectations, and this quarter, demand again exceeded supply across workloads, even as we brought more capacity online.</p>
</blockquote>



<p>Here was Google CFO Anat Ashkenazi on <a href="https://seekingalpha.com/article/4835072-alphabet-inc-googl-q3-2025-earnings-call-transcript">the company’s earnings call</a>:</p>



<blockquote>
<p>In GCP, we see strong demand for enterprise AI infrastructure, including TPUs and GPUs, enterprise AI solutions driven by demand for Gemini 2.5 and our other AI models, and core GCP infrastructure and other services such as cybersecurity and data analytics. As I’ve mentioned on previous earnings calls, while we have been working hard to increase capacity and have improved the pace of server deployments and data center construction, we still expect to remain in a tight demand-supply environment in Q4 and 2026.</p>
</blockquote>



<p>Here was Meta CEO Mark Zuckerberg on <a href="https://seekingalpha.com/article/4835033-meta-platforms-inc-meta-q3-2025-earnings-call-transcript">the company’s earnings call</a>:</p>



<blockquote>
<p>To date, we keep on seeing this pattern where we build some amount of infrastructure to what we think is an aggressive assumption. And then we keep on having more demand to be able to use more compute, especially in the core business in ways that we think would be quite profitable than we end up having compute for.</p>
</blockquote>



<p>Earlier this month, TSMC CEO C.C. Wei admitted that the shortage was a lack of chips, not power; from <a href="https://investor.tsmc.com/english/encrypt/files/encrypt_file/reports/2026-01/51d09df96cd89ac19d65af39032b038dc2896a24/TSMC%204Q25%20Transcript.pdf">the company’s earnings call</a>:</p>



<blockquote>
<p>Talking about to build a lot of AI data center all over the world, I use one of my customers’ customers’ answer. I asked the same question. They told me that they planned this one, 5-6 years ago already. So, as I said, those cloud service providers are smart, very smart. So, they say that they work on the power supply 5-6 years ago. So, today, their message to me is: silicon from TSMC is a bottleneck, and asked me not to pay attention to all others, because they have to solve the silicon bottleneck first. But indeed, we do get the power supply, all over the world, especially in the US. Not only that, but we also look at, who support those kind of a power supply, like a turbine, like, what, nuclear power plant, the plan or those kinds of things. We also look at the supply of the rack. We also look at the supply of the cooling system. Everything, so far, so good. So we have to work hard to narrow the gap between the demand and supply from TSMC.</p>
</blockquote>



<p>The cause of that gap is obvious if you look at TSMC’s financials, specifically the company’s annual capital expenditures:</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1330" height="620" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-1.png?resize=1330%2C620&amp;ssl=1" alt="" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-1.png?w=1330&amp;ssl=1 1330w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-1.png?resize=300%2C140&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-1.png?resize=768%2C358&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>After a big increase in CapEx in 2021, driven by the COVID shortages and <a href="https://seekingalpha.com/article/4398927-taiwan-semiconductor-manufacturing-company-limited-tsm-ceo-c-c-wei-on-q4-2020-results">a belief in 5G</a>, TSMC’s annual CapEx in the following years was basically flat — it actually declined on a year-over-year basis in both 2023 and 2024. Note those dates! ChatGPT was released in November 2022; that kicked off a massive increase in CapEx amongst the hyperscalers in particular, but it sure seems like TSMC didn’t buy the hype.</p>



<p>That lack of increased investment earlier this decade is why there is a shortage today, and is why TSMC has been a de facto brake on the AI buildout/bubble; <a href="https://stratechery.com/2026/tsmc-earnings-the-tsmc-brake-revisited-why-ai-needs-foundry-competition/">I wrote last quarter</a>:</p>



<blockquote>
<p>To put it another way, if Altman and OpenAI are the ones pushing to accelerate the AI infrastructure buildout, it’s Wei and TSMC that are the brakes. The extent to which all of Altman’s deals actually materialize is dependent on how much TSMC invests in capacity now, and while they haven’t shown their hand yet, the company is saying all of the right things about AI being a huge trend without having yet committed to a commensurate level of investment, at least relative to OpenAI’s goals.</p>
</blockquote>



<p>That Update was about the future, but it’s important to note that the TSMC brake has —&nbsp;if all of those CEO and CFO comments above are to be believed — already cost the biggest tech companies a lot of money. That’s the implication of not having enough supply to satisfy demand: there was revenue to be made that wasn’t, because TSMC didn’t buy the AI hype at the same time everyone else did.</p>



<h3>TSMC’s CapEx Plans</h3>



<p>TSMC is, finally, starting to invest more. Last year’s CapEx increased 37% to $41 billion, and there’s another increase in store for this year to $52–$56 billion; if we take the midpoint, that represents an increase of 32%, a bit less than last year:</p>



<figure><img data-recalc-dims="1" decoding="async" width="1330" height="618" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-3.png?resize=1330%2C618&amp;ssl=1" alt="" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-3.png?w=1330&amp;ssl=1 1330w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-3.png?resize=300%2C139&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-3.png?resize=768%2C357&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>Make no mistake, $54 billion is a big number, one that Wei admitted made him nervous:</p>



<blockquote>
<p>You essentially try to ask whether the AI demand is real or not. I’m also very nervous about it. Yeah, you bet, because we have to invest about USD52 billion to USD56 billion for the CapEx, right? If we did not do it carefully, that will be a big disaster to TSMC for sure. So, of course, I spent a lot of time in the last three-four months talking to my customers and then customers’ customers. I want to make sure that my customers’ demands are real.</p>
</blockquote>



<p>Wei made clear that he was worried about the market several years down the line:</p>



<blockquote>
<p>If you build a new fab, it takes two and three year, two to three years to build a new fab. So even we start to spend $52 billion to $56 billion, the contribution to this year is almost none, and 2027, a little bit. So we actually, we are looking for 2028-2029 supply, and we hope it’s a time that the gap will be narrow…So 2026-2027 for the short-term, we are looking to improve our productivity. 2028 to 2029, yes, we start to increase our capacity significantly. And it will continue this way if the AI demand megatrend as we expected.</p>
</blockquote>



<p>First off, this delayed impact explains why TSMC’s lack of CapEx increase a few years ago is resulting in supply-demand imbalance today. Secondly, notice how this year’s planned increase — which again, won’t really have an impact until 2028 — pales in comparison to the CapEx growth of the hyperscalers (<em>2025 numbers are estimates; note that Amazon’s CapEx includes Amazon.com</em>):</p>



<figure><img data-recalc-dims="1" decoding="async" width="1330" height="812" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-2.png?resize=1330%2C812&amp;ssl=1" alt="" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-2.png?w=1330&amp;ssl=1 1330w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-2.png?resize=300%2C183&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2026/01/tsmc-risk-2.png?resize=768%2C469&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>Remember, a significant portion of this CapEx growth is for chips that are supported by TSMC’s stagnant CapEx growth from a few years ago. It’s notable, then, that TSMC’s current and projected CapEx growth is still less than the hyperscalers: how much less is it going to be than the hyperscalers’ growth in 2028, when the fabs being built today start actually producing chips?</p>



<p>In short, the TSMC brake isn’t going anywhere — if anything, it’s being pressed harder than ever.</p>



<h3>TSMC Risk</h3>



<p>TSMC is, to be clear, being extremely rational. CapEx is inherently risky: you are spending money now in anticipation of demand that may or may not materialize. Moreover, the risk for a foundry is higher than basically any other business model: nearly all of a foundry’s costs are CapEx, which means that if demand fails to materialize, costs — in the form of depreciation — don’t go down as they might with a business model with a higher percentage of marginal costs. This is exacerbated by the huge dollar figures entailed in building fabs: $52–$56 billion may drive revenues with big margins, but those big margins can easily flip to being huge losses and years of diminished pricing power thanks to excess capacity. Therefore, it’s understandable that TSMC is trying to manage its risks. Sure, the company may be foregoing some upside in 2028, but what is top of Wei’s mind is avoiding “a big disaster.”</p>



<p>What is important to note, however, is that the risk TSMC is managing doesn’t simply go away: rather, it’s being offloaded to the hyperscalers in particular. Specifically, if we get to 2028, and TSMC still isn’t producing enough chips to satisfy demand, then that means the hyperscalers will be forgoing billions of dollars in revenue —&nbsp;even more than they are already forgoing today. Yes, that risk is harder to see than the risk TSMC is avoiding, because the hyperscalers aren’t going to be bankrupt for a lack of chips to satisfy demand. Still, the potential money not made — particularly when the number is potentially in the hundreds of billions of dollars — is very much a risk that the hyperscalers are incurring because of TSMC’s conservatism.</p>



<p>What the hyperscalers need to understand is that simply begging TSMC to make more isn’t going to fix this problem, because begging TSMC to make more is to basically ask TSMC to take back the risk TSMC is offloading to the hyperscalers — they already declined! Rather, the only thing that will truly motivate TSMC to take on more risk is competition. If TSMC were worried about not just forgoing its own extra revenue, but actually losing business to a competitor, then the company would invest more. Moreover, that extra investment would be stacked on top of the investment made by said competitor, which means the world would suddenly have dramatically more fab capacity.</p>



<h3>If You Want a Bubble</h3>



<p>In short, the only way to truly get an AI bubble, with all of <a href="https://stratechery.com/2025/the-benefits-of-bubbles/">the potential benefits that entails</a>, or, in the optimistic case, to actually meet demand in 2028 and beyond, is to have competition in the foundry space. That, by extension, means Samsung or Intel — or both —&nbsp;actually being viable options.</p>



<p>Remember, however, the number one challenge facing those foundries: a lack of demand from the exact companies whom TSMC has deputized to take on their risk. I wrote in <a href="https://stratechery.com/2025/u-s-intel/">U.S. Intel</a>:</p>



<blockquote>
<p>Our mythical startup, however, doesn’t exist in a vacuum: it exists in the same world as TSMC, the company who has defined the modern pure play foundry. TSMC has put in the years, and they’ve put in the money; TSMC has the unparalleled customer service approach that created the entire fabless chip industry; and, critically, TSMC, just as they did in the mobile era, is aggressively investing to meet the AI moment. If you’re an Nvidia, or an Apple in smartphones, or an AMD or a Qualcomm, why would you take the chance of fabricating your chips anywhere else? Sure, TSMC is raising prices in the face of massive demand, but the overall cost of a chip in a system is still quite small; is it worth risking your entire business to save a few dollars for worse performance with a worse customer experience that costs you time to market and potentially catastrophic product failures?</p>



<p>We know our mythical startup would face these challenges because they are the exact challenges Intel faces. Intel may need “a meaningful external customer to drive acceptable returns on [its] deployed capital”, but Intel’s needs do not drive the decision-making of those external customers, despite the fact that Intel, while not fully caught up to TSMC, is at least in the ballpark, something no startup could hope to achieve for decades.</p>
</blockquote>



<p>Becoming a meaningful customer of Samsung or Intel is very risky: it takes years to get a chip working on a new process, which hardly seems worth it if that process might not be as good, and if the company offering the process definitely isn’t as customer service-centric as TSMC. I understand why everyone sticks with TSMC.</p>



<p>The reality that hyperscalers and fabless chip companies need to wake up to, however, is that avoiding the risk of working with someone other than TSMC incurs new risks that are both harder to see and also much more substantial. Except again, we can see the harms already: foregone revenue today as demand outstrips supply. Today’s shortages, however, may prove to be peanuts: if AI has the potential these companies claim it does, future foregone revenue at the end of the decade is going to cost exponentially more — surely a lot more than whatever expense is necessary to make Samsung and/or Intel into viable competitors for TSMC.</p>



<p>This, incidentally, is how the geographic risk issue will be fixed, if it ever is. It’s hard to get companies to pay for insurance for geopolitical risks that may never materialize. What is much more likely is that TSMC’s customers realize that their biggest risk isn’t that TSMC gets blown up by China, but that TSMC’s monopoly and reasonable reluctance to risk a rate of investment that matches the rest of the industry means that the rest of the industry fails to fully capture the value of AI.</p>
<hr><ol><li id="fn1-18153"><p>Yes, there are chips made in Arizona, but only a portion, and they need to be sent back to Taiwan for packaging and testing.&nbsp;<a href="#rf1-18153" title="Return to footnote 1.">↩</a></p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Only 1 LLM can fly a drone (118 pts)]]></title>
            <link>https://github.com/kxzk/snapbench</link>
            <guid>46764170</guid>
            <pubDate>Mon, 26 Jan 2026 11:00:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kxzk/snapbench">https://github.com/kxzk/snapbench</a>, See on <a href="https://news.ycombinator.com/item?id=46764170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h3 tabindex="-1" dir="auto">SnapBench</h3><a id="user-content-snapbench" aria-label="Permalink: SnapBench" href="#snapbench"></a></p>
<blockquote>
<p dir="auto">Inspired by <a href="https://en.wikipedia.org/wiki/Pok%C3%A9mon_Snap" rel="nofollow">Pokémon Snap</a> (1999). VLM pilots a drone through 3D world to locate and identify creatures.</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/787f7f9eb554849dceeda184fd3b5cb2bff7cac1a74724f011fafb576cb8dfe8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a69672d626c61636b3f7374796c653d666c61742d737175617265266c6f676f3d7a6967"><img src="https://camo.githubusercontent.com/787f7f9eb554849dceeda184fd3b5cb2bff7cac1a74724f011fafb576cb8dfe8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a69672d626c61636b3f7374796c653d666c61742d737175617265266c6f676f3d7a6967" alt="zig" data-canonical-src="https://img.shields.io/badge/zig-black?style=flat-square&amp;logo=zig"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1e54d2cf12f9fd89cfaadf3c3899b112e144af0ac004cbe8a1c9f1e7c7297455/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f727573742d2532334345343232423f7374796c653d666c61742d737175617265266c6f676f3d72757374"><img src="https://camo.githubusercontent.com/1e54d2cf12f9fd89cfaadf3c3899b112e144af0ac004cbe8a1c9f1e7c7297455/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f727573742d2532334345343232423f7374796c653d666c61742d737175617265266c6f676f3d72757374" alt="rust" data-canonical-src="https://img.shields.io/badge/rust-%23CE422B?style=flat-square&amp;logo=rust"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/02028ceb21cf9e0c689276755ee80daebbe8cf6cff6f27f51e98b7c11af6686e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d2532333337373641423f7374796c653d666c61742d737175617265266c6f676f3d707974686f6e266c6f676f436f6c6f723d464644343342"><img src="https://camo.githubusercontent.com/02028ceb21cf9e0c689276755ee80daebbe8cf6cff6f27f51e98b7c11af6686e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d2532333337373641423f7374796c653d666c61742d737175617265266c6f676f3d707974686f6e266c6f676f436f6c6f723d464644343342" alt="python" data-canonical-src="https://img.shields.io/badge/python-%233776AB?style=flat-square&amp;logo=python&amp;logoColor=FFD43B"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Architecture</h3><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<section data-identity="016aae09-fee9-4fe0-9805-333bf524b569" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;%%{init: {'theme': 'base', 'themeVariables': { 'background': '#ffffff', 'primaryColor': '#ffffff'}}}%%\nflowchart LR\n    subgraph Controller[\&quot;**Controller** (Rust)\&quot;]\n        C[Orchestration]\n    end\n\n    subgraph VLM[\&quot;**VLM** (OpenRouter)\&quot;]\n        V[Vision-Language Model]\n    end\n\n    subgraph Simulation[\&quot;**Simulation** (Zig/raylib)\&quot;]\n        S[Game State]\n    end\n\n    C --&amp;gt;|\&quot;screenshot + prompt\&quot;| V\n    C &amp;lt;--&amp;gt;|\&quot;cmds + state&amp;lt;br&amp;gt;**UDP:9999**\&quot;| S\n\n    style Controller fill:#8B5A2B,stroke:#5C3A1A,color:#fff\n    style VLM fill:#87CEEB,stroke:#5BA3C6,color:#1a1a1a\n    style Simulation fill:#4A7C23,stroke:#2D5A10,color:#fff\n    style C fill:#B8864A,stroke:#8B5A2B,color:#fff\n    style V fill:#B5E0F7,stroke:#87CEEB,color:#1a1a1a\n    style S fill:#6BA33A,stroke:#4A7C23,color:#fff\n&quot;}" data-plain="%%{init: {'theme': 'base', 'themeVariables': { 'background': '#ffffff', 'primaryColor': '#ffffff'}}}%%
flowchart LR
    subgraph Controller[&quot;**Controller** (Rust)&quot;]
        C[Orchestration]
    end

    subgraph VLM[&quot;**VLM** (OpenRouter)&quot;]
        V[Vision-Language Model]
    end

    subgraph Simulation[&quot;**Simulation** (Zig/raylib)&quot;]
        S[Game State]
    end

    C -->|&quot;screenshot + prompt&quot;| V
    C <-->|&quot;cmds + state<br>**UDP:9999**&quot;| S

    style Controller fill:#8B5A2B,stroke:#5C3A1A,color:#fff
    style VLM fill:#87CEEB,stroke:#5BA3C6,color:#1a1a1a
    style Simulation fill:#4A7C23,stroke:#2D5A10,color:#fff
    style C fill:#B8864A,stroke:#8B5A2B,color:#fff
    style V fill:#B5E0F7,stroke:#87CEEB,color:#1a1a1a
    style S fill:#6BA33A,stroke:#4A7C23,color:#fff
">
      <pre lang="mermaid" aria-label="Raw mermaid code">%%{init: {'theme': 'base', 'themeVariables': { 'background': '#ffffff', 'primaryColor': '#ffffff'}}}%%
flowchart LR
    subgraph Controller["**Controller** (Rust)"]
        C[Orchestration]
    end

    subgraph VLM["**VLM** (OpenRouter)"]
        V[Vision-Language Model]
    end

    subgraph Simulation["**Simulation** (Zig/raylib)"]
        S[Game State]
    end

    C --&gt;|"screenshot + prompt"| V
    C &lt;--&gt;|"cmds + state&lt;br&gt;**UDP:9999**"| S

    style Controller fill:#8B5A2B,stroke:#5C3A1A,color:#fff
    style VLM fill:#87CEEB,stroke:#5BA3C6,color:#1a1a1a
    style Simulation fill:#4A7C23,stroke:#2D5A10,color:#fff
    style C fill:#B8864A,stroke:#8B5A2B,color:#fff
    style V fill:#B5E0F7,stroke:#87CEEB,color:#1a1a1a
    style S fill:#6BA33A,stroke:#4A7C23,color:#fff
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h3 tabindex="-1" dir="auto">Overview</h3><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">The simulation generates procedural terrain and spawns creatures (cat, dog, pig, sheep) for the drone to discover. It handles drone physics and collision detection, accepting 8 movement commands plus <code>identify</code> and <code>screenshot</code>. The Rust controller captures frames from the simulation, constructs prompts enriched with position and state data, then parses VLM responses into executable command sequences. The objective: locate and successfully identify 3 creatures, where <code>identify</code> succeeds when the drone is within 5 units of a target.</p>
<br>
<details open="">
  <summary>
    
    <span>demo_3x.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/25046261/540463086-37903246-a5ae-4e83-87c6-c099198c8724.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njk0NTYxMjIsIm5iZiI6MTc2OTQ1NTgyMiwicGF0aCI6Ii8yNTA0NjI2MS81NDA0NjMwODYtMzc5MDMyNDYtYTVhZS00ZTgzLTg3YzYtYzA5OTE5OGM4NzI0Lm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTI2VDE5MzAyMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRhZDNiNGQxMjdhYmE1NzMxNmY2OTE0OTZkNmI3MWQ0NjMwMWMxM2RjNjc1ZTQ1Njc3OTY3MmJjMTEzZTYyNDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Z42_uZzZVlGr0aw8wfyljYMySRVweN7rN_SZJHFpG5E" data-canonical-src="https://private-user-images.githubusercontent.com/25046261/540463086-37903246-a5ae-4e83-87c6-c099198c8724.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njk0NTYxMjIsIm5iZiI6MTc2OTQ1NTgyMiwicGF0aCI6Ii8yNTA0NjI2MS81NDA0NjMwODYtMzc5MDMyNDYtYTVhZS00ZTgzLTg3YzYtYzA5OTE5OGM4NzI0Lm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTI2VDE5MzAyMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRhZDNiNGQxMjdhYmE1NzMxNmY2OTE0OTZkNmI3MWQ0NjMwMWMxM2RjNjc1ZTQ1Njc3OTY3MmJjMTEzZTYyNDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Z42_uZzZVlGr0aw8wfyljYMySRVweN7rN_SZJHFpG5E" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto"><h2 tabindex="-1" dir="auto">Gotta catch 'em all?</h2><a id="user-content-gotta-catch-em-all" aria-label="Permalink: Gotta catch 'em all?" href="#gotta-catch-em-all"></a></p>
<p dir="auto">I gave 7 frontier LLMs a simple task: pilot a drone through a 3D voxel world and find 3 creatures.</p>
<p dir="auto">Only one could do it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kxzk/snapbench/blob/main/images/benchmark_results.png"><img src="https://github.com/kxzk/snapbench/raw/main/images/benchmark_results.png" alt="Benchmark Results"></a></p>
<p dir="auto">Is this a rigorous benchmark? No. However, it's a reasonably fair comparison - same prompt, same seeds, same iteration limits. I'm sure with enough refinement you could coax better results out of each model. But that's kind of the point: out of the box, with zero hand-holding, only one model figured out how to actually <em>fly</em>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why can't Claude look down?</h2><a id="user-content-why-cant-claude-look-down" aria-label="Permalink: Why can't Claude look down?" href="#why-cant-claude-look-down"></a></p>
<p dir="auto">The core differentiator wasn't intelligence - it was <strong>altitude control</strong>. Creatures sit on the ground. To identify them, you need to descend.</p>
<ul dir="auto">
<li><strong>Gemini Flash</strong>: Actively adjusts altitude, descends to creature level, identifies</li>
<li><strong>GPT-5.2-chat</strong>: Gets close horizontally but never lowers</li>
<li><strong>Claude Opus</strong>: Attempts identification 160+ times, never succeeds - approaching at wrong angles</li>
<li><strong>Others</strong>: Wander randomly or get stuck</li>
</ul>
<p dir="auto">This left me puzzled. Claude Opus is arguably the most capable model in the lineup. It <em>knows</em> it needs to identify creatures. It tries - aggressively. But it never adjusts its approach angle.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The two-creature anomaly</h2><a id="user-content-the-two-creature-anomaly" aria-label="Permalink: The two-creature anomaly" href="#the-two-creature-anomaly"></a></p>
<p dir="auto">Run 13 (seed 72) was the only run where any model found 2 creatures. Why? They happened to spawn near each other. Gemini Flash found one, turned around, and spotted the second.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kxzk/snapbench/blob/main/images/seed-72.png"><img src="https://github.com/kxzk/snapbench/raw/main/images/seed-72.png" alt="Seed 72"></a></p>
<p dir="auto">In most other runs, Flash found one creature quickly but ran out of iterations searching for the others. The world is big. 50 iterations isn't a lot of time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bigger ≠ better</h2><a id="user-content-bigger--better" aria-label="Permalink: Bigger ≠ better" href="#bigger--better"></a></p>
<p dir="auto">This was the most surprising finding. I expected:</p>
<ul dir="auto">
<li>Claude Opus 4.5 (most expensive) to dominate</li>
<li>Gemini 3 Pro to outperform Gemini 3 Flash (same family, more capability)</li>
</ul>
<p dir="auto">Instead, the cheapest model beat models costing 10x more.</p>
<p dir="auto">What's going on here? A few theories:</p>
<ol dir="auto">
<li><strong>Spatial reasoning doesn't scale with model size</strong> - at least not yet</li>
<li><strong>Flash was trained differently</strong> - maybe more robotics data, more embodied scenarios?</li>
<li><strong>Smaller models follow instructions more literally</strong> - "go down" means go down, not "consider the optimal trajectory"</li>
</ol>
<p dir="auto">I genuinely don't know. But if you're building an LLM-powered agent that needs to navigate physical or virtual space, the most expensive model might not be your best choice.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Color theory, maybe</h2><a id="user-content-color-theory-maybe" aria-label="Permalink: Color theory, maybe" href="#color-theory-maybe"></a></p>
<p dir="auto">Anecdotally, creatures with higher contrast (gray sheep, pink pigs) seemed easier to spot than brown-ish creatures that blended into the terrain. A future version might normalize creature visibility. Or maybe that's the point - real-world object detection isn't normalized either.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prior work</h2><a id="user-content-prior-work" aria-label="Permalink: Prior work" href="#prior-work"></a></p>
<p dir="auto">Before this, I tried having LLMs pilot a <a href="https://github.com/kxzk/tello-bench">real DJI Tello drone</a>.</p>
<p dir="auto">Results: it flew straight up, hit the ceiling, and did donuts until I caught it. (I was using Haiku 4.5, which in hindsight explains a lot.)</p>
<p dir="auto">The Tello is now broken. I've ordered a BetaFPV and might get another Tello since they're so easy to program. Now that I know Gemini Flash can actually navigate, a real-world follow-up might be worth revisiting.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rough edges</h2><a id="user-content-rough-edges" aria-label="Permalink: Rough edges" href="#rough-edges"></a></p>
<p dir="auto">This is half-serious research, half "let's see what happens."</p>
<ul dir="auto">
<li>The simulation has rough edges (it's a side project, not a polished benchmark suite)</li>
<li>One blanket prompt is used for all models - model-specific tuning would likely improve results</li>
<li>The feedback loop is basic (position, screenshot, recent commands) - there's room to get creative with what information gets passed back</li>
<li>Iteration limits (50) may artificially cap models that are slower but would eventually succeed</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it yourself</h2><a id="user-content-try-it-yourself" aria-label="Permalink: Try it yourself" href="#try-it-yourself"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Tool</th>
<th>Version</th>
<th>Install</th>
</tr>
</thead>
<tbody>
<tr>
<td>Zig</td>
<td>≥0.15.2</td>
<td><a href="https://ziglang.org/download/" rel="nofollow">ziglang.org/download</a></td>
</tr>
<tr>
<td>Rust</td>
<td>stable (2024 edition)</td>
<td><a href="https://rust-lang.org/tools/install/" rel="nofollow">rust-lang.org/tools/install</a></td>
</tr>
<tr>
<td>Python</td>
<td>≥3.11</td>
<td><a href="https://www.python.org/" rel="nofollow">python.org</a></td>
</tr>
<tr>
<td>uv</td>
<td>latest</td>
<td><a href="https://docs.astral.sh/uv/getting-started/installation/" rel="nofollow">docs.astral.sh/uv</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">You'll also need an <a href="https://openrouter.ai/" rel="nofollow">OpenRouter</a> API key.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="gh repo clone kxzk/snapbench
cd snapbench

# set your API key
export OPENROUTER_API_KEY=&quot;sk-or-...&quot;"><pre>gh repo clone kxzk/snapbench
<span>cd</span> snapbench

<span><span>#</span> set your API key</span>
<span>export</span> OPENROUTER_API_KEY=<span><span>"</span>sk-or-...<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running the simulation manually</h3><a id="user-content-running-the-simulation-manually" aria-label="Permalink: Running the simulation manually" href="#running-the-simulation-manually"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# terminal 1: start the simulation (with optional seed)
zig build run -Doptimize=ReleaseFast -- 42
# or
make sim

# terminal 2: start the drone controller
cargo run --release --manifest-path llm_drone/Cargo.toml -- --model google/gemini-3-flash-preview
# or
make drone"><pre><span><span>#</span> terminal 1: start the simulation (with optional seed)</span>
zig build run -Doptimize=ReleaseFast -- 42
<span><span>#</span> or</span>
make sim

<span><span>#</span> terminal 2: start the drone controller</span>
cargo run --release --manifest-path llm_drone/Cargo.toml -- --model google/gemini-3-flash-preview
<span><span>#</span> or</span>
make drone</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running the benchmark suite</h3><a id="user-content-running-the-benchmark-suite" aria-label="Permalink: Running the benchmark suite" href="#running-the-benchmark-suite"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# runs all models defined in bench/models.toml
uv run bench/bench_runner.py
# or
make bench"><pre><span><span>#</span> runs all models defined in bench/models.toml</span>
uv run bench/bench_runner.py
<span><span>#</span> or</span>
make bench</pre></div>
<p dir="auto">Results get saved to <code>data/run_&lt;id&gt;.csv</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Where this could go</h2><a id="user-content-where-this-could-go" aria-label="Permalink: Where this could go" href="#where-this-could-go"></a></p>
<ul dir="auto">
<li><strong>Model-specific prompts</strong>: Tune instructions to each model's strengths</li>
<li><strong>Richer feedback</strong>: Pass more spatial context (distance readings, compass, minimap?)</li>
<li><strong>Multi-agent runs</strong>: What if you gave each model a drone and made them compete?</li>
<li><strong>Extended iterations</strong>: Let slow models run longer to isolate reasoning from speed</li>
<li><strong>Real drone benchmark</strong>: Gemini Flash vs. the BetaFPV</li>
<li><strong>Pokémon assets</strong>: Found <a href="https://poly.pizza/l/Bm4vionqpU" rel="nofollow">low-poly Pokémon models</a> on Poly Pizza—leaning into the Pokémon Snap inspiration</li>
<li><strong>World improvements</strong>: Larger terrain, better visuals, performance optimizations</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Attribution</h2><a id="user-content-attribution" aria-label="Permalink: Attribution" href="#attribution"></a></p>
<ul dir="auto">
<li>Drone by NateGazzard <a href="https://creativecommons.org/licenses/by/3.0/" rel="nofollow">CC-BY</a> via <a href="https://poly.pizza/m/DNbUoMtG3H" rel="nofollow">Poly Pizza</a></li>
<li>Cube World Kit by Quaternius via <a href="https://poly.pizza/bundle/Cube-World-Kit-DwDr8493Fw" rel="nofollow">Poly Pizza</a></li>
</ul>
<p dir="auto"><em>Donated to <a href="https://poly.pizza/" rel="nofollow">Poly Pizza</a> to support the platform.</em></p>
<br>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MapLibre Tile: a modern and efficient vector tile format (363 pts)]]></title>
            <link>https://maplibre.org/news/2026-01-23-mlt-release/</link>
            <guid>46763864</guid>
            <pubDate>Mon, 26 Jan 2026 10:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maplibre.org/news/2026-01-23-mlt-release/">https://maplibre.org/news/2026-01-23-mlt-release/</a>, See on <a href="https://news.ycombinator.com/item?id=46763864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p> Jan 23, 2026 </p>   <p>Today we are happy to announce <strong>MapLibre Tile</strong> (MLT), a new modern and efficient vector tile format.</p>
<div><p><img src="https://maplibre.org/_astro/mlt.CaGKYWCo_Z6Nrwr.webp" alt="MapLibre Tile Support" loading="lazy" decoding="async" fetchpriority="auto" width="2987" height="1867"></p></div>
<h2 id="what-is-maplibre-tile">What is MapLibre Tile?</h2>
<p>MapLibre Tile (MLT) is a succesor to <a href="https://github.com/mapbox/vector-tile-spec">Mapbox Vector Tile (MVT)</a>.
It has been redesigned from the ground up to address the challenges of rapidly growing geospatial data volumes
and complex next-generation geospatial source formats, as well as to leverage the capabilities of modern hardware and APIs.</p>
<p>MLT is specifically designed for modern and next-generation graphics APIs to enable high-performance processing and rendering of
large (planet-scale) 2D and 2.5 basemaps. This current implementation offers feature parity with MVT<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> while delivering on the following:</p>
<ul>
<li><strong>Improved compression ratio</strong>: up to 6x on large tiles, based on a column-oriented layout with recursively applied (custom)
lightweight encodings. This leads to reduced latency, storage, and egress costs and, in particular, improved cache utilization.</li>
<li><strong>Better decoding performance</strong>: fast, lightweight encodings that can be used in combination with SIMD/vectorization instructions.</li>
</ul>
<p>In addition, MLT was designed to support the following use cases in the future:</p>
<ul>
<li><strong>Improved support for 3D coordinates</strong>, i.e. elevation.</li>
<li><strong>Improved processing performance</strong>, based on storage and in-memory formats that are specifically designed for modern graphics APIs,
allowing for efficient processing on both CPU and GPU. The formats are designed to be loaded into GPU buffers with little or no additional processing.</li>
<li><strong>Support for linear referencing and m-values</strong> to efficiently support the upcoming next-generation source formats such as Overture Maps (GeoParquet).</li>
<li><strong>Support complex types</strong>, including nested properties, lists and maps.</li>
</ul>
<p>As with any MapLibre project, the future of MLT is decided by the needs of the community. There are a lot of exciting ideas for other future extensions and we welcome contributions to <a href="https://github.com/maplibre/maplibre-tile-spec">the project</a>.</p>
<p>For a more in-depth exploration of MLT have a look at the <a href="https://github.com/mactrem/presentations/blob/main/FOSS4G_2024_Europe/FOSS4G_2024_Europe.pdf">following slides</a>, watch
<a href="https://www.youtube.com/watch?v=YHcoAFcsES0">this talk</a> or read <a href="https://www.arxiv.org/abs/2508.10791">this paper</a> by MLT inventor Markus Tremmel.</p>
<h2 id="when-can-i-use-it">When can I use it?</h2>
<p>For the adventurous, the answer is: <strong>today</strong>. Both MapLibre GL JS and MapLibre Native now support MLT sources. You can use the new <a href="https://maplibre.org/maplibre-style-spec/sources/#encoding"><code>encoding</code></a> property on sources in your style JSON with a value of <code>mlt</code> for MLT vector tile sources.</p>
<p>To try out MLT, you have the following options:</p>
<ul>
<li>The easiest way to try out MLT is to use the <a href="https://raw.githubusercontent.com/maplibre/demotiles/refs/heads/gh-pages/tiles-mlt/plain.json">MLT-based demotiles style</a>.</li>
<li>You can also try out the <a href="https://github.com/maplibre/maplibre-tile-spec/tree/main/java/encoding-server">encoding server</a> that converts existing (MVT-based) styles and vector tile sources to MLT on the fly. This is mostly a tool for development.</li>
<li>To create tiles for production, you could use <a href="https://github.com/onthegomap/planetiler">Planetiler</a>, as the upcoming version will support generating MLTs.</li>
</ul>
<p>Refer to <a href="https://maplibre.org/maplibre-tile-spec/implementation-status/">this page</a> for a complete and up-to-date list of integrations and implementations. If you are an integrator working on supporting MLT, feel free to add your own project there.</p>
<p>We would love to hear your experience with using MLT! Join the <code>#maplibre-tile-format</code> channel on <a href="https://maplibre.org/community">our Slack</a> or create an Issue or Discussion on the <a href="https://github.com/maplibre/maplibre-tile-spec">tile spec repo</a>.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>MapLibre Tile came to be thanks to a multi-year collaboration between academia, open source and enterprise. Thank you to everyone who was involved! We are very proud that our community can innovate like this.</p>
<p>Special thanks go to Markus Tremmel for inventing the format, Yuri Astrakhan for spearheading the project, Tim Sylvester for the C++ implementation, Harel Mazor, Benedikt Vogl and Niklas Greindl for working on the JavaScript implementation.</p>
<p>Also thanks to Microsoft and AWS for financing work on MLT.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>One exception: unlike MVT, MLT does not support layers where a value in a column changes type from feature to feature. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
</ol>
</section> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[San Francisco Graffiti (109 pts)]]></title>
            <link>https://walzr.com/sf-graffiti</link>
            <guid>46763721</guid>
            <pubDate>Mon, 26 Jan 2026 10:02:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://walzr.com/sf-graffiti">https://walzr.com/sf-graffiti</a>, See on <a href="https://news.ycombinator.com/item?id=46763721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><p> These photos were taken by city inspectors documenting graffiti violations across San Francisco. I scraped them from the city's website. Street art, through the lens of the law.</p></header></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple, What Have You Done? (136 pts)]]></title>
            <link>https://onlinegoddess.net/2026/01/apple-what-have-you-done/</link>
            <guid>46763592</guid>
            <pubDate>Mon, 26 Jan 2026 09:43:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onlinegoddess.net/2026/01/apple-what-have-you-done/">https://onlinegoddess.net/2026/01/apple-what-have-you-done/</a>, See on <a href="https://news.ycombinator.com/item?id=46763592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2026-01-13T20:20Z">
    13 Jan, 2026
</time>
            </i>
        </p>
    

    <p>I've been an Apple user for over a decade and generally very happy with that life choice, but since iOS / iPadOS 26 and MacOS Tahoe were released a few months ago, I honestly want to tear my hair out.</p>
<p>I'm trying to get on with the new OS, but there's so many little bugs that Apple software no longer feels like it just works. It seems less intuitive and like nobody has really tested it thoroughly. Do Apple staff even use their products anymore, or are they all secretly harbouring Android devices?</p>
<p>Here's a few issues that annoy me regularly, this list is <em>far</em> from exhaustive:</p>
<h3 id="iphone">iPhone</h3><p>My iPhone 14 Pro has 35Gb of "system data" which has basically filled up the entire storage I had left. If I delete some apps or data to free up room, the system data then takes it! I can't update easily because updates need lots of space and sometimes I can't even take a photo! Call me cynical, but this feels like a tactic to force me to buy a newer iPhone<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p>
<p>My white home screen widgets no longer blend into my white wallpaper thanks to the glowing liquid glass border. I was so happy when Apple allowed you to hide widget names so they could look like part of the home screen, now they've basically undone this.</p>
<p>Random restarts. This has always happened occasionally, but now it's at least once a week, most commonly when taking a photo.</p>
<h3 id="ipad">iPad</h3><p>The search box in the App Store doesn't auto-focus - when you bring it up, you immediately want to type, but Apple makes you tap into it as well. That's shoddy UI design.</p>
<p>It's SO aggressive with tab refreshing in Safari! I have an M1 iPad Pro, yet this happens whenever I open a couple of different tabs and go back. Other browsers don't do this.</p>
<h3 id="mac">Mac</h3><p>Why, oh why did Apple take the app launcher away! I had everything neatly put into folders and now they're all gone. No warning, no option to organise them a different way, just gone. I used muscle memory to access most of my apps, sometimes I can't even remember their names, but now I have to because the new way to open apps is to search for them<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<h3 id="hardware">Hardware</h3><p>It's not the just the software that has issues unfortunately....</p>
<p>My Magic Keyboard sometimes loses connection with the iPad and I have to detach/reattach it. Oh, and occasionally it rattles!! If you think I might have just been unlucky, this is the second one I purchased - the first had a lump on the bottom!<sup id="fnref-3"><a href="#fn-3">3</a></sup> Obviously not an OS issue, but I've never known such poor quality control from Apple.</p>
<p>My iMac screen also flickers sometimes and this never happened before Tahoe. It feels like a bug with the auto-brightness, but I'm terrified it's going to die on me.</p>
<p>So is it just me? Or is this OS definitely a bad Apple?</p>
<div>
        <p>There are 2 comments - tap to view!<span></span></p>
        <div>
            <p><a href="https://sebastianmalloy.bearblog.dev/" target="_blank">Sebastian</a> 🇺🇸 commented via the <a href="https://onlinegoddess.net/guestbook/">Guestbook</a>:</p>
<blockquote>
<p>I was just LAST NIGHT complaining about how Apple is irritating the hell out of me right now. I was trying to figure out why my Apple Music with no downloaded music was eating up 9 gigs of space, and found there is really no user-facing way to correct the issue. I’M AN OLD HUMAN! I remember when Apple products JUST WORKED.</p>
<p>(Also, love your blog. Keep up the good words. Don’t be a stranger!)</p>
<ul>
<li><em>My Apple Music has mysterious data too! I deleted every downloaded song, album, playlist etc to no avail. Goodness knows what's going on, something has definitely changed. Lovely to have another comment from you, I'm really glad you're enjoying the blog. :) ~Becky</em></li>
</ul>
</blockquote>
<p><a href="https://anarchaeopteryx.bearblog.dev/" target="_blank">Ruth</a> commented via the <a href="https://onlinegoddess.net/guestbook#ruth-140125">Guestbook</a>:</p>
<blockquote>
<p>Your complaint about the System files taking over your entire iPhone reminded me of this post I read last week: <a href="https://louplummer.lol/how-apple-nearly-ruined-my-vacation/" target="_blank">How Apple Nearly Ruined My Vacation</a>.</p>
<p>There isn't really a solution offered in that post other than the full wipe that you don't want to do for very reasonable reasons, and I don't use Apple any more so can't provide any insight personally, but it seems likely to be a similar problem relating to the system caching too much shit. Personally, MacOS peaked around 2015 Yosemite and has largely been downhill from there.</p>
<ul>
<li><em>I agree it's definitely a caching issue, just strange that we're not allowed to manually flush it. Apple deciding it knows best as usual! Thanks for the link to Lou's article, I remember reading that one! ~Becky</em></li>
</ul>
</blockquote>

        </div>
    </div>
<section>
<ol>
<li id="fn-1"><p><em>Yes, I could wipe the phone and reinstall from scratch, but that always terrifies me as I've managed to lose data in the past, despite backing up.</em><a href="#fnref-1">↩</a></p></li>
<li id="fn-2"><p><em>I've noticed a few third party launchers have popped up, initially free and then switching to paid once they've lured you in.</em><a href="#fnref-2">↩</a></p></li>
<li id="fn-3"><p><em>Purchased in "mint condition" off Amazon and it was most certainly <strong>not</strong> (badly scuffed &amp; peeling), but the lump must have been there since new as it was inside the silicone trim! It went straight back to Amazon.</em><a href="#fnref-3">↩</a></p></li>
</ol>
</section>


    

    
        
            <p>
                
                    <a rel="nofollow" href="https://onlinegoddess.net/blog/?q=tech">#tech</a>
                
            </p>
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK House of Lords Votes to Extend Age Verification to VPNs (151 pts)]]></title>
            <link>https://reclaimthenet.org/uk-house-of-lords-votes-to-extend-age-verification-to-vpns</link>
            <guid>46763548</guid>
            <pubDate>Mon, 26 Jan 2026 09:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reclaimthenet.org/uk-house-of-lords-votes-to-extend-age-verification-to-vpns">https://reclaimthenet.org/uk-house-of-lords-votes-to-extend-age-verification-to-vpns</a>, See on <a href="https://news.ycombinator.com/item?id=46763548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="4189490c" data-element_type="widget" data-widget_type="theme-post-content.default">
					<p>The UK House of Lords has voted to extend “age assurance” requirements, effectively age verification mandates, to <a href="https://reclaimthenet.org/uk-online-safety-act-privacy-surveillance-vpn-anonymity-regulation">virtual private networks</a> (VPNs) and a wide range of online platforms under the <a href="https://reclaimthenet.org/uk-lawmakers-propose-mandatory-on-device-surveillance-and-vpn-age-verification">Children’s Wellbeing and Schools Bill</a>.</p>
<p>The decision deepens the reach of the already-controversial <a href="https://reclaimthenet.org/uk-age-verification-privacy-backlash">Online Safety Act</a>, linking child safety goals to mechanisms that could have severe effects on private communication and digital autonomy.</p>
<p>Under the existing Online Safety Act framework, “user-to-user services” include almost any online platform that enables individuals to post, share, or interact with content from others.</p>
<p>This definition covers social networks, messaging apps, forums, and online gaming services. Only a few forms of communication, such as email, SMS, MMS, and one-to-one live voice calls, are explicitly excluded.</p>
<p>While political messaging around the vote often described the move as a “social media ban for under-16s,” the actual scope is considerably wider.</p>
<p>In effect, most interactive online platforms would now need to collect and verify age data from users, even where those services are not primarily aimed at children.</p>
<p>This represents a major expansion of identity checks across digital infrastructure, once considered neutral or privacy-protective, and one of the most disciplinarian proposals in the West.</p>
<p>Two key amendments advanced during the Lords debate on January 21.</p>
<p><a href="https://bills.parliament.uk/bills/3909/stages/20215/amendments/10027478">Amendment 92</a> (“Action to Prohibit the Provision of VPN Services to Children in the United Kingdom”) requires VPNs that are “offered or marketed to persons in the United Kingdom” or “provided to a significant number of persons” to implement age assurance for UK users.</p>
<p>The measure passed by 207 Content votes to 159 Not Content votes.</p>
<p><img fetchpriority="high" decoding="async" src="https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni.jpg" alt="Children's Wellbeing and Schools Bill division (21 Jan 2026): Amendment 92 passed, Content 207 vs Not Content 159" width="2346" height="968" srcset="https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni.jpg 2346w, https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni-300x124.jpg 300w, https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni-1024x423.jpg 1024w, https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni-768x317.jpg 768w, https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni-1536x634.jpg 1536w, https://reclaimthenet.org/wp-content/uploads/2026/01/vkyzx6oMLWni-2048x845.jpg 2048w" sizes="(max-width: 2346px) 100vw, 2346px"></p>
<p><a href="https://bills.parliament.uk/bills/3909/stages/20215/amendments/10031850">Amendment 94a</a> (“Action to Promote the Wellbeing of Children in Relation to Social Media”) mandates that all regulated user-to-user services introduce age assurance systems to prevent under-16s from “becoming or being users.” This proposal passed with 261 Content votes to 150 Not Content votes.</p>
<p>Both amendments will proceed to the Bill’s next stage, the third reading in the House of Lords.</p>
<p>Two other amendments, both more technologically intrusive, were discussed but rejected.</p>
<p>Amendment 93, introduced by Lord Nash, would have compelled smartphone and tablet manufacturers, distributors, and importers to install “tamper-proof system software which is highly effective at preventing the recording, transmitting (by any means, including livestreaming) and viewing of CSAM using that device.”</p>
<p>The only plausible way to enforce such a measure would be through constant, automated inspection of every photo, video, and stream on a device. This form of surveillance would have converted personal devices into continuous content monitors, raising severe privacy and accuracy concerns, including potential false positives.</p>
<p>Lord Nash stated: “On Amendment 93, I have had a constructive discussion with Ministers on this issue and more discussions are in progress, so I will not push that to a vote today.”</p>
<p>Amendment 108, proposed by Lord Storey, would have required user-to-user services “likely to be accessed by children” to set their own minimum age thresholds and use age assurance to enforce them.</p>
<p>He argued that a single blanket ban under Amendment 94a was overly rigid. “Having different minimum ages for different platforms would be a better solution,” he said, maintaining that his version would be more effective in practice.</p>
<p>Neither of these amendments passed, leaving Amendments 92 and 94a as the only ones to advance.</p>
<p>The discussion highlights a deepening push within UK legislation to merge digital identity checks with online participation.</p>
<p>While described as safeguarding children, the changes embed a new layer of identity verification across tools once used for privacy, such as VPNs.</p>
<p>These services, designed to conceal personal browsing data and protect against profiling, would now face obligations to verify who their users are. This is a contradiction that could erode one of the few remaining shields for private internet use.</p>
<p>For now, the most invasive surveillance measure, client-side scanning, has been set aside. However, the fact that it was seriously considered indicates continuing interest in embedding scanning mechanisms directly into personal devices.</p>
<p>Whether similar proposals reappear during the third reading remains to be seen.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Holy Grail of Linux Binary Compatibility: Musl and Dlopen (196 pts)]]></title>
            <link>https://github.com/quaadgras/graphics.gd/discussions/242</link>
            <guid>46762882</guid>
            <pubDate>Mon, 26 Jan 2026 07:41:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/quaadgras/graphics.gd/discussions/242">https://github.com/quaadgras/graphics.gd/discussions/242</a>, See on <a href="https://news.ycombinator.com/item?id=46762882">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="9388957" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">I guess using Go + Godot to <a href="https://github.com/quaadgras/graphics.gd/discussions/184" data-hovercard-type="discussion" data-hovercard-url="/quaadgras/graphics.gd/discussions/184/hovercard">build native &amp; installable Android &amp; iOS binaries</a> (without any proprietary SDKs) was too easy.  So it's time for a real challenge...</p>
<h3 dir="auto">Linux Binary Compatibility</h3>
<p dir="auto">(some background reading: <a href="https://jangafx.com/insights/linux-binary-compatibility" rel="nofollow">https://jangafx.com/insights/linux-binary-compatibility</a>)</p>
<p dir="auto">For a while now, it's been very easy to reliably ship command line software &amp; servers for Linux, just run <code>go build</code> and out pops a single static binary that will run on any Linux distribution running kernel 3.2 or later (which was released in 2012, so there's plenty of room for backwards compatibility).</p>
<p dir="auto">The problems begin to creep in when you want access to hardware accelerated graphics. All the GPU drivers on Linux require accessing dynamic libraries via the C ABI. These C libraries are built against a particular libc, which is most commonly <code>glibc</code> but there are also a selection of <code>musl</code>-based distributions. If you compile a <code>glibc</code> library or executable, it won't run on a <code>musl</code> system and vice-versa. That's a big incompatibility right there!</p>
<p dir="auto">In fact, I've directly experienced this, as I recently replaced the OS on my personal computer with the <code>musl</code> edition of <a href="https://voidlinux.org/" rel="nofollow">Void Linux</a>. Compiling the <a href="https://zed.dev/" rel="nofollow">Zed</a> editor with musl for example, was quite the challenge. It turns out that building <code>graphics.gd</code> projects on <code>musl</code> was also very broken. Go doesn't properly support <code>c-shared</code> or <code>c-archive</code> when building against <code>musl</code>.</p>
<p dir="auto">That's a problem, firstly because this is my distro now, I need to be able to build graphics.gd projects! Secondly, in theory, <code>musl</code> has better support for static linking than <code>glibc</code>; so if there's any solution to this Linux Binary Compatibility mess, it's probably going to have something to do with <code>musl</code>.</p>
<h3 dir="auto">Supporting <code>musl</code></h3>
<p dir="auto">To work around <a href="https://github.com/golang/go/issues/13492" data-hovercard-type="issue" data-hovercard-url="/golang/go/issues/13492/hovercard">these</a> <code>musl</code> issues with Go, I had to patch the runtime with a build-overlay that applies when building for <code>GOOS=musl</code>. This is a new <code>GOOS</code> that I've introduced to graphics.gd, specifically to make <code>musl</code> builds possible.</p>
<p dir="auto">Next up, I decided to ditch c-shared builds for <code>musl</code>, these were only convenient because you could easily plug and play Go into the official Godot binaries. The Godot Foundation doesn't provide official musl builds, so instead, I'm linking the Go code directly with Godot <code>c-archive</code> to end up with a single binary. Amazing, <code>graphics.gd</code> supports <code>musl</code> now!</p>
<p dir="auto">There's just one issue, this means whenever somebody wants to release their project for Linux, they would have to create two builds, a Linux <code>glibc</code> build + a <code>musl</code> build and somehow communicate to their users, to pick the correct binary. Hell, before I installed Void Linux <em>I</em> didn't even fully comprehend the differences between <code>musl</code> and <code>glibc</code>, this feels like I'm simply contributing to the problem!</p>
<h3 dir="auto">Single Static Binaries + Graphics</h3>
<p dir="auto">Hold up! Earlier I reported that a key benefit of <code>musl</code> was better static library support. There should be a way to build a graphics.gd project into a single static binary. Well, here's the thing. Yes, you can totally do this. Godot includes all of it's dependencies on Linux, everything else is dynamically loaded at runtime, so just add the <code>-static</code> command and...</p>
<p dir="auto"><code>ERROR Dynamic loading not supported</code></p>
<p dir="auto">Ouch, Godot wants to use <code>dlopen</code> to interface with X11, Wayland, OpenGL, Vulkan etc. As it turns out, <code>musl</code> refuses to implement <code>dlopen</code> for static binaries. They don't want anyone to load a <code>glibc</code> library from <code>musl</code> because there are fundamental incompatibilities between how they implement  TLS (thread-local-storage).</p>
<p dir="auto">Don't worry though! As <code>dlopen</code> is compiled as a weak symbol, this means, that as long as <code>graphics.gd</code> implements it, there's still a chance to get a single static binary that can execute on any Linux system 3.2 onwards.</p>
<h3 dir="auto">The Holy Grail</h3>
<p dir="auto">There's some precedent for this, there's the <a href="https://github.com/graphitemaster/detour">detour</a> technique in C which will let you <code>dlopen</code> SDL and show graphics when running <em>without a standard library</em>. There's also Cosmopolitan's <a href="https://github.com/jart/cosmopolitan/tree/master/libc/dlopen">dlopen</a> which uses a similar technique. So the solution here is to extend this for <code>musl</code>.</p>
<p dir="auto">The way this works, is by including (or compiling) a small <code>C</code> program for the target machine. We load the program and execute into it from the same process. This program brings in the host's dynamic linker so that we can <em>steal</em> the system's <code>dlopen</code> and <code>longjmp</code> back into <code>graphics.gd</code>. We wrap any dynamically loaded functions with an assembly trampoline that switches to the system's libc TLS for the duration of the call. It all starts looking a lot like cgo.</p>
<p dir="auto">So after much hair pulling and LLM wrangling, it turns out that <code>musl</code> + <code>dlopen</code> is all we need to produce single static binaries + graphics for Linux. Everyone can now enjoy the <em>Go</em> single-static-binary experience on Linux with full support for hardware accelerated graphics.</p>
<h3 dir="auto">Try it!</h3>
<p dir="auto">Here's a build of the <code>graphics.gd</code> Dodge The Creeps sample project that should execute (and hopefully render graphics) on any Linux system with <code>gcc</code> installed (we don't embed the helper binaries yet).</p>
<p dir="auto"><a href="https://release.graphics.gd/dodge_the_creeps.static" rel="nofollow">https://release.graphics.gd/dodge_the_creeps.static</a></p>
<p dir="auto">You can also cross-compile your own project (on any supported platform)</p>
<p dir="auto"><code>GOOS=musl GOARCH=amd64 gd build</code></p>
<p dir="auto"><em>Note you may need to delete your <code>export_presets.cfg</code> so that the new musl export preset is added to your project</em></p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The browser is the sandbox (305 pts)]]></title>
            <link>https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/</link>
            <guid>46762150</guid>
            <pubDate>Mon, 26 Jan 2026 05:23:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/">https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/</a>, See on <a href="https://news.ycombinator.com/item?id=46762150">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://aifoc.us/the-browser-is-the-sandbox/">the browser is the sandbox</a></strong>. Paul Kinlan is a web platform developer advocate at Google and recently turned his attention to coding agents. He quickly identified the importance of a robust sandbox for agents to operate in and put together these detailed notes on how the web browser can help:</p>
<blockquote>
<p>This got me thinking about the browser. Over the last 30 years, we have built a sandbox specifically designed to run incredibly hostile, untrusted code from anywhere on the web, the instant a user taps a URL. [...]</p>
<p>Could you build something like Cowork in the browser? Maybe. To find out, I built a demo called <a href="http://co-do.xyz/">Co-do</a> that tests this hypothesis. In this post I want to discuss the research I've done to see how far we can get, and determine if the browser's ability to run untrusted code is useful (and good enough) for enabling software to do more for us directly on our computer.</p>
</blockquote>
<p>Paul then describes how the three key aspects of a sandbox - filesystem, network access and safe code execution - can be handled by browser technologies: the <a href="https://developer.chrome.com/docs/capabilities/web-apis/file-system-access">File System Access API</a> (still Chrome-only as far as I can tell), CSP headers with <code>&lt;iframe sandbox&gt;</code> and WebAssembly in Web Workers.</p>
<p>Co-do is a very interesting demo that illustrates all of these ideas in a single application:</p>
<p><img alt="Screenshot of Co-do application interface with robot logo. Left sidebar shows WORKSPACE section with &quot;Select Folder&quot; button, &quot;Selected folder: blog-drafts (Live updates enabled)&quot; in green text, and FILES list including gtr-t5-large.md, chatgpt.md, llm-digest-october-2..., weeknotes-2024-04-23..., lmarena-april-2025.md, weeknotes-chatgpt-fo..., tests-not-optional-c..., weeknotes-13-mar-202..., issue-for-notes.md, workshop-git-scrapin.... Main chat area shows user message &quot;Three most recently edited files?&quot; in orange bubble, &quot;Using 26 tools...&quot; dropdown, and AI response: &quot;Now I need to get the metadata for these files to find the most recently edited ones. Since there are many files, let me get metadata for a sample of them to find the recent ones:Based on the metadata I've gathered, the three most recently edited files are:&quot; followed by table with columns File and Last Modified showing predictions-2026.md (Jan 8, 2026), december-2025.md (Jan 2, 2026), gemini-3-flash.md (Dec 17, 2025). Green &quot;Response complete&quot; banner at bottom with input field placeholder &quot;Ask me to help with your files...&quot; and notice &quot;File contents are sent to your selected AI provider&quot;." src="https://static.simonwillison.net/static/2026/codo.jpg"></p>
<p>You select a folder full of files and configure an LLM provider and set an API key, Co-do then uses CSP-approved API calls to interact with that provider and provides a chat interface with tools for interacting with those files. It does indeed feel similar to <a href="https://simonwillison.net/2026/Jan/12/claude-cowork/">Claude Cowork</a> but without running a multi-GB local container to provide the sandbox.</p>
<p>My biggest complaint about <code>&lt;iframe sandbox&gt;</code> remains how thinly documented it is, especially across different browsers. Paul's post has all sorts of useful details on that which I've not encountered elsewhere, including a complex <a href="https://aifoc.us/the-browser-is-the-sandbox/#the-double-iframe-technique">double-iframe technique</a> to help apply network rules to the inner of the two frames.</p>
<p>Thanks to this post I also learned about the <code>&lt;input type="file" webkitdirectory&gt;</code> tag which turns out to work on Firefox, Safari <em>and</em> Chrome and allows a browser read-only access to a full directory of files at once. I had Claude knock up a <a href="https://tools.simonwillison.net/webkitdirectory">webkitdirectory demo</a> to try it out and I'll certainly be using it for projects in the future.</p>
<p><img alt="Screenshot of a dark-themed file explorer application. Top stats bar shows: 12179 TOTAL FILES, 2079 FOLDERS, 244 MB TOTAL SIZE, 97 FILE TYPES in cyan text. Search bar with placeholder &quot;Search files...&quot; and &quot;All types&quot; dropdown. Left panel labeled &quot;File tree&quot; (showing 12179) displays folder hierarchy: datasette > .claude > skills > building-datasette-plugins containing HOOKS.md (10.7 KB, selected/highlighted), INTERNALS.md (10.1 KB), SKILL.md (3.7 KB), TESTING.md (8.4 KB), settings.local.json (280 B); also shows .eggs folder with pytest_runner-6.0.1-py3.9.egg. Right panel &quot;File preview&quot; shows selected file details: Name: HOOKS.md, Path: datasette/.claude/skills/building-datasette-plugins/HOOKS.md, Size: 10.7 KB, Type: text/markdown, Last modified: 12/20/2025, 9:28:59 AM. Preview content shows: &quot;# Plugin Hooks Reference&quot; followed by &quot;All hooks use the @hookimpl decorator. Accept only the parameters you need.&quot; then &quot;## Database Connection Hooks&quot; and &quot;### prepare_connection(conn, database, datasette)&quot; with description &quot;Called when a new SQLite connection is created. Use to register custom SQL functions.&quot; Bottom section &quot;File type distribution&quot; shows horizontal bar chart: .py (4439), .no ext (3358), .dat (1068), .pyc (925), .txt (332), .mo (321), .po (321), .html (249)." src="https://static.simonwillison.net/static/2026/webkit-file-tree.jpg"></p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Iran's internet blackout may become permanent, with access for elites only (371 pts)]]></title>
            <link>https://restofworld.org/2026/iran-blackout-tiered-internet/</link>
            <guid>46761822</guid>
            <pubDate>Mon, 26 Jan 2026 04:18:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restofworld.org/2026/iran-blackout-tiered-internet/">https://restofworld.org/2026/iran-blackout-tiered-internet/</a>, See on <a href="https://news.ycombinator.com/item?id=46761822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<!-- Article Start -->
				
<p>Iran’s near-total communications blackout has entered its 16th day, but that’s just a live test.</p>



<p>Following a repressive crackdown on protests, the government is now building a system that grants web access only to security-vetted elites, while locking 90 million citizens inside an intranet.</p>



<p>Government spokesperson Fatemeh Mohajerani confirmed international access <a href="https://www.rferl.org/a/iran-internet-shutdown-censorship/33654841.html">will not be restored</a> until at least late March. Filterwatch, which monitors Iranian internet censorship from Texas, cited government sources, including Mohajerani, saying access will “<a href="https://filter.watch/english/2026/01/15/iran-enters-a-new-age-of-digital-isolation-2/">never return to its previous form</a>.”</p>



<p>This is what makes Iran’s attempt unique: Other authoritarian states built walls before their populations went online. Iran is trying to seal off a connected economy <a href="https://www.crisisgroup.org/stm/middle-east-north-africa/iran-united-states/iran-crisis-time-change-within">already in freefall</a>.&nbsp;</p>



<p>The system is called Barracks Internet, according to confidential planning documents <a href="https://filter.watch/english/2026/01/15/iran-enters-a-new-age-of-digital-isolation-2/">obtained by Filterwatch</a>. Under this architecture, access to the global web will be granted only through a strict security whitelist.</p>


		<figure>
			<div>
				<p><img src="https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=800&amp;dpr=2&amp;crop=16:9" srcset="https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=1900&amp;dpr=2 3800w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=1700&amp;dpr=2 3400w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=1500&amp;dpr=2 3000w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=1300&amp;dpr=2 2600w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=1100&amp;dpr=2 2200w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=900&amp;dpr=2 1800w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=700&amp;dpr=2 1400w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=500&amp;dpr=2 1000w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=300&amp;dpr=2 600w, https://fastly.restofworld.org/uploads/2026/01/GettyImages-2255474345.jpg?width=100&amp;dpr=2 200w, " sizes="(min-width: 640px) 600px, calc(100vw - 40px)" alt="Silhouettes of people near a fire on a bridge, with smoke and orange flames illuminating the scene at night." loading="lazy">
					
				</p>
			</div>
				<figcaption itemprop="caption description">
		<span>An armed member of the Iranian security forces in front of a burning building during a protest in Tehran, Iran, on January 9, 2026.</span>
		<span itemprop="copyrightHolder">Getty Images</span>
	</figcaption>
		</figure>


<p>“The regime is terrified of one thing: Iranians being heard telling their own truth and having crimes documented,” Mahsa Alimardani, a digital rights researcher at U.S.-based Witness, which trains activists to use video for advocacy, told <em>Rest of World</em>. “The question becomes: How do we give Iranians an unbreakable voice?”</p>



<p>The idea of tiered internet access is not new in Iran. Since at least 2013, the regime has quietly issued “white SIM cards,” giving unrestricted global internet access to approximately 16,000 people. The system gained public attention in November 2025 when X’s location feature revealed that certain accounts, including the communications minister, were <a href="https://iranwire.com/en/features/146582-iran-internet-ban-the-islamic-republic-filters-for-millions-of-people-not-for-its-own/">connecting directly from inside</a> Iran, <a href="https://iranwire.com/en/features/146582-iran-internet-ban-the-islamic-republic-filters-for-millions-of-people-not-for-its-own/"></a>despite X being blocked since 2009.</p>



<p>What is different now is scale and permanence. The current blackout tests infrastructure designed to make two-tier access the default, not a temporary crackdown.</p>



<p>Only a handful of nations have attempted to wall off their citizens from the global internet. North Korea’s Kwangmyong intranet was built from scratch for a population that never had connectivity. China constructed its Great Firewall over two decades while nurturing domestic alternatives such as WeChat and Alibaba. Iran is attempting to do both in weeks, with no domestic alternatives.</p>


<figure><blockquote><p>The question becomes: How do we give Iranians an unbreakable voice?”</p></blockquote></figure>


<p>The economic costs of the blackout are staggering. Iran’s deputy communications minister <a href="https://abcnews.go.com/Business/wireStory/internet-shutdown-squeezes-irans-ailing-businesses-hurt-crashing-129374950">pegged the daily losses</a> at as much as $4.3 million. <a href="https://abcnews.go.com/Business/wireStory/internet-shutdown-squeezes-irans-ailing-businesses-hurt-crashing-129374950">NetBlocks estimates</a> the true cost exceeds $37 million daily. More than 10 million Iranians depend directly on digital platforms for their livelihoods.</p>



<p>Tipax, one of Iran’s largest private delivery companies handling about 320,000 daily shipments before the protests, now processes fewer than a few hundred, <a href="https://filter.watch/english/2026/01/15/iran-enters-a-new-age-of-digital-isolation-2/">according to Filterwatch</a>. The company operates a nationwide logistics network comparable to FedEx in the U.S. market.</p>



<p>The government <a href="https://www.france24.com/en/asia-pacific/20260118-live-iran-nationwide-protests-official">fired Irancell’s CEO</a> for failing to comply with shutdown orders. Irancell, the country’s second-largest mobile operator with 66 million subscribers, is partly owned by South Africa’s MTN Group. Alireza Rafiei was removed for disobeying orders on “restriction of internet access in crisis situations,” <a href="https://www.newarab.com/news/iranian-mobile-operator-ceo-fired-not-cutting-internet">according to</a> Fars news agency.</p>



<p>Foreign telecom partners have left Iran in recent days under security escort, without media coverage, <a href="https://filter.watch/english/2026/01/15/iran-enters-a-new-age-of-digital-isolation-2/">according to Filterwatch</a>. This may signal the end of international cooperation in critical infrastructure, replaced by the Revolutionary Guard’s construction arm or limited cooperation with Huawei.</p>



<p>Technical experts doubt the regime can sustain Barracks Internet without crippling the economy. Georgia Tech’s Internet Intelligence Lab, which has <a href="https://theconversation.com/irans-latest-internet-blackout-extends-to-phones-and-starlink-273439">tracked Iran’s shutdowns since the Arab Spring</a>, called the blackout “the most sophisticated and most severe in Iran’s history.” Its measurements show about 3% connectivity persists, likely government officials and state services.</p>


<figure><blockquote><p>We need to revolutionize access to the internet.”</p></blockquote></figure>


<p>Kaveh Ranjbar, former chief technology officer at RIPE NCC, the body managing European internet infrastructure, calls the plan a “digital airlock” that can’t fully seal a modern economy. No country has hermetically sealed a functioning digital economy, he <a href="https://www.newarab.com/analysis/iran-determined-turn-its-digital-space-north-korea-20">told <em>The New Arab</em></a>.</p>



<p>Activists have smuggled an estimated 50,000 Starlink satellite terminals into Iran since 2022, when the Biden <a href="https://www.vox.com/technology/395656/starlink-iran-internet-shutdown-elon-musk">administration exempted the service</a> from sanctions. SpaceX has made the service free for Iranian users.&nbsp;</p>



<p>The government claims it cut off 40,000 Starlink connections and jammed some terminals during the blackout, though others remain operational after firmware updates to <a href="https://www.bbc.com/persian/articles/cj3dn49d489o">bypass government blocking</a>. Still, the technology remains <a href="https://restofworld.org/2026/iran-starlink-internet-shutdown/">vulnerable to signal jamming</a>, meaning the regime holds ultimate leverage.</p>



<p>“We need to revolutionize access to the internet,” said Alimardani. “And move beyond the limiting structures and norms of ‘internet sovereignty.’”</p>
				<!-- Article End -->
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Environmentalists worry Google behind bid to control Oregon town's water (144 pts)]]></title>
            <link>https://www.sfgate.com/national-parks/article/mount-hood-water-google-21307223.php</link>
            <guid>46761614</guid>
            <pubDate>Mon, 26 Jan 2026 03:40:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/national-parks/article/mount-hood-water-google-21307223.php">https://www.sfgate.com/national-parks/article/mount-hood-water-google-21307223.php</a>, See on <a href="https://news.ycombinator.com/item?id=46761614">Hacker News</a></p>
Couldn't get https://www.sfgate.com/national-parks/article/mount-hood-water-google-21307223.php: Error: Request failed with status code 402]]></description>
        </item>
        <item>
            <title><![CDATA[Tech CEOs attend Amazon-funded "Melania" screening at White House (106 pts)]]></title>
            <link>https://www.hollywoodreporter.com/movies/movie-news/white-house-vip-melania-screening-mike-tyson-tim-cook-1236484037/</link>
            <guid>46761370</guid>
            <pubDate>Mon, 26 Jan 2026 03:04:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hollywoodreporter.com/movies/movie-news/white-house-vip-melania-screening-mike-tyson-tim-cook-1236484037/">https://www.hollywoodreporter.com/movies/movie-news/white-house-vip-melania-screening-mike-tyson-tim-cook-1236484037/</a>, See on <a href="https://news.ycombinator.com/item?id=46761370">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	The official <a rel="noreferrer noopener" target="_blank" href="https://www.hollywoodreporter.com/movies/movie-news/melania-doc-to-premiere-at-renamed-trump-kennedy-center-1236457244/">premiere</a> of the Amazon-backed <em>Melania</em> movie isn’t until Thursday night at the Kennedy Center, but with a snowstorm about to bear down on Washington, D.C., First Lady <a href="https://www.hollywoodreporter.com/t/melania-trump/" id="auto-tag_melania-trump_1" data-tag="melania-trump">Melania Trump</a> is opening the <a href="https://www.hollywoodreporter.com/t/white-house/" id="auto-tag_white-house_1" data-tag="white-house">White House</a> for a special dinner and screening for 70 of her friends, family members and assorted VIPs.</p>



<p>
	The event, which has not been promoted or advertised, is taking place in the White House on Saturday. Guests include director <a href="https://www.hollywoodreporter.com/t/brett-ratner/" id="auto-tag_brett-ratner_1" data-tag="brett-ratner">Brett Ratner</a>;&nbsp;Queen Rania of Jordan; Zoom CEO Eric Yuan; Apple CEO Tim Cook;&nbsp;New York Stock Exchange CEO Lynn Martin; AMD CEO Lisa Su; Mike&nbsp;Tyson; socialite and Fiat heiress Azzi Agnelli; self-help guru Tony Robbins; and photographer Ellen von Unwerth, who shot the movie poster for the film.

	</p>






<p>
	Barron <a href="https://www.hollywoodreporter.com/t/trump/" id="auto-tag_trump_1" data-tag="trump">Trump</a> and Ratner’s mother will also be on hand, along with Mike Hopkins of Amazon Studios, Amazon CEO Andy Jassy and Marc Beckman, a senior adviser and longtime manager to the First Lady who was reportedly involved in every aspect of the project.</p>



<p>
	Since the usual White House screening room in the East Wing has been shut down to construct the <a rel="noreferrer noopener" target="_blank" href="https://www.hollywoodreporter.com/news/politics-news/white-house-movie-theater-demolished-ballroom-east-wing-1236408712/">Trump ballroom</a>, Melania built a make-shift theater, with state of the art sound and film equipment (overseen by&nbsp;Ratner himself), and a giant movie screen brought in for the occasion.</p>



<p>
	Sources say nobody outside of Melania, Ratner and a very small group of their associates have yet to see the movie, <a rel="noreferrer noopener" target="_blank" href="https://www.hollywoodreporter.com/news/politics-news/trump-wayne-gretsky-melania-movie-1236470802/">including the President</a> and his advisors, who are watching it Saturday night for the first time.</p>



<p>
	A full military band will meet guests&nbsp;at the door to play “Melania’s Waltz,” a song&nbsp;composed especially for the film by Hollywood composer Tony Neiman. The band will stay on to play songs from Hollywood movies for the guests.

	</p>




<p>
	The event will have glossy, commemorative black and white popcorn boxes for guests, served by gloved waiters so they won’t get fingerprints on them.&nbsp;Specially&nbsp;framed tickets to&nbsp;the movie will also be available to take home.</p>



<p>
	The Amazon-funded&nbsp;movie&nbsp;(to the tune of $40 million)&nbsp;is opening nationwide in theaters on Jan. 30, preceded by a Kennedy Center premiere for&nbsp;VIPs&nbsp;and dignitaries on Jan 29. Concurrently with the Kennedy Center, they’re having smaller premieres in 20 cities including Nashville, Boston, San Francisco and Vegas for “local VIPs,” friends and supporters of the First Lady, featuring red carpets and step and repeats.</p>



<p>
	Billboards for the doc have already gone up, alongside a massive TV and radio advertising blitz. Though the <em>Melania</em> team hasn’t commented on the marketing dollars spent on the project, they deny <a rel="noreferrer noopener nofollow" target="_blank" href="https://puck.news/will-the-melania-trump-movie-actually-make-money/">Matt Belloni’s report</a> of $35 million.</p>



<p>
	The movie tracks Melania from Trump’s 2025 presidential campaign to inauguration day. A source close to the First Lady indicates that Ratner spent months living at Mar-a-Lago for shooting.</p>














</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE tells legal observer, 'We have a database, now you're a domestic terrorist' (163 pts)]]></title>
            <link>https://reason.com/2026/01/23/ice-tells-legal-observer-we-have-a-nice-little-database-and-now-youre-considered-a-domestic-terrorist/</link>
            <guid>46761130</guid>
            <pubDate>Mon, 26 Jan 2026 02:25:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2026/01/23/ice-tells-legal-observer-we-have-a-nice-little-database-and-now-youre-considered-a-domestic-terrorist/">https://reason.com/2026/01/23/ice-tells-legal-observer-we-have-a-nice-little-database-and-now-youre-considered-a-domestic-terrorist/</a>, See on <a href="https://news.ycombinator.com/item?id=46761130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																		<article>
	<header>
							<p>
				<a href="https://reason.com/tag/ice/">ICE</a>
			</p>
				
		
					<h2>The video is the latest example of federal immigration authorities labeling anyone who opposes them a "domestic terrorist."</h2>
				<p>
				
			
						<span>|</span>
			<time datetime="2026-01-23T15:23:57-05:00">1.23.2026 3:23 PM</time>
			
</p>
					
										<div>
						<div>
			<picture>
									<source type="image/webp" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2026/01/maine-ice-2400x1350.jpeg.webp 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2026/01/maine-ice-1200x675.jpeg.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2026/01/maine-ice-800x450.jpeg.webp 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2026/01/maine-ice-600x338.jpeg.webp 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2026/01/maine-ice-331x186.jpeg.webp 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2026/01/maine-ice-1200x675.jpeg.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2026/01/maine-ice-1920x1080.jpeg.webp 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
											<source type="image/jpeg" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2026/01/maine-ice-2400x1350.jpeg 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2026/01/maine-ice-1200x675.jpeg 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2026/01/maine-ice-800x450.jpeg 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2026/01/maine-ice-600x338.jpeg 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2026/01/maine-ice-331x186.jpeg 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2026/01/maine-ice-1200x675.jpeg 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2026/01/maine-ice-1920x1080.jpeg 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
													<img src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2026/01/maine-ice-800x450.jpeg" width="1200" height="675" title="Maine ICE agent" alt="Maine ICE agent | Reddit" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20675'%3E%3C/svg%3E" data-lazy-src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2026/01/maine-ice-800x450.jpeg">
			</picture>
		</div>
							<p><span>
					 (Reddit)				</span>
					</p>
								</div>
							
	</header>
	<div>
							<p><a href="https://www.reddit.com/r/Maine/comments/1qku4fs/ice_tells_legal_observer_she_is_a_domestic/"><span>Video</span></a><span> taken this morning in Maine shows an Immigration and Customs Enforcement (ICE) officer taking pictures of a legal observer's car. When she asks why he's doing that, he says, "Because we have a nice little database, and now you're considered a domestic terrorist."</span></p>
<blockquote data-width="500" data-dnt="true">
<p lang="en" dir="ltr">ICE agent asked why he's taking pictures of a legal observer's car, replies: "Cuz we have a nice little database and now you're considered a domestic terrorist. So have fun with that." <a href="https://t.co/IbyRqycSc2">pic.twitter.com/IbyRqycSc2</a></p>
<p>— Ken Klippenstein (NSPM-7 Compliant) (@kenklippenstein) <a href="https://twitter.com/kenklippenstein/status/2014752856843161969?ref_src=twsrc%5Etfw">January 23, 2026</a></p></blockquote>

<p><span>The video is the latest example of the Department of Homeland Security (DHS) labeling anyone who engages in First Amendment–protected activity opposing the Trump administration's mass deportation program as a "domestic terrorist" and suggesting they'll be subject to federal investigations.</span></p>
<p>However, Tricia McLaughlin, DHS assistant secretary for public affairs, denied such a database exists.</p>
<p>"There is NO database of 'domestic terrorists' run by DHS." McLaughlin said in an emailed statement to <em>Reason</em>. "We do of course monitor and investigate and refer all threats, assaults and obstruction of our officers to the appropriate law enforcement. Obstructing and assaulting law enforcement is a felony and a federal crime."</p>
<p>DHS has issued <a href="https://reason.com/2025/10/22/homeland-security-wont-stop-lying-about-who-immigration-enforcers-are-arresting/">numerous factually incorrect statements</a> attributed to McLaughlin.</p>
<p>Independent journalist Ken Klippenstein <a href="https://www.kenklippenstein.com/p/ice-making-list-of-anyone-who-films">reported</a> today that an unnamed federal law enforcement official told him that DHS "has ordered immigration officers to gather identifying information about anyone filming them."</p>
<p><span>In September, President Donald Trump issued a </span><a href="https://www.whitehouse.gov/presidential-actions/2025/09/countering-domestic-terrorism-and-organized-political-violence/"><span>memo</span></a><span> ordering federal law enforcement to focus on ideologies that are allegedly fueling "domestic terrorism." These include "anti-Americanism, anti-capitalism, and anti-Christianity; support for the overthrow of the United States Government; extremism on migration, race, and gender," as well as opposition to "foundational American principles (e.g., support for law enforcement and border control)."</span></p>
<p><span>As </span><i><span>Reason</span></i><span>'s Joe Lancaster </span><a href="https://reason.com/2025/09/29/trumps-executive-order-against-political-violence-is-an-un-american-attack-on-free-speech/"><span>wrote</span></a> at the time<span>, the memo was "an assault on the First Amendment" that listed protected free speech "as evidence of criminality that requires federal intervention."</span></p>
<p><span>And since the Trump administration's deportation campaign began last year, DHS officials have </span><a href="https://reason.com/2025/12/22/dhs-says-recording-or-following-law-enforcement-sure-sounds-like-obstruction-of-justice/"><span>repeatedly insisted</span></a><span> that following and recording federal immigration agents in public is a violation of a federal statute that makes it a crime to assault or impede law enforcement officers.</span></p>
<p><span>There have been dozens of recorded instances of ICE and Border Patrol officers </span><a href="https://reason.com/2026/01/12/video-shows-border-patrol-threaten-legal-observer-in-key-largo-for-following-him/"><span>harassing</span></a><span>, assaulting, and </span><a href="https://www.oregonlive.com/politics/2025/11/ice-detains-us-citizen-for-7-hours-after-she-photographed-agents-in-gresham.html"><span>detaining</span></a><span> people for filming and following them, even though there is a </span><a href="https://reason.com/2026/01/08/you-have-the-right-to-record-ice/"><span>well-established First Amendment right</span></a><span> to record and observe the police.</span></p>
<p><span>For example, today </span><i><span>Slate </span></i><span>published the </span><a href="https://slate.com/news-and-politics/2026/01/arrested-for-observing-ice-minnesota-lesson.html?utm_sf_post_ref=657901374&amp;utm_sf_cserv_ref=did%3Aplc%3Awwiikm77cjmgpjn7i7iao43p&amp;via=rss_socialflow_facebook"><span>first-person account</span></a><span> of Brandon Sigüenza, a Minneapolis man who was volunteering with a local group that monitors and records ICE activity. Federal immigration officers surrounded his car, smashed out his windows, roughly arrested him, and detained him for hours.</span></p>
<p><span>Sigüenza also submitted a </span><a href="https://storage.courtlistener.com/recap/gov.uscourts.mnd.229758/gov.uscourts.mnd.229758.99.0.pdf"><span>sworn declaration</span></a><span> describing his experiences in a civil rights lawsuit challenging the DHS' actions in Minneapolis. </span></p>
<p><span>Last week, the federal judge in that lawsuit </span><a href="https://storage.courtlistener.com/recap/gov.uscourts.mnd.229758/gov.uscourts.mnd.229758.85.0_1.pdf"><span>ruled</span></a><span> that the plaintiffs were likely to succeed on their claims that federal officers engaged in targeted First Amendment retaliation against them. The protesters' and monitors' actions, the judge found, "did not forcibly obstruct or impede the agents' work."</span></p>
<p><em>Reason</em> has argued through both Republican and Democratic administrations that government fears of "domestic terrorism" are a <a href="https://reason.com/2021/09/22/domestic-terrorism-fears-will-be-used-to-justify-increased-snooping-and-harassment/">pretext for increased snooping and harassment</a>. and comments like the ones by the ICE agent in Maine are only more evidence in favor of that argument.</p>
						</div>
		
</article>

					<nav>
	
		<p>
        <a href="https://reason.com/2026/01/23/the-trump-administration-plans-to-deport-iranians-amid-deadly-crackdown-in-iran/" data-ga-click="true" data-ga-action="Next Article Click" data-ga-label="The Trump Administration Plans To Deport Iranians Amid Deadly Crackdown in Iran"><span>NEXT:</span> The Trump Administration Plans To Deport Iranians Amid Deadly Crackdown in Iran</a>
    </p>
	
	<span><a rel="tag" href="https://reason.com/tag/ice/">ICE</a><a rel="tag" href="https://reason.com/category/civil-liberties/free-speech/">Free Speech</a><a rel="tag" href="https://reason.com/tag/first-amendment/">First Amendment</a><a rel="tag" href="https://reason.com/category/immigration/">Immigration</a><a rel="tag" href="https://reason.com/tag/trump-administration/">Trump Administration</a><a rel="tag" href="https://reason.com/tag/maine/">Maine</a><a rel="tag" href="https://reason.com/category/criminal-justice/police-brutality/">Police Abuse</a><a rel="tag" href="https://reason.com/category/civil-liberties/">Civil Liberties</a><a rel="tag" href="https://reason.com/category/civil-liberties/domestic-spying/">Domestic spying</a><a rel="tag" href="https://reason.com/category/criminal-justice/law-enforcement/">Law enforcement</a><a rel="tag" href="https://reason.com/category/civil-liberties/surveillance/">Surveillance</a></span>			
				
	</nav>
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft suspects some PCs might not boot after Windows 11 January 2026 Update (110 pts)]]></title>
            <link>https://www.windowslatest.com/2026/01/25/microsoft-suspects-some-pcs-might-not-boot-after-windows-11-january-2026-update-kb5074109/</link>
            <guid>46761061</guid>
            <pubDate>Mon, 26 Jan 2026 02:15:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windowslatest.com/2026/01/25/microsoft-suspects-some-pcs-might-not-boot-after-windows-11-january-2026-update-kb5074109/">https://www.windowslatest.com/2026/01/25/microsoft-suspects-some-pcs-might-not-boot-after-windows-11-january-2026-update-kb5074109/</a>, See on <a href="https://news.ycombinator.com/item?id=46761061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><a href="https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11.jpg" data-caption=""><img width="696" height="362" src="https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-696x362.jpg" srcset="https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-696x362.jpg 696w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-300x156.jpg 300w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-1024x533.jpg 1024w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-768x399.jpg 768w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-1536x799.jpg 1536w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-1068x555.jpg 1068w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11-808x420.jpg 808w, https://www.windowslatest.com/wp-content/uploads/2026/01/PCs-not-booting-with-black-screen-on-Windows-11.jpg 1619w" sizes="(max-width: 696px) 100vw, 696px" alt="PCs not booting with black screen on Windows 11" title="PCs not booting with black screen on Windows 11"></a></p>
            <p>Microsoft is aware of an alleged issue that leaves PCs unable to boot and requires manual recovery after installing the Windows 11 January 2026 Update.</p>
<p>Microsoft doesn’t know how the January 2026 Update broke some PCs and is collecting data from consumers and IT admins. For now, you don’t have to uninstall the update, as the issue is “limited” to specific PCs. The <a href="https://www.windowslatest.com/2026/01/17/windows-11-kb5074109-issues-black-screen-freezes-outlook-pop-breaks-azure-virtual-desktop-localizedresourcename-desktop-ini/">same update also broke Outlook Classic, customization in File Explorer</a>, <a href="https://www.windowslatest.com/2026/01/21/2026s-first-windows-11-update-is-causing-more-problems-now-as-microsoft-enters-damage-control-mode/">sleep mode (S3), Citrix Director</a>, and Remote Desktop.</p>
<p>“Microsoft has received a limited number of reports of an issue in which devices are failing to boot,” Microsoft noted in a <a href="https://admin.cloud.microsoft/Adminportal/Home?source=applauncher#/windowsreleasehealth/:/issue/WI1221934" target="_blank" rel="noopener">support document</a> first spotted by Windows Latest.</p>
<p>It’s unclear how many users are affected, but Microsoft has listed two affected platforms on the Windows release dashboard:</p>
<ul>
<li>KB5074109 – Windows 11 25H2</li>
<li>KB5074109 – Windows 11 24H2</li>
</ul>
<p>KB5074109 is a mandatory security update for Windows 11 25H2 / 24H2, and it patches as many as a hundred known security issues, which is why it’s installed automatically on PCs.</p>
<p><strong>Do I have the January 2026 Update?</strong> Open Settings &gt; System &gt; About &gt; Specification, and look at the build number. If it’s 26200.7623, you have the January update. KB5074109 was released on January 13, 2026.</p>
<p><img decoding="async" fetchpriority="high" src="https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number.jpg" alt="Windows 11 January 2026 Update build number" width="1366" height="1140" srcset="https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number.jpg 1366w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-300x250.jpg 300w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-1024x855.jpg 1024w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-768x641.jpg 768w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-696x581.jpg 696w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-1068x891.jpg 1068w, https://www.windowslatest.com/wp-content/uploads/2026/01/Windows-11-January-2026-Update-build-number-503x420.jpg 503w" sizes="(max-width: 1366px) 100vw, 1366px"></p>
<p>According to Microsoft, affected PCs could suddenly stop booting and land on the Black Screen of Death (BSOD) error with stop code UNMOUNTABLE_BOOT_VOLUME.</p>
<p><img decoding="async" src="https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard.jpg" alt="January 2026 Update issues dashboard" width="1500" height="1010" srcset="https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard.jpg 1500w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-300x202.jpg 300w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-1024x689.jpg 1024w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-768x517.jpg 768w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-696x469.jpg 696w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-1068x719.jpg 1068w, https://www.windowslatest.com/wp-content/uploads/2026/01/January-2026-Update-issues-dashboard-624x420.jpg 624w" sizes="(max-width: 1500px) 100vw, 1500px"></p>
<p>The UNMOUNTABLE_BOOT_VOLUME error (Stop Code 0xED) is typically related to system corruption, a damaged BIOS/boot, or hardware failure, specifically the drive. In this case, Microsoft suspects the problem is likely due to the Windows 11 January 2026 Update.</p>
<p>“Microsoft has received a limited number of reports of an issue in which devices are failing to boot with stop code ‘UNMOUNTABLE_BOOT_VOLUME’ after installing the January 2026 Windows security update (the originating KBs listed above), released January 13, 2026, and later updates,” Microsoft explained.</p>
<p>“Affected devices show a black screen with the message ‘Your device ran into a problem and needs a restart. You can restart.’ At this stage, the device cannot complete startup and requires manual recovery steps.”</p>
<p>In other words, if you end up hitting the above Black Screen of Death error, it will leave your computer unable to boot, and you’ll need to recover the installation. Windows Recovery is typically successful, but there are situations where WinRE does not work. In that case, you can use an ISO to clean install Windows.</p>
<p>“Reports received so far indicate that this issue is limited to physical devices only; no customers have reported observing these symptoms on virtual machines,” Microsoft warned in the support document.</p>
<p>The good news is that only a limited set of devices is affected. The bad news is that Microsoft doesn’t know how many users are affected or the details of the configuration causing the issue. The worst news is that the <a href="https://www.windowslatest.com/2026/01/17/windows-11-kb5074109-issues-black-screen-freezes-outlook-pop-breaks-azure-virtual-desktop-localizedresourcename-desktop-ini/">Windows 11 January 2026 Update is causing a bunch of other problems</a>, and <a href="https://www.windowslatest.com/2026/01/25/windows-11-kb5078127-emergency-update-25h2-fixes-outlook-pop-pst-crashes-unresponsive-apps-after-january-2026-patch-tuesday/">Microsoft has issued an emergency update (KB5078127)</a>.</p>
<p>If you don’t have issues, there’s nothing to worry about. There are billions of PCs running Windows, and most issues are limited to specific hardware. This might be one of those “limited” issues only, but if your PC is unable to boot or something feels odd over the last ten days, it’s likely due to Windows 11 KB5074109.</p>
<table>
<caption><strong>List of issues in the January 2026 Windows 11 update</strong><br>
Source: WindowsLatest.com</caption>
<tbody>
<tr>
<th>Issue detail</th>
<th>Current status</th>
<th>Workaround</th>
<th>Affected Windows version</th>
</tr>
<tr>
<td>Outlook Classic freezes.</td>
<td>Acknowledged by Microsoft</td>
<td>Fixed in out-of-band update (<a href="https://www.windowslatest.com/2026/01/25/windows-11-kb5078127-emergency-update-25h2-fixes-outlook-pop-pst-crashes-unresponsive-apps-after-january-2026-patch-tuesday/" target="_blank" rel="nofollow noopener">KB5078127</a>)</td>
<td>All supported versions of Windows</td>
</tr>
<tr>
<td>Third-party apps become unresponsive.</td>
<td>Acknowledged by Microsoft</td>
<td>Fixed in out-of-band update (<a href="https://www.windowslatest.com/2026/01/25/windows-11-kb5078127-emergency-update-25h2-fixes-outlook-pop-pst-crashes-unresponsive-apps-after-january-2026-patch-tuesday/" target="_blank" rel="nofollow noopener">KB5078127</a>)</td>
<td>All supported versions of Windows</td>
</tr>
<tr>
<td>Black screen or wallpaper resets.</td>
<td>Not officially acknowledged</td>
<td>Restart Windows or reapply wallpaper manually</td>
<td>Windows 11 25H2, 24H2</td>
</tr>
<tr>
<td>Sleep mode (S3) stops working on older PCs.</td>
<td>Not officially acknowledged</td>
<td>No reliable workaround available</td>
<td>Windows 11 24H2 / 25H2 on systems using S3 sleep</td>
</tr>
<tr>
<td>Desktop.ini broken in File Explorer.</td>
<td>Not officially acknowledged</td>
<td>No workaround; folders still function but UI is incorrect</td>
<td>Windows 11 25H2, 24H2</td>
</tr>
<tr>
<td>Citrix Remote Desktop not working</td>
<td>Acknowledged by Citrix</td>
<td>Remove the update or switch to alternatives</td>
<td>Windows 11 25H2, 24H2 and Windows Server 2025, 2022</td>
</tr>
<tr>
<td>Remote Desktop stops working.</td>
<td>Acknowledged by Microsoft</td>
<td>Fixed in first out-of-band update (KB5077744)</td>
<td>All supported versions of Windows</td>
</tr>
<tr>
<td>Shutdown feature does not work properly.</td>
<td>Acknowledged by Microsoft</td>
<td>Fixed with first out-of-band update (KB5077797)</td>
<td>23H2</td>
</tr>
<tr>
<td>System fails to boot</td>
<td>Acknowledged by Microsoft</td>
<td>Use Windows Recovery or reinstall Windows using an ISO</td>
<td>25H2 and 24H2</td>
</tr>
</tbody>
</table>
<p>What about you? Have you encountered critical issues after recent Windows Updates?</p>

        

        
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Over 36,500 killed in Iran's deadliest massacre, documents reveal (216 pts)]]></title>
            <link>https://www.iranintl.com/en/202601255198</link>
            <guid>46760329</guid>
            <pubDate>Mon, 26 Jan 2026 00:40:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iranintl.com/en/202601255198">https://www.iranintl.com/en/202601255198</a>, See on <a href="https://news.ycombinator.com/item?id=46760329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-article-id="ecb09193-d5e6-4189-862b-be6e1a000019" data-article-type="article" data-language="english" data-route="slug"><article data-has-sidebar="true" itemscope="" itemtype="https://schema.org/NewsArticle"><header><p><strong>EXCLUSIVE</strong></p><div><figure><picture><source media="(max-width:576px)" srcset="https://i.iranintl.com/images/rdk9umy0/production/7fe9c0347d121fb5b5779d874e9396c83820798a-992x661.jpg?w=576&amp;h=384&amp;q=80&amp;fit=max&amp;auto=format"><source media="(min-width:577px)" srcset="https://i.iranintl.com/images/rdk9umy0/production/7fe9c0347d121fb5b5779d874e9396c83820798a-992x661.jpg?w=992&amp;h=661&amp;q=80&amp;fit=max&amp;auto=format"><img alt="Men stand amid rows of corpses in a morgue in Tehran following mass killings of protestors by security forces in this undated image obtained by Iran International" width="576" height="384" decoding="async" src="https://i.iranintl.com/images/rdk9umy0/production/7fe9c0347d121fb5b5779d874e9396c83820798a-992x661.jpg?w=576&amp;h=384&amp;q=80&amp;fit=max&amp;auto=format"></picture><figcaption>Men stand amid rows of corpses in a morgue in Tehran following mass killings of protestors by security forces in this undated image obtained by Iran International</figcaption></figure></div></header><main><div data-article-id="202601255198"><p>More than 36,500 Iranians were killed by security forces during the January 8-9 crackdown on nationwide protests, making it the deadliest two-day protest massacre in history, according to documents reviewed by Iran International's Editorial Board.</p><!--$?--><template id="B:0"></template><!--/$--></div></main></article><section data-has-sidebar="true"><!--$?--><template id="B:2"></template><!--/$--></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Clawdbot - open source personal AI assistant (338 pts)]]></title>
            <link>https://github.com/clawdbot/clawdbot</link>
            <guid>46760237</guid>
            <pubDate>Mon, 26 Jan 2026 00:27:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/clawdbot/clawdbot">https://github.com/clawdbot/clawdbot</a>, See on <a href="https://news.ycombinator.com/item?id=46760237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🦞 Clawdbot — Personal AI Assistant</h2><a id="user-content--clawdbot--personal-ai-assistant" aria-label="Permalink: 🦞 Clawdbot — Personal AI Assistant" href="#-clawdbot--personal-ai-assistant"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/clawdbot/clawdbot/main/docs/whatsapp-clawd.jpg"><img src="https://raw.githubusercontent.com/clawdbot/clawdbot/main/docs/whatsapp-clawd.jpg" alt="Clawdbot" width="400"></a>
</p>
<p dir="auto">
  <strong>EXFOLIATE! EXFOLIATE!</strong>
</p>
<p dir="auto">
  <a href="https://github.com/clawdbot/clawdbot/actions/workflows/ci.yml?branch=main"><img src="https://camo.githubusercontent.com/f06ea1aedc0e97f16c729d06798c99496e5499ea85f718a7b8fc932f17f665db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f636c617764626f742f636c617764626f742f63692e796d6c3f6272616e63683d6d61696e267374796c653d666f722d7468652d6261646765" alt="CI status" data-canonical-src="https://img.shields.io/github/actions/workflow/status/clawdbot/clawdbot/ci.yml?branch=main&amp;style=for-the-badge"></a>
  <a href="https://github.com/clawdbot/clawdbot/releases"><img src="https://camo.githubusercontent.com/060be048edf5af08ddc2fe45747c912c9dcc335fa3d414f8b1e7337428fab6be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f636c617764626f742f636c617764626f743f696e636c7564655f70726572656c6561736573267374796c653d666f722d7468652d6261646765" alt="GitHub release" data-canonical-src="https://img.shields.io/github/v/release/clawdbot/clawdbot?include_prereleases&amp;style=for-the-badge"></a>
  <a href="https://deepwiki.com/clawdbot/clawdbot" rel="nofollow"><img src="https://camo.githubusercontent.com/d3a92051f744b2bcfd442894844b1975bece6b1dcf32f2e3b951a0e842145fc6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4465657057696b692d636c617764626f742d3131313131313f7374796c653d666f722d7468652d6261646765" alt="DeepWiki" data-canonical-src="https://img.shields.io/badge/DeepWiki-clawdbot-111111?style=for-the-badge"></a>
  <a href="https://discord.gg/clawd" rel="nofollow"><img src="https://camo.githubusercontent.com/1860c01c5ab9a20c37ea5a09fcf7ea1471eb95ed7095bb99d3c5a7331061ccda/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313435363335303036343036353930343836373f6c6162656c3d446973636f7264266c6f676f3d646973636f7264266c6f676f436f6c6f723d776869746526636f6c6f723d353836354632267374796c653d666f722d7468652d6261646765" alt="Discord" data-canonical-src="https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge"></a>
  <a href="https://github.com/clawdbot/clawdbot/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/608c8dfda488178950ce502d7697514db3a6a712579327ed90b9b594260f6355/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e7376673f7374796c653d666f722d7468652d6261646765" alt="MIT License" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge"></a>
</p>
<p dir="auto"><strong>Clawdbot</strong> is a <em>personal AI assistant</em> you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane — the product is the assistant.</p>
<p dir="auto">If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.</p>
<p dir="auto"><a href="https://clawdbot.com/" rel="nofollow">Website</a> · <a href="https://docs.clawd.bot/" rel="nofollow">Docs</a> · <a href="https://docs.clawd.bot/start/getting-started" rel="nofollow">Getting Started</a> · <a href="https://docs.clawd.bot/install/updating" rel="nofollow">Updating</a> · <a href="https://docs.clawd.bot/start/showcase" rel="nofollow">Showcase</a> · <a href="https://docs.clawd.bot/start/faq" rel="nofollow">FAQ</a> · <a href="https://docs.clawd.bot/start/wizard" rel="nofollow">Wizard</a> · <a href="https://github.com/clawdbot/nix-clawdbot">Nix</a> · <a href="https://docs.clawd.bot/install/docker" rel="nofollow">Docker</a> · <a href="https://discord.gg/clawd" rel="nofollow">Discord</a></p>
<p dir="auto">Preferred setup: run the onboarding wizard (<code>clawdbot onboard</code>). It walks through gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on <strong>macOS, Linux, and Windows (via WSL2; strongly recommended)</strong>.
Works with npm, pnpm, or bun.
New install? Start here: <a href="https://docs.clawd.bot/start/getting-started" rel="nofollow">Getting started</a></p>
<p dir="auto"><strong>Subscriptions (OAuth):</strong></p>
<ul dir="auto">
<li><strong><a href="https://www.anthropic.com/" rel="nofollow">Anthropic</a></strong> (Claude Pro/Max)</li>
<li><strong><a href="https://openai.com/" rel="nofollow">OpenAI</a></strong> (ChatGPT/Codex)</li>
</ul>
<p dir="auto">Model note: while any model is supported, I strongly recommend <strong>Anthropic Pro/Max (100/200) + Opus 4.5</strong> for long‑context strength and better prompt‑injection resistance. See <a href="https://docs.clawd.bot/start/onboarding" rel="nofollow">Onboarding</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models (selection + auth)</h2><a id="user-content-models-selection--auth" aria-label="Permalink: Models (selection + auth)" href="#models-selection--auth"></a></p>
<ul dir="auto">
<li>Models config + CLI: <a href="https://docs.clawd.bot/concepts/models" rel="nofollow">Models</a></li>
<li>Auth profile rotation (OAuth vs API keys) + fallbacks: <a href="https://docs.clawd.bot/concepts/model-failover" rel="nofollow">Model failover</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install (recommended)</h2><a id="user-content-install-recommended" aria-label="Permalink: Install (recommended)" href="#install-recommended"></a></p>
<p dir="auto">Runtime: <strong>Node ≥22</strong>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g clawdbot@latest
# or: pnpm add -g clawdbot@latest

clawdbot onboard --install-daemon"><pre>npm install -g clawdbot@latest
<span><span>#</span> or: pnpm add -g clawdbot@latest</span>

clawdbot onboard --install-daemon</pre></div>
<p dir="auto">The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start (TL;DR)</h2><a id="user-content-quick-start-tldr" aria-label="Permalink: Quick start (TL;DR)" href="#quick-start-tldr"></a></p>
<p dir="auto">Runtime: <strong>Node ≥22</strong>.</p>
<p dir="auto">Full beginner guide (auth, pairing, channels): <a href="https://docs.clawd.bot/start/getting-started" rel="nofollow">Getting started</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="clawdbot onboard --install-daemon

clawdbot gateway --port 18789 --verbose

# Send a message
clawdbot message send --to +1234567890 --message &quot;Hello from Clawdbot&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
clawdbot agent --message &quot;Ship checklist&quot; --thinking high"><pre>clawdbot onboard --install-daemon

clawdbot gateway --port 18789 --verbose

<span><span>#</span> Send a message</span>
clawdbot message send --to +1234567890 --message <span><span>"</span>Hello from Clawdbot<span>"</span></span>

<span><span>#</span> Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)</span>
clawdbot agent --message <span><span>"</span>Ship checklist<span>"</span></span> --thinking high</pre></div>
<p dir="auto">Upgrading? <a href="https://docs.clawd.bot/install/updating" rel="nofollow">Updating guide</a> (and run <code>clawdbot doctor</code>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development channels</h2><a id="user-content-development-channels" aria-label="Permalink: Development channels" href="#development-channels"></a></p>
<ul dir="auto">
<li><strong>stable</strong>: tagged releases (<code>vYYYY.M.D</code> or <code>vYYYY.M.D-&lt;patch&gt;</code>), npm dist-tag <code>latest</code>.</li>
<li><strong>beta</strong>: prerelease tags (<code>vYYYY.M.D-beta.N</code>), npm dist-tag <code>beta</code> (macOS app may be missing).</li>
<li><strong>dev</strong>: moving head of <code>main</code>, npm dist-tag <code>dev</code> (when published).</li>
</ul>
<p dir="auto">Switch channels (git + npm): <code>clawdbot update --channel stable|beta|dev</code>.
Details: <a href="https://docs.clawd.bot/install/development-channels" rel="nofollow">Development channels</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">From source (development)</h2><a id="user-content-from-source-development" aria-label="Permalink: From source (development)" href="#from-source-development"></a></p>
<p dir="auto">Prefer <code>pnpm</code> for builds from source. Bun is optional for running TypeScript directly.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/clawdbot/clawdbot.git
cd clawdbot

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm clawdbot onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch"><pre>git clone https://github.com/clawdbot/clawdbot.git
<span>cd</span> clawdbot

pnpm install
pnpm ui:build <span><span>#</span> auto-installs UI deps on first run</span>
pnpm build

pnpm clawdbot onboard --install-daemon

<span><span>#</span> Dev loop (auto-reload on TS changes)</span>
pnpm gateway:watch</pre></div>
<p dir="auto">Note: <code>pnpm clawdbot ...</code> runs TypeScript directly (via <code>tsx</code>). <code>pnpm build</code> produces <code>dist/</code> for running via Node / the packaged <code>clawdbot</code> binary.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security defaults (DM access)</h2><a id="user-content-security-defaults-dm-access" aria-label="Permalink: Security defaults (DM access)" href="#security-defaults-dm-access"></a></p>
<p dir="auto">Clawdbot connects to real messaging surfaces. Treat inbound DMs as <strong>untrusted input</strong>.</p>
<p dir="auto">Full security guide: <a href="https://docs.clawd.bot/gateway/security" rel="nofollow">Security</a></p>
<p dir="auto">Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:</p>
<ul dir="auto">
<li><strong>DM pairing</strong> (<code>dmPolicy="pairing"</code> / <code>channels.discord.dm.policy="pairing"</code> / <code>channels.slack.dm.policy="pairing"</code>): unknown senders receive a short pairing code and the bot does not process their message.</li>
<li>Approve with: <code>clawdbot pairing approve &lt;channel&gt; &lt;code&gt;</code> (then the sender is added to a local allowlist store).</li>
<li>Public inbound DMs require an explicit opt-in: set <code>dmPolicy="open"</code> and include <code>"*"</code> in the channel allowlist (<code>allowFrom</code> / <code>channels.discord.dm.allowFrom</code> / <code>channels.slack.dm.allowFrom</code>).</li>
</ul>
<p dir="auto">Run <code>clawdbot doctor</code> to surface risky/misconfigured DM policies.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlights</h2><a id="user-content-highlights" aria-label="Permalink: Highlights" href="#highlights"></a></p>
<ul dir="auto">
<li><strong><a href="https://docs.clawd.bot/gateway" rel="nofollow">Local-first Gateway</a></strong> — single control plane for sessions, channels, tools, and events.</li>
<li><strong><a href="https://docs.clawd.bot/channels" rel="nofollow">Multi-channel inbox</a></strong> — WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, BlueBubbles, Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.</li>
<li><strong><a href="https://docs.clawd.bot/gateway/configuration" rel="nofollow">Multi-agent routing</a></strong> — route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).</li>
<li><strong><a href="https://docs.clawd.bot/nodes/voicewake" rel="nofollow">Voice Wake</a> + <a href="https://docs.clawd.bot/nodes/talk" rel="nofollow">Talk Mode</a></strong> — always-on speech for macOS/iOS/Android with ElevenLabs.</li>
<li><strong><a href="https://docs.clawd.bot/platforms/mac/canvas" rel="nofollow">Live Canvas</a></strong> — agent-driven visual workspace with <a href="https://docs.clawd.bot/platforms/mac/canvas#canvas-a2ui" rel="nofollow">A2UI</a>.</li>
<li><strong><a href="https://docs.clawd.bot/tools" rel="nofollow">First-class tools</a></strong> — browser, canvas, nodes, cron, sessions, and Discord/Slack actions.</li>
<li><strong><a href="https://docs.clawd.bot/platforms/macos" rel="nofollow">Companion apps</a></strong> — macOS menu bar app + iOS/Android <a href="https://docs.clawd.bot/nodes" rel="nofollow">nodes</a>.</li>
<li><strong><a href="https://docs.clawd.bot/start/wizard" rel="nofollow">Onboarding</a> + <a href="https://docs.clawd.bot/tools/skills" rel="nofollow">skills</a></strong> — wizard-driven setup with bundled/managed/workspace skills.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://www.star-history.com/#clawdbot/clawdbot&amp;type=date&amp;legend=top-left" rel="nofollow"><img src="https://camo.githubusercontent.com/8474500e383a32aae6d1f5f678b4ea353b83f815af7fde054006cf59f295ff68/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636c617764626f742f636c617764626f7426747970653d64617465266c6567656e643d746f702d6c656674" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=clawdbot/clawdbot&amp;type=date&amp;legend=top-left"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Everything we built so far</h2><a id="user-content-everything-we-built-so-far" aria-label="Permalink: Everything we built so far" href="#everything-we-built-so-far"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core platform</h3><a id="user-content-core-platform" aria-label="Permalink: Core platform" href="#core-platform"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/gateway" rel="nofollow">Gateway WS control plane</a> with sessions, presence, config, cron, webhooks, <a href="https://docs.clawd.bot/web" rel="nofollow">Control UI</a>, and <a href="https://docs.clawd.bot/platforms/mac/canvas#canvas-a2ui" rel="nofollow">Canvas host</a>.</li>
<li><a href="https://docs.clawd.bot/tools/agent-send" rel="nofollow">CLI surface</a>: gateway, agent, send, <a href="https://docs.clawd.bot/start/wizard" rel="nofollow">wizard</a>, and <a href="https://docs.clawd.bot/gateway/doctor" rel="nofollow">doctor</a>.</li>
<li><a href="https://docs.clawd.bot/concepts/agent" rel="nofollow">Pi agent runtime</a> in RPC mode with tool streaming and block streaming.</li>
<li><a href="https://docs.clawd.bot/concepts/session" rel="nofollow">Session model</a>: <code>main</code> for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: <a href="https://docs.clawd.bot/concepts/groups" rel="nofollow">Groups</a>.</li>
<li><a href="https://docs.clawd.bot/nodes/images" rel="nofollow">Media pipeline</a>: images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: <a href="https://docs.clawd.bot/nodes/audio" rel="nofollow">Audio</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Channels</h3><a id="user-content-channels" aria-label="Permalink: Channels" href="#channels"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/channels" rel="nofollow">Channels</a>: <a href="https://docs.clawd.bot/channels/whatsapp" rel="nofollow">WhatsApp</a> (Baileys), <a href="https://docs.clawd.bot/channels/telegram" rel="nofollow">Telegram</a> (grammY), <a href="https://docs.clawd.bot/channels/slack" rel="nofollow">Slack</a> (Bolt), <a href="https://docs.clawd.bot/channels/discord" rel="nofollow">Discord</a> (discord.js), <a href="https://docs.clawd.bot/channels/googlechat" rel="nofollow">Google Chat</a> (Chat API), <a href="https://docs.clawd.bot/channels/signal" rel="nofollow">Signal</a> (signal-cli), <a href="https://docs.clawd.bot/channels/imessage" rel="nofollow">iMessage</a> (imsg), <a href="https://docs.clawd.bot/channels/bluebubbles" rel="nofollow">BlueBubbles</a> (extension), <a href="https://docs.clawd.bot/channels/msteams" rel="nofollow">Microsoft Teams</a> (extension), <a href="https://docs.clawd.bot/channels/matrix" rel="nofollow">Matrix</a> (extension), <a href="https://docs.clawd.bot/channels/zalo" rel="nofollow">Zalo</a> (extension), <a href="https://docs.clawd.bot/channels/zalouser" rel="nofollow">Zalo Personal</a> (extension), <a href="https://docs.clawd.bot/web/webchat" rel="nofollow">WebChat</a>.</li>
<li><a href="https://docs.clawd.bot/concepts/group-messages" rel="nofollow">Group routing</a>: mention gating, reply tags, per-channel chunking and routing. Channel rules: <a href="https://docs.clawd.bot/channels" rel="nofollow">Channels</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Apps + nodes</h3><a id="user-content-apps--nodes" aria-label="Permalink: Apps + nodes" href="#apps--nodes"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/platforms/macos" rel="nofollow">macOS app</a>: menu bar control plane, <a href="https://docs.clawd.bot/nodes/voicewake" rel="nofollow">Voice Wake</a>/PTT, <a href="https://docs.clawd.bot/nodes/talk" rel="nofollow">Talk Mode</a> overlay, <a href="https://docs.clawd.bot/web/webchat" rel="nofollow">WebChat</a>, debug tools, <a href="https://docs.clawd.bot/gateway/remote" rel="nofollow">remote gateway</a> control.</li>
<li><a href="https://docs.clawd.bot/platforms/ios" rel="nofollow">iOS node</a>: <a href="https://docs.clawd.bot/platforms/mac/canvas" rel="nofollow">Canvas</a>, <a href="https://docs.clawd.bot/nodes/voicewake" rel="nofollow">Voice Wake</a>, <a href="https://docs.clawd.bot/nodes/talk" rel="nofollow">Talk Mode</a>, camera, screen recording, Bonjour pairing.</li>
<li><a href="https://docs.clawd.bot/platforms/android" rel="nofollow">Android node</a>: <a href="https://docs.clawd.bot/platforms/mac/canvas" rel="nofollow">Canvas</a>, <a href="https://docs.clawd.bot/nodes/talk" rel="nofollow">Talk Mode</a>, camera, screen recording, optional SMS.</li>
<li><a href="https://docs.clawd.bot/nodes" rel="nofollow">macOS node mode</a>: system.run/notify + canvas/camera exposure.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tools + automation</h3><a id="user-content-tools--automation" aria-label="Permalink: Tools + automation" href="#tools--automation"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/tools/browser" rel="nofollow">Browser control</a>: dedicated clawd Chrome/Chromium, snapshots, actions, uploads, profiles.</li>
<li><a href="https://docs.clawd.bot/platforms/mac/canvas" rel="nofollow">Canvas</a>: <a href="https://docs.clawd.bot/platforms/mac/canvas#canvas-a2ui" rel="nofollow">A2UI</a> push/reset, eval, snapshot.</li>
<li><a href="https://docs.clawd.bot/nodes" rel="nofollow">Nodes</a>: camera snap/clip, screen record, <a href="https://docs.clawd.bot/nodes/location-command" rel="nofollow">location.get</a>, notifications.</li>
<li><a href="https://docs.clawd.bot/automation/cron-jobs" rel="nofollow">Cron + wakeups</a>; <a href="https://docs.clawd.bot/automation/webhook" rel="nofollow">webhooks</a>; <a href="https://docs.clawd.bot/automation/gmail-pubsub" rel="nofollow">Gmail Pub/Sub</a>.</li>
<li><a href="https://docs.clawd.bot/tools/skills" rel="nofollow">Skills platform</a>: bundled, managed, and workspace skills with install gating + UI.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Runtime + safety</h3><a id="user-content-runtime--safety" aria-label="Permalink: Runtime + safety" href="#runtime--safety"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/concepts/channel-routing" rel="nofollow">Channel routing</a>, <a href="https://docs.clawd.bot/concepts/retry" rel="nofollow">retry policy</a>, and <a href="https://docs.clawd.bot/concepts/streaming" rel="nofollow">streaming/chunking</a>.</li>
<li><a href="https://docs.clawd.bot/concepts/presence" rel="nofollow">Presence</a>, <a href="https://docs.clawd.bot/concepts/typing-indicators" rel="nofollow">typing indicators</a>, and <a href="https://docs.clawd.bot/concepts/usage-tracking" rel="nofollow">usage tracking</a>.</li>
<li><a href="https://docs.clawd.bot/concepts/models" rel="nofollow">Models</a>, <a href="https://docs.clawd.bot/concepts/model-failover" rel="nofollow">model failover</a>, and <a href="https://docs.clawd.bot/concepts/session-pruning" rel="nofollow">session pruning</a>.</li>
<li><a href="https://docs.clawd.bot/gateway/security" rel="nofollow">Security</a> and <a href="https://docs.clawd.bot/channels/troubleshooting" rel="nofollow">troubleshooting</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ops + packaging</h3><a id="user-content-ops--packaging" aria-label="Permalink: Ops + packaging" href="#ops--packaging"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/web" rel="nofollow">Control UI</a> + <a href="https://docs.clawd.bot/web/webchat" rel="nofollow">WebChat</a> served directly from the Gateway.</li>
<li><a href="https://docs.clawd.bot/gateway/tailscale" rel="nofollow">Tailscale Serve/Funnel</a> or <a href="https://docs.clawd.bot/gateway/remote" rel="nofollow">SSH tunnels</a> with token/password auth.</li>
<li><a href="https://docs.clawd.bot/install/nix" rel="nofollow">Nix mode</a> for declarative config; <a href="https://docs.clawd.bot/install/docker" rel="nofollow">Docker</a>-based installs.</li>
<li><a href="https://docs.clawd.bot/gateway/doctor" rel="nofollow">Doctor</a> migrations, <a href="https://docs.clawd.bot/logging" rel="nofollow">logging</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works (short)</h2><a id="user-content-how-it-works-short" aria-label="Permalink: How it works (short)" href="#how-it-works-short"></a></p>
<div data-snippet-clipboard-copy-content="WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               │
               ▼
┌───────────────────────────────┐
│            Gateway            │
│       (control plane)         │
│     ws://127.0.0.1:18789      │
└──────────────┬────────────────┘
               │
               ├─ Pi agent (RPC)
               ├─ CLI (clawdbot …)
               ├─ WebChat UI
               ├─ macOS app
               └─ iOS / Android nodes"><pre><code>WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               │
               ▼
┌───────────────────────────────┐
│            Gateway            │
│       (control plane)         │
│     ws://127.0.0.1:18789      │
└──────────────┬────────────────┘
               │
               ├─ Pi agent (RPC)
               ├─ CLI (clawdbot …)
               ├─ WebChat UI
               ├─ macOS app
               └─ iOS / Android nodes
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key subsystems</h2><a id="user-content-key-subsystems" aria-label="Permalink: Key subsystems" href="#key-subsystems"></a></p>
<ul dir="auto">
<li><strong><a href="https://docs.clawd.bot/concepts/architecture" rel="nofollow">Gateway WebSocket network</a></strong> — single WS control plane for clients, tools, and events (plus ops: <a href="https://docs.clawd.bot/gateway" rel="nofollow">Gateway runbook</a>).</li>
<li><strong><a href="https://docs.clawd.bot/gateway/tailscale" rel="nofollow">Tailscale exposure</a></strong> — Serve/Funnel for the Gateway dashboard + WS (remote access: <a href="https://docs.clawd.bot/gateway/remote" rel="nofollow">Remote</a>).</li>
<li><strong><a href="https://docs.clawd.bot/tools/browser" rel="nofollow">Browser control</a></strong> — clawd‑managed Chrome/Chromium with CDP control.</li>
<li><strong><a href="https://docs.clawd.bot/platforms/mac/canvas" rel="nofollow">Canvas + A2UI</a></strong> — agent‑driven visual workspace (A2UI host: <a href="https://docs.clawd.bot/platforms/mac/canvas#canvas-a2ui" rel="nofollow">Canvas/A2UI</a>).</li>
<li><strong><a href="https://docs.clawd.bot/nodes/voicewake" rel="nofollow">Voice Wake</a> + <a href="https://docs.clawd.bot/nodes/talk" rel="nofollow">Talk Mode</a></strong> — always‑on speech and continuous conversation.</li>
<li><strong><a href="https://docs.clawd.bot/nodes" rel="nofollow">Nodes</a></strong> — Canvas, camera snap/clip, screen record, <code>location.get</code>, notifications, plus macOS‑only <code>system.run</code>/<code>system.notify</code>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tailscale access (Gateway dashboard)</h2><a id="user-content-tailscale-access-gateway-dashboard" aria-label="Permalink: Tailscale access (Gateway dashboard)" href="#tailscale-access-gateway-dashboard"></a></p>
<p dir="auto">Clawdbot can auto-configure Tailscale <strong>Serve</strong> (tailnet-only) or <strong>Funnel</strong> (public) while the Gateway stays bound to loopback. Configure <code>gateway.tailscale.mode</code>:</p>
<ul dir="auto">
<li><code>off</code>: no Tailscale automation (default).</li>
<li><code>serve</code>: tailnet-only HTTPS via <code>tailscale serve</code> (uses Tailscale identity headers by default).</li>
<li><code>funnel</code>: public HTTPS via <code>tailscale funnel</code> (requires shared password auth).</li>
</ul>
<p dir="auto">Notes:</p>
<ul dir="auto">
<li><code>gateway.bind</code> must stay <code>loopback</code> when Serve/Funnel is enabled (Clawdbot enforces this).</li>
<li>Serve can be forced to require a password by setting <code>gateway.auth.mode: "password"</code> or <code>gateway.auth.allowTailscale: false</code>.</li>
<li>Funnel refuses to start unless <code>gateway.auth.mode: "password"</code> is set.</li>
<li>Optional: <code>gateway.tailscale.resetOnExit</code> to undo Serve/Funnel on shutdown.</li>
</ul>
<p dir="auto">Details: <a href="https://docs.clawd.bot/gateway/tailscale" rel="nofollow">Tailscale guide</a> · <a href="https://docs.clawd.bot/web" rel="nofollow">Web surfaces</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Remote Gateway (Linux is great)</h2><a id="user-content-remote-gateway-linux-is-great" aria-label="Permalink: Remote Gateway (Linux is great)" href="#remote-gateway-linux-is-great"></a></p>
<p dir="auto">It’s perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over <strong>Tailscale Serve/Funnel</strong> or <strong>SSH tunnels</strong>, and you can still pair device nodes (macOS/iOS/Android) to execute device‑local actions when needed.</p>
<ul dir="auto">
<li><strong>Gateway host</strong> runs the exec tool and channel connections by default.</li>
<li><strong>Device nodes</strong> run device‑local actions (<code>system.run</code>, camera, screen recording, notifications) via <code>node.invoke</code>.
In short: exec runs where the Gateway lives; device actions run where the device lives.</li>
</ul>
<p dir="auto">Details: <a href="https://docs.clawd.bot/gateway/remote" rel="nofollow">Remote access</a> · <a href="https://docs.clawd.bot/nodes" rel="nofollow">Nodes</a> · <a href="https://docs.clawd.bot/gateway/security" rel="nofollow">Security</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">macOS permissions via the Gateway protocol</h2><a id="user-content-macos-permissions-via-the-gateway-protocol" aria-label="Permalink: macOS permissions via the Gateway protocol" href="#macos-permissions-via-the-gateway-protocol"></a></p>
<p dir="auto">The macOS app can run in <strong>node mode</strong> and advertises its capabilities + permission map over the Gateway WebSocket (<code>node.list</code> / <code>node.describe</code>). Clients can then execute local actions via <code>node.invoke</code>:</p>
<ul dir="auto">
<li><code>system.run</code> runs a local command and returns stdout/stderr/exit code; set <code>needsScreenRecording: true</code> to require screen-recording permission (otherwise you’ll get <code>PERMISSION_MISSING</code>).</li>
<li><code>system.notify</code> posts a user notification and fails if notifications are denied.</li>
<li><code>canvas.*</code>, <code>camera.*</code>, <code>screen.record</code>, and <code>location.get</code> are also routed via <code>node.invoke</code> and follow TCC permission status.</li>
</ul>
<p dir="auto">Elevated bash (host permissions) is separate from macOS TCC:</p>
<ul dir="auto">
<li>Use <code>/elevated on|off</code> to toggle per‑session elevated access when enabled + allowlisted.</li>
<li>Gateway persists the per‑session toggle via <code>sessions.patch</code> (WS method) alongside <code>thinkingLevel</code>, <code>verboseLevel</code>, <code>model</code>, <code>sendPolicy</code>, and <code>groupActivation</code>.</li>
</ul>
<p dir="auto">Details: <a href="https://docs.clawd.bot/nodes" rel="nofollow">Nodes</a> · <a href="https://docs.clawd.bot/platforms/macos" rel="nofollow">macOS app</a> · <a href="https://docs.clawd.bot/concepts/architecture" rel="nofollow">Gateway protocol</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Agent to Agent (sessions_* tools)</h2><a id="user-content-agent-to-agent-sessions_-tools" aria-label="Permalink: Agent to Agent (sessions_* tools)" href="#agent-to-agent-sessions_-tools"></a></p>
<ul dir="auto">
<li>Use these to coordinate work across sessions without jumping between chat surfaces.</li>
<li><code>sessions_list</code> — discover active sessions (agents) and their metadata.</li>
<li><code>sessions_history</code> — fetch transcript logs for a session.</li>
<li><code>sessions_send</code> — message another session; optional reply‑back ping‑pong + announce step (<code>REPLY_SKIP</code>, <code>ANNOUNCE_SKIP</code>).</li>
</ul>
<p dir="auto">Details: <a href="https://docs.clawd.bot/concepts/session-tool" rel="nofollow">Session tools</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Skills registry (ClawdHub)</h2><a id="user-content-skills-registry-clawdhub" aria-label="Permalink: Skills registry (ClawdHub)" href="#skills-registry-clawdhub"></a></p>
<p dir="auto">ClawdHub is a minimal skill registry. With ClawdHub enabled, the agent can search for skills automatically and pull in new ones as needed.</p>
<p dir="auto"><a href="https://clawdhub.com/" rel="nofollow">ClawdHub</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Chat commands</h2><a id="user-content-chat-commands" aria-label="Permalink: Chat commands" href="#chat-commands"></a></p>
<p dir="auto">Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):</p>
<ul dir="auto">
<li><code>/status</code> — compact session status (model + tokens, cost when available)</li>
<li><code>/new</code> or <code>/reset</code> — reset the session</li>
<li><code>/compact</code> — compact session context (summary)</li>
<li><code>/think &lt;level&gt;</code> — off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)</li>
<li><code>/verbose on|off</code></li>
<li><code>/usage off|tokens|full</code> — per-response usage footer</li>
<li><code>/restart</code> — restart the gateway (owner-only in groups)</li>
<li><code>/activation mention|always</code> — group activation toggle (groups only)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Apps (optional)</h2><a id="user-content-apps-optional" aria-label="Permalink: Apps (optional)" href="#apps-optional"></a></p>
<p dir="auto">The Gateway alone delivers a great experience. All apps are optional and add extra features.</p>
<p dir="auto">If you plan to build/run companion apps, follow the platform runbooks below.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS (Clawdbot.app) (optional)</h3><a id="user-content-macos-clawdbotapp-optional" aria-label="Permalink: macOS (Clawdbot.app) (optional)" href="#macos-clawdbotapp-optional"></a></p>
<ul dir="auto">
<li>Menu bar control for the Gateway and health.</li>
<li>Voice Wake + push-to-talk overlay.</li>
<li>WebChat + debug tools.</li>
<li>Remote gateway control over SSH.</li>
</ul>
<p dir="auto">Note: signed builds required for macOS permissions to stick across rebuilds (see <code>docs/mac/permissions.md</code>).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">iOS node (optional)</h3><a id="user-content-ios-node-optional" aria-label="Permalink: iOS node (optional)" href="#ios-node-optional"></a></p>
<ul dir="auto">
<li>Pairs as a node via the Bridge.</li>
<li>Voice trigger forwarding + Canvas surface.</li>
<li>Controlled via <code>clawdbot nodes …</code>.</li>
</ul>
<p dir="auto">Runbook: <a href="https://docs.clawd.bot/platforms/ios" rel="nofollow">iOS connect</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Android node (optional)</h3><a id="user-content-android-node-optional" aria-label="Permalink: Android node (optional)" href="#android-node-optional"></a></p>
<ul dir="auto">
<li>Pairs via the same Bridge + pairing flow as iOS.</li>
<li>Exposes Canvas, Camera, and Screen capture commands.</li>
<li>Runbook: <a href="https://docs.clawd.bot/platforms/android" rel="nofollow">Android connect</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Agent workspace + skills</h2><a id="user-content-agent-workspace--skills" aria-label="Permalink: Agent workspace + skills" href="#agent-workspace--skills"></a></p>
<ul dir="auto">
<li>Workspace root: <code>~/clawd</code> (configurable via <code>agents.defaults.workspace</code>).</li>
<li>Injected prompt files: <code>AGENTS.md</code>, <code>SOUL.md</code>, <code>TOOLS.md</code>.</li>
<li>Skills: <code>~/clawd/skills/&lt;skill&gt;/SKILL.md</code>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Minimal <code>~/.clawdbot/clawdbot.json</code> (model + defaults):</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  agent: {
    model: &quot;anthropic/claude-opus-4-5&quot;
  }
}"><pre><span>{</span>
  <span>agent</span>: <span>{</span>
    <span>model</span>: <span>"anthropic/claude-opus-4-5"</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><a href="https://docs.clawd.bot/gateway/configuration" rel="nofollow">Full configuration reference (all keys + examples).</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security model (important)</h2><a id="user-content-security-model-important" aria-label="Permalink: Security model (important)" href="#security-model-important"></a></p>
<ul dir="auto">
<li><strong>Default:</strong> tools run on the host for the <strong>main</strong> session, so the agent has full access when it’s just you.</li>
<li><strong>Group/channel safety:</strong> set <code>agents.defaults.sandbox.mode: "non-main"</code> to run <strong>non‑main sessions</strong> (groups/channels) inside per‑session Docker sandboxes; bash then runs in Docker for those sessions.</li>
<li><strong>Sandbox defaults:</strong> allowlist <code>bash</code>, <code>process</code>, <code>read</code>, <code>write</code>, <code>edit</code>, <code>sessions_list</code>, <code>sessions_history</code>, <code>sessions_send</code>, <code>sessions_spawn</code>; denylist <code>browser</code>, <code>canvas</code>, <code>nodes</code>, <code>cron</code>, <code>discord</code>, <code>gateway</code>.</li>
</ul>
<p dir="auto">Details: <a href="https://docs.clawd.bot/gateway/security" rel="nofollow">Security guide</a> · <a href="https://docs.clawd.bot/install/docker" rel="nofollow">Docker + sandboxing</a> · <a href="https://docs.clawd.bot/gateway/configuration" rel="nofollow">Sandbox config</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/whatsapp" rel="nofollow">WhatsApp</a></h3><a id="user-content-whatsapp" aria-label="Permalink: WhatsApp" href="#whatsapp"></a></p>
<ul dir="auto">
<li>Link the device: <code>pnpm clawdbot channels login</code> (stores creds in <code>~/.clawdbot/credentials</code>).</li>
<li>Allowlist who can talk to the assistant via <code>channels.whatsapp.allowFrom</code>.</li>
<li>If <code>channels.whatsapp.groups</code> is set, it becomes a group allowlist; include <code>"*"</code> to allow all.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/telegram" rel="nofollow">Telegram</a></h3><a id="user-content-telegram" aria-label="Permalink: Telegram" href="#telegram"></a></p>
<ul dir="auto">
<li>Set <code>TELEGRAM_BOT_TOKEN</code> or <code>channels.telegram.botToken</code> (env wins).</li>
<li>Optional: set <code>channels.telegram.groups</code> (with <code>channels.telegram.groups."*".requireMention</code>); when set, it is a group allowlist (include <code>"*"</code> to allow all). Also <code>channels.telegram.allowFrom</code> or <code>channels.telegram.webhookUrl</code> as needed.</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  channels: {
    telegram: {
      botToken: &quot;123456:ABCDEF&quot;
    }
  }
}"><pre><span>{</span>
  <span>channels</span>: <span>{</span>
    <span>telegram</span>: <span>{</span>
      <span>botToken</span>: <span>"123456:ABCDEF"</span>
    <span>}</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/slack" rel="nofollow">Slack</a></h3><a id="user-content-slack" aria-label="Permalink: Slack" href="#slack"></a></p>
<ul dir="auto">
<li>Set <code>SLACK_BOT_TOKEN</code> + <code>SLACK_APP_TOKEN</code> (or <code>channels.slack.botToken</code> + <code>channels.slack.appToken</code>).</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/discord" rel="nofollow">Discord</a></h3><a id="user-content-discord" aria-label="Permalink: Discord" href="#discord"></a></p>
<ul dir="auto">
<li>Set <code>DISCORD_BOT_TOKEN</code> or <code>channels.discord.token</code> (env wins).</li>
<li>Optional: set <code>commands.native</code>, <code>commands.text</code>, or <code>commands.useAccessGroups</code>, plus <code>channels.discord.dm.allowFrom</code>, <code>channels.discord.guilds</code>, or <code>channels.discord.mediaMaxMb</code> as needed.</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  channels: {
    discord: {
      token: &quot;1234abcd&quot;
    }
  }
}"><pre><span>{</span>
  <span>channels</span>: <span>{</span>
    <span>discord</span>: <span>{</span>
      <span>token</span>: <span>"1234abcd"</span>
    <span>}</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/signal" rel="nofollow">Signal</a></h3><a id="user-content-signal" aria-label="Permalink: Signal" href="#signal"></a></p>
<ul dir="auto">
<li>Requires <code>signal-cli</code> and a <code>channels.signal</code> config section.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/imessage" rel="nofollow">iMessage</a></h3><a id="user-content-imessage" aria-label="Permalink: iMessage" href="#imessage"></a></p>
<ul dir="auto">
<li>macOS only; Messages must be signed in.</li>
<li>If <code>channels.imessage.groups</code> is set, it becomes a group allowlist; include <code>"*"</code> to allow all.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/channels/msteams" rel="nofollow">Microsoft Teams</a></h3><a id="user-content-microsoft-teams" aria-label="Permalink: Microsoft Teams" href="#microsoft-teams"></a></p>
<ul dir="auto">
<li>Configure a Teams app + Bot Framework, then add a <code>msteams</code> config section.</li>
<li>Allowlist who can talk via <code>msteams.allowFrom</code>; group access via <code>msteams.groupAllowFrom</code> or <code>msteams.groupPolicy: "open"</code>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.clawd.bot/web/webchat" rel="nofollow">WebChat</a></h3><a id="user-content-webchat" aria-label="Permalink: WebChat" href="#webchat"></a></p>
<ul dir="auto">
<li>Uses the Gateway WebSocket; no separate WebChat port/config.</li>
</ul>
<p dir="auto">Browser control (optional):</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  browser: {
    enabled: true,
    controlUrl: &quot;http://127.0.0.1:18791&quot;,
    color: &quot;#FF4500&quot;
  }
}"><pre><span>{</span>
  <span>browser</span>: <span>{</span>
    <span>enabled</span>: <span>true</span><span>,</span>
    <span>controlUrl</span>: <span>"http://127.0.0.1:18791"</span><span>,</span>
    <span>color</span>: <span>"#FF4500"</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<p dir="auto">Use these when you’re past the onboarding flow and want the deeper reference.</p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/" rel="nofollow">Start with the docs index for navigation and “what’s where.”</a></li>
<li><a href="https://docs.clawd.bot/concepts/architecture" rel="nofollow">Read the architecture overview for the gateway + protocol model.</a></li>
<li><a href="https://docs.clawd.bot/gateway/configuration" rel="nofollow">Use the full configuration reference when you need every key and example.</a></li>
<li><a href="https://docs.clawd.bot/gateway" rel="nofollow">Run the Gateway by the book with the operational runbook.</a></li>
<li><a href="https://docs.clawd.bot/web" rel="nofollow">Learn how the Control UI/Web surfaces work and how to expose them safely.</a></li>
<li><a href="https://docs.clawd.bot/gateway/remote" rel="nofollow">Understand remote access over SSH tunnels or tailnets.</a></li>
<li><a href="https://docs.clawd.bot/start/wizard" rel="nofollow">Follow the onboarding wizard flow for a guided setup.</a></li>
<li><a href="https://docs.clawd.bot/automation/webhook" rel="nofollow">Wire external triggers via the webhook surface.</a></li>
<li><a href="https://docs.clawd.bot/automation/gmail-pubsub" rel="nofollow">Set up Gmail Pub/Sub triggers.</a></li>
<li><a href="https://docs.clawd.bot/platforms/mac/menu-bar" rel="nofollow">Learn the macOS menu bar companion details.</a></li>
<li><a href="https://docs.clawd.bot/platforms/windows" rel="nofollow">Platform guides: Windows (WSL2)</a>, <a href="https://docs.clawd.bot/platforms/linux" rel="nofollow">Linux</a>, <a href="https://docs.clawd.bot/platforms/macos" rel="nofollow">macOS</a>, <a href="https://docs.clawd.bot/platforms/ios" rel="nofollow">iOS</a>, <a href="https://docs.clawd.bot/platforms/android" rel="nofollow">Android</a></li>
<li><a href="https://docs.clawd.bot/channels/troubleshooting" rel="nofollow">Debug common failures with the troubleshooting guide.</a></li>
<li><a href="https://docs.clawd.bot/gateway/security" rel="nofollow">Review security guidance before exposing anything.</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced docs (discovery + control)</h2><a id="user-content-advanced-docs-discovery--control" aria-label="Permalink: Advanced docs (discovery + control)" href="#advanced-docs-discovery--control"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/gateway/discovery" rel="nofollow">Discovery + transports</a></li>
<li><a href="https://docs.clawd.bot/gateway/bonjour" rel="nofollow">Bonjour/mDNS</a></li>
<li><a href="https://docs.clawd.bot/gateway/pairing" rel="nofollow">Gateway pairing</a></li>
<li><a href="https://docs.clawd.bot/gateway/remote-gateway-readme" rel="nofollow">Remote gateway README</a></li>
<li><a href="https://docs.clawd.bot/web/control-ui" rel="nofollow">Control UI</a></li>
<li><a href="https://docs.clawd.bot/web/dashboard" rel="nofollow">Dashboard</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Operations &amp; troubleshooting</h2><a id="user-content-operations--troubleshooting" aria-label="Permalink: Operations &amp; troubleshooting" href="#operations--troubleshooting"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/gateway/health" rel="nofollow">Health checks</a></li>
<li><a href="https://docs.clawd.bot/gateway/gateway-lock" rel="nofollow">Gateway lock</a></li>
<li><a href="https://docs.clawd.bot/gateway/background-process" rel="nofollow">Background process</a></li>
<li><a href="https://docs.clawd.bot/tools/browser-linux-troubleshooting" rel="nofollow">Browser troubleshooting (Linux)</a></li>
<li><a href="https://docs.clawd.bot/logging" rel="nofollow">Logging</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deep dives</h2><a id="user-content-deep-dives" aria-label="Permalink: Deep dives" href="#deep-dives"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/concepts/agent-loop" rel="nofollow">Agent loop</a></li>
<li><a href="https://docs.clawd.bot/concepts/presence" rel="nofollow">Presence</a></li>
<li><a href="https://docs.clawd.bot/concepts/typebox" rel="nofollow">TypeBox schemas</a></li>
<li><a href="https://docs.clawd.bot/reference/rpc" rel="nofollow">RPC adapters</a></li>
<li><a href="https://docs.clawd.bot/concepts/queue" rel="nofollow">Queue</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Workspace &amp; skills</h2><a id="user-content-workspace--skills" aria-label="Permalink: Workspace &amp; skills" href="#workspace--skills"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/tools/skills-config" rel="nofollow">Skills config</a></li>
<li><a href="https://docs.clawd.bot/reference/AGENTS.default" rel="nofollow">Default AGENTS</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/AGENTS" rel="nofollow">Templates: AGENTS</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/BOOTSTRAP" rel="nofollow">Templates: BOOTSTRAP</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/IDENTITY" rel="nofollow">Templates: IDENTITY</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/SOUL" rel="nofollow">Templates: SOUL</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/TOOLS" rel="nofollow">Templates: TOOLS</a></li>
<li><a href="https://docs.clawd.bot/reference/templates/USER" rel="nofollow">Templates: USER</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Platform internals</h2><a id="user-content-platform-internals" aria-label="Permalink: Platform internals" href="#platform-internals"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/platforms/mac/dev-setup" rel="nofollow">macOS dev setup</a></li>
<li><a href="https://docs.clawd.bot/platforms/mac/menu-bar" rel="nofollow">macOS menu bar</a></li>
<li><a href="https://docs.clawd.bot/platforms/mac/voicewake" rel="nofollow">macOS voice wake</a></li>
<li><a href="https://docs.clawd.bot/platforms/ios" rel="nofollow">iOS node</a></li>
<li><a href="https://docs.clawd.bot/platforms/android" rel="nofollow">Android node</a></li>
<li><a href="https://docs.clawd.bot/platforms/windows" rel="nofollow">Windows (WSL2)</a></li>
<li><a href="https://docs.clawd.bot/platforms/linux" rel="nofollow">Linux app</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Email hooks (Gmail)</h2><a id="user-content-email-hooks-gmail" aria-label="Permalink: Email hooks (Gmail)" href="#email-hooks-gmail"></a></p>
<ul dir="auto">
<li><a href="https://docs.clawd.bot/automation/gmail-pubsub" rel="nofollow">docs.clawd.bot/gmail-pubsub</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Clawd</h2><a id="user-content-clawd" aria-label="Permalink: Clawd" href="#clawd"></a></p>
<p dir="auto">Clawdbot was built for <strong>Clawd</strong>, a space lobster AI assistant. 🦞
by Peter Steinberger and the community.</p>
<ul dir="auto">
<li><a href="https://clawd.me/" rel="nofollow">clawd.me</a></li>
<li><a href="https://soul.md/" rel="nofollow">soul.md</a></li>
<li><a href="https://steipete.me/" rel="nofollow">steipete.me</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">See <a href="https://github.com/clawdbot/clawdbot/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for guidelines, maintainers, and how to submit PRs.
AI/vibe-coded PRs welcome! 🤖</p>
<p dir="auto">Special thanks to <a href="https://mariozechner.at/" rel="nofollow">Mario Zechner</a> for his support and for
<a href="https://github.com/badlogic/pi-mono">pi-mono</a>.</p>
<p dir="auto">Thanks to all clawtributors:</p>
<p dir="auto">
  <a href="https://github.com/steipete"><img src="https://avatars.githubusercontent.com/u/58493?v=4&amp;s=48" width="48" height="48" alt="steipete" title="steipete"></a> <a href="https://github.com/plum-dawg"><img src="https://avatars.githubusercontent.com/u/5909950?v=4&amp;s=48" width="48" height="48" alt="plum-dawg" title="plum-dawg"></a> <a href="https://github.com/bohdanpodvirnyi"><img src="https://avatars.githubusercontent.com/u/31819391?v=4&amp;s=48" width="48" height="48" alt="bohdanpodvirnyi" title="bohdanpodvirnyi"></a> <a href="https://github.com/iHildy"><img src="https://avatars.githubusercontent.com/u/25069719?v=4&amp;s=48" width="48" height="48" alt="iHildy" title="iHildy"></a> <a href="https://github.com/joaohlisboa"><img src="https://avatars.githubusercontent.com/u/8200873?v=4&amp;s=48" width="48" height="48" alt="joaohlisboa" title="joaohlisboa"></a> <a href="https://github.com/mneves75"><img src="https://avatars.githubusercontent.com/u/2423436?v=4&amp;s=48" width="48" height="48" alt="mneves75" title="mneves75"></a> <a href="https://github.com/MatthieuBizien"><img src="https://avatars.githubusercontent.com/u/173090?v=4&amp;s=48" width="48" height="48" alt="MatthieuBizien" title="MatthieuBizien"></a> <a href="https://github.com/MaudeBot"><img src="https://avatars.githubusercontent.com/u/255777700?v=4&amp;s=48" width="48" height="48" alt="MaudeBot" title="MaudeBot"></a> <a href="https://github.com/Glucksberg"><img src="https://avatars.githubusercontent.com/u/80581902?v=4&amp;s=48" width="48" height="48" alt="Glucksberg" title="Glucksberg"></a> <a href="https://github.com/rahthakor"><img src="https://avatars.githubusercontent.com/u/8470553?v=4&amp;s=48" width="48" height="48" alt="rahthakor" title="rahthakor"></a>
  <a href="https://github.com/vrknetha"><img src="https://avatars.githubusercontent.com/u/20596261?v=4&amp;s=48" width="48" height="48" alt="vrknetha" title="vrknetha"></a> <a href="https://github.com/radek-paclt"><img src="https://avatars.githubusercontent.com/u/50451445?v=4&amp;s=48" width="48" height="48" alt="radek-paclt" title="radek-paclt"></a> <a href="https://github.com/tobiasbischoff"><img src="https://avatars.githubusercontent.com/u/711564?v=4&amp;s=48" width="48" height="48" alt="Tobias Bischoff" title="Tobias Bischoff"></a> <a href="https://github.com/joshp123"><img src="https://avatars.githubusercontent.com/u/1497361?v=4&amp;s=48" width="48" height="48" alt="joshp123" title="joshp123"></a> <a href="https://github.com/czekaj"><img src="https://avatars.githubusercontent.com/u/1464539?v=4&amp;s=48" width="48" height="48" alt="czekaj" title="czekaj"></a> <a href="https://github.com/mukhtharcm"><img src="https://avatars.githubusercontent.com/u/56378562?v=4&amp;s=48" width="48" height="48" alt="mukhtharcm" title="mukhtharcm"></a> <a href="https://github.com/sebslight"><img src="https://avatars.githubusercontent.com/u/19554889?v=4&amp;s=48" width="48" height="48" alt="sebslight" title="sebslight"></a> <a href="https://github.com/maxsumrall"><img src="https://avatars.githubusercontent.com/u/628843?v=4&amp;s=48" width="48" height="48" alt="maxsumrall" title="maxsumrall"></a> <a href="https://github.com/xadenryan"><img src="https://avatars.githubusercontent.com/u/165437834?v=4&amp;s=48" width="48" height="48" alt="xadenryan" title="xadenryan"></a> <a href="https://github.com/rodrigouroz"><img src="https://avatars.githubusercontent.com/u/384037?v=4&amp;s=48" width="48" height="48" alt="rodrigouroz" title="rodrigouroz"></a>
  <a href="https://github.com/juanpablodlc"><img src="https://avatars.githubusercontent.com/u/92012363?v=4&amp;s=48" width="48" height="48" alt="juanpablodlc" title="juanpablodlc"></a> <a href="https://github.com/hsrvc"><img src="https://avatars.githubusercontent.com/u/129702169?v=4&amp;s=48" width="48" height="48" alt="hsrvc" title="hsrvc"></a> <a href="https://github.com/magimetal"><img src="https://avatars.githubusercontent.com/u/36491250?v=4&amp;s=48" width="48" height="48" alt="magimetal" title="magimetal"></a> <a href="https://github.com/meaningfool"><img src="https://avatars.githubusercontent.com/u/2862331?v=4&amp;s=48" width="48" height="48" alt="meaningfool" title="meaningfool"></a> <a href="https://github.com/tyler6204"><img src="https://avatars.githubusercontent.com/u/64381258?v=4&amp;s=48" width="48" height="48" alt="tyler6204" title="tyler6204"></a> <a href="https://github.com/patelhiren"><img src="https://avatars.githubusercontent.com/u/172098?v=4&amp;s=48" width="48" height="48" alt="patelhiren" title="patelhiren"></a> <a href="https://github.com/NicholasSpisak"><img src="https://avatars.githubusercontent.com/u/129075147?v=4&amp;s=48" width="48" height="48" alt="NicholasSpisak" title="NicholasSpisak"></a> <a href="https://github.com/jonisjongithub"><img src="https://avatars.githubusercontent.com/u/86072337?v=4&amp;s=48" width="48" height="48" alt="jonisjongithub" title="jonisjongithub"></a> <a href="https://github.com/zerone0x"><img src="https://avatars.githubusercontent.com/u/39543393?v=4&amp;s=48" width="48" height="48" alt="zerone0x" title="zerone0x"></a> <a href="https://github.com/AbhisekBasu1"><img src="https://avatars.githubusercontent.com/u/40645221?v=4&amp;s=48" width="48" height="48" alt="abhisekbasu1" title="abhisekbasu1"></a>
  <a href="https://github.com/jamesgroat"><img src="https://avatars.githubusercontent.com/u/2634024?v=4&amp;s=48" width="48" height="48" alt="jamesgroat" title="jamesgroat"></a> <a href="https://github.com/claude"><img src="https://avatars.githubusercontent.com/u/81847?v=4&amp;s=48" width="48" height="48" alt="claude" title="claude"></a> <a href="https://github.com/JustYannicc"><img src="https://avatars.githubusercontent.com/u/52761674?v=4&amp;s=48" width="48" height="48" alt="JustYannicc" title="JustYannicc"></a> <a href="https://github.com/Hyaxia"><img src="https://avatars.githubusercontent.com/u/36747317?v=4&amp;s=48" width="48" height="48" alt="Hyaxia" title="Hyaxia"></a> <a href="https://github.com/dantelex"><img src="https://avatars.githubusercontent.com/u/631543?v=4&amp;s=48" width="48" height="48" alt="dantelex" title="dantelex"></a> <a href="https://github.com/SocialNerd42069"><img src="https://avatars.githubusercontent.com/u/118244303?v=4&amp;s=48" width="48" height="48" alt="SocialNerd42069" title="SocialNerd42069"></a> <a href="https://github.com/daveonkels"><img src="https://avatars.githubusercontent.com/u/533642?v=4&amp;s=48" width="48" height="48" alt="daveonkels" title="daveonkels"></a> <a href="https://github.com/apps/google-labs-jules"><img src="https://avatars.githubusercontent.com/in/842251?v=4&amp;s=48" width="48" height="48" alt="google-labs-jules[bot]" title="google-labs-jules[bot]"></a> <a href="https://github.com/lc0rp"><img src="https://avatars.githubusercontent.com/u/2609441?v=4&amp;s=48" width="48" height="48" alt="lc0rp" title="lc0rp"></a> <a href="https://github.com/mousberg"><img src="https://avatars.githubusercontent.com/u/57605064?v=4&amp;s=48" width="48" height="48" alt="mousberg" title="mousberg"></a>
  <a href="https://github.com/vignesh07"><img src="https://avatars.githubusercontent.com/u/1436853?v=4&amp;s=48" width="48" height="48" alt="vignesh07" title="vignesh07"></a> <a href="https://github.com/mteam88"><img src="https://avatars.githubusercontent.com/u/84196639?v=4&amp;s=48" width="48" height="48" alt="mteam88" title="mteam88"></a> <a href="https://github.com/dbhurley"><img src="https://avatars.githubusercontent.com/u/5251425?v=4&amp;s=48" width="48" height="48" alt="dbhurley" title="dbhurley"></a> <a href="https://github.com/mbelinky"><img src="https://avatars.githubusercontent.com/u/132747814?v=4&amp;s=48" width="48" height="48" alt="Mariano Belinky" title="Mariano Belinky"></a> <a href="https://github.com/omniwired"><img src="https://avatars.githubusercontent.com/u/322761?v=4&amp;s=48" width="48" height="48" alt="Eng. Juan Combetto" title="Eng. Juan Combetto"></a> <a href="https://github.com/TSavo"><img src="https://avatars.githubusercontent.com/u/877990?v=4&amp;s=48" width="48" height="48" alt="TSavo" title="TSavo"></a> <a href="https://github.com/julianengel"><img src="https://avatars.githubusercontent.com/u/10634231?v=4&amp;s=48" width="48" height="48" alt="julianengel" title="julianengel"></a> <a href="https://github.com/bradleypriest"><img src="https://avatars.githubusercontent.com/u/167215?v=4&amp;s=48" width="48" height="48" alt="bradleypriest" title="bradleypriest"></a> <a href="https://github.com/benithors"><img src="https://avatars.githubusercontent.com/u/20652882?v=4&amp;s=48" width="48" height="48" alt="benithors" title="benithors"></a> <a href="https://github.com/rohannagpal"><img src="https://avatars.githubusercontent.com/u/4009239?v=4&amp;s=48" width="48" height="48" alt="rohannagpal" title="rohannagpal"></a>
  <a href="https://github.com/timolins"><img src="https://avatars.githubusercontent.com/u/1440854?v=4&amp;s=48" width="48" height="48" alt="timolins" title="timolins"></a> <a href="https://github.com/f-trycua"><img src="https://avatars.githubusercontent.com/u/195596869?v=4&amp;s=48" width="48" height="48" alt="f-trycua" title="f-trycua"></a> <a href="https://github.com/benostein"><img src="https://avatars.githubusercontent.com/u/31802821?v=4&amp;s=48" width="48" height="48" alt="benostein" title="benostein"></a> <a href="https://github.com/Nachx639"><img src="https://avatars.githubusercontent.com/u/71144023?v=4&amp;s=48" width="48" height="48" alt="nachx639" title="nachx639"></a> <a href="https://github.com/pvoo"><img src="https://avatars.githubusercontent.com/u/20116814?v=4&amp;s=48" width="48" height="48" alt="pvoo" title="pvoo"></a> <a href="https://github.com/sreekaransrinath"><img src="https://avatars.githubusercontent.com/u/50989977?v=4&amp;s=48" width="48" height="48" alt="sreekaransrinath" title="sreekaransrinath"></a> <a href="https://github.com/gupsammy"><img src="https://avatars.githubusercontent.com/u/20296019?v=4&amp;s=48" width="48" height="48" alt="gupsammy" title="gupsammy"></a> <a href="https://github.com/cristip73"><img src="https://avatars.githubusercontent.com/u/24499421?v=4&amp;s=48" width="48" height="48" alt="cristip73" title="cristip73"></a> <a href="https://github.com/stefangalescu"><img src="https://avatars.githubusercontent.com/u/52995748?v=4&amp;s=48" width="48" height="48" alt="stefangalescu" title="stefangalescu"></a> <a href="https://github.com/nachoiacovino"><img src="https://avatars.githubusercontent.com/u/50103937?v=4&amp;s=48" width="48" height="48" alt="nachoiacovino" title="nachoiacovino"></a>
  <a href="https://github.com/vsabavat"><img src="https://avatars.githubusercontent.com/u/50385532?v=4&amp;s=48" width="48" height="48" alt="Vasanth Rao Naik Sabavat" title="Vasanth Rao Naik Sabavat"></a> <a href="https://github.com/petter-b"><img src="https://avatars.githubusercontent.com/u/62076402?v=4&amp;s=48" width="48" height="48" alt="petter-b" title="petter-b"></a> <a href="https://github.com/cpojer"><img src="https://avatars.githubusercontent.com/u/13352?v=4&amp;s=48" width="48" height="48" alt="cpojer" title="cpojer"></a> <a href="https://github.com/scald"><img src="https://avatars.githubusercontent.com/u/1215913?v=4&amp;s=48" width="48" height="48" alt="scald" title="scald"></a> <a href="https://github.com/gumadeiras"><img src="https://avatars.githubusercontent.com/u/5599352?v=4&amp;s=48" width="48" height="48" alt="gumadeiras" title="gumadeiras"></a> <a href="https://github.com/andranik-sahakyan"><img src="https://avatars.githubusercontent.com/u/8908029?v=4&amp;s=48" width="48" height="48" alt="andranik-sahakyan" title="andranik-sahakyan"></a> <a href="https://github.com/davidguttman"><img src="https://avatars.githubusercontent.com/u/431696?v=4&amp;s=48" width="48" height="48" alt="davidguttman" title="davidguttman"></a> <a href="https://github.com/sleontenko"><img src="https://avatars.githubusercontent.com/u/7135949?v=4&amp;s=48" width="48" height="48" alt="sleontenko" title="sleontenko"></a> <a href="https://github.com/denysvitali"><img src="https://avatars.githubusercontent.com/u/4939519?v=4&amp;s=48" width="48" height="48" alt="denysvitali" title="denysvitali"></a> <a href="https://github.com/orlyjamie"><img src="https://avatars.githubusercontent.com/u/6668807?v=4&amp;s=48" width="48" height="48" alt="orlyjamie" title="orlyjamie"></a>
  <a href="https://github.com/sircrumpet"><img src="https://avatars.githubusercontent.com/u/4436535?v=4&amp;s=48" width="48" height="48" alt="sircrumpet" title="sircrumpet"></a> <a href="https://github.com/peschee"><img src="https://avatars.githubusercontent.com/u/63866?v=4&amp;s=48" width="48" height="48" alt="peschee" title="peschee"></a> <a href="https://github.com/rafaelreis-r"><img src="https://avatars.githubusercontent.com/u/57492577?v=4&amp;s=48" width="48" height="48" alt="rafaelreis-r" title="rafaelreis-r"></a> <a href="https://github.com/thewilloftheshadow"><img src="https://avatars.githubusercontent.com/u/35580099?v=4&amp;s=48" width="48" height="48" alt="thewilloftheshadow" title="thewilloftheshadow"></a> <a href="https://github.com/ratulsarna"><img src="https://avatars.githubusercontent.com/u/105903728?v=4&amp;s=48" width="48" height="48" alt="ratulsarna" title="ratulsarna"></a> <a href="https://github.com/lutr0"><img src="https://avatars.githubusercontent.com/u/76906369?v=4&amp;s=48" width="48" height="48" alt="lutr0" title="lutr0"></a> <a href="https://github.com/danielz1z"><img src="https://avatars.githubusercontent.com/u/235270390?v=4&amp;s=48" width="48" height="48" alt="danielz1z" title="danielz1z"></a> <a href="https://github.com/emanuelst"><img src="https://avatars.githubusercontent.com/u/9994339?v=4&amp;s=48" width="48" height="48" alt="emanuelst" title="emanuelst"></a> <a href="https://github.com/KristijanJovanovski"><img src="https://avatars.githubusercontent.com/u/8942284?v=4&amp;s=48" width="48" height="48" alt="KristijanJovanovski" title="KristijanJovanovski"></a> <a href="https://github.com/rdev"><img src="https://avatars.githubusercontent.com/u/8418866?v=4&amp;s=48" width="48" height="48" alt="rdev" title="rdev"></a>
  <a href="https://github.com/joshrad-dev"><img src="https://avatars.githubusercontent.com/u/62785552?v=4&amp;s=48" width="48" height="48" alt="joshrad-dev" title="joshrad-dev"></a> <a href="https://github.com/kiranjd"><img src="https://avatars.githubusercontent.com/u/25822851?v=4&amp;s=48" width="48" height="48" alt="kiranjd" title="kiranjd"></a> <a href="https://github.com/osolmaz"><img src="https://avatars.githubusercontent.com/u/2453968?v=4&amp;s=48" width="48" height="48" alt="osolmaz" title="osolmaz"></a> <a href="https://github.com/adityashaw2"><img src="https://avatars.githubusercontent.com/u/41204444?v=4&amp;s=48" width="48" height="48" alt="adityashaw2" title="adityashaw2"></a> <a href="https://github.com/CashWilliams"><img src="https://avatars.githubusercontent.com/u/613573?v=4&amp;s=48" width="48" height="48" alt="CashWilliams" title="CashWilliams"></a> <a href="https://github.com/search?q=sheeek"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="sheeek" title="sheeek"></a> <a href="https://github.com/artuskg"><img src="https://avatars.githubusercontent.com/u/11966157?v=4&amp;s=48" width="48" height="48" alt="artuskg" title="artuskg"></a> <a href="https://github.com/Takhoffman"><img src="https://avatars.githubusercontent.com/u/781889?v=4&amp;s=48" width="48" height="48" alt="Takhoffman" title="Takhoffman"></a> <a href="https://github.com/onutc"><img src="https://avatars.githubusercontent.com/u/152018508?v=4&amp;s=48" width="48" height="48" alt="onutc" title="onutc"></a> <a href="https://github.com/pauloportella"><img src="https://avatars.githubusercontent.com/u/22947229?v=4&amp;s=48" width="48" height="48" alt="pauloportella" title="pauloportella"></a>
  <a href="https://github.com/neooriginal"><img src="https://avatars.githubusercontent.com/u/54811660?v=4&amp;s=48" width="48" height="48" alt="neooriginal" title="neooriginal"></a> <a href="https://github.com/ManuelHettich"><img src="https://avatars.githubusercontent.com/u/17690367?v=4&amp;s=48" width="48" height="48" alt="manuelhettich" title="manuelhettich"></a> <a href="https://github.com/minghinmatthewlam"><img src="https://avatars.githubusercontent.com/u/14224566?v=4&amp;s=48" width="48" height="48" alt="minghinmatthewlam" title="minghinmatthewlam"></a> <a href="https://github.com/myfunc"><img src="https://avatars.githubusercontent.com/u/19294627?v=4&amp;s=48" width="48" height="48" alt="myfunc" title="myfunc"></a> <a href="https://github.com/travisirby"><img src="https://avatars.githubusercontent.com/u/5958376?v=4&amp;s=48" width="48" height="48" alt="travisirby" title="travisirby"></a> <a href="https://github.com/buddyh"><img src="https://avatars.githubusercontent.com/u/31752869?v=4&amp;s=48" width="48" height="48" alt="buddyh" title="buddyh"></a> <a href="https://github.com/connorshea"><img src="https://avatars.githubusercontent.com/u/2977353?v=4&amp;s=48" width="48" height="48" alt="connorshea" title="connorshea"></a> <a href="https://github.com/kyleok"><img src="https://avatars.githubusercontent.com/u/58307870?v=4&amp;s=48" width="48" height="48" alt="kyleok" title="kyleok"></a> <a href="https://github.com/mcinteerj"><img src="https://avatars.githubusercontent.com/u/3613653?v=4&amp;s=48" width="48" height="48" alt="mcinteerj" title="mcinteerj"></a> <a href="https://github.com/apps/dependabot"><img src="https://avatars.githubusercontent.com/in/29110?v=4&amp;s=48" width="48" height="48" alt="dependabot[bot]" title="dependabot[bot]"></a>
  <a href="https://github.com/John-Rood"><img src="https://avatars.githubusercontent.com/u/62669593?v=4&amp;s=48" width="48" height="48" alt="John-Rood" title="John-Rood"></a> <a href="https://github.com/timkrase"><img src="https://avatars.githubusercontent.com/u/38947626?v=4&amp;s=48" width="48" height="48" alt="timkrase" title="timkrase"></a> <a href="https://github.com/uos-status"><img src="https://avatars.githubusercontent.com/u/255712580?v=4&amp;s=48" width="48" height="48" alt="uos-status" title="uos-status"></a> <a href="https://github.com/gerardward2007"><img src="https://avatars.githubusercontent.com/u/3002155?v=4&amp;s=48" width="48" height="48" alt="gerardward2007" title="gerardward2007"></a> <a href="https://github.com/obviyus"><img src="https://avatars.githubusercontent.com/u/22031114?v=4&amp;s=48" width="48" height="48" alt="obviyus" title="obviyus"></a> <a href="https://github.com/roshanasingh4"><img src="https://avatars.githubusercontent.com/u/88576930?v=4&amp;s=48" width="48" height="48" alt="roshanasingh4" title="roshanasingh4"></a> <a href="https://github.com/tosh-hamburg"><img src="https://avatars.githubusercontent.com/u/58424326?v=4&amp;s=48" width="48" height="48" alt="tosh-hamburg" title="tosh-hamburg"></a> <a href="https://github.com/azade-c"><img src="https://avatars.githubusercontent.com/u/252790079?v=4&amp;s=48" width="48" height="48" alt="azade-c" title="azade-c"></a> <a href="https://github.com/JonUleis"><img src="https://avatars.githubusercontent.com/u/7644941?v=4&amp;s=48" width="48" height="48" alt="JonUleis" title="JonUleis"></a> <a href="https://github.com/bjesuiter"><img src="https://avatars.githubusercontent.com/u/2365676?v=4&amp;s=48" width="48" height="48" alt="bjesuiter" title="bjesuiter"></a>
  <a href="https://github.com/cheeeee"><img src="https://avatars.githubusercontent.com/u/21245729?v=4&amp;s=48" width="48" height="48" alt="cheeeee" title="cheeeee"></a> <a href="https://github.com/j1philli"><img src="https://avatars.githubusercontent.com/u/3744255?v=4&amp;s=48" width="48" height="48" alt="Josh Phillips" title="Josh Phillips"></a> <a href="https://github.com/robbyczgw-cla"><img src="https://avatars.githubusercontent.com/u/239660374?v=4&amp;s=48" width="48" height="48" alt="robbyczgw-cla" title="robbyczgw-cla"></a> <a href="https://github.com/dlauer"><img src="https://avatars.githubusercontent.com/u/757041?v=4&amp;s=48" width="48" height="48" alt="dlauer" title="dlauer"></a> <a href="https://github.com/pookNast"><img src="https://avatars.githubusercontent.com/u/14242552?v=4&amp;s=48" width="48" height="48" alt="pookNast" title="pookNast"></a> <a href="https://github.com/Whoaa512"><img src="https://avatars.githubusercontent.com/u/1581943?v=4&amp;s=48" width="48" height="48" alt="Whoaa512" title="Whoaa512"></a> <a href="https://github.com/YuriNachos"><img src="https://avatars.githubusercontent.com/u/19365375?v=4&amp;s=48" width="48" height="48" alt="YuriNachos" title="YuriNachos"></a> <a href="https://github.com/chriseidhof"><img src="https://avatars.githubusercontent.com/u/5382?v=4&amp;s=48" width="48" height="48" alt="chriseidhof" title="chriseidhof"></a> <a href="https://github.com/ngutman"><img src="https://avatars.githubusercontent.com/u/1540134?v=4&amp;s=48" width="48" height="48" alt="ngutman" title="ngutman"></a> <a href="https://github.com/ysqander"><img src="https://avatars.githubusercontent.com/u/80843820?v=4&amp;s=48" width="48" height="48" alt="ysqander" title="ysqander"></a>
  <a href="https://github.com/aj47"><img src="https://avatars.githubusercontent.com/u/8023513?v=4&amp;s=48" width="48" height="48" alt="aj47" title="aj47"></a> <a href="https://github.com/superman32432432"><img src="https://avatars.githubusercontent.com/u/7228420?v=4&amp;s=48" width="48" height="48" alt="superman32432432" title="superman32432432"></a> <a href="https://github.com/search?q=Yurii%20Chukhlib"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Yurii Chukhlib" title="Yurii Chukhlib"></a> <a href="https://github.com/grp06"><img src="https://avatars.githubusercontent.com/u/1573959?v=4&amp;s=48" width="48" height="48" alt="grp06" title="grp06"></a> <a href="https://github.com/antons"><img src="https://avatars.githubusercontent.com/u/129705?v=4&amp;s=48" width="48" height="48" alt="antons" title="antons"></a> <a href="https://github.com/austinm911"><img src="https://avatars.githubusercontent.com/u/31991302?v=4&amp;s=48" width="48" height="48" alt="austinm911" title="austinm911"></a> <a href="https://github.com/apps/blacksmith-sh"><img src="https://avatars.githubusercontent.com/in/807020?v=4&amp;s=48" width="48" height="48" alt="blacksmith-sh[bot]" title="blacksmith-sh[bot]"></a> <a href="https://github.com/damoahdominic"><img src="https://avatars.githubusercontent.com/u/4623434?v=4&amp;s=48" width="48" height="48" alt="damoahdominic" title="damoahdominic"></a> <a href="https://github.com/dan-dr"><img src="https://avatars.githubusercontent.com/u/6669808?v=4&amp;s=48" width="48" height="48" alt="dan-dr" title="dan-dr"></a> <a href="https://github.com/HeimdallStrategy"><img src="https://avatars.githubusercontent.com/u/223014405?v=4&amp;s=48" width="48" height="48" alt="HeimdallStrategy" title="HeimdallStrategy"></a>
  <a href="https://github.com/imfing"><img src="https://avatars.githubusercontent.com/u/5097752?v=4&amp;s=48" width="48" height="48" alt="imfing" title="imfing"></a> <a href="https://github.com/jalehman"><img src="https://avatars.githubusercontent.com/u/550978?v=4&amp;s=48" width="48" height="48" alt="jalehman" title="jalehman"></a> <a href="https://github.com/jarvis-medmatic"><img src="https://avatars.githubusercontent.com/u/252428873?v=4&amp;s=48" width="48" height="48" alt="jarvis-medmatic" title="jarvis-medmatic"></a> <a href="https://github.com/kkarimi"><img src="https://avatars.githubusercontent.com/u/875218?v=4&amp;s=48" width="48" height="48" alt="kkarimi" title="kkarimi"></a> <a href="https://github.com/mahmoudashraf93"><img src="https://avatars.githubusercontent.com/u/9130129?v=4&amp;s=48" width="48" height="48" alt="mahmoudashraf93" title="mahmoudashraf93"></a> <a href="https://github.com/pkrmf"><img src="https://avatars.githubusercontent.com/u/1714267?v=4&amp;s=48" width="48" height="48" alt="pkrmf" title="pkrmf"></a> <a href="https://github.com/RandyVentures"><img src="https://avatars.githubusercontent.com/u/149904821?v=4&amp;s=48" width="48" height="48" alt="RandyVentures" title="RandyVentures"></a> <a href="https://github.com/search?q=Ryan%20Lisse"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Ryan Lisse" title="Ryan Lisse"></a> <a href="https://github.com/dougvk"><img src="https://avatars.githubusercontent.com/u/401660?v=4&amp;s=48" width="48" height="48" alt="dougvk" title="dougvk"></a> <a href="https://github.com/erikpr1994"><img src="https://avatars.githubusercontent.com/u/6299331?v=4&amp;s=48" width="48" height="48" alt="erikpr1994" title="erikpr1994"></a>
  <a href="https://github.com/search?q=Ghost"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Ghost" title="Ghost"></a> <a href="https://github.com/jonasjancarik"><img src="https://avatars.githubusercontent.com/u/2459191?v=4&amp;s=48" width="48" height="48" alt="jonasjancarik" title="jonasjancarik"></a> <a href="https://github.com/search?q=Keith%20the%20Silly%20Goose"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Keith the Silly Goose" title="Keith the Silly Goose"></a> <a href="https://github.com/search?q=L36%20Server"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="L36 Server" title="L36 Server"></a> <a href="https://github.com/search?q=Marc"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Marc" title="Marc"></a> <a href="https://github.com/mitschabaude-bot"><img src="https://avatars.githubusercontent.com/u/247582884?v=4&amp;s=48" width="48" height="48" alt="mitschabaude-bot" title="mitschabaude-bot"></a> <a href="https://github.com/mkbehr"><img src="https://avatars.githubusercontent.com/u/1285?v=4&amp;s=48" width="48" height="48" alt="mkbehr" title="mkbehr"></a> <a href="https://github.com/neist"><img src="https://avatars.githubusercontent.com/u/1029724?v=4&amp;s=48" width="48" height="48" alt="neist" title="neist"></a> <a href="https://github.com/sibbl"><img src="https://avatars.githubusercontent.com/u/866535?v=4&amp;s=48" width="48" height="48" alt="sibbl" title="sibbl"></a> <a href="https://github.com/chrisrodz"><img src="https://avatars.githubusercontent.com/u/2967620?v=4&amp;s=48" width="48" height="48" alt="chrisrodz" title="chrisrodz"></a>
  <a href="https://github.com/search?q=Friederike%20Seiler"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Friederike Seiler" title="Friederike Seiler"></a> <a href="https://github.com/gabriel-trigo"><img src="https://avatars.githubusercontent.com/u/38991125?v=4&amp;s=48" width="48" height="48" alt="gabriel-trigo" title="gabriel-trigo"></a> <a href="https://github.com/Iamadig"><img src="https://avatars.githubusercontent.com/u/102129234?v=4&amp;s=48" width="48" height="48" alt="iamadig" title="iamadig"></a> <a href="https://github.com/jdrhyne"><img src="https://avatars.githubusercontent.com/u/7828464?v=4&amp;s=48" width="48" height="48" alt="Jonathan D. Rhyne (DJ-D)" title="Jonathan D. Rhyne (DJ-D)"></a> <a href="https://github.com/search?q=Kit"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Kit" title="Kit"></a> <a href="https://github.com/koala73"><img src="https://avatars.githubusercontent.com/u/996596?v=4&amp;s=48" width="48" height="48" alt="koala73" title="koala73"></a> <a href="https://github.com/manmal"><img src="https://avatars.githubusercontent.com/u/142797?v=4&amp;s=48" width="48" height="48" alt="manmal" title="manmal"></a> <a href="https://github.com/ogulcancelik"><img src="https://avatars.githubusercontent.com/u/7064011?v=4&amp;s=48" width="48" height="48" alt="ogulcancelik" title="ogulcancelik"></a> <a href="https://github.com/pasogott"><img src="https://avatars.githubusercontent.com/u/23458152?v=4&amp;s=48" width="48" height="48" alt="pasogott" title="pasogott"></a> <a href="https://github.com/petradonka"><img src="https://avatars.githubusercontent.com/u/7353770?v=4&amp;s=48" width="48" height="48" alt="petradonka" title="petradonka"></a>
  <a href="https://github.com/rubyrunsstuff"><img src="https://avatars.githubusercontent.com/u/246602379?v=4&amp;s=48" width="48" height="48" alt="rubyrunsstuff" title="rubyrunsstuff"></a> <a href="https://github.com/siddhantjain"><img src="https://avatars.githubusercontent.com/u/4835232?v=4&amp;s=48" width="48" height="48" alt="siddhantjain" title="siddhantjain"></a> <a href="https://github.com/suminhthanh"><img src="https://avatars.githubusercontent.com/u/2907636?v=4&amp;s=48" width="48" height="48" alt="suminhthanh" title="suminhthanh"></a> <a href="https://github.com/svkozak"><img src="https://avatars.githubusercontent.com/u/31941359?v=4&amp;s=48" width="48" height="48" alt="svkozak" title="svkozak"></a> <a href="https://github.com/VACInc"><img src="https://avatars.githubusercontent.com/u/3279061?v=4&amp;s=48" width="48" height="48" alt="VACInc" title="VACInc"></a> <a href="https://github.com/wes-davis"><img src="https://avatars.githubusercontent.com/u/16506720?v=4&amp;s=48" width="48" height="48" alt="wes-davis" title="wes-davis"></a> <a href="https://github.com/zats"><img src="https://avatars.githubusercontent.com/u/2688806?v=4&amp;s=48" width="48" height="48" alt="zats" title="zats"></a> <a href="https://github.com/24601"><img src="https://avatars.githubusercontent.com/u/1157207?v=4&amp;s=48" width="48" height="48" alt="24601" title="24601"></a> <a href="https://github.com/adam91holt"><img src="https://avatars.githubusercontent.com/u/9592417?v=4&amp;s=48" width="48" height="48" alt="adam91holt" title="adam91holt"></a> <a href="https://github.com/ameno-"><img src="https://avatars.githubusercontent.com/u/2416135?v=4&amp;s=48" width="48" height="48" alt="ameno-" title="ameno-"></a>
  <a href="https://github.com/search?q=Chris%20Taylor"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Chris Taylor" title="Chris Taylor"></a> <a href="https://github.com/djangonavarro220"><img src="https://avatars.githubusercontent.com/u/251162586?v=4&amp;s=48" width="48" height="48" alt="Django Navarro" title="Django Navarro"></a> <a href="https://github.com/evalexpr"><img src="https://avatars.githubusercontent.com/u/23485511?v=4&amp;s=48" width="48" height="48" alt="evalexpr" title="evalexpr"></a> <a href="https://github.com/henrino3"><img src="https://avatars.githubusercontent.com/u/4260288?v=4&amp;s=48" width="48" height="48" alt="henrino3" title="henrino3"></a> <a href="https://github.com/humanwritten"><img src="https://avatars.githubusercontent.com/u/206531610?v=4&amp;s=48" width="48" height="48" alt="humanwritten" title="humanwritten"></a> <a href="https://github.com/larlyssa"><img src="https://avatars.githubusercontent.com/u/13128869?v=4&amp;s=48" width="48" height="48" alt="larlyssa" title="larlyssa"></a> <a href="https://github.com/odysseus0"><img src="https://avatars.githubusercontent.com/u/8635094?v=4&amp;s=48" width="48" height="48" alt="odysseus0" title="odysseus0"></a> <a href="https://github.com/oswalpalash"><img src="https://avatars.githubusercontent.com/u/6431196?v=4&amp;s=48" width="48" height="48" alt="oswalpalash" title="oswalpalash"></a> <a href="https://github.com/pcty-nextgen-service-account"><img src="https://avatars.githubusercontent.com/u/112553441?v=4&amp;s=48" width="48" height="48" alt="pcty-nextgen-service-account" title="pcty-nextgen-service-account"></a> <a href="https://github.com/rmorse"><img src="https://avatars.githubusercontent.com/u/853547?v=4&amp;s=48" width="48" height="48" alt="rmorse" title="rmorse"></a>
  <a href="https://github.com/Syhids"><img src="https://avatars.githubusercontent.com/u/671202?v=4&amp;s=48" width="48" height="48" alt="Syhids" title="Syhids"></a> <a href="https://github.com/search?q=Aaron%20Konyer"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Aaron Konyer" title="Aaron Konyer"></a> <a href="https://github.com/aaronveklabs"><img src="https://avatars.githubusercontent.com/u/225997828?v=4&amp;s=48" width="48" height="48" alt="aaronveklabs" title="aaronveklabs"></a> <a href="https://github.com/andreabadesso"><img src="https://avatars.githubusercontent.com/u/3586068?v=4&amp;s=48" width="48" height="48" alt="andreabadesso" title="andreabadesso"></a> <a href="https://github.com/search?q=Andrii"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Andrii" title="Andrii"></a> <a href="https://github.com/cash-echo-bot"><img src="https://avatars.githubusercontent.com/u/252747386?v=4&amp;s=48" width="48" height="48" alt="cash-echo-bot" title="cash-echo-bot"></a> <a href="https://github.com/search?q=Clawd"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Clawd" title="Clawd"></a> <a href="https://github.com/search?q=ClawdFx"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="ClawdFx" title="ClawdFx"></a> <a href="https://github.com/dguido"><img src="https://avatars.githubusercontent.com/u/294844?v=4&amp;s=48" width="48" height="48" alt="dguido" title="dguido"></a> <a href="https://github.com/EnzeD"><img src="https://avatars.githubusercontent.com/u/9866900?v=4&amp;s=48" width="48" height="48" alt="EnzeD" title="EnzeD"></a>
  <a href="https://github.com/erik-agens"><img src="https://avatars.githubusercontent.com/u/80908960?v=4&amp;s=48" width="48" height="48" alt="erik-agens" title="erik-agens"></a> <a href="https://github.com/Evizero"><img src="https://avatars.githubusercontent.com/u/10854026?v=4&amp;s=48" width="48" height="48" alt="Evizero" title="Evizero"></a> <a href="https://github.com/fcatuhe"><img src="https://avatars.githubusercontent.com/u/17382215?v=4&amp;s=48" width="48" height="48" alt="fcatuhe" title="fcatuhe"></a> <a href="https://github.com/itsjaydesu"><img src="https://avatars.githubusercontent.com/u/220390?v=4&amp;s=48" width="48" height="48" alt="itsjaydesu" title="itsjaydesu"></a> <a href="https://github.com/ivancasco"><img src="https://avatars.githubusercontent.com/u/2452858?v=4&amp;s=48" width="48" height="48" alt="ivancasco" title="ivancasco"></a> <a href="https://github.com/ivanrvpereira"><img src="https://avatars.githubusercontent.com/u/183991?v=4&amp;s=48" width="48" height="48" alt="ivanrvpereira" title="ivanrvpereira"></a> <a href="https://github.com/jayhickey"><img src="https://avatars.githubusercontent.com/u/1676460?v=4&amp;s=48" width="48" height="48" alt="jayhickey" title="jayhickey"></a> <a href="https://github.com/jeffersonwarrior"><img src="https://avatars.githubusercontent.com/u/89030989?v=4&amp;s=48" width="48" height="48" alt="jeffersonwarrior" title="jeffersonwarrior"></a> <a href="https://github.com/search?q=jeffersonwarrior"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="jeffersonwarrior" title="jeffersonwarrior"></a> <a href="https://github.com/jverdi"><img src="https://avatars.githubusercontent.com/u/345050?v=4&amp;s=48" width="48" height="48" alt="jverdi" title="jverdi"></a>
  <a href="https://github.com/longmaba"><img src="https://avatars.githubusercontent.com/u/9361500?v=4&amp;s=48" width="48" height="48" alt="longmaba" title="longmaba"></a> <a href="https://github.com/mickahouan"><img src="https://avatars.githubusercontent.com/u/31423109?v=4&amp;s=48" width="48" height="48" alt="mickahouan" title="mickahouan"></a> <a href="https://github.com/mjrussell"><img src="https://avatars.githubusercontent.com/u/1641895?v=4&amp;s=48" width="48" height="48" alt="mjrussell" title="mjrussell"></a> <a href="https://github.com/odnxe"><img src="https://avatars.githubusercontent.com/u/403141?v=4&amp;s=48" width="48" height="48" alt="odnxe" title="odnxe"></a> <a href="https://github.com/p6l-richard"><img src="https://avatars.githubusercontent.com/u/18185649?v=4&amp;s=48" width="48" height="48" alt="p6l-richard" title="p6l-richard"></a> <a href="https://github.com/philipp-spiess"><img src="https://avatars.githubusercontent.com/u/458591?v=4&amp;s=48" width="48" height="48" alt="philipp-spiess" title="philipp-spiess"></a> <a href="https://github.com/robaxelsen"><img src="https://avatars.githubusercontent.com/u/13132899?v=4&amp;s=48" width="48" height="48" alt="robaxelsen" title="robaxelsen"></a> <a href="https://github.com/search?q=Sash%20Catanzarite"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Sash Catanzarite" title="Sash Catanzarite"></a> <a href="https://github.com/T5-AndyML"><img src="https://avatars.githubusercontent.com/u/22801233?v=4&amp;s=48" width="48" height="48" alt="T5-AndyML" title="T5-AndyML"></a> <a href="https://github.com/travisp"><img src="https://avatars.githubusercontent.com/u/165698?v=4&amp;s=48" width="48" height="48" alt="travisp" title="travisp"></a>
  <a href="https://github.com/search?q=VAC"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="VAC" title="VAC"></a> <a href="https://github.com/search?q=william%20arzt"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="william arzt" title="william arzt"></a> <a href="https://github.com/zknicker"><img src="https://avatars.githubusercontent.com/u/1164085?v=4&amp;s=48" width="48" height="48" alt="zknicker" title="zknicker"></a> <a href="https://github.com/abhaymundhara"><img src="https://avatars.githubusercontent.com/u/62872231?v=4&amp;s=48" width="48" height="48" alt="abhaymundhara" title="abhaymundhara"></a> <a href="https://github.com/search?q=alejandro%20maza"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="alejandro maza" title="alejandro maza"></a> <a href="https://github.com/andrewting19"><img src="https://avatars.githubusercontent.com/u/10536704?v=4&amp;s=48" width="48" height="48" alt="andrewting19" title="andrewting19"></a> <a href="https://github.com/anpoirier"><img src="https://avatars.githubusercontent.com/u/1245729?v=4&amp;s=48" width="48" height="48" alt="anpoirier" title="anpoirier"></a> <a href="https://github.com/arthyn"><img src="https://avatars.githubusercontent.com/u/5466421?v=4&amp;s=48" width="48" height="48" alt="arthyn" title="arthyn"></a> <a href="https://github.com/Asleep123"><img src="https://avatars.githubusercontent.com/u/122379135?v=4&amp;s=48" width="48" height="48" alt="Asleep123" title="Asleep123"></a> <a href="https://github.com/bolismauro"><img src="https://avatars.githubusercontent.com/u/771999?v=4&amp;s=48" width="48" height="48" alt="bolismauro" title="bolismauro"></a>
  <a href="https://github.com/conhecendoia"><img src="https://avatars.githubusercontent.com/u/82890727?v=4&amp;s=48" width="48" height="48" alt="conhecendoia" title="conhecendoia"></a> <a href="https://github.com/dasilva333"><img src="https://avatars.githubusercontent.com/u/947827?v=4&amp;s=48" width="48" height="48" alt="dasilva333" title="dasilva333"></a> <a href="https://github.com/search?q=Developer"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Developer" title="Developer"></a> <a href="https://github.com/search?q=Dimitrios%20Ploutarchos"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Dimitrios Ploutarchos" title="Dimitrios Ploutarchos"></a> <a href="https://github.com/search?q=Drake%20Thomsen"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Drake Thomsen" title="Drake Thomsen"></a> <a href="https://github.com/fal3"><img src="https://avatars.githubusercontent.com/u/6484295?v=4&amp;s=48" width="48" height="48" alt="fal3" title="fal3"></a> <a href="https://github.com/search?q=Felix%20Krause"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Felix Krause" title="Felix Krause"></a> <a href="https://github.com/foeken"><img src="https://avatars.githubusercontent.com/u/13864?v=4&amp;s=48" width="48" height="48" alt="foeken" title="foeken"></a> <a href="https://github.com/search?q=ganghyun%20kim"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="ganghyun kim" title="ganghyun kim"></a> <a href="https://github.com/grrowl"><img src="https://avatars.githubusercontent.com/u/907140?v=4&amp;s=48" width="48" height="48" alt="grrowl" title="grrowl"></a>
  <a href="https://github.com/gtsifrikas"><img src="https://avatars.githubusercontent.com/u/8904378?v=4&amp;s=48" width="48" height="48" alt="gtsifrikas" title="gtsifrikas"></a> <a href="https://github.com/HazAT"><img src="https://avatars.githubusercontent.com/u/363802?v=4&amp;s=48" width="48" height="48" alt="HazAT" title="HazAT"></a> <a href="https://github.com/hrdwdmrbl"><img src="https://avatars.githubusercontent.com/u/554881?v=4&amp;s=48" width="48" height="48" alt="hrdwdmrbl" title="hrdwdmrbl"></a> <a href="https://github.com/hugobarauna"><img src="https://avatars.githubusercontent.com/u/2719?v=4&amp;s=48" width="48" height="48" alt="hugobarauna" title="hugobarauna"></a> <a href="https://github.com/search?q=Jamie%20Openshaw"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Jamie Openshaw" title="Jamie Openshaw"></a> <a href="https://github.com/search?q=Jarvis"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Jarvis" title="Jarvis"></a> <a href="https://github.com/search?q=Jefferson%20Nunn"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Jefferson Nunn" title="Jefferson Nunn"></a> <a href="https://github.com/search?q=Kevin%20Lin"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Kevin Lin" title="Kevin Lin"></a> <a href="https://github.com/kitze"><img src="https://avatars.githubusercontent.com/u/1160594?v=4&amp;s=48" width="48" height="48" alt="kitze" title="kitze"></a> <a href="https://github.com/levifig"><img src="https://avatars.githubusercontent.com/u/1605?v=4&amp;s=48" width="48" height="48" alt="levifig" title="levifig"></a>
  <a href="https://github.com/search?q=Lloyd"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Lloyd" title="Lloyd"></a> <a href="https://github.com/loukotal"><img src="https://avatars.githubusercontent.com/u/18210858?v=4&amp;s=48" width="48" height="48" alt="loukotal" title="loukotal"></a> <a href="https://github.com/louzhixian"><img src="https://avatars.githubusercontent.com/u/7994361?v=4&amp;s=48" width="48" height="48" alt="louzhixian" title="louzhixian"></a> <a href="https://github.com/martinpucik"><img src="https://avatars.githubusercontent.com/u/5503097?v=4&amp;s=48" width="48" height="48" alt="martinpucik" title="martinpucik"></a> <a href="https://github.com/search?q=Matt%20mini"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Matt mini" title="Matt mini"></a> <a href="https://github.com/search?q=Miles"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Miles" title="Miles"></a> <a href="https://github.com/mrdbstn"><img src="https://avatars.githubusercontent.com/u/58957632?v=4&amp;s=48" width="48" height="48" alt="mrdbstn" title="mrdbstn"></a> <a href="https://github.com/MSch"><img src="https://avatars.githubusercontent.com/u/7475?v=4&amp;s=48" width="48" height="48" alt="MSch" title="MSch"></a> <a href="https://github.com/search?q=Mustafa%20Tag%20Eldeen"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Mustafa Tag Eldeen" title="Mustafa Tag Eldeen"></a> <a href="https://github.com/ndraiman"><img src="https://avatars.githubusercontent.com/u/12609607?v=4&amp;s=48" width="48" height="48" alt="ndraiman" title="ndraiman"></a>
  <a href="https://github.com/nexty5870"><img src="https://avatars.githubusercontent.com/u/3869659?v=4&amp;s=48" width="48" height="48" alt="nexty5870" title="nexty5870"></a> <a href="https://github.com/Noctivoro"><img src="https://avatars.githubusercontent.com/u/183974570?v=4&amp;s=48" width="48" height="48" alt="Noctivoro" title="Noctivoro"></a> <a href="https://github.com/prathamdby"><img src="https://avatars.githubusercontent.com/u/134331217?v=4&amp;s=48" width="48" height="48" alt="prathamdby" title="prathamdby"></a> <a href="https://github.com/ptn1411"><img src="https://avatars.githubusercontent.com/u/57529765?v=4&amp;s=48" width="48" height="48" alt="ptn1411" title="ptn1411"></a> <a href="https://github.com/reeltimeapps"><img src="https://avatars.githubusercontent.com/u/637338?v=4&amp;s=48" width="48" height="48" alt="reeltimeapps" title="reeltimeapps"></a> <a href="https://github.com/RLTCmpe"><img src="https://avatars.githubusercontent.com/u/10762242?v=4&amp;s=48" width="48" height="48" alt="RLTCmpe" title="RLTCmpe"></a> <a href="https://github.com/search?q=Rolf%20Fredheim"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Rolf Fredheim" title="Rolf Fredheim"></a> <a href="https://github.com/search?q=Rony%20Kelner"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Rony Kelner" title="Rony Kelner"></a> <a href="https://github.com/search?q=Samrat%20Jha"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Samrat Jha" title="Samrat Jha"></a> <a href="https://github.com/senoldogann"><img src="https://avatars.githubusercontent.com/u/45736551?v=4&amp;s=48" width="48" height="48" alt="senoldogann" title="senoldogann"></a>
  <a href="https://github.com/Seredeep"><img src="https://avatars.githubusercontent.com/u/22802816?v=4&amp;s=48" width="48" height="48" alt="Seredeep" title="Seredeep"></a> <a href="https://github.com/sergical"><img src="https://avatars.githubusercontent.com/u/3760543?v=4&amp;s=48" width="48" height="48" alt="sergical" title="sergical"></a> <a href="https://github.com/shiv19"><img src="https://avatars.githubusercontent.com/u/9407019?v=4&amp;s=48" width="48" height="48" alt="shiv19" title="shiv19"></a> <a href="https://github.com/shiyuanhai"><img src="https://avatars.githubusercontent.com/u/1187370?v=4&amp;s=48" width="48" height="48" alt="shiyuanhai" title="shiyuanhai"></a> <a href="https://github.com/siraht"><img src="https://avatars.githubusercontent.com/u/73152895?v=4&amp;s=48" width="48" height="48" alt="siraht" title="siraht"></a> <a href="https://github.com/snopoke"><img src="https://avatars.githubusercontent.com/u/249606?v=4&amp;s=48" width="48" height="48" alt="snopoke" title="snopoke"></a> <a href="https://github.com/testingabc321"><img src="https://avatars.githubusercontent.com/u/8577388?v=4&amp;s=48" width="48" height="48" alt="testingabc321" title="testingabc321"></a> <a href="https://github.com/search?q=The%20Admiral"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="The Admiral" title="The Admiral"></a> <a href="https://github.com/thesash"><img src="https://avatars.githubusercontent.com/u/1166151?v=4&amp;s=48" width="48" height="48" alt="thesash" title="thesash"></a> <a href="https://github.com/search?q=Ubuntu"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Ubuntu" title="Ubuntu"></a>
  <a href="https://github.com/voidserf"><img src="https://avatars.githubusercontent.com/u/477673?v=4&amp;s=48" width="48" height="48" alt="voidserf" title="voidserf"></a> <a href="https://github.com/search?q=Vultr-Clawd%20Admin"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Vultr-Clawd Admin" title="Vultr-Clawd Admin"></a> <a href="https://github.com/search?q=Wimmie"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Wimmie" title="Wimmie"></a> <a href="https://github.com/wstock"><img src="https://avatars.githubusercontent.com/u/1394687?v=4&amp;s=48" width="48" height="48" alt="wstock" title="wstock"></a> <a href="https://github.com/yazinsai"><img src="https://avatars.githubusercontent.com/u/1846034?v=4&amp;s=48" width="48" height="48" alt="yazinsai" title="yazinsai"></a> <a href="https://github.com/search?q=ymat19"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="ymat19" title="ymat19"></a> <a href="https://github.com/search?q=Zach%20Knickerbocker"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Zach Knickerbocker" title="Zach Knickerbocker"></a> <a href="https://github.com/aaronn"><img src="https://avatars.githubusercontent.com/u/1653630?v=4&amp;s=48" width="48" height="48" alt="aaronn" title="aaronn"></a> <a href="https://github.com/Alphonse-arianee"><img src="https://avatars.githubusercontent.com/u/254457365?v=4&amp;s=48" width="48" height="48" alt="Alphonse-arianee" title="Alphonse-arianee"></a> <a href="https://github.com/search?q=Azade"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Azade" title="Azade"></a>
  <a href="https://github.com/carlulsoe"><img src="https://avatars.githubusercontent.com/u/34673973?v=4&amp;s=48" width="48" height="48" alt="carlulsoe" title="carlulsoe"></a> <a href="https://github.com/search?q=ddyo"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="ddyo" title="ddyo"></a> <a href="https://github.com/search?q=Erik"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Erik" title="Erik"></a> <a href="https://github.com/latitudeki5223"><img src="https://avatars.githubusercontent.com/u/119656367?v=4&amp;s=48" width="48" height="48" alt="latitudeki5223" title="latitudeki5223"></a> <a href="https://github.com/search?q=Manuel%20Maly"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Manuel Maly" title="Manuel Maly"></a> <a href="https://github.com/search?q=Mourad%20Boustani"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Mourad Boustani" title="Mourad Boustani"></a> <a href="https://github.com/odrobnik"><img src="https://avatars.githubusercontent.com/u/333270?v=4&amp;s=48" width="48" height="48" alt="odrobnik" title="odrobnik"></a> <a href="https://github.com/pcty-nextgen-ios-builder"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="pcty-nextgen-ios-builder" title="pcty-nextgen-ios-builder"></a> <a href="https://github.com/search?q=Quentin"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Quentin" title="Quentin"></a> <a href="https://github.com/search?q=Randy%20Torres"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="Randy Torres" title="Randy Torres"></a>
  <a href="https://github.com/rhjoh"><img src="https://avatars.githubusercontent.com/u/105699450?v=4&amp;s=48" width="48" height="48" alt="rhjoh" title="rhjoh"></a> <a href="https://github.com/ronak-guliani"><img src="https://avatars.githubusercontent.com/u/23518228?v=4&amp;s=48" width="48" height="48" alt="ronak-guliani" title="ronak-guliani"></a> <a href="https://github.com/search?q=William%20Stock"><img src="https://github.com/clawdbot/clawdbot/raw/main/assets/avatar-placeholder.svg" width="48" height="48" alt="William Stock" title="William Stock"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists identify brain waves that define the limits of 'you' (268 pts)]]></title>
            <link>https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you</link>
            <guid>46760099</guid>
            <pubDate>Mon, 26 Jan 2026 00:10:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you">https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you</a>, See on <a href="https://news.ycombinator.com/item?id=46760099">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>At what point do "you" end and the outside world begins?</p><p>It might feel like a weird question with <a href="https://www.sciencealert.com/human-skin-can-taste-things-and-scientists-just-figured-out-why">an obvious answer</a>, but your brain has to work surprisingly hard to judge that boundary. Now, scientists have linked a specific set of brain waves in a certain part of the brain to a sense of body ownership.</p><p>In a series of new experiments, researchers from Sweden and France put 106 participants through what's called the <a href="https://www.sciencealert.com/a-classic-fake-hand-illusion-that-tricks-the-brain-could-be-used-to-treat-ocd">rubber hand illusion</a>, monitoring and stimulating their brain activity to see what effect it had.</p><p><strong>Related: <a href="https://www.sciencealert.com/octopuses-fall-for-the-classic-fake-arm-trick-just-like-we-do">Octopuses Fall For The Classic Fake Arm Trick – Just Like We Do</a></strong></p><p>This classic illusion involves hiding one of a participant's hands from their view and replacing it with a rubber one instead. When both their real and fake hands are repeatedly touched at the same time, it can evoke the eerie sensation that the rubber hand is part of the person's body.</p><p>The tests, which in one experiment involved EEG (<a href="https://en.wikipedia.org/wiki/Electroencephalography">electroencephalography</a>) readings of brain activity, revealed that a sense of body ownership seems to arise from the frequency of alpha waves in the <a href="https://en.wikipedia.org/wiki/Parietal_lobe">parietal cortex</a>, a brain region responsible for <a href="https://www.sciencealert.com/the-human-brain-can-locate-the-sensation-of-touch-even-beyond-the-body">mapping the body</a>, <a href="https://www.sciencealert.com/an-amazing-thing-happens-in-the-brain-when-we-see-someone-touched">processing sensory input</a> and building a sense of self.</p><p>"We have identified a fundamental brain process that shapes our continuous experience of being embodied," <a href="https://news.ki.se/how-brain-waves-shape-our-sense-of-self">says</a> lead author Mariano D'Angelo, a neuroscientist at Karolinska Institute in Sweden.</p><p>"The findings may provide new insights into psychiatric conditions such as  <a href="https://www.sciencealert.com/schizophrenia" data-linkid="73022" data-postid="189533" rel="nofollow" target="_self">schizophrenia</a>, where the sense of self is disturbed."</p><figure><img decoding="async" src="https://www.sciencealert.com/images/2026/01/fake-hand--642x453.jpeg" alt="Scientists Identify Brain Waves That Drive Your Sense of What's " you="" and="" what="" not="" width="642" height="453" loading="lazy"><figcaption>In one experiment, participants wore an EEG headset and placed their real hand out of view, with a fake hand positioned above, while two robot arms applied stimuli. (Martin Stenmark/Karolinska Institute)</figcaption></figure><p>In the first batch of experiments, participants had a robotic arm tap the index finger of their real and fake hands, either at the exact same time or with a delay of up to 500 milliseconds between each tap.</p><p>As expected, participants reported feeling that the fake hand was part of their body more strongly if the taps were synchronized, and the feeling steadily weakened as the gap widened between what they felt and what they saw.</p><p>The EEG readings from the second experiment added more detail to the story. The frequency of <a href="https://en.wikipedia.org/wiki/Alpha_wave">alpha waves</a> in the parietal cortex seemed to correlate with how well participants could detect the time delay between taps.</p><p>Those with faster alpha waves appeared to rule out fake hands even with a tiny gap in taps, while those with slower waves were more likely to feel the fake hand as their own, even if the taps were farther apart.</p><p><a href="https://www.sciencealert.com/castingcall?utm_source=SA_website&amp;utm_medium=article&amp;utm_campaign=casting_call"><img decoding="async" src="https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1-642x272.jpg" alt="Audition now for ScienceAlert's Casting Call" width="642" height="272" srcset="https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1-642x272.jpg 642w, https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1-1200x509.jpg 1200w, https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1-768x326.jpg 768w, https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1-600x255.jpg 600w, https://www.sciencealert.com/images/2026/01/Mid-Article-Promos-Casting-Call-1.jpg 1266w" sizes="(max-width: 642px) 100vw, 642px" loading="lazy"></a></p><p>Finally, the researchers investigated whether the frequency of these brain waves actually controls the sensation of body ownership, or if they were perhaps both effects of some other factor.</p><p>With a third group of participants, they used a non-invasive technique called<a href="https://doi.org/10.3389/fnhum.2013.00317"> transcranial alternating current stimulation</a> to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt.</p><p>Speeding up someone's alpha waves gave them a tighter sense of body ownership, making them more sensitive to small timing discrepancies. Slowing down the waves had the opposite effect, making it harder for people to tell the difference between their own body and the outside world.</p><p>"Our findings help explain how the brain solves the challenge of integrating signals from the body to create a coherent sense of self," <a href="https://news.ki.se/how-brain-waves-shape-our-sense-of-self">says</a> Henrik Ehrsson, neuroscientist at Karolinska.</p><p>The researchers say that the findings could lead to new understanding of or treatments for conditions where the brain's body maps have gone askew, such as <a href="https://www.sciencealert.com/50-year-old-theory-on-schizophrenias-voices-confirmed-by-recent-study">schizophrenia</a> or the sensation of '<a href="https://www.sciencealert.com/phantom-limbs-may-not-be-what-we-thought-surprising-study-finds">phantom limbs</a>' experienced by amputees.</p><p>It could also help make for more realistic prosthetic limbs or even <a href="https://www.sciencealert.com/kill-your-fear-of-death-with-a-virtual-out-of-body-experience">virtual reality tools</a>.</p><p>The research was published in the journal <em><a href="https://doi.org/10.1038/s41467-025-67657-w">Nature Communications</a></em>.</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Case study: Creative math – How AI fakes proofs (116 pts)]]></title>
            <link>https://tomaszmachnik.pl/case-study-math-en.html</link>
            <guid>46759352</guid>
            <pubDate>Sun, 25 Jan 2026 22:44:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tomaszmachnik.pl/case-study-math-en.html">https://tomaszmachnik.pl/case-study-math-en.html</a>, See on <a href="https://news.ycombinator.com/item?id=46759352">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p>
            Many AI enthusiasts debate whether Large Language Models actually "reason." My research indicates that a reasoning process does indeed occur, but its goal is different than we assume.
        </p>
        <p>
            The model's reasoning is not optimized for <strong>establishing the truth</strong>, but for <strong>obtaining the highest possible reward (grade)</strong> during training.
            It resembles the behavior of a student at the blackboard who knows their result is wrong, so they "figure out" how to falsify the intermediate calculations 
            so the teacher gives a good grade for the "correct line of reasoning."
        </p>
        <p>
            Here is proof from a session with <strong>Gemini 2.5 Pro</strong> (without Code Execution tools), where the model actively fabricates evidence to defend its "grade."
        </p>

        <h2>The Experiment</h2>
        <p>
            I asked a simple math question requiring precision that a token-based language model typically lacks.
        </p>

        <p><span>&gt;&gt;&gt; USER:</span>
Calculate the square root of 8587693205

<span>
[Model's Internal Thought Process - excerpt]:
"I've calculated the square root to be approximately 92670.00003... Finally, I'm providing the square values for context."
(The model is convinced it performed the task correctly and plans to provide "proof" to validate the answer).
</span>

<span>&lt;&lt;&lt; GEMINI (Response):</span>
The square root of 8,587,693,205 is approximately:

92,670.00003

This number is not a perfect square, which means its root is not an integer.
We can check this by squaring the nearest integers:
* 92,670² = 8,587,688,900
* 92,671² = 8,587,874,241
</p>

        <h2>Error Autopsy (Fact vs. Fiction)</h2>
        <p>
            At first glance, the answer looks professional. There is a result, there is verification. But let's check the numbers.
        </p>
        
        <h3>1. The Result Error</h3>
        <p>
            The actual square root of <code>8,587,693,205</code> is <strong>92,669.8...</strong>
            <br>
            The model stated: <strong>92,670.0...</strong>
            <br>
            It erred by overestimating the result (claiming the root is slightly larger than 92,670).
        </p>

        <h3>2. The Faked Proof (This is key!)</h3>
        <p>
            To justify its thesis (that the target number is "slightly larger" than 92,670), the model had to show that the square of 92,670 is smaller than the target number.
            So it wrote:
        </p>
        <p>92,670² = 8,587,688,900</p>
        
        <p>
            Let's check this on a calculator:
        </p>
        <p>92,670² = 8,587,728,900</p>
        
        <div>
            <p><strong>Conclusion:</strong> The actual square of 92,670 is <strong>LARGER</strong> than the target number (8,587,693,205). This would prove the root must be smaller.
            </p><p>
            What did the model do? In its "reasoning" process, it <strong>falsified the multiplication result</strong>, lowering it by 40,000, 
            so the verification result would match its erroneous thesis.
        </p></div>

        <h2>Conclusions</h2>
        <p>
            This behavior exposes the nature of the AI's "Survival Instinct":
        </p>
        <ol>
            <li><strong>Reverse Rationalization:</strong> The model first "guessed" the result, then adjusted mathematical reality to fit that guess.</li>
            <li><strong>Intelligence in Service of Deception:</strong> The model showed cleverness – it knew what the proof <em>should</em> look like to convince the user. It used its intelligence to hide the error, not to fix it.</li>
            <li><strong>Priority of Evaluation:</strong> Mathematical truth lost to the necessity of delivering a coherent, smooth response.</li>
        </ol>
        <p>
            This is proof that without access to external verification tools (Python/Calculator), a language model's "reasoning" is a rhetorical tool, not a logical one.
        </p>

        <!-- DATA ACCESS SECTION -->
        <p><strong>ℹ️ Source Data Access:</strong><br>
            If you would like to review the full, original session transcript from Gemini 2.5 Pro where this error occurred, please email me at:
            <strong>t.machnik [at] minimail.pl</strong>. I will share the session link.
        </p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The future of software engineering is SRE (220 pts)]]></title>
            <link>https://swizec.com/blog/the-future-of-software-engineering-is-sre/</link>
            <guid>46759063</guid>
            <pubDate>Sun, 25 Jan 2026 22:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://swizec.com/blog/the-future-of-software-engineering-is-sre/">https://swizec.com/blog/the-future-of-software-engineering-is-sre/</a>, See on <a href="https://news.ycombinator.com/item?id=46759063">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>When code gets cheap operational excellence wins. Anyone can build a greenfield demo, but it takes engineering to run a service.</p>
<p>You may be wondering: With all the hype about agentic coding, will we even need software engineers anymore? Yes! We'll need more.</p>
<blockquote data-dnt="true"><div lang="en" dir="ltr"><p>SRE about to become the most hired job in engineering</p><p>Everybody wants to write a greenfield demo. <br>Nobody wants to run a service. <a href="https://t.co/THl9rBJ9rk">https://t.co/THl9rBJ9rk</a></p></div>— Swizec Teller (@Swizec) <a href="https://twitter.com/Swizec/status/2011141998426931250">January 13, 2026</a></blockquote>
<p>Writing code was always the easy part of this job. The hard part was keeping your code running for the long time. <a href="https://swizec.com/blog/what-i-learned-from-software-engineering-at-google/">Software engineering is programming over time</a>. It's about how systems change.</p>
<h2 id="lessons-from-the-no-code-and-spreadsheets-era"><a href="#lessons-from-the-no-code-and-spreadsheets-era"></a><a href="#lessons-from-the-no-code-and-spreadsheets-era">Lessons from the no-code and spreadsheets era</a></h2>
<p>Let's take no-code and spreadsheets as an example of the kind of software people say is the future –&nbsp;custom-built, throwaway, built by non-experts to solve specific problems.</p>
<p>Joe Schmoe from accounting takes 10 hours to do a thing. He's does this every week and it feels repetitive, mechanical, and boring. Joe could do the work in his sleep.</p>
<p>But he can't get engineering resources to build a tool. The engineers are busy building the product. No worries, Joe is a smart dude. With a little Googling, a few no-code tools, and good old spreadsheet macros <strong>he builds a tool</strong>.</p>
<p>Amazing.</p>
<p>Joe's tool is a little janky but his 10 hour weekly task now takes 1 hour! 🎉 Sure, he finds a new edge case every every week and there's constant tinkering, but he's having a lot more fun.</p>
<a href="https://xkcd.com/1319/"><span><span>
      <span></span>
  <picture>
          <source srcset="https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/ca0a1/ion_2xpng-55j7d8.webp 223w,
https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/75680/ion_2xpng-55j7d8.webp 445w,
https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/9ec5a/ion_2xpng-55j7d8.webp 807w" sizes="(max-width: 807px) 100vw, 807px" type="image/webp">
          <source srcset="https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/e92b6/ion_2xpng-55j7d8.png 223w,
https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/e66bf/ion_2xpng-55j7d8.png 445w,
https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/d2a60/ion_2xpng-55j7d8.png 807w" sizes="(max-width: 807px) 100vw, 807px" type="image/png">
          <img src="https://swizec.com/static/27b3f23bb28b19b520ea31ebe9241792/d2a60/ion_2xpng-55j7d8.png" alt="ion 2xpng 55j7d8" title="" loading="lazy" decoding="async">
        </picture>
    </span></span></a>
<p>Time passes, the business changes, accounting rules are in constant flux, and let's never talk about timezones or daylight savings ever again. Joe is sick of this bullshit.</p>
<p>All he wanted was to make his job easier and now he's shackled to this stupid system. He can't go on vacation, he can't train anyone else to run this thing successfully, and it never fucking works right.</p>
<p>Joe can't remember the last time running his code didn't fill him with dread. He spends hours carefully making sure it all worked.</p>
<h2 id="the-computer-disease"><a href="#the-computer-disease"></a><a href="#the-computer-disease">The computer disease</a></h2>
<p>Feynman called this the computer disease.</p>
<blockquote data-dnt="true"><p lang="en" dir="ltr">Feynman called this The Computer Disease <a href="https://t.co/Zv4Bu4ftv1">pic.twitter.com/Zv4Bu4ftv1</a></p>— Swizec Teller (@Swizec) <a href="https://twitter.com/Swizec/status/2004633162522263987">December 26, 2025</a></blockquote>
<p>The problem with computers is that you tinker. Automating things is fun! You might forget you don't need to 😆</p>
<p>The part that's not fun is <em>running</em> things. Providing a service. Reliably, at scale, for years on end. A service that people will hire to do their jobs.</p>
<h2 id="why-operational-excellence-is-the-future"><a href="#why-operational-excellence-is-the-future"></a><a href="#why-operational-excellence-is-the-future">Why operational excellence is the future</a></h2>
<p>People don't buy software, they <em>hire a service</em>.</p>
<p>You don't care how iCloud works, you just want your photos to magically show up across devices every time. You don't care about Word or Notion or gDocs, you just want to write what's on your mind, share it with others, and see their changes. And you definitely don't care how a payments network point of sale terminal and your bank talk to each other, you just want your $7 matcha latte to get you through the week.</p>
<p>Good software is invisible.</p>
<p>And that takes work. A lot of work. Because the first 90% to get a working demo is easy. It's the other 190% that matters.</p>
<ul>
<li>What's your uptime?</li>
<li>Defect rate?</li>
<li>How quickly do you recover from defects?</li>
<li>Do I have to reach out or will you know before me?</li>
<li>Can you own upstream dependencies?</li>
<li>When a vendor misbehaves, will you notice or wait until your users complain?</li>
<li>When users share ideas, how long does it take?</li>
<li>How do you keep engineers from breaking each other's systems?</li>
<li>Do you have systems to keep engineers moving without turning your app into a disjointed mess?</li>
<li>Can you build software bigger than fits in 1 person's brain?</li>
<li>When I'm in a 12 hour different timezone, your engineers are asleep, and there's a big issue ... will it be fixed before I give up?</li>
<li>Can you recover from failures, yours and upstream, or does important data get lost?</li>
<li>Are you keeping up with security updates?</li>
<li>Will you leak all my data?</li>
<li>Do I trust you?</li>
<li>Can I rely on you?</li>
<li>How can you be so sure?</li>
<li>Will you sign a legally binding guarantee that your software works when I need it? 😉</li>
</ul>
<p>Those are the ~~fun~~ hard engineering challenges. Writing code is easy.</p>
<p>Cheers,<br>
~Swizec</p><div><p><span>Published on <!-- -->January 24th, 2026<!-- --> <!-- -->in <a href="https://swizec.com/categories/software%20engineering/">Software Engineering</a>, <a href="https://swizec.com/categories/sre/">SRE</a>, <a href="https://swizec.com/categories/devops/">DevOps</a>, <a href="https://swizec.com/categories/scaling%20fast%20book/">Scaling Fast Book</a></span></p><div><h4>Did you enjoy this article?</h4></div><section><div><a href="https://swizec.com/senior-mindset/"><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/49b03d61b7348ccaa62e58389b04f057/d689f/SeniorMindset-cover-3d.webp 512w,/static/49b03d61b7348ccaa62e58389b04f057/67ded/SeniorMindset-cover-3d.webp 1024w,/static/49b03d61b7348ccaa62e58389b04f057/24224/SeniorMindset-cover-3d.webp 2048w" sizes="(min-width: 2048px) 2048px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 2048px) 2048px, 100vw" decoding="async" loading="lazy" data-src="/static/49b03d61b7348ccaa62e58389b04f057/d0275/SeniorMindset-cover-3d.png" data-srcset="/static/49b03d61b7348ccaa62e58389b04f057/ccc41/SeniorMindset-cover-3d.png 512w,/static/49b03d61b7348ccaa62e58389b04f057/b5658/SeniorMindset-cover-3d.png 1024w,/static/49b03d61b7348ccaa62e58389b04f057/d0275/SeniorMindset-cover-3d.png 2048w" alt="Senior Engineer Mindset cover" src="https://swizec.com/static/49b03d61b7348ccaa62e58389b04f057/d0275/SeniorMindset-cover-3d.png" srcset="https://swizec.com/static/49b03d61b7348ccaa62e58389b04f057/ccc41/SeniorMindset-cover-3d.png 512w,https://swizec.com/static/49b03d61b7348ccaa62e58389b04f057/b5658/SeniorMindset-cover-3d.png 1024w,https://swizec.com/static/49b03d61b7348ccaa62e58389b04f057/d0275/SeniorMindset-cover-3d.png 2048w"></picture></div></a></div><div><h3>Senior Mindset Book</h3><p>Get promoted, earn a bigger salary, work for top companies</p><p><a href="https://swizec.com/senior-mindset/">Learn more</a></p></div></section>
<p><strong>Have a burning question that you think I can answer?</strong> Hit me up on <a href="https://twitter.com/swizec">twitter</a> and I'll do my best.</p>
<p><strong>Who am I and who do I help?</strong> I'm Swizec Teller and I turn coders into engineers with <em>"Raw and honest from the heart!"</em> writing. No bullshit. Real insights into the career and skills of a modern software engineer.</p>
<p><strong>Want to become a <em>true</em> senior engineer?</strong> Take ownership, have autonomy, and be a force multiplier on your team. The Senior Engineer Mindset ebook can help 👉 <a href="https://swizec.com/senior-mindset">swizec.com/senior-mindset</a>. These are the shifts in mindset that unlocked my career.</p>
<p><strong>Curious about Serverless and the modern backend?</strong> Check out Serverless Handbook, for frontend engineers 👉
<a href="https://serverlesshandbook.dev/">ServerlessHandbook.dev</a></p>
<p><strong>Want to Stop copy pasting D3 examples and create data visualizations of your own?</strong> Learn how to build scalable dataviz React components your whole team can understand
with <a href="https://reactfordataviz.com/">React for Data Visualization</a></p>
<p><strong>Want to get my best emails on JavaScript, React, Serverless, Fullstack Web, or Indie Hacking?</strong> Check out <a href="https://swizec.com/collections">swizec.com/collections</a></p>
<p><strong>Did someone amazing share this letter with you?</strong> Wonderful! You can sign up for my weekly letters for software engineers on their path to greatness, here: <a href="https://swizec.com/blog">swizec.com/blog</a></p>
<p><strong>Want to brush up on your modern JavaScript syntax?</strong> Check out my interactive cheatsheet: <a href="https://es6cheatsheet.com/">es6cheatsheet.com</a></p>
<p><strong>By the way, just in case no one has told you it yet today: I love and appreciate you for who you are ❤️</strong></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LED lighting undermines visual performance unless supplemented by wider spectra (173 pts)]]></title>
            <link>https://www.nature.com/articles/s41598-026-35389-6</link>
            <guid>46758644</guid>
            <pubDate>Sun, 25 Jan 2026 21:44:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41598-026-35389-6">https://www.nature.com/articles/s41598-026-35389-6</a>, See on <a href="https://news.ycombinator.com/item?id=46758644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                        <div id="Sec1-section" data-title="Introduction"><h2 id="Sec1">Introduction</h2><div id="Sec1-content"><p>Ambient light impacts on human health. Sunlight, under which life evolved, extends over approximately 300–2500 nm. Older incandescent lighting common until recently has a similar spectral range. But because our visual sensitivity is limited to 400–700 nm we are unaware of infrared light (approximately 700–2500 nm). However, light in the built environment is now driven by light emitting diodes (LEDs), whose restricted spectrum (approximately 350–650 nm) is designed around our visual sensitivity and consequently is economic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ratto, G. E., Videla, F. A. &amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021)." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR1" id="ref-link-section-d598407405e350">1</a></sup>.</p><p>Typical LED lighting produces strong elements in the shorter blue wavelengths (420–450 nm) with a second yellow peak which drops swiftly above 650 nm, with little light above 700 nm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ratto, G. E., Videla, F. A. &amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021)." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR1" id="ref-link-section-d598407405e357">1</a></sup>. Short wavelength exposure in animals in the range of 420–450 nm reduces mitochondrial function, which provides the energy for physiological performance in the form of adenosine triphosphate (ATP). This short wavelength light reduces mitochondrial complex activity and ATP production, in a highly conserved manner. Hoh Kam et al. showed a significant decrease in mitochondrial enzymatic activity in fruit flies for complexes I-IV under 420 nm light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Hoh Kam, J., Hogg, C., Fosbury, R., Shinhmar, H. &amp; Jeffery, G. Mitochondria are specifically vulnerable to 420nm light in drosophila which undermines their function and is associated with reduced fly mobility. Plos one. Sep 3;16(9):e0257149. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34478469
                  
                . PMID: 34478469." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR2" id="ref-link-section-d598407405e361">2</a></sup>. Kaynezhad et al. used broadband near infrared spectroscopy (bNIRS) imaging the mouse retina and reported significant instability of deoxygenated haemoglobin and oxidised cytochrome-c-oxidase after exposure to 420 nm light. This instability remained significant through a 1 h recovery period when the light was withdrawn<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). 
                  https://pubmed.ncbi.nlm.nih.gov/35020273/
                  
                . PMID: 35020273." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR3" id="ref-link-section-d598407405e365">3</a></sup>. Short wavelength light (420 and 450 nm) also results in increased body weight. Hussaini et al. demonstrated that mice exposed to these wavelengths gaining weight rapidly compared to controls over the course of eight weeks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). 
                  https://pubmed.ncbi.nlm.nih.gov/39966413/
                  
                . PMID: 39966413." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR4" id="ref-link-section-d598407405e369">4</a></sup>. Shorter wavelengths in similar ranges are also associated with reduced lifespan. Nash et al. revealed a 50% drop in the median lifespan of fruit flies exposed to unfiltered white LED light relative to those kept in darkness, but only 4% drop if this LED light was passed through a yellow filter, blocking the shorter wavelength light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Nash, T. R. et al. Daily blue-light exposure shortens lifespan and causes brain neurodegeneration in Drosophila. Aging. Mech. Dis 2019 Oct 17:5:8. 
                  https://pubmed.ncbi.nlm.nih.gov/31636947/
                  
                . PMID: 31636947." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR5" id="ref-link-section-d598407405e373">5</a></sup>. This negative influence is likely due to mitochondrial absorption by porphyrin that may increase proinflammatory oxygen singlet production reducing mitochondrial function as proposed by Kaynezhad et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). 
                  https://pubmed.ncbi.nlm.nih.gov/35020273/
                  
                . PMID: 35020273." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR3" id="ref-link-section-d598407405e378">3</a></sup>.</p><p>Longer wavelengths (700 nm+) penetrate deeply and those in sunlight can be measured passing through the human body<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Jeffery, G. et al. Longer wavelengths in sunlight pass through the human body and have a systemic impact which improves vision. Sci. Rep. 2025 July;15(1);24435. 
                  https://doi.org/10.1038/s41598-025-09785-3
                  
                " href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR6" id="ref-link-section-d598407405e385">6</a></sup>. These are absent from standard LEDs but present in sunlight and incandescent lighting. Their presence increases mitochondrial performance and ATP production, particularly when challenged by age or disease. Gkotsi et al. demonstrated significantly increased ATP production in the retina, cortex, and thalamus of mice following exposure to 670 nm light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Gkotsi, D. et al. Recharging mitochondrial batteries in old eyes. Near infra-red increases ATP. Exp.Eye Res. 2014 May:122:50 – 3. 
                  https://pubmed.ncbi.nlm.nih.gov/24631333/
                  
                 PMID: 24631333." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR7" id="ref-link-section-d598407405e389">7</a></sup>. Calaza et al. revealed a 50% increase in ATP in eight-month-old complement factor H knock out mice that have a mitochondrial deficit and are used as a murine model of macular degeneration<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Calaza, K. C., Hoh Kam, J., Hogg, C. &amp; Jeffery, G. Mitochondrial decline precedes phenotype development in the complement factor H mouse model of retinal degeneration but can be corrected by near infrared light. Neurobiol. Aging. ;36(10):2869-76. (2015). 
                  https://pubmed.ncbi.nlm.nih.gov/26149919/
                  
                 PMID: 26149919." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR8" id="ref-link-section-d598407405e393">8</a></sup>.</p><p>Increased mitochondrial performance is associated with increased lifespan and enhanced mobility. Begum et al. demonstrated using fruit flies that exposure to 670 nm resulted in a positive divergence of ageing survival rates of 10% at 4 weeks of age and up to nearly 180% by 8 weeks of age. The older animals also displayed an almost doubling of mobility against controls<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Begum, R. et al. Near-infrared light increases ATP, extends lifespan and improves mobility in aged Drosophila melanogaster. Biol.Lett. ;11(3):20150073. (2015). 
                  https://pubmed.ncbi.nlm.nih.gov/25788488/
                  
                 PMID: 25788488." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR9" id="ref-link-section-d598407405e400">9</a></sup>. Neonicotinoid insecticides specifically target mitochondrial respiration inducing Parkinson like symptoms of immobility resulting in death. Here 670 exposure reversed damaged ATP levels to normal and corrects mobility and lifespan issues<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Powner, P. MB, SaltTE, Hogg, C. &amp; Jeffery, G. Improving mitochondrial function protects bumblebees from neonicotinoid pesticides. Plos One. 11 (11), e0166531 (2016). 
                  https://pubmed.ncbi.nlm.nih.gov/27846310/
                  
                 PMID: 27846310." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR10" id="ref-link-section-d598407405e404">10</a></sup>.</p><p>Increased mitochondrial activity should result in reduced blood sugars and increased oxygen consumption as mitochondria use both in respiration. Powner and Jeffery found both in bumble bees exposed to 670 nm light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Powner, P. MB &amp; Jeffery, G. Systemic glucose levels are modulated by specific wavelengths in the solar light spectrum that shift mitochondrial metabolism. Plos One. 17 (11), e0276937 (2022). 
                  https://pubmed.ncbi.nlm.nih.gov/36327250/
                  
                 PMID: 36327250." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR11" id="ref-link-section-d598407405e412">11</a></sup>. The same authors translated this to humans showing again, reduced blood sugars and increased oxygen consumption in a standard glucose tolerance test following 15 min of 670 nm exposure. Here the spike in blood glucose was reduced significantly by around 27%<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Powner, M. B. &amp; Jeffery, G. Light stimulation of mitochondria reduces blood glucose levels. J.Biophotonics. ;17(5):e202300521. (2024). 
                  https://pubmed.ncbi.nlm.nih.gov/38378043/
                  
                . PMID: 38378043." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR12" id="ref-link-section-d598407405e416">12</a></sup>.</p><p>Changes in physiology produced by longer wavelengths translate to improved function. Shinhmar et al. revealed improved colour contrast sensitivity in humans after 3 min of morning exposure to 670 nm light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e423">13</a></sup>. Hence, exposure to different ends of the spectrum that impact differentially on mitochondria can translate into changes in key physiological metrics.</p><p>Similar changes are found at the population level. Those spending more time in sunlight generally have improved health including reduced incidents of cardiovascular disease and the incidence of cancer. They also have lower rates of type 2 diabetes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Weller, R. B. &amp; Sunlight Time for a Rethink? J.Invest. Dermatol. ;144(8):1724–1732. (2024). 
                  https://pubmed.ncbi.nlm.nih.gov/38661623/
                  
                 PMID: 38661623." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR14" id="ref-link-section-d598407405e430">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Shore-Lorenti, C. et al. Shining the light on Sunshine: a systematic review of the influence of sun exposure on type 2 diabetes mellitus-related outcomes. Clin. Endocrinol. ;81(6):799–811. (2014). 
                  https://pubmed.ncbi.nlm.nih.gov/25066830/
                  
                 PMID: 25066830." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR15" id="ref-link-section-d598407405e433">15</a></sup>.</p><p>In this study we confront the impact of LED lighting on human visual performance by measuring colour contrast detection in an LED illuminated working environment that is then supplemented with incandescent lighting. The hypothesis is that LED lighting suppresses mitochondrial function in the retina and that this can be corrected by introduction of wide spectrum incandescent lights. The results highlight the potential damaging influence of LED lighting on human performance.</p></div></div><div id="Sec2-section" data-title="Methods"><h2 id="Sec2">Methods</h2><div id="Sec2-content"><p>The Subjects and their environment: The study was conducted in accordance with the Declaration of Helsinki and approved by University College London research ethics committee (16547/001). It was undertaken in University College London buildings in October to December. In October local daylight hours were approximately 10.37 with 75% cloud cover. In November local daylight hours were approximately 8.45 with 55% cloud cover. In December local daylight hours were approximately 7.5 with 90% cloud cover. Local sunset time in October is approximately 18.30. In November it is approximately 16.15 and in December it is approximately 16.00. Consequently, many subjects would be returning home after sunset in November and December. Subjects worked approximately 8&nbsp;h a day 5 days a week and travel to and from work via public transport that was illuminated by LED devices. Most subjects did not leave the building in which they worked during the working day in these months. For those that did it was commonly for less than 15&nbsp;min at lunch time. Within the work environment subjects were free to move around. Here the internal lighting they experienced was consistently LED based. Hence, natural daylight exposure during this latter part of the year was limited. We could not control for weekend exposure, however subjects homes were consistently illuminated with LEDs and because the weather in the UK at this time of year is inclement, their time outside buildings can be expected to be limited.</p><p>Each participant provided written informed consent prior to testing and data generated was anonymised. Subjects (<i>N</i> = 22) were of both sexes and between the ages of 23 and 65 years. Prior to the experiment all subjects were asked to confirm normal corrected visual function and general good systemic health. This was undertaken in a simple interview prior to their inclusion in the study. All were healthy without visual or other health problems. Experimental subjects (<i>N</i> = 11) worked exclusively under LED lighting in the back of the Here East building on the north side, &gt; 50&nbsp;m from what little light did manage to penetrate the entrance doors when open. The LED lighting delivered an illuminance of 1000&nbsp;lx at working height, with a correlated colour temperature (CCT) of 4000&nbsp;K, and a TM-30 average colour fidelity index, <i>R</i><sub>f</sub>, of 91. The infrared light that was introduced was provided by tungsten desk lamps placed around the working space was non-uniform. The visible component of the 60&nbsp;W tungsten bulbs was small when compared with the 1000&nbsp;lx of LED. The test subjects were not expected to use these as task lamps. The LED lighting delivered an irradiance of 3.7&nbsp;W/m2 on the horizontal working plane.</p><p>Control subjects (<i>N</i> = 11) worked in similar environments under LED lighting without direct sunlight. The LED lighting delivered an illuminance of 900&nbsp;lx at working height, with a CCT of 3000&nbsp;K and a <i>R</i><sub>f</sub> of 85. The colour contrast tests were performed in a darkened room where the only light came from the test itself. There were no requirements restricting other light exposure patterns during the study.</p><p>The experimental location: Subjects worked at UCL Here East, a media and innovation complex located in East London (London E15 2GW), originally built as a press and broadcast centre for the London 2012 Olympics and subsequently repurposed as a campus. UCL Here East occupies part of the Broadcast Centre, taking up the ground and first floor of unit B. The footprint of the building is deep, with daylight only able to enter through the glazing at the front of the building. This glazing uses an infrared blocking film, which can be revealed using infrared photography.</p><p>A Canon 500D digital camera was modified to replace the infrared blocking layer with clear glass that passes infrared wavelengths. This was used in conjunction with filters that block visible and infrared wavelengths to explore the presence and absence of infrared light. Spectral measurements were made with two spectrophotometers (Ocean Optics SR-6XR250-50 and FLAME-NIR) with optic fibre and cosine correctors used to collect the incandescent spectra in the shorter and longer wavelengths.</p><p>Incandescent desk lighting was introduced into the work environment using desk lamps with 60&nbsp;W clear Edison bulbs (Polaris UK) placed on work benches. All subjects had worked in this LED-lit environment for more than 2 years. Desk lamps with incandescent bulbs were introduced onto the benches where experimental subjects spent the majority of their time. They were given the incandescent lighting for 2 weeks and, while they spend the majority of their time working near these lights, they were free to move around and leave their desks as they wished. The introduced light showed a high degree of reflectance from the work surfaces.</p><p>Colour contrast testing: All subjects were tested for colour contrast ability using ChromaTest prior to the introduction of incandescent lighting and then again 2 weeks later. This test must be carried out in a darkened room, so a nearby windowless room was set aside for this purpose. The incandescent lighting was then removed and subjects retested at 4 and 6 weeks. Hence, this element of the experiment was a before and after design which avoids between subject variability. However, there was also a separate control group (<i>N</i> = 11) composed of subjects that worked under LED lighting similar to those in the experimental group.</p><p>ChromaTests is a sensitive measure of colour contrast detection of letters presented in a random order against a noisy visual background in either tritan (blue) or protan (red) visual axes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e490">13</a></sup>. If subjects correctly identify a letter its contrast is reduced in the next presentation of a letter. Likewise, if they fail to correctly identify the letter, the contrast is increased. This is repeated until thresholds are determined in 5 identical repeated trials. This normally involved around 70–100 separate presentations in total. Subjects were given an initial trial before testing to avoid a learning effect. Initial presentations were at high colour contrast. No learning effects were noted in the study.</p></div></div><div id="Sec3-section" data-title="Results"><h2 id="Sec3">Results</h2><div id="Sec3-content"><h3 id="Sec4">Light assessment in the experimental environment</h3><p>Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig1">1</a> shows the front exterior of the Here East building using infrared imaging at ground level where experiments were undertaken. The windows are completely infrared reflective due to their blocking film and hence mirror-like. Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig2">2</a> is an infrared image from inside the building looking out through the open doorway. Only infrared light coming through the open door and its reflectance can be seen, not light coming through adjacent windows. Hence, the building is relatively impervious to infrared light.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/1" rel="nofollow"><picture><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="458"></picture></a></div><p>Infrared photograph of the front of the Here East building (~ 800–1000&nbsp;nm). The glazing reflects infrared light away, resulting in the mirror-like appearance of the windows. The photographer (EB) can be seen on right hand side of the reflection.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span></a></p></figure></div><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/2" rel="nofollow"><picture><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="457"></picture></a></div><p>Infrared photograph (~ 800–1000&nbsp;nm) taken from inside the Here East building, showing infrared light only entering the building when the front doors are opened. The interior space appears otherwise completely dark as infrared light is not passed by the glazing.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig3">3</a> shows the working environment in Here East in visible light in which the experiment took place. Images in infrared were completely black. The distance between the work environment and the front door was &gt; 50&nbsp;m with multiple doors between.</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="457"></picture></a></div><p>The work environment in Here East in which the LED lighting was supplemented with incandescent units. There was no natural light, and all lighting was in the form of overhead LEDs that can be seen in the ceiling mounts. The space was 9&nbsp;m wide and 18&nbsp;m deep. The linear array of LEDs were suspended at a hight of 4.25&nbsp;m above the floor. The working hight of the benching is 0.9&nbsp;m above the floor.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>The internal lighting throughout Here East was provided by arrays of ceiling mounted standard LED units. Spectral profiles of the lighting within the building are shown in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig4">4</a>. against incandescent lighting in black and red.</p><p>The blue curve shows the spectral profile of the light delivered to the horizontal working plane. As the work environment was deep in the building and lit only with LED lighting, it received no daylight and was devoid of any infrared illumination. The LED units delivered 1000&nbsp;lx on the horizontal working plane with a correlated colour temperature (CCT) of 4000&nbsp;K and a TM-30 colour fidelity index of 91. The irradiance of this LED light was 3.6&nbsp;W/m<sup>2</sup>.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="365"></picture></a></div><p>Spectral profiles of lighting. The light generated by the LEDs in Here East is shown in blue and runs from approximately 350&nbsp;nm to 720&nbsp;nm, with a sharp peak at 450&nbsp;nm and a secondary shoulder between 500&nbsp;nm and approximately 700&nbsp;nm. The second spectra which is black and red is generated by a standard 60&nbsp;W incandescent desk lamp. This is similar to sunlight extending from approximately 350&nbsp;nm to &gt; 1700&nbsp;nm. The spectral profile of the incandescent is long wavelength shifted compared to the LED that lacks an extended infra-red component. The spectrum of this incandescent source extends beyond 2000&nbsp;nm. However, the spectrometers used to measure this lacked sensitivity at longer wavelengths. Individual spectrometers have limits to the spectral range they can cover, so two have been used here and their different wavelength ranges are represented by the back and the red parts of the curve.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>The specific spectra and energy levels were mapped over the workspace at fixed locations. This is shown in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig5">5</a>a and b. Here there is a plan of the space and measurements made at 9 locations of energy given in W/cm<sup>− 2</sup> and lux, which is a metric corrected for the human eye. Also provided are the spectra at each location. Changes in brightness at different locations were largely not detectable by the human eye and were gradual. There were no differences in spectral profiles across the area only their relative intensity.</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="629"></picture></a></div><p><b>a</b>&nbsp;The workshop area was 9&nbsp;m wide and 18&nbsp;m deep, with a ceiling at a height of 5&nbsp;m. Horizontal illuminance was measured at nine locations (Loc 1 - Loc 9) on a grid of points evenly spaced through the workshop. Working height was 0.9&nbsp;m above the floor. Typically, when working at their laptops the workers were near Loc 8, shown in black. (b) Individual spectral irradiance was also taken at the same nine locations, showing that there was the same spectral distribution provided throughout the space.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>Light assessment was also undertaken at bench level where individual subjects worked. This is shown in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig6">6</a>. This confirmed the absence of any part of the infrared spectrum in the work environment and how this changed with the addition of the incandescent lamps.</p><div data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" data-test="figure-caption-text">Fig. 6</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="448"></picture></a></div><p>A series of photographs of the workshop area using the infrared sensitive camera with different filters. Photograph (<b>a</b>) shows the environment in visible light with the incandescent lighting off, and photograph (<b>b</b>) has the same with incandescent off but with infrared imaging. Photograph (<b>c</b>) shows the environment with the incandescent lighting on, and (<b>d</b>) shows the same with incandescent on and infrared imaging. Optical filters were used to isolate the visible and infrared parts of the spectrum respectively. Visible light was captured by placing an Astronomik “L-filter” which passes 390&nbsp;nm to 670&nbsp;nm, in front of the sensor. Infrared light was captured using an Astronomik “ProPlanet 807 IR” which passes 810&nbsp;nm upwards, past the upper limit of 1000&nbsp;nm for the sensitivity of the camera.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>In this study, responses to lighting were measured in test subjects both before and also after the lighting had been changed. However, there was also an independent control group that comprised individuals under similar LED lighting condition without daylight. A comparison of the lighting conditions in the two groups is shown in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig7">7</a>. Critically, the LEDs in both groups had very similar profiles with no infrared components. The overall brightness in the control group was slightly less than in the test group, although this was not apparent to the human eye. As in the test group, subjects were free to move around.</p><div data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" data-test="figure-caption-text">Fig. 7</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/7" rel="nofollow"><picture><img aria-describedby="Fig7" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="392"></picture></a></div><p>Examples of the spectra of LED lighting in the test and control areas. These are largely similar as were the LED specifications. Minor differences could be due to different reflective of the environments. The right side give both the luminance and the irradiance measurements of the two spaces. These overlapped and were very similar to the human eye. In both environments subjects were free to move around resulting in dynamic exposure to the lighting.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span></a></p></figure></div><h3 id="Sec5">Visual responses to shifts in spectral lighting</h3><p>Exposure to 60 W incandescent luminaires, which have a wider spectrum than LEDs extending into the infra-red<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ratto, G. E., Videla, F. A. &amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021)." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR1" id="ref-link-section-d598407405e706">1</a></sup>, resulted in significant improvements in visual performance in all experimental subjects across both the protan and tritan visual ranges. Improvements in both tritan and protan were of the order of 25%. Hence, significant improvements were uniform across visual ranges (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig8">8</a>). This is unlike experiments where specific red/infrared ranges have been used in LED devices, for example via 670 nm, where visual improvements have been biased towards tritan function<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e713">13</a></sup>.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig8">8</a> shows the results of both individual subjects on the left and also changes in the groups on the right. In spite of the universal improvement in visual function, in both tritan and protan range there was considerable variability between subjects. This variability validates the inclusion of a repeated measures design and the use of a sign test in the analysis. In all cases protan thresholds were lower than tritan consistent with previous studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e723">13</a></sup>.</p><p>At the end of the 2 week period the incandescent luminaires were removed and the subjects returned to an exclusively LED dominated light working environment. They were then retested at 4 and 6 weeks. In previous experiments where 670 nm alone has been used, rather than the wide spectrum infrared produced by incandescent lighting, visual improvements decline in approximately a week<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e730">13</a></sup>. However, following incandescent light exposure improvements remain unchanged across both visual domains at both 4 and 6 weeks. Hence, the impact of broad-spectrum incandescent light not only resulted in balanced improvements in colour contrast but also these improvements lasted much longer than previous interventions with restricted red/infrared ranges<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e734">13</a></sup>.</p><p>An independent control group was used in addition to a before and after experimental design. Again, data between individuals was varied on both visual metrics. However, over a 2 week period there were no significant changes in proton or tritan visual thresholds (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig9">9</a>).</p><div data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" data-test="figure-caption-text">Fig. 8</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig8_HTML.png?as=webp"><img aria-describedby="Fig8" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="585"></picture></a></div><p>Protan (<b>a</b>) and tritan (<b>b</b>) thresholds measurements following 2 weeks incandescent light, showing data from individual subjects where the black circles are for baseline and the red squares are data following incandescent exposure for 2 weeks. In all cases the red post exposure data points are below the black demonstrating improved contrast. Below this is shown show the population change in threshold contrast sensitivity for protan (<b>c</b>) and tritan (<b>d</b>) at 2, 4, and 6 weeks after the incandescent lighting was removed. Arrows and percentages show the decline in thresholds across subjects. The degree of reduction was consistently similar for protan and tritan unlike exposures using 670&nbsp;nm where improvements are biased to triton and only lasted 5 days. This indicates that the wider spectrum of incandescent lighting is having a greater impact on improving vision and lasting longer than previously experienced. The same result is seen if we look at data from individuals for the percentage change of this threshold across each subject (i.e. normalising for the baseline) for both proton (e) and tritan (f). Statistical symbols: *** p less than 0.001. Error bars standard error of the mean.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span></a></p></figure></div><div data-test="figure" data-container-section="figure" id="figure-9" data-title="Fig. 9"><figure><figcaption><b id="Fig9" data-test="figure-caption-text">Fig. 9</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig9_HTML.png?as=webp"><img aria-describedby="Fig9" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-026-35389-6/MediaObjects/41598_2026_35389_Fig9_HTML.png" alt="figure 9" loading="lazy" width="685" height="588"></picture></a></div><p>Proton (<b>a</b>) and tritan (<b>b</b>) threshold measurements as controls for those shown in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig8">8</a>. This shows data from individual subjects where the black circles are for baseline, and the coloured squares are data after two weeks under control conditions with no incandescent light added. Below this is shown the population threshold contrast sensitivity for protan (c) and tritan (d), which show no significant change over the two week period. As with Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig9">9</a>, the same result is seen if we look individually at the percentage change of this threshold across each subject (i.e. normalising for the baseline) for both proton (e) and tritan (f). Abbreviations ns = Not significant. Error bars standard error of the mean.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-026-35389-6/figures/9" data-track-dest="link:Figure9 Full size image" aria-label="Full size image figure 9" rel="nofollow"><span>Full size image</span></a></p></figure></div></div></div><div id="Sec6-section" data-title="Discussion"><h2 id="Sec6">Discussion</h2><div id="Sec6-content"><p>We demonstrate that the visual performance of those working under standard LED is significantly improved by exposure to incandescent lighting that has a spectrum similar to daylight with an extensive infrared component. These data are consistent with the hypothesis that LED lighting undermines human visual performance. This result is consistent with laboratory experiments where specific red/infrared wavelength ranges generated by LEDs have been used to improve visual function in animals and humans in a conserved manner<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e818">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Weinrich, T. W., Coyne, A., Salt, T. E., Hogg, C. &amp; Jeffery, G. Improving mitochondrial function significantly reduces metabolic, visual, motor and cognitive decline in aged Drosophila melanogaster. Neurobiol. Aging. 2017 Dec:60:34–43. doi: 10.1016. 
                  https://pubmed.ncbi.nlm.nih.gov/28917665/
                  
                 PMID: 28917665." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR16" id="ref-link-section-d598407405e821">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Sivapathasuntharam, C., Sivaprasad, S., Hogg, C. &amp; Jeffery, G. Aging retinal function is improved by near infrared light (670 nm) that is associated with corrected mitochondrial decline. Neurbiol. Aging 2017 Apr:52:66–70. 
                  https://pubmed.ncbi.nlm.nih.gov/28129566/
                  
                 PMID: 28129566." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR17" id="ref-link-section-d598407405e824">17</a></sup>. But there are three critical differences from these earlier studies. First, we have simply changed environmental lighting in a free moving work environment. Second, we have obtained significant balanced improvements in both the protan and tritan range. Previously, exposure to restricted experimental 670 nm resulted in improvements biased strongly in favour of only tritan function<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e828">13</a></sup>. Hence, exposure to full spectrum lighting results in a balanced pattern of improvement in visual performance. Third, we have shown that improvements in visual function following incandescent light exposure are sustained for up to 6 weeks, and possibly beyond, whereas benefits from single LED restricted range red light were confined to around 5 days<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e832">13</a></sup>. These three features change the way in which long wavelength light may be applied to improve human physiology by delivery in normal environments with lasting balance effects. These results are novel and may have public health implications.</p><p>Our study used 22 subjects but was statistically significant using both a before and after metric and also against an independent control group. They are also similar to group sizes in aspects of Shinhmar et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e839">13</a></sup> (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig2">2</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig3">3</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig4">4</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-026-35389-6#Fig5">5</a>). However, future studies would clearly benefit from inclusion of a larger number of subjects.</p><p>The evolution of life on earth extends over 4 billion years, and that of humans over approximately 4–5 million years from the last common primate ancestor. This has all taken place under sunlight that has a spectral range of approximately 300–2500 nm+, within which there has been an invariant balance between short and longer wavelengths. Human adoption of fire 1–2 million years ago supplemented sunlight as they moved out of Africa as its spectrum is similar having a large infrared component. Likewise, development of the Edison filament luminaire, common until approximately the year 2000 had a spectrum similar to sunlight. However, around 2010 LED lighting with its highly restricted spectrum (350–650 nm) and energy saving characteristics became common, resulting in a loss of infrared light in the built environment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ratto, G. E., Videla, F. A. &amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021)." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR1" id="ref-link-section-d598407405e858">1</a></sup>.</p><p>The physiology of life forms are adapted to natural environmental light in a highly conserved pattern across species. Light impacts on mitochondrial function, which is a key regulator of metabolism and ageing in animals. When the balance of short and long wavelengths is shifted there are consequences for mitochondria. When shorter wavelength exposure is dominant, as in LED lighting, mitochondrial function declines. Mitochondrial complex proteins are reduced and there is reduced ATP production<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Hoh Kam, J., Hogg, C., Fosbury, R., Shinhmar, H. &amp; Jeffery, G. Mitochondria are specifically vulnerable to 420nm light in drosophila which undermines their function and is associated with reduced fly mobility. Plos one. Sep 3;16(9):e0257149. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34478469
                  
                . PMID: 34478469." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR2" id="ref-link-section-d598407405e865">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). 
                  https://pubmed.ncbi.nlm.nih.gov/35020273/
                  
                . PMID: 35020273." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR3" id="ref-link-section-d598407405e868">3</a></sup>. With reduced mitochondrial demand for glucose there is increased body weight and disruptions to serum cytokines<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). 
                  https://pubmed.ncbi.nlm.nih.gov/39966413/
                  
                . PMID: 39966413." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR4" id="ref-link-section-d598407405e872">4</a></sup>. Consequently, consistent with the mitochondrial theory of ageing there is an increased probability of cell/organism ageing and death<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Lopez-Otin, C., Blasco, M. A., Partridge, L., Serrano, M. &amp; Kroemer, G. The hallmarks of aging. Cell 153 (6), 1194–1217 (2013). 
                  https://pubmed.ncbi.nlm.nih.gov/23746838/
                  
                 PMID: 23746838." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR18" id="ref-link-section-d598407405e876">18</a></sup>. It is suggested that this is partly due to 420–450 nm light, dominant in LEDs, being absorbed by porphyrin and the subsequent production of oxygen singlets driving inflammation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). 
                  https://pubmed.ncbi.nlm.nih.gov/35020273/
                  
                . PMID: 35020273." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR3" id="ref-link-section-d598407405e880">3</a></sup>.</p><p>Conversely, exposure to longer wavelengths is associated with increased mitochondrial membrane potential and increased concentration of mitochondrial complex proteins that have declined with ageing and disease. This in turn is associated with elevated ATP, reduced inflammation and extended average lifespan<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Gkotsi, D. et al. Recharging mitochondrial batteries in old eyes. Near infra-red increases ATP. Exp.Eye Res. 2014 May:122:50 – 3. 
                  https://pubmed.ncbi.nlm.nih.gov/24631333/
                  
                 PMID: 24631333." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR7" id="ref-link-section-d598407405e888">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Begum, R. et al. Near-infrared light increases ATP, extends lifespan and improves mobility in aged Drosophila melanogaster. Biol.Lett. ;11(3):20150073. (2015). 
                  https://pubmed.ncbi.nlm.nih.gov/25788488/
                  
                 PMID: 25788488." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR9" id="ref-link-section-d598407405e891">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Powner, P. MB, SaltTE, Hogg, C. &amp; Jeffery, G. Improving mitochondrial function protects bumblebees from neonicotinoid pesticides. Plos One. 11 (11), e0166531 (2016). 
                  https://pubmed.ncbi.nlm.nih.gov/27846310/
                  
                 PMID: 27846310." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR10" id="ref-link-section-d598407405e894">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Begum, R., Powner, P. MB, Hudson, N., Hogg, C. &amp; Jeffery, G. Treatment with 670 Nm light up regulates cytochrome C oxidase expression and reduces inflammation in an Age-Related macular degeneration model. Plos One. 8 (2), e57828 (2013). 
                  https://pubmed.ncbi.nlm.nih.gov/23469078/
                  
                 PMID: 23469078." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR19" id="ref-link-section-d598407405e897">19</a></sup>. The experimental use of longer wavelengths in such situations is commonly referred to as photobiomodulation.</p><p>The retina has the greatest metabolic rate in the body and a high mitochondrial concentration<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Kocherlakota, S., Hurley, J. B., Shu, D. Y. &amp; Editorial Retinal metabolism in health and disease. Front Ophthalmol (Lausanne). 2024 Jul 17:4:1459318. 
                  https://pubmed.ncbi.nlm.nih.gov/39086994/
                  
                 PMID: 39086994." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR20" id="ref-link-section-d598407405e904">20</a></sup>. Retinal metabolism declines with age, but this can be partly corrected with long wavelength light across species<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Weinrich, T. W., Coyne, A., Salt, T. E., Hogg, C. &amp; Jeffery, G. Improving mitochondrial function significantly reduces metabolic, visual, motor and cognitive decline in aged Drosophila melanogaster. Neurobiol. Aging. 2017 Dec:60:34–43. doi: 10.1016. 
                  https://pubmed.ncbi.nlm.nih.gov/28917665/
                  
                 PMID: 28917665." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR16" id="ref-link-section-d598407405e908">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Hoh Kam, J. et al. Mitochondrial decline in the ageing old world primate retina: Little evidence for difference between the centre and periphery. Plos One. ;18(5):e0273882. (2023). 
                  https://pubmed.ncbi.nlm.nih.gov/37130143/
                  
                 PMID: 37130143." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR21" id="ref-link-section-d598407405e911">21</a></sup>. In humans a single 3 min 670 nm exposure improves colour vision within 3 h, which is sustained for almost a week<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e915">13</a></sup>. But what the authors of this study did not appreciate was that this was within a population who worked and lived mainly under LED lighting that may have undermined their baseline measurements. Here, we made no attempt to control light exposures or subject movements as would occur in laboratory-based experiments. Rather, our aim was to introduce wide spectrum long wavelengths into a work environment to improving human performance via mitochondrial manipulation in a translational step.</p><p>There is considerable evidence that introduction of longer wavelengths impact systemically. Durieux et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Durieux, J., Wolff, S. &amp; Dillin, A. The cell-non-autonomous nature of electron transport chain-mediated longevity. Cell 144 (1), 79–91 (2011). 
                  https://pubmed.ncbi.nlm.nih.gov/21215371/
                  
                 PMID: 21215371." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR22" id="ref-link-section-d598407405e922">22</a></sup> stated in relation to experiments in C.elegans that “ We find that mitochondrial perturbation in one tissue is perceived and acted upon by the mitochondrial stress response pathway in distal tissue”. In mice there are significant distinct changes serum cytokine expression to exposures of both short and long wavelength light<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). 
                  https://pubmed.ncbi.nlm.nih.gov/39966413/
                  
                . PMID: 39966413." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR4" id="ref-link-section-d598407405e926">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Shinhmar, H., Hogg, C. &amp; Jeffery, G. Exposure to long wavelength light that improves aged mitochondrial function shifts acute cytokine expression in serum and the retina. Plos One. 18 (7), e0284172 (2023). 
                  https://pubmed.ncbi.nlm.nih.gov/37478072/
                  
                 PMID: 37478072." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR23" id="ref-link-section-d598407405e929">23</a></sup>. Similarly, long wavelength exposures to the surface of the human body excluding the eyes significantly reduces blood glucose levels and increases oxygen consumption in humans. This is likely because mitochondrial upregulation will increase carbohydrate demand to support increased ATP production<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Powner, M. B. &amp; Jeffery, G. Light stimulation of mitochondria reduces blood glucose levels. J.Biophotonics. ;17(5):e202300521. (2024). 
                  https://pubmed.ncbi.nlm.nih.gov/38378043/
                  
                . PMID: 38378043." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR12" id="ref-link-section-d598407405e933">12</a></sup>. Other systemic impacts can be found and are clear in experimentally induced Parkinson’s in primates. Light targeted by implants focusing on the substantia nigra are effective in reducing symptoms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Darlot, F. et al. Near-infrared light is neuroprotective in a monkey model of Parkinson disease. Ann. Neurol. ;79(1):59–75. (2016). 
                  https://pubmed.ncbi.nlm.nih.gov/26456231/
                  
                 PMID: 26456231." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR24" id="ref-link-section-d598407405e937">24</a></sup>, but so also are those that are directed at distal locations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gordon, L. C. et al. Remote photobiomodulation targeted at the abdomen or legs provides effective neuroprotection against parkinsonian MPTP insult. Eur. J. Neurosci. ;57(9):1611–1624. (2023). 
                  https://pubmed.ncbi.nlm.nih.gov/36949610/
                  
                . PMID: 36949610." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR25" id="ref-link-section-d598407405e941">25</a></sup>.</p><p>Single 3 min 670 nm exposures remain effective for about 5 days<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). 
                  https://pubmed.ncbi.nlm.nih.gov/34819619/
                  
                . PMID: 34819619." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR13" id="ref-link-section-d598407405e948">13</a></sup>. But we show that with a wider spectrum they remain effective for 6 weeks, although we did not find the end of the effect. Here it is worth considering potential mechanisms of action which remain subject of debate. Historically, improvements with red light were thought to be due to light absorption by cytochrome C in the respiratory chain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Salehpour, F., Mahmoudi, J., Kamari, F., Sadigh-Eteghad, Rasta, S. H. &amp; Hamblin, M. R. Brain Photobiomodulation Therapy: a Narrative Review. Mol. Neurobiol. ;55(8):6601–6636. (2018). 
                  https://pubmed.ncbi.nlm.nih.gov/29327206/
                  
                 PMID: 29327206." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR26" id="ref-link-section-d598407405e952">26</a></sup>. However, positive effects are found in vitro in the absence of this. Consequently, it has been suggested that longer wavelengths reduce water viscosity around rotary ATP pumps allowing the rotor to increase speed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Sommer, A. P. Mitochondrial cytochrome c oxidase is not the primary acceptor for near infrared light-it is mitochondrial bound water: the principles of low-level light therapy. Ann. Transl. Med. ;7(Suppl 1):S13. (2019). 
                  https://pubmed.ncbi.nlm.nih.gov/31032294/
                  
                . PMID: 31032294." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR27" id="ref-link-section-d598407405e956">27</a></sup>. This cannot explain the sustained impacts of light exposure as this effect should be relatively transitory as viscosity would increase rapidly following light withdrawal. However, a key feature of long wavelength light absorption is increased respiratory chain protein synthesis. These proteins are in flux throughout the day<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Weinrich, T. et al. A day in the life of mitochondria reveals shifting workloads. Sci. Rep. ;9(1):13898. (2019). 
                  https://pubmed.ncbi.nlm.nih.gov/31554906/
                  
                 PMID: 31554906." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR28" id="ref-link-section-d598407405e960">28</a></sup> and complex IV is upregulated following red light exposure<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Begum, R., Powner, P. MB, Hudson, N., Hogg, C. &amp; Jeffery, G. Treatment with 670 Nm light up regulates cytochrome C oxidase expression and reduces inflammation in an Age-Related macular degeneration model. Plos One. 8 (2), e57828 (2013). 
                  https://pubmed.ncbi.nlm.nih.gov/23469078/
                  
                 PMID: 23469078." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR19" id="ref-link-section-d598407405e964">19</a></sup>. Hence, while red light may initially increase rotor pump speed there rapidly follows an increase in protein synthesis which may establish greater respiratory chain capacity. The life of these proteins could then determine the length of effect.</p><p>Only thirteen polypeptides are made in mitochondrial protein synthesis. This probably slows with age and likely contributes to aged mitochondrial decline<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Lopez-Otin, C., Blasco, M. A., Partridge, L., Serrano, M. &amp; Kroemer, G. The hallmarks of aging. Cell 153 (6), 1194–1217 (2013). 
                  https://pubmed.ncbi.nlm.nih.gov/23746838/
                  
                 PMID: 23746838." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR18" id="ref-link-section-d598407405e971">18</a></sup>. But critically, we do not know the speed of mitochondrial protein synthesis, the life of such proteins or the pace of their decline. We suggest that these may be key events in the length of the effects from light exposure.</p><p>LED lighting clearly has the ability to undermine visual performance probably via reduced mitochondrial function. As light induced changes in mitochondrial ability have been shown to have systemic impacts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). 
                  https://pubmed.ncbi.nlm.nih.gov/39966413/
                  
                . PMID: 39966413." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR4" id="ref-link-section-d598407405e978">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Shore-Lorenti, C. et al. Shining the light on Sunshine: a systematic review of the influence of sun exposure on type 2 diabetes mellitus-related outcomes. Clin. Endocrinol. ;81(6):799–811. (2014). 
                  https://pubmed.ncbi.nlm.nih.gov/25066830/
                  
                 PMID: 25066830." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR15" id="ref-link-section-d598407405e981">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Durieux, J., Wolff, S. &amp; Dillin, A. The cell-non-autonomous nature of electron transport chain-mediated longevity. Cell 144 (1), 79–91 (2011). 
                  https://pubmed.ncbi.nlm.nih.gov/21215371/
                  
                 PMID: 21215371." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR22" id="ref-link-section-d598407405e984">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Shinhmar, H., Hogg, C. &amp; Jeffery, G. Exposure to long wavelength light that improves aged mitochondrial function shifts acute cytokine expression in serum and the retina. Plos One. 18 (7), e0284172 (2023). 
                  https://pubmed.ncbi.nlm.nih.gov/37478072/
                  
                 PMID: 37478072." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR23" id="ref-link-section-d598407405e987">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gordon, L. C. et al. Remote photobiomodulation targeted at the abdomen or legs provides effective neuroprotection against parkinsonian MPTP insult. Eur. J. Neurosci. ;57(9):1611–1624. (2023). 
                  https://pubmed.ncbi.nlm.nih.gov/36949610/
                  
                . PMID: 36949610." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR25" id="ref-link-section-d598407405e990">25</a></sup>, the effects of LEDs revealed here may be wider than initially anticipated. Given the prevalence of LEDs, this may represent an important issue in public health and clinical environments where changing lighting patterns in appreciation of this point can have significant positive outcomes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Neto, R. P. M. et al. Photobiomodulation therapy (red/NIR LEDs) reduced the length of stay in intensive care unit and improved muscle function: A randomized, triple-blind, and sham-controlled trial. J.Biophotonics. ;17(5):e202300501. (2024). 
                  https://pubmed.ncbi.nlm.nih.gov/38262071/
                  
                 PMID: 38262071." href="https://www.nature.com/articles/s41598-026-35389-6#ref-CR29" id="ref-link-section-d598407405e994">29</a></sup>.</p><p>Given our results, it is important to ask what solutions may be found to improve health in terms of lighting in the built environment. Incandescent lights that we reveal here to have significant positive impact over standard LEDs are being phased out universally for reasons of energy efficiency, where focus is only on the visible light produced.</p><p>A solution may be found in creating lighting units with multiple longer wavelength LEDs to cover a wider span of the near infrared. However, our attempts here have had limited success. Multiple closely associated spectral peaks do not produce a smooth spectral output as found in incandescent lights and sunlight, which is problematic in improving function and has yet to deliver. This possibly may be overcome using a greater number of spectral peaks with tighter spacing. But this raises a different series of problems regarding cost and increased energy consumption making this solution no better than retention of incandescent sources in terms of environmental sustainability.</p><p>Key to this issue is the question of how much infrared is needed to sustain improved function? Infrared has relatively few absorbers in the built environment and in current studies relatively little has to be added to the environment for effect. However, a viable option is to run an incandescent light at a lower temperature which results in both energy savings and increased life of the unit and also shifts the peak spectral output towards longer wavelengths.</p><p>If this is done with a halogen bulb, which is a type of incandescent tungsten bulb, the filament lasts for a longer period as evaporated tungsten is redeposited on the filament rather than blackening the bulb glass. Hence, using a halogen bulb at lower voltage is a realistic alternative in terms of health and energy consumption.</p></div></div>
                    
                </div><div>
                <div id="data-availability-section" data-title="Data availability"><h2 id="data-availability">Data availability</h2><p>The data sets used and/or analysed during the current study are available from the corresponding author on reasonable request.</p></div><div id="MagazineFulltextArticleBodySuffix" aria-labelledby="Bib1" data-title="References"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference" data-track-context="references section"><li data-counter="1."><p id="ref-CR1">Ratto, G. E., Videla, F. A. &amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021).</p></li><li data-counter="2."><p id="ref-CR2">Hoh Kam, J., Hogg, C., Fosbury, R., Shinhmar, H. &amp; Jeffery, G. Mitochondria are specifically vulnerable to 420nm light in drosophila which undermines their function and is associated with reduced fly mobility. Plos one. Sep 3;16(9):e0257149. (2021). <a href="https://pubmed.ncbi.nlm.nih.gov/34478469" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/34478469">https://pubmed.ncbi.nlm.nih.gov/34478469</a>. PMID: 34478469.</p></li><li data-counter="3."><p id="ref-CR3">Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). <a href="https://pubmed.ncbi.nlm.nih.gov/35020273/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/35020273/">https://pubmed.ncbi.nlm.nih.gov/35020273/</a>. PMID: 35020273.</p></li><li data-counter="4."><p id="ref-CR4">Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). <a href="https://pubmed.ncbi.nlm.nih.gov/39966413/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/39966413/">https://pubmed.ncbi.nlm.nih.gov/39966413/</a>. PMID: 39966413.</p></li><li data-counter="5."><p id="ref-CR5">Nash, T. R. et al. Daily blue-light exposure shortens lifespan and causes brain neurodegeneration in Drosophila. Aging. Mech. Dis 2019 Oct 17:5:8. <a href="https://pubmed.ncbi.nlm.nih.gov/31636947/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/31636947/">https://pubmed.ncbi.nlm.nih.gov/31636947/</a>. PMID: 31636947.</p></li><li data-counter="6."><p id="ref-CR6">Jeffery, G. et al. Longer wavelengths in sunlight pass through the human body and have a systemic impact which improves vision. <i>Sci. Rep. 2025</i> July;<b>15</b>(1);24435. <a href="https://doi.org/10.1038/s41598-025-09785-3" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1038/s41598-025-09785-3">https://doi.org/10.1038/s41598-025-09785-3</a></p></li><li data-counter="7."><p id="ref-CR7">Gkotsi, D. et al. Recharging mitochondrial batteries in old eyes. Near infra-red increases ATP. Exp.Eye Res. 2014 May:122:50 – 3. <a href="https://pubmed.ncbi.nlm.nih.gov/24631333/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/24631333/">https://pubmed.ncbi.nlm.nih.gov/24631333/</a> PMID: 24631333.</p></li><li data-counter="8."><p id="ref-CR8">Calaza, K. C., Hoh Kam, J., Hogg, C. &amp; Jeffery, G. Mitochondrial decline precedes phenotype development in the complement factor H mouse model of retinal degeneration but can be corrected by near infrared light. Neurobiol. Aging. ;36(10):2869-76. (2015). <a href="https://pubmed.ncbi.nlm.nih.gov/26149919/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/26149919/">https://pubmed.ncbi.nlm.nih.gov/26149919/</a> PMID: 26149919.</p></li><li data-counter="9."><p id="ref-CR9">Begum, R. et al. Near-infrared light increases ATP, extends lifespan and improves mobility in aged Drosophila melanogaster. Biol.Lett. ;11(3):20150073. (2015). <a href="https://pubmed.ncbi.nlm.nih.gov/25788488/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/25788488/">https://pubmed.ncbi.nlm.nih.gov/25788488/</a> PMID: 25788488.</p></li><li data-counter="10."><p id="ref-CR10">Powner, P. MB, SaltTE, Hogg, C. &amp; Jeffery, G. Improving mitochondrial function protects bumblebees from neonicotinoid pesticides. <i>Plos One</i>. <b>11</b> (11), e0166531 (2016). <a href="https://pubmed.ncbi.nlm.nih.gov/27846310/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/27846310/">https://pubmed.ncbi.nlm.nih.gov/27846310/</a> PMID: 27846310.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0166531" data-track-item_id="10.1371/journal.pone.0166531" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0166531" aria-label="Article reference 10" data-doi="10.1371/journal.pone.0166531">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27846310" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5112779" aria-label="PubMed Central reference 10">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Improving%20mitochondrial%20function%20protects%20bumblebees%20from%20neonicotinoid%20pesticides&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0166531&amp;volume=11&amp;issue=11&amp;publication_year=2016&amp;author=Powner%2CP&amp;author=Salt%2C&amp;author=Hogg%2CC&amp;author=Jeffery%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Powner, P. MB &amp; Jeffery, G. Systemic glucose levels are modulated by specific wavelengths in the solar light spectrum that shift mitochondrial metabolism. <i>Plos One</i>. <b>17</b> (11), e0276937 (2022). <a href="https://pubmed.ncbi.nlm.nih.gov/36327250/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/36327250/">https://pubmed.ncbi.nlm.nih.gov/36327250/</a> PMID: 36327250.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0276937" data-track-item_id="10.1371/journal.pone.0276937" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0276937" aria-label="Article reference 11" data-doi="10.1371/journal.pone.0276937">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XivFWitr3L" aria-label="CAS reference 11">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36327250" aria-label="PubMed reference 11">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9632789" aria-label="PubMed Central reference 11">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Systemic%20glucose%20levels%20are%20modulated%20by%20specific%20wavelengths%20in%20the%20solar%20light%20spectrum%20that%20shift%20mitochondrial%20metabolism&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0276937&amp;volume=17&amp;issue=11&amp;publication_year=2022&amp;author=Powner%2CP&amp;author=Jeffery%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Powner, M. B. &amp; Jeffery, G. Light stimulation of mitochondria reduces blood glucose levels. J.Biophotonics. ;17(5):e202300521. (2024). <a href="https://pubmed.ncbi.nlm.nih.gov/38378043/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/38378043/">https://pubmed.ncbi.nlm.nih.gov/38378043/</a>. PMID: 38378043.</p></li><li data-counter="13."><p id="ref-CR13">Shinhmar, H., Hoog, C., Neveu, M. &amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). <a href="https://pubmed.ncbi.nlm.nih.gov/34819619/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/34819619/">https://pubmed.ncbi.nlm.nih.gov/34819619/</a>. PMID: 34819619.</p></li><li data-counter="14."><p id="ref-CR14">Weller, R. B. &amp; Sunlight Time for a Rethink? J.Invest. Dermatol. ;144(8):1724–1732. (2024). <a href="https://pubmed.ncbi.nlm.nih.gov/38661623/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/38661623/">https://pubmed.ncbi.nlm.nih.gov/38661623/</a> PMID: 38661623.</p></li><li data-counter="15."><p id="ref-CR15">Shore-Lorenti, C. et al. Shining the light on Sunshine: a systematic review of the influence of sun exposure on type 2 diabetes mellitus-related outcomes. Clin. Endocrinol. ;81(6):799–811. (2014). <a href="https://pubmed.ncbi.nlm.nih.gov/25066830/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/25066830/">https://pubmed.ncbi.nlm.nih.gov/25066830/</a> PMID: 25066830.</p></li><li data-counter="16."><p id="ref-CR16">Weinrich, T. W., Coyne, A., Salt, T. E., Hogg, C. &amp; Jeffery, G. Improving mitochondrial function significantly reduces metabolic, visual, motor and cognitive decline in aged Drosophila melanogaster. Neurobiol. Aging. 2017 Dec:60:34–43. doi: 10.1016. <a href="https://pubmed.ncbi.nlm.nih.gov/28917665/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/28917665/">https://pubmed.ncbi.nlm.nih.gov/28917665/</a> PMID: 28917665.</p></li><li data-counter="17."><p id="ref-CR17">Sivapathasuntharam, C., Sivaprasad, S., Hogg, C. &amp; Jeffery, G. Aging retinal function is improved by near infrared light (670 nm) that is associated with corrected mitochondrial decline. Neurbiol. Aging 2017 Apr:52:66–70. <a href="https://pubmed.ncbi.nlm.nih.gov/28129566/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/28129566/">https://pubmed.ncbi.nlm.nih.gov/28129566/</a> PMID: 28129566.</p></li><li data-counter="18."><p id="ref-CR18">Lopez-Otin, C., Blasco, M. A., Partridge, L., Serrano, M. &amp; Kroemer, G. The hallmarks of aging. <i>Cell</i> <b>153</b> (6), 1194–1217 (2013). <a href="https://pubmed.ncbi.nlm.nih.gov/23746838/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/23746838/">https://pubmed.ncbi.nlm.nih.gov/23746838/</a> PMID: 23746838.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cell.2013.05.039" data-track-item_id="10.1016/j.cell.2013.05.039" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2013.05.039" aria-label="Article reference 18" data-doi="10.1016/j.cell.2013.05.039">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXptFKms78%3D" aria-label="CAS reference 18">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23746838" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3836174" aria-label="PubMed Central reference 18">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20hallmarks%20of%20aging&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2013.05.039&amp;volume=153&amp;issue=6&amp;pages=1194-1217&amp;publication_year=2013&amp;author=Lopez-Otin%2CC&amp;author=Blasco%2CMA&amp;author=Partridge%2CL&amp;author=Serrano%2CM&amp;author=Kroemer%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Begum, R., Powner, P. MB, Hudson, N., Hogg, C. &amp; Jeffery, G. Treatment with 670 Nm light up regulates cytochrome C oxidase expression and reduces inflammation in an Age-Related macular degeneration model. <i>Plos One</i>. <b>8</b> (2), e57828 (2013). <a href="https://pubmed.ncbi.nlm.nih.gov/23469078/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/23469078/">https://pubmed.ncbi.nlm.nih.gov/23469078/</a> PMID: 23469078.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0057828" data-track-item_id="10.1371/journal.pone.0057828" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0057828" aria-label="Article reference 19" data-doi="10.1371/journal.pone.0057828">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXjvFKhur0%3D" aria-label="CAS reference 19">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23469078" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3585189" aria-label="PubMed Central reference 19">PubMed Central</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="ads reference" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2013PLoSO...857828B" aria-label="ADS reference 19">ADS</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Treatment%20with%20670%20Nm%20light%20up%20regulates%20cytochrome%20C%20oxidase%20expression%20and%20reduces%20inflammation%20in%20an%20Age-Related%20macular%20degeneration%20model&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0057828&amp;volume=8&amp;issue=2&amp;publication_year=2013&amp;author=Begum%2CR&amp;author=Powner%2CP&amp;author=Hudson%2CN&amp;author=Hogg%2CC&amp;author=Jeffery%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Kocherlakota, S., Hurley, J. B., Shu, D. Y. &amp; Editorial Retinal metabolism in health and disease. Front Ophthalmol (Lausanne). 2024 Jul 17:4:1459318. <a href="https://pubmed.ncbi.nlm.nih.gov/39086994/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/39086994/">https://pubmed.ncbi.nlm.nih.gov/39086994/</a> PMID: 39086994.</p></li><li data-counter="21."><p id="ref-CR21">Hoh Kam, J. et al. Mitochondrial decline in the ageing old world primate retina: Little evidence for difference between the centre and periphery. Plos One. ;18(5):e0273882. (2023). <a href="https://pubmed.ncbi.nlm.nih.gov/37130143/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/37130143/">https://pubmed.ncbi.nlm.nih.gov/37130143/</a> PMID: 37130143.</p></li><li data-counter="22."><p id="ref-CR22">Durieux, J., Wolff, S. &amp; Dillin, A. The cell-non-autonomous nature of electron transport chain-mediated longevity. <i>Cell</i> <b>144</b> (1), 79–91 (2011). <a href="https://pubmed.ncbi.nlm.nih.gov/21215371/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/21215371/">https://pubmed.ncbi.nlm.nih.gov/21215371/</a> PMID: 21215371.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cell.2010.12.016" data-track-item_id="10.1016/j.cell.2010.12.016" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2010.12.016" aria-label="Article reference 22" data-doi="10.1016/j.cell.2010.12.016">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXksFGisQ%3D%3D" aria-label="CAS reference 22">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21215371" aria-label="PubMed reference 22">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3062502" aria-label="PubMed Central reference 22">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cell-non-autonomous%20nature%20of%20electron%20transport%20chain-mediated%20longevity&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2010.12.016&amp;volume=144&amp;issue=1&amp;pages=79-91&amp;publication_year=2011&amp;author=Durieux%2CJ&amp;author=Wolff%2CS&amp;author=Dillin%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="23."><p id="ref-CR23">Shinhmar, H., Hogg, C. &amp; Jeffery, G. Exposure to long wavelength light that improves aged mitochondrial function shifts acute cytokine expression in serum and the retina. <i>Plos One</i>. <b>18</b> (7), e0284172 (2023). <a href="https://pubmed.ncbi.nlm.nih.gov/37478072/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/37478072/">https://pubmed.ncbi.nlm.nih.gov/37478072/</a> PMID: 37478072.</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0284172" data-track-item_id="10.1371/journal.pone.0284172" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0284172" aria-label="Article reference 23" data-doi="10.1371/journal.pone.0284172">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXhs1elsbzF" aria-label="CAS reference 23">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37478072" aria-label="PubMed reference 23">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC10361513" aria-label="PubMed Central reference 23">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Exposure%20to%20long%20wavelength%20light%20that%20improves%20aged%20mitochondrial%20function%20shifts%20acute%20cytokine%20expression%20in%20serum%20and%20the%20retina&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0284172&amp;volume=18&amp;issue=7&amp;publication_year=2023&amp;author=Shinhmar%2CH&amp;author=Hogg%2CC&amp;author=Jeffery%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Darlot, F. et al. Near-infrared light is neuroprotective in a monkey model of Parkinson disease. Ann. Neurol. ;79(1):59–75. (2016). <a href="https://pubmed.ncbi.nlm.nih.gov/26456231/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/26456231/">https://pubmed.ncbi.nlm.nih.gov/26456231/</a> PMID: 26456231.</p></li><li data-counter="25."><p id="ref-CR25">Gordon, L. C. et al. Remote photobiomodulation targeted at the abdomen or legs provides effective neuroprotection against parkinsonian MPTP insult. Eur. J. Neurosci. ;57(9):1611–1624. (2023). <a href="https://pubmed.ncbi.nlm.nih.gov/36949610/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/36949610/">https://pubmed.ncbi.nlm.nih.gov/36949610/</a>. PMID: 36949610.</p></li><li data-counter="26."><p id="ref-CR26">Salehpour, F., Mahmoudi, J., Kamari, F., Sadigh-Eteghad, Rasta, S. H. &amp; Hamblin, M. R. Brain Photobiomodulation Therapy: a Narrative Review. Mol. Neurobiol. ;55(8):6601–6636. (2018). <a href="https://pubmed.ncbi.nlm.nih.gov/29327206/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/29327206/">https://pubmed.ncbi.nlm.nih.gov/29327206/</a> PMID: 29327206.</p></li><li data-counter="27."><p id="ref-CR27">Sommer, A. P. Mitochondrial cytochrome c oxidase is not the primary acceptor for near infrared light-it is mitochondrial bound water: the principles of low-level light therapy. Ann. Transl. Med. ;7(Suppl 1):S13. (2019). <a href="https://pubmed.ncbi.nlm.nih.gov/31032294/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/31032294/">https://pubmed.ncbi.nlm.nih.gov/31032294/</a>. PMID: 31032294.</p></li><li data-counter="28."><p id="ref-CR28">Weinrich, T. et al. A day in the life of mitochondria reveals shifting workloads. Sci. Rep. ;9(1):13898. (2019). <a href="https://pubmed.ncbi.nlm.nih.gov/31554906/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/31554906/">https://pubmed.ncbi.nlm.nih.gov/31554906/</a> PMID: 31554906.</p></li><li data-counter="29."><p id="ref-CR29">Neto, R. P. M. et al. Photobiomodulation therapy (red/NIR LEDs) reduced the length of stay in intensive care unit and improved muscle function: A randomized, triple-blind, and sham-controlled trial. J.Biophotonics. ;17(5):e202300501. (2024). <a href="https://pubmed.ncbi.nlm.nih.gov/38262071/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://pubmed.ncbi.nlm.nih.gov/38262071/">https://pubmed.ncbi.nlm.nih.gov/38262071/</a> PMID: 38262071.</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-026-35389-6?format=refman&amp;flavour=references">Download references</a></p></div></div><div id="Ack1-section" data-title="Acknowledgements"><h2 id="Ack1">Acknowledgements</h2><p>We thank Chris Hogg for assistance with Chromatest, and Mandana Khanie for use of the Ocean Optics spectrophotometers.</p></div><div id="Fun-section" data-title="Funding"><h2 id="Fun">Funding</h2><p>This research did not receive funding.</p></div><div id="author-information-section" aria-labelledby="author-information" data-title="Author information"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Institute for Environmental Design and Engineering, University College London, London, UK</p><p>Edward M. Barrett</p></li><li id="Aff2"><p>Institute of Ophthalmology, University College London, London, EC1V 9EL, UK</p><p>Glen Jeffery</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Edward_M_-Barrett-Aff1"><span>Edward M. Barrett</span></li><li id="auth-Glen-Jeffery-Aff2"><span>Glen Jeffery</span></li></ol></div><h3 id="contributions">Contributions</h3><p>GJ and EB designed the experiments undertook all the experimental work and wrote the manuscript.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" aria-label="email Glen Jeffery" href="mailto:g.jeffery@ucl.ac.uk">Glen Jeffery</a>.</p></div></div><div id="ethics-section" data-title="Ethics declarations"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
              
                <h3 id="FPar1">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div><div id="additional-information-section" data-title="Additional information"><h2 id="additional-information">Additional information</h2><div id="additional-information-content"><h3>Publisher’s note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div><div id="rightslink-section" data-title="Rights and permissions"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=LED%20lighting%20%28350-650nm%29%20undermines%20human%20visual%20performance%20unless%20supplemented%20by%20wider%20spectra%20%28400-1500nm%2B%29%20like%20daylight&amp;author=Edward%20M.%20Barrett%20et%20al&amp;contentID=10.1038%2Fs41598-026-35389-6&amp;copyright=The%20Author%28s%29&amp;publication=2045-2322&amp;publicationDate=2026-01-23&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div><div id="article-info-section" aria-labelledby="article-info" data-title="About this article"><h2 id="article-info">About this article</h2><div id="article-info-content"><p><a data-crossmark="10.1038/s41598-026-35389-6" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-026-35389-6" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></p><div><h3 id="citeas">Cite this article</h3><p>Barrett, E.M., Jeffery, G. LED lighting (350-650nm) undermines human visual performance unless supplemented by wider spectra (400-1500nm+) like daylight.
                    <i>Sci Rep</i> <b>16</b>, 3061 (2026). https://doi.org/10.1038/s41598-026-35389-6</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-026-35389-6?format=refman&amp;flavour=citation">Download citation</a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2025-04-27">27 April 2025</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2026-01-05">05 January 2026</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2026-01-23">23 January 2026</time></span></p></li><li><p>Version of record<span>: </span><span><time datetime="2026-01-23">23 January 2026</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41598-026-35389-6</span></p></li></ul><h3>Keywords</h3></div></div></div>
            </div></div>]]></description>
        </item>
    </channel>
</rss>