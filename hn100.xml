<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 30 Dec 2025 08:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Stranger Things creator says turn off "garbage" settings (143 pts)]]></title>
            <link>https://screenrant.com/stranger-things-creator-turn-off-settings-premiere/</link>
            <guid>46427586</guid>
            <pubDate>Mon, 29 Dec 2025 23:50:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://screenrant.com/stranger-things-creator-turn-off-settings-premiere/">https://screenrant.com/stranger-things-creator-turn-off-settings-premiere/</a>, See on <a href="https://news.ycombinator.com/item?id=46427586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                            <div data-nosnippet="">
                                            <p><a href="https://screenrant.com/author/jennifer-chu/">
                                    <img src="https://static0.srcdn.com/wordpress%2Fwp-content%2Fauthors%2F68b72cebb10c6-FullSizeRender.jpeg?fit=crop&amp;w=90&amp;h=90" alt="4" loading="lazy" decoding="async">
                                </a>
                                                    </p>
                                    </div>
                        
                                            
                                
                                    <div data-nosnippet=""><p>Jennifer is a TV News Editor at ScreenRant. She started her journey in entertainment media in 2022 when she first joined Valnet at CBR before coming to ScreenRant.</p><p>

Jennifer loves TV, especially science fiction. She also loves late-night talk shows, due to her insomnia. Alien: Earth is definitely one of her favorite shows, and she jumps on any chance she gets to write about it. Even on her days off, she will claim an Alien Earth article if one is available.&nbsp;</p><p>

Jimmy Kimmel and Jimmy Fallon are two of her favorite late-night hosts, and Conan O'Brien before he left his show.</p><p>

Her Alien: Earth coverage for Screen Rant is by far the work that she is most proud of so far.</p><p>

She began her career as an editor in 2014. She was initially a finance editor, but her passion for pop culture convinced her to transition into entertainment journalism.</p><p>

During her off time, she loves to binge-watch cooking shows such as Kitchen Nightmares. Jennifer also loves spending time with her daughter and cherishes every moment of it. </p></div>
                                        
            
        </div><div id="article-body" itemprop="articleBody"><p><a href="https://screenrant.com/tag/franchise/stranger-things/" target="_blank"><strong><em>Stranger Things</em></strong></a> creator Ross Duffer offered a piece of advice to viewers who plan on watching the season 5 premiere.</p>    <!-- No AdsNinja v10 Client! --><!-- No AdsNinja v10 Client! --><p>On <a href="https://www.instagram.com/reel/DRiaP2zEow4/?utm_source=ig_embed&amp;ig_rid=e69150fa-99bd-43a7-a7df-82914c66fdaa" rel="noopener noreferrer nofollow" target="_blank">Instagram</a>, Duffer guided fans through their TV settings so they could watch the <a href="https://screenrant.com/stranger-things-season-5-volume-1-ending-will-vecna-cliffhanger-bower-response/" target="_blank">new season of <em>Stranger Things</em></a> the way it was meant to be seen. He stated, "<em>A little PSA before you watch tonight. I want to make sure that your TVs are set up properly." He proceeded to tell his followers to turn off all their settings, especially dynamic contrast, super resolution, edge enhancer, and color filter</em>. He even described those features as "<em>garbage</em>."</p>    <p>The<em> <a href="https://screenrant.com/stranger-things-duffer-brothers-essential-episodes/" target="_blank">Stranger Things</a></em><a href="https://screenrant.com/stranger-things-duffer-brothers-essential-episodes/" target="_blank"> creator</a> then returns to the picture settings menu, pointing out that viewers should disable noise reduction, too. He also said that truemotion and smoothmotion are the biggest "<em>offenders</em>" and should be turned off most of all because they cause “<em>the dreaded soap opera effect</em>.”</p>    <p>He explains that most televisions will fix many of these problems if you switch to their advanced viewing presets, such as Dolby Vision Movie Dark. However, even those modes aren’t perfect. He urges fans to manually confirm each setting is off and adds, “<em>Whatever you do, do not switch anything on ‘vivid’ because it’s gonna turn on all the worst offenders. It’s gonna destroy the color, and it’s not the filmmaker’s intent.</em>”</p>    
    
    
    
<p>Duffer’s advice highlights a conflict between technological advances and creators' goals. Features like the ones he mentioned are designed to appeal to casual viewers by making images appear sharper or more colorful, but they alter the original look of the content. By asking fans to turn these features off, he is stressing the importance of preserving the director’s vision.</p>    

                

                    
    
                                                            <p><a href="https://screenrant.com/stranger-things-season-5-kali-eight-return-explained/" target="_blank"><em><strong>Stranger Things</strong></em> season 5</a>, volume 1, is available to stream now on Netflix. Volume 2 will be released on December 25, 2025, and the finale on December 31, 2025.</p>        
    
                
                                
                
                
    
                    
                    
    

        

                

        
                    
    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                            
    
    
    <div data-show-streamrentbuy-links="true" data-include-community-rating="true" id="269f-41f8-a442d90dd91b">
                                    <div data-img-url="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;" data-stnl="%7B%22category%22%3A%22Click%20Interactions%22%2C%22name%22%3A%22Tag%20Display%20Card%22%2C%22action%22%3A%22Fullscreen%20Image%20Load%22%2C%22once%22%3Atrue%7D" data-stnl-group-once="txxtGchWlS">
                                                                                                                                                            <picture><source media="(max-width: 480px)" data-srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=49&amp;fit=contain&amp;w=300&amp;dpr=2" srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=49&amp;fit=contain&amp;w=300&amp;dpr=2">
        <source media="(max-width: 767px)" data-srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=70&amp;fit=contain&amp;w=400&amp;dpr=1" srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=70&amp;fit=contain&amp;w=400&amp;dpr=1">
        <source media="(max-width: 1023px)" data-srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=49&amp;fit=contain&amp;w=320&amp;dpr=2" srcset="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=49&amp;fit=contain&amp;w=320&amp;dpr=2">
        <img width="480" height="720" loading="lazy" decoding="async" alt="03112487_poster_w780.jpg" data-img-url="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=70&amp;fit=contain&amp;w=480&amp;dpr=1" src="https://static0.srcdn.com/wordpress/wp-content/uploads/2025/06/03112487_poster_w780.jpg?q=70&amp;fit=contain&amp;w=480&amp;dpr=1">
        </picture>
            
        </div>
                                <div>
                                                <dl>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <p>
                                        <dt>
                                            <strong>Release Date</strong>
                                        </dt>
                                        <dd>
                                            <span>
					
		
			
				2016 - 2025-00-00

			
			</span>
                                        </dd>
                                    </p>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <p>
                                        <dt>
                                            <strong>Network</strong>
                                        </dt>
                                        <dd>
                                            <span>
					
		
			
			
															Netflix
			
			</span>
                                        </dd>
                                    </p>
                                                                                                                                                                                                                                                                    <p>
                                        <dt>
                                            <strong>Showrunner</strong>
                                        </dt>
                                        <dd>
                                            <span>
					
		
			
			
															Matt Duffer, Ross Duffer
			
			</span>
                                        </dd>
                                    </p>
                                                                                                                                                                                                        <p>
                                        <dt>
                                            <strong>Directors</strong>
                                        </dt>
                                        <dd>
                                            <span>
					
		
			
			
															Matt Duffer, Ross Duffer, Andrew Stanton, Frank Darabont, Nimród Antal, Uta Briesewitz
			
			</span>
                                        </dd>
                                    </p>
                                                                                                                                                                                                        <p>
                                        <dt>
                                            <strong>Writers</strong>
                                        </dt>
                                        <dd>
                                            <span>
					
		
			
			
															Kate Trefry, Jessie Nickson-Lopez, Jessica Mecklenburg, Alison Tatlock
			
			</span>
                                        </dd>
                                    </p>
                                                                                    </dl>

                                            </div>
            </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I migrated to an almost all-EU stack and saved 500€ per year (149 pts)]]></title>
            <link>https://www.zeitgeistofbytes.com/p/bye-bye-big-tech-how-i-migrated-to</link>
            <guid>46427582</guid>
            <pubDate>Mon, 29 Dec 2025 23:50:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zeitgeistofbytes.com/p/bye-bye-big-tech-how-i-migrated-to">https://www.zeitgeistofbytes.com/p/bye-bye-big-tech-how-i-migrated-to</a>, See on <a href="https://news.ycombinator.com/item?id=46427582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>For a long time, the narrative has been that if you want privacy and data sovereignty, you have to sacrifice usability. But after settling into this new stack, I’ve realized that isn’t true anymore. In fact, most of these tools aren’t just more private; they are significantly better than the US-based giants I left behind.</p><p>Here is a breakdown of the tools I’m using, the money I’m saving, and the few hurdles I’m still trying to jump over.</p><blockquote><p>by the way, this post is for personal setups not for companies. Yet, I think most tools can be used for teams and companies too.</p></blockquote><p><span>The biggest impact on this migration has come from </span><a href="https://proton.me/" rel="">Proton</a><span>. They have matured from a simple encrypted email provider into a (almost) full-suite productivity powerhouse.</span></p><p>My subscription now covers:</p><ul><li><p><strong>Mail &amp; Calendar:</strong><span> Encrypted and clean.</span></p></li><li><p><strong>Drive</strong><span>: Secure cloud storage, having docs for a while, and now also tables.</span></p></li><li><p><strong>Proton Pass:</strong><span> A solid password manager with 2FA integration.</span></p></li><li><p><strong>VPN:</strong><span> Fast and reliable.</span></p></li><li><p><strong>Standard Notes: </strong><span>My go-to for note-taking, now under the Proton umbrella.</span></p></li><li><p><strong>Lumo AI:</strong><span> A privacy-first GenAI, I’m not yet frequently using it, but we will talk about it later.</span></p></li></ul><p><span>Everything is integrated and the user experience is superb. I’m also eagerly awaiting the release of </span><em>Proton Meet</em><span> to complete the suite.</span></p><p>This entire setup replaces for me my Google Drive and Gmail ecosystem. Plus NordVPN, Notion, 1Password and Authenticator. </p><p><span>Curious? I will drop you my referral&nbsp;</span><a href="https://pr.tn/ref/R7DT0GYT" rel="">link here</a><span>.</span></p><p>AI is the hardest thing to decouple from Big Tech, but improvements are happening fast here, too.</p><p><span>For privacy-first GenAI tasks within my workflow, I’m using </span><strong><a href="https://lumo.proton.me/" rel="">Lumo AI</a></strong><span>. It’s great for quick, private queries.</span></p><p><span>However, sometimes you need raw power. For that, I started using </span><strong><a href="https://mammouth.ai/" rel="">Mammouth</a></strong><span>. I use this less for privacy reasons and more for the sheer value and flexibility. Getting access to every major AI model (including image generation) for just €10 is incredible value.</span></p><p>My default for Mammouth looks like this. You can sort them in your favourite order; whatever is leftmost is your default one. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!PBzZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!PBzZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 424w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 848w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 1272w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!PBzZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png" width="1456" height="827" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:827,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:162671,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeitgeistofbytes.com/i/182763884?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!PBzZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 424w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 848w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 1272w, https://substackcdn.com/image/fetch/$s_!PBzZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5463c8de-5f08-4c33-b88a-f7c36429ffae_1930x1096.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The two models I use most are Mistral Medium 3.1 and Flux 2 Pro or Fast. For simple coding tasks, I also use Mistral, but when playing around with a larger codebase, I have to admit I’m using Claude Code.</p><p>For research, Mistral does its job. But if it becomes complex, I often find Gemini's results to be the best.</p><p>At last, Flux for images is fantastic. Yet, in my opinion, it comes with a major downside: You have to give a lot of good instructions. Where a Nano Banana seems more creative, even from short, simple inputs, Flux needs precise orders.</p><ul><li><p><strong>Browser</strong><span>: I moved to </span><a href="https://vivaldi.com/de/" rel="">Vivaldi</a><span> Technologies. It’s highly customizable and respects user data.</span></p></li><li><p><strong>Search</strong><span>: My default is </span><a href="https://www.ecosia.org/" rel="">Ecosia</a><span>. It works well, and planting trees while searching adds a nice layer of purpose to mindless scrolling. Yet, every now and then I have to use Google :/</span></p></li><li><p><strong>Translation</strong><span>: I’ve been using </span><a href="https://www.deepl.com/de/translator" rel="">DeepL</a><span> forever. In my opinion, it is still miles ahead of Google Translate in terms of nuance and quality.</span></p></li><li><p><strong>Spell Check</strong><span>: … Haven’t found a good alternative, so I stay with Grammarly. Hoping for them to return to Europe with their Superhuman Platform.</span></p></li></ul><p><span>For my website and domains, I moved everything to </span><a href="https://www.scaleway.com/en/" rel="">Scaleway</a><span>.</span></p><p>If you are technical, you will appreciate this switch. It is lean, simple, and provides everything you need as a cloud provider without the bloat of AWS or Azure. Plus, it’s cheaper.</p><p>Canva… what shall I say. </p><p><span>Thanks to the initial discussion I had on LinkedIn (</span><a href="https://www.linkedin.com/posts/maxkoerbaecher_sovereignty-privacy-welcometothebrightside-activity-7392125165960241152-AP02?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAkB0HYB16qpwrVpb6Bhx1qPq4ZN_pYUNpM" rel="">original post</a><span>), I found </span><a href="https://www.superlist.com/" rel="">Superlist</a><span>, to which I transitioned from Todoist. I also had a mini stop at MeisterTask, but that was a complete waste of time. </span></p><p>MeisterTaks feels like a kindergarten playground, too much colorful design and too little actual functionality. It is 100% not user-intuitive for any workflow.</p><p>So, I’m now on Superlist, and very happy with it.</p><p>We often assume that “boutique” privacy tools cost a premium. Surprisingly, my migration proved the opposite. Initially, I wrote only about a small saving, but I missed the costs of Notion, Todoist, 1 Password, Claude and Canva as I focused on the “Office” suite.</p><p><strong>My Old Stack cost ca. 83€ per month</strong></p><p><strong>My New EU Stack cost ca. 39€ per month</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!I8iD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!I8iD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 424w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 848w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 1272w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!I8iD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png" width="1456" height="772" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:772,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:420875,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeitgeistofbytes.com/i/182763884?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!I8iD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 424w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 848w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 1272w, https://substackcdn.com/image/fetch/$s_!I8iD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faacf66d5-6597-4653-9f34-949d1b710cd3_1482x786.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I’m saving over 528 € a year while owning most of my data.</p><p>I want to be transparent: you cannot escape everything, and some things are just harder to use.</p><ol><li><p><strong>The “Guilty Pleasure”:</strong><span> As a techie, I have too much fun playing with </span><strong>Claude Code</strong><span>. It’s a luxury I treat myself to, so I frequently turn the subscription on. Yet, if you don’t have that use case → Mistral, Lumo</span></p></li><li><p><strong>The Social Web:</strong><span> You simply can’t get around LinkedIn, GitHub, YouTube, Medium, Substack and so on if you want to stay connected.</span></p></li><li><p><strong><s>Convenience:</s></strong><s> I miss a good Google SSO. It is everywhere, and losing that “one-click login” friction does make life slightly more annoying.</s><span> </span><em><strong>I migrated every Login to Proton Pass using MFA and Passkey wherever possible.</strong></em></p></li><li><p><strong><s>Office Suite:</s></strong><s> I am struggling to get used to LibreOffice and Collabora Online. They feel similar to MS Office, but “not quite.” Since I don’t create documents or spreadsheets every day for personal use, the learning curve feels steeper than it should.</s><span> Screw that → </span><strong>Proton Docs and Sheets </strong><span>are doing it. Worst case for slides, I’m going for Canva, I’m paying for it anyhow.</span></p></li><li><p><strong>Blogging, Newsletter &amp; Co.: </strong><span>Well, as you can see, I’m writing on Substack. There are no alternatives except to host it entirely yourself, but that doesn’t make sense to me right now.</span></p></li></ol><p>I also found a couple of positive side effects. The Proton platform itself has everything you need for your day-to-day life.</p><p>In addition, I migrated to a Duo plan with my wife. Together we have 2TB on storage for Mails, Files etc. Before we had 30GB on Gmail, which cost a little more.</p><p>Proton Pass creates anonymous email addresses in case you don’t want to use your real email address. This plays entirely on Proton's privacy aspect. </p><p>Superlist is free for the same features Todoist provided me for a little subscription. </p><p>Lastly, I’m always fighting with note-taking. I tested everything and started building something complex on Notion. I’m glad that I could delete it and just use Standard Notes from Proton. In simple terms, it is like notes from Apple, yet E2E encrypted and you can back them up offline. However, most helpful for me is that I finally found a way to work effectively with notes, keep it clean, lean and functional. </p><p>With Proton, Scaleway, Mammouth, Vivaldi, Superlist and DeepL, I have built a useful toolset that, in my opinion, surpasses what I used before.</p><p>The apps are cleaner, the UI is often more user-friendly, and the migration was surprisingly simple. Best of all, I can do more with my tech stack for less money.</p><p>If you’ve been on the fence about migrating to EU-hosted solutions, take the leap. It’s worth it.</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Stop Claude Code from forgetting everything (138 pts)]]></title>
            <link>https://github.com/mutable-state-inc/ensue-skill</link>
            <guid>46426624</guid>
            <pubDate>Mon, 29 Dec 2025 22:30:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mutable-state-inc/ensue-skill">https://github.com/mutable-state-inc/ensue-skill</a>, See on <a href="https://news.ycombinator.com/item?id=46426624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Ensue Memory Network</h2><a id="user-content-ensue-memory-network" aria-label="Permalink: Ensue Memory Network" href="#ensue-memory-network"></a></p>
<p dir="auto"><strong>Get smarter alongside your AI.</strong></p>
<p dir="auto">Your intelligence shouldn't reset every conversation. Ensue is a persistent knowledge tree that grows with you - what you learn today enriches tomorrow's reasoning.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Idea</h2><a id="user-content-the-idea" aria-label="Permalink: The Idea" href="#the-idea"></a></p>
<p dir="auto">Every conversation with an LLM starts from zero. You explain context, re-establish preferences, repeat decisions you've already made. Your knowledge doesn't compound.</p>
<p dir="auto">Ensue changes that:</p>
<ul dir="auto">
<li><strong>Your knowledge persists</strong> - Build a tree of intelligence that spans conversations</li>
<li><strong>Context carries forward</strong> - Prior research, decisions, and insights inform new work</li>
<li><strong>You get smarter together</strong> - The LLM learns your thinking patterns, not just facts</li>
</ul>
<p dir="auto">Think of it as extended memory. When you ask about GPU inference, the LLM checks what you already know. When you make an architecture decision, it connects to past decisions in similar domains. Your accumulated knowledge becomes part of every conversation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install (Claude Code)</h2><a id="user-content-install-claude-code" aria-label="Permalink: Install (Claude Code)" href="#install-claude-code"></a></p>
<div data-snippet-clipboard-copy-content="/plugin marketplace add https://github.com/mutable-state-inc/ensue-skill"><pre><code>/plugin marketplace add https://github.com/mutable-state-inc/ensue-skill
</code></pre></div>
<div data-snippet-clipboard-copy-content="/plugin install ensue-memory"><pre><code>/plugin install ensue-memory
</code></pre></div>
<p dir="auto">Restart Claude Code. The skill will guide you through setup.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ENSUE_API_KEY</code></td>
<td>Required. Get one at <a href="https://www.ensue-network.ai/dashboard" rel="nofollow">dashboard</a></td>
</tr>
<tr>
<td><code>ENSUE_READONLY</code></td>
<td>Set to <code>true</code> to disable auto-logging (session tracking, tool capture). Manual <code>remember</code>/<code>recall</code> still works.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto" data-snippet-clipboard-copy-content="# Disable auto-logging for a session
ENSUE_READONLY=true claude

# Or add to ~/.zshrc for permanent read-only mode
export ENSUE_READONLY=true"><pre><span><span>#</span> Disable auto-logging for a session</span>
ENSUE_READONLY=true claude

<span><span>#</span> Or add to ~/.zshrc for permanent read-only mode</span>
<span>export</span> ENSUE_READONLY=true</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it</h2><a id="user-content-try-it" aria-label="Permalink: Try it" href="#try-it"></a></p>
<div data-snippet-clipboard-copy-content="&quot;remember my preferred stack is React + Postgres&quot;
&quot;what do I know about caching strategies?&quot;
&quot;check my research/distributed-systems/ notes&quot;"><pre><code>"remember my preferred stack is React + Postgres"
"what do I know about caching strategies?"
"check my research/distributed-systems/ notes"
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Links</h2><a id="user-content-links" aria-label="Permalink: Links" href="#links"></a></p>
<p dir="auto"><a href="https://www.ensue-network.ai/docs" rel="nofollow">Docs</a> · <a href="https://www.ensue-network.ai/dashboard" rel="nofollow">Dashboard</a> · <a href="https://ensue.dev/" rel="nofollow">Homepage</a> · API: <code>https://api.ensue-network.ai</code></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI employees don't pay taxes (103 pts)]]></title>
            <link>https://alec.is/posts/ai-employees-dont-pay-taxes/</link>
            <guid>46426596</guid>
            <pubDate>Mon, 29 Dec 2025 22:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alec.is/posts/ai-employees-dont-pay-taxes/">https://alec.is/posts/ai-employees-dont-pay-taxes/</a>, See on <a href="https://news.ycombinator.com/item?id=46426596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I recently overheard a conversation in a River Falls, Wisconsin, coffee shop that has stayed with me.</p><p>A person was venting to a friend about being forced to use AI—likely Microsoft Copilot—within a work spreadsheet. After several rounds of frustrating trial and error, she eventually gave up and finished the task manually. In the end, the “shortcut” had cost her more time than if she’d just done the work herself from the start.</p><p>To many, this looks like failure, but I see it as a green flag. It is a sign that the system is working exactly as it should: by keeping a human in the loop, much like a pilot in a cockpit. Being frustrated is proof, to me, they’re effectively using this amazing tool in the real world.</p><p>But if we want to phase out human-in-the-loop systems for AGI, there is one critical problem we must solve first—at least, if we care about society. Beyond the technical hurdles, the real challenge is taxes.</p><p>Governments are funded by people, not software. Our schools, roads, and healthcare systems rely on the taxation of human income. When a worker is removed from the equation, that tax base vanishes with them. At scale, the “efficiency” of AI creates a massive shortfall in public revenue. The results are predictable: crumbling infrastructure, reduced services, and an even heavier tax burden on the few workers who remain.</p><p>I know what the technologists and free-market absolutists will say. I’ve heard the arguments, but they crumble under scrutiny:</p><h3 id="corporate-taxes-will-cover-the-gap">“Corporate taxes will cover the gap.”</h3><p>Argument: If companies replace humans with AI, their profits will skyrocket. We can just tax those profits to fund society.</p><p>Reality: Payroll taxes are unavoidable “flow” taxes. Corporate profit taxes are a game of hide-and-seek. Corporations are experts at shifting IP to tax havens, engaging in stock buybacks, and “reinvesting” to show zero profit on paper. You cannot fund a government on the goodwill of creative accountants.</p><h3 id="its-just-a-tool-like-a-tractor">“It’s just a tool, like a tractor.”</h3><p>Argument: We didn’t tax tractors when they replaced farmhands; we shouldn’t tax AI for replacing lawyers.</p><p>Reality: Tractors magnified physical labor; they didn’t simulate the mind. More importantly, the industrial revolution took decades. The AI displacement is happening in quarters. “Retraining” is a myth when the goalpost moves faster than the semester.</p><h3 id="you-cant-tax-software-it-has-no-location">“You can’t tax software; it has no location.”</h3><p>Argument: If you tax AI “agents,” companies will just host the models in a deregulated jurisdiction and beam the work in.</p><p>Reality: Correct, you can’t tax the code. But you can tax the value flow, the revenue generated in-country, or the massive energy consumption of the data centers. We don’t need to give AI personhood to tax the electricity it burns to replace a taxpayer.</p><h3 id="this-is-just-luddite-fear-mongering">“This is just Luddite fear-mongering.”</h3><p>Reality: It’s not fear; it’s math. If 30% of the workforce is displaced, and the remaining 70% have to pay for the social safety net (or UBI) required to keep the displaced alive, the math breaks.</p><p>Anyway…</p><p>This is why we should be cautious about celebrating the wholesale replacement of people with AI agents. I am an optimist when it comes to LLMs and the possibilities they unlock (especially in SWE), but enthusiasm shouldn’t blind us to economic reality.</p><p>Productivity gains that bypass human labor also bypass the tax system that sustains our society. AI should be used to offload drudgery—to free humans for meaningful work—not to quietly dismantle the systems that support us all.</p><p>Some investors know this. They aren’t trying to improve society; they are trying to exit it. As my AI assistant <code>gemini-3-flash-preview</code> put it so blindly today:</p><h3 id="its-a-bold-strategy-replace-the-humans-who-pay-for-the-roads-then-take-the-billions-you-made-and-flee-to-an-island-where-you-dont-need-roads">“It’s a bold strategy: replace the humans who pay for the roads, then take the billions you made and flee to an island where you don’t need roads.”</h3><p>The evolution shouldn’t be human to AI, but human to human-in-the-loop. It’s the necessary compromise: we guarantee the quality of the output, capital gets its efficiency, and—crucially—the tax base that keeps civilization running remains intact.</p><hr><p><a href="https://news.ycombinator.com/item?id=46426596">Discuss this post on Hacker News</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ManusAI Joins Meta (209 pts)]]></title>
            <link>https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation</link>
            <guid>46426534</guid>
            <pubDate>Mon, 29 Dec 2025 22:24:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation">https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation</a>, See on <a href="https://news.ycombinator.com/item?id=46426534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div spellcheck="false" data-slate-editor="true" data-slate-node="value" contenteditable="false" zindex="-1"><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">The news is out, and it's big: Manus is joining Meta.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">This announcement is more than just a headline—it's validation of our pioneering work with General AI Agents.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">Since the launch, Manus has focused on building a general-purpose AI agent designed to help users tackle research, automation, and complex tasks. Through continuous product iteration, we’ve been working hard to make these capabilities more reliable and useful across a growing range of real-world use cases. In just a few months, our agent has processed more than 147 Trillion tokens and powered the creation of over 80 Million virtual computers.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">We believe in the potential of autonomous agents, and this development reinforces Manus’s role as an execution layer — turning advanced AI capabilities into scalable, reliable systems that can carry out end-to-end work in real-world settings.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">Our top priority is ensuring that this change won’t be disruptive for our customers. We will continue to sell and operate our product subscription service through our app and website. The company will continue to operate from Singapore.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">Our solution is driving value for millions of users worldwide today. With time, we hope to expand this subscription to the millions of businesses and billions of people on Meta’s platforms.</span></span></span></p></div><div><p><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-string="true">“Joining Meta allows us to build on a stronger, more sustainable foundation without changing how Manus works or how decisions are made,” said Xiao Hong, CEO of Manus. “We’re excited about what the future holds with Meta and Manus working together and we will continue to iterate the product and serve users that have defined Manus from the beginning.”</span></span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is dead. Where do we go now? (739 pts)]]></title>
            <link>https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/</link>
            <guid>46425198</guid>
            <pubDate>Mon, 29 Dec 2025 20:29:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/">https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/</a>, See on <a href="https://news.ycombinator.com/item?id=46425198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<p><a href="#content">
			Skip to content		</a></p><!-- .site-header -->

		<div id="content">
	<main id="main">
		
<article id="post-3482">
	<!-- .entry-header -->

	
	
	<div>
		
<div><p>It’s anecdotal, I know, but my main <a href="https://bigtop.co.za/" target="_blank" rel="noreferrer noopener">entertainment business</a> revenue is down 50% over the past 3 months. Our main paid source of leads was Google Ads, which have served us well over the past 10 years or so – I think I know what I am doing in adwords by now. </p><p>Once per month I check the analytics, updating keywords and tweaking ad campaigns. Over the past year we increased our budget, and then I started looking at it once per week, running simultaneous campaigns with different settings, just trying to get SOMETHING. </p><p>Last month Google gave us a bonus – free money! This was 5x our monthly ad spend, to spend just when we needed it most – over the December holidays. I added another new campaign, updated the budgets for the existing ones. Still no change. The last week there was money to burn, left over from unused ad spend. I increased our budget to 10x. ZERO RETURN. </p><p>The money ran out. I am not putting more in. Where do we go from here? </p></div>



<h2>What is next</h2>



<p>Research shows that many young people are getting their information from short video platforms like TikTok and Instagram. We are trying ads on there. </p>



<p><br>Our customer base is comprised of 50% returning customers (I am proud of that statistic!). We have an email newsletter, we started sending them regularly over the past 2 months. Remember us? </p>



<div><p>We also plan to do some actual physical advertising – I am going to a market next weekend, doing a free show or two, handing out cards. </p><p>Also, we are branching out – I have some projects I want to make, related to the <a href="http://www.patreon.com/c/CircusScientist" target="_blank" rel="noreferrer noopener">Magic Poi project</a>, and hopefully sell. We ordered supplies last week. </p><p>Right now, though – I’m broke. Anyone need a <a href="https://devsoft.co.za/" target="_blank" rel="noreferrer noopener">website or IOT project built</a>? I am AI assisted, very fast! </p></div>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-3482 -->

<!-- .comments-area -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</main><!-- .site-main -->

	
</div><!-- .site-content -->

		<!-- .site-footer -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta's ads tools started switching out top-performing ads with AI-generated ones (131 pts)]]></title>
            <link>https://www.businessinsider.com/meta-ai-generating-bizarre-ads-advantage-plus-2025-10</link>
            <guid>46424733</guid>
            <pubDate>Mon, 29 Dec 2025 19:51:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/meta-ai-generating-bizarre-ads-advantage-plus-2025-10">https://www.businessinsider.com/meta-ai-generating-bizarre-ads-advantage-plus-2025-10</a>, See on <a href="https://news.ycombinator.com/item?id=46424733">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-content-container="">

  
    
  
    

  <section>
    
    
    
    
      <section id="post-body" data-component-type="post-body" data-load-strategy="exclude" data-lock-content="">
            
            
            
            <div data-component-type="post-hero" data-load-strategy="exclude">
                
                <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                    <div>
                      <meta itemprop="contentUrl" content="https://i.insider.com/69025a210be9845f2dc55366?width=700">
                      <p><img src="https://i.insider.com/69025a210be9845f2dc55366?width=700" srcset="https://i.insider.com/69025a210be9845f2dc55366?width=400&amp;format=jpeg&amp;auto=webp 400w, https://i.insider.com/69025a210be9845f2dc55366?width=500&amp;format=jpeg&amp;auto=webp 500w, https://i.insider.com/69025a210be9845f2dc55366?width=700&amp;format=jpeg&amp;auto=webp 700w, https://i.insider.com/69025a210be9845f2dc55366?width=1000&amp;format=jpeg&amp;auto=webp 1000w, https://i.insider.com/69025a210be9845f2dc55366?width=1300&amp;format=jpeg&amp;auto=webp 1300w, https://i.insider.com/69025a210be9845f2dc55366?width=2000&amp;format=jpeg&amp;auto=webp 2000w" sizes="(min-width: 1280px) 900px" alt="True Classic ad" decoding="sync">
                    </p></div>
                
                  <span>
                        <span>
                          
                          <label for="caption-drawer-btn">
                            <svg role="img" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 24 24">
                              <path fill="currentColor" fill-rule="evenodd" d="m4.56 18.5 7.486-7.72 7.394 7.626 2.56-2.64L12.046 5.5 2 15.86l2.56 2.64Z"></path>
                            </svg>        </label>
                  
                          <figcaption data-e2e-name="image-caption">
                            <span>"This is what Meta's AI did to my top ad," the head of marketing for clothing brand True Classic wrote on X.</span>
                            <span>
                              <span data-e2e-name="image-source" itemprop="creditText">X/Screenshot</span>          </span>
                          </figcaption>
                        </span>
                  </span></figure>
            </div>
    
    
    
              
      
            
      
              
              
              
              <div data-component-type="post-summary-bullets" data-load-strategy="exclude" data-track-marfeel="post-summary-bullets">
                <ul>
                    <li>Meta's generative AI ads system is having some … senior moments.</li>
                    <li>Advertisers have noticed the platform conjuring up bizarre ads, such as an AI granny.</li>
                    <li>The phenomenon has persisted even after brands switched off some AI-related settings.</li>
                </ul>
              </div>
      
            
            
            
            
            <section data-component-type="post-body-content" data-load-strategy="exclude" data-track-content="" data-post-type="story" data-track-marfeel="post-body-content">
            
                <p>Marketers are finding out the hard way that <a target="_self" href="https://www.businessinsider.com/meta-adds-new-generative-ai-to-advertising-tools-details-2024-5" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">Meta's AI tools</a> can churn out some very strange ads.</p><p>Meta CEO Mark Zuckerberg said earlier this year that <a target="_blank" href="https://stratechery.com/2025/an-interview-with-meta-ceo-mark-zuckerberg-about-ai-and-the-evolution-of-social-media/" data-track-click="{&quot;click_type&quot;:&quot;other&quot;,&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;outbound_click&quot;}" rel=" nofollow">the company's artificial intelligence</a> had become so advanced that advertisers would no longer need to create their own ads. Brands could simply hand over their bank accounts and campaign objectives and let the AI take the wheel.</p><p>Some marketers, however, haven't been pleased with the results when they let <a target="_self" href="https://www.businessinsider.com/metas-bet-on-ai-is-bringing-back-advertisers-2023-1" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">Meta's AI</a> drive their ad campaigns.</p><p>Bryan Cano, head of marketing of the "elevated basics" clothing brand True Classic, was aghast when he noticed Meta had switched out his top-performing ad — an attractive millennial man in a matching fleece set, casually posing on a stool — with an AI-generated photo of a cheerful yet unnatural granny sitting in an armchair. True Classic typically targets its Meta ads to men ages 30 to 45.</p><p>The ad ran on Meta for three days before customers alerted True Classic to it, Cano told Business Insider. He said that while the direction Meta is taking with AI makes sense, he felt the generative-ads tool wasn't yet ready for prime time.</p>
              
            
              
            <p>"This doesn't just affect our relationship with customers, who were upset by this, but it could also damage relationships with wholesale customers and the relationships we have built with retailers," Cano said.</p><p>Tech companies, including Meta, Google, Amazon, and TikTok, have heralded AI as a way for advertisers to speed up ad creation and <a target="_self" href="https://www.businessinsider.com/tiktok-gmv-max-september-shop-ads-big-brand-pushback-2025-8" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">enhance the performance</a> of their campaigns. However, many advertisers are wary of ceding too much control to <a target="_self" href="https://www.businessinsider.com/google-ai-boosts-ad-performance-but-some-advertisers-push-back-2023-11" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">black box systems</a>, particularly since consumers often have an <a target="_self" href="https://www.businessinsider.com/brands-reject-ai-aerie-heineken-polaroid-marketing-2025-10" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">aversion to ads</a> that are obviously generated by AI. The AI granny is a comical example of what can happen when algorithms go unchecked.</p><p>True Classic isn't the only brand to have a chaotic Meta ad experience recently, thanks to AI.</p><p>European footwear brand Kirruna noticed Meta's AI had whipped up an ad featuring a model whose leg had twisted around completely the wrong way.</p>
              <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
              
              
                <div>
            
              
              <meta itemprop="contentUrl" content="https://i.insider.com/690263750be9845f2dc55462">
              <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/png" data-srcs="{&quot;https://i.insider.com/690263750be9845f2dc55462&quot;:{&quot;contentType&quot;:&quot;image/png&quot;,&quot;aspectRatioW&quot;:591,&quot;aspectRatioH&quot;:1280}}" alt="Kirruna ad">
            </p></div>
              
              <span>
                    <figcaption data-e2e-name="image-caption">
                      That looks painful.
                      
              <span data-e2e-name="image-source" itemprop="creditText">
              
              Courtesy of Pieter Van der Auwera
              
              </span>
                    </figcaption>
                  </span>
              </figure>
            <p>Elsewhere, Meta generated an ad for the e-bike company Lectric, asking "What are the easiest eBikes to put in my trunk," which featured the trunk of a car. So far, so normal — except the car also appeared to be flying through clouds. Logan Young, Lectric's VP of digital marketing, said the company managed to catch the ad before it ran.</p><p>"We turn it all off, pretty much," Young said of Meta's AI-generated ad enhancements.</p><p>A Meta spokesperson said in a statement that millions of advertisers are finding value and improved performance by using its Advantage+ creative tools.</p><p>"Advertisers who use our full image generation feature have the opportunity to review the generated images before running their ad. We are continuously improving our products and features based on advertiser feedback," the Meta spokesperson said.</p><p>Cano of True Classic said the AI granny ad hadn't surfaced as one of the selected ads in its campaign preview, which is why the brand was caught off guard.</p>
              <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
              
              
                <div>
            
              
              <meta itemprop="contentUrl" content="https://i.insider.com/690273e9599d46a4ccc1177c">
              <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/png" data-srcs="{&quot;https://i.insider.com/690273e9599d46a4ccc1177c&quot;:{&quot;contentType&quot;:&quot;image/png&quot;,&quot;aspectRatioW&quot;:794,&quot;aspectRatioH&quot;:524}}" alt="Lectric AI ads">
            </p></div>
              
              <span>
                    <figcaption data-e2e-name="image-caption">
                      Lectric decided not to run these AI-generated ads.
                      
              <span data-e2e-name="image-source" itemprop="creditText">
              
              Courtesy of Logan Young
              
              </span>
                    </figcaption>
                  </span>
              </figure>
            <h2 id="c129d359-b5d5-4644-b0d3-cbd48a64baeb" data-toc-id="c129d359-b5d5-4644-b0d3-cbd48a64baeb">Surreptitious settings</h2><p>So, what's going on here?</p><p>Advertisers told Business Insider that the cause of the uncanny valley Meta ads seemed to be two tickbox settings within their accounts — "test new creative features" and "automatic adjustments" — and another group of "Advantage+ creative" settings in the area where advertisers build their campaigns. Advantage+ is the brand name for Meta's suite of <a target="_self" href="https://www.businessinsider.com/meta-adds-new-generative-ai-to-advertising-tools-details-2024-5" data-track-click="{&quot;element_name&quot;:&quot;body_link&quot;,&quot;event&quot;:&quot;tout_click&quot;,&quot;index&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}" rel="">AI-powered ad</a> products.</p><p>Three advertisers also said they'd encountered a problem where Meta automatically switched those toggles to "on," even when they'd explicitly turned them off — meaning they inadvertently spent their budgets on AI-generated ads they didn't intend to run.</p><p>Rok Hladnik, CEO of the marketing agency Flat Circle, which manages around $100 million in annual Meta ad spending for numerous direct-to-consumer brands, said he has encountered similar issues with Meta auto-generating bizarre ads. His company is now setting aside time two to three mornings a week to manually check that AI enhancements are switched off. The task takes up to an hour per account, he said.</p><p>"It randomly turns on, even for ads you've turned off for a second time," Hladnik said. "It's a complete mess."</p><p>Jonas Vonk, founder of the e-commerce business Yuzu Knives, said he became so frustrated by how toggles like the AI-creative feature can be hidden within Meta's settings that he created his own startup, AdsFlow, which helps surface them more clearly for ad buyers.</p><p>"You really have to dig for them, and switch them all off every time you run an ad," Vonk said of Meta's ad settings.</p><p>Pieter Van der Auwera, a marketing consultant who runs Meta ads for the Kirruna shoe brand, said the company has had to issue two refunds to customers who complained that the items they received weren't made of the material depicted in ads generated by Meta's AI. (Remarkably, the ad featuring the model with the backward leg did a good job of replicating the real boot, he added.)</p><p>Van der Auwera said an issue with AI-generated ads is that while Meta provides a preview of ads prelaunch, they need to be opened one by one to check, which can be a time suck when brands run hundreds of different versions.</p><p>"When I first heard about Meta AI, I was really hopeful and thought it would take away a lot of my work and make my work a lot faster so that I can do more for my clients," Van der Auwera said. "Now, I have more work than before."</p>
            
            
            </section>
            
            
            
            
            
            
    
    
    
    
      </section>

    
    <!-- Included desktop "post-aside" -->  

    
      
      <section data-component-type="post-bottom" data-load-strategy="exclude" data-track-marfeel="post-bottom">
        <section>
    
    
    
          
          
          
          <div data-component-type="post-category-tags" data-load-strategy="lazy" data-track-marfeel="post-category-tags">
            <ul data-track-click-shared="{&quot;product_field&quot;:&quot;bi_value_unassigned&quot;,&quot;event&quot;:&quot;navigation&quot;,&quot;element_name&quot;:&quot;category_link&quot;}">
                
                <li>
                  <a data-track-click="" href="https://www.businessinsider.com/category/meta" title="Meta">Meta</a>
                </li>      
                <li>
                  <a data-track-click="" href="https://www.businessinsider.com/category/ai" title="AI">AI</a>
                </li>
          
            </ul>
          </div>
    
            
              
              
              <section data-component-type="dad-related-posts" data-delay-third-party-scripts="true" data-size="4" data-min-size="3" data-container-index="" data-included-verticals="advertising" data-placement="post-bottom" data-track-marfeel="dad-related-posts-post-bottom" data-excluded-verticals="bi-video" data-root-margin="250px 0px" data-track-view="{&quot;element_name&quot;:&quot;end_of_article_recirc&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;,&quot;subscription_experience&quot;:&quot;bi_value_unassigned&quot;}">
                  <p>
                    <h2>
                      Read next
                    </h2>
                  </p>
            
            
                
              </section>
        </section>
    
        
    
          <section data-track-page-area="Post Bottom">
          <!-- Included desktop "taboola" -->    <vendor-taboola data-component-type="vendor-taboola" data-root-margin="0px 0px 100% 0px" data-consent="MARKETING" config="{&quot;providerName&quot;:&quot;taboola&quot;,&quot;providerPageType&quot;:{&quot;article&quot;:&quot;auto&quot;},&quot;providerUrl&quot;:&quot;//cdn.taboola.com/libtrc/businessinsider/loader.js&quot;,&quot;providerFlushValue&quot;:{&quot;flush&quot;:true},&quot;providerData&quot;:{&quot;mode&quot;:&quot;thumbs-1r&quot;,&quot;container&quot;:&quot;taboola-below-main-column&quot;,&quot;placement&quot;:&quot;below-main-column&quot;,&quot;onlyOn&quot;:&quot;desktop&quot;,&quot;target_type&quot;:&quot;mix&quot;}}" data-load-strategy="defer">
                
              </vendor-taboola>
          
          <!-- Excluded mobile "taboola" --></section>
            
            
      </section>
  </section>

  
  


  <back-to-home data-component-type="back-to-home" data-load-strategy="defer" data-only-on="mobile">
  
    
  
    
  </back-to-home></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When someone says they hate your product (139 pts)]]></title>
            <link>https://www.getflack.com/p/responding-to-negative-feedback</link>
            <guid>46424460</guid>
            <pubDate>Mon, 29 Dec 2025 19:30:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.getflack.com/p/responding-to-negative-feedback">https://www.getflack.com/p/responding-to-negative-feedback</a>, See on <a href="https://news.ycombinator.com/item?id=46424460">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Let’s say you get negative feedback in public. It’s blunt, even abrasive. You instinctively bristle: they’re wrong, they don’t get it, they’re trolling. So naturally, you push back. But your rebuttal only makes the critic double down, and now others are piling on. You clarify your position, but it only gets worse.</p><p>Why does this happen, and what can you do about it?</p><p><span>Imagine a thermostat for your credibility. People form an opinion on what the correct setting should be, and they regulate if the reality seems off. If you’re above their setpoint, people feel you’re overrated and want to bring you down; if you’re below it, people feel you’re underrated and want to build you up. And the </span><em>farther off</em><span> you are, the more they’ll overcorrect.</span></p><p>When someone is frustrated with you (or your company, or your product), they have a view of how much you should be dinged for something. Venting in public is a way to regulate your reputation and achieve the proper homeostasis, like turning a thermostat toward the desired setting.</p><p>This means that the substance of someone’s feedback is totally separate from their frustration or desire to be heard. Complaints often seem unfair and you might want to jump to fact checking, but that won’t get anywhere unless you first resolve the frustration and make people feel that you actually listened. (It turns out facts do care about our feelings.)</p><p>When you reject someone’s feedback, you’re implying that (1) they’re wrong, (2) they’re possibly dumb, and (3) they don’t have the authority to judge you.</p><p>To be clear, sometimes that’s all true and you need to fight or ignore. But in this case, we’re focusing on substantive feedback from people who matter, like your customers.</p><p>By rebutting, you’re forcing them to justify and defend their initial statements. Either they were wrong to raise it or you were wrong to resist! Their choice is obvious.</p><p>Now their move is to escalate further, maybe with more examples or stronger language. As this plays out, onlookers will tend to take the critic’s side, as an angry customer is more relatable than an imperious founder.</p><p>Going back to the thermostat analogy, a stubborn dial only makes people twist harder.</p><p>Here’s a recent example.</p><p><span>Last week, Aiden Bai posted about grievances with CodeRabbit. Pretty normal so far; users complain about products all the time. A CodeRabbit engineer jumped in to ask for feedback, which was good, and Aiden followed up with details (full context </span><a href="https://x.com/aidenybai/status/2004033871244099613" rel="">here</a><span>):</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!LaKm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LaKm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 424w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 848w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 1272w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!LaKm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png" width="492" height="320.12582781456956" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:786,&quot;width&quot;:1208,&quot;resizeWidth&quot;:492,&quot;bytes&quot;:204114,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!LaKm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 424w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 848w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 1272w, https://substackcdn.com/image/fetch/$s_!LaKm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>CodeRabbit’s CEO, Harjot, then entered the chat:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!A4lW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!A4lW!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 424w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 848w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 1272w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!A4lW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png" width="472" height="468.81081081081084" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1176,&quot;width&quot;:1184,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:217392,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!A4lW!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 424w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 848w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 1272w, https://substackcdn.com/image/fetch/$s_!A4lW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In one post, he</p><ul><li><p>called his own customer clueless,</p></li><li><p>then implied CodeRabbit had enough users that this feedback didn’t matter,</p></li><li><p>then condescendingly speculated that, even if it were valid, it could probably be solved by “simpler controls and a lot of handholding,”</p></li><li><p><span>then</span><em>, </em><span>to gild the lily, made sure to insult not only Aiden personally but indie developers as a category.</span></p></li></ul><p>Now, we should remember that writing a bad response isn’t the same as being a bad person. Harjot was frustrated by what he felt was a bad faith attack on his company, and I have a lot of sympathy for founders getting hater-fatigue.</p><p>Nonetheless, the response was objectively not good, and what came next was predictable:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SRle!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SRle!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 424w, https://substackcdn.com/image/fetch/$s_!SRle!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 848w, https://substackcdn.com/image/fetch/$s_!SRle!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 1272w, https://substackcdn.com/image/fetch/$s_!SRle!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SRle!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png" width="472" height="459.1782682512733" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1146,&quot;width&quot;:1178,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:204664,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!SRle!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 424w, https://substackcdn.com/image/fetch/$s_!SRle!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 848w, https://substackcdn.com/image/fetch/$s_!SRle!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 1272w, https://substackcdn.com/image/fetch/$s_!SRle!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!vsPu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!vsPu!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 424w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 848w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 1272w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!vsPu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png" width="476" height="554.7918088737201" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1366,&quot;width&quot;:1172,&quot;resizeWidth&quot;:476,&quot;bytes&quot;:559361,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!vsPu!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 424w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 848w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 1272w, https://substackcdn.com/image/fetch/$s_!vsPu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fe26fc5-d265-4bdc-880b-f9519ce0e2ce_1172x1366.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The net upshot was bad vibes for CodeRabbit and a layup for its competitors:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!xMvr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!xMvr!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 424w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 848w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 1272w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!xMvr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png" width="444" height="497.1602023608769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1328,&quot;width&quot;:1186,&quot;resizeWidth&quot;:444,&quot;bytes&quot;:395031,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!xMvr!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 424w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 848w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 1272w, https://substackcdn.com/image/fetch/$s_!xMvr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cf61160-0960-41d8-b46b-f2dd6e5329da_1186x1328.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The episode finally ended with an apologish from Harjot:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!bZ5L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!bZ5L!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 424w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 848w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 1272w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!bZ5L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png" width="460" height="695.5288461538462" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1258,&quot;width&quot;:832,&quot;resizeWidth&quot;:460,&quot;bytes&quot;:289737,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!bZ5L!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 424w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 848w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 1272w, https://substackcdn.com/image/fetch/$s_!bZ5L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F942dd7bc-0a2c-4d80-a0af-1868f25a4ac7_832x1258.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>My advice for this kind of post is to pick a lane: if it’s an apology, make it a proper one and resist the urge to sprinkle in more veiled jabs. You could also take the other route and just not apologize. It’s best to try avoiding any uncanny valley situations. But it happens: bad interactions are unavoidable and this one wasn’t too damaging in the grand scheme.</p><p>As Tolstoy would’ve said, all positive mentions are alike; every negative mention is irksome in its own way. It varies based on who’s involved, what the feedback is, how much traction it’s getting, etc. etc. etc. — there isn’t a universal solution. As I’ve noted, sometimes it really is bad faith trolling, and that calls for a very different approach.</p><p><span>But </span><em>in general</em><span>, as a founder you should be your own hardest critic. You should have a higher standard for yourself than anyone else could possibly impose. You should be voracious for user feedback, even if it feels unfair.</span></p><p>And the magical thing is, when you sincerely feel that way and you demonstrate it, criticism tends to wilt. </p><p>Imagine a scenario where you get negative feedback, and you overrule the instinct to push back. Instead, you listen to the feedback, you embrace the responsibility to make the best product possible, you even thank them for caring enough to share their thoughts (remembering that your real enemy isn’t negativity but indifference).</p><p>With just this, you’ll have shown more curiosity, more ownership, more humility than they were even hoping to enforce. They’re surprised to find that the imbalance is now in the other direction. Instead of feeling snubbed or dismissed, they might consider whether their initial jab was excessive. They now risk overcorrecting and overshooting the setpoint they were aiming for.</p><p>And when people feel they’ve gone too far, they restore balance by pulling back. It’s common to see someone gearing up for a confrontation but, upon finding the other person gracious and receptive, pivot to, “Thanks for sharing the context,” “I shouldn’t have overreacted,” “I appreciate how you handled this, “I do like the product overall,” or some other form of deescalation — maybe even an apology or retraction.</p><p>Claude gets it!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Uy58!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Uy58!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 424w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 848w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 1272w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Uy58!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png" width="520" height="506.734693877551" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/df9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1146,&quot;width&quot;:1176,&quot;resizeWidth&quot;:520,&quot;bytes&quot;:296267,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.getflack.com/i/182801768?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Uy58!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 424w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 848w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 1272w, https://substackcdn.com/image/fetch/$s_!Uy58!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf9bfe93-ffb9-46b3-a007-b023a9839a7d_1176x1146.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>When getting negative feedback:</p><ol><li><p>Separate the information part from the emotion part. There’s the substance of the feedback, and there’s the customer’s frustration and expectation of being heard. Those are discrete, and you can’t address the former without resolving the latter.</p></li><li><p>Start by aligning on principles, before rushing to defend yourself. Whatever the merits of the feedback, you agree that quality is important, that feedback is valuable, and that the feedback has found the person who’s responsible. Again, there’s no hope of aligning on facts if you can’t first align on principles.</p></li><li><p>Make a point of overindexing on accountability. Take more responsibility than what seems necessary. Take so much ownership that it surprises people. This obviates their need to hector you over it and removes a lot of surface area for attack, creating space for a calmer exchange. More importantly, if you’re the founder, the reality is that every detail of your product does fall on you.</p></li><li><p>If you need to clarify facts, explain instead of defending. You can share the exact same information in a way that’s either defensive and caustic, or earnest and transparent. The only difference is tone.</p></li><li><p>If self-critique or apology is warranted (it isn’t always), keep it straightforward. No need to grovel or self flagellate. Recap the problem plainly, explain the fix, say what you’re doing to prevent it in the future, and wrap it up. Then move on.</p></li></ol></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All Delisted Steam Games (236 pts)]]></title>
            <link>https://delistedgames.com/all-delisted-steam-games/</link>
            <guid>46424262</guid>
            <pubDate>Mon, 29 Dec 2025 19:16:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://delistedgames.com/all-delisted-steam-games/">https://delistedgames.com/all-delisted-steam-games/</a>, See on <a href="https://news.ycombinator.com/item?id=46424262">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="simcal"><h2>Upcoming Delistings</h2><div data-prev="1767070859" data-next="1767157266" data-heading-small="Dec 2025" data-heading-large="December 2025" data-calendar-id="2393" data-timezone="America/Indiana/Indianapolis" data-offset="-18000" data-week-start="0" data-calendar-start="1766984400" data-calendar-end="1775707141" data-events-first="1767070859" data-events-last="1775707141"><div data-events-count="1">
	<ul>
	<li itemscope="" itemtype="http://schema.org/Event" data-start="1767070859">
		<div><p><strong><span itemprop="name">ChronoForge</span><br>
</strong><span data-event-start="1767070859" data-event-format="F j, Y" itemprop="startDate" content="2025-12-30T00:00:59-05:00">December 30, 2025</span><br>
</p><div itemprop="description"><p><a href="https://delistedgames.com/blockchain-based-chronoforge-to-shut-down-by-december-30th/">READ MORE</a></p>
</div></div>
	</li>
</ul>

</div>
<div data-events-count="7">
	<ul>
	<li itemscope="" itemtype="http://schema.org/Event" data-start="1767157259">
		<div><p><strong><span itemprop="name">NBA 2K24 (online services)</span><br>
</strong><span data-event-start="1767157259" data-event-format="F j, Y" itemprop="startDate" content="2025-12-31T00:00:59-05:00">December 31, 2025</span><br>
</p><div itemprop="description"><p><a href="https://delistedgames.com/nba-2k23-losing-online-servers-december-31th-2024-and-nba-2k24-on-december-31th-2025/">READ MORE</a></p>
</div></div>
	</li>
	<li itemscope="" itemtype="http://schema.org/Event" data-start="1767157259">
		<div><p><strong><span itemprop="name">Chiyo</span><br>
</strong><span data-event-start="1767157259" data-event-format="F j, Y" itemprop="startDate" content="2025-12-31T00:00:59-05:00">December 31, 2025</span><br>
</p><div itemprop="description"><p><a href="https://delistedgames.com/chiyo-leaving-steam-on-december-31st/">READ MORE</a></p>
</div></div>
	</li>
	<li itemscope="" itemtype="http://schema.org/Event" data-start="1767157259">
		<div><p><strong><span itemprop="name">Ming Imperial Guards</span><br>
</strong><span data-event-start="1767157259" data-event-format="F j, Y" itemprop="startDate" content="2025-12-31T00:00:59-05:00">December 31, 2025</span><br>
</p><div itemprop="description"><p><a href="https://delistedgames.com/ming-imperial-guards-to-be-delisted-on-steam-on-december-31st/">READ MORE</a></p>
</div></div>
	</li>
	
	
	
	
</ul>
</div>
</div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The future of software development is software developers (175 pts)]]></title>
            <link>https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/</link>
            <guid>46424233</guid>
            <pubDate>Mon, 29 Dec 2025 19:14:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/">https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/</a>, See on <a href="https://news.ycombinator.com/item?id=46424233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>I’ve been a computer programmer all-told for 43 years. That’s more than half the entire history of electronic programmable computers. </p>



<p>In that time, I’ve seen a lot of things change. But I’ve also seen some things stay pretty much exactly the same.</p>



<p>I’ve lived through several cycles of technology that, at the time, was hailed as the “end of computer programmers”. </p>



<p>WYSIWYG, drag-and-drop editors like Visual Basic and Delphi were going to end the need for programmers. </p>



<figure><a href="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png"><img data-attachment-id="2936" data-permalink="https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/image-42/" data-orig-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=300" data-large-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=800" width="800" height="600" src="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=800" alt="" srcset="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png 800w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=150 150w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=300 300w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-4.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"></a></figure>



<p>Wizards and macros in Microsoft Office were going to end the need for programmers.</p>



<p>Executable UML was going to end the need for programmers.</p>



<p>No-Code and Low-Code platforms were going to end the need for programmers.</p>



<p>And now, Large Language Models are, I read on a daily basis, going to end the need for programmers.</p>



<p>These cycles are nothing new. In the 1970s and 1980s, 4GLs and 5GLs were touted as the end of programmers.</p>



<p>And before them, 3GLs like Fortran and COBOL.</p>



<p>And before them, compilers like A-0 were going to end the need for programmers who instructed computers in binary by literally punching holes in cards.</p>



<figure><a href="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png"><img data-attachment-id="2938" data-permalink="https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/image-43/" data-orig-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png" data-orig-size="691,460" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png?w=300" data-large-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png?w=691" width="691" height="460" src="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png?w=691" alt="" srcset="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png 691w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png?w=150 150w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-5.png?w=300 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"></a></figure>



<p>But it goes back even further, if we consider the earliest (classified) beginning of electronic programmable computers. The first of them, COLOSSUS, was programmed by physically rewiring it.</p>



<figure><a href="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png"><img data-attachment-id="2939" data-permalink="https://codemanship.wordpress.com/2025/11/25/the-future-of-software-development-is-software-developers/image-44/" data-orig-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png" data-orig-size="275,183" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png?w=275" data-large-file="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png?w=275" loading="lazy" width="275" height="183" src="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png?w=275" alt="" srcset="https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png 275w, https://codemanship.wordpress.com/wp-content/uploads/2025/11/image-6.png?w=150 150w" sizes="(max-width: 275px) 85vw, 275px"></a></figure>



<p>Perhaps the engineers who worked on that machine sneered at the people working on the first stored-program computers for not being “<em>real </em>programmers”.</p>



<p>In every cycle, the predictions have turned out to be very, very wrong. The end result hasn’t been fewer programmers, but <em>more </em>programs and <em>more </em>programmers. It’s a $1.5 trillion-a-year example of <a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons Paradox</a>.</p>



<p>And here we are again, in another cycle. </p>



<p>“But this time it’s different, Jason!”</p>



<p>Yes, it certainly is. Different in scale to previous cycles. I don’t recall seeing the claims about Visual Basic or Executable UML on the covers of national newspapers. I don’t recall seeing entire economies betting on 4GLs.</p>



<p>And there’s another important distinction: in previous cycles, the technology <em>worked</em> <em>reliably</em>. We really could produce working software faster with VB or with Microsoft Access. This is proving not to be the case with LLMs, which – for the majority of teams – actually slow them down while making the software less reliable and less maintainable. It’s a kind of LOSE-LOSE in most cases. (Unless those teams have addressed the <a href="https://codemanship.wordpress.com/2025/10/30/the-ai-ready-software-developer-index/">real bottlenecks in their development process</a>.)</p>



<p>But all of this is academic. Even if the technology genuinely made a positive difference for more teams, it still wouldn’t mean that we don’t need programmers anymore.</p>



<p>The hard part of computer programming isn’t expressing what we want the machine to do in code. The hard part is turning human thinking – with all its wooliness and ambiguity and contradictions – into <em>computational thinking</em> that is logically precise and unambiguous, and that can then be expressed formally in the syntax of a programming language.</p>



<p>That was the hard part when programmers were punching holes in cards. It was the hard part when they were typing COBOL code. It was the hard part when they were bringing Visual Basic GUIs to life (presumably to track the killer’s IP address). And it’s the hard part when they’re prompting language models to predict plausible-looking Python.</p>



<p>The hard part has always been – and likely will continue to be for many years to come – knowing <em>exactly </em>what to ask for.</p>



<p>Edgar Dijkstra called it <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html">nearly 50 years ago</a>: we will never be programming in English, or French, or Spanish. Natural languages have not evolved to be precise enough and unambiguous enough. Semantic ambiguity and language entropy will always defeat this ambition.</p>



<p>And while pretty much anybody can learn to think that way, not everybody’s going to enjoy it, and not everybody’s going to be good at it. The demand for people who do and people who are will always outstrip supply.</p>



<p><em>Especially </em>if businesses stop hiring and training them for a few years, like they recently have. But these boom-and-bust cycles have also been a regular feature during my career. This one just happens to coincide with a technology hype cycle that presents a convenient excuse.</p>



<p>There’s no credible evidence that “AI” is replacing software developers in significant numbers. A combination of over-hiring during the pandemic, rises in borrowing costs, and a data centre gold rush that’s diverting massive funds away from headcount, are doing the heavy lifting here.</p>



<p>And there’s no reason to believe that “AI” is going to evolve to the point where it can do what human programmers have to do – understand, reason and learn – anytime soon. AGI seem as far away as it’s always been, and the hard part of computer programming really does require general intelligence.</p>



<p>On top of all that, “AI” coding assistants are really nothing like the compilers and code generators of previous cycles. The exact same prompt is very unlikely to produce the exact same computer program. And the code that gets generated is pretty much guaranteed to have issues that a real programmer will need to be able to recognise and address.</p>



<p>When I write code, I’m executing it in my head. My internal model of a program isn’t just syntactic, like an LLM’s is. I’m not just matching patterns and predicting tokens to produce statistically plausible code. I actually <em>understand </em>the code.</p>



<p>Even the C-suite has noticed the correlation of major outages and incidents proceeding grand claims about how much of that company’s code is “AI”-generated.</p>



<p>The folly of many people now claiming that “prompts are the new source code”, and even that entire working systems can be regenerated from the original model inputs, will be revealed to be the nonsense that it is. The problem with getting into a debate with reality is that reality always wins. (And doesn’t even realise it’s in a debate.)</p>



<p>So, no, “AI” isn’t the end of programmers. I’m not even sure, 1-3 years from now, that this current mania won’t have just burned itself out, as the bean counters tot up the final scores. And they <em>always </em>win.</p>



<p>To folks who say this technology isn’t going anywhere, I would remind them of just how expensive these models are to build and what massive losses they’re incurring. Yes, you <em>could </em>carry on using your local instance of  some small model distilled from a hyper-scale model trained today. But as the years roll by, you may find not being able to move on from the programming language and library versions it was trained on a tad constraining.</p>



<p>For this reason, I’m skeptical that hyper-scale LLMs have a viable long-term future. They are the Apollo Moon missions of “AI”. In the end, quite probably just not worth it. Maybe we’ll get to visit them in the museums their data centres might become?</p>



<p>The foreseeable future of software development is one where perhaps “AI” – in a much more modest form (e.g., a Java coding assistant built atop a basic language model) – is used to generate prototypes, and maybe for inline completion on production code and those sorts of minor things.</p>



<p>But, when it matters, there <em>will </em>be a software developer at the wheel. And, if Jevons is to be believed, probably even <em>more </em>of us.</p>



<p>Employers, if I were you, I might start hiring now to beat the stampede when everyone wakes up from this fever dream.</p>



<p>And then maybe <a href="https://codemanship.co.uk/">drop me a line</a> if you’re interested in skilling them up in the technical practices that can dramatically shrink delivery lead times while improving reliability and reducing the cost of change, with or without “AI”. That’s a WIN-WIN-WIN.</p>

<div>
	<p><img referrerpolicy="no-referrer" alt="Unknown's avatar" src="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G" srcset="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G 1x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=63&amp;d=identicon&amp;r=G 1.5x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=84&amp;d=identicon&amp;r=G 2x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=126&amp;d=identicon&amp;r=G 3x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=168&amp;d=identicon&amp;r=G 4x" height="42" width="42" loading="lazy" decoding="async">	</p><!-- .author-avatar -->

	<!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is forcing us to write good code (164 pts)]]></title>
            <link>https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code</link>
            <guid>46424200</guid>
            <pubDate>Mon, 29 Dec 2025 19:11:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code">https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code</a>, See on <a href="https://news.ycombinator.com/item?id=46424200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!M5s0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!M5s0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!M5s0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Header Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Header Image" title="Header Image" srcset="https://substackcdn.com/image/fetch/$s_!M5s0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!M5s0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>For decades, we’ve all known what “good code” looks like. Thorough tests. Clear documentation. Small, well-scoped modules. Static typing. Dev environments you can spin up without a minor religious ritual.</p><p><span>These things were always </span><em>optional</em><span>, and time pressure usually meant </span><em>optional</em><span> got cut.</span></p><p><strong>Agents need these optional things though. </strong><span>They aren’t great at making a mess and cleaning it up later.</span><strong> </strong><span>Agents will happily be the Roomba that rolls over dog poop and drags it all over your house.</span></p><p><span>The only guardrails are the ones you </span><strong>set and</strong><span> </span><strong>enforce</strong><span>. If the agentic context is lacking and the guardrails aren’t sufficient, you’ll find yourself in a world of pain</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-1-182812243" target="_self" rel="">1</a></span><span>. But if the guardrails are solid, the LLM can bounce around tirelessly until the only path out is the correct one.</span></p><p><a href="https://logic.inc/" rel="">Our six-person team</a><span> has made a lot of specific and, sometimes, controversial investments to accommodate our agentic coders. Let’s talk about some of the less obvious ones.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Ml4F!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Ml4F!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Ml4F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Header Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Header Image" title="Header Image" srcset="https://substackcdn.com/image/fetch/$s_!Ml4F!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Ml4F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>The most controversial guideline we have is our most valuable: </span><strong>We require 100% code coverage</strong><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-2-182812243" target="_self" rel="">2</a></span><span>.</span></p><p>Everyone is skeptical when they hear this until they live with it for a day. It feels like a secret weapon at times.</p><p>Coverage, as we use it, isn’t strictly about bug prevention; it’s about guaranteeing the agent has double-checked the behavior of every line of code it wrote.</p><p>The usual misinterpretation is that people think we believe 100% coverage means “no bugs”. Or that we’re chasing a metric, and metrics get gamed. Neither of those are the case here.</p><div><p><span>Why 100%? At 95% coverage, you’re still making decisions about what’s “important enough” to test. At 99.99%, you don’t know if that uncovered line in </span><em>./src/foo.ts</em><span> was there before you started work on the new feature. At 100%, there’s a </span><strong>phase change</strong><span> and all of that ambiguity goes away</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-3-182812243" target="_self" rel="">3</a></span><span>. If a line isn’t covered, it’s because of something you actively just did.</span></p><p><span>The coverage report becomes a simple todo list of tests you still need to write. It’s also one less degree of freedom we have to give to the agent to reason about.</span></p></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!7kIE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!7kIE!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 424w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 848w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 1272w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!7kIE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png" width="702" height="524.16" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:896,&quot;width&quot;:1200,&quot;resizeWidth&quot;:702,&quot;bytes&quot;:432198,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bits.logic.inc/i/182812243?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!7kIE!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 424w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 848w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 1272w, https://substackcdn.com/image/fetch/$s_!7kIE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>At 100% coverage, the leverage you get from the tests experiences a step-function increase.</figcaption></figure></div><p>When a model adds or changes code, we force it to demonstrate how that line behaves. It can’t stop at “this seems right.” It has to back it up with an executable example.</p><p>Other nice benefits: Unreachable code gets deleted. Edge cases are made explicit. And code reviews become easier because you see concrete examples of how every aspect of the system is expected to behave or change.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!WdHC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WdHC!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!WdHC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Header Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Header Image" title="Header Image" srcset="https://substackcdn.com/image/fetch/$s_!WdHC!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WdHC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The main mechanism agentic tools use to navigate your codebase is the filesystem</span><strong>.</strong><span> They list directories, read filenames, search for strings, and pull files into context. </span></p><p><strong>You should treat your directory structure and file naming with the same thoughtfulness you’d treat any other interface.</strong></p><p><span>A file called </span><em>./billing/invoices/compute.ts</em><span> communicates much more than </span><em>./utils/helpers.ts</em><span>, even if the code inside is identical. Help the LLM out and give your files thoughtful organization.</span></p><p><span>Additionally, </span><strong>prefer many small well-scoped files.</strong></p><p>It improves how context gets loaded. Agents often summarize or truncate large files when they pull them into their working set. Small files reduce that risk. If a file is short enough to be loaded in full, the model can keep the entire thing active in context.</p><p>In practice, it will speed up the agent’s flow and eliminate a whole class of degraded performance.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ME7a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ME7a!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ME7a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Header Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Header Image" title="Header Image" srcset="https://substackcdn.com/image/fetch/$s_!ME7a!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ME7a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the old world, you lived in one dev environment. This is where you’d craft your perfect solution, tweak things, run commands, restart servers, and gradually converge on a solution.</p><p><span>With agents, </span><a href="https://bits.logic.inc/p/engineering-is-becoming-beekeeping" rel="">you do something closer to beekeeping</a><span>, orchestrating across processes without knowing the specifics of what exactly is happening within each of them. So you need to cultivate a good and healthy hive.</span></p><p>You need your automated guardrails to run quickly, because you need to run them often.</p><p><span>The goal is to keep the agent on a short leash: </span><em>make a small change,</em><span> </span><em>check it, fix it, repeat.</em></p><p><span>You can run them a few ways: agent hooks, git hooks, or just prompting (i.e. in your </span><em>AGENTS.md</em><span>), but no matter how you run them, your quality checks need to be cheap enough that running them constantly is not slowing things down.</span></p><p><span>In our setup, every </span><em>npm test</em><span> creates a brand new database, runs migrations, and executes the full suite.</span></p><p><span>This only works for us because we’ve made each of those stages exceptionally fast. We run tests with high concurrency, strong isolation, and </span><a href="https://github.com/with-logic/fast-forward" rel="">a caching layer</a><span> for third-party calls</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-5-182812243" target="_self" rel="">5</a></span><span>. We have 10,000+ assertions that finish in about a minute. Without caching, it takes 20-30 minutes, which would add hours if you expected an agent to run tests several times per task.</span></p><p>Once you get comfortable with agents, you naturally start running many of them. You’ll spin up and tear down many dev environments multiple times a day. That has to all be fully automated or you’ll avoid doing it.</p><p>We have a simple workflow here:</p><p><code>new-feature &lt;name&gt;</code></p><p><span>That command creates a new git worktree, copies in local config that doesn’t live in git (like </span><code>.env </code><span>files), installs dependencies, and then starts your agent with a prompt to interview you to write a PRD together. If the feature name is descriptive enough, it may even just ask to get right to work, assuming it can figure out the rest of the context on its own.</span></p><p>The important part isn’t our specific scripts. It’s the latency. If it takes minutes and involves a bunch of tinkering and manual configuration, you won’t do it. If it is one command and takes 1-2 seconds, you’ll do it constantly.</p><p>In our case, one command gives you a fresh, working environment almost immediately, with an agent ready to start.</p><p>The final piece is being able to run each environment at the same time. Having a bunch of worktrees doesn’t help if you can only have one of them active at a time.</p><p>That means anything that could conflict (e.g. ports, database names, caches, background jobs) needs to be configurable (ideally via environment variables) or otherwise allocated in some conflict-free way.</p><p>If you use Docker you get some of this for free, but the general requirement is the same: you need a solid isolation story so you can run several fully functioning dev environments on one machine without cross-talk.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!YIal!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!YIal!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!YIal!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!YIal!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!YIal!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!YIal!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Header Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Header Image" title="Header Image" srcset="https://substackcdn.com/image/fetch/$s_!YIal!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!YIal!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!YIal!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!YIal!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>More broadly, automate the enforcement of as many best practices as you can. Remove degrees of freedom from the LLM. If you’re not already using automatic linters and formatters</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-6-182812243" target="_self" rel="">6</a></span><span>, start there. Make those as strict as possible and configured to automatically apply fixes whenever the LLM finishes a task or is about to commit</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-7-182812243" target="_self" rel="">7</a></span><span>.</span></p><p><strong>But you should also be using a typed language</strong><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-182812243" href="https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code#footnote-8-182812243" target="_self" rel="">8</a></span><span>.</span></p><p>Entire categories of illegal states and transitions can be eliminated. And types shrink the search space of possible actions the model can take, while doubling as source-of-truth documentation describing exactly what kind of data flows through each layer.</p><p>We lean on TypeScript pretty heavily. If something can be reasonably represented cleanly in the type system, we do it.</p><p>And we push semantic meaning into the type names. The goal is to make “what is this?” and “where does it go?” answerable at a glance.</p><p><span>When you’re working with agents, good semantic names are an amplifier. If the model sees a type like </span><code>UserId</code><span>, </span><code>WorkspaceSlug</code><span>, or </span><code>SignedWebhookPayload</code><span>, it can immediately understand what kind of thing it is dealing with. It can also search for that thing easily.</span></p><p><span>Generic names like </span><code>T</code><span> are fine when you’re writing a small self-contained generic algorithm, but much less helpful when you’re communicating intent inside a real business system.</span></p><p>On the API side, we use OpenAPI and generate well-typed clients, so the frontend and backend agree on shapes.</p><p><span>On the data side, we use Postgres’ type system as best as we can, and add checks and triggers for invariants that don’t fit into simple column types. Postgres doesn’t have a particularly rich type system, but it has enough there to enforce a surprising amount of correctness. If an agent tries to write invalid data, our database will usually complain clearly and loudly. And we use </span><a href="https://kysely.dev/" rel="">Kysely</a><span> to generate well-typed TypeScript clients for us.</span></p><p>All of our other 3rd-party clients either give us good types, or we wrap them to give us good types.</p><p>Agents are tireless and often brilliant coders, but they’re only as effective as the environment you place them in. Once you realize this, “good code” stops feeling superfluous and starts feeling essential.</p><p>Yes, the upfront work feels like a tax, but it’s the same tax we’ve all been dodging for years. So pay it intentionally. Put it on your agentic roadmap, get it funded by eng leadership, and finally ship the codebase you always hoped for.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs Are Not Fun (201 pts)]]></title>
            <link>https://orib.dev/nofun.html</link>
            <guid>46424136</guid>
            <pubDate>Mon, 29 Dec 2025 19:06:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://orib.dev/nofun.html">https://orib.dev/nofun.html</a>, See on <a href="https://news.ycombinator.com/item?id=46424136">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2><a href="https://orib.dev/">orib.dev</a>: LLMS Are Not Fun</h2>

<p>I got into programming because it let me turn thought into
reality.  If I could reason precisely, then a computer could
carry out my thoughts unerringly. I could step away from tiring,
ambiguous human interaction for a while.</p>

<p>Over time, I warmed up to people.  The most fun I've had in
my career has been watching my colleagues improve. Handing them
projects just outside the range of their abilities, and giving
them an environment where they were unafraid to fail.</p>

<p>Today, I consult with several companies on all aspects of
building software.  Sometimes, that means thinking through
product direction and building a team to execute on it. 
Sometimes, it means designing system architecture and writing code.</p>

<p>I would not be doing my duty to my clients if I wasn't
able to guide them on the effective use of LLMs.  So I,
through gritted teeth, regularly use LLMs for projects.</p>

<p>Some people describe LLMs as the ultimate programming tool.
Others describe it as an extra machine teammate. It's a dark
parody of both.</p>

<p>LLMs are not fun.</p>

<p>For me, the joy of programming is understanding a problem
in full depth, so that when considering a change, I can follow
the ripples through the connected components of the system.</p>

<p>The joy of management is seeing my colleagues learn and
excel, carving their own paths as they grow. Watching them
rise to new challenges. As they grow, I learn from their
growth; mentoring benefits the mentor alongside the mentee.</p>

<p>Using LLMs undercuts both.</p>

<p>On the engineering side, using LLMs to write code is as fun as
hiring a taskrabbit to solve my jigsaw puzzles. And if you think
of LLMs as an extra teammate, there's no fun in managing them either.
Nurturing the personal growth of an LLM is an obvious waste of time.
Micromanaging them, watching to preempt slop and derailment, is
frustrating and rage-inducing.</p>

<p>I can make effective use of LLMs. It merely costs me my care
for my craft, and my joy in its practice.</p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[List of domains censored by German ISPs (363 pts)]]></title>
            <link>https://cuiiliste.de/domains</link>
            <guid>46423566</guid>
            <pubDate>Mon, 29 Dec 2025 18:21:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cuiiliste.de/domains">https://cuiiliste.de/domains</a>, See on <a href="https://news.ycombinator.com/item?id=46423566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://cuiiliste.de/"><span>CUII</span><span>Liste.de</span></a></p><div><ul><!--[--><li><a href="https://cuiiliste.de/"><div><p><span><!--[-->Home<!--]--></span></p><p><span><!--[-->Home<!--]--></span></p></div></a></li><li><a aria-current="page" href="https://cuiiliste.de/domains"><div><p><span><!--[-->Gesperrte Domains<!--]--></span></p><!----></div></a></li><li><a href="https://cuiiliste.de/probe"><div><p><span><!--[-->Domain hinzufügen<!--]--></span></p><p><span><!--[-->Domain hinzufügen<!--]--></span></p></div></a></li><li><a href="https://cuiiliste.de/isp"><div><p><span><!--[-->Bin ich betroffen?<!--]--></span></p><p><span><!--[-->Bin ich betroffen?<!--]--></span></p></div></a></li><li><a href="https://cuiiliste.de/umgehen"><div><p><span><!--[-->Zensur umgehen<!--]--></span></p><p><span><!--[-->Zensur umgehen<!--]--></span></p></div></a></li><li><a href="https://cuiiliste.de/about"><div><p><span><!--[-->Über uns<!--]--></span></p><p><span><!--[-->Über uns<!--]--></span></p></div></a></li><!--]--></ul></div></div><section><!--[--><!--[--><h2>Von der <span>CUII</span> gesperrte Domains</h2><!--]--><!--]--></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A production bug that made me care about undefined behavior (132 pts)]]></title>
            <link>https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html</link>
            <guid>46423521</guid>
            <pubDate>Mon, 29 Dec 2025 18:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html">https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html</a>, See on <a href="https://news.ycombinator.com/item?id=46423521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pseudo-body">

<div>
  <p><a href="https://gaultier.github.io/blog"> ⏴ Back to all articles</a></p>

  <p>Published on 2025-12-27</p>
</div>

 <p><strong>Table of contents</strong></p><ul>

  <li>
    <a href="#the-bug-report">The bug report</a>
  </li>

  <li>
    <a href="#investigating">Investigating</a>
  </li>

  <li>
    <a href="#just-enough-rope-to-hang-yourself">Just enough rope to hang yourself</a>
  </li>

  <li>
    <a href="#aftermath">Aftermath</a>
  </li>

  <li>
    <a href="#static-analysis-to-the-rescue">Static analysis to the rescue?</a>
  </li>

  <li>
    <a href="#runtime-analysis-to-the-rescue">Runtime analysis to the rescue</a>
  </li>

  <li>
    <a href="#the-aftermath">The aftermath</a>
  </li>

  <li>
    <a href="#some-bonus-cplusplus-rules-for-you">Some bonus C++ rules for you</a>
  </li>

  <li>
    <a href="#conclusion">Conclusion</a>
  </li>

  <li>
    <a href="#addendum">Addendum</a>
  </li>
</ul>

<p><em>Discussions: <a href="https://www.reddit.com/r/programming/comments/1px4uug/the_production_bug_that_made_me_care_about/?">/r/programming</a>, <a href="https://lobste.rs/s/c7jhl3/production_bug_made_me_care_about">lobsters</a>.</em></p>
<p>Years ago, I maintained a big C++ codebase at my day job. This product was the bread winner for the company and offered a public HTTP API for online payments. We are talking billions of euros of processed payments a year.</p>
<p>I was not a seasoned C++ developer yet. I knew about undefined behavior of course, but it was an abstract concept, something only beginners fall into. Oh boy was I wrong.</p>
<p>Please note that I am not and never was a C++ expert, and it's been a few years since I have been writing C++ for a living, so hopefully I got the wording and details right, but please tell me if I did not.</p>
<p><em>In this article I always say 'struct' when I mean 'struct or class'.</em></p>
<h2 id="the-bug-report">
  <a href="#the-bug-report">The bug report</a>
  
</h2>
<p>So, one day I receive a bug report. There is this HTTP endpoint that returns a simple response to  inform the client that the operation either succeeded or had an error:</p>
<pre><code>{
  "error": false,
  "succeeded": true,
}
</code></pre>
<p>or</p>
<pre><code>{
  "error": true,
  "succeeded": false,
}

</code></pre>
<p><em>The actual format was probably not JSON, it was probably form encoded, I cannot exactly remember, but that does not matter for this bug.</em></p>
<p>This data model is not ideal but that's what the software did. Obviously, either <code>error</code> or <code>succeeded</code> is set but not both or neither (it's a XOR).</p>
<p>Anyway, the bug report says that the client received this reply:</p>
<pre><code>{
  "error": true,
  "succeeded": true
}
</code></pre>
<p>Hmm ok. That should not be possible, it's a bug indeed.</p>
<h2 id="investigating">
  <a href="#investigating">Investigating</a>
  
</h2>
<p>I now look at the code. It's all in one big function, and it's doing lots of database operations, but the shape of the code is very simple:</p>
<pre><code>struct Response {
  bool error;
  bool succeeded;

  std::string data;
};

void handle() {
  Response response;
  
  try {
    // [..] Lots of database operations *not* touching `response`.

    response.succeeded = true;
  } catch(...) {
    response.error = true;
  }
  response.write();
}
</code></pre>
<p><em>Here is a <a href="https://godbolt.org/z/5Wbbq3P7a">godbolt</a> link with roughly this code.</em></p>
<p>There's only one place that sets the <code>succeeded</code> field. And only one that sets the <code>error</code> field. No other place in the code touches these two fields.</p>
<p>So now I am flabbergasted. How is that possible that both fields are true? The code is straightforward. Each field is only set once and exclusively. It should be impossible to have both fields with the value <code>true</code>.</p>
<h2 id="just-enough-rope-to-hang-yourself">
  <a href="#just-enough-rope-to-hang-yourself">Just enough rope to hang yourself</a>
  
</h2>
<p>At this point, my C developer spider senses are tingling: is <code>Response response;</code> the culprit? It has to be, right? In C, that's clear undefined behavior to read fields from <code>response</code>: The C struct is not initialized.</p>
<p>But right after, I stumble upon official C++ examples that use this syntax. So now I am confused. C++ initialization rules are different from C, after all.</p>
<p>Cue a training montage with 80's music of me reading the C++ standard for hours. The short answer is: yes, the rules are different (enough to fill a book, and also they vary by C++ version) and <em>in some conditions</em>, <code>Response response;</code> is perfectly fine. In some other cases, this is undefined behavior.</p>
<p>In a nutshell: The <a href="https://en.cppreference.com/w/cpp/language/default_initialization">default initialization</a> rule applies when a variable is declared without an initializer. It's quite complex but I'll try to simplify it here.</p>
<p>Default initialization occurs under certain circumstances when using the syntax <code>T object;</code> :</p>
<ol>
<li>If <code>T</code> is a non struct, non array type, e.g. <code>int a;</code>, no initialization is performed at all. This is obvious undefined behavior.</li>
<li>If <code>T</code> is an array, e.g. <code>std::string a[10];</code>, this is fine: each element is default-initialized. But note that some types do not have default initialization, such as <code>int</code>: <code>int a[10]</code> would leave each element uninitialized.</li>
<li>If <code>T</code> is a <a href="https://en.cppreference.com/w/cpp/named_req/PODType">POD</a> (Plain Old Data, pre C++11. The wording in the standard changed with C++11 but the idea remains under the term Trivially Default Constructible) struct, e.g. <code>Foo foo;</code> no initialization is performed at all. This is akin to doing <code>int a;</code> and then reading <code>a</code>. This is obvious undefined behavior.</li>
<li>If <code>T</code> is a non-POD struct, e.g. <code>Bar bar;</code> the default constructor is called, and it is responsible for initializing all fields. It is easy to miss one, or even forget to implement a default constructor entirely, leading to undefined behavior.</li>
</ol>
<p>It's important to distinguish the first and last case: in the first case, no call to the default constructor is emitted by the compiler. In the last case, the default constructor is called. If no default constructor is declared in the struct, the compiler generates one for us, and calls it. This can be confirmed by inspecting the generated assembly.</p>
<p>With this bug, we are in the last case: the <code>Response</code> type is a non-POD struct (due to the <code>std::string data</code> field), so the default constructor is called. <code>Response</code> does not implement a default constructor. This means  that the compiler generates a default constructor for us, and in this generated code, each struct field is default initialized. So, the <code>std::string</code> constructor is called for the <code>data</code> field and all is well. Except, the other two fields are <em>not</em> initialized in any way. Oops.</p>
<p>Here is a quick summary:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Example</th>
<th>Result (Default Init)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Primitive (int, bool, etc)</td>
<td>int x;</td>
<td>Indeterminate (Garbage value)</td>
</tr>
<tr>
<td>POD / Trivial Struct</td>
<td>Point p;</td>
<td>Indeterminate (All fields garbage)</td>
</tr>
<tr>
<td>Array of Objects</td>
<td>std::string x[10];</td>
<td>Safe (All strings initialized)</td>
</tr>
<tr>
<td>Array of Primitives</td>
<td>int x[10];</td>
<td>Indeterminate (All garbage)</td>
</tr>
<tr>
<td>Non-Trivial Struct</td>
<td>Response r;</td>
<td>Calls Default Constructor (Structs ok, primitives garbage)</td>
</tr>
<tr>
<td>Any Type (Braces)</td>
<td>T obj{};</td>
<td>Value Initialized (Safe / Zeroed)</td>
</tr>
</tbody>
</table>
<p>Thus, the only way to fix the struct without having to fix all call sites is to implement a default constructor that properly initializes every field:</p>
<pre><code>struct Response {
  bool error;
  bool succeeded;

  std::string data;

  Response(): error{false}, succeeded{false}, data{} 
  {
  }
};
</code></pre>
<p><em>Here is a <a href="https://godbolt.org/z/bveKbxGeM">godbolt</a> link with this code.</em></p>
<p>Of course, due to the rule of 6 (when I started to learn C++ it was 3), we now have to implement the default destructor, the default move constructor etc etc etc.</p>
<p>Alternatively, we can define default values for the fields in the struct definition and avoid defining a default constructor:</p>
<pre><code>struct Response {
  bool error = false;
  bool succeeded = false;

  std::string data;
}
</code></pre>
<p>This way, the default constructor generated by the compiler will initialize all the fields.</p>
<h2 id="aftermath">
  <a href="#aftermath">Aftermath</a>
  
</h2>
<p>My fix at the time was to simply change the call site to:</p>
<pre><code>  Response response{};
</code></pre>
<p><em>Here is a <a href="https://godbolt.org/z/rTqernMfq">godbolt</a> link with this code.</em></p>
<p>That forces zero initialization of the <code>error</code> and <code>succeeded</code> fields as well as default initialization of the <code>data</code> field. And no need to change the struct definition.</p>
<p>This was my recommendation to my teammates at the time: do not tempt the devil, just <em>always</em> zero initialize when declaring a variable.</p>
<hr>
<p>It is important to note that in some cases, the declaration syntax <code>Response response;</code> is perfectly correct, provided that:</p>
<ul>
<li>The type is an array, or the type is a non-POD struct and</li>
<li>Each field has a default constructor, or has a default value in the struct definition</li>
</ul>
<p>Then, the default constructor of the struct is invoked, which invokes the default constructor of each field.</p>
<p>For example:</p>
<pre><code>struct Bar {
  std::string s;
  std::vector&lt;std::string&gt; vec;
};

int main() {
  Bar bar;

  // Prints: s=`` v.len=0
  // No undefined behavior.
  printf("s=%s v.len=%zu\n", bar.s.c_str(), bar.vec.size());
}
</code></pre>
<p>But to know that, you need to inspect each field (recursively) of the struct, or assume that every default constructor initializes each field.</p>
<p>Finally, it's also worth noting that it is only undefined behavior to read an uninitialized value. Simply having uninitialized fields is not undefined behavior. If the fields are never read, or written to with a known value, before being read, there is no undefined behavior.</p>
<h2 id="static-analysis-to-the-rescue">
  <a href="#static-analysis-to-the-rescue">Static analysis to the rescue?</a>
  
</h2>
<p>The compiler (<code>clang</code>) does not catch this issue even with all warnings enabled. This is frustrating because the compiler happily generates, and calls, a default constructor that does not initialize all the fields. So, the caller is expected to set all the uninitialized fields to some value manually? This is nonsense to me.</p>
<p><code>clang-tidy</code> catches the issue. However at the time it was imperfect, quoting my notes from back then:</p>
<blockquote>
<p><code>clang-tidy</code> reports this issue when trying to pass such a variable as argument to a function, but that's all. We want to detect all problematic locations, even when the variable is not passed to a function. Also, <code>clang-tidy</code> only reports one location and exits.</p>
</blockquote>
<p>But now, it seems it has improved, and reports all problematic locations, and not only in function calls, which is great.</p>
<p>I also wrote in my notes at the time that <code>cppcheck</code> 'spots this without issues', but when I try it today, it does not spot anything even with <code>--enable=all</code>. So, maybe it's a regression, or I am not using it correctly.</p>
<h2 id="runtime-analysis-to-the-rescue">
  <a href="#runtime-analysis-to-the-rescue">Runtime analysis to the rescue</a>
  
</h2>
<p>Most experienced C or C++ developers are probably screaming at their screen right now, thinking: just use Address Sanitizer (or ASan for short)!</p>
<p>Let's try it on the problematic code:</p>
<pre><code>$ clang++ main.cpp -Weverything -std=c++11 -g -fsanitize=address,undefined -Wno-padded
$ ./a.out
a.out(46953,0x1f7f4a0c0) malloc: nano zone abandoned due to inability to reserve vm space.
main.cpp:21:41: runtime error: load of value 8, which is not a valid value for type 'bool'
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior main.cpp:21:41 
error=0 success=1
</code></pre>
<p>Great, the undefined behavior is spotted! Even if the error message is not super clear.  This is ASan's way of saying: "I expected a 0 or 1 for this boolean, but I found a random 8 in that memory slot."</p>
<p>We alternatively could also have used Valgrind to the same effect.</p>
<p>But: it means that we now need to have 100% test coverage to be certain that our code does not have undefined behavior. That's a big ask.</p>
<p>Also, in my testing, Address Sanitizer did not always report the issue. That's the nature of the tool: it is meant to be conservative and avoid false positives, to avoid alerting fatigue, but that means it won't catch all issues.</p>
<p>Additionally, these tools have a performance cost and can make the build process a bit more complex.</p>
<h2 id="the-aftermath">
  <a href="#the-aftermath">The aftermath</a>
  
</h2>
<p>I wrote a <code>libclang</code> plugin at the time to catch other instances of this problem in the codebase at build time: <a href="https://github.com/gaultier/c/tree/master/libclang-plugin">https://github.com/gaultier/c/tree/master/libclang-plugin</a> .</p>
<p>Amazingly, there was only one other case in the whole codebase, and it was a false positive because by chance, the caller set the uninitialized fields right after, like this:</p>
<pre><code>Response response;
response.error = false;
response.success = true;
</code></pre>
<p>I have no idea if this <code>libclang</code> plugin still works today because I have heard that the <code>libclang</code> API often has breaking changes.</p>
<h2 id="some-bonus-cplusplus-rules-for-you">
  <a href="#some-bonus-cplusplus-rules-for-you">Some bonus C++ rules for you</a>
  
</h2>
<p>Remember all these rules we have just gone through? You want more? What if we added some sweet <em>special cases</em> to them?</p>
<p>Some types, when the value is not initialized, do <strong>not</strong> trigger undefined behavior, if they are used in certain ways:</p>
<ul>
<li><code>std::byte</code></li>
<li><code>unsigned char</code></li>
<li><code>char</code> if the underlying representation is <code>unsigned</code></li>
</ul>
<p>For example, this code is perfectly valid and free of undefined behavior:</p>
<pre><code>    unsigned char c;     // “c” has an indeterminate/erroneous value
 
    unsigned char d = c; // no undefined/erroneous behavior,
                         // but “d” has an indeterminate/erroneous value
 
    assert(c == d);  // holds, but both integral promotions have
                         // undefined/erroneous behavior
</code></pre>
<p>And this runs perfectly fine under ASan. Clang throws some warnings but compiles fine, and this is valid (in terms of the C++ standard) code.</p>
<p>Now, if we use <code>bool</code> (for example) instead:</p>
<pre><code>  bool c; 
  bool d = c;
  assert(c == d);
</code></pre>
<p>This is undefined behavior and immediately triggers ASan errors! Even if the code is the same in terms of type sizes and stack layout!</p>
<p>I do not know why the C++ standard felt the need to muddy the water even more, but they surely had a reason. Right?</p>
<p>Some quick research seems to indicate that these types are special cases to allow code to manipulate raw bytes like memcpy or buffer management without
the compiler freaking out. Which...maybe makes sense?</p>
<h2 id="conclusion">
  <a href="#conclusion">Conclusion</a>
  
</h2>
<p>In my opinion, this bug is C++ in a nutshell:</p>
<ul>
<li>Syntax that looks like C but <em>sometimes</em> does something completely different than C, invisibly. This syntax can be perfectly correct (e.g. in the case of an array, or a non POD type in some cases) or be undefined behavior. This makes code review really difficult. C and C++ really are two different languages.</li>
<li>The compiler does not warn about undefined behavior and we have to rely on third-party tools, and these have limitations, and are usually slow</li>
<li>The compiler happily generates a default constructor that leaves the object in a half-initialized state</li>
<li>The rules in the standard are intricate and change with every new standard version (or at least the language they use). I just noticed that C++26 changed again these rules and introduced new wording. Urgh.</li>
<li>So many ways in C++ to initialize a variable, and most are wrong.</li>
<li>For the code to behave correctly, the developer must not only consider the call site, but also the full struct definition, and whether it is a POD type.</li>
<li>Adding or removing one struct field (e.g. the <code>data</code> field) makes the compiler generate completely different code at the call sites.</li>
<li>You need a PhD in programming legalese to understand what is undefined behavior in the standard, and how you can trigger it</li>
</ul>
<p>In contrast I really, really like the 'POD' approach that many languages have taken, from C, to Go, to Rust: a struct is just plain data. Either the compiler forces you to set each field in the struct when creating it, or it does not force you, and in this case, it zero-initializes all unmentioned fields. This is so simple it is obviously correct (but let's not talk about uninitialized padding between fields in C :/ ).</p>
<p>In the end I am thankful for this bug, because it made me aware for the first time that undefined behavior is real and dangerous, for one simple reason: it makes your program behave completely differently than the code. By reading the code, you cannot predict the behavior of the program in any way. The code stopped being the source of truth. Impossible values appear in the program, as if a cosmic ray hit your machine and flipped some bits.
And you can very easily, and invisibly, trigger undefined behavior.</p>
<p>We programmers are only humans, and we only internalize that something (data corruption, undefined behavior, data races, etc) is a big real issue when we have been bitten by it and it ruined our day.</p>
<hr>
<p>Post-Scriptum: This is not a hit piece on C++: C++ paid my bills for 10 years. I have been able to take a mortgage and build a house thanks to C++. But it is also a deeply flawed language, and I would not start a new professional project in C++ today without a very good reason. If you like C++, all the power to you. I just want to raise awareness on this (perhaps) little-known rule in the language that might trip you up.</p>
<h2 id="addendum">
  <a href="#addendum">Addendum</a>
  
</h2>
<p>A commenter posted this Forrest Gump gif that I had completely forgotten about, so thank you :)</p>
<video loop="true" muted="true" preload="false" controls="">
<source src="https://gaultier.github.io/blog/forrest_gump_c++.mp4" type="video/mp4">
<source src="https://gaultier.github.io/blog/forrest_gump_c++.webm" type="video/webm">
<source src="https://gaultier.github.io/blog/forrest_gump_c++.gif" type="image/gif">
</video>
<p><a href="https://gaultier.github.io/blog"> ⏴ Back to all articles</a></p>

<blockquote id="donate">
  <p>If you enjoy what you're reading, you want to support me, and can afford it: <a href="https://paypal.me/philigaultier?country.x=DE&amp;locale.x=en_US">Support me</a>. That allows me to write more cool articles!</p>

  <p>
    This blog is <a href="https://github.com/gaultier/blog">open-source</a>!
    If you find a problem, please open a Github issue.
    The content of this blog as well as the code snippets are under the <a href="https://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_(%22BSD_License_2.0%22,_%22Revised_BSD_License%22,_%22New_BSD_License%22,_or_%22Modified_BSD_License%22)">BSD-3 License</a> which I also usually use for all my personal projects. It's basically free for every use but you have to mention me as the original author.
  </p>
</blockquote>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla's 4680 battery supply chain collapses as partner writes down deal by 99% (404 pts)]]></title>
            <link>https://electrek.co/2025/12/29/tesla-4680-battery-supply-chain-collapses-partner-writes-down-dea/</link>
            <guid>46423290</guid>
            <pubDate>Mon, 29 Dec 2025 17:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/12/29/tesla-4680-battery-supply-chain-collapses-partner-writes-down-dea/">https://electrek.co/2025/12/29/tesla-4680-battery-supply-chain-collapses-partner-writes-down-dea/</a>, See on <a href="https://news.ycombinator.com/item?id=46423290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="800" src="https://electrek.co/wp-content/uploads/sites/3/2021/10/Tesla-4680-Battery-cell.jpg?quality=82&amp;strip=all&amp;w=1600" alt="Tesla 4680 Battery cell" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2021/10/Tesla-4680-Battery-cell.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2021/10/Tesla-4680-Battery-cell.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2021/10/Tesla-4680-Battery-cell.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2021/10/Tesla-4680-Battery-cell.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>A major link in Tesla’s 4680 battery supply chain has just snapped. South Korean battery material supplier L&amp;F Co. announced today that the value of its massive supply deal with Tesla has been slashed by over 99%, signaling a catastrophic drop in demand for the automaker’s in-house battery cells.</p>



<p>This is arguably the strongest evidence yet that Tesla’s 4680 program, and the vehicle that relies on it, the Cybertruck, is in serious trouble.</p>



<p>In early 2023, L&amp;F <a href="https://www.reuters.com/world/asia-pacific/south-koreas-lf-says-value-battery-material-supply-deal-with-tesla-cut-7386-2025-12-29/" target="_blank" rel="noreferrer noopener">announced a $2.9 billion contract</a> to supply high-nickel cathode materials directly to Tesla.</p>



<p>At the time, the industry saw this as a major move by Tesla to secure materials for its ramp-up of the 4680 battery cell, which Elon Musk had touted as the key to halving battery costs and enabling cheaper electric vehicles, a plan he later scrapped.</p>	
	



<p>Right now, Tesla’s Cybertruck is the only vehicle using the automaker’s own 4680 cells.</p>



<p>In a regulatory filing today, L&amp;F revealed that the contract’s value has been written down to just $7,386.</p>



<p>No, that is not a typo. $2.9 billion to roughly $7,400.</p>



<p>L&amp;F did not explicitly state the reason for the cut, citing only a “change in supply quantity,” but the dots are easy to connect. The high-nickel cathode was destined for Tesla’s 4680 cells, and the primary consumer of those cells is the Cybertruck.</p>



<p>We have been reporting on the Cybertruck’s demand issues for the better part of this year. In March, we noted that the truck was <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/03/06/tesla-now-offers-discounted-financing-on-cybertruck-as-the-truck-turns-out-to-be-a-flop/">turning out to be a flop</a> as Tesla began offering discounted financing to move inventory. By June, Tesla <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/06/05/tesla-goes-full-desperate-cybertruck-with-biggest-discount-yet/">became desperate</a>, launching 0% APR incentives as inventory piled up in lots across the US.</p>



<p>Despite a production capacity of 250,000 units per year at Giga Texas, the Cybertruck is currently selling at a run rate of roughly 20,000 to 25,000 units annually. We even saw Tesla <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/09/13/tesla-discontinues-cheapest-cybertruck/">discontinue the cheapest Cybertruck</a> in September because, frankly, no one wanted a gutted version of a truck that was already struggling to find buyers.</p>



<p>If Tesla isn’t building Cybertrucks, it doesn’t need 4680 cells. And if it doesn’t need 4680 cells, L&amp;F has no one to sell its cathode material to.</p>



<h3 id="h-electrek-s-take">Electrek’s Take</h3>



<p>This is not a good look Tesla’s 4680 program.</p>



<p>For years, we’ve been told that the 4680 cell was the “holy grail” that would allow Tesla to produce a $25,000 electric car. But five years after Battery Day, the cells are still reportedly difficult to manufacture at scale due to the dry electrode process, and their only application is a low-volume pickup truck that has become a commercial failure.</p>



<p>The math here is brutal. A 99% reduction in a supply contract basically means the contract was cancelled. It means Tesla is not ramping 4680 production; if anything, they might be winding it down.</p>




	<p>The ‘Cybercab’ is also supposed to be using the 4680 cells, but we will have to wait and see how that goes.</p>



<p>It’s also a vehicle program that could go the way of the Cybertruck. CEO Elon Musk is insisting that it will launch in early 2026 without a steering wheel, but Tesla has yet to solve level 4 autonomous driving.</p>



<p>If it does launch without a steering wheel, it will be a program even more limited in volume than the Cybertruck.</p>



<p><em>The battery supply situation and the critical minerals behind it are evolving fast, and China controls most of it. In <a href="https://zalkon.substack.com/p/china-is-running-out-of-some-crticial">a new Substack, I shared a full list</a> of the years of reserve remaining for each mineral.</em></p>
	<p><a target="_blank" rel="nofollow" href="https://google.com/preferences/source?q=https://electrek.co" aria-label="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-dark.png" alt="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-light.png" alt="Add Electrek as a preferred source on Google">
		</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia takes $5B stake in Intel under September agreement (210 pts)]]></title>
            <link>https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/</link>
            <guid>46423010</guid>
            <pubDate>Mon, 29 Dec 2025 17:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/">https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/</a>, See on <a href="https://news.ycombinator.com/item?id=46423010">Hacker News</a></p>
Couldn't get https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[GOG is getting acquired by its original co-founder: What it means for you (647 pts)]]></title>
            <link>https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/</link>
            <guid>46422412</guid>
            <pubDate>Mon, 29 Dec 2025 16:43:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/">https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/</a>, See on <a href="https://news.ycombinator.com/item?id=46422412">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-3173">
  
  <div data-hide-featured-media="0">
<p>Hey everyone, GOG Team here.<br></p>



<p>Today, Michał Kiciński, one of the co-founders of CD PROJEKT, and the co-founder of GOG, has acquired GOG from CD PROJEKT.</p>



<h2>Why GOG and Michal Kicinski are getting together</h2>



<p>We believe the games that shaped us deserve to stay alive: easy to find, buy, download, and play forever. But time is annoyingly good at erasing them. Rights get tangled, compatibility breaks, builds disappear, and a nostalgic evening often turns into a troubleshooting session. That’s the difference between “I’m playing today” (the game lives on) and “I’ll play someday” (the game dies).</p>



<p>As Michał put it: “GOG stands for freedom, independence, and genuine control.”</p>



<p>GOG has always been built on strong values and clear principles. When Marcin Iwiński and Michał Kiciński first came up with the idea for GOG in 2007, the vision was simple: bring classic games back to players, and make sure that once you buy a game, it truly belongs to you, forever. In a market increasingly defined by mandatory clients and closed ecosystems, that philosophy feels more relevant than ever.</p>



<p>This new chapter is about doubling down on that vision. We want to do more to preserve the classics of the past, celebrate standout games of today, and help shape the classics of tomorrow, including new games with real retro spirit.</p>



<h2>What it means for you</h2>



<p>First of all, DRM-free is more central to GOG than ever. Your library stays yours to enjoy: same access, same offline installers, same sense of ownership. Your data stays with GOG, and GOG GALAXY remains optional.</p>



<p>We’ll keep our relationship with CD PROJEKT. CD PROJEKT RED games will continue to be available on <a href="http://gog.com/" rel="nofollow noopener" target="_blank">GOG</a>, and upcoming titles from the studio will also be released on the platform.&nbsp;</p>



<p>If you’re a GOG Patron, or you donate to support the Preservation Program, those funds stay within GOG. Your support has been huge this year, and we think that with your help, we can undertake even more ambitious rescue missions in 2026 and 2027. We’ll have more to say about that sometime in 2026.</p>



<p>GOG will remain&nbsp; independent in its operations. We will continue building a platform that’s ethical, non-predatory, and made to last, while helping indie developers reach the world. We’re also committed to giving the community a stronger voice, with new initiatives planned for 2026.</p>



<p>Thanks for being the reason this all matters.</p>



<p>A lot of companies sell games. Fewer do the unglamorous work of making sure the games that shaped people’s lives don’t quietly rot into incompatibility.</p>



<p>Thanks for caring about this mission with us. We’ll keep you posted as we ship, and in the meantime, you can dig into the full FAQ for the detailed answers.</p>











<h2>FAQ</h2>


<div id="rank-math-faq">
<div id="faq-question-1767024478694">
<h3><strong>What is happening?</strong></h3>
<p>Michał Kiciński, the original co-founder of GOG and co-founder of CD PROJEKT, has acquired GOG from CD PROJEKT. GOG will continue operating as GOG, a distinct company, with the same mission to Make Games Live Forever.</p>
</div>
<div id="faq-question-1767024494514">
<h3><strong>What is GOG’s position in this?</strong></h3>
<p>To us at GOG, this feels like the best way to accelerate what is unique about GOG. Michał Kiciński is one of the people who created GOG around a simple idea: bring classic games back, and make sure that once you purchase a game, you have control over it forever. With him acquiring GOG, we keep long-term backing that is aligned with our values: freedom, independence, control, and making games stay playable over time.</p>
</div>
<div id="faq-question-1767024505630">
<h3><strong>Why is Michał Kiciński doing this?</strong></h3>
<p>Because he wants to preserve and grow the original philosophy behind GOG. In a PC market that keeps moving toward mandatory clients and closed ecosystems, he believes GOG’s approach is more relevant than ever: no lock-in, no forced platforms, sense of ownership. His goal is to keep supporting both gamers and developers, and strengthen GOG’s mission: preserve the classics of the past, celebrate standout games of today, and help shape the classics of tomorrow.</p>
</div>
<div id="faq-question-1767024516030">
<h3><strong>Why is CD PROJEKT doing this?</strong></h3>
<p>Selling GOG fits CD PROJEKT’s long-term strategy. CD PROJEKT wants to focus its full attention on creating top-quality RPGs and providing our fans with other forms of entertainment based on our brands. This deal lets CD PROJEKT keep that focus, while GOG gets stronger backing to pursue its own mission.</p>
</div>
<div id="faq-question-1767024528013">
<h3><strong>Does the mission of GOG change?</strong></h3>
<p>No. Our mission remains to Make Games Live Forever.</p>
</div>
<div id="faq-question-1767024541869">
<h3><strong>Is DRM-free still central to GOG?</strong></h3>
<p>Yes. DRM-free is more central to GOG than ever.</p>
</div>
<div id="faq-question-1767024551235">
<h3><strong>What happens to my GOG account?</strong></h3>
<p>Nothing changes. Your account stays a GOG account.</p>
</div>
<div id="faq-question-1767024556896">
<h3><strong>Is GOG financially unstable?</strong></h3>
<p>No. GOG is stable and has had a really encouraging year. In fact, we’ve seen more enthusiasm from gamers towards our mission than ever before.</p>
</div>
<div id="faq-question-1767024569496">
<h3><strong>Will my tips or GOG Patrons donations be shared with Michał Kiciński, or any other party?</strong></h3>
<p>No. These funds stay within GOG to support preservation work, and they are not shared with publishers or other companies.</p>
</div>
<div id="faq-question-1767024582077">
<h3><strong>What happens to my library?</strong></h3>
<p>Nothing. Your library remains yours to enjoy, even if a game gets delisted, as it always has.</p>
</div>
<div id="faq-question-1767024620707">
<h3><strong>Can I still download offline installers?</strong></h3>
<p>Yes.</p>
</div>
<div id="faq-question-1767024630144">
<h3><strong>Will you share my data with Michał Kiciński, or other parties?</strong></h3>
<p>No. GOG remains the controller of your data, and nothing changes here.</p>
</div>
<div id="faq-question-1767024638626">
<h3><strong>Will CD PROJEKT RED games continue to release on GOG?</strong></h3>
<p>CD PROJEKT RED games will continue to be available on GOG, and upcoming titles from the studio will also be released on the platfo<strong>rm.</strong></p>
</div>
</div></div><!--/inner-wrap-->
    
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Static Allocation with Zig (188 pts)]]></title>
            <link>https://nickmonad.blog/2025/static-allocation-with-zig-kv/</link>
            <guid>46422009</guid>
            <pubDate>Mon, 29 Dec 2025 16:07:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nickmonad.blog/2025/static-allocation-with-zig-kv/">https://nickmonad.blog/2025/static-allocation-with-zig-kv/</a>, See on <a href="https://news.ycombinator.com/item?id=46422009">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            <p>Over the past few months I've been chipping away at a small Redis-compatible key/value server called
<a rel="noopener" target="_blank" href="https://github.com/nickmonad/kv"><code>kv</code></a>. The goal is to have something (mostly) production-ready, while implementing
only a small subset of commands. The world doesn't necessarily need another key/value store, I'm just interested in
implementing it in Zig and learning about some new (to me) techniques for systems programming.</p>
<p>One of those techniques is static memory allocation during initialization. The idea here is that all memory is requested
and allocated from the OS <em>at startup</em>, and held until termination. I first heard about this while learning about
<a rel="noopener" target="_blank" href="https://tigerbeetle.com/">TigerBeetle</a>, and they reference it explicitly in their development style guide dubbed "TigerStyle".</p>
<blockquote>
<p>All memory must be statically allocated at startup. <strong>No memory may be dynamically allocated (or freed and reallocated)
after initialization.</strong> This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free.
As a second-order effect, it is our experience that this also makes for more efficient, simpler designs that are more
performant and easier to maintain and reason about, compared to designs that do not consider all possible memory usage
patterns upfront as part of the design.</p>
<p><a rel="noopener" target="_blank" href="https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TIGER_STYLE.md">TigerStyle</a></p>
</blockquote>
<p>Although, this isn't as straightforward as it might sound at first. The first question that comes to mind might be:
"How much memory do I allocate?" Of course, the answer depends on the system. If we're writing a server, how many
concurrent connections do we allow? How much space is each connection allowed to work with? How much data do we expect
to process at any given time? Are there limits in response size? Do we need all the data at once, or can it streamed in
some fashion?</p>
<p>These are all questions that depend on the nature of the system and the context in which it will operate. I believe
that going through the exercise of answering these questions is ultimately a good thing, as it seems to have a strong
possibility of resulting in more stable systems, and forces us to understand the nature of our program at a deeper level.<sup id="fr-1-1"><a href="#fn-1">1</a></sup></p>
<p>On the language front, I feel like Zig is currently the best option out there for doing this with <em>relative</em> ease,
considering its design choices around explicit memory allocation and the <code>std.mem.Allocator</code> interface, which allows
the standard library to ship with a variety of different allocators.</p>
<p>Let's take a look at how we can manage static allocation in <code>kv</code>, considering three areas of request handling in
sequence: connection handling, command parsing, and key/value storage.</p>
<blockquote>
<p>A lot of this is pretty new to me, and I'm still wrestling with all these concepts. (And learning Zig!) I'm sure
there are better ways of handling this stuff. I'm presenting this as one possible implementation completed as a
learning exercise. I'll speak more about the trade-offs and where I think it can go further at the end of this post.</p>
</blockquote>
<h2 id="connection-handling">Connection Handling</h2>
<p>The first thing we have to consider is how data comes into the system, which we'll maintain through the concept
of a <code>Connection</code>.</p>
<p>A connection represents the communication to a particular client that wants to access the key/value store.
Since we're using <code>io_uring</code> for asynchronous I/O, we have to keep some information around through the life-cycle of
a request, so the kernel can use it. The space for that information is what we'll statically allocate and re-use across
different connections as they come and go.</p>
<pre data-lang="zig"><code data-lang="zig"><span>const </span><span>Connection = </span><span>struct </span><span>{
</span><span>	</span><span>completion</span><span>: </span><span>Completion </span><span>= </span><span>undefined</span><span>,
</span><span>	</span><span>client</span><span>: </span><span>posix.socket_t </span><span>= </span><span>undefined</span><span>,
</span><span>	
</span><span>	</span><span>recv_buffer</span><span>: *</span><span>ByteArray</span><span>,
</span><span>	</span><span>send_buffer</span><span>: *</span><span>ByteArray</span><span>,
</span><span>};
</span></code></pre>
<blockquote>
<p>Connections also must maintain something called a "completion". This detail is related to integration with <code>io_uring</code>,
the full details of which are outside the scope of this post. There are some good resources
<a rel="noopener" target="_blank" href="https://unixism.net/loti/index.html">here</a> and <a rel="noopener" target="_blank" href="https://man7.org/linux/man-pages/man7/io_uring.7.html">here</a>.
I also took some inspiration from TigerBeetle's <a rel="noopener" target="_blank" href="https://github.com/tigerbeetle/tigerbeetle/blob/522c0b9d15b112b20c57903987f140f1c16f627b/src/io/linux.zig">IO module</a>.</p>
</blockquote>
<p>During initialization, we create three pools: one for the Connection structs themselves, one for receive buffers
(requests), and one for send buffers (responses). When a request comes in to the server, a Connection is pulled
from a <code>std.heap.MemoryPool</code>, and then two buffers are associated with that <code>Connection</code>. The buffers are
implemented as <code>ByteArray</code> structs, which are in turn allocated as part of a <code>ByteArrayPool</code>. The <code>ByteArrayPool</code>
is custom and uses a <a rel="noopener" target="_blank" href="https://en.wikipedia.org/wiki/Free_list">free list</a> to keep track of which buffers are available
to reserve for a new connection.</p>
<pre data-lang="zig"><code data-lang="zig"><span>const </span><span>ConnectionPool = </span><span>struct </span><span>{
</span><span>    </span><span>const</span><span> Pool = std.heap.</span><span>MemoryPoolExtra</span><span>(Connection, .{ .growable = </span><span>false </span><span>});
</span><span>
</span><span>    </span><span>recv_buffers</span><span>: </span><span>ByteArrayPool</span><span>,
</span><span>    </span><span>send_buffers</span><span>: </span><span>ByteArrayPool</span><span>,
</span><span>
</span><span>    </span><span>connections</span><span>: </span><span>Pool</span><span>,
</span><span>
</span><span>    </span><span>fn </span><span>init</span><span>(
</span><span>        </span><span>config</span><span>: </span><span>Config</span><span>,
</span><span>        </span><span>gpa</span><span>: </span><span>std.mem.Allocator</span><span>,
</span><span>    ) !</span><span>ConnectionPool </span><span>{
</span><span>        </span><span>const</span><span> allocation = config.</span><span>allocation</span><span>();
</span><span>        </span><span>const</span><span> recv_size = allocation.connection_recv_size;
</span><span>        </span><span>const</span><span> send_size = allocation.connection_send_size;
</span><span>
</span><span>        </span><span>const</span><span> pool = </span><span>try</span><span> Pool.</span><span>initPreheated</span><span>(gpa, config.connections_max);
</span><span>        </span><span>const</span><span> recv_buffers = </span><span>try</span><span> ByteArrayPool.</span><span>init</span><span>(gpa, config.connections_max, recv_size);
</span><span>        </span><span>const</span><span> send_buffers = </span><span>try</span><span> ByteArrayPool.</span><span>init</span><span>(gpa, config.connections_max, send_size);
</span><span>
</span><span>        </span><span>return</span><span> .{
</span><span>            .recv_buffers = recv_buffers,
</span><span>            .send_buffers = send_buffers,
</span><span>            .connections = pool,
</span><span>        };
</span><span>    }
</span><span>	
</span><span>...
</span><span>};
</span></code></pre>
<p><img src="https://nickmonad.blog/images/kv-connection-pool.png" alt="A diagram showing how the kv connection pool works. A connection has two buffers, one for receive and one for send. Each come from a separate pool."></p>
<p>At runtime, connections are created and destroyed (marked as available) using these pools and no actual allocation
needs to happen. If no <code>Connection</code> is available in the pool, the request is rejected and the client will have to try again.</p>
<p>This does mean that the server must be configured with an upper limit on the number of connections. Each connection
must also have a limit on how much data it can receive and send.</p>
<p>At first this might seem limiting, but in practice, it creates a more robust system. Databases in particular will
enforce a limit on the number of active connections for that exact reason! For a backend, networked system like <code>kv</code>,
I would say something like 1000 active connections is a pretty reasonable limit. For a public facing system you'd
likely want more. Of course, this should all be configurable by the user.</p>
<p>The <code>Config</code> struct given to the <code>ConnectionPool</code> represents these user-configured options. Note that the <code>Config</code>
struct has a method <code>.allocation()</code> which is computed after the options have been set. In this case,
the <code>connection_recv_size</code> and <code>connection_send_size</code> depend on other options, such as <code>config.key_count</code> and
<code>config.key_size_max</code>. We'll revisit those later.</p>
<p>Now that data can get into the system, the next step is to parse out Redis commands.</p>
<h2 id="command-parsing">Command Parsing</h2>
<p>In an attempt to be compatible with Redis (at least a very small subset of it), <code>kv</code> has to parse incoming commands
following the <a rel="noopener" target="_blank" href="https://redis.io/docs/latest/develop/reference/protocol-spec/">Redis serialization protocol</a> ("RESP") format.</p>
<p>Here's an example of an incoming <code>GET key</code> command.</p>
<pre><code><span>*2\r\n$3\r\nGET\r\n$3\r\nkey\r\n
</span></code></pre>
<p>I won't go into detail on how these commands are structured, the RESP document will do a much better job there.
Basically, what we're looking at is "Here's an array with 2 elements. The first element has 3 characters,
with the content <code>GET</code> and the second element has 3 characters, with the contenhttps://github.com/nickmonad/kvt <code>key</code>."</p>
<p>In order to parse this command, we need to look at the buffer that contains the request data, create some kind of
iterator over that buffer, and split each entry on the CRLF <code>\r\n</code> byte sequence. Here's the signature for <code>parse</code>,
the function that does just that.</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub fn </span><span>parse</span><span>(</span><span>config</span><span>: </span><span>Config</span><span>, </span><span>alloc</span><span>: </span><span>std.mem.Allocator</span><span>, </span><span>buf</span><span>: []</span><span>const u8</span><span>) !</span><span>Command
</span></code></pre>
<p>The allocator is used to create some book-keeping structure as we parse through the command. We need to create a list
of <code>[]const u8</code> slices that points into the whole buffer and then is given to a command's <code>parse()</code> function, once
we know the command. This has the benefit of being a "zero copy" approach to parsing. No request data needs to be copied,
only pointed to.</p>
<p>Zig's <code>std.heap.FixedBufferAllocator</code> is perfect for this kind of operation. During initialization, we ask for buffer
space from a general purpose allocator, and pass it to the <code>FixedBufferAllocator</code>. This allocator works as "bump" allocator,
where each internal allocation happens in a linear fashion, up to the amount of available space. The trade-off here is
that memory allocated within the fixed buffer can't be free'd directly. Instead, the entire buffer is reset after use,
which simply resets an index back to <code>0</code>. (Just about as cheap as an operation can get!)</p>
<p>Since our server is single-threaded<sup id="fr-2-1"><a href="#fn-2">2</a></sup> and processes one request at a time, we can re-use this <code>FixedBufferAllocator</code>
across every request. After the request is processed, the response is copied to a <code>Writer</code> object backed by the
connection's <code>send</code> buffer and the <code>FixedBufferAllocator</code> is reset for the next request.</p>
<p><img src="https://nickmonad.blog/images/kv-parsing-state.png" alt="A diagram showing how parsing state works in kv."></p>
<p>Knowing how much space to give the <code>FixedBufferAllocator</code> depends again on our system configuration. We need space for
the <code>ArrayList</code> of parsed command items, and space for any copied list items that are written back as a response during
command execution. Parsing must be able to support the largest possible command (a list <code>PUSH</code> of maximum size/length) and
copying has to support the largest possible response (again, a maximally sized list).</p>
<p>Copying has the extra consideration that we have to actually store the copied list items, which are duplicated when
read from the key/value store. During parsing, we just need to keep <em>slices</em> into the request buffer. For the copied
items, we need to keep a list of slices that point to the items, and the items themselves. As long as we give the
<code>FixedBufferAllocator</code> space, we can use it for all these (sub-)allocations.</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub const </span><span>Runner = </span><span>struct </span><span>{
</span><span>    </span><span>config</span><span>: </span><span>Config</span><span>,
</span><span>    </span><span>fba</span><span>: </span><span>std.heap.FixedBufferAllocator</span><span>,
</span><span>    </span><span>kv</span><span>: *</span><span>Store</span><span>,
</span><span>
</span><span>    </span><span>pub fn </span><span>init</span><span>(</span><span>config</span><span>: </span><span>Config</span><span>, </span><span>gpa</span><span>: </span><span>std.mem.Allocator</span><span>, </span><span>kv</span><span>: *</span><span>Store</span><span>) !</span><span>Runner </span><span>{
</span><span>        </span><span>const</span><span> L = config.list_length_max;
</span><span>        </span><span>const</span><span> V = config.val_size_max;
</span><span>
</span><span>        </span><span>// ArrayList([]const u8) of largest possible command.
</span><span>        </span><span>// "[L/R]PUSH list item1 item2 ... itemL"
</span><span>        </span><span>const</span><span> parse_cap = (</span><span>1 </span><span>+ </span><span>1 </span><span>+ L);
</span><span>        </span><span>const </span><span>parse_size</span><span>: </span><span>u64 </span><span>= (parse_cap * </span><span>@sizeOf</span><span>([]</span><span>const</span><span> u8));
</span><span>
</span><span>        </span><span>// ArrayList([]const u8) pointing to duplicated values.
</span><span>        </span><span>const</span><span> copy_size = (L * </span><span>@sizeOf</span><span>([]</span><span>const</span><span> u8));
</span><span>        </span><span>const</span><span> copy_data = (L * V);
</span><span>
</span><span>        </span><span>const </span><span>fba_size</span><span>: </span><span>u64 </span><span>= parse_size + copy_size + copy_data;
</span><span>        </span><span>const</span><span> buffer = </span><span>try</span><span> gpa.</span><span>alloc</span><span>(u8, fba_size);
</span><span>        </span><span>const</span><span> fba = std.heap.FixedBufferAllocator.</span><span>init</span><span>(buffer);
</span><span>
</span><span>        </span><span>return</span><span> .{
</span><span>            .config = config,
</span><span>            .fba = fba,
</span><span>            .kv = kv,
</span><span>        };
</span><span>    }
</span><span>...
</span><span>};
</span></code></pre>
<p><img src="https://nickmonad.blog/images/kv-fixed-buffer-space.png" alt="A diagram showing how the Fixed Buffer Allocator is utilized in kv. The first section is the parse array, the second is the copy array, and the third is copy data."></p>
<p>The underlying <code>Store</code> will use the <code>FixedBufferAllocator</code> to allocate an <code>ArrayList</code> of fixed capacity
(determined by <code>config.list_length_max</code>) and then use the remaining space in the allocator for the copied data.</p>
<p>Hopefully all is clear so far! Now we can move on to the core of the system: key/value storage.</p>
<h2 id="key-value-storage">Key/Value Storage</h2>
<p>Perhaps obviously, the fundamental data structure in <code>kv</code> is a hash map, used to associate user provided keys with
user provided values.</p>
<p>Without looking too closely at the standard library, if you grab one of the provided hash map implementations,
it will accept a <code>std.mem.Allocator</code> and hold onto the allocator for the lifetime of the map. When a key/value pair
is added to the map, it will use that same allocator and request the appropriate amount of memory to store that data.
This won't work for our case though, since we need to control allocation prior to adding any data to the map.</p>
<p>Fortunately, Zig also provides an "unmanaged" version of a hash map. Generally, these unmanaged versions of data
structures in the standard library mean that an allocator is not held by the structure itself. It's up to us to provide
that allocator when needed. A cool trick we can play with an unmanaged map is ask it to ensure it has enough capacity
up front, and then "assume" that capacity during runtime when adding data to it. The hashing and internal details are
still handled by the map.</p>
<pre data-lang="zig"><code data-lang="zig"><span>var </span><span>map</span><span>: std.</span><span>StringHashMapUnmanaged</span><span>(Value) =</span><span> .empty</span><span>;
</span><span>try</span><span> map.</span><span>ensureTotalCapacity</span><span>(gpa, capacity);
</span></code></pre>
<p>The <code>ensure</code> operation can fail with <code>error.OutOfMemory</code>, which is OK during initialization. But, assuming this succeeds,
we no longer need to pass an allocator when we store data in the map.</p>
<pre data-lang="zig"><code data-lang="zig"><span>store.map.</span><span>putAssumeCapacity</span><span>(key, value);
</span></code></pre>
<p>This <em>could</em> in theory fail, in which case there would an assertion failure. It's ultimately up to us to check against
the map's available capacity before calling this function. But, again, no allocation is required.</p>
<p>Since the map itself doesn't do any allocation at runtime, we have to provide space for incoming keys and values. We'll
reuse the same <code>ByteArrayPool</code> implementation that we used for connection buffers. Basically, we have a big space
allocated for keys and values and the hash map just maintains an association of pointers from keys to values.
The key/value data isn't literally <em>stored</em> "in the map." The allocation that happens in <code>ensureTotalCapacity</code> is for
the internal book-keeping structure of the map, not for the user data.</p>
<h3 id="navigating-the-map">Navigating the map</h3>
<p>At the highest level, the primary challenge with storing keys and values in a statically allocated map is that we
could get poor utilization of the allocated space, especially when we need to support keys pointed at lists as values.</p>
<p>To illustrate this, let's say our map is configured to allocate space for 5 keys and 5 values. If each key maps to one
value, we get perfect utilization. At the other extreme, if one key maps to a value containing a list of 5 elements,
we have to use all the allocated value space for this one key, preventing other keys from using any value space,
causing the map to be "biased". The store wouldn't be able to hold any more key/value pairs, even though there is
allocated memory "on the table."</p>
<p><img src="https://nickmonad.blog/images/kv-map-utilization.png" alt="A diagram showing three different possibilities of how allocated memory can be used in a static hash map."></p>
<p>Basically, the only way to mitigate this is to make sure there's enough allocated space for <em>every</em> key to hold a
list of maximum size. This definitely inflates the amount of space we have to allocate, but the alternative is a
system that doesn't support its configured properties. Every key must be <em>able</em> to store a list of maximum size,
even if they don't during actual use.</p>
<p>Another issue with static allocation in the context of a map is dealing with map deletions. Our
<code>std.StringHashMapUnmanaged</code> structure uses open-addressing and linear probing to place keys in the map when hash
collisions occur. Deletions are tricky because they can break the map's ability to know if a key is actually present
in the map. To handle this, a "tombstone" technique is used to mark a space as logically (but not physically) deleted
in order to preserve accurate lookups.</p>
<p>There's a lot more to figure out here, but it's my understanding that a map will have to periodically rehash the
keys in order to reclaim space if too many tombstones pile up. When this occurs is still a bit of mystery to me.
If it occurs when the map needs to grow to accommodate more key/value pairs, we'll never actually trigger that
condition in a static context. If it occurs at some other point, based on number of keys compared to capacity,
perhaps that could work. Or maybe, it's up to us to call <code>rehash()</code> whenever it appears there is no space left,
and try the operation again.</p>
<p>All of this considered, I think a custom map implementation is more appropriate for the context of static allocation.
This current implementation proves the concept, but definitely leaves room for improvement!</p>
<h2 id="revisiting-allocation-size">Revisiting allocation size</h2>
<p>Now that we have a method for statically allocating space for these three components (connections, parsing, and storage),
we can finally answer the first question: How much space do we allocate?</p>
<p>In this current iteration of <code>kv</code>, the answer can really only be determined after the fact, once configuration has
been set and all the allocations have been made. There are five options that can be configured by the user,
and two derived properties based on those options.</p>
<pre data-lang="zig"><code data-lang="zig"><span>pub const </span><span>Config = </span><span>struct </span><span>{
</span><span>    </span><span>/// Allocation is a calculated set of values (in bytes), based on the given configuration.
</span><span>    </span><span>/// This informs static allocation requested at initialization.
</span><span>    </span><span>pub const </span><span>Allocation = </span><span>struct </span><span>{
</span><span>        </span><span>connection_recv_size</span><span>: </span><span>u64</span><span>,
</span><span>        </span><span>connection_send_size</span><span>: </span><span>u64</span><span>,
</span><span>    };
</span><span>
</span><span>    </span><span>/// Maximum number of concurrent connections.
</span><span>    </span><span>connections_max</span><span>: </span><span>u32</span><span>,
</span><span>
</span><span>    </span><span>/// Key count is the number of possible keys we can store.
</span><span>    </span><span>/// Internally, the store will allocate (key_count * list_length_max) number
</span><span>    </span><span>/// of values, such that each key could support the maximum number of list elements.
</span><span>    </span><span>key_count</span><span>: </span><span>u32</span><span>,
</span><span>
</span><span>    </span><span>/// The maximum allowable key size in bytes.
</span><span>    </span><span>key_size_max</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>/// The maximum allowable value size in bytes.
</span><span>    </span><span>val_size_max</span><span>: </span><span>u32</span><span>,
</span><span>
</span><span>    </span><span>/// The maximum allowable length for a list as a value.
</span><span>    </span><span>list_length_max</span><span>: </span><span>u32</span><span>,
</span><span>
</span><span>    </span><span>pub fn </span><span>allocation</span><span>(</span><span>config</span><span>: </span><span>Config</span><span>) </span><span>Allocation </span><span>{
</span><span>		</span><span>// ... calculate recv and send size ....
</span><span>		
</span><span>        </span><span>return</span><span> .{
</span><span>            .connection_recv_size = connection_recv_size,
</span><span>            .connection_send_size = connection_send_size,
</span><span>        };
</span><span>    }
</span><span>};
</span></code></pre>
<p>The <code>connection_recv_size</code> and <code>connection_send_size</code> properties of <code>Allocation</code> depend on some details of the
RESP protocol, but is mostly informed by our user configuration. In the interest of wrapping this post up,
I'll gloss over those details, and encourage you to check out <a rel="noopener" target="_blank" href="https://github.com/nickmonad/kv/blob/master/src/config.zig"><code>src/config.zig</code></a>.</p>
<p>This <code>Config</code> struct doesn't directly specify <em>every</em> aspect of allocation, but it does provide the basis for it.
Something not listed in the <code>Config</code> struct directly is the "list item pool", part of the key/value <code>Store</code> struct.
When keys point to lists as values, there is a linked list backing that value in the hash map, and we need a pool of
structs to assist in the construction and iteration of that linked list.</p>
<p>With some reasonable configuration options set, let's see just how much memory we allocate!</p>
<pre data-lang="sh"><code data-lang="sh"><span>$</span><span> zig build run
</span><span>config
</span><span>  </span><span>connections_max</span><span> = 1000
</span><span>  </span><span>key_count</span><span>       = 1000
</span><span>  </span><span>key_size_max</span><span>    = 1024
</span><span>  </span><span>val_size_max</span><span>    = 4096
</span><span>  </span><span>list_length_max</span><span> = 50
</span><span>allocation
</span><span>  </span><span>connection_recv_size</span><span> = 206299
</span><span>  </span><span>connection_send_size</span><span> = 205255
</span><span>map</span><span> capacity = 2048, map size = 0, available = 1638
</span><span>total_requested_bytes</span><span> = 748213015
</span><span>ready!
</span></code></pre>
<p>Everything here is measured in bytes, so we're looking at approximately <code>750 MB</code> of memory for the given configuration.
<code>total_requested_bytes</code> is a feature of Zig's <code>std.heap.DebugAllocator</code>. The exact number of bytes will be different
on each run, although it will hover around that value. I think the reason for this is how Zig requests <em>pages</em> of
memory from the OS. It won't always be the same and the OS is very likely doing some fancy book-keeping of its own.</p>
<p>If you play around with the configuration options and see how <code>total_requested_bytes</code> changes, it might be
surprising just how much memory is allocated up-front, before any of it is actually used! For example, if we
double <code>val_size_max</code> to <code>8192</code> and <code>list_length_max</code> to <code>100</code>, we're looking at about <code>2.8 GB</code> of allocated memory.</p>
<p>In the context of modern servers, this isn't a lot, but it can quickly grow as we adjust these parameters.
Should we be asking ourselves: Is this inefficient? What if we don't use all that memory?</p>
<p>Like all good engineering decisions, we have to consider them in the context of the problem we're trying to
solve, and the guarantees we expect from our systems. With this design, ensuring that each request and each
key/value pair <em>can</em> utilize the maximum configured space, seems like a worthy trade-off to make.</p>
<h2 id="final-thoughts">Final thoughts</h2>
<p>Like most projects, this one took a lot longer than I expected! Trying to incorporate both <code>io_uring</code> and
static allocation was something I had never done before, but I'm pretty happy with the result.</p>
<p>I'm looking forward to improving the internal hash map to better fit a static context, consider alternative
allocator implementations to improve memory utilization, and incorporate fuzz testing to find the limits of the system.</p>
<p>Checkout the code on <a rel="noopener" target="_blank" href="https://github.com/nickmonad/kv">GitHub</a>!</p>
<h3 id="notes">Notes</h3>
<section>
<ol>
<li id="fn-1">
<p>At the risk of stating the obvious, these limits can (and likely should) be configured at runtime by the user.
These aren't values that have to be set at compile time and enforced upon all users in every context,
although some might be. Again, it depends on <em>which</em> part of the system is using the memory.
The point is that once the program starts it will allocate memory, but after that, it does not. <a href="#fr-1-1">↩</a></p>
</li>
<li id="fn-2">
<p>Going with a single-threaded design simplifies a lot! Even though processing in <code>kv</code> is single-threaded,
it still enjoys the benefits of I/O concurrency via <code>io_uring</code>. The kernel handles writing responses back out to
clients and waiting for that operation to complete, so we don't have to worry (as much) about slow clients. <a href="#fr-2-1">↩</a></p>
</li>
</ol>
</section>

        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swapping SIM cards used to be easy, and then came eSIM (214 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/12/i-switched-to-esim-in-2025-and-i-am-full-of-regret/</link>
            <guid>46421653</guid>
            <pubDate>Mon, 29 Dec 2025 15:30:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/12/i-switched-to-esim-in-2025-and-i-am-full-of-regret/">https://arstechnica.com/gadgets/2025/12/i-switched-to-esim-in-2025-and-i-am-full-of-regret/</a>, See on <a href="https://news.ycombinator.com/item?id=46421653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Maybe this isn’t a good idea</h2>
<p>Many people have had the same phone number for years—even decades at this point. These numbers aren’t just a way for people to get in touch because, stupidly, we have also settled on phone numbers as a means of authentication. Banks, messaging apps, crypto exchanges, this very website’s publishing platform, and even the carriers managing your number rely on SMS multifactor codes. And those codes <a href="https://arstechnica.com/gadgets/2025/02/google-plans-to-stop-using-insecure-sms-verification-in-gmail/">aren’t even very secure</a>.</p>
<p>So losing access to your phone number doesn’t just lock you out of your phone. Key parts of your digital life can also become inaccessible, and that could happen more often now due to the fungible nature of eSIMs.</p>
<p>Most people won’t need to move their phone number very often, but the risk that your eSIM goes up in smoke when you do is very real. Compare that to a physical SIM card, which will virtually never fail unless you damage the card. Swapping that tiny bit of plastic takes a few seconds, and it never requires you to sit on hold with your carrier’s support agents or drive to a store. In short, a physical SIM is essentially foolproof, and eSIM is not.</p>
<p>Obviously, the solution is not to remove multifactor authentication—your phone number is, unfortunately, too important to be unguarded. However, carriers’ use of SMS to control account access is self-defeating and virtually guarantees people are going to have bad experiences in the era of eSIM. Enshittification has truly come for SIM cards.</p>
<p>If this future is inevitable, there ought to be a better way to confirm account ownership when your eSIM glitches. It doesn’t matter what that is as long as SMS isn’t the default. Google actually gets this right with Fi. You can download an eSIM at any time via the Fi app, and it’s secured with the same settings as your Google account. That’s really as good as it gets for consumer security. Between Google Authenticator, passkeys, and push notifications, it’s pretty hard to get locked out of Google, even if you take advantage of advanced security features.</p>
<p>We gave up the headphone jack. We gave up the microSD card. Is all this worthwhile to boost battery capacity by 8 percent? That’s a tough sell.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Libgodc: Write Go Programs for Sega Dreamcast (212 pts)]]></title>
            <link>https://github.com/drpaneas/libgodc</link>
            <guid>46420672</guid>
            <pubDate>Mon, 29 Dec 2025 13:43:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/drpaneas/libgodc">https://github.com/drpaneas/libgodc</a>, See on <a href="https://news.ycombinator.com/item?id=46420672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">libgodc - Go runtime for Sega Dreamcast</h2><a id="user-content-libgodc---go-runtime-for-sega-dreamcast" aria-label="Permalink: libgodc - Go runtime for Sega Dreamcast" href="#libgodc---go-runtime-for-sega-dreamcast"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/drpaneas/libgodc/blob/main/logo.png"><img src="https://github.com/drpaneas/libgodc/raw/main/logo.png" alt="libgodc" width="400"></a>
</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/drpaneas/libgodc/blob/main/examples/pong/pong.gif"><img src="https://github.com/drpaneas/libgodc/raw/main/examples/pong/pong.gif" alt="Pong" width="240" data-animated-image=""></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/drpaneas/libgodc/blob/main/examples/brkout/brkout.gif"><img src="https://github.com/drpaneas/libgodc/raw/main/examples/brkout/brkout.gif" alt="Breakout" width="240" data-animated-image=""></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/drpaneas/libgodc/blob/main/examples/platformer/platformer.gif"><img src="https://github.com/drpaneas/libgodc/raw/main/examples/platformer/platformer.gif" alt="Platformer" width="240" data-animated-image=""></a>
</p>
<p dir="auto">Replaces the standard Go runtime with one designed for the Dreamcast's
constraints: memory 16MB RAM, CPU single-core SH-4, no operating system. Provides garbage
collection, goroutines, channels, and the core runtime functions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><strong>Prerequisites:</strong> Go 1.25.3+, <code>make</code>, and <code>git</code> must be installed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/drpaneas/godc@latest
godc setup
godc doctor # to check (optional)"><pre>go install github.com/drpaneas/godc@latest
godc setup
godc doctor <span><span>#</span> to check (optional)</span></pre></div>
<blockquote>
<p dir="auto"><strong>Note:</strong> The <a href="https://github.com/drpaneas/godc"><code>godc</code></a> CLI tool is a separate project that handles toolchain setup and builds.</p>
</blockquote>
<p dir="auto">Create and run a project:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir myproject &amp;&amp; cd myproject
godc init
# write you main.go and other *.go files
godc build
godc run"><pre>mkdir myproject <span>&amp;&amp;</span> <span>cd</span> myproject
godc init
<span><span>#</span> write you main.go and other *.go files</span>
godc build
godc run</pre></div>
<p dir="auto">See the <a href="https://drpaneas.github.io/libgodc/getting-started/quick-start.html" rel="nofollow">Quick Start Guide</a> for your first program.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">📚 <strong><a href="https://drpaneas.github.io/libgodc/" rel="nofollow">Full Documentation</a></strong></p>
<ul dir="auto">
<li><a href="https://drpaneas.github.io/libgodc/getting-started/installation.html" rel="nofollow">Installation</a> — Setup and configuration</li>
<li><a href="https://drpaneas.github.io/libgodc/getting-started/quick-start.html" rel="nofollow">Quick Start</a> — First program walkthrough</li>
<li><a href="https://drpaneas.github.io/libgodc/reference/design.html" rel="nofollow">Design</a> — Runtime architecture</li>
<li><a href="https://drpaneas.github.io/libgodc/reference/effective-dreamcast-go.html" rel="nofollow">Effective Dreamcast Go</a> — Best practices</li>
<li><a href="https://drpaneas.github.io/libgodc/reference/kos-wrappers.html" rel="nofollow">KOS Wrappers</a> — Calling C from Go</li>
<li><a href="https://drpaneas.github.io/libgodc/reference/limitations.html" rel="nofollow">Limitations</a> — What doesn't work</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance</h2><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">Measured on real hardware (SH-4 @ 200MHz):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gosched yield</td>
<td>~120 ns</td>
</tr>
<tr>
<td>Allocation</td>
<td>~186 ns</td>
</tr>
<tr>
<td>Buffered channel</td>
<td>~1.8 μs</td>
</tr>
<tr>
<td>Context switch</td>
<td>~6.4 μs</td>
</tr>
<tr>
<td>Unbuffered channel</td>
<td>~13 μs</td>
</tr>
<tr>
<td>Goroutine spawn</td>
<td>~31 μs</td>
</tr>
<tr>
<td>GC pause</td>
<td>72 μs - 6 ms</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">The <code>examples/</code> directory contains working programs:</p>
<ul dir="auto">
<li><code>hello</code> — Minimal program (debug output)</li>
<li><code>hello_screen</code> — Hello World on screen using BIOS font</li>
<li><code>blue_screen</code> — Minimal graphics</li>
<li><code>input</code> — Controller input</li>
<li><code>goroutines</code> — Concurrent bouncing balls</li>
<li><code>channels</code> — Producer/consumer pattern</li>
<li><code>timer</code> — Frame-rate independent animation</li>
<li><code>bfont</code> — BIOS font rendering</li>
<li><code>filesystem</code> — Directory browser</li>
<li><code>vmu</code> — VMU LCD and buzzer</li>
<li><code>brkout</code> — Breakout clone (GPL v2, port of Jim Ursetto's original)</li>
<li><code>pong</code> — Pong clone with 1P/2P mode, particle effects, and AI</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">BSD 3-Clause License. See <a href="https://github.com/drpaneas/libgodc/blob/main/LICENSE">LICENSE</a> for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Vibe coding a bookshelf with Claude Code (264 pts)]]></title>
            <link>https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/</link>
            <guid>46420453</guid>
            <pubDate>Mon, 29 Dec 2025 13:22:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/">https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/</a>, See on <a href="https://news.ycombinator.com/item?id=46420453">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>I own more books than I can read. Not in a charming, aspirational way, but in
the practical sense that at some point I stopped knowing what I owned.
Somewhere around 500 books, memory stopped being a reliable catalog.</p>
<p>For years, I told myself I would fix this. Nothing elaborate, nothing worthy
of a startup idea. A spreadsheet would have been enough. I never did it, not
because it was hard, but because it was tedious.</p>
<figure><img src="https://balajmarius.com/images/vibe-coding-a-bookshelf-with-claude-code/part-of-my-personal-library.jpg" alt="Part of my personal library"><figcaption>Part of my personal library</figcaption></figure>
<p>The gap between intention and execution was small, but it was enough to keep the
project permanently parked in the someday pile.</p>
<p>By the end of 2025, I had been working with AI agents long enough that this
kind of project finally felt possible. Not because they made things more
impressive, but because they removed the part I always stalled on. Execution.</p>
<p>The bookshelf project is where I clearly understood what my role becomes once
execution stops being the bottleneck.</p>
<h2>The problem</h2>
<p>I tried the obvious tools first. <a href="https://apps.apple.com/us/app/isbn-scan-book-info-ratings/id6463488866">ISBN scanner apps</a> failed on Romanian
editions, and <a href="https://goodreads.com/">Goodreads</a> could not identify obscure publishers or antiquarian
finds. Anything even slightly nonstandard came back incomplete or wrong.
Partial data felt worse than no data at all, so every attempt ended the same
way: a few entries filled in, followed by abandonment.</p>
<p>What I needed was not a better app, but a way to tolerate imperfection without
the whole system falling apart.</p>
<h2>The data</h2>
<p>Every project starts with bad data, and this one started with worse data. One
afternoon, I photographed every book I own: spines, covers, duplicates, and
the occasional blurry thumb. <strong>Four hundred and seventy photos in total</strong>. Once
the images were on my laptop, I opened Claude.</p>
<figure><img src="https://balajmarius.com/images/vibe-coding-a-bookshelf-with-claude-code/470-shots-one-afternoon.jpg" alt="470 shots, one afternoon"><figcaption>470 shots, one afternoon</figcaption></figure>
<p>The first steps were mechanical. Renaming files. Converting <code>HEIC</code> to <code>JPG</code>. Then
I asked for something real: a script that sends each image to OpenAI's vision
API, extracts author, title, and publisher, normalizes names, resizes images
to avoid wasting tokens, and writes everything to a <code>JSON</code> file.</p>
<p>Claude wrote the script and ran it. It worked. Not perfectly, but well enough
to matter.</p>
<pre><code>{
  "id": "ZfEPBCMZDaCKm6k0NVJ8F",
  "title": "Simulacre și simulare",
  "author": "Jean Baudrillard",
  "publisher": "Colectia Panopticon",
  "source": "dataset/83.jpg",
},
</code></pre>
<p>Roughly 90 percent of the books came back correct. The failures were
predictable: poor lighting, damaged covers, unreadable spines. One novel was
confidently identified as a 1987 Soviet agricultural manual.</p>
<p>I fixed the rest by hand. That decision was not technical, it was judgment.
Ninety percent accuracy was enough. Chasing the remaining ten percent would
have meant days of edge cases for very little additional value. That was the
first moment where my role became clear.</p>
<p>Later, when I received a few books for Christmas, we added a second script that
runs the same pipeline for new additions. <em>Photo in, metadata and images out</em>.</p>
<h2>The covers</h2>
<p>With metadata sorted, covers were still missing. My photos showed spines, not
artwork, and I wanted a clean visual representation. Claude suggested using
<a href="https://openlibrary.org/">Open Library</a>'s API to fetch covers, which mostly worked. Half the covers were
low quality or incorrect, and Romanian editions barely existed in the
database.</p>
<p>We iterated. Claude wrote a second pass, another model call that scored cover
quality and flagged bad matches. For flagged books, it fell back to Google
Images via <a href="https://serpapi.com/">SerpAPI</a>. That handled most cases. A few remained: antiquarian finds
and obscure Soviet boxing manuals that no database was ever going to have
clean assets for.</p>
<p>I opened Photoshop and fixed ten covers by hand. For a collection of 460
books, ten manual edits felt like a win.</p>
<h2>The shelf</h2>
<p>Once the data and covers were in place, the UI came next. The obvious solution
was a grid of covers. It was correct, and it was lifeless. I kept looking at
my physical bookshelf instead. What makes it interesting is not the covers,
but the spines. Different widths, uneven pressure, colors blending into a
single texture.</p>
<figure><img src="https://balajmarius.com/images/vibe-coding-a-bookshelf-with-claude-code/the-shelf-version-zero.jpg" alt="The shelf, version zero"><figcaption>The shelf, version zero</figcaption></figure>
<p>That was the thing I wanted to recreate.</p>
<p>Claude did not invent that idea. It executed it. It wrote a script to extract
dominant colors from each cover using color quantization, then computed
contrasting text colors for readability. The result was better, but still
wrong. Every book had the same width, and real books are not like that.</p>
<p><a href="https://openlibrary.org/">Open Library</a> had page counts. We mapped page count to spine width and added
slight variation to break the uniformity. At that point, it finally looked
like a bookshelf.</p>
<pre><code>{
  "id": "ZfEPBCMZDaCKm6k0NVJ8F",
  "title": "Simulacre si simulare",
  "author": "Jean Baudrillard",
  "backgroundColor": "#f0f0ff",
  "color": "#1f1f2e",
  "paddingLeft": 13,
  "paddingRight": 13,
  "height": 384,
  "cover": "/images/bookshelf/simulacre-si-simulare@2x.webp",
  "source": "dataset/83.jpg"
},
</code></pre>
<h2>The animation</h2>
<p>Visually, the shelf worked, but it felt static. A real shelf responds to
touch. When you run your finger along the spines, they tilt slightly. I asked
Claude for an animation, and it came back with a scroll based tilt using
<a href="https://motion.dev/">Framer Motion</a>.</p>
<p>It was close, but wrong. The movement snapped instead of flowing. I did not
know why, I just knew it felt off. That was enough.</p>
<figure><video src="https://balajmarius.com/images/vibe-coding-a-bookshelf-with-claude-code/scroll-animation.webm" autoplay="" loop="" muted="" playsinline=""></video><figcaption>Scroll-based tilt animation</figcaption></figure>
<p>Claude explained the issue immediately. We were updating React state on every
scroll event, causing unnecessary re renders. The fix was to use motion values
and springs that animate outside React's render cycle. Two minutes later, it
was fixed. I spent the next few minutes scrolling back and forth, just
watching it move. This was the moment my caution dropped, not because the tool
was always right, but because the cost of trying ideas had collapsed.</p>
<h2>Killing good code</h2>
<p>That confidence had a downside. I started asking for things I did not need.
Infinite scroll seemed sensible. Why render 460 books at once? Claude
implemented it, and technically it worked. Memory stayed flat, and the DOM
updated correctly.</p>
<p>But scrolling broke. The container height desynced, the last books were
unreachable, and every attempted fix introduced new jank. The feature worked,
but the experience did not. So we removed it. Not because it was broken, but
because it was unnecessary. Four hundred and sixty books is not a scale
problem. Knowing when to delete working code is not something an AI can decide
for you.</p>
<h2>The stack view</h2>
<p>The shelf looked great on desktop, but on mobile, horizontal scrolling felt
cramped. I wanted an alternative layout: books lying flat, stacked vertically,
readable without tilting your head. I pointed Claude at the shelf
implementation and asked for a stack view.</p>
<figure><img src="https://balajmarius.com/images/vibe-coding-a-bookshelf-with-claude-code/stack-ui-on-mobile.jpg" alt="Stack UI on mobile"><figcaption>Stack UI on mobile</figcaption></figure>
<p>It read the code, inferred the patterns, and reused them: animation timing,
color extraction, scroll based opacity, the same data shape. It built the new
component and wired up a toggle between layouts. It worked without
explanation. That surprised me more than anything else.</p>
<h2>What I actually did</h2>
<p>Claude wrote all the code. So what did I do?</p>
<ul>
<li>I decided that 90 percent accuracy was enough.</li>
<li>I fixed the ten covers no API could find.</li>
<li>I rejected a grid because I wanted spines.</li>
<li>I deleted infinite scroll because I did not need it.</li>
<li>I kept scrolling the animation until it felt right.</li>
</ul>
<p>Claude handled implementation. I handled taste.</p>
<p>After years of false starts, my bookshelf finally exists. Four hundred and
sixty books, cataloged and displayed at <a href="https://balajmarius.com/bookshelf">bookshelf</a>. I almost
dismissed Claude Code as hype. Now, the times when I wrote everything by hand
feel distant, almost strange.</p>
<p>Execution keeps getting cheaper. Taste still does not.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK accounting body to halt remote exams amid AI cheating (175 pts)]]></title>
            <link>https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca</link>
            <guid>46420289</guid>
            <pubDate>Mon, 29 Dec 2025 13:06:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca">https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca</a>, See on <a href="https://news.ycombinator.com/item?id=46420289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The world’s largest accounting body is to stop students being allowed to take exams remotely to crack down on a rise in cheating on tests that underpin professional qualifications.</p><p>The Association of Chartered Certified Accountants (ACCA), which has almost 260,000 members, has said that from March it will stop allowing students to take online exams in all but exceptional circumstances.</p><p>“We’re seeing the sophistication of [cheating] systems outpacing what can be put in, [in] terms of safeguards,” Helen Brand, the chief executive of the ACCA, said in an interview with the Financial Times.</p><figure id="159db197-4b56-44e8-ab42-f3a5716959a9" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Nvidia insists it isn’t Enron, but its AI deals are testing investor faith&quot;,&quot;elementId&quot;:&quot;159db197-4b56-44e8-ab42-f3a5716959a9&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/technology/2025/dec/28/nvidia-insists-it-isnt-enron-but-its-ai-deals-are-testing-investor-faith&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Remote testing was introduced during the Covid pandemic to allow students to continue to be able to qualify at a time when lockdowns prevented in-person exam assessment.</p><p>In 2022, the Financial Reporting Council (FRC), the UK’s accounting and auditing industry regulator, said that cheating in professional exams <a href="https://www.theguardian.com/business/2022/dec/21/exam-cheating-at-uk-audit-firms-uncovered-by-watchdog" data-link-name="in body link">was a “live” issue at Britain’s biggest companies.</a></p><p>A number of multimillion-dollar fines have been issued to large auditing and accounting companies around the world over cheating scandals in tests.</p><p>The FRC’s investigation found that instances of cheating also included some tier-one auditors, a category comprising the “big four” accountants – KPMG, PwC, Deloitte and EY – along with Mazars, Grant Thornton and BDO.</p><p>In 2022, EY agreed to <a href="https://www.theguardian.com/business/2022/jun/28/ernst-and-young-fined-cheating-audit-settlement" data-link-name="in body link">pay a record $100m (£74m) to US regulators</a> over claims that dozens of its employees cheated on an ethics exam and that the company then misled investigators.</p><p>The ACCA said it had concluded that online tests have become too difficult to police, given the rise in artificial intelligence (AI) tools available to students.</p><p>Brand said the ACCA, which has more than half a million students, had worked “intensively” to combat cheating but “people who want to do bad things are probably working at a quicker pace”.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><gu-island name="EmailSignUpWrapper" priority="feature" deferuntil="visible" props="{&quot;index&quot;:11,&quot;listId&quot;:4139,&quot;identityName&quot;:&quot;business-today&quot;,&quot;description&quot;:&quot;Get set for the working day – we'll point you to all the business news and analysis you need every morning&quot;,&quot;name&quot;:&quot;Business Today&quot;,&quot;frequency&quot;:&quot;Every weekday&quot;,&quot;successDescription&quot;:&quot;We'll send you Business Today every weekday&quot;,&quot;theme&quot;:&quot;news&quot;,&quot;idApiUrl&quot;:&quot;https://idapi.theguardian.com&quot;}"></gu-island></figure><p>She added that the rapid rise of technology, led by AI tools, had pushed the issue of cheating to a “tipping point”.</p><p>Last year, the Institute of Chartered Accountants in England and Wales (ICAEW), which also trains accountants around the world, said reports of cheating were still increasing.</p><p>However, the ICAEW still permits some exams to be sat online.</p><p>“There are very few high-stakes examinations now that are allowing [remote invigilation],” Brand said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kidnapped by Deutsche Bahn (978 pts)]]></title>
            <link>https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/</link>
            <guid>46419970</guid>
            <pubDate>Mon, 29 Dec 2025 12:24:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/">https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/</a>, See on <a href="https://news.ycombinator.com/item?id=46419970">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you live in Germany, you have been treated like livestock by Deutsche Bahn (DB). Almost all of my friends have a story: they traveled with DB, got thrown out in the middle of the night in some cow village, and had to wait hours for the next train.</p><p>I have something better. I was kidnapped.</p><hr><p>December 24th, 2024. 15:30. Cologne Main Station, Platform 9 D-G.</p><p>I am taking the RE5 (ID 28521) to my grandmother’s house in Meckenheim. Scheduled departure: 15:32. Scheduled arrival in Bonn: 15:54. From there, the S23 to Meckenheim. A journey of 35 kilometers, or, in DB units, somewhere between forty-five minutes and the heat death of the universe.</p><p>I wanted to arrive early to spend more time with her. My father, who lives near Troisdorf, was supposed to join us later.</p><p>I board the train. It is twenty minutes late. I consider this early. At least the train showed up. In DB’s official statistics, a train counts as “on time” if it’s less than six minutes late.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> Cancelled trains are not counted at all.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> If a train doesn’t exist, it cannot be late.</p><p>The train starts moving. The driver announces there are “issues around Bonn.” He does not specify what kind. No one asks. We have learned not to ask. He suggests we exit at Cologne South and take the subway, or continue to Troisdorf and catch a bus from there.</p><p>I decide to continue to Troisdorf. My father can just pick me up there and we drive together. The plan adapts.</p><p>The driver announces the full detour: from Cologne South to Troisdorf to Neuwied to Koblenz. The entire left bank of the Rhine is unavailable. Only then I notice: the driver has been speaking German only. If you were a tourist who got on in Cologne to visit Brühl, thirteen minutes away, you were about to have a very confusing Christmas in Troisdorf.</p><p>A woman near me is holding chocolates and flowers. She is on the phone with her mother. “Sorry Mama, I’ll be late.” Pause. “Deutsche Bahn.” Pause. Her mother understood.</p><p>Twenty minutes later. We are approaching Troisdorf. I stand up. I gather my things. My father texts me: he is at the station, waiting.</p><p>The driver comes back on: “Hello everyone. Apparently we were not registered at Troisdorf station, so we are on the wrong tracks. We cannot stop.”</p><p>He says this the way someone might say “the coffee machine is broken.”</p><p>Silence. Laughter. Silence.</p><p>I watch Troisdorf slide past the window. Somewhere in the parking lot outside the station, my father is sitting in his car, watching his son pass by as livestock.</p><p>My father calls.</p><p>“The train couldn’t stop.”</p><p>“What?”</p><p>“Next stop is Neuwied.”</p><p>“Neuwied?” Pause. “That’s in Rheinland-Pfalz.” Pause. “That’s a different <em>federal state</em>.”</p><p>“Yup.”</p><p>I was trying to travel 35 kilometers. I was now 63 kilometers from my grandmother’s house. Further away than when I started.</p><p>There are fifteen stations between Troisdorf and Neuwied. We pass all of them.</p><p>At some point you stop being a passenger and start being cargo. A cow transporter. Mooohhhhh. A cow transporter going to a cow village. (Germany has a word for this: Kuhdorf. The cows are metaphorical. Usually.) I reached this point around Oberkassel.</p><p>DB once operated a bus to Llucalcari, a Mallorcan village of seventeen people.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> I wanted to take it home.</p><p>An English speaker near the doors is getting agitated. “What is happening? Why didn’t we stop?”</p><p>“We are not registered for this track.”</p><p>“But where will we stop?”</p><p>“Neuwied. Fifty-five minutes.”</p><p>“Fifty-five minutes.” He said it again, quieter. “I am being kidnapped.”</p><p>My seatmate, who had not looked up from his book in forty minutes, turned a page. “Deutsche Bahn.”</p><hr><p>I looked up my compensation.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> 1.50 EUR. Minimum payout threshold: 4.00 EUR.</p><p>I had been kidnapped at a loss.</p><figure><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/neuwied-station_hu11707903120371504183.jpg 480w,
https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/neuwied-station_hu924015653143594208.jpg 800w,
https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/neuwied-station_hu13922672958805438656.jpg 1200w,
https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/neuwied-station_hu10343310073074022003.jpg 1500w," src="https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/neuwied-station_hu924015653143594208.jpg" alt="Neuwied station. My final destination. Photo: Frila, CC BY-SA 3.0"><figcaption><p>Neuwied station. My final destination. Photo: <a href="https://commons.wikimedia.org/wiki/File:Bahnhof_Neuwied.jpg">Frila</a>, CC BY-SA 3.0</p></figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux DAW: Help Linux musicians to quickly and easily find the tools they need (214 pts)]]></title>
            <link>https://linuxdaw.org/</link>
            <guid>46419968</guid>
            <pubDate>Mon, 29 Dec 2025 12:23:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxdaw.org/">https://linuxdaw.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46419968">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: See what readers who loved your favorite book/author also loved to read (113 pts)]]></title>
            <link>https://shepherd.com/bboy/2025</link>
            <guid>46419822</guid>
            <pubDate>Mon, 29 Dec 2025 11:58:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shepherd.com/bboy/2025">https://shepherd.com/bboy/2025</a>, See on <a href="https://news.ycombinator.com/item?id=46419822">Hacker News</a></p>
Couldn't get https://shepherd.com/bboy/2025: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Feynman's Hughes Lectures: 950 pages of notes (174 pts)]]></title>
            <link>https://thehugheslectures.info/the-lectures/</link>
            <guid>46419273</guid>
            <pubDate>Mon, 29 Dec 2025 10:43:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehugheslectures.info/the-lectures/">https://thehugheslectures.info/the-lectures/</a>, See on <a href="https://news.ycombinator.com/item?id=46419273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main">

				
					
<article id="post-17" class="page">
	<!-- .entry-header -->

	<div>
		<p>These lectures notes run from the fall of 1966 to 1971. Feynman lectured prior to this period and continued on after 1971. With a few exceptions, the actual 2 hours lectures were not dated. However, the volumes in chronological order.</p>
<p><em><b>I want to stress, again, that these are my personal notes and are only a representation of the lectures I attended. They are to the best of my ability my recreation from memory and my original real time notes. No AV recording system was used in the transcription of my raw notes.</b></em></p>
<div id="attachment_20"><p><a href="https://thehugheslectures.info/wp-content/uploads/lectures/FeynmanHughesLectures_Vol1.pdf"><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-20" title="Feynman Hughes Lectures - Volume 1" src="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-1-231x300.jpg" alt="Feynman Hughes Lectures - Volume 1" width="231" height="300" srcset="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-1-231x300.jpg 231w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-1-791x1024.jpg 791w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-1.jpg 1700w" sizes="(max-width: 231px) 100vw, 231px"></a></p><p id="caption-attachment-20">25 MB Download</p></div>
<p><strong>Volume 1<br>
</strong><strong>Astronomy, Astrophysics, and Cosmology<br>
</strong><strong>(224 pages)</strong></p>
<p>Feynman solicited topic input from the scientists and engineers at the Labs for the coming year. New discoveries were being made in astronomy, astrophysics, and cosmology at the time. This 1966-1967 lecture series focused on these subjects. This volume is unique since, as far as I can tell, Feynman did not lecture on this subject matter at CalTech. While much of the material is now dated, what remains is a look into the mind of Feynman as he worked to explain such topics as stellar evolution, nuclear synthesis, cosmology, “black stars” (aka black holes), and general relativity.</p>
<p>I inserted more current content from the web which relates to the 1966-67 lectures with recent experimental observations and discoveries. While this lecture series has been “eclipsed” by the tremendous theoretical and experimental advancements over the past 45 years, I am sure the reader(s) will find in these lectures the power of Feynman’s insight and ability to have fun with a new subject not touched on by him at CalTech in his “normal” class and research work. I trust others, more specialized in the topics of volume 1, can and will contribute to the additional information to further enrich the notes in the future. This editing will best be done when the notes are moved and dropped in a dynamic and editable platform, yet to be identified.</p>
<p>The Volume I subject matter was not part of his prior lecture activity, Feynman would talk with some of his CalTech colleagues who worked in the field of astronomy, astrophysics, and cosmology about their work and theories. He would then come to the lecture literally with a (maybe 2 or 3) 3×5 cards and proceed to pour out 2 hours of theory and complex mathematical representations of the topic of the day. This was his genius and almost mystical in his ability to focus his thinking and presentation ability on the most important aspects of a given topic.</p>

<div id="attachment_21"><p><a href="https://thehugheslectures.info/wp-content/uploads/lectures/FeynmanHughesLectures_Vol2.pdf"><img decoding="async" aria-describedby="caption-attachment-21" title="Feynman Hughes Lectures - Volume 2" src="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-2-231x300.jpg" alt="Feynman Hughes Lectures - Volume 2" width="231" height="300" srcset="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-2-231x300.jpg 231w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-2-791x1024.jpg 791w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-2.jpg 1700w" sizes="(max-width: 231px) 100vw, 231px"></a></p><p id="caption-attachment-21">36 MB Download</p></div>
<p><b></b><strong>Volumes 2<br>
</strong><strong>Relativity, Electrostatics, Electrodynamics, Matter-Wave Interaction<br>
(209 pages)</strong></p>
<p>Feynman reflected on how he could teach his original FLP’s volume 2 &amp; 3 differently and better than in his first pass through the subjects five years earlier. The attendees wanted him to lecture a couple years on the subject matter in the original FLP and essentially let him give his revised, enhanced, and expanded lectures. This then led more naturally into QED with a good foundation layer established. Feynman also tailored his lectures more to the level of his audience understanding they were not freshman and sophomore undergraduates but post graduate, doctorate level scientists, employed doing advanced research.&nbsp;</p>



<div id="attachment_22"><p><a href="https://thehugheslectures.info/wp-content/uploads/lectures/FeynmanHughesLectures_Vol3.pdf"><img decoding="async" aria-describedby="caption-attachment-22" title="Feynman Hughes Lectures - Volume 3" src="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-3-231x300.jpg" alt="Feynman Hughes Lectures - Volume 3" width="231" height="300" srcset="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-3-231x300.jpg 231w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-3-791x1024.jpg 791w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-3.jpg 1700w" sizes="(max-width: 231px) 100vw, 231px"></a></p><p id="caption-attachment-22">49 MB Download</p></div>
<p><b></b><strong>Volume 3<br>
</strong><strong>More on Matter-Wave Interaction, Intro to Quantum Mechanics, Scattering Theory, Quantum Theory of Angular Momentum, Intro to Lie Group, SU 2 &amp; 3 “stuff”, Quantum Electrodynamics (QED), Pair Production<br>
(314 pages)<br>
</strong></p>
<p>Feynman went on in greater detail to complete his lectures on wave-matter interaction. From there he started into quantum mechanics and his path history formulation. He extended his lectures to include Lie Group theory and the SU 2&amp;3 “Stuff”.</p>
<p>Feynman diagrams are discussed in Volume 3 at some length as he went deep into QED theory including such topics as quantum scattering. As better understood today, his diagrams represent a visual language of the complex physical processes at the particle interaction level. I have noted recently that with the power of new computers and new concepts the Feynman diagrams have, arguably, run their course. While this is possibly the case, I would assert that bypassing a fundamental understanding of the Feynman diagram concept makes it hard to understand what replaces them. This is like hand held calculators replacing the need to know the fundamental multiplication tables and being able to check what the calculator is telling you. I personally observed in a number of lectures where Feynman would self-check himself as he was working out the math because he could sense that if he kept going he would not get the right physics. This was his true genius at work. That was truly amazing to both watch and try to absorb in real time<b>. &nbsp;</b></p>
<div id="attachment_19"><p><a href="https://thehugheslectures.info/wp-content/uploads/lectures/FeynmanHughesLectures_Vol4.pdf"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-19" title="Feynman Hughes Lectures - Volume 4" src="https://thehugheslectures.info/wp-content/uploads/2014/04/FHLcover-dark-Green-Vol-4-231x300.jpg" alt="Feynman Hughes Lectures - Volume 4" width="231" height="300" srcset="https://thehugheslectures.info/wp-content/uploads/2014/04/FHLcover-dark-Green-Vol-4-231x300.jpg 231w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHLcover-dark-Green-Vol-4-791x1024.jpg 791w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHLcover-dark-Green-Vol-4.jpg 1700w" sizes="auto, (max-width: 231px) 100vw, 231px"></a></p><p id="caption-attachment-19">13 MB Download</p></div>
<p><b></b><strong>Volume 4<br>
</strong><strong>Molecular Biology<br>
(65 pages)</strong></p>
<p>The Molecular Biology lectures started out and then eventually died out as the year progressed. Feynman found the material challenging to get his head around before the lecture and, therefore, very time consuming. He apparently found a CalTech colleague, Seymour Benzer, who changed from physics to biophysics as a person who stimulated Feynman’s interest in this topic.</p>
<p>By consensus the lecture series ended early. Feynman was deep into his own parton theory which was his version of quark theory. He and Gell-Mann were collegial competitors in those days.</p>
<p>In preparing these notes for release I decided to include what notes I had of those lectures only to give evidence of Feynman’s interest to explore all the dimensions of science and nature. For those involved in the field these notes will not provide much informational value particularly with all the advancements on research and understanding of molecular biology. The value, I believe, for the reader is how Feynman thought through the subject matter and mentally organized it so he could lecture on it. That might aid teachers in this field to sharpen up their own presentation material. At the end of the volume are my un-transcribed real-time notes that I never got to but I decided to include for those who are into this field.</p>
<div id="attachment_23"><p><a href="https://thehugheslectures.info/wp-content/uploads/lectures/FeynmanHughesLectures_Vol5.pdf"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-23" title="Feynman Hughes Lectures - Volume 5" src="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-5-231x300.jpg" alt="Feynman Hughes Lectures - Volume 5" width="231" height="300" srcset="https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-5-231x300.jpg 231w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-5-791x1024.jpg 791w, https://thehugheslectures.info/wp-content/uploads/2014/04/FHL-cover-dark-Green-Vol-5.jpg 1700w" sizes="auto, (max-width: 231px) 100vw, 231px"></a></p><p id="caption-attachment-23">6 MB Download</p></div>
<p><b></b><strong>Volume 5<br>
</strong><strong>Mathematical Methods/Techniques in Physics and Engineering<br>
(163&nbsp;pages)</strong></p>
<p>By some who have seen samples of my notes Volume 5 has been referred to as the “missing lectures” to the FLP “Red Books”. Feynman himself felt that he should have taught the mathematical methods first and then the physics since math <b>is&nbsp;</b><b>the</b> “language” of physics. Feynman was apparently talked out of starting with a course in math-physics. The attendees at the lab talked him into a year-long lecture on his approach to mathematics as the language of physics.</p>
<p>I note here also that the math lectures have been referred on the Reddit by someone as “sophomoric” since all physic students must take similar course work and presumably “master” math while learning the physics. In my own case I wanted to learn the physics and minimize the math, or better said, not confused by the physics because the math was too difficult to grasp.</p>
<p>This is how Feynman approached physics and how he taught himself, at an early age, by developing many shortcuts through the math; “Feynman diagrams” were one clear by product of his self learning process. He did not want to get bogged down and distracted from understanding the physics. This is why and how he got involved in the Manhattan Project; he was their math wizard.</p>
<p>One story he told of those days: Someone came running into him needing a quick answer to a nuclear decay process that was described by some expansion series like the Sum from 1 to infinity of 1/(1+n^2)[probably not the real one]. Feynman asked how accurately he wanted the answer and the person said 10% would do for now. Feynman said he took a few seconds and said the answer was 1.3 (or something like that); the person was amazed how fast he could give him that and asked how he did it. He said since you told me you only wanted the answer to 10%, it was only necessary to go to the second term in the series expansion and that was good enough for better than 10% accuracy. This story is emblematic of Feynman’s mathematical thinking which is not sophomoric. This is why he made such a contribution to the Manhattan project and ultimately QED. He did indeed “think different”.</p>
<p>In my own experience I found in my graduate studies that the some of the professors tended to focus more on the math rigor than in teaching the real physics. In Feynman’s world he “felt” the physics and used the math to express that “feeling” and understanding. Language does not necessarily express the essence of the content contained in the idea being described. One must understand both the power and limitations of the language used when discussing a subject. Words don’t always express what one wants to say; so it is for math and physics.</p>
<p><strong>Lecture Sidebars</strong><strong>:</strong> Another “feature”, or aspect, of the notes is my attempt to capture “side bar” topics. These special topics or thoughts (including some philosophical ones) added color and currency to the lectures as only Feynman could deliver. He was unconstrained in the lecture environment to take off on a sidebar and the attendees both enjoyed and encouraged him to do so.</p>
		
			</div><!-- .entry-content -->
	</article><!-- #post-17 -->
					

	<!-- #comments .comments-area -->

				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU to build no-fee payments service like Visa/Mastercard and Apple/Google Pay (139 pts)]]></title>
            <link>https://www.independent.ie/business/digital-euro-what-it-is-and-how-we-will-use-the-new-form-of-cash/a165973061.html</link>
            <guid>46419121</guid>
            <pubDate>Mon, 29 Dec 2025 10:12:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.ie/business/digital-euro-what-it-is-and-how-we-will-use-the-new-form-of-cash/a165973061.html">https://www.independent.ie/business/digital-euro-what-it-is-and-how-we-will-use-the-new-form-of-cash/a165973061.html</a>, See on <a href="https://news.ycombinator.com/item?id=46419121">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="CIKAc2QkuuB" data-fragment-name="articleDetail"><header data-testid="article-header"></header><p data-testid="title-summary">
The European Central Bank is determined to break the US grip on card payments
</p><div><figure data-testid="article-image-wrapper"><figcaption data-testid="image-caption"><p>Digital euro. Image: Getty</p></figcaption></figure></div><div><div data-testid="article-author"><p><span data-testid="author-name">John Burns</span></p></div><p><time datetime="2025-12-29T05:30:00Z" data-testid="article-date">Today at 06:30</time></p></div><p>It’s January 1, 2029, the first day of the digital euro. You are in a shop buying milk and bread, and decide to pay with this new money. How exactly will it work?</p><p>If you have a bank account, the digital euro will sit inside its app on your phone. The cost of the bread and milk can be taken out of your digital-euro wallet, which is separate from your regular bank account. You don’t have a bank?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asking Gemini 3 to generate Brainfuck code results in an infinite loop (106 pts)]]></title>
            <link>https://teodordyakov.github.io/brainfuck-agi/</link>
            <guid>46418966</guid>
            <pubDate>Mon, 29 Dec 2025 09:40:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://teodordyakov.github.io/brainfuck-agi/">https://teodordyakov.github.io/brainfuck-agi/</a>, See on <a href="https://news.ycombinator.com/item?id=46418966">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <header>
            
        </header>

        <section>
            <p>Asking Gemini 3 to generate Brainf*ck code results in an infinite loop, akin amost to a DDoS attack:</p>
            <img src="https://teodordyakov.github.io/brainfuck-agi/bf.gif">
            <p>That is fascinating. So it made me wonder.
            Is Brainf*ck the ultimate test for AGI?
            I think so, and for 3 good reasons.
            </p>
            <h2>1. The Data Scarcity Problem</h2>
            <p>Large Language Models (LLMs) thrive on sheer volume. To master JavaScript, an LLM has been trained on
                virtually every available line of open-source code—hundreds of millions of lines of code (LOC). By
                comparison, the amount of functional <strong>Brainf*ck</strong> code on the web is a statistical
                rounding error.</p>
            <p>We are talking about a <span>million times less training data</span>. Without the
                luxury of infinite patterns to copy, the model can't rely on mimicry; it has to understand the
                underlying logic.</p>
        </section>

        <section>
            <h2>2. Anti-Literate Programming</h2>
            <p>Brainf*ck is the antithesis of modern software engineering. There are no comments, no meaningful variable
                names, and no structure. In many ways, looking at existing Brainf*ck code is actually
                <em>detrimental</em> to a novice. Consider this typical snippet:</p>

            <code>&gt;++++++++[&lt;+++++++++&gt;-]&lt;.&gt;++++[&lt;+++++++&gt;-]&lt;+.+++++++..+++.&gt;&gt;++++++[&lt;+++++++&gt;-]&lt;+
+.------------.&gt;++++++[&lt;+++++++++&gt;-]&lt;+.&lt;.+++.------.--------.&gt;&gt;&gt;++++[&lt;++++++++&gt;-
]&lt;+.</code>

            <p>Writing in this environment is akin to <span>zero-shot learning</span>. Success
                requires reasoning at a high level of abstraction based on the fundamental rules of the language and a
                precise mental model of semantics, rather than memorized syntax.</p>
        </section>

        <section>
            <h2>3. The Repetition Problem</h2>
              <div>
            <p>As we saw earlier, asking a modern model for complex Brainf*ck code often results in the model falling into an infinite loop—spewing the same characters over and over. The minimalistic nature of the language results in highly repetitive structures in the code. This poses a unique challenge to the way LLMs work.</p>
            <p>An LLM is more likely to output what it has already seen based on previous tokens, and that pertains to its own output too. When some structure is repeated more than a couple of times, there is a likelihood that the model may learn that token <strong>X</strong> is the most likely output following <strong>itself</strong>. With every subsequent iteration, this increases the likelihood of outputting <strong>X</strong> in a self-fulfilling prophecy, resulting in the infinite loop.</p>
        </div>
        </section>

        <section>
            <p> <strong>So, is Brainf*ck the ultimate test for LLMs? You be the judge.</strong></p>
        </section>

        
    </article></div>]]></description>
        </item>
    </channel>
</rss>