<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 10 Mar 2024 02:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Bruno: Fast and Git-friendly open-source API client (Postman alternative) (579 pts)]]></title>
            <link>https://www.usebruno.com/</link>
            <guid>39653718</guid>
            <pubDate>Sat, 09 Mar 2024 18:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usebruno.com/">https://www.usebruno.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39653718">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Bruno is a Fast and Git-Friendly Opensource API client, aimed at revolutionizing the status quo represented by Postman, Insomnia and similar tools out there. </p><p>Bruno stores your collections directly in a folder on your filesystem. We use a plain text markup language, Bru, to save information about API requests. </p><p>You can use git or any version control of your choice to collaborate over your API collections. </p><p>Bruno is offline-only. There are no plans to add cloud-sync to Bruno, ever. We value your data privacy and believe it should stay on your device. Read our long-term vision <a href="https://github.com/usebruno/bruno/discussions/269" target="_blank" rel="noreferrer">here</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Monks Know about Focus (112 pts)]]></title>
            <link>https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus</link>
            <guid>39653517</guid>
            <pubDate>Sat, 09 Mar 2024 18:02:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus">https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus</a>, See on <a href="https://news.ycombinator.com/item?id=39653517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Books are a waste of time. So says </span><a href="https://open.substack.com/users/6319739-richard-hanania?utm_source=mentions" rel="">Richard Hanania</a><span> in “</span><a href="https://www.richardhanania.com/p/the-case-against-most-books?r=1nizk&amp;utm_campaign=post&amp;utm_medium=web" rel="">The Case Against (Most) Books</a><span>.” He allows that books of historical interest and those by contemporary thought leaders might be valuable, but the vast majority of everything else on the shelf is worthless, especially old books. That’s correct: The classics are garbage.</span></p><p><span>I’ve </span><a href="https://www.millersbookreview.com/p/vital-necessity-of-very-old-books" rel="">addressed Hanania’s argument before</a><span> but return now to note that the best rebuttal are the classics themselves. To that end I offer you </span><em><a href="https://press.princeton.edu/books/hardcover/9780691208084/how-to-focus" rel="">How to Focus: A Monastic Guide for an Age of Distraction</a></em><span>, which serves up several choice selections from John Cassian’s fifth-century monastic guide, the</span><em> Conferences</em><span>, as edited and translated by Jamie Kreiner.</span></p><p><span>The subject of monks struggling to maintain focus represents familiar ground for Kreiner, a professor of history at the University of Georgia. Last year I reviewed her book, </span><em><a href="https://www.millersbookreview.com/p/jamie-kreiner-wandering-mind-distraction?utm_source=%2Fsearch%2FKreiner&amp;utm_medium=reader2" rel="">The Wandering Mind: What Medieval Monks Tell Us about Distraction</a></em><span>.</span></p><p><span>In that book, Kreiner explores the monastic enterprise from late antiquity through the Middle Ages across Europe and the Near East to see how monks managed intense concentration while battling interruptions and distractions. In contrast, with </span><em>How to Focus</em><span> she narrows the scope to just one remarkable text, refreshed for modern readers.</span></p><p><span>Cassian wrote his </span><em>Conferences</em><span> as an older man looking back to a period of youthful experimentation and adventure. </span></p><p>In his twenties, he and his friend Germanus joined a monastery in Bethlehem. The two became fast friends, “inseparable bunkmates,” of such shared intensity and interest “everyone remarked on the equality of our companionship and our sense of purpose. They said that we were one mind and soul in two bodies.”</p><p>The pair wanted to know all the ins and outs of their discipline and decided to travel beyond their local confines to hear from reputed monastic masters. So, for the next decade and a half they traveled the Nile Delta, interviewing the men known as the Desert Fathers, those in monasteries as well as hermits living on their own.</p><p><span>They asked a million questions. The final word count of Cassian’s </span><em>Conferences</em><span> stands at 150,000 words, a remarkably large book for the time. </span><em>How to Focus</em><span>, as Kreiner notes, represents less than 10 percent of that total with her selections geared toward, as the title suggests, the conversations dealing with attention and distraction.</span></p><p>And just what would monks know about that?</p><p>We’re so attuned to our own crises and challenges, we tend to think of them as purely contemporary concerns—especially when we externalize our difficulties and blame our tools, the times, and the like. Desert monastics didn’t have Instagram; ergo, they didn’t have attentional problems.</p><p>Au contraire. While technology has evolved in the last fifteen hundred years, the human brain has not. And few people in the ancient world cared as much about the challenges of attention and distraction as monks. Our reasons might differ today, but we have much to learn nonetheless.</p><p>A repeated complaint from Cassian and Germanus is the difficulty maintaining focus on their prayers. “The mind is always moving and meandering, and it’s torn apart in different directions like it’s drunk,” says Germanus at one point. “It doesn’t even have the power to hold onto or stick with things it finds entertaining!”</p><p>Unfortunately, knowing focus matters fails to engender concentration. “What we know hasn’t helped us attain the steady and stable clarity we’ve been seeking,” he says. “Even when we feel our heart heading straight toward its goals, the mind imperceptibly turns the other way. . . .”</p><p><span>Germanus directed this second comment to Abba Serenus of Scetis, who responded, “The </span><em>nous</em><span> or mind is defined as </span><em>aeikinētos kai polykinētos</em><span>, always and very much on the move.” You might recognize our word </span><em>kinetic</em><span> in the Greek. This bubbling, jumping, flitting mind can only be tamed by training through meditation, memorization, fasting, and other forms of ascetical effort by which “it will become strong enough to drive off the enemy’s stimuli. . . .”</span></p><p>It’s a bit of a relief to realize, no? Why does the mind meander? Because that’s what minds do.</p><p>Monks attempted the radical and difficult practice of pure prayer, to bring their entire mind to bear on the act. Given their intense interest in concentration, and also being prone to endless disruptions in the effort, monks became experts in what we today call metacognition—thinking about thinking.</p><p>“It is impossible for the human mind to empty itself of all thoughts,” says Abba Nestorus, a hermit interviewed by Cassian and Germanus. The question is what kind of thoughts to entertain? Nestorus advises the pair to immerse themselves in sacred reading. “Do it continually—or better, nonstop!—until that constant recitation and reflection saturates your mind and shapes it into a kind of likeness of itself.” </p><p>Nestorus offers three reasons, the third the most profound. First, when a person is engrossed in literature, the mind can stay attuned to its content instead of “toxic thoughts.” Second, an understanding of the text comes not only while reading, but also when we take those thoughts with us into other mental states. We’re able to reflect on what we’ve read when we’ve turned out attentions elsewhere, even when we go to sleep.</p><p><span>Another interviewee, Abba Isaac, also talks about this tricky feature of mental latency, though regarding prayer, not reading. “We should,” he says, “be the sort of person we are in prayer </span><em>before</em><span> it’s time to pray. After all, our state of mind during prayer is unavoidably shaped by the situation prior to the moment.” </span></p><p><span>Attention researcher Gloria Mark—a modern scientist, not a monastic—would affirm Isaac’s point. When we approach any task, as Mark notes in her book, </span><em><a href="https://www.harpercollins.com/products/attention-span-gloria-mark?variant=40346590117922" rel="">Attention Span</a></em><span>, we do so by constructing cognitive frames that marshal the various mental resources required for the activity. When distractions occur, we change frames mid-action. The frustration we feel in getting back on task involves the difficulty in reassembling the cognitive frame we enjoyed prior to the interruption. </span></p><p>Since our mental states persist from one moment to the next, Isaac encourages Cassian and Germanus to hold onto their desired state by preparing for it in advance. It’s a way of ensuring our cognitive frame is strong enough to resist distraction and an approach that applies to a wide variety of intellectual activities.</p><p>I mentioned three reasons from Nestorus for immersive reading but have so far only covered two. What of the third and most mysterious of his reasons?</p><p>Nestorus’s third and most mysterious reason for immersive reading is that sustained engagement deepens our understanding of what we read by the changes wrought in ourselves through the very process of reading. </p><p>“How the scriptures look depends on what the human senses are capable of,” he says. “As our mind is gradually remade through this sustained effort, the shape of the scriptures begins to be remade, too, and it’s as if the beauty born of this more sacred perceptiveness grows as we grow.”</p><p>Our investment in reading changes the book because the book has changed us. And this is where Hanania’s argument fundamentally falls short. If books are merely a means of transferring information, then perhaps, yes, a book is a waste of time. If a summary of its thesis and key points could be presented in a brief article or Substack post, why not just save the hours and read the Substack post? All the more if the information is outdated or questionable for one reason or another.</p><p>But that mistakes what a book is for. A book is a tool. It’s a machine for thinking. And “all machines,” as Thoreau once said, “have their friction.” The time it takes to engage with ideas—whether factual or fictional, emotional or intellectual, accurate or inaccurate, efficient or inefficient—might strike some as a drag. But the time given to working through those ideas, adopting and adapting, developing or discarding, changes our minds, changes us.</p><p>It’s not about the wisdom we glean. It’s about what wisdom we grow.</p><p>What about that more basic plane upon which we engage a book, the information itself? After all, if the book is ancient, is the information even useful? Can the ideas shared in distant philosophical or spiritual contexts translate with any value to our present, secular world? Though the answer depends entirely on the ends to which we put the information, Cassian’s book offers us an answer here as well.</p><p><span>In the first chapter of the </span><em>Conferences</em><span>, Cassian and Germanus visit Abba Moses of Scetis, known to the faithful as St. Moses the Black or St. Moses the Ethiopian, whom they regard as “the sweetest of all those extraordinary flowers” in the desert. They ply Moses with the same sorts of questions they later asked of other fathers: Why is the monastic life so difficult? Curiously, Moses addresses their pleas by talking about short- and long-term goals.</span></p><p><span>“Every acquired skill and every discipline,” says Moses, “has a </span><em>scopos</em><span> and a </span><em>telos</em><span>, some immediate goal and some ultimate goal that is particular to it. Practitioners of any skilled craft will gladly and good-naturedly work through all their fatigue and risks and costs as they keep those goals in mind.”</span></p><p>Moses develops the idea from there and, as someone who professionally spends a lot of time reading modern goal-achievement literature, I can say that his treatment is every bit as useful as the work of scholars working today. Moses’s argument can even help resolve the question of whether we should read the classics.</p><p><span>If you’re Richard Hanania, no. You don’t possess a </span><em>telos</em><span> that would justify the effort. But if you see classics such as John Cassian’s </span><em>Conferences</em><span> as valuable, then most definitely yes. And Jamie Kreiner’s presentation in </span><em><a href="https://press.princeton.edu/books/hardcover/9780691208084/how-to-focus" rel="">How to Focus</a><span> </span></em><span>represents the perfect </span><em>scopos</em><span>. Pick it up and enjoy the thoughts it helps you conjure.</span></p><p>Thanks for reading! If you enjoyed this post, please hit the ❤️ below and share it with your friends.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>Not a subscriber? Take a moment and sign up. It’s free for now, and I’ll send you my top-fifteen quotes about books and reading. Thanks again! </p><p>Make sure you also read . . . </p><div data-component-name="DigestPostEmbed"><a href="https://www.millersbookreview.com/p/jamie-kreiner-wandering-mind-distraction" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dd55a9a-9f9e-4681-9294-e241a526e2c5_3024x3024.jpeg"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dd55a9a-9f9e-4681-9294-e241a526e2c5_3024x3024.jpeg" sizes="100vw" alt="‘Lead Us Not into Distraction’" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://www.millersbookreview.com/p/dear-abbot-monastic-advice-for-modern" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee116ebe-e8b9-4b88-a2b6-438eb0acee44_2880x2880.jpeg"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee116ebe-e8b9-4b88-a2b6-438eb0acee44_2880x2880.jpeg" sizes="100vw" alt="Dear Abbot: Monastic Advice for Modern Living" width="140" height="140"></picture></div></a></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA Designates MM120 (LSD) Breakthrough Therapy for Generalized Anxiety Disorder (113 pts)]]></title>
            <link>https://www.businesswire.com/news/home/20240307733599/en/MindMed-Receives-FDA-Breakthrough-Therapy-Designation-and-Announces-Positive-12-Week-Durability-Data-From-Phase-2B-Study-of-MM120-for-Generalized-Anxiety-Disorder</link>
            <guid>39653125</guid>
            <pubDate>Sat, 09 Mar 2024 17:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesswire.com/news/home/20240307733599/en/MindMed-Receives-FDA-Breakthrough-Therapy-Designation-and-Announces-Positive-12-Week-Durability-Data-From-Phase-2B-Study-of-MM120-for-Generalized-Anxiety-Disorder">https://www.businesswire.com/news/home/20240307733599/en/MindMed-Receives-FDA-Breakthrough-Therapy-Designation-and-Announces-Positive-12-Week-Durability-Data-From-Phase-2B-Study-of-MM120-for-Generalized-Anxiety-Disorder</a>, See on <a href="https://news.ycombinator.com/item?id=39653125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>NEW YORK--(<span itemprop="provider publisher copyrightHolder" itemscope="itemscope" itemtype="https://schema.org/Organization" itemid="https://www.businesswire.com"><span itemprop="name"><a referrerpolicy="unsafe-url" rel="nofollow" itemprop="url" href="https://www.businesswire.com/">BUSINESS WIRE</a></span></span>)--<b>Mind Medicine (MindMed) Inc. </b>(NASDAQ: MNMD), (Cboe Canada MMED), (the “Company” or “MindMed”), a clinical stage biopharmaceutical company developing novel product candidates to treat brain health disorders, today announced that FDA has granted breakthrough designation to its MM120 (lysergide d-tartrate) program for the treatment of generalized anxiety disorder (GAD). The Company also announced that its Phase 2b study of MM120 in GAD met its key secondary endpoint, and 12-week topline data demonstrated clinically and statistically significant durability of activity observed through Week 12.

</p>
<blockquote></blockquote>
<p>
MindMed previously announced rapid, clinically meaningful, and statistically significant improvements on the Hamilton Anxiety rating scale (HAM-A) compared to placebo at Week 4, which was the trial’s primary endpoint. MM120 was administered as a single dose in a monitored clinical setting with no additional therapeutic intervention.

</p><p>
“I’ve conducted clinical research studies in psychiatry for over two decades and have seen studies of many drugs under development for the treatment of anxiety. That MM120 exhibited rapid and robust efficacy, solidly sustained for 12 weeks after a single dose, is truly remarkable,” stated David Feifel, MD, PhD, Professor Emeritus of Psychiatry at the University of California, San Diego and Director of the Kadima Neuropsychiatry Institute in La Jolla, California and an investigator in the MM120 study. “These results suggest the potential MM120 has in the treatment of anxiety, and those of us who struggle every day to alleviate anxiety in our patients look forward to seeing results from future Phase 3 trials.”

</p><p>
MM120 100 µg – the dose with optimal clinical activity observed in the trial – demonstrated a 7.7-point improvement over placebo at Week 12 (-21.9 MM120 vs. -14.2 placebo; p&lt;0.003 Cohen’s d=0.81), with a 65% clinical response rate and a 48% clinical remission rate sustained to Week 12. Clinical Global Impressions - Severity (CGI-S) scores on average improved from 4.8 to 2.2 in the 100-µg dose group, representing a two-category shift from ‘markedly ill’ to ‘borderline ill’ at Week 12 (p&lt;0.004). This clinical activity was rapid, observed as early as study day 2, and durable with further improvements observed in mean HAM-A or CGI-S scores between Weeks 4 and 12.

</p><p>
Based on the significant unmet medical need in the treatment of GAD – especially in patients who do not respond to or tolerate currently available medications – along with the initial clinical data from Phase 2b and other research conducted by MindMed, the U.S. Food &amp; Drug Administration (FDA) has designated MM120 for GAD as a breakthrough therapy. The Company plans to hold an End-of-Phase 2 meeting with the FDA in the first half of 2024 and initiate a Phase 3 clinical program in the second half of 2024.

</p><p>
“The FDA’s decision to designate MM120 as a breakthrough therapy for GAD and the durability data from our Phase 2b study provide further validation of the important potential role this treatment can play in addressing the huge unmet need among individuals living with GAD,” said Robert Barrow, Chief Executive Officer and Director of MindMed. “We are committed to bringing MM120 to people living with GAD and delivering on the potential of our pipeline to treat serious brain health disorders.”

</p><p>
In the Phase 2b study, known as MMED008, MM120 was generally well-tolerated with most adverse events rated as mild to moderate, transient and occurring on dosing day, and being consistent with expected acute effects of the study drug. The most common adverse events (at least 10% incidence in the high dose groups) on dosing day included illusion, hallucinations, euphoric mood, anxiety, abnormal thinking, headache, paresthesia, dizziness, tremor, nausea, vomiting, feeling abnormal, mydriasis and hyperhidrosis.

</p><p>
Prior to treatment with MM120, study participants were clinically tapered and then washed out from any anxiolytic or antidepressant treatments and did not receive any form of study-related psychotherapy for the duration of their participation in the study.

</p><p>
“As a clinician and clinical researcher, I applaud the way this study was designed by MindMed to isolate the effect of MM120 by removing confounding variables like additional medications and psychotherapy,” said Reid Robison, MD, Psychiatrist and Chief Clinical Officer at Numinus (TSX:NUMI) who has served as adjunct faculty at the University of Utah for the last 12 years and was an investigator in the MM120 study. “It gives me confidence in the data and the positive results give me hope that this may translate into meaningful benefits for my patients.”

</p><p>
The primary data analyses from MMED008 have been accepted for presentation at the American Psychiatric Association’s annual meeting, which will be held in New York on May 4-8, 2024. The study is also being submitted for publication in a leading medical journal.

</p><p>
<b>Conference Call and Webcast</b>

</p><p>
MindMed management will host a webcast at 8:00 am ET today to discuss the Phase 2b results of MM120 in GAD. The webcast and slides will be accessible live under “News &amp; Events” on the Investors page of the Company’s website at <a referrerpolicy="unsafe-url" target="_blank" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fir.mindmed.co%2F&amp;esheet=53906612&amp;newsitemid=20240307733599&amp;lan=en-US&amp;anchor=https%3A%2F%2Fir.mindmed.co%2F&amp;index=1&amp;md5=1f5a9dc24dd37580f1bf69afefc00ac6" rel="nofollow" shape="rect">https://ir.mindmed.co/</a> or by clicking <a referrerpolicy="unsafe-url" target="_blank" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fmindmed-2024-virtual-investor-event.open-exchange.net%2Fwelcome&amp;esheet=53906612&amp;newsitemid=20240307733599&amp;lan=en-US&amp;anchor=here&amp;index=2&amp;md5=2c0c2e1c0e28deb77d4cdb54c18f44c3" rel="nofollow" shape="rect">here</a>. A replay of the event will be available on MindMed’s website. The webcast will be archived on the Company’s website for at least 30 days after the conference call.

</p><p>
<b>About Generalized Anxiety Disorder (GAD)</b>

</p><p>
GAD is a common condition associated with significant impairment that adversely affects millions of people. GAD results in fear, persistent anxiety and a constant feeling of being overwhelmed. It is characterized by excessive, persistent, and unrealistic worry about everyday things. Approximately 10% of U.S. adults, representing around 20 million people, currently suffer from GAD, an underdiagnosed and underserved indication that is associated with significant impairment, less accomplishment at work and reduced labor force participation. Despite the significant personal and societal burden of GAD, there has been little innovation in the treatment of GAD in the past several decades, with the last new drug approval occurring in 2004.

</p><p>
<b>About MMED008</b>

</p><p>
MMED008 was a multi-center, parallel, randomized, double-blind, placebo-controlled, dose-optimization study. The trial enrolled 198 participants who were randomized to receive a single administration of MM120 at a dose of 25, 50, 100 or 200 µg or placebo. The full analysis set (FAS) for the trial included 194 subjects, those that had at least one valid post-baseline Hamilton Anxiety rating scale (HAM-A) score. Subjects enrolled in the trial presented with severe GAD symptoms (average baseline HAM-A scores of approximately 30). The study's main objective was to determine the dose-response relationship of four doses of MM120 versus placebo as measured by the change in HAM-A from Baseline to Week 4. The key secondary objective of the study was to determine the dose-response relationship of four doses of MM120 versus placebo as measured by the change in HAM-A from Baseline to Week 8. Secondary objectives, measured up to 12 weeks after the single administration, include assessments of anxiety symptoms, safety and tolerability, and other measures of efficacy and quality of life. More information about the trial is available on the MindMed website (mindmed.co) or on clinicaltrials.gov (NCT05407064).

</p><p>
<b>About MM120</b>

</p><p>
Lysergide is a synthetic ergotamine belonging to the group of classic, or serotonergic, psychedelics, which acts as a partial agonist at human serotonin-2A (5-hydroxytryptamine-2A [5-HT2A]) receptors. MindMed is developing MM120 (lysergide D-tartrate), the tartrate salt form of lysergide, for GAD and is exploring its potential applications in other serious brain health disorders.

</p><p>
<b>About MindMed</b>

</p><p>
MindMed is a clinical stage biopharmaceutical company developing novel product candidates to treat brain health disorders. Our mission is to be the global leader in the development and delivery of treatments that unlock new opportunities to improve patient outcomes. We are developing a pipeline of innovative product candidates, with and without acute perceptual effects, targeting neurotransmitter pathways that play key roles in brain health disorders.

</p><p>
MindMed trades on NASDAQ under the symbol MNMD and on the Cboe Canada (formerly known as the NEO Exchange, Inc.) under the symbol MMED.

</p><p>
<b>Forward-Looking Statements</b>

</p><p>
Certain statements in this news release related to the Company constitute “forward-looking information” within the meaning of applicable securities laws and are prospective in nature. Forward-looking information is not based on historical facts, but rather on current expectations and projections about future events and are therefore subject to risks and uncertainties which could cause actual results to differ materially from the future results expressed or implied by the forward-looking statements. These statements generally can be identified by the use of forward-looking words such as “will”, “may”, “should”, “could”, “intend”, “estimate”, “plan”, “anticipate”, “expect”, “believe”, “potential” or “continue”, or the negative thereof or similar variations. Forward-looking information in this news release includes, but is not limited to, statements regarding anticipated upcoming milestones, and progress of trials and studies; results and timing of and reporting of full data from the Company’s Phase 2b clinical trial of MM120; timing of a potential End-of-Phase-2 meeting with the FDA; timing of the initiation of a potential Phase 3 clinical trial of MM120; and the potential benefits of the Company’s product candidates. There can be no guarantees regarding the results of the potential Phase 3 clinical trial or that, following any such trial, MM120 will receive the necessary regulatory approvals. There are numerous risks and uncertainties that could cause actual results and the Company’s plans and objectives to differ materially from those expressed in the forward-looking information, including history of negative cash flows; limited operating history; incurrence of future losses; availability of additional capital; lack of product revenue; compliance with laws and regulations; difficulty associated with research and development; risks associated with clinical trials or studies; heightened regulatory scrutiny; early stage product development; clinical trial risks; regulatory approval processes; novelty of the psychedelic inspired medicines industry; as well as those risk factors discussed or referred to herein and the risks described in the Company’s Annual Report on Form 10-K for the fiscal year ended December 31, 2023, under headings such as “Special Note Regarding Forward-Looking Statements,” “Risk Factors” and “Management’s Discussion and Analysis of Financial Condition and Results of Operations,” and other filings and furnishings made by the Company with the securities regulatory authorities in all provinces and territories of Canada which are available under the Company’s profile on SEDAR at <span><a referrerpolicy="unsafe-url" target="_blank" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.sedar.com&amp;esheet=53906612&amp;newsitemid=20240307733599&amp;lan=en-US&amp;anchor=www.sedar.com&amp;index=3&amp;md5=13bd8d738361aab62249735088c381d7" rel="nofollow" shape="rect">www.sedar.com</a></span> and with the U.S. Securities and Exchange Commission on EDGAR at <span><a referrerpolicy="unsafe-url" target="_blank" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.sec.gov&amp;esheet=53906612&amp;newsitemid=20240307733599&amp;lan=en-US&amp;anchor=www.sec.gov&amp;index=4&amp;md5=2253927ea51d3c244d9ba449edb52596" rel="nofollow" shape="rect">www.sec.gov</a></span>. Except as required by law, the Company undertakes no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.

</p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An ALS drug fails, again (103 pts)]]></title>
            <link>https://www.science.org/content/blog-post/als-drug-fails-again</link>
            <guid>39652667</guid>
            <pubDate>Sat, 09 Mar 2024 16:20:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/blog-post/als-drug-fails-again">https://www.science.org/content/blog-post/als-drug-fails-again</a>, See on <a href="https://news.ycombinator.com/item?id=39652667">Hacker News</a></p>
Couldn't get https://www.science.org/content/blog-post/als-drug-fails-again: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[AI-Generated Data Can Poison Future AI Models (120 pts)]]></title>
            <link>https://www.scientificamerican.com/article/ai-generated-data-can-poison-future-ai-models/</link>
            <guid>39652262</guid>
            <pubDate>Sat, 09 Mar 2024 15:34:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/ai-generated-data-can-poison-future-ai-models/">https://www.scientificamerican.com/article/ai-generated-data-can-poison-future-ai-models/</a>, See on <a href="https://news.ycombinator.com/item?id=39652262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block="sciam/paragraph">Thanks to a boom in <a href="https://www.scientificamerican.com/podcast/episode/why-were-worried-about-generative-ai/">generative artificial intelligence</a>, programs that can produce text, computer code, images and music are readily available to the average person. And we’re already using them: AI content is <a href="https://www.wsj.com/articles/chatgpt-already-floods-some-corners-of-the-internet-with-spam-its-just-the-beginning-9c86ea25?mod=tech_lead_pos6&amp;mc_cid=987d4025e9&amp;mc_eid=74dd22853c">taking over the Internet</a>, and text generated by “<a href="https://www.scientificamerican.com/article/what-the-new-gpt-4-ai-can-do/">large language models</a>” is filling hundreds of websites, including CNET and Gizmodo. But as AI developers scrape the Internet, AI-generated content may soon enter the data sets used to <a href="https://www.scientificamerican.com/article/why-we-need-to-see-inside-ais-black-box/">train new models</a> to respond like humans. Some experts say that will inadvertently introduce errors that build up with each succeeding generation of models.</p><p data-block="sciam/paragraph">A growing body of evidence supports this idea. It suggests that a training diet of AI-generated text, even in small quantities, eventually becomes “poisonous” to the model being trained. Currently there are few obvious antidotes. “While it may not be an issue right now or in, let’s say, a few months, I believe it will become a consideration in a few years,” says Rik Sarkar, a computer scientist at the School of Informatics at the University of Edinburgh in Scotland.</p><figure data-original-class="cms-video" data-block="sciam/image"><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="360" loading="lazy" src="https://www.youtube.com/embed/ZWvTr5wKGCA" title="Video player" width="640"></iframe></figure><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">The possibility of AI models tainting themselves may be a bit analogous to a certain 20th-century dilemma. After the first atomic bombs were detonated at World War II’s end, decades of nuclear testing spiced Earth’s atmosphere with a dash of radioactive fallout. When that air entered newly-made steel, it brought elevated radiation with it. For particularly radiation-sensitive steel applications, such as Geiger counter consoles, that fallout poses an obvious problem: it won’t do for a Geiger counter to flag itself. Thus, a rush began for a dwindling supply of low-radiation metal. Scavengers <a href="https://www.theatlantic.com/science/archive/2019/10/search-dark-matter-depends-ancient-shipwrecks/600718/">scoured</a> old shipwrecks to extract scraps of prewar steel. Now some insiders believe a similar cycle is set to repeat in generative AI—with training data instead of steel.</p><p data-block="sciam/paragraph">Researchers can watch AI’s poisoning in action. For instance, start with a language model trained on human-produced data. Use the model to generate some AI output. Then use that output to train a new instance of the model and use the resulting output to train a third version, and so forth. With each iteration, errors build atop one another. The 10th model, prompted to write about historical English architecture, <a href="https://arxiv.org/abs/2305.17493v2">spews out gibberish about jackrabbits</a>.</p><p data-block="sciam/paragraph">“It gets to a point where your model is practically meaningless,” says Ilia Shumailov, a machine learning researcher at the University of Oxford.</p><p data-block="sciam/paragraph">Shumailov and his colleagues call this phenomenon “model collapse.” They observed it in a language model called OPT-125m, as well as a different AI model that generates handwritten-looking numbers and even a simple model that tries to separate two probability distributions. “Even in the simplest of models, it’s already happening,” Shumailov says. “I promise you, in more complicated models, it’s 100 percent already happening as well.”</p><p data-block="sciam/paragraph">In a recent preprint study, Sarkar and his colleagues in Madrid and Edinburgh <a href="https://arxiv.org/abs/2306.06130">conducted a similar experiment</a> with a type of AI image generator called a diffusion model. Their first model in this series could generate recognizable flowers or birds. By their third model, those pictures had devolved into blurs.</p><p data-block="sciam/paragraph">Other tests showed that even a partly AI-generated training data set was toxic, Sarkar says. “As long as some reasonable fraction is AI-generated, it becomes an issue,” he explains. “Now exactly how much AI-generated content is needed to cause issues in what sort of models is something that remains to be studied.”</p><p data-block="sciam/paragraph">Both groups experimented with relatively modest models—programs that are smaller and use fewer training data than the likes of the language model GPT-4 or the image generator Stable Diffusion. It’s possible that larger models will prove more resistant to model collapse, but researchers say there is little reason to believe so.</p><p data-block="sciam/paragraph">The research so far indicates that a model will suffer most at the “tails” of its data—the data elements that are less frequently represented in a model’s training set. Because these tails include data that are further from the “norm,” a model collapse could cause the AI’s output to lose the diversity that researchers say is distinctive about human data. In particular, Shumailov fears this will exacerbate models’ existing biases against marginalized groups. “It’s quite clear that the future is the models becoming more biased,” he says. “Explicit effort needs to be put in order to curtail it.”</p><p data-block="sciam/paragraph">Perhaps all this is speculation, but AI-generated content is already beginning to enter realms that machine-learning engineers rely on for training data. Take language models: even mainstream news outlets <a href="https://www.wired.com/story/cnet-published-ai-generated-stories-then-its-staff-pushed-back/">have begun publishing AI-generated articles</a>, and some Wikipedia editors <a href="https://www.vice.com/en/article/v7bdba/ai-is-tearing-wikipedia-apart">want to use language models</a> to produce content for the site.</p><p data-block="sciam/paragraph">“I feel like we’re kind of at this inflection point where a lot of the existing tools that we use to train these models are quickly becoming saturated with synthetic text,” says Veniamin Veselovskyy, a graduate student at the Swiss Federal Institute of Technology in Lausanne (EPFL).</p><p data-block="sciam/paragraph">There are warning signs that AI-generated data might enter model training from elsewhere, too. Machine-learning engineers have long relied on crowd-work platforms, such as Amazon’s Mechanical Turk, to annotate their models’ training data or to review output. Veselovskyy and his colleagues at EPFL asked Mechanical Turk workers to summarize medical research abstracts. They found that around <a href="https://arxiv.org/abs/2306.07899">a third of the summaries had ChatGPT’s touch</a>.</p><p data-block="sciam/paragraph">The EPFL group’s work, released on the preprint server arXiv.org last month, examined only 46 responses from Mechanical Turk workers, and summarizing is a classic language model task. But the result has raised a specter in machine-learning engineers’ minds. “It is much easier to annotate textual data with ChatGPT, and the results are extremely good,” says Manoel Horta Ribeiro, a graduate student at EPFL. Researchers such as Veselovskyy and Ribeiro have begun considering ways to protect the humanity of crowdsourced data, including tweaking websites such as Mechanical Turk in ways that discourage users from turning to language models and redesigning experiments to encourage more human data.</p><p data-block="sciam/paragraph">Against the threat of model collapse, what is a hapless machine-learning engineer to do? The answer could be the equivalent of prewar steel in a Geiger counter: data known to be free (or perhaps as free as possible) from generative AI’s touch. For instance, Sarkar suggests the idea of employing “standardized” image data sets that would be curated by humans who know their content consists only of human creations and freely available for developers to use.</p><p data-block="sciam/paragraph">Some engineers may be tempted to pry open the Internet Archive and look up content that predates the AI boom, but Shumailov doesn’t see going back to historical data as a solution. For one thing, he thinks there may not be enough historical information to feed growing models’ demands. For another, such data are just that: historical and not necessarily reflective of a changing world.</p><p data-block="sciam/paragraph">“If you wanted to collect the news of the past 100 years and try and predict the news of today, it’s obviously not going to work, because technology’s changed,” Shumailov says. “The lingo has changed. The understanding of the issues has changed.”</p><p data-block="sciam/paragraph">The challenge, then, may be more direct: discerning human-generated data from synthetic content and filtering out the latter. But even if the technology for this existed, it is far from a straightforward task. As Sarkar points out, in a world where Adobe Photoshop <a href="https://www.adobe.com/sensei/generative-ai/firefly.html">allows its users to edit images with generative AI</a>, is the result an AI-generated image—or not?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An all-optical general-purpose CPU and optical computer architecture (135 pts)]]></title>
            <link>https://arxiv.org/abs/2403.00045</link>
            <guid>39651926</guid>
            <pubDate>Sat, 09 Mar 2024 14:49:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.00045">https://arxiv.org/abs/2403.00045</a>, See on <a href="https://news.ycombinator.com/item?id=39651926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.00045">Download PDF</a>
    <a href="https://arxiv.org/html/2403.00045v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Energy efficiency of electronic digital processors is primarily limited by the energy consumption of electronic communication and interconnects. The industry is almost unanimously pushing towards replacing both long-haul, as well as local chip interconnects, using optics to drastically increase efficiency. In this paper, we explore what comes after the successful migration to optical interconnects, as with this inefficiency solved, the main source of energy consumption will be electronic digital computing, memory and electro-optical conversion. Our approach attempts to address all these issues by introducing efficient all-optical digital computing and memory, which in turn eliminates the need for electro-optical conversions. Here, we demonstrate for the first time a scheme to enable general purpose digital data processing in an integrated form and present our photonic integrated circuit (PIC) implementation. For this demonstration we implemented a URISC architecture capable of running any classical piece of software all-optically and present a comprehensive architectural framework for all-optical computing to go beyond.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Leonardo Del Bino [<a href="https://arxiv.org/show-email/211339aa/2403.00045">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 29 Feb 2024 15:49:25 UTC (2,392 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monodraw (564 pts)]]></title>
            <link>https://monodraw.helftone.com/</link>
            <guid>39651796</guid>
            <pubDate>Sat, 09 Mar 2024 14:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://monodraw.helftone.com/">https://monodraw.helftone.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39651796">Hacker News</a></p>
<div id="readability-page-1" class="page">

<section id="introduction">

	<header>
		
	</header>

<div>

	<hgroup id="ani_h1">
		<h2 data-wow-duration="1.2s" data-wow-delay=".7s">Powerful ASCII art editor designed for the Mac.</h2>
		<!-- <h2 class="inline-block h1 wow fadeInRight" data-wow-delay="1.6s"> Now in Beta.</h2> -->
	</hgroup>
	
	<p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-robot.png" width="1072"></p>
</div>

</section>

<div>

	<h2>Harness the Power and Simplicity of Plain Text</h2>

	<p>
		Plain text has been around for decades and it's here to stay. <strong>Monodraw</strong> allows you to easily create text-based art (like diagrams, layouts, flow charts) and visually represent algorithms, data structures, binary formats and more. Because it's all just text, it can be easily embedded almost anywhere. Of course, exporting as images is also supported (PNG and SVG).
	</p>

</div>



<div id="section-text-tool">
    <div data-wow-delay="0.2s" data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/diagram-icon.png" width="44px"> Diagrams</h2>
        <p>
          A picture is worth a thousand words. A diagram is probably worth twice as much. Enhance your technical <a href="https://github.com/dguerri/vagrant-ansible-openstack#architecture---network-diagram">documentation</a> (code, specs) with easy to comprehend textual art. Visualisation of data structures, algorithms and data formats plays a crucial role in understanding. You will be reading the code more often than writing it, so why not make it much easier to grasp.
          </p>
      </div>
    <div data-wow-duration="1.1s">
        <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-diagrams.png">
        </p>
    </div>
  </div>

<!-- Section Text Field -->
<div id="section-text-tool">

    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-mind-map.png">
      </p>
    </div>

    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/mindmap-icon.png" width="44px"> Mind Mapping</h2>
        <p>
          Combine the simplicity of plain text with the power of mind mapping. Monodraw gives you the freedom to manage your textual data exactly the way you want. Move text around anywhere in the infinite canvas – no need to be constrained by the linear structure of a text file.
        </p>
      </div>

  </div>
<!-- # End Section  -->

<!-- Section Text Field -->
<div id="section-text-tool">
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/erdiagram-icon.png" width="44px"> ER Diagrams</h2>
        <p>
			Do you deal with databases? Then you know how useful entity-relationship diagrams can be. Visually describe your data model with a simple ER diagram. Monodraw supports Crow's Foot notation in three different variants to suit your personal preference.
        </p>
      </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-er-diagrams.png">
      </p>
    </div>
  </div>
<!-- # End Section  -->

<!-- Section Text Field -->
<div id="section-text-tool">

    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-banners.png">
      </p>
    </div>
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/banner-icon.png" width="44px"> Banners</h2>
        <p>
      Easily create text banners with just a single click. <a href="http://www.figlet.org/">FIGlet</a> is built into Monodraw and we bundle 148 fonts as standard (custom ones are supported, too). You can interactively resize the text box, change the font and adjust the alignment – no need for a terminal.
        </p>
      </div>
  </div>
<!-- # End Section  -->


<!-- <section class="center bg-white">
<div class=" gradient-7 py1 mx-auto wow fadeIn">
	<h2 class="h1 mt0 thin black fw300">Tools that will extend your capabilities </h2>
	<p class="col-10 h4 mx-auto dark-gray">
		Plain text has been around for decades and it's here to stay.
	</p>
<ul class="table table-fixed center p0">
	<li class="table-cell"><h2 class="h3 h-has-icon"><img class="block mx-auto mb2 2x" src="/static/images/text-field-icon.png" width="44px"/> Text Tool</h2></li>

	<li class="table-cell"><h2 class="h3 h-has-icon"><img class="block mx-auto mb2 2x" src="/static/images/line-icon.png" width="44px"/> Line Tool</h2></li>
	<li class="table-cell"><h2 class="h3 h-has-icon"><img class="block mx-auto mb2 2x" src="/static/images/text-field-icon.png" width="44px"/> Rect Tool</h2></li>
	<li class="table-cell"><h2 class="h3 h-has-icon"><img class="block mx-auto mb2 2x" src="/static/images/text-field-icon.png" width="44px"/> Drawing Tool</h2></li>
</ul>
</div>

</section> -->

<!-- Section Text Field -->
<div id="section-text-tool">
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/text-field-icon.png" width="44px"> Text Tool</h2>
        <p>
          Monodraw is powered by a custom CoreText-based text engine giving you precise control over the layout. You can adjust the alignment, position, line sweep direction and line movement. Adding a border around your text is only a click away, too.
        </p>
      </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-text-tool.png">
      </p>
    </div>
  </div>
<!-- # End Section  -->

<!-- Section Line Tool  -->
<div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-line-tool.png">
      </p>
    </div>
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/line-icon.png" width="44px">Line Tool</h2>
        <p>
          The line tool makes connecting shapes as easy as pie. Orthogonal and staircase lines are supported with the ability to set a line dash pattern. Attachment points allow you to dynamically attach your lines to other shapes so that you don't have to re-arrange them each time you move things around.
        </p>
      </div>
  </div>
<!-- # End Section  -->

<!-- Section Rectangle -->
<div>
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/rectangle-icon.png" width="44px">Rect Tool</h2>
        <p>
          The rectangle tool can be used to create all kinds of boxes which are the most commonly used element in text art. Specify border or a background with just a few clicks. Oh, you can add shadows, too! Last but not least, custom attachment points will help you attach your lines at exactly the right place.
        </p>
      </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-rect-tool.png">
      </p>
    </div>
  </div>
<!-- # End Section  -->

<!-- Section Text Field -->
<div id="section-text-tool">

    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/monodraw-cli.png">
      </p>
    </div>
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/terminal-icon.png" width="44px">CLI Included</h2>
        <p>
      Monodraw includes a command-line interface (<a href="#cli-tool-direct-store">Direct version only</a>). For example, you can use it to automatically generate docs when committing by leveraging version control hooks. The tool can also output JSON, for easier programmatic manipulation.
        </p>
      </div>
  </div>
<!-- # End Section  -->

<!-- Section Text Field -->
<div id="section-text-tool">
    <div data-wow-duration="1.1s">
        <h2><img src="https://monodraw.helftone.com/static/images/pencil-icon.png" width="44px">Drawing Tools</h2>
        <p>
			The basic drawing tools that you would expect make their usual appearance. The Pencil, Eraser, Bucket Fill and Picker are all indispensable when it comes to producing textual art. You can also easily overlay any images on the canvas for tracing purposes.
        </p>
      </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/screenshots/shot-drawing-tools.png">
      </p>
    </div>
  </div>
<!-- # End Section  -->



<!-- Section Powerful features -->
<section>
  <div data-wow-duration="1.1s">
      <h2><img src="https://monodraw.helftone.com/static/images/power-icon.png" width="44px">Powerful Features</h2>
      <p>When it comes to creating text art, Monodraw helps you out by providing the tools you need.</p>
    </div>
  <div>
    <div data-wow-duration="1.1s" data-wow-delay="0.2s">
      <p><img src="https://monodraw.helftone.com/static/images/feat-group-icon.png" width="48px"></p><h2>Groups</h2>
      <p>
        Shapes can be grouped for effortless management. By composing multiple elements to form a single group, duplication and movement become very easy.
      </p>
    </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.4s">
      <p><img src="https://monodraw.helftone.com/static/images/guides-icon.png" width="48px"></p><h2>Guides</h2>
      <p>
        Alignment guides are a life-saver when arranging and sizing your content – no longer do you have to stare at the screen and count the number of characters.
      </p>
    </div>
    <div data-wow-duration="1.1s" data-wow-delay="0.6s">
      <p><img src="https://monodraw.helftone.com/static/images/focus-group-icon.png" width="48px"></p><h2>Focus</h2>
      <p>
        When you need to focus on a particular part of the canvas, the rest of the shapes can be locked or hidden away. You can then zoom in to concentrate on the currently visible elements.
      </p>
    </div>
    <div data-wow-duration="1.1s" data-wow-delay=".8s">
      <p><img src="https://monodraw.helftone.com/static/images/shortcuts-icon.png" width="72px"></p><h2>Shortcuts</h2>
      <p>
        All functionality can be efficiently accessed via shortcuts, so there is no need to take your hands off the keyboard. Tools are quickly accessible with a single keystroke, without the need for a modifier.
      </p>
    </div>
  </div>
  <!-- <div class="container clearfix">
  <div class="col col-6">
  <div class="right p4 feature">
  <h2 class="h1 thin h-has-icon"><img class="left mr2 2x" src="/static/images/power-icon.png" width="44px"/>Powerful Features</h2>
  <p>
  When it comes to creating text art, Monodraw helps you out by providing the tools you need. Shapes can be grouped for effortless management. Alignment guides are a life-saver when you are trying to arrange and size your content &ndash; no longer do you have to stare at the screen and count the number of characters.
</p>
<p>
When you need to focus on a particular part of your drawing, you can just lock or hide the rest of the shapes. All the functionality can be efficiently accessed via shortcuts, so there is no need to take your hands off the keyboard.
</p>
</div>
</div>
<div class="col col-6">
<div class="screenshot ss-right">
<img class="2x" src="/static/images/screenshot.png" width="100%"/>
</div>
</div>
</div> -->
</section>
<!-- # End Section  -->

<!-- Section Powerful features -->
<div id="designed_for_mac">
<div id="" data-wow-duration="1.1s" data-wow-delay="0.2s">
  <pre>                        ◎
                        │
                        │                ┌─────────────────────┐
                 ┌──────◇──────┐         │                     │
                 │             │         │                     │
             ┏■──┘━━━━━━━━━━━━━└──■┓     │                     │
             ┃*━━━━━━━━━━━━━━━━━━━*┃     ◍ Hello, dear friend! │
             ┃┃   ■■■■■   ■■■■■   ┃┃    ╱                      │
             ┃┃   ■■■■■   ■■■■■   ┃┃   ╱                       │
             ┃┃   ■■■■■   ■■■■■   ┃┃  ╱──◍                     │
             ┃*━━━━━━━━━━━━━━━━━━━*┃     └─────────────────────┘
            ◆─────◆─────◆─────◆─────◆
            │╲***╱*╲***╱*╲***╱*╲***╱│
            │*╲*╱***╲*╱***╲*╱***╲*╱*│
            └──◆─────◆─────◆─────◆──┘
             ┗━━━━━━━━━━━━━━━━━━━━━┛
      ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┏━━━━━┃///////////////////////////////////┃━━━━━┓
┃ ┌─┐ ┃.▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫.┃ ┌─┐ ┃
┃ │ │ ┃.▫          ╔═════════╗          ▫.┃ │ │ ┃
┗━│ │━┃.▫          ║   ┌┐ ●─○║          ▫.┃━│ │━┛
  │ │ ◎─▣──────────▣   ││  ┌─▣──────────▣─◎ │ │
  │ │ ┃.▫▨▨▨▨▨▨▨▨▨▨└┐ ┌┘└┐┌┘ ║▨▨▨▨▨▨▨▨▨▨▫.┃ │ │
  │ │ ┃.▫◹◹◹◹◹◹◹◹◹◹║└─┘  └┘  ║◸◸◸◸◸◸◸◸◸◸▫.┃ │ │
  │ │ ┃.           ╚═════════╝           .┃ │ │
 ┏━━━┓┃.                                 .┃┏━━━┓
 ┗━━━┛┃.     M  O  N  O  D  R  A  W      .┃┗━━━┛
  │ │ ┃.                                 .┃ │ │
  │ │ ┗━━━━━━///////////////////////━━━━━━┛ │ │
  │ │       ┃◦                     ◦┃       │ │
  │ │       ┃   ┏━━━━━━━━━━━━━━━┓   ┃       │ │
  │ │       ┃◦  ┃▤▤▤▤▤▤▤▤▤▤▤▤▤▤▤┃  ◦┃       │ │
  │ │       ┃   ┗━━━━━━━━━━━━━━━┛   ┃       │ │
┌──◎──┐     ┃◦                     ◦┃     ┌──◎──┐
│ ┌─┐ │ ┏━━━━━━━━━━━━┓◬◬◬◬◬┏━━━━━━━━━━━━┓ │ ┌─┐ │
└─┘ └─┘ ┃            ┃━━━━━┃            ┃ └─┘ └─┘
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
        ┃\\\\\\\\\\\\┃     ┃\\\\\\\\\\\\┃
       ┌──────────────┐   ┌──────────────┐
       │              │   │              │
       └──────────────┘   └──────────────┘
        ┃////////////┃     ┃////////////┃
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
        ┃            ┃     ┃            ┃
      ┌────────────────┐ ┌────────────────┐
      │                │ │                │
      ┏━━━━━━━━━━━━━━━━┓ ┏━━━━━━━━━━━━━━━━┓
      ┗━━━━━━━━━━━━━━━━┛ ┗━━━━━━━━━━━━━━━━┛
  </pre>
  </div>
<div data-wow-duration="1.1s">
    <h2><img src="https://monodraw.helftone.com/static/images/finder-icon.png" width="44px">Designed for Mac</h2>
    <div><p>
      Monodraw is designed for the Mac from the ground up – everything from the text layout engine to the interface is made to take advantage of macOS. Like all native apps, it just works the way you expect. When you make a mistake, undo is always ready to come to the rescue. Exporting your text art could not get any easier – just copy and paste it into your favourite text editor. </p><p><a href="http://blog.helftone.com/ascii-art-unicode/">Not displaying correctly?</a></p></div>
  </div>
 </div>
<!-- # End Section  -->



<div id="section-faq">
  <p><strong>What are the system requirements?</strong></p>
  <div><p>The app requires macOS 11 Big Sur or later.</p><p>If you're running an older version of macOS, you can download <a href="https://updates.helftone.com/monodraw/downloads/Monodraw-b102.dmg">Monodraw v1.3</a> which requires macOS 10.10 Yosemite or <a href="https://updates.helftone.com/monodraw/downloads/Monodraw-b107.dmg">Monodraw v1.5</a> which requires macOS 10.14 Mojave.</p></div>

  <p><strong>Which versions include the command line tool?</strong></p>
  <p>
    Only the versions which you download directly from our website and purchase from <a href="https://sites.fastspring.com/helftone/product/monodraw">our store</a>. Due to restrictions imposed by the <a href="https://developer.apple.com/app-sandboxing/">App Sandbox</a> on the Mac App Store, the tool cannot be included there.
  </p>

  <!-- <p class="h3 fw300"><strong>How do I keep track of the latest news?</strong></p>
  <p class="mid-gray border-left p2">We're going to be posting updates on our <a href="http://blog.helftone.com/">blog</a> (<a href="http://blog.helftone.com/feed.xml">RSS feed</a>) and you should follow <a href="http://twitter.com/monodraw" title="Monodraw on Twitter" target="_blank">@Monodraw</a>. You can also subscribe to receive updates straight to your email inbox &mdash; scroll to the bottom of the page and sign up.</p> -->

  <p><strong>How do I provide feedback?</strong></p>
  <p>We would love to hear from you — the best way would be to drop us an <a href="mailto:monodraw@helftone.com?subject=Monodraw%20Feedback">email</a>. Alternatively, just tweet us <a href="http://twitter.com/monodraw" title="Monodraw on Twitter" target="_blank">@Monodraw</a>.</p>

  <p><strong>How are you going to use my email? I hate spam.</strong></p>
  <p>We hate spam, too. We would not share your email with any 3rd parties, period. We would only email you if we have important news about Monodraw and our upcoming products, that's it.</p>

  <p><strong>Do you have a Press Kit? </strong></p>
  <p>Of course — you can download it <a href="http://helftone-assets.s3.amazonaws.com/monodraw/Monodraw-Press-Kit.zip">from here</a>.</p>  


  <p><strong>Do you offer Educational Pricing?</strong></p>
  <p>Yes, we do — just <a href="mailto:support@helftone.com?subject=Educational%20Pricing">get in touch</a>.</p>

  <p><strong>Privacy Policy</strong></p>
  <p>We take your privacy very seriously. Monodraw does not collect any data whatsoever.</p>  

</div>




<!-- Popup itself -->













</div>]]></description>
        </item>
        <item>
            <title><![CDATA[4D Knit Dress (174 pts)]]></title>
            <link>https://selfassemblylab.mit.edu/4d-knit-dress</link>
            <guid>39651710</guid>
            <pubDate>Sat, 09 Mar 2024 14:19:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://selfassemblylab.mit.edu/4d-knit-dress">https://selfassemblylab.mit.edu/4d-knit-dress</a>, See on <a href="https://news.ycombinator.com/item?id=39651710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-d17cc2c97847c0510e48">
  <p>4D Knit Dress: Transforming Style<br>MIT Self-Assembly Lab x Ministry of Supply</p><p>MIT Self-Assembly Lab Team:<br>Sasha Mckinlay, Danny Griffin, Sofia Chen, Lavender Tessmer, Natalie Pearl, Susan Williams, Agnes Parker, Jared Laucks, Skylar Tibbits</p><p>Ministry of Supply Team:<br>Jarlath Mellett, Alessandra Vasi, Ryan Connary, Gihan Amarasiriwardena</p><div><p>Typical garment construction requires a designer to build a 2D pattern, then cut and sew from 2D fabric – yielding excess waste, additional cost/labor and bulky seams that don’t always follow human anatomy. New innovation in 3D knitting – akin to 3D printing - has allowed fabric variation and standardized 3D shaping - however customized shaping of knitted garments to fit anyone’s unique body or style hasn’t been possible.</p><p>4D Knit Dress, combines several technologies – heat-activated yarns, computerized knitting and 6-axis robotic activation to create a garment that is sculpted to create a personalized fit or style. Heat-activated yarns are embedded within a unique knit structure to create controlled transformation, while maintaining softness, stretch and resilience. Using an efficient tubular knitting technique, a 6-axis robotic arm (commonly used in automotive manufacturing) heats specific areas to take-in – mimicking the design process of pinning &amp; tucking used in traditional dress tailoring – transforming the dress in real-time to create a perfect fit or a unique look.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple curl security incident 12604 (242 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2024/03/08/the-apple-curl-security-incident-12604/</link>
            <guid>39650498</guid>
            <pubDate>Sat, 09 Mar 2024 09:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2024/03/08/the-apple-curl-security-incident-12604/">https://daniel.haxx.se/blog/2024/03/08/the-apple-curl-security-incident-12604/</a>, See on <a href="https://news.ycombinator.com/item?id=39650498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-23833">
	
		<p><img width="672" height="338" src="https://daniel.haxx.se/blog/wp-content/uploads/2022/03/apples.jpg" alt="" decoding="async">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>tldr: Apple thinks it is fine. I do not.</p>



<p>On December 28 2023, <a href="https://github.com/curl/curl/issues/12604">bugreport 12604</a> was filed in the curl issue tracker. We get a lot issues filed most days so this fact alone was hardly anything out of the ordinary. We read the reports, investigate, ask follow-up questions to see what we can learn and what we need to address.</p>



<p>The title stated of the problem in this case was quite clear: <em><a href="https://github.com/curl/curl/issues/12604">flag –cacert behavior isn’t consistent between macOS and Linux</a></em>, and it was filed by Yuedong Wu.</p>



<p>The friendly reporter showed how the curl version bundled with macOS behaves differently than curl binaries built entirely from open source. Even when running the same curl version on the same macOS machine.</p>



<p>The curl command line option <code><a href="https://curl.se/docs/manpage.html#--cacert">--cacert</a></code> provides a way for the user to say to curl that <strong>this is the exact set of CA certificates to trust</strong> when doing the following transfer. If the TLS server cannot provide a certificate that can be verified with that set of certificates, it should fail and return error.</p>



<p>This particular behavior and functionality in curl has been established since many years (this option was added to curl in December 2000) and of course is provided to allow users to know that it communicates with a known and trusted server. A pretty fundamental part of what TLS does really.</p>



<p>When this command line option is used with curl on macOS, <em>the version shipped by Apple</em>, <strong>it seems to fall back and checks the system CA store in case the provided set of CA certs fail the verification</strong>.  A <em>secondary check</em> that was not asked for,  is not documented and plain frankly comes completely by surprise. Therefore, when a user runs the check with a trimmed and dedicated CA cert file, it will not fail if the system CA store contains a cert that can verify the server!</p>



<p>This is a security problem because now<strong> suddenly certificate checks pass that should not pass.</strong></p>



<p>I reported this as a security problem in an email sent to Product Security at Apple on December 29 2023, 08:30 UTC. It’s not a major problem, but it is an issue.</p>



<h2>Apple’s says it is fine</h2>



<p>On March 8, 2024 Apple Product Security responded with their wisdom:</p>



<pre>Hello,

Thank you again for reporting this to us and allowing us time to investigate.

Apple’s version of OpenSSL (LibreSSL) intentionally uses the built-in system trust store as a default source of trust. Because the server certificate can be validated successfully using the built-in system trust store, we don't consider this something that needs to be addressed in our platforms.

Best regards,
KC
Apple Product Security</pre>



<p>Case closed.</p>



<h2>I disagree</h2>



<p>Obviously I think differently. This <em>undocumented feature</em> makes CA cert verification with curl on macOS totally unreliable and inconsistent with documentation. It tricks users.</p>



<p>Be aware.</p>



<p>Since this is not a security vulnerability in the curl version we ship, we have not issued a CVE or anything for this problem. The problem is strictly speaking not even in curl code. It comes with the version of LibreSSL that Apple ships and builds curl to use on their platforms.</p>
	</div><!-- .entry-content -->
	
	</article><!-- #post-23833 -->
		<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>tech, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anomalous contribution to galactic rotation curves due to stochastic spacetime (128 pts)]]></title>
            <link>https://arxiv.org/abs/2402.19459</link>
            <guid>39650489</guid>
            <pubDate>Sat, 09 Mar 2024 09:13:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2402.19459">https://arxiv.org/abs/2402.19459</a>, See on <a href="https://news.ycombinator.com/item?id=39650489">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2402.19459.pdf">Download PDF</a>
    <a href="https://arxiv.org/html/2402.19459v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We consider a proposed alternative to quantum gravity, in which the spacetime metric is treated as classical, even while matter fields remain quantum. Consistency of the theory necessarily requires that the metric evolve stochastically. Here, we show that this stochastic behaviour leads to a modification of general relativity at low accelerations.
<br>In the low acceleration regime, the variance in the acceleration produced by the gravitational field is high in comparison to that produced by the Newtonian potential, and acts as an entropic force, causing a deviation from Einstein's theory of general relativity. We show that in this "diffusion regime", the entropic force acts from a gravitational point of view, as if it were a contribution to the matter distribution.
<br>We compute how this modifies the expectation value of the metric via the path integral formalism, and find that an entropic force driven by a stochastic cosmological constant can explain galactic rotation curves without needing to evoke dark matter. We caution that a greater understanding of this effect is needed before conclusions can be drawn, most likely through numerical simulations, and provide a template for computing the deviation from general relativity which serves as an experimental signature of the Brownian motion of spacetime.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jonathan Oppenheim [<a href="https://arxiv.org/show-email/c6d5dc9a/2402.19459">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 29 Feb 2024 18:52:40 UTC (173 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1brc merykitty's magic SWAR: 8 lines of code explained in 3k words (170 pts)]]></title>
            <link>https://questdb.io/blog/1brc-merykittys-magic-swar/</link>
            <guid>39649732</guid>
            <pubDate>Sat, 09 Mar 2024 05:57:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://questdb.io/blog/1brc-merykittys-magic-swar/">https://questdb.io/blog/1brc-merykittys-magic-swar/</a>, See on <a href="https://news.ycombinator.com/item?id=39649732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>
  QuestDB is a high performance time series database with SQL
  analytics that can power through data ingestion and analysis.
  It's <a href="https://github.com/questdb/questdb">open source</a>
  and integrates with many tools and languages. Give us a try!</p><hr><p>In a
<a href="https://questdb.io/blog/billion-row-challenge-step-by-step/" target="_blank" rel="noopener noreferrer">recent blog post</a>
I described the most important optimizations I and other contestants applied at
the recent <a href="https://1brc.dev/" target="_blank" rel="noopener noreferrer">One Billion Row Challenge (1BRC)</a>. Using them I
showed how the performance of the initial idiomatic, parallelized Java code
improves by a factor of 40. We went from 71 seconds, down to 1.7.</p><p>The optimization techniques we applied ranged from simple and digestible to
arcane and mystifying. One technique in particular stood out as especially
awesome but cryptic, and I noted that explaining it would take another full blog
post.</p><p>So, here we are!</p><h2>Enter the 1BRC<a href="#enter-the-1brc" title="Direct link to heading">#</a></h2><p>Several experts predicted at the outset of the 1BRC contest that, once the
"usual suspects" are dealt with, one particular concern would become the
botteneck: parsing the temperature from the CSV file. It isn't a complicated
format – the temperature can range from -99.9 to 99.9, so there are a total of
four possible arrangements of characters: <code>-XX.X</code>, <code>-X.X</code>, <code>X.X</code>, and <code>XX.X</code>.
But, when your goal is to parse one billion of them in less than a second, every
little detail and variation becomes an issue.</p><p>Initially, contestants used the <code>Double.parseDouble()</code> library call. But soon
enough, custom solutions started popping up that were up to a screenful long.
Many adopted an approach that looked pretty optimal. It didn't involve any
loops, and had the seeming "theoretical minimum" of two branching points,
covering the four possibilities.</p><p>Then, out of the blue, a solution appeared that set the Twitter #1BRC hashtag on
fire. No <code>if</code> statements, and just a single read from the file! It was a part of
the solution contributed by Quân Anh Mai (GitHub handle
<a href="https://github.com/MeryKitty" target="_blank" rel="noopener noreferrer">@merykitty</a>). The code looked like nothing less
than magic incantations, and even the top experts nodded in disbelief.</p><p>Since 1BRC was an open source contest, everyone could look at and copy ideas
from others. As a result, this snippet spread like wildfire and became a
standard element of all the top solutions. The winning contestant, Thomas
Wuerthinger, went as far as listing Quân Anh as a part of the team that
contributed to his solution.</p><blockquote><p><strong>Big thanks to Quân Anh, who reviewed this post for correctness and approved
it!</strong></p></blockquote><h2>Unpacking merykitty’s Magic SWAR<a href="#unpacking-merykittys-magic-swar" title="Direct link to heading">#</a></h2><p>Merykitty's code consists of nothing but a fixed sequence of 18 ALU operations:
bitwise shift, AND, NOT and XOR; arithmetic add, subtract, and multiply; and a
single low-level function call <code>numberOfTrailingZeros()</code>, for which the JDK has
a compiler intrinsic using specialized CPU instructions.</p><p>In goes a <code>long</code> number filled with 8 bytes from the CSV (in little-endian
order), and out comes the temperature as an integer (10x the actual
temperature).</p><p>We pack eight bytes of input into a single CPU register, and then perform
operations on the register as a whole. Usually, such work is performed using
specialized CPU instructions, designed specifically to operate on many bytes of
data at once. Such instructions are called "Single Instruction, Multiple Data",
or SIMD for short. In this case, we're using standard CPU registers and
instructions – this kind of technique goes by the name of "SIMD Within A
Register", or SWAR.</p><p>The full code at a glance:</p><blockquote><p>Note: this is not the exact original code by merykitty. It is slightly
transformed for easier reading.
<a href="https://github.com/gunnarmorling/1brc/blob/dfec2cdbe6a0334cff054f333ec4b4d9e4d775cf/src/main/java/dev/morling/onebrc/CalculateAverage_merykitty.java#L165-L195" target="_blank" rel="noopener noreferrer">View the original</a>.</p></blockquote><p>The value of the <code>inputData</code> parameter comes from a direct native memory read of
the <code>mmap</code>'d CSV file. We don't have to deal with that code since it's a
separate concern.</p><p>Now, we've all seen a line or two of bit-twiddling code here and there that
looks cryptic at first. However, after half an hour explaining it to yourself,
it becomes kind of familiar and not that scary.</p><p>But have you ever seen <em>this</em> much of it in one place? And solving such a
complex, high-level problem like parsing temperature? It seems to lie beyond
human comprehension.</p><p>I'm here to show you that you can get it. It's just a number of steps, after
all. They are put together amazingly tight, like a rocket engine. But when you
zoom in on each part alone, you'll see it boils down to familiar concepts. No
maths beyond 6th grade, I promise!</p><p>At a high-level, the code code takes these steps:</p><ol><li>Detect whether the number is negative (i.e., the first character is <code>-</code>)</li><li>Zero out the sign character, if any</li><li>Find where is the decimal dot</li><li>Shift the contents so that the digits align with the template <code>XY.Z</code> placed
over the bits of the <code>long</code> value</li><li>Transform the ASCII characters to their digit values</li><li>Multiply each digit by its weight (1x, 10x, 100x), and add them all up</li><li>Apply the sign</li></ol><p>When you break it down into steps like this, it sounds less magical right away.
These are the reasonable steps to take. But the really interesting bits come
when you try to do them with nothing but ALU operations.</p><h3>1. Detect the minus sign<a href="#1-detect-the-minus-sign" title="Direct link to heading">#</a></h3><p>This code detects the minus sign:</p><p>Let me reverse the order of negation (<code>~</code>) and shifting, to make the explanation
easier, like this:</p><p>The result is that <code>broadcastSign</code> contains either all zeros, or all ones. In
other words, it has the sign bit broadcast across the entire <code>long</code> word. How
does it work? It relies on the special property of the ASCII code for the minus
sign. Its bit number 4 is zero, as opposed to all the digits, where it's one.</p><p>To better explain it, let's use some visuals. I'll print the CSV input
characters reflected right-to-left, to help you remember they're stored in
little-endian order. Here's a temperature reading of -10.8 ℃, with the bit
number 4 emphasized in each character:</p><figure><div><p><img alt="Image shows the little-endian order of ASCII bytes that spell out -10.8. Bit number 4 in each byte is marked with a red rectangle." src="https://questdb.io/img/blog/2024-03-07/input-word-1.webp" loading="lazy"></p><figcaption>Bit structure of the input word -10.8</figcaption></div></figure><p>So, what happens when we perform the bitwise ops as the code says? We'll start
with the full <code>long</code> word just like in the picture, with the three missing bytes
added on the left:</p><p><code>00000000 00000000 00000000 00111000 00101110 00110000 00110001 00101101</code></p><p>Then shift it left by 59:</p><p><code>inputData &lt;&lt; 59</code> =</p><p><code>01101000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</code></p><p>Our special bit that tells the difference between a digit and the minus sign is
now all the way to the left. Let us apply the negation now, flipping all the
bits:</p><p><code>~(inputData &lt;&lt; 59)</code> =</p><p><code>10010111 11111111 11111111 11111111 11111111 11111111 11111111 11111111</code></p><p>Now the leftmost bit is <code>1</code> when the first character is a minus sign, and <code>0</code>
when it's not a minus sign.</p><p>Next, we make an <em>arithmetic</em> shift right by 63. This means that the leftmost
bit, as it moves to the right, leaves a "trail" of itself:</p><p><code>broadcastSign = ( ~(inputData &lt;&lt; 59) ) &gt;&gt; 63</code> =</p><p><code>11111111 11111111 11111111 11111111 11111111 11111111 11111111 11111111</code></p><p>We end up with the whole long word full of that leftmost bit! If it was 0, the
whole word would be zero.</p><p>So that's our <code>broadcastSign</code>. It is all ones if there's a minus sign, and all
zeros if there's no minus sign. Our example has the minus sign, and therefore
it's all ones.</p><h3>2. Zero out the sign character<a href="#2-zero-out-the-sign-character" title="Direct link to heading">#</a></h3><p>Now that we've dealt with the minus sign and stored its information in a
variable, we want to get rid of it from the input data. This will make the input
data more uniform, and we'll then only deal with the absolute value of the
temperature.</p><p>It's very easy to zero out the lowest byte in a <code>long</code> number. To do so, just
apply the AND mask that has ones all over it, except for the lowest 8 bits. But,
the challenge is that this lowest byte may be either a minus sign or a digit,
and we must definitely keep the digit intact.</p><p>So, we'll construct the AND mask by relying on the <code>broadcastSign</code> variable to
guide the calculation towards either all ones (such a mask leaves everything as
it was), or the lowest 8 bits set to zero:</p><p>Let's zoom in on the steps now.</p><p><code>broadcastSign</code> =</p><p><code>11111111 11111111 11111111 11111111 11111111 11111111 11111111 11111111</code></p><p><code>0xFF</code> =</p><p><code>00000000 00000000 00000000 00000000 00000000 00000000 00000000 11111111</code></p><p><code>broadcastSign &amp; 0xFF</code> =</p><p><code>00000000 00000000 00000000 00000000 00000000 00000000 00000000 11111111</code></p><p>Then we flip all the bits (<code>~</code>), so</p><p><code>maskToRemoveSign = ~(broadcastSign &amp; 0xFF)</code> =</p><p><code>11111111 11111111 11111111 11111111 11111111 11111111 11111111 00000000</code></p><p>This is the case where the minus sign is present. Otherwise, we'd have all zeros
in <code>broadcastSign</code>, resulting in all ones in the mask. We got exactly what we
wanted.</p><p>Now we apply this to <code>inputData</code>, with another AND operation:</p><p>The minus sign is now gone from our <code>inputWord</code>. But if there was a digit
instead of the minus sign, it would still be there, untouched.</p><h3>3. Find where is the decimal dot<a href="#3-find-where-is-the-decimal-dot" title="Direct link to heading">#</a></h3><p>We'll find the dot with this statement:</p><p>You may have noticed that the dot character <code>.</code> has the same distinguishing
property as the minus character: its bit 4 is zero. We'll use that property once
again to locate the dot character in the input word. This time we'll apply an
AND mask that has 1 at bit 4 of each of the three possible bytes where the dot
may appear:</p><p>Or, in more condensed hexadecimal notation:</p><p>Now, since the distinguishing bit is 0 in the dot character, we'll use the
negated input word, where this bit will be 1:</p><p>The result is all zero bits except bit number 4 in byte number 3, that is, bit
number 3 * 8 + 4 = 28. Now we apply <code>numberOfTrailingZeros</code> to that, and get
the number 28. So, for our example of -10.8 ℃, <code>int dotPos = 28</code>.</p><h3>4. Shift the contents to align to template<a href="#4-shift-the-contents-to-align-to-template" title="Direct link to heading">#</a></h3><p>Now that we have the position of the dot, we want to shift the contents of the
<code>inputWord</code> so that each byte has the same meaning, regardless of the original
input format. We want the word to fit into this template:</p><p><code>0 0 0 Z . Y X 0</code></p><p>where:</p><ul><li><code>X</code> is the tens digit</li><li><code>Y</code> is the ones digit</li><li><code>Z</code> is the decimal digit</li></ul><blockquote><p>NOTE: <code>0</code> represents a zero byte, not the ASCII character <code>"0"</code></p></blockquote><p>So far, our word could be in any of these layouts (remember we zeroed out the
minus):</p><p>And we'll use this line of code to align it:</p><p>For our Example 1, with -10.8 ℃, it's easy — the word is already aligned,
<code>dotPos = 28</code>, and so we shift by zero.</p><p>To see this line of code in action, let's use Example 2, a temperature reading
of -7.7 ℃:</p><figure><div><p><img alt="Image shows the little-endian order of ASCII bytes that spell out -7.7. Bit number 4 in each byte is marked with a red rectangle." src="https://questdb.io/img/blog/2024-03-07/input-word-2.webp" loading="lazy"></p><figcaption>Bit structure of the input word -7.7</figcaption></div></figure><p>After completing the steps that remove the minus sign, the bytes in the input
word will be like this:</p><p><code>0 0 0 0 7 . 7 0</code></p><p>Recall the calculation from the previous step: we apply a mask that ignores the
rightmost red rectangle, and isolates the bits in the other three rectangles.</p><p>So, it will detect that the 3rd byte from the right has a zero bit in the red
rectangle. That's bit number 2 * 8 + 4 = 20. Therefore, <code>dotPos = 20</code>, and
since we shift left by <code>28 - dotPos</code>, we'll shift by <code>28 - 20 = 8</code> — one byte to
the left.</p><p>The result will be this:</p><p><code>0 0 0 7 . 7 0 0</code></p><p>And here's our template once again:</p><p><code>0 0 0 Z . Y X 0</code></p><p><code>X</code> comes out as <code>0</code>, exactly as it should be. Our number -7.7 ℃ is equal to
-07.7 ℃ — the tens digit is indeed zero.</p><p>This step already feels a bit magical. With nothing but straight-through bit
manipulation, we managed to align all the different cases to the same fixed
template!</p><h3>5. Transform the ASCII characters to their digit values<a href="#5-transform-the-ascii-characters-to-their-digit-values" title="Direct link to heading">#</a></h3><blockquote><p>From this point on, we return to Example 1: -10.8 ℃.</p></blockquote><p>So far we've been a bit loose in our notation — we used <code>0</code> to represent the
zero-valued byte, but all the other digits represented ASCII characters. At this
point we have to clean this up, because we are after the numerical value of the
temperature.</p><p>It turns out that the designers of the ASCII table were very careful about this
and made it super-simple to go from the digit to the number! As we can see in
this excerpt:</p><p>So all we have to do is zero out the left hex digit (3), and we have the
numbers. Since a hex digit corresponds to exactly four bits, this will be easy.</p><p>Given our template, the ASCII_TO_DIGIT_MASK constant should now make sense:</p><p>There are <code>F</code>s under each of the three digits. Let's go back to our example 1,
-10.8 ℃, and set the value of <code>alignedToTemplate</code> against this mask (excuse my
one last misuse of <code>0</code> to mean both zero and ASCII <code>"0"</code>):</p><p>Matching this to our template, we can see that this exactly represents our
number 10.8.</p><h3>6. Multiply each digit with its weight, and add them all up<a href="#6-multiply-each-digit-with-its-weight-and-add-them-all-up" title="Direct link to heading">#</a></h3><p>And now, for the truly epic grand finale! We'll find a single integer that
multiplies our <code>digits</code> number, and somehow magically the temperature value will
materialize in the middle of the resulting integer!</p><p>To get there, we'll rely heavily on the fact that multiplication and addition
are linear operations, and can be decomposed into independent parts that combine
into the final result.</p><p>First, let's see how we could arrange a multiplier that would make the sum <code>X</code> +
<code>Y</code> + <code>Z</code> appear within the result. To do so, we'll evaluate a schematic
representation of our <code>digits</code> number. In this representation, each symbol
represents four bits, and <code>.</code> represents <code>0000</code>:</p><p>We can shift it left by 16 and 24 to align <code>X</code>, <code>Y</code>, and <code>Z</code> within the same bit
range:</p><p>Now we can sum up these three:</p><p>Here <code>W</code> stands for <code>X + Y + Z</code>, and is at most 5 bits wide because the sum of
three decimal digits is at most 27. Now we can shift this number to the right
and apply an AND mask to eliminate what we don't need:</p><p>Bam, out comes our sum!</p><p>Now, we could do exactly as described: use two more variables to hold the two
shifted numbers, and then sum them up. However, there's a much simpler and
cleaner way to represent this. We just need to remember how multiplication
works. It's nothing but a sequence of shift-left and add operations! Like this:</p><p>So, what is the factor that will do all of our calculation in one go? We simply
need a binary number with all zeros except at positions 0 (no shift), 16, and
24:</p><p>Or, in the more condensed HEX representation,</p><p>Now we can perform that single multiplication, and get exactly the same effect
as we showed above:</p><p>This is pretty awesome, but… We don't actually need <code>X</code> + <code>Y</code> + <code>Z</code>, we just
used that for practice. We need <code>100 * X</code> + <code>10 * Y</code> + <code>Z</code>!</p><p>This is where things get <em>really</em> tense. We got assured that our <code>WW</code> part of
the result is at most 5 bits wide, representing 27. But, with our actual
calculation, this can be a number up to 999, a <em>ten</em>-digit number in binary! And
those two <code>WW</code> are right next to <code>Y</code> on the left. Apparently we have room for
only 8 bits. Will their bits get mixed together, spoiling our result?</p><p>We have to look at this very carefully. Let's use our schematic again, but now
we'll add the decimal multipliers <code>100</code> and <code>10</code> in the right places:</p><p>We can see that the first two rows give us no trouble.</p><ul><li>In the first row, <code>Z</code> is well isolated from the others.</li><li>In the second row, <code>X</code> is tightly below <code>Y</code>, but that row is only multiplied
by 10, with the maximum value of 90, occupying 7 bits.</li><li>In the third row, however, we have <code>X * 100</code>, ten bits wide, enroaching on the
bit positions of <code>Y</code>. Here, it seems that the scheme may break.</li></ul><p>But then, almost as a <em>deus ex machina</em>, we realize that <code>Y</code> is also multiplied
by <code>100</code>, which breaks down into <code>4 * 25</code> — that 4 in there is a round binary
number <code>100</code>.</p><p>Just like multiplying by <strong>decimal</strong> <code>100</code> results in a <strong>decimal</strong> number
ending in two zeros, so does multiplying by <strong>binary</strong> <code>100</code> result in a
<strong>binary</strong> number ending with two zeros. The rightmost two bits of <code>Y * 100</code>
will therefore be zero, and that is <em>exactly</em> the two bits that we need to fit
<code>X * 100</code>!</p><p>So we escape by a split hair and get a clean sum of all three rows in the bit
range <code>41..32</code>. As merykitty commented, <code>// That was close :)</code></p><p>Let's wrap up this step with the complete formula:</p><p><code>0x3FF</code> is a number with ten ones in binary form, isolating our ten-bit-wide
result.</p><h3>7. Apply the sign<a href="#7-apply-the-sign" title="Direct link to heading">#</a></h3><p>After all the fireworks in the previous step, this step is kind of an
anticlimax. And yet, even here we find ingenious tricks.</p><p>So far, we have the absolute value of the temperature (multiplied by 10 so that
it's an integer), and, in a separate variable, we have the information whether
there is a minus sign. This is encoded in the variable <code>broadcastSign</code> as 0 for
"no minus", and -1 for "yes minus".</p><p>How do you put the sign on the absolute value, without using an <code>if</code>? If the "no
minus" case was encoded as 1, it would be a trivial multiplication. But, that's
just wishful thinking, we have what we have. We're so close, is there anything
else we can use? One last magic trick?</p><p>Yes, there is a trick! It's a very well-known, basic concept, but coming to
realize it's the right thing in this moment was a touch of genius.</p><p>There's a good chance you already know how signed integers work in programming
languages. We don't just slap on a sign bit to signal a negative number. We use
the two's complement formula:</p><p><code>-n = NOT(n) + 1</code></p><p>Now look and marvel how this formula serves us the solution on a silver platter.
We need one of these two things to happen:</p><ol><li><code>value = absValue</code> when there is no minus sign</li></ol><p>OR</p><ol start="2"><li><code>value = NOT(absValue) + 1</code> when there is a minus sign.</li></ol><p>We can call upon the <code>XOR</code> operation to act as switchable negation: <code>n XOR -1</code>
is <code>NOT(n)</code>, and <code>n XOR 0</code> is just <code>n</code>. Guess what, this is an exact match to
the value of <code>broadcastSign</code>! As for our optional <code>+ 1</code>, we can conveniently use
<code>-broadcastSign</code>. So, our formula is this:</p><p><code>temperature = (absValue ^ broadcastSign) - broadcastSign</code></p><p>And there it is, our temperature has materialized!</p><h3>8. Bonus: compute the end of the CSV row<a href="#8-bonus-compute-the-end-of-the-csv-row" title="Direct link to heading">#</a></h3><p>Now that we have the temperature, you may wonder why go on. In the broader 1BRC
solution, it was very important to also cheaply find out where the next CSV line
starts.</p><p>We calculate that by using the decimal dot as the anchor, because after it
there's always one decimal, followed by a newline. <code>dotPos</code>, as you recall, is
the number of bits, not bytes, so we divide it by 8 (shift right by 3, same
thing) and add three, in order to point out the first byte of the next CSV line:</p><p><code>nextLineStart = (dotPos &gt;&gt;&gt; 3) + 3</code></p><h2>Conclusion<a href="#conclusion" title="Direct link to heading">#</a></h2><p>While I can hope this blog post explained the mystery behind merykitty's magic
SWAR, the real mystery is how a single guy working alone could come up with all
this in just a few days of casually doing an online challenge with a T-shirt and
a coffee mug as a reward.</p><p>That is the kind of mystery you won't find a blog post explaining.</p><p>Take care!</p><div><p><a href="https://questdb.io/download/">Download QuestDB</a><span> Open source under Apache 2.0. Blazing fast ingest. SQL analytics. </span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Suicide PhD Candidate Huixiang Chen (2019) (131 pts)]]></title>
            <link>https://huixiangvoice.medium.com/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3</link>
            <guid>39649486</guid>
            <pubDate>Sat, 09 Mar 2024 04:57:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huixiangvoice.medium.com/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">https://huixiangvoice.medium.com/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3</a>, See on <a href="https://news.ycombinator.com/item?id=39649486">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><div><div><a rel="noopener follow" href="https://huixiangvoice.medium.com/?source=post_page-----236cd39f79d3--------------------------------"><div aria-hidden="false"><p><img alt="Huixiang Voice" src="https://miro.medium.com/v2/resize:fill:88:88/2*VAo28uyHI7zNBI3nN-xXEA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="6094">On June 13, 2019, just before the ISCA 2019 conference in Phoenix, a doctoral candidate, whose paper was supposed to be published at this conference, <a href="https://www.gainesville.com/news/20190614/body-of-chinese-student-found-in-campus-building" rel="noopener ugc nofollow" target="_blank">hanged himself in the campus building of the University of Florida</a>.</p><p id="89a0">As more and more information comes out, we find that there should be a lot of hidden stories behind his suicide. The most important one may be related to his struggle against academic misconduct.</p><p id="2f64">A suicide note was sent to his friends, lab colleges, and especially his mentor Doctor <a href="http://www.taoli.ece.ufl.edu/" rel="noopener ugc nofollow" target="_blank">Tao Li</a>, a tenured professor (with preeminence professorship) in the Department of Electrical and Computer Engineering, also the last author of the paper mentioned in Huixiang’s suicide note.</p><p id="1c80">The original version of the suicide note is in Chinese:</p></div><div><figure></figure><figure><figcaption>Huixiang Chen’s Suicide Note</figcaption></figure></div><div><p id="bfae">Here we translated it into English (This is not a certified legal translation):</p><blockquote><p id="b65e">Dear fellow colleagues:</p><p id="d3c0">If you get this message, that means I have already passed away.</p><p id="eb99">As you know, since last year December, I wrote an ISCA paper in a very short time and it was submitted and accepted very quickly. As all of you know the reason, it was owe to our professor Dr.Tao Li ’s networking. Among the six reviewers of my paper, four of them are friends of Tao Li. But this paper has very severe issues: the design doesn’t make any sense and the reviewers also pay no attention to it. The paper was accepted at no reason which can make anyone feel guilty in this case.</p><p id="dbae">After the deadline, crazy modifications of the paper were made and I started to make up for the missing experiments. During those experiments, I found that the phenomenon of the experiments and the design was different from what was claimed before, which made this paper doesn’t make any sense from title to characterization and to design. For example, It was claimed that this (the accelerator) is targeted for 3D CNN, which can maximize the performance by changing Diffy architecture to achieve the dynamic control of the temporal delta and spatial delta. But there are too many issues with this. First of all, the Diffy architecture has a serious problem of synchronization. If the width of the input feature is too narrow, the overhead of lane synchronization … . But it was assumed that the temporal dimension of 3D CNN (the maximum is generally 16 and it will decrease with layer) will expand with Diffy. Secondly, it can’t skip zero, because of the synchronization of lane and the incremental of spatial/temporal delta. So if I want to make a change the whole paper need to be rewrite. It is unrealistic to propose a totally new idea before the final version. After I communicated with Tao Li, it turned out that I have to fix the paper by myself. Until today I am still unable to patch up any of those issues. These issues are too obvious which can be easily caught by any experts of accelerator. I have no words to comment that Dr. Li acquiesced to the data which makes no sense.</p><p id="f282">Considering that this will have an impact on my career in the future and my reputation in the area of Computer Architecture, my future life will be worse than death and I will be totally in a dilemma. I considered all the cases, I really can’t work them around. In order to make up for the fault, I decide to suicide. I hope you can learn my lessons and don’t mess around things. We shall never claim too much in the paper before we can really achieve it. I hope this will make a change in this world.</p><p id="83ee">I hope you can keep simple and stay honest in this society. I will bless you in another world.</p><p id="24be">Best</p><p id="23c7">Huxiang</p></blockquote><p id="1ee8">After the tragedy, some dialogues between Huixiang Chen and his friends are exposed, which also shed some light on his struggling against academic misconduct and the intense relationship between him and Dr. Tao Li. (Translations here are not certified legal translation. To protect the information providers, we cover the content of their words.)</p></div><div><p id="adf7">Only a suicide note and several pieces of dialogues may not uncover all the truth. University of Florida and the ECE department should have an elaborate and responsible investigation on this event.</p></div></div></article></div>]]></description>
        </item>
    </channel>
</rss>