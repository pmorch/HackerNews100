<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 23 Nov 2024 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Understanding Google's Quantum Error Correction Breakthrough (109 pts)]]></title>
            <link>https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/</link>
            <guid>42215910</guid>
            <pubDate>Fri, 22 Nov 2024 17:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/">https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/</a>, See on <a href="https://news.ycombinator.com/item?id=42215910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine trying to balance thousands of spinning tops at the same time—each top representing a qubit, the fundamental building block of a quantum computer. Now imagine these tops are so sensitive that even a slight breeze, a tiny vibration, or a quick peek to see if they’re still spinning could make them wobble or fall. That’s the challenge of quantum computing: Qubits are incredibly fragile, and even the process of controlling or measuring them introduces errors.</p>
<p>This is where Quantum Error Correction (QEC) comes in. By combining multiple fragile physical qubits into a more robust logical qubit, QEC allows us to correct errors faster than they accumulate. The goal is to operate below a critical threshold—the point where adding more qubits reduces, rather than increases, errors. That’s precisely what <a href="https://arxiv.org/abs/2408.13687">Google Quantum AI has achieved with their recent breakthrough [1]</a>.</p>

<h2 aria-level="1"><strong>Google’s Breakthrough Achievement&nbsp;</strong></h2>
<p><span data-contrast="auto">To grasp the significance of Google’s result, let’s first understand what success in error correction looks like. In classical computers, error-resistant memory is achieved by duplicating bits to detect and correct errors. A method called majority voting is often used, where multiple copies of a bit are compared, and the majority value is taken as the correct bit. In quantum systems, physical qubits are combined to create logical qubits, where errors are corrected by monitoring correlations among qubits instead of directly observing the qubits themselves. It involves redundancy like majority voting, but does not rely on observation but rather entanglement. This indirect approach is crucial because directly measuring a qubit’s state would disrupt its quantum properties. Effective quantum error correction maintains the integrity of logical qubits, even when some physical qubits experience errors, making it essential for scalable quantum computing.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">However, this only works if the physical error rate is below a critical threshold. In fact, intuition says that increasing the number of physical qubits that make a logical qubit should allow for better error correction. In truth if each physical qubit is very error-prone, adding qubits makes errors accumulate faster than we can detect and correct them. In other words, quantum error correction works only if each qubit can operate below an error threshold even before any error correction. Having more physical qubits allows to increase the QEC code distance, which is a measure of a quantum code’s ability to detect and correct errors.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">By showing logical error decreased by a factor of 2.14 when increasing code distance from five to seven, Google has now demonstrated below-threshold operation using surface codes—a specific type of quantum error correction code.&nbsp; This reduction in errors (which is exponential with increasing code distance) is the smoking gun proving that their QEC strategy works. With this, Google could show that their logical qubit lasted more than twice as long as their best physical qubit, as shown in Figure 1, demonstrating that logical qubits didn’t just survive—they outperformed physical ones.</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16103"><p><img decoding="async" aria-describedby="caption-attachment-16103" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png" alt="An adapted plot showing logical qubit error rates versus code distance, highlighting exponential suppression of logical errors as the code distance increases." width="800" height="303" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-300x114.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-768x291.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724.png 1470w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20303'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-300x114.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-768x291.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724.png 1470w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png"></p><p id="caption-attachment-16103">Fig. 1 – An adapted plot showing logical qubit error rates versus code distance, highlighting exponential suppression of logical errors as the code distance increases. The figure illustrates the transition to below-threshold performance and the “beyond break-even” behavior achieved with distance-7 codes. (Adapted from [1] by Google Quantum AI, CC BY 4.0)</p></div>
<p><span data-contrast="auto" xml:lang="EN-US" lang="EN-US"><span>A distance-7 surface code on 101 qubits effectively doubled the logical qubit’s lifetime</span><span> (blue line in Figure 1c)</span><span> compared to uncorrected physical qubits</span><span> (green line in Figure 1c)</span><span>. This accomplishment </span><span>demonstrates</span><span> that error-corrected qubits can preserve coherence </span><span>for longer periods, which is crucial for running extended quantum algorithms and computations. </span></span><span data-ccp-props="{}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">A Control Engineering Perspective: How Google Made It Work. </span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">The experiment wasn’t just a test of surface codes—it was a carefully orchestrated feat of engineering and control. The control system had to deliver flawless precision on multiple fronts—synchronization, frequency control, measurement fidelity, real-time decoding, and stability—over many hours of operation. Let’s stop for a second to talk about some of these interesting challenges.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">At the heart of the system was </span><b><span data-contrast="auto">real-time synchronization</span></b><span data-contrast="auto">. Every correction cycle had to complete within 1.1 µs—a narrow window in which the qubits were measured. The precision of this synchronization was critical to preventing errors from accumulating and destabilizing the computation. Achieving this required precise coordination of control signals across the qubit array, ensuring that every gate operation, measurement, was perfectly aligned.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">One of the most important components was </span><b><span data-contrast="auto">real-time decoding</span></b><span data-contrast="auto">. Decoding refers to the process of analyzing measurement data to determine where and how errors have occurred. To use logical qubits to perform universal quantum computation, certain gates called non-Clifford gates must be applied. Applying these gates, required correcting errors in real-time based on the real-time decoding. In Google’s system, the real-time decoder maintained a constant latency of about 63 µs while operating over one million correction cycles. Namely, the real-time error correction pipeline could process the measurements fast enough to avoid congestion. This rapid decoding process was essential, as any delay could allow errors to propagate and accumulate, potentially destabilizing the logical qubits. </span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">The experiment also demanded </span><b><span data-contrast="auto">high-fidelity gate operations</span></b><span data-contrast="auto">. Errors in qubit gates could easily propagate through the system, jeopardizing the stability of the logical qubit. Google achieved single-qubit gate errors below 0.1% and two-qubit CZ gate errors around 0.3%—thresholds essential to keeping logical qubits stable over time. For this goal, high performance of the control electronics is paramount, as fidelity can directly be impaired by errors of control pulses. These fidelities are especially critical when scaling surface codes, where even minor gate errors could degrade the effectiveness of error correction.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">As quantum computers scale to more qubits and longer computations, these and more control requirements will only grow more demanding, making the development of advanced control hardware essential for the future of fault-tolerant quantum computing.&nbsp;</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Out of the requirements above, real-time decoding, in particular, is fundamental for any scalable quantum computing system, as it provides the rapid response required to keep quantum information stable.</span><span data-ccp-props="{}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">A deeper dive into real-time decoding&nbsp;</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Google’s work highlights that the feasibility of the decoding depends on the decoder latency and throughput, as one of the most important pieces for running QEC below threshold.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Decoding is a classical compute task, and it can be done effectively on various classical architectures, such as FPGAs or GPUs. However, there is usually a trade-off between computational resources. FPGAs for example, are limited in computing power, but operate deterministically and in strict timing, making them suitable to manage the qubit control and measurement tasks as well as perform dedicated classical computations with low latency. On the other hand, CPUs or GPUs might have increased latency but enable far more advanced and larger computation. At Quantum Machines, </span><a href="https://www.quantum-machines.co/blog/quantum-machines-announces-deep-quantum-classical-integration-to-power-quantum-accelerated-supercomputers-with-nvidia/"><span data-contrast="none">we partnered with NVIDIA</span></a><span data-contrast="auto"> to deliver a unique platform, called DGX Quantum, that provides a unique combination of ultra-low controller-decoder latency, high-performance computational power, and flexible SW programmability. Our platform, which includes a less than 4 µs communication between our controller, OPX1000 and the CPU/GPU, allows to easily program and execute QEC workflows, including real-time decoding such as Google’s decoding. The SW programmability allows iterating over the decoding algorithm and scheme very quickly. A feature we believe is key for faster progress towards scalable and effective QEC. The truth is that a lot more experimentation and benchmarking is needed to learn what decoders to use, which classical resources optimize performance and meet requirements and how to design systems that can eventually run QEC on a much larger scale. What we know so far is that the latency of decoders should be less than 10 µs for QEC schemes to converge. </span><a href="https://qm.quantum-machines.co/factoring21"><span data-contrast="none">Watch our CEO Itamar Sivan explaining this further</span></a><span data-contrast="auto"> with the example of Shor’s algorithm for factorizing the number 21. </span><span><br>
</span><span><br>
</span><span data-contrast="auto">DGX-quantum is already live, showcasing less than 4 µs round-trip latency between controller and GPU. To learn more, <a href="https://www.quantum-machines.co/resources/tutorials/tightly-integrating-gpus-and-qpus-for-quantum-error-correction-and-optimal-control-part-1/">watch the IEEE QCE 2024 tutorial below</a>, on DGX-quantum, co-authored by QM and NVIDIA.</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16105"><p><a href="https://www.quantum-machines.co/resources/tutorials/tightly-integrating-gpus-and-qpus-for-quantum-error-correction-and-optimal-control-part-1/"><img decoding="async" aria-describedby="caption-attachment-16105" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png" alt="Video tutorial: Tightly integrating GPUs and QPUs for Quantum Error Correction and Optimal Control." width="800" height="440" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-300x165.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-768x422.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1536x844.png 1536w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-2048x1126.png 2048w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20440'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-300x165.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-768x422.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1536x844.png 1536w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-2048x1126.png 2048w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png"></a></p><p id="caption-attachment-16105">Video tutorial: Tightly integrating GPUs and QPUs for Quantum Error Correction and Optimal Control.</p></div>

<h2 aria-level="1"><span data-contrast="none">So, what’s next?&nbsp;</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Google’s demonstration of below-threshold quantum error correction marks a milestone towards fault-tolerant quantum computing. By demonstrating that logical qubits can outperform physical qubits and showing that errors can be corrected faster than they accumulate, they’ve paved the way for scalable quantum processors.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">However, this is just the beginning. In the future, to perform universal quantum computation with error corrected logical qubits, the full feedback loop must be closed, meaning that the control system needs to make decisions in real-time based on the decoder computation. Future developments will require faster decoders, better error mitigation strategies, automated calibrations embedded within&nbsp;quantum programs to stabilize parameters, and control hardware that tightly integrates and manages classical and quantum workflows.&nbsp;</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Google’s achievement signifies a substantial step toward fault-tolerant quantum computing. By demonstrating that logical error rates can be exponentially suppressed through the use of surface codes, the work provides a scalable and practical pathway to reliable quantum computing. As code distance increases, errors decrease at a rapid rate, setting the stage for quantum processors capable of handling complex operations with higher fidelity. Furthermore, this implementation of&nbsp;fast&nbsp;decoding represents a fundamental advancement in QEC. This technique allows for correction of errors faster than their propagation, minimizing the chance for errors to propagate through the quantum system.</span><span data-ccp-props="{&quot;134233117&quot;:false,&quot;134233118&quot;:false,&quot;201341983&quot;:0,&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559685&quot;:0,&quot;335559737&quot;:0,&quot;335559738&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">Quantum Error Correction and the Vision for Fault Tolerance</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Real-time, low-latency feedback loops are going to be an essential element of future fault tolerant quantum devices, to ensure that errors are corrected faster than they accumulate. This principle resonates across the broader quantum computing community, where rapid and robust control mechanisms are viewed as the key to achieving large-scale, reliable quantum operations.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">By focusing on low-latency, high-fidelity feedback and decoding, the broader quantum technology field is advancing toward the shared goal of fault-tolerant quantum computing, just as Google’s milestone achievement shows. The evolution of quantum control systems that support agile error correction and real-time adaptability will continue to play a central role in the pursuit of stable, scalable quantum computing systems that can be deployed in practical applications. And with DGX-quantum, we are just starting this exciting journey, so stay tuned for what’s to come! </span><span data-contrast="auto">​</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16104"><p><img decoding="async" aria-describedby="caption-attachment-16104" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png" alt="The DGX-Quantum solution, co-developed by NVIDIA and Quantum Machines, enables quantum error correction (QEC), calibration, and fast retuning for large-scale quantum computers. It leverages classical resources (GPUs and CPUs) for quantum computing, with ultra-fast data round-trip delays of under 4 microseconds." width="800" height="306" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png 602w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1-300x115.png 300w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20306'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png 602w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1-300x115.png 300w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png"></p><p id="caption-attachment-16104">The DGX Quantum solution, co-developed by NVIDIA and Quantum Machines, enables quantum error correction, calibration, and fast retuning for large-scale quantum computers. It allows the use of robust classical resources (GPUs and CPUs) for quantum computer operation, with ultra-fast data round-trip delays of under 4 µs.</p></div>

<h2><strong>Reference</strong></h2>
<p>[1] Acharya, Rajeev, et al. <a href="https://arxiv.org/abs/2408.13687">“Quantum error correction below the surface code threshold.” arXiv preprint arXiv:2408.13687</a> (2024).</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phased Array Microphone (2023) (386 pts)]]></title>
            <link>https://benwang.dev/2023/02/26/Phased-Array-Microphone.html</link>
            <guid>42215552</guid>
            <pubDate>Fri, 22 Nov 2024 17:10:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benwang.dev/2023/02/26/Phased-Array-Microphone.html">https://benwang.dev/2023/02/26/Phased-Array-Microphone.html</a>, See on <a href="https://news.ycombinator.com/item?id=42215552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article>

  

  <div>
    <p>A 192-channel phased array microphone, with FPGA data acquisition and beamforming/visualization on the GPU.
Phased arrays allow for applications not possible with traditional directional microphones, as the directionality
can be changed instantly, after the recording is made, or even be focused at hundreds of thousands of points 
simultaneously in real time.</p>

<p>All designs are open source:</p>

<ul>
  <li><a href="https://github.com/kingoflolz/mic_host">Host software</a></li>
  <li><a href="https://github.com/kingoflolz/mic_gateware">FPGA gateware</a></li>
  <li><a href="https://github.com/kingoflolz/mic_hardware">PCB layout and schematics, mechanical components</a></li>
</ul>

<p><img src="https://benwang.dev/assets/mic%20block%20diagram.png" alt=""></p>
<p> Block diagram </p>

<p><img src="https://benwang.dev/assets/mic%20overall.jpg" alt=""></p>
<p> Glamor shot </p>

<h2 id="hardware">Hardware</h2>

<p>To create a phased array microphone, a large number of microphones needs to be placed in an arrangement with
 a wide distribution of spacing. For a linear array, exponential spacing between microphones is found to be optimal for
 broadband signals. To create a 2d array, these symmetrical linear arrays (“arms”) are be placed radially, which allows
the central (“hub”) board to be compact. The total cost for the array is approximately $700.</p>

<h3 id="arms">Arms</h3>

<p>The length of each arm is dictated by the limits of PCB manufacturing and assembly. These boards were made at JLCPCB,
where the maximum length for manufacturing and assembly of 4 layer PCBs was 570mm.</p>

<p>The microphones chosen were the <a href="https://www.lcsc.com/product-detail/MEMS-Microphones_MEMS-MSM261D4030H1CPM_C966942.html">cheapest digital output MEMS microphone</a>
(because there are a lot of them!), which were about $0.5. At this bottom of the barrel price
range, there is little differentiation in the performance characteristics between different microphones. Most have 
decent performance up to 10khz and unspecified matching of phase delay and volume.</p>

<p>These microphones output data using pulse density modulation (PDM), which provides a one bit output at a frequency
significantly higher than the audible range (up to 4 MHz), with the high sampling rate compensating for quantization noise. 
These microphones also support latching the data either on the rising or falling edge of the clock (DDR), which allows
two microphones to be multiplexed on a single wire, reducing the amount of connections required.</p>

<p>Each arm contains 8 microphones sharing 4 output lines, as well as an output buffer on the clock input line.
This ensures the rise times are reasonable, even with hundreds of microphones sharing the same clock signal.</p>

<p>For some reason (likely the low rigidity of the panel and some suboptimal solder paste stencil patterns combined with 
the LGA microphone footprints), the yields on the arm PCBs are not very good, with only 50% of them working out of the 
box. The most common fault was the clock line being shorted to either 3V3 or ground, which unfortunately requires trial
and error of removing microphones from the PCB until the short is resolved. Next time some series resistors on the
clock line would speed this process up a lot, and improving the panelization and paste stencil would likely 
improve yields so extensive rework isn’t required.</p>

<p>Even with rework, there are still some microphones which produce bogus data. These are just masked out in the code, as
there are enough working ones to make up for it (and it’s too much work to remove a bunch of arms to do more rework…)</p>

<p><img src="https://benwang.dev/assets/mic%20arm%20panel.png" alt=""></p>

<h3 id="hub">Hub</h3>

<p>An FPGA is used to collect all the data, due to the large number of low latency IOs available combined with the ability 
to communicate using high speed interfaces (e.g. Gigabit Ethernet). Specifically, the <a href="https://www.colorlight-led.com/product/colorlight-i5-led-display-receiver-card.html">Colorlight i5</a>
card is used, as it has enough IOs, is cheap and readily available, and has two integrated ethernet PHYs 
(only one is used for this project). The card is originally designed as an ethernet interface for LED panels, but has 
been <a href="https://github.com/wuxx/Colorlight-FPGA-Projects">fully reverse engineered</a>. About 100 GPIOs are broken out over 
the DDR2 connector, which is much easier to fan out than the BGA of the original FPGA.</p>

<p><img src="https://benwang.dev/assets/mic%20hub%20board.png" alt=""></p>

<p>Other than the FPGA, the hub contains some simple power management circuitry, and connectors for the arm boards as well
as an Ethernet connector with integrated magnetics.</p>

<h3 id="mechanical-design">Mechanical Design</h3>

<p>The arms are attached with M3 screws to the hub using <a href="https://www.lcsc.com/product-detail/Nuts_Sinhoo-SMTSO3080CTJ_C2916369.html">PCB mounted standoffs/nuts</a> 
, which conveniently can be assembled with SMD processes. The connections from each arm to the hub is made with 8 pin,
2mm pitch connectors.</p>

<p><img src="https://benwang.dev/assets/mic%20hub%20attachment.png" alt=""></p>

<p>The original mechanical design consists of slots on the arm PCBs which interlock with circumferential structural PCBs,
however the low torsional rigidity of the arms means the whole structure deformed too easily.</p>

<p><img src="https://benwang.dev/assets/mic%20structural%20pcb.png" alt=""></p>

<p>The final mechanical design consists of pieces of laser cut 1/4th inch MDF around the outer edge of the array, with each
arm attached to the MDF with some zip ties.</p>

<p><img src="https://benwang.dev/assets/mic%20arm%20attachment.jpg" alt=""></p>

<p>As the microphone array is mounted on the wall (which is very susceptible to reflections), a layer of acoustic foam is
used to attenuate the reflections to make calibration easier.</p>

<h2 id="gateware">Gateware</h2>

<p>The main objective for the gateware is to reliably transmit the raw acquired data losslessly to the computer for 
further processing, while keeping it as simple as possible. Performing decimation and filtering on the
FPGA would reduce the data rate, but sending the raw PDM data is achievable with Gigabit Ethernet. This
reduces the complexity of the FPGA code and allowing faster iteration. Compiling is much faster than place and route,
and it’s much easier to use a debugger in code than in gateware!</p>

<p>There are three major components to the gateware, a module for interfacing with the PDM interfaces, a module for 
creating fixed size packets from those readings, and a UDP streamer to write the packets to the Ethernet interface.</p>

<h3 id="pdm-interface">PDM Interface</h3>

<p>The PDM input module is a relatively simple piece of logic, which divides the 50 MHz system clock by a factor of 16 to 
output a 3.125MHz PDM clock, latches all 96 of the input pins after each clock edge, and then shifts out 32 bits of the 
data on each clock cycle. Each chunk of 192 bits is has a header added which is a 32 bit incrementing integer.</p>

<p>The PDM interface receives data at a rate of 3.125Mhz * 96 (input pins) * 2 (DDR), which is 600Mbps. With the header,
the data rate output from this module is 700Mbps, or approximately 40% utilization of the 32 bit output data path.</p>

<h3 id="packetizer">Packetizer</h3>

<p>The packetizer is essentially a FIFO buffer with a special interface on the input. A standard FIFO marks the output as available
whenever there is at least one item in the queue, but this would lead to smaller packets than requested as the ethernet
interface operates faster than the PDM output (leading to buffer underruns).
Thus, the packetizer waits until there is at least a full packet worth of 
data in the queue before starting a packet, which ensures constant sized packets.</p>

<p>48 PDM output blocks at 224 bits (192 bits of data with a 32 bit header) are placed into each packet, which totals
1344 bytes of data per packet, plus a 20 byte IPv4 header and an 8 byte UDP header, at a rate of approximately 65k pps.</p>

<p>This leads to a wire rate of 715 Mbps, or about 70% utilization of Gigabit Ethernet.</p>

<h3 id="udp-streamer">UDP Streamer</h3>

<p>The LiteEth project made this module very easy, as it abstracts out the lower level complexities of UDP and IP 
encapsulation, ARP tables and the like, and provides a convenient interface for simply hooking up a FIFO to a UDP 
stream. Occasionally there is some latency, but there is enough slack in the bus and buffer in the
packetizer FIFO to absorb any hiccups.</p>

<h3 id="utilization-and-timing">Utilization and Timing</h3>

<p>The FPGA on the Colorlight i5 is a <code>LFE5U-25F-6BG381C</code>, which has 25k LUTs. The design is 
placed and routed with the open source Project Trellis toolchain. By keeping the gateware very simple, 
the utilization on the device is quite low, and there is lots of room for additional functionality.</p>

<div><pre><code>Info: Device utilisation:
Info:                 DP16KD:    16/   56    28%
Info:                EHXPLLL:     1/    2    50%
Info:             TRELLIS_FF:  1950/24288     8%
Info:           TRELLIS_COMB:  3701/24288    15%
Info:           TRELLIS_RAMW:    49/ 3036     1%

Info: Max frequency for clock                   '$glbnet$crg_clkout': 73.17 MHz (PASS at 50.00 MHz)
Warning: Max frequency for clock '$glbnet$eth_clocks1_rx$TRELLIS_IO_IN': 124.07 MHz (FAIL at 125.00 MHz)
</code></pre></div>

<p>(Timing violations on eth rx clock is due to <a href="https://github.com/litex-hub/litex-boards/issues/40#issuecomment-1108817182">false positive from gray counter in liteeth</a>)</p>

<h2 id="software">Software</h2>

<h3 id="cic-filter">CIC Filter</h3>

<p>Each microphone produces a 1 bit signal at 3.125Mhz, and needs to be reduced to a more reasonable sample rate
and bit depth for further
processing. This is done very efficiently with a CIC filter, which only requires a few arithmetic operations to 
process each sample. For understanding more about CIC filters, <a href="https://tomverbeure.github.io/2020/09/30/Moving-Average-and-CIC-Filters.html">this series</a>
of blog posts from Tom Verbeure provides an excellent introduction. Following the nice graphs from there, 
I decided on a 4 stage, 16x decimation CIC filter which reduced the sample rate to a much reasonable 195kHz, at 32 bits.</p>

<p>To ingest the data at 3.125Mhz, the filter must be able to process each set of samples in 320ns. A naive implementation
in Rust wasn’t fast enough on a single core, but an implementation with some less abstraction (and a hence some more 
autovectorization) got there, and is what was used at the end. I also experimented with a version using SIMD 
intrinsics which was much faster, but ended up running into alignment issues when using it in together with other code.</p>

<p>Even with close to a billion bits per second of data to process, a single CPU core can do quite a few operations on 
each individual bit!</p>

<div><pre><code>test cic::bench_cic       ... bench: 574 ns/iter (+/- 79) = 41 MB/s
test cic::bench_fast_cic  ... bench: 181 ns/iter (+/- 24) = 132 MB/s
test cic::bench_simd_cic  ... bench:  36 ns/iter (+/- 0)  = 666 MB/s
</code></pre></div>

<h3 id="calibration">Calibration</h3>

<p>To perform array calibration, a speaker playing white noise is moved around the room in front of the array. An FFT based
cross correlation is performed between all pairs of microphones to compute relative delays.</p>

<p>A cross correlation can be
performed by computing the FFT of both signals (cached and computed once for each signal), and then computing the 
inverse FFT of the complex multiplication of the two. This is quite compute intensive, as there are over 18 thousand
pairs! For the window sizes used of 16-64k, the FFTs are memory bound, and thus the IFFT and peak finding is fused to
avoid writing the results to memory, which results in a 15x speedup. On a 7950X, this process runs in realtime.</p>

<p>Then the positions of the source at each timestep 
and the positions of each microphone is optimized using gradient descent (when you know PyTorch, all optimization 
problems look like gradient descent…). The loss function tries to minimize the difference between the measured
correlations and the ideal correlations, while trying to minimize the deviation of the microphone positions from
the initial positions as well as the jerk of the source trajectory.</p>

<p>As part of the calibration, the speed of sound is also a parameter which is optimized to obtain the best model of the
system, which allows this whole procedure to act as a ridiculously overengineered thermometer.</p>

<p>After a few hundred iterations, it converges to a reasonable solution for both
the source positions and the microphone positions, as well as constants such as the speed of sound. Fortunately this
problem vectorizes well for GPU, and converges in a few seconds.</p>

<p>The final mean position error is on the order of 1mm, and is able to correct for large scale systematic distortions
such as concavity from the lack of structural rigidity. The largest position error between the calibrated positions
and the designed positions is on the order of 5mm, which is enough to introduce significant phase errors to high 
frequency sound if uncorrected, although perhaps not strictly necessary (10khz sound has a wavelength of ~3.4cm).</p>

<p><img src="https://benwang.dev/assets/mic%20calibration.png" alt=""></p>

<h3 id="beamforming">Beamforming</h3>

<p>Beamforming is how the raw microphone inputs are processed to produce directional responses. The simplest method of
beamforming is delay-and-sum (DAS), where each signal is delayed according to its distance from the source. This is 
the type of beamforming implemented for this process, with the beamforming happening in the frequency domain.</p>

<p>In the frequency domain, a delay can be implemented by the complex multiplication of the signal with a linear phase term
proportional to the delay required, which also nicely handles delays which are not integer multiples of the sampling 
period.</p>

<p>Multiple nested subarrays of the original array are used for different frequency ranges. This reduces the processing
required for beamforming, as each frequency does not need to be beamformed with all the microphone. This also ensures
that the beamforming gains of all the frequencies are matched.</p>

<p><img src="https://benwang.dev/assets/mic%20subarray.png" alt=""></p>

<p>Two different types of beamforming visualizations are implemented, a 3d near field beamformer and a 2d far field
beamformer. When the audio source is far away, the wavefront is essentially a flat plane, and how far away the
source is does not meaningfully change the signals at the array. On the other hand, if the source is close to the 
array, the wavefront will have a significant curvature which allows the 3d location of the source to be determined.</p>

<p>The beamformer is implemented as a <a href="https://github.com/openai/triton/">Triton kernel</a>, a Python DSL which compiles to 
run on Nvidia GPUs. When beamforming to hundreds of thousands of points, the massive parallelism provided
by GPUs allows for results to be produced in real time. Some <a href="https://github.com/openai/triton/issues/974">current limitations</a>
with the Triton language around 
support to indexing with shared memory arrays lead to slightly suboptimal performance, but writing CUDA C++ doesn’t 
seem very fun…</p>

<h4 id="near-field-3d-beamforming">Near Field 3D Beamforming</h4>

<p>Near field 3D beamforming is performed a 5cm voxel grid with size 64x64x64. An update rate of 12hz is achieved on a
RTX 4090 with higher update rates limited by overhead of suboptimal CPU-GPU synchronization with the smaller work units. 
The voxel grid is then visualized using <a href="https://vispy.org/">VisPy</a>,
a high performance data visualization library which uses OpenGL. Modern games have millions of polygons, so rendering
a quarter million semi-transparent voxels at interactive framerates is no issue.</p>

<p>A quick demo of the voxel visualization below, note the reflection off the roof!</p>

<video controls="">
<source src="https://benwang.dev/assets/mic%203d%20demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

<h4 id="far-field-2d-beamforming">Far Field 2D Beamforming</h4>

<p>Far field beamforming works similarly, but can be performed in higher resolution as there is no depth dimension
required. A 512x512 pixel grid is used, and the same 12hz update rate achieved. (The far field beamforming uses an 
approximation of just putting the points far away instead of actually assuming planar wavefront due to laziness…)</p>

<p>A demo of the 2d visualization here, but it’s not very exciting due to the poor acoustic environment of my room around 
the array, with lots of reflections and multipath.</p>

<video controls="">
<source src="https://benwang.dev/assets/mic%202d%20demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

<h4 id="directional-audio">Directional Audio</h4>

<p>The previous two beamforming implementations compute the energy of sound from each location, but never materializes
the beamformed audio in memory. A time domain delay and sum beamformer is implemented to allow for directional audio 
recording. It takes a 3D coordinate relative from array center and outputs audio samples. 
An interesting aspect about this beamformer is that it is differentiable with regard to the location from the output. 
This means the location of the audio sources can be optimized
based on some differentiable loss function (like neural network), which might allow for some interesting applications 
such as using a forced alignment model of a multi-party transcript to determine the physical location of each speaker.</p>

<p>A speaker playing some audio is placed in front of the array, with another speaker placed approximately 45 degrees away
at the same distance from array center, playing white noise. The effectiveness of the beamforming can be demonstrated
by comparing the raw audio from a single microphone with the output from the beamforming.</p>

<p>Raw audio from a single microphone:</p>

<p><audio controls="">
<source src="https://benwang.dev/assets/mic%20raw.wav" type="audio/wav">
Your browser does not support the video tag.
</audio></p><p>Beamformed audio:</p>

<p><audio controls="">
<source src="https://benwang.dev/assets/mic%20beamformed.wav" type="audio/wav">
Your browser does not support the video tag.
</audio></p><h3 id="recording">Recording</h3>

<p>As the data from the microphone array is just UDP packets, it can be recorded with tools like <code>tcpdump</code>, and the 
packet capture file can be read to reinject the packets back into the listener. All the programs in the
previous sections are designed to work at real time, but can also work on recorded data using this process.</p>

<p>The tradeoff with this recording implementation is that the output data rate is quite high (due to faithfully recording
everything, even the quantization noise). At 87.5 MBps, a 1-hour recording would be 315 GB! A more optimized
implementation would do some compression, and do the recording after the CIC filter at a lower sample rate.</p>

<h2 id="next-steps">Next Steps</h2>

<p>I consider this project essentially complete, and don’t plan to work on it any further for the foreseeable future, but
there are still lots of possible cool extensions if you’d like to build one!</p>
<ul>
  <li>Using more advanced beamforming algorithms (<a href="https://ntrs.nasa.gov/api/citations/20080015889/downloads/20080015889.pdf">DAMAS</a> etc.)</li>
  <li>Better GUI to combine all existing functions (e.g. See where sound is coming from, and record audio from there)</li>
  <li>Combine differentiable beamforming and neural models (e.g. forced alignment example mentioned above)</li>
</ul>

  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon to invest another $4B in Anthropic, OpenAI's biggest rival (500 pts)]]></title>
            <link>https://www.cnbc.com/2024/11/22/amazon-to-invest-another-4-billion-in-anthropic-openais-biggest-rival.html</link>
            <guid>42215126</guid>
            <pubDate>Fri, 22 Nov 2024 16:25:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/11/22/amazon-to-invest-another-4-billion-in-anthropic-openais-biggest-rival.html">https://www.cnbc.com/2024/11/22/amazon-to-invest-another-4-billion-in-anthropic-openais-biggest-rival.html</a>, See on <a href="https://news.ycombinator.com/item?id=42215126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ArticleBody-InlineImage-107408832" data-test="InlineImage"><p>Anadolu | Anadolu | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> on Friday announced it would invest an additional $4 billion in Anthropic, the artificial intelligence startup founded by ex-OpenAI research executives.</p><p>The new funding brings the tech giant's total investment to $8 billion, though Amazon will retain its position as a minority investor, according to Anthropic, the San Francisco-based company behind the Claude chatbot and AI model.</p><p>Amazon Web Services will also become Anthropic's "primary cloud and training partner," according to a blog post. From now on, Anthropic will use AWS Trainium and Inferentia chips&nbsp;to train and deploy its largest AI models.</p><p>Anthropic is the company behind Claude — one of the chatbots that, like OpenAI's ChatGPT and&nbsp;Google's Gemini, has exploded in popularity. Startups like Anthropic and OpenAI, alongside tech giants such as&nbsp;<a href="https://www.cnbc.com/quotes/GOOG/">Google</a>,&nbsp;<a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a>,&nbsp;<a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a>&nbsp;and&nbsp;<a href="https://www.cnbc.com/quotes/META/">Meta</a>, are all part of a generative AI arms race to ensure they don't fall behind in a market&nbsp;<a href="https://www.bloomberg.com/professional/insights/data/generative-ai-races-toward-1-3-trillion-in-revenue-by-2032/#:~:text=Generative%20AI%20is%20poised%20to,our%20proprietary%20market%2Dsizing%20model." target="_blank">predicted to top $1 trillion</a>&nbsp;in revenue within a decade. </p><p>Some, like Microsoft and Amazon, are <a href="https://www.cnbc.com/2024/03/30/fomo-drives-tech-heavyweights-to-invest-billions-in-generative-ai-.html">backing generative AI startups with hefty investments</a> as well as working on in-house generative AI.</p><p>The partnership announced Friday will also allow AWS customers "early access" to an Anthropic feature: the ability for an AWS customer to do fine-tuning with their own data on Anthropic's Claude. It's a unique benefit for AWS customers, according to a company blog post.</p><p>In March, Amazon's $2.75 billion investment in Anthropic was the company's largest outside investment in its three-decade history. The companies announced an&nbsp;<a href="https://www.cnbc.com/2023/09/25/amazon-to-invest-up-to-4-billion-in-anthropic-a-rival-to-chatgpt-developer-openai.html">initial $1.25 billion investment</a>&nbsp;in September 2023.</p><p>Amazon does not have a seat on Anthropic's board.</p><p>News of Amazon's additional investment comes one month after <a href="https://www.cnbc.com/2024/10/22/anthropic-announces-ai-agents-for-complex-tasks-racing-openai.html">Anthropic announced</a> a significant milestone for the company: AI agents that can use a computer to complete complex tasks like a human would.</p><p>Anthropic's new Computer Use capability, part of its two newest AI models, allows its tech to interpret what's on a computer screen, select buttons, enter text, navigate websites, and execute tasks through any software and real-time internet browsing.</p><p>The tool can "use computers in basically the same way that we do," Jared Kaplan, Anthropic's chief science officer, told CNBC in an interview last month, adding it can do tasks with "tens or even hundreds of steps."</p><p>Amazon had early access to the tool, Anthropic told CNBC at the time, and early customers and beta testers included Asana, Canva and Notion. The company had been working on the tool since early this year, according to Kaplan.</p><p>In September, Anthropic&nbsp;<a href="https://www.cnbc.com/2024/09/04/amazon-backed-anthropic-rolls-out-claude-enterprise-ai-for-big-business.html">rolled out Claude Enterprise</a>, its biggest new product since its chatbot's debut, designed for businesses looking to integrate Anthropic's AI. In&nbsp;<a href="https://www.cnbc.com/2024/06/20/anthropic-claude-3point5-sonnet-ai-announced.html">June</a>, the company debuted its more powerful AI model, Claude 3.5 Sonnet, and in May, it rolled out its&nbsp;<a href="https://www.cnbc.com/2024/05/01/anthropic-iphone-ai-app-business-plan-to-compete-with-openai-announced.html">"Team" plan for smaller businesses</a>.</p><p>Last year, Google&nbsp;<a href="https://www.cnbc.com/2023/10/27/google-commits-to-invest-2-billion-in-openai-competitor-anthropic.html">committed</a>&nbsp;to invest $2 billion in Anthropic, after previously confirming it had taken a 10% stake in the startup alongside a large cloud contract between the two companies.</p></div><div id="SpecialReportArticle-RelatedContent-1"><h2>Don’t miss these insights from CNBC PRO</h2><div><ul><li><a href="https://www.cnbc.com/2024/11/14/warren-buffetts-berkshire-hathaway-takes-a-stake-in-dominos-pizza.html">Warren Buffett's Berkshire Hathaway takes a stake in Domino's Pizza</a></li><li><a href="https://www.cnbc.com/2024/11/17/wall-street-gears-up-for-ma-boom-these-names-could-be-attractive-targets.html">Wall Street is gearing up for an M&amp;A boom under Trump. These companies could be targets</a></li><li><a href="https://www.cnbc.com/2024/11/13/inflation-report-shows-market-could-have-a-recipe-for-disaster-heading-into-new-year-says-economist.html">Inflation report shows market could have a 'recipe for disaster' heading into new year, says economist</a></li><li><a href="https://www.cnbc.com/2024/11/18/morningstar-strategist-picks-2-stocks-from-a-sector-he-is-betting-on.html">Morningstar names cheap stocks in a sector that ‘deserves a place in everybody’s portfolio’</a></li><li><a href="https://www.cnbc.com/2024/11/18/these-2-active-etfs-have-outperformed-the-sp-500-this-year-last-year-and-over-5-years.html">These 2 active ETFs have outperformed the S&amp;P 500 this year, last year and over 5 years</a><br></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Deceptively Asymmetric Unit Sphere (107 pts)]]></title>
            <link>https://www.tangramvision.com/blog/the-deceptively-asymmetric-unit-sphere</link>
            <guid>42214880</guid>
            <pubDate>Fri, 22 Nov 2024 16:00:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tangramvision.com/blog/the-deceptively-asymmetric-unit-sphere">https://www.tangramvision.com/blog/the-deceptively-asymmetric-unit-sphere</a>, See on <a href="https://news.ycombinator.com/item?id=42214880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Previously, we talked about [Pinhole Obsession](https://www.tangramvision.com/blog/camera-modeling-pinhole-obsession) and the downsides of assuming a default pinhole model. We presented an alternative formulation where rays are modeled on the unit sphere \\(\mathcal{S}^2\\) instead of the normalized image plane \\(\mathbb{T}^2\\).</p><p>We’ve also previously written posts about how many problems in robotics can be formulated as [an optimization](https://www.tangramvision.com/blog/introduction-to-optimization-theory). At a high level, many continuous optimization algorithms perform the following steps</p><p>- Compute a quantity to minimize — error, misalignment, risk, loss, etc.<br>- Compute a direction along which the quantity is locally reduced<br>- Move the parameters in the quantity-reducing direction<br>- Repeat until the problem converges</p><p>Many continuous optimization problems are modeled on [vector spaces](https://en.wikipedia.org/wiki/Vector_space) and “moving” the parameters is simply vector addition. However, our prescription of using the unit sphere to model rays is obviously **not** a linear space! Therefore, we must start our discussion by describing how to travel on the sphere.</p><p>## Traveling on the Sphere</p><p>Generally, when we *travel* we want to do so in the most efficient manner. Undoubtedly, you’ve heard the expression “get from point a to b,” perhaps also with the implication “as fast as possible.” Therefore, we’ll want to minimize the distance that we travel or equivalently travel along the shortest path. In Differential Geometry, we call these “shortest paths” *geodesics.*</p><p>An alternate way to view a *geodesic* is by starting at a point \\(p\\) on the manifold and traveling in the direction of some vector \\(v\\), carefully minimizing the distance at each increment. However, minimizing the distance at each step may mean we have to *change direction* along our shortest path.</p><p>“Changing direction” and “traveling in the shortest path” may seem to counter one another. After all, we all know that the shortest path between two points is a line. However, imagine we are flying in a plane starting at the equator and a heading of 45°. If our goal is to travel *as far as possible* from our starting point, how should we chart our course?</p><p>&gt;&nbsp;As usual, ignore air resistance, the jet stream and assume a spherical earth. This is a thought exercise, not pilot’s school.</p><p>A simple suggestion would be to maintain a heading of 45° during our travel, like we would locally: travel in a constant direction. However, if we maintain a fixed heading indefinitely, we will end up close to the north pole! The line traced by a path of constant heading is known as a [Rhumb Line](https://en.wikipedia.org/wiki/Rhumb_line) and, as pictured, is certainly not the shortest distance between two points on a sphere.</p><p>![Loxodrome.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f6319ebc7cd01b693200a_Loxodrome.png)<br>*PC: [https://en.wikipedia.org/wiki/Rhumb_line#/media/File:Loxodrome.png](https://en.wikipedia.org/wiki/Rhumb_line#/media/File:Loxodrome.png)*</p><p>Alternatively, to truly travel the *farthest distance,* we travel along the [great circle](https://en.wikipedia.org/wiki/Great-circle_distance) until the aircraft runs out of fuel. Here it’s more obvious that the geodesic’s heading is continuously changing. One implication of this is that if we start at one point along the geodesic with a vector \\(v\\), we may not end up in the same location as if we start at a different point along the geodesic with the same vector \\(v\\).</p><p>![Illustration_of_great-circle_distance.svg](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f8b9f2d9bfdd0a7e52425_Illustration_of_great-circle_distance.png)<br>*PC: [https://en.wikipedia.org/wiki/Great-circle_distance#/media/File:Illustration_of_great-circle_distance.svg](https://en.wikipedia.org/wiki/Great-circle_distance#/media/File:Illustration_of_great-circle_distance.svg)*</p><p>In Differential Geometry, the operator that traces the geodesic is known as “the exponential map.” For the reasons listed above, it’s defined as a local operator originating at a point \\(p\\) and traveling in a direction \\(v\\) i.e.</p><p>$$<br>\text{Exp}_p(v)<br>$$</p><p>Similarly, the operator that computes the direction and distance between two points on the manifold (the manifold’s logarithm) is defined as a local operator \\(\text{Log}_p(q)\\).</p><p>So to perform optimization on the unit sphere, we</p><p>- Compute the quantity to minimize — error, misalignment, risk, loss, etc.<br>- Compute a direction \\(v\\) along which the quantity can be locally reduced<br>- Move the parameters along the great circle using the exponential map \\(\text{Exp}_p(v)\\)<br>- Repeat until the problem converges</p><p>This begs the question: how do we compute this direction \\(v\\)? What does it really mean?</p><p>---</p><p>## The Briefest Introduction to Differential Geometry</p><p>&gt;&nbsp;⚠️ Many maths below! But they’re cool maths, we promise.</p><p>To explain what a direction \\(v\\) means on the sphere and to explain why working with \\(\mathcal{S}^2\\) is difficult, we have to briefly touch on one of my favorite subjects: [Differential Geometry](https://en.wikipedia.org/wiki/Differential_geometry). This post will dive deep into the motivations behind why we use differential geometry in computer vision, and what advantages it brings. Much of this may seem like a tangent (no pun intended), but don’t worry: we’ll bring it all back to our Pinhole Obsession and optimization at the end!</p><p>&gt;&nbsp;💡 Obviously, we cannot cover the entirety of Differential Geometry in one blog post. There are many great resources to learn Differential Geometry. Some of our favorites are:<br>&gt;&nbsp;- [Introduction to Smooth Manifolds](https://link.springer.com/book/10.1007/978-1-4419-9982-5)<br>&gt;&nbsp;- [A Micro Lie Theory for State Estimation in Robotics](https://arxiv.org/pdf/1812.01537)<br>&gt;&nbsp;- [Differential Geometry and Lie Groups](https://link.springer.com/book/10.1007/978-3-030-46040-2)</p><p>Historically, differential geometry arose from the study of “curves and surfaces.” As traditionally taught in multi-variable calculus, a curve is a mapping \\(\gamma: \mathbb{R} \to \mathbb{R}^3\\) and likewise, a surface is a mapping \\(\sigma: \mathbb{R}^2 \to \mathbb{R}^3\\).</p><p>Differential geometry generalizes these “curves and surfaces” to arbitrary dimensions. These generalized “curves and surfaces” are known as *smooth manifolds*. In this post, we’ll skip the rigorous definition of a smooth manifold and simply define it as</p><p>&gt; *Smooth Manifold:* An N-dimensional space without corners, edges or self-intersections.</p><p>This smoothness (called continuity) allows us to perform optimization “on the manifold” using our standard calculus techniques. We can compute errors and also compute the directions along which we can reduce those errors.</p><p>## Intrinsic vs Extrinsic Manifolds</p><p>To assist intuition, we’ve leaned on prior knowledge of multi-variable calculus of curves and surfaces. At the undergraduate level, curves and surfaces are presented as [embedded entities](https://en.wikipedia.org/wiki/Nash_embedding_theorems) living in a higher-dimensional ambient space e.g. 3D Euclidean Space. However, this ambient space isn’t *strictly* needed for the development of differential geometry. In their search for a minimal set of axioms, differential geometers have taken great care to remove this dependence on an ambient space; they describe *smooth manifolds* as objects existing in their own right. Thus, there are two ways of thinking about differential geometry:</p><p>- *Extrinsic*: manifolds as embedded objects in space<br>- *Intrinsic*: manifolds are entities in their own right</p><p>In this manner, the error-minimizing direction we are searching for can either be viewed as *extrinsic* (embedded in ambient space) or it can be viewed as *intrinsic* (living alongside the manifold).</p><p>As engineers, the decision to use the intrinsic view of a manifold vs. the extrinsic view mostly impacts representation and computation. Thus, for a specific manifold, we choose the representation that’s computationally easiest to work with. Although the remainder of this post only briefly touches on the representation of manifolds, it’s **always** necessary to determine what representation is being used. The decision of an intrinsic or extrinsic representation will change how computation is performed on the manifold. Regardless of the choice of *intrinsic* or *extrinsic* representation, we often “bundle” the representation of the manifold with the representation directions on that manifold.</p><p>&gt;&nbsp;⚠️ The concepts of *intrinsic* and *extrinsic* used in differential geometry are unrelated to intrinsics (interior orientation) and extrinsics (exterior orientation) of cameras. This is simply an unfortunate naming collision at the intersection of two fields.</p><p>## A Brief Tangent for Tangents</p><p>…which brings us to **the** key concept in differential geometry: the [Tangent Bundle](https://en.wikipedia.org/wiki/Tangent_bundle). The Tangent Bundle is the underlying manifold stitched together with the vector spaces that are tangent to the manifold at each point.</p><p>To illustrate this, consider the unit circle \\(\mathcal{S}^1\\) below. The blue circle represents the underlying manifold and the red lines represent the one dimensional tangent space at each point on the circle. Together, the points and tangent spaces form the tangent bundle. It is important to note that that vectors in one tangent space should be regarded as distinct and separate from vectors in another tangent space.</p><p>![Tangent_bundle.svg](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f63501b983d8e9953910b_image.png)<br>*PC: [https://commons.wikimedia.org/wiki/File:Tangent_bundle.svg](https://commons.wikimedia.org/wiki/File:Tangent_bundle.svg)*</p><p>Now that we have the correct picture in our heads, let’s visualize tangent vectors and the tangent bundle in more detail.</p><p>Consider an arbitrary manifold \\(M\\), and furthermore consider a curve on that manifold \\(\gamma: \mathbb{R} \to M\\). This curve \\(\gamma(t)\\) can be thought of “the location on the manifold at time \\(t\\).” Furthermore, let \\(\gamma(0)\\) be some point of interest \\(p \in M\\) on the manifold.</p><p>For visualization, consider this wavy circle manifold:</p><p>![GenericManifold_ManimCE_v0.18.1.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f636093b3a75b96cec282_GenericManifold_ManimCE_v0.18.1.png)</p><p>Now, consider the curve \\(\gamma(t)\\) living on this manifold.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GenericManifoldWithCurve.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GenericManifoldWithCurve.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>If we take the derivative of this curve, we obtain a pair \\((\gamma(t), \gamma'(t))\\), where the first entry describes the point along the curve and the second entry describes how the curve is changing in time. This can be visualized as a vector “riding along” the curve.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GenericManifoldWithCurveAndTangent.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GenericManifoldWithCurveAndTangent.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>The magnitude and sign of this vector can be changed by re-parametrizing the curve as</p><p>$$\gamma_{\alpha}(t) = \gamma(\alpha t)$$</p><p>Specifically, note that</p><p>$$\gamma'_\alpha(0) = \alpha \gamma'(0)$$</p><p>In this manner, we can “scale” curves in the same way that we would scale vectors. Similarly, we can derive addition, inverse and zero curves and form a “vector space of curves.”</p><p>Thus, we define the tangent space \\(T_pM\\) as the set of all curves that pass through a point of interest \\(p \in M\\). The tangent bundle of a manifold \\(TM\\) is the set of all tangent spaces combined under a *disjoint* union. In this context, a disjoint union simply means we cannot combine vectors in distinct tangent spaces. This is perhaps the most important takeaway: tangent vectors living in distinct tangent spaces cannot be added, combined or related without using some additional manifold structure.</p><p>&gt;&nbsp;⚠️ Here, we have *de facto* assumed that we can take the derivative of a curve on the manifold. This is made more rigorous in most differential geometry books by either using charts on the manifold or an extrinsic view of a manifold facilitated by an embedding. Furthermore, we didn’t really show how to “add curves.” We haven’t done anything *improper* with this explanation, but it certainly is lacking detail! You can refer to the previously mentioned resources to learn more about the mathematically precise definitions of the Tangent Bundle.</p><p>If this is your first time studying Differential Geometry, you may be very uncomfortable with the notion of a vector being *attached* in any way to a specific point. After all, vectors are commonly taught as being geometric entities that can be moved anywhere in space, e.g. vector addition is taught using the “head to tail” method. It’s unclear when presenting these geometric explanations if the vectors are “sitting on top of” the underlying manifold or if they are in their own “vector space.”</p><p>To see why this “head to tail” method breaks down on manifolds, imagine traveling 1000 miles north and then 1000 miles west. This will take you to a very different location than if you had traveled 1000 miles west and then 1000 miles north. In other words, vectors may point in different directions at different points on the manifold, so we can only really discuss what a vector means *locally*.</p><p>The representation we have presented here of \\((\gamma(0), \gamma'(0))\\) , is useful in describing the construction tangent vectors on a manifold and also useful in derivations of certain operators, but it is typically not used in computation. In “the real world,” we typically choose some canonical coordinates for the manifold and a basis for the associated tangent space and think of tangent vectors as \\((p, v) \in M \times \mathbb{R}^n\\).</p><p>With this understanding of tangent spaces, the exponential map can be understood more formally as an operator mapping vectors in a tangent space onto manifold.</p><p>$$<br>\text{Exp}_p(v): T_pM \to M<br>$$</p><p>Likewise, the logarithmic map can be understood as an operator mapping points on the manifold back into a tangent space</p><p>$$<br>\text{Log}_p(q): M \times M \to T_pM<br>$$</p><p>&gt;&nbsp;🚧 Ok, *technically*, more structure is needed for the existence of an exponential map. Since the exponential map minimizes distance along a path, we must have some notion of *length.* The subfield of Differential Geometry with *lengths* and *angles* is called [Riemannian Geometry](https://en.wikipedia.org/wiki/Riemannian_geometry) and is a fascinating subject in its own right. The definition of *lengths* and *angles* for a specific manifold is called the Riemannian Metric. We don’t have the space in this post to develop these ideas fully but we encourage the motivated reader to learn more!</p><p>With this understanding, we have the following prescription for optimization on a generic manifold \\(M\\)</p><p>- Compute the quantity to minimize — perhaps using our logarithmic map \\(\text{Log}_p(q)\\)<br>- Compute a direction \\(v\\) in \\(T_pM\\) &nbsp;along which the quantity is locally reduced<br>- Move the parameters using the exponential map \\(\text{Exp}_p(v)\\)<br>- Repeat until the problem converges</p><p>At this point, you are probably saying</p><p>&gt; “Why isn’t multi-variable optimization taught like this?”<br></p><p>&gt; “I haven’t had to worry about *tangent spaces* and *exponential maps* before.”<br></p><p>&gt; “Adding vectors has always *just worked* for me in the past.”<br></p><p>Yes, BUT. The secret here is that you’ve been exploiting a very special property of euclidean space: *continuous symmetry* of its tangent bundle.</p><p>## Continuous Symmetry</p><p>Some smooth manifolds exhibit a natural symmetry. By symmetry, we mean a concept that implies more than reflections or rotations of polygons taught in grade school. For instance, reflections and rotations of polygons are examples of *discrete symmetry.* However, in the study of smooth manifolds, we are interested in *continuous* *symmetry* of the Tangent Bundle. This is what makes optimization so simple in euclidean space.</p><p>To illustrate, consider the smooth manifold of real numbers of dimension \\(n\\): \\(\mathbb{R}^n\\) or Euclidean Space. We will visualize the plane \\(\mathbb{R}^2\\), but realize that these properties apply in higher dimensions, too.</p><p>Let’s place a uniform vector field on \\(\mathbb{R}^n\\), where “the same” vector \\(v\\) is attached to each point in the space \\(p\\). Imagine those points *flowing* along the vectors, as if the vectors describe the current of a river and the points are rafts in that river.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftPoints.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftPoints.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>You’ll notice that the points before and after the flow are effectively the same! Since this flow doesn’t *fundamentally* change the total set of points, it’s called an *invariant flow.*</p><p>Now let’s flip it: instead of moving each point along the flow of individual vectors, let’s recenter the points on a new origin.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOrigin.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOrigin.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Notice that this recentering effectively produces the same transformation as the vector field above. This is one important property of continuous symmetry of the manifold: the equivalence of local transformations under *constant* vector fields and global transformations of the entire space.</p><p>We can also recenter both the vector field and its associated points. Doing so, we find that the points and vector field are fundamentally *unchanged.*</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOriginPointsVectors.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOriginPointsVectors.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Furthermore, the points and vector field don’t have to be recentered in the same direction as the vector field. Under any arbitrary translation, the points and the *constant* vector field remain unchanged*.* In this way, both the manifold and the Tangent Bundle exhibit continuous symmetry.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOriginPointsVectors2.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridShiftOriginPointsVectors2.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>So to recap, when we say *continuous symmetry* of the tangent bundle of \\(\mathbb{R}^n\\) we mean three things:</p><p>- Local flows along an invariant vector field are the same as a global translation of all points<br>- Arbitrary translations of points yields the same set of points<br>- Arbitrary translations of *constant* vector fields yields the same *constant* vector field</p><p>One consequence of this continuous symmetry is that we can effectively treat *any* point in \\(\mathbb{R}^n\\) as the origin. To illustrate this, we will “subtract” two points \\(p\\) and \\(q\\) &nbsp;and get a vector pointing from \\(p\\) to \\(q\\), &nbsp;and then flow \\(p\\) along the vector to recover \\(q\\).</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridSubtractPoints.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridSubtractPoints.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>If we follow this animation *carefully,* we have to remember that this red vector lives in \\(T_p\mathbb{R}^n\\) and then *flow* the point starting at \\(p\\) until it reaches \\(q\\). Now, let’s first recenter the origin at \\(p\\) and then perform the subtraction.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridSubtractPointsAtOrigin.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/GridSubtractPointsAtOrigin.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>We see that this produces the *same* result, and this time the vector was “attached to the origin.” In effect, we can do the subtraction *as if* the space was centered at \\(p\\) and then only worry about vectors living in \\(T_0 \mathbb{R}^n\\).</p><p>You probably didn’t realize it, but we’ve set ourselves up for easy computation! If we use the standard basis of \\(\mathbb{R}^n\\), we simply subtract the coordinates of each point element-wise to get the vector. If we want to translate a point by a vector, we again can simply perform element-wise addition of the coordinates. The annoying book-keeping that comes with this vector distribution is effectively non-existent, because we just treat all vectors *as if* they lived in the tangent space at the origin.</p><p>In fact, since \\(T_0\mathbb{R}^n\\) is essentially just a copy of \\(\mathbb{R}^n\\), we can confuse points and vectors and likely *get away with it*. The distinction between a point and the vector that points from the origin to a point is so subtle that in practice it’s often not worth mentioning.</p><p>Using the continuous symmetry of \\(\mathbb{R}^n\\) we formulate our optimization steps as</p><p>- Compute the quantity to minimize *as if* our parameters represent the origin<br>- Compute a direction along which the quantity is locally reduced<br>- Add the minimizing direction to our parameters *as if* our parameters represent the origin<br>- Repeat until the problem converges</p><p>With continuous symmetry in euclidean space on our side, we can use the \\(\mathbb{R}^n\\) hammer on *everything*. Recalling our [previous post](https://www.tangramvision.com/blog/camera-modeling-pinhole-obsession): consider \\(\mathbb{T}^2\\). You’ll notice now that it is essentially \\(\mathbb{R}^2\\) with a couple of “extra points at infinity.” This makes computer vision with camera rays and the pinhole camera model feel easy! We just treat \\(\mathbb{T}^2\\) &nbsp;as \\(\mathbb{R}^2\\) and compute reprojection error by subtracting points and minimizing that error.</p><p>## Lie Groups: *Continuing* the Symmetry Party</p><p>But, I hear you mutter to yourself,</p><p>&gt; “Are there manifolds that have continuous symmetry of their Tangent Bundle, but are not flat like \\(\mathbb{R}^n\\)?”<br></p><p>Great question! The answer is yes! An example of manifolds that fit these criteria are [Lie Groups](https://en.wikipedia.org/wiki/Lie_group). A Lie Group (we’ll call it \\(\mathcal{G})\\) is a [mathematical group](https://en.wikipedia.org/wiki/Group_(mathematics)) that is also a smooth manifold.</p><p>Many commonly-used manifolds in robotics are Lie Groups:</p><p>- Special Orthogonal Group \\(SO(3)\\) - used for describing rigid-body rotations<br>- Special Euclidean Group \\(SE(3)\\) - used for describing rigid-body motion<br>- Special Linear Group \\(SL(3)\\) - used for describing continuous-time homographies<br>- Similarity Group \\(Sim(3)\\) - used for describing similarity transforms (rigid-body + scale)</p><p>Given their wide usage, it’s worthwhile to explore what makes them so useful.</p><p>A Lie Group is a mathematical group; it’s in the name. This means it has a way to compose elements, typically denoted as \\(g \circ h\\) for group elements \\(g,h \in \mathcal{G}\\). Additionally, the group has an identity element (typically called \\(e\\)). In some fashion, this identity can be considered the “origin”. Since a Lie group is *also* a smooth manifold, it has a tangent space at this “origin.” The tangent space at the identity element is called the [Lie Algebra](https://en.wikipedia.org/wiki/Lie_algebra) and is denoted by \\(T_e \mathcal{G} = \mathfrak{g}.\\)</p><p>To help us develop some intuition of Lie Groups, we will consider the simplest non-euclidean Lie Group, the unit circle \\(\mathcal{S}^1\\) and its associated Lie Algebra. Note that unlike our visualization of \\(\mathbb{R}^n,\\) we have chosen to explicitly display a tangent space of unit circle, since it takes a different shape than the underlying manifold.</p><p>![CircleLieAlgebra_ManimCE_v0.18.1.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f8903a9b45c2d4aa6779b_CircleLieAlgebra_ManimCE_v0.18.1.png)</p><p> Now, we proceed to choose some vector in this tangent space at the identity.</p><p>![CircleVector_ManimCE_v0.18.1.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f89037c2ce14a94eb854b_CircleVector_ManimCE_v0.18.1.png)</p><p>Now, let’s try to move a point along our chosen vector.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleVectorFlowWrong.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleVectorFlowWrong.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>If we simply move the point along the vector, the point leaves the manifold! This is not a valid flow, because the points must *by definition* live on the underlying manifold. To fix this, we will define the *flow* as the curve \\(\varphi(t)\\) such that &nbsp;\\(\varphi'(t)\\) matches the tangent vector. For a vector field \\(X\\) defined on the entire manifold, we denote this flow as \\(\varphi_X(t)\\).</p><p>However, this definition makes solving for \\(\varphi_X(t)\\) a bit tough since we have to solve an ordinary differential equation on a manifold. If we instead think of Euler integration, we can *approximate* a solution by “moving along” the manifold in the direction of the vector field.</p><p>In \\(\mathbb{R}^n\\), for a given vector field \\(X: \mathbb{R}^n \to T\mathbb{R}^n\\) euler integration gives us the recurrence of</p><p>$$<br>p_k = p_{k-1} + X(p_{k-1}) \Delta t<br>$$</p><p>On the manifold we can use the exponential map to similar effect. For a given vector field \\(X: M \to TM\\) “euler integration” takes the form of</p><p>&lt;p&gt;$$p_k = \text{Exp}_{p_{k-1}}(X(p_{k-1})\Delta t)$$&lt;/p&gt;&lt;!-- manual html to prevent showdown changing underscores into emphasis tags before mathjax gets to it --&gt;</p><p>We can imagine this exponential map as a “pushed down” vector on the manifold.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleVectorFlowRight.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleVectorFlowRight.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>&gt; ⚠️ In actuality, there is no such thing as a “pushed down vector,” however it’s a useful concept for visualization. If we use the definition of the exponential map, we can imagine this “pushed down vector” as the line drawn by the equation \\(\text{Exp}(\alpha v)\\) for a fixed vector \\(v\\) and a scalar \\(\alpha \in [0,1]\\).</p><p>Now following our example with \\(\mathbb{R}^2\\), let’s try to create a *constant* vector field by copying a vector into all points on the manifold. If we naively copy this vector in the same way that we did in the euclidean case (remember that big grid of arrows?), we get the following:</p><p>![CircleTangentSectionWrong_ManimCE_v0.18.1.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f89065b7a81cc793276c6_CircleTangentSectionWrong_ManimCE_v0.18.1.png)</p><p>This cannot be correct; our vectors wouldn’t live in their own respective tangent spaces. These “tangent vectors” have some component pointing normal to the manifold, which implies they are not tangent vectors at all! How do we address this mathematically?</p><p>&gt; ⚠️ Here we are claiming that this visualization is incorrect because we are considering the unit circle and its tangent bundle as entities *embedded* in ambient euclidean space \\(\mathbb{R}^2\\). In reality, we only care about the geometric and algebraic structure of the unit circle and our visualization is *somewhat independent* of that structure. It it not uncommon to visualize a manifold and an associated fibre bundle (e.g. the tangent bundle) as living in orthogonal spaces but connected at a single point. This explains why you sometimes may see the tangent bundle visualized as a manifold with non-overlapping tangent spaces.</p><p>&gt; ![Tangent_bundle.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f8903a9b1afcd2cb9b285_Tangent_bundle.png)<br>*PC: [https://commons.wikimedia.org/wiki/File:Tangent_bundle.svg](https://commons.wikimedia.org/wiki/File:Tangent_bundle.svg)*</p><p>&gt; In this post, we’ll continue with the embedded and overlapping view to aid intuition, but don’t be surprised if you see the tangent bundle drawn differently in other resources.</p><p>Instead of naively copying the vector at identity to every point on the lie group, let’s consider an arbitrary point \\(g \in \mathcal{G}\\). We can consider this point on the manifold as simply a point or, using the group structure, we can consider it as an operator since \\(g \circ e = g\\). In other words, \\(g\\) can be regarded as an operator that takes the identity into \\(g\\). This “operatorness” of \\(g\\) is typically denoted as the map</p><p>$$<br>\begin{aligned}<br>L_g: \mathcal{G} &amp;\to \mathcal{G} \\\\<br>h &amp;\mapsto g \circ h<br>\end{aligned}<br>$$</p><p>where the \\(L\\) denotes that we are composing with \\(g\\) on the left. You can form a similar map by composing on the right; we’ll call it \\(R_g\\).</p><p>We can use this operator concept to “push” vectors around on the manifold. Instead of \\(L_g\\) operating on a fixed value \\(h\\), we can imagine it operating on a curve \\(\gamma(t)\\) with \\(\gamma(0) = h\\).</p><p>Now we have a new *shifted* curve</p><p>$$<br>L_g(\gamma(t)) = g \circ \gamma(t)<br>$$</p><p>We can now consider the derivative of this new *shifted vector* as a vector living in the tangent space \\(T_{g \circ h} \mathcal{G}\\):</p><p>$$<br>\frac{d}{dt}L_g(\gamma(t))\vert_{t=0}<br>$$</p><p>…just like we did in our original vector field in \\(\mathbb{R}^n\\). For convenience of notation, we’ll drop the explicit parametrization of the curves and denote this vector shift as \\(dL_g(h,v)\\) for some \\(v \in T_h \mathcal{G}.\\)</p><p>&lt;blockquote&gt;<br>💡</p><p>The argument made here to derive this &lt;em&gt;vector shift&lt;/em&gt; function actually extends to arbitrary manifolds. If we have an map between manifolds</p><p>$$<br>\begin{aligned}<br>f: M \to N<br>\end{aligned}<br>$$</p><p>that obeys the continuity properties of the manifold, we can create an induced map on the tangent bundle</p><p>$$<br>df: TM \to TN<br>$$</p><p>This induced map is often referred to as the differential or “push forward” map because it “pushes” vectors in tangent spaces of one manifold onto tangent spaces of another manifold.</p><p>&lt;/blockquote&gt;</p><p>Now, we will state a few facts without proof about \\(dL_g(h,v)\\)</p><p>1. \\(dL_g(h,v)\\) &nbsp;is linear in \\(v\\)<br>2. \\(dL_g(h, v)\\) actually does not depend on \\(h\\), so we can write it as \\(dL_g(v)\\)<br>3. \\(dL_g(dL_h(v)) = dL_{g \circ h}(v)\\) or in other words group composition is compatible with vector shifting.</p><p>Got all that? Good! Now that we have this structure in place, let’s return to our tangent vector at the origin.</p><p>![CircleVector_ManimCE_v0.18.1.png](https://cdn.prod.website-files.com/5fff85e7f613e35edb5806ed/673f89037c2ce14a94eb854b_CircleVector_ManimCE_v0.18.1.png)</p><p>This time we will copy the vector to the other points on the manifold by *pushing* the vector with \\(dL_g\\) to each \\(g\\) on the manifold.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleTangentSectionRight.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleTangentSectionRight.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>If we flow all the points on the manifold along these vectors we’ll notice that all the points change in a consistent way! In the case for \\(\mathcal{S}^1\\) they are all rotating around the circle.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleTangentSectionFlow.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleTangentSectionFlow.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Here, we’ve found another invariant flow field. Let’s determine if the vector field is *unchanged* under the combined transformation</p><p>$$<br>(h, v) \mapsto (L_g(h), dL_g(v))<br>$$</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleShiftVectors.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleShiftVectors.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Just like the case for \\(\mathbb{R}^n\\), the points and vector field remain *unchanged*. Furthermore, like \\(\mathbb{R}^n\\) the transformation does not have to be *in the same direction* as the vector field.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleShiftVectors2.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleShiftVectors2.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Since these vectors don’t all point in the same direction (at least from an extrinsic point of view), we cannot call this a *constant* vector field. However, the vector field is invariant to group transformations, so we will call it an *invariant* vector field.</p><p>With these observations, we can state that all Lie Groups have a *continuously symmetric* Tangent Bundle*.* The difference from the euclidean case is that points and (certain) vector fields are invariant under group *transformations* instead of *translations*.</p><p>&gt; 💡Although this difference may seem significant at first, it turns that \\(\mathbb{R}^n\\) is actually Lie Group with translation as the group operator! Would you look at that.</p><p>As an added bonus, for these *invariant* vector fields, the Euler integration using the exponential map is **exact.** Specifically, for an *invariant* vector field the following closed-form integration holds:</p><p>$$<br>\varphi_X(t) = \text{Exp}_{p}(X(p)t)<br>$$</p><p>&gt; ⚠️ Here in this section, we’ve implied a parallel between *geodesics* on manifolds with a Riemannian Metric and the exponential map on Lie Groups. Technically, we have not defined a notion of a Riemannian Metric for Lie Groups. In this manner, it is possible to define a Riemannian Metric on Lie Groups such that the *geodesic exponential* and the *group exponential* are distinct. Regardless, broadly speaking, in both cases the exponential map helps us move along the manifold in a coherent manner.</p><p>As with Euclidean space, we can “recenter” the manifold by using the group operator to move \\(g\\) to the identity \\(e\\) while maintaining the distance to all other points. To do this, we simply apply the operator \\(L_{g^{-1}}\\) to all points on the manifold.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleRecenter.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleRecenter.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Likewise, we can “subtract” any two points \\(h\\) and \\(g\\) on the manifold by shifting the point we are subtracting to the origin and then using our aforementioned logarithm \\(\text{Log}_e(g^{-1} \circ h)\\).</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleRecenterSubtract.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/CircleRecenterSubtract.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Leveraging this *continuous symmetry* of Lie Groups, our optimization steps become</p><p>- Compute the quantity to minimize *as if* our parameters represent the origin i.e. using \\(\text{Log}_e(g^{-1} \circ h)\\)<br>- Compute a direction along which the quantity is locally reduced<br>- Add the minimizing direction to our parameters *as if* our parameters represent the origin i.e. using \\(g \circ \text{Exp}_e(v)\\)<br>- Repeat until the problem converges</p><p>Which makes for a pretty simple algorithm! We really only have to worry about two extra operators \\(\text{Log}_e\\) and \\(\text{Exp}_e\\). Maybe optimizing “on the manifold” isn’t so difficult after all? Let’s apply this *continuous symmetry* concept to the unit sphere to finally cure our Pinhole Obsession.</p><p>## Symmetry of the Sphere</p><p>Back to our unit sphere! The whole reason we did this in the first place.</p><p>Ideally, we’d want the unit sphere to exhibit *continuous symmetry* of the Tangent Bundle so we can take advantage of its benefits:</p><p>- Local flow along *invariant* vector fields is the same as a global transformation<br>- Some arbitrary concept of “origin” or “identity”<br>- Invariance of points and certain vector fields under global transformations</p><p>At first glance, the sphere *looks* fairly symmetric, so constructing an *invariant* vector field should be straightforward. Let’s try to find such a vector field. To start, let’s choose a vector field where all the vectors point at the north pole.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/longitude_sphere.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/longitude_sphere.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Here we notice that the points on the manifold are generally not all moving in the “same direction.” The points close to the north pole are converging and the points close to the south pole are diverging. This is not an invariant flow field.</p><p>Let’s again try to find an invariant flow field but this time choose the vector field where all the vectors are pointing east.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/east_sphere.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/east_sphere.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>Following the flow, the total set of points remains unchanged*.* This flow field yields a rotation of the sphere. So, the manifold itself exhibits some *continuous symmetry* because rotation leaves the set of points on the manifold unchanged.</p><p>&gt; ⭐ If you are wondering why these points flowing east are not moving along great circles, then you are a very astute reader! Remember, that in general using the exponential map \\(\text{Exp}_p(v)\\) to solve the flow \\(\varphi_X(t)\\) of a vector field \\(X\\) is an *approximation.* The true definition is that derivative of the flow \\(\varphi_X'(t)\\) must match the vector field \\(X\\) at every point along the curve.</p><p>Does this symmetry extend to the tangent bundle \\(T\mathcal{S}^2\\)? Well, if we swap the north pole and south pole, the vector field is now pointing west! So, the vector field that produces rotations is *not* *invariant* under rotations.</p><p>&lt;video width="100%" preload="metadata" loop muted controls&gt;&lt;source src="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/flip_sphere.mp4" type="video/mp4"&gt; If this video doesn't work in browser, &lt;a href="https://tangram-vision-blog-resources.s3.us-west-1.amazonaws.com/video/flip_sphere.mp4"&gt;download the video to view it&lt;/a&gt;&lt;/video&gt;</p><p>These visualizations, and the aircraft example from beginning of this post point to \\(\mathcal{S}^2\\) not having *continuous symmetry* of its Tangent Bundle. This lack of Tangent Bundle symmetry can be proven rigorously by using the [Hairy Ball theorem](https://en.wikipedia.org/wiki/Hairy_ball_theorem). Unfortunately, this means that we cannot take advantage of **all** the benefits of symmetry when optimizing over \\(\mathcal{S}^2\\). Specifically:</p><p>- There is no invariant vector field under a set of global transformations<br>- We can’t *recenter* a point of interest to do tangent-space computations in a more convenient location<br>- Each tangent space must be regarded as distinct and not simply *shifted copies* of an origin tangent space</p><p>Ultimately, optimizing over a generic asymmetric manifold is a large increase in complexity as opposed optimizing over Euclidean Space or Lie Groups. For each computation, we must perform careful book-keeping to ensure the coherence between:</p><p>- Points on the manifold: \\(p \in \mathcal{S}^2\\)<br>- Vectors in the tangent spaces at each point: \\(v \in T\mathcal{S}^2\\)<br>- Exponential maps to “move along the manifold”: \\(\text{Exp}_p(v)\\)<br>- Logarithmic maps to compute the difference between points: \\(\text{Log}_p(q)\\)</p><p>If this coherence is not maintained and properly modeled, the optimization is likely to fail. After really digging into the full complexity of optimization over a generic asymmetric manifold, Lie Groups and Euclidean Space seem even more pleasant to work with.</p><p>## “Grouping” it All Up</p><p>As we can see, optimization over Lie Groups (including Euclidean space) is actually a special case of optimization over a manifold. With *continuous symmetry,* we can actually ignore the effects of the starting point on the exponential operator*. Continuous symmetry* allows us to recenter the manifold on our starting point \\(g\\) (the Lie algebra) and *pretend* that we started at the origin. This is *incredibly handy* and in robotics we use this property a lot!</p><p>You’ll notice that in the optimization steps For Lie Groups, we only used the exponential and logarithmic maps at one point: the identity \\(e\\). From a mathematical perspective, this is **the** defining characteristic of Lie Groups. This defining characteristic can be described as an isomorphism between</p><p>- The group itself \\(\mathcal{G}\\)<br>- The Lie Algebra \\(\mathfrak{g} = T_e\mathcal{G}\\)<br>- The invariant vector fields on \\(\mathcal{G}\\)</p><p>There is a number of deep mathematical connections that can be made here, and we encourage the interested reader to learn more. However, for our use-case, it means we can rewrite our exponential map as</p><p>$$<br>\text{Exp}_g(v) = g \circ \text{Exp}_e(v)<br>$$</p><p>If you’ve read the previously mentioned “Micro Lie Theory” paper, you’ll recognize this as the “circle plus” operator i.e. \\(g \oplus v\\). With Lie Groups, there **really** is only one exponential map of concern — the one defined at the identity. This does not hold true for general manifolds. This is why when talking about Lie Groups **the** exponential \\(\text{Exp}\\) map will be described instead of mentioning exponential maps at each point.</p><p>So, when using Lie Groups for optimization, we can ignore the specifics about “which tangent space” we’re in. We operate either on the group \\(\mathcal{G}\\), or in the [Lie Algebra](https://en.wikipedia.org/wiki/Lie_algebra) \\(\mathfrak{g}\\). To recall our tools analogy, In the land of Lie Groups, we have two tools to master: a hammer \\(\mathcal{G}\\) &nbsp;and… screwdriver \\(\mathfrak{g}\\).</p><p>---</p><p>Did you have fun? We sure did. Thanks for going on this deep dive into Differential Geometry and its implications for optimization problems in robotics. Everyone loves Lie groups, no doubt about it.</p><p>Of course, if you’re experiencing these concerns in your day-to-day development, it’s probably time you considered working with the Tangram team. We’ve solved these problems so many different ways, on twice as many platforms. It’s our specialty! All this cool math in an easy-to-use package that can shorten your time to market; what’s not to love?</p><p>‍</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What made Dostoevsky's work immortal (123 pts)]]></title>
            <link>https://thoughts.wyounas.com/p/what-made-dostoevsky-immortal</link>
            <guid>42214331</guid>
            <pubDate>Fri, 22 Nov 2024 14:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoughts.wyounas.com/p/what-made-dostoevsky-immortal">https://thoughts.wyounas.com/p/what-made-dostoevsky-immortal</a>, See on <a href="https://news.ycombinator.com/item?id=42214331">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em>Along with air, earth, water, and fire, money is the fifth natural force a human being has to reckon with most often. This is one, if not the main, reason why today, one hundred years after Dostoevsky’s death, his novels preserve their relevance. – Joseph Brodsky.&nbsp;</em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1503923,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F363b2e5d-d3f7-479c-b1e8-3bfdc37e547c_6240x4160.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Image sourced from pexels.com</figcaption></figure></div><p><span>Joseph Brodsky is a name I wasn’t familiar with until a few months ago. I read about him for the first time in one of the pieces in </span><em>The New Yorker</em><span> magazine. I enjoyed reading that piece. Whenever I like some writing that makes a good impression of another author, then often I do more research about the recommended author and if the appeal remains I go ahead and buy their books and either put them in the library to be read later or, if the urge is strong, I try to read as soon as I get my hands on them. So I went ahead and bought a book of essays, titled “Less than one”, by Joseph Brodsky.&nbsp;</span></p><p>I’m glad I did.&nbsp;</p><p>He didn’t write ordinary essays, some of his essays are profound. Just as a beautiful sunrise captures your gaze, some of his insightful prose holds your attention. Joseph Brodsky’s mastery of language isn’t surprising given his background as a poet, the mastery shines through in his prose. If you enjoy reading good prose, you’ll miss out on a real treat if you don’t read prose written by a skilled poet like him.</p><p>As an aside, I just discovered that he died at the age of 57 and, judging by the amount and quality of his wiring, it seems he lived quite a life (not to forget he also won a Nobel prize for literature).</p><p>Anyway, back to his essays. One of his essays is about Dostoevsky, one of the great Russian novelists, and it’s a profound one not just because it’s about a profound writer but because it offers some subtle insights about Dostoevsky’s work.</p><p><span>Immortality of Dostoevsky’s art is unquestionable; his art will likely continue to live on. One of the first questions that Brodsky tackles in his essay is why do Dostoevsky's works preserve their relevance? Brodsky notes (though the following is quoted at the top, but repeating here for convenience):</span><br><span>“Along with air, earth, water, and fire, money is the fifth natural force a human being has to reckon with most often. This is one, if not the main, reason why today, one hundred years after Dostoevsky’s death, his novels preserve their relevance.”</span></p><p>Money never followed Dostoevsky; he had to follow it. Just as sharks pursue their prey, debtors and deadlines pursued him. There is a story about him that gives chills. He once signed a contract with a publisher on perilous terms: if he missed the deadline, the publisher would gain the rights to all his current and future works. He had one year to complete the project, but he did nothing for eleven months. In the final month, he hired a stenographer and dictated the entire book to her and, remarkably, he finished the book just in time. (And a few days later, he married the stenographer, a fitting celebration perhaps.) It's somewhat comforting to know that even great minds procrastinated heavily! But yes, they also produced timeless art.&nbsp;</p><p>Near the start of the essay, Brodsky notes: “For the best way to avoid mistakes in dealing with the future is to perceive it through the prism of poverty or guilt.”</p><p>There is something to ponder here. The road from poverty to prosperity is never guaranteed, but poverty can drive people to prosperity if people develop the required discipline and relentless drive for excellence. The lives of many great men and women stand as a testament to this.</p><p>Brodsky then comes back to the part where he connects the dots about why money is the reason Dostoevsky's work preserves relevance. Brodsky shares an excerpt about Dostoevsky from the diary of Russian socialite Elizaveta Stackenschneider:</p><p>“. . .&nbsp; but he is a petit bourgeois, yes, a petit bourgeois. Not of the gentry, nor of the clergy, not a merchant, nor an odd ball, like an artist or scholar, but precisely a petit bourgeois. And yet this petit bourgeois is the most profound thinker and a writer of genius . . . Now he frequents the house of the aristocracy and even those of the high nobility, and of course he bears himself with dignity, and yet the petit bourgeois in him trickles through. It can be spotted in certain traits, surfacing in private conversation, but most of all, in his works . . . in his depiction of big capital he will always regard 6,000 rubles as a vast amount of money.”</p><p>And Brodsky comments:</p><p>“What Mme Stackenschneider, a product of her epoch’s social stratification, calls petit bourgeois is known today as middle class, as defined in terms of annual income and not social affiliation. In other words, the said amount means neither great riches nor screaming poverty, but a tolerable human condition: a condition that makes one human.”</p><p>And he continues:</p><p>“A writer who regards six thousand rubles as a vast amount of money operates, therefore, on the same physical and psychological plan as the majority of people; i.e., he deals with life on its own general terms, since, like every natural process, human life gravitates toward moderation. Conversely, a writer who belongs to the upper echelon of society or to its lower depths will invariably produce a somewhat distorted picture of existence, for, in either case, he would regard it at too sharp an angle. Criticism of society (which is a nickname for life) from either above or below may produce a great read; but it’s only an inside job that can supply you with moral imperatives.</p><p>Furthermore, a middle-class writer’s own position is precarious enough to make him view what goes on below with considerable keenness. Alternatively, the situation above, due to its physical proximity, lacks in celestial appeal. Numerically, to say the least, a middle-class writer deals with a greater variety of plights, increasing, by the same token, the size of his audience. In any case, this is one way to account for the wide readership enjoyed by Dostoevsky, as well as by Melville, Balzac, Hardy, Kafka, Joyce, Faulkner. It looks as if the equivalent of six thousand rubles ensures great literature.”</p><p>This is an incisive observation. It’s not to say that the rich can’t write but, generally speaking, and as Brodsky hints above, a precarious financial condition is often a precondition for great literature, especially one with moral imperatives. There is something profound about the human condition which is not too rich and not too poor to have sensibilities required to produce great literature. Just enough suffering that fuels great literature.&nbsp;</p><p>Perhaps there is another reason, beyond the precarious position of the middle-class writer: a middle-class person must navigate every twist and turn of life on their own. And when you confront life at every turn, you can’t escape its realities. You inevitably notice nuances of human psychology and morality that a wealthy person might miss, as luxuries can keep them at a distance.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp" width="510" height="510" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:510,&quot;bytes&quot;:366984,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45cc327c-19df-492e-8be9-b450600f5715_1024x1024.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Life wasn’t easy for many great writers, and honestly, there would have been nothing remarkable about their lives if they had been easy. Many struggled financially. I randomly looked up the profiles of a few Nobel prize winners in literature. Though my data sample is small, none of them had a great financial situation when they were starting as a writer. Gabriel García Márquez, a Nobel Prize winner, while writing his magnum opus </span><em>One Hundred Years of Solitude</em><span>, “sold his car so his family would have money to live on while he wrote. Writing the novel took far longer than he expected; he wrote every day for 18 months. His wife had to ask for food on credit from their butcher and baker as well as nine months of rent on credit from their landlord.” [1] The road to greatness for him wasn’t built with riches. Those 18 months seemed far from a “tolerable human condition,” and you’ve got to give him credit for mustering all his talent and courage to not only produce, under such difficult circumstances, another book, but to create a remarkable work of fiction that brought South American literature into the spotlight. Most people lose their wits when they don't know how they'll put food on the table next month.</span></p><p><span>Another Nobel prize winner, William Faulkner, was born in poverty. He first attempted to join the army but later dropped out. “After dropping out, he took a series of odd jobs: at a New York City bookstore, as a carpenter in Oxford, and as the Ole Miss postmaster. He resigned from the post office with the declaration: ‘I will be damned if I propose to be at the beck and call of every itinerant scoundrel who has two cents to invest in a postage stamp.’“ [2] Definitely not great riches nor screaming poverty. He also had the courage of a genius because not many have the courage to put out the beck and call of their masters. “By 1932, Faulkner was in need of money. He asked Wasson to sell the serialization rights for his newly completed novel, </span><em>Light in August</em><span>, to a magazine for $5,000, but none accepted the offer.” [2] Life must have not been easy for Faulkner.&nbsp;</span></p><p>For another Nobel prize winner, Gabriela Mistral, “Poverty was a constant presence in her early life.” [3] Poverty was a stimulus for another winner, Albert Camus: “ His identity and poor background had a substantial effect on his later life.” [4]&nbsp;</p><p>One needs to further this analysis of evaluating financial well-being of great writers with a larger data pool, but none of the above writers had great riches. It seems that a certain kind of financial struggle often serves as a catalyst for writers to produce great works. That may not be true for all writers from all kinds of social and financial backgrounds, but some seem to thrive only under such circumstances.&nbsp;</p><p>Another question that often captures my attention, as a writer and a reader, is what makes Dostoevsky a great writer? His narratives? His writing style? Brodsky believes it’s neither. He observes:</p><p>“Almost without exception, all his novels are about people in narrow circumstances. This kind of material itself guarantees absorbing reading. However, what turned Dostoevsky into a great writer was neither the inevitable intricacy of his subject matter nor even the unique profundity of his mind and his capacity for compassion; it was the tool or, rather, the texture of the material he was using, i.e., the Russian language.”</p><p>He adds:</p><p>“Its polysyllabic nature (the average length of a Russian word is three to four syllables) reveals the elemental, primeval force of the phenomena covered by a word a lot better than any rationalization possibly could, and a writer sometimes, instead of developing his thought, stumbles and simply revels in the word’s euphonic contents, thereby sidetracking his issue in an unforeseen direction. And in Dostoevsky’s writing we witness an extraordinary friction, nearly sadistic in its intensity, between the metaphysics of the subject matter and that of the language.</p><p>He made the most of Russian’s irregular grammar. His sentences have a feverish, hysterical, idiosyncratic pace and their lexical content is an all but maddening fusion of belles lettres, colloquialisms, and bureaucratese. True, he never wrote at leisure. Much like his characters, he worked to make ends meet: there was always either creditors or a deadline. Still, for a man beset with deadlines, he was extraordinarily digressive, and those digressions, I venture to say, were prompted more by the language than by the requirements of a plot. Reading him simply makes one realize that stream of consciousness springs not from consciousness but from a word which alters or redirects one’s consciousness.”</p><p>I must admit, it takes some mastery of language to recognize the subtle role of language, as Brodsky did. After all, only a star can fully appreciate the beauty of another star.</p><p>I do wonder though if Dostoevsky’s digressions were only due to the nuances of Russian language? Did not his own suffering, of being a victim to epilepsy and then of Siberian exile, play any part in his narrative explorations? Was it not his intent to dig deeper into moral questions that play some part in his narrative explorations?&nbsp; I believe all this suffering must have played some role in shaping his thoughts and imaginations. A person who hasn’t endured hardship may struggle to capture the subtle complexities of human behavior when faced with adversity.</p><p>There is another insight about Dostoevsky that struck a chord with me. Brodsky notes near the end of the essay:</p><p>“From classicism, he took the principle that before you come forth with your argument, however right or righteous you may feel, you have to list all the arguments of the opposite side. And it is not that in the process of listing them one is being swayed by the opposite side; it is simply that the listing itself is a mightily absorbing process. One may not in the end drift away from one’s original stance, but after having exhausted all the arguments on behalf of evil, one utters the creed’s dictums with nostalgia rather with fervor. This, in its own way, also fosters the case of verisimilitude.”</p><p>This is beautifully expressed. Few can argue their opponent's case better than the opponents themselves. Rare, very rare is this skill, probably because it’s not easy to develop. But when someone possesses it and uses it masterfully, we must listen. Dostoevsky had this gift. Perhaps that’s why we still pay attention to his works. Life would be a little calmer if all were trained to adopt this approach whenever we found ourselves in disagreement.</p><p>Overall, the essay sparked some interesting thoughts on the life of a great writer. It’s enlightening to read a critique of Dostoevsky’s work by Joseph Brodsky—not just because his prose is above average, but also because his unique polyglot skills and extensive reading make his perspective stand out.</p><p>And it’s hard to refute Brodsky about the fact that being able to argue better can enrich fictional arcs; it can open up many pathways for the writer to follow in his narration that otherwise wouldn’t have been possible. Such an author can offer readers not just a richer reading experience but also a richer emotional experience. If fiction broadens our general awareness, then the writing of an author skilled in analyzing different viewpoints and adept at using language to probe the depths of the human experience also offers us a more profound emotional journey. A journey that stirs our souls.&nbsp;</p><p>Is there some correlation between an author's financial situation and the quality of their fiction writing? It's possible that the authors' financial conditions influence how they shape their characters, how their characters talk and act, or even how their characters transform over time. As Brodsky noted, you have to be in a certain kind of a financial situation to gather subtle insights about human psychology and morality. Although this poses an interesting dilemma for those that are financially well off and still want to write with incredible depth: how do they gather such subtle insights? Because though you can adapt the lifestyle of a financially struggling person, it's hard to replicate the state of mind of an impoverished individual. A wealthy person aiming to write great fiction might move into a middle-class neighborhood to experience the "tolerable human condition," but as long as their pockets remain full, they cannot truly capture the mental anguish of someone facing real financial hardship.This line of thought deserves an essay of its own though.&nbsp;</p><p>In the end, Brodky’s insightful insights about a great author makes his essay a special one.&nbsp;</p><p>References:</p><ol><li><p><a href="https://en.wikipedia.org/wiki/Gabriel_Garc%C3%ADa_M%C3%A1rquez" rel="">https://en.wikipedia.org/wiki/Gabriel_Garc%C3%ADa_M%C3%A1rquez</a><span>&nbsp;</span></p></li><li><p><a href="https://en.wikipedia.org/wiki/William_Faulkner" rel="">https://en.wikipedia.org/wiki/William_Faulkner</a><span>&nbsp;</span></p></li><li><p><a href="https://en.wikipedia.org/wiki/Gabriela_Mistral" rel="">https://en.wikipedia.org/wiki/Gabriela_Mistral</a><span>&nbsp;</span></p></li><li><p><a href="https://en.wikipedia.org/wiki/Albert_Camus" rel="">https://en.wikipedia.org/wiki/Albert_Camus</a><span>&nbsp;</span></p></li></ol></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Salmon return to lay eggs in historic habitat after dam removal project (312 pts)]]></title>
            <link>https://www.opb.org/article/2024/11/17/salmon-return-to-lay-eggs-in-historic-habitat-after-largest-dam-removal-project-in-us-history/</link>
            <guid>42213663</guid>
            <pubDate>Fri, 22 Nov 2024 13:27:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opb.org/article/2024/11/17/salmon-return-to-lay-eggs-in-historic-habitat-after-largest-dam-removal-project-in-us-history/">https://www.opb.org/article/2024/11/17/salmon-return-to-lay-eggs-in-historic-habitat-after-largest-dam-removal-project-in-us-history/</a>, See on <a href="https://news.ycombinator.com/item?id=42213663">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3><a href="https://www.opb.org/science_environment/">Science &amp; Environment</a></h3><h2>Less than a month after four towering dams on the Klamath River were demolished, hundreds of salmon made it into waters they have been cut off from for decades to spawn in cool creeks</h2></div><div><p>A giant female Chinook salmon flips on her side in the shallow water and wriggles wildly, using her tail to carve out a nest in the riverbed as her body glistens in the sunlight. In another moment, males butt into each other as they jockey for a good position to fertilize eggs.</p><p>These are scenes local tribes have dreamed of seeing for decades as they fought to bring down four hydroelectric dams blocking passage for struggling salmon along more than 400 miles (644 kilometers) of the Klamath River and its tributaries along the Oregon-California border.</p><p>Now, less than a month after those dams came down in the largest dam removal project in U.S. history, salmon are once more returning to spawn in cool creeks that have been cut off to them for generations. Video shot by the Yurok Tribe show that hundreds of salmon have made it to tributaries between the former Iron Gate and Copco dams, a hopeful sign for the <a href="https://apnews.com/article/klamath-dams-removal-california-oregon-river-salmon-44fefba145d74383aa70a68d50597299">newly freed waterway</a>.</p><p>“Seeing salmon spawning above the former dams fills my heart,” said Joseph L. James, chairman of the Yurok Tribe. “Our salmon are coming home. Klamath Basin tribes fought for decades to make this day a reality because our future generations deserve to inherit a healthier river from the headwaters to the sea.”</p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/L4PZ6DW7WVFY7CAPQQYK4LFYBY.jpg?auth=dbf1036c45044667d8c89bc083e002747fbe8424784231f2f62fa4f20e53863d&amp;width=150" alt="FILE - Excess water spills over the top of a dam on the Lower Klamath River known as Copco 1 near Hornbrook, Calif."></picture><figcaption><p>FILE - Excess water spills over the top of a dam on the Lower Klamath River known as Copco 1 near Hornbrook, Calif.</p><p><em>Gillian Flaccus / AP</em></p></figcaption></figure><p>The Klamath River flows from its headwaters in southern Oregon and across the mountainous forests of northern California before it reaches the Pacific Ocean.</p><p>The completion of the hydroelectric dam removal project on Oct. 2 marked a <a href="https://apnews.com/article/klamath-dam-removal-completed-tribes-435b955f5bfdeaca82de66bfc6551ba1">major victory for local tribes</a>. Through protests, testimony and lawsuits, the tribes showcased the environmental devastation caused by the dams, especially to salmon, which were cut off from their historic habitat and dying in alarming numbers because of poor water-quality.</p><p>There have been lower concentrations of harmful algae blooms since the dam removal, Toz Soto, fisheries program manager with the Karuk Tribe, said during a press conference after the dams came down. In October, the water temperature during the day was an average of 8 degrees Celsius (14 degrees Fahrenheit) cooler compared to the same month over the last nine years, according to the Klamath River Renewal Corporation, the nonprofit entity created to oversee the project.</p><p>“All in all, the fish that came up this year were really healthy,” Soto said. “I didn’t see fish with bacterial infections and things like that, so water temperature’s already having an impact on the fishes’ health.”</p><p>The number of salmon that have quickly made it into previously inaccessible tributaries has also been encouraging. Experts have counted 42 redds, or salmon egg nests, and have tallied as many as 115 Chinook salmon in one day in Spencer Creek, which is above the former J.C. Boyle dam, the furthest upstream of the four removed dams, said Mark Hereford with the Oregon Department of Fish and Wildlife.</p><p>“They’re showing us where the good habitat is; they’re showing us where there’s a lack of habitat,” said Barry McCovey Jr, director of the Yurok Tribal Fisheries department. “So we can use these fish to inform us as river managers, as scientists, where restoration needs to take place.”</p><figure><picture><img src="https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/LGNPDXOGT5BVVFRWUYS2JOUJZM.jpg?auth=4044d38dcd2939dc685d1e8ed46985f104509dd24221fb95319420e09aed3ad1&amp;width=150" alt="FILE - A view shows the Copco 1 Dam in Hornbrook, Calif., Sunday, Sept. 17, 2023."></picture><figcaption><p>FILE - A view shows the Copco 1 Dam in Hornbrook, Calif., Sunday, Sept. 17, 2023.</p><p><em>Haven Daley / AP</em></p></figcaption></figure><p>Power company PacifiCorp built <a href="https://apnews.com/article/klamath-dam-california-removal-restoration-473a570024584c2e02837434e05693da">the dams</a> to generate electricity between 1918 and 1962. But the structures halted the natural flow of the waterway that was once known as the third-largest salmon-producing river on the West Coast. They disrupted the lifecycle of the region’s salmon, which spend most of their life in the Pacific Ocean but return to the chilly mountain streams to lay eggs.</p><p>At the same time, the dams only produced a fraction of PacifiCorp’s energy at full capacity, enough to power about 70,000 homes. They also didn’t provide irrigation, drinking water or flood control, according to Klamath River Renewal Corporation.</p><p>McCovey said the return of so many salmon happened faster than he had expected and makes him hopeful for the future of the river.</p><p>“Out of all the milestones that we’ve had, this one to me is the most significant,” he said. “It feels like catharsis. It feels like the right path.”</p><p>___</p><p><i>Associated Press reporter Sophie Austin contributed to this report.</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From string to AST: parsing (2019) (104 pts)]]></title>
            <link>https://kubuszok.com/2019/from-string-to-ast-parsing/</link>
            <guid>42213322</guid>
            <pubDate>Fri, 22 Nov 2024 12:35:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kubuszok.com/2019/from-string-to-ast-parsing/">https://kubuszok.com/2019/from-string-to-ast-parsing/</a>, See on <a href="https://news.ycombinator.com/item?id=42213322">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Whether you have to do with data in form of CSV, JSON or a full-blooded programming language like C, JavaScript, Scala, or maybe a query language like SQL, you always transform some sequence of characters (or binary values) into a structured representation. Whatever you’ll do with that representation depends on your domain and business goals, and is quite often the core value of whatever you are doing. With a plethora of tools doing the parsing for us (including the error-handling), we might easily overlook how complex and interesting process it is.</p>

<h2 id="formal-grammars">Formal grammars</h2>

<p>First of all, most input formats that we handle follow some formal definition, telling e.g. how key-values are organized (JSON), how do you separate column names/values (CSV), how do you express projections and conditions (SQL). These rules are defined in an unambiguous way so that the input could be interpreted in a very deterministic way. It directly opposed language we use to communicate with other people, which often is ambiguous and put into the context. <em>Wanna grab some burger?</em> might be a nice suggestion if you are talking to a colleague that have to skip lunch and likes burgers, but might be offensive if told in a sarcastic tone to someone who doesn’t like meat. Then, words can have different meaning depending on the culture you are currently in, in which times you live or what are you and your conversationalist social position (<em>vide</em>, e.g. Japanese and how your position and suffixes you add at the end of the name change the tone of the whole conversation). Languages we use when communicating with a computer must be free of such uncertainties. The meaning should depend only on the input we explicitly entered and interpreted deterministically. (Just in case: by deterministically, I mean, deterministically interpreted, which doesn’t mean that it would always produce the same result. If I write <code>currentTimeMillis()</code>, the function will always return a different result, but the meaning will be always the same - compiler/interpreter will understand that I want to call <code>currentTimeMillis()</code> function, and it won’t suddenly decide that I want to e.g. change the compiler flag. Of course, the meaning of the function can change in time - for instance, if I edit the source code in between runs - and surely the value returned by it, which is bound to time).</p>

<p>Initially, it wasn’t known, how to parse languages. The reason, that we had to start with punching cards, sometime later moved on to assembly, and later on invent Fortran and Lisp, go through whole spaghetti code with Basic, get <em>The case against goto statement</em> by Dijkstra, until we could - slowly - started developing more sophisticated compilers we have today, was that there were no formal foundations to it.</p>

<p>Linguists know, that we can distinguish some <em>parts of speech</em> like: <em>noun</em> (specific thing, e.g. <em>cat</em>, <em>Alice</em>, <em>Bob</em>), <em>pronoun</em> (generic replacement for a specific thing, e.g. <em>I</em>, <em>you</em>, <em>he</em>, <em>she</em>), <em>verb</em> (action), <em>adjective</em> (description or trait of something, e.g. <em>red</em>, <em>smart</em>), etc. However, the also know that the function of part of speech changes depending on how we construct a sentence - that’s why we also have <em>the parts of the sentence</em>: <em>subject</em> (who performs the action: e.g. <em>Alice</em> in <em>Alice eats dinner</em>), <em>object</em> (who is the target of the action, e.g. <em>dinner</em> in <em>Alice eats dinner</em>), <em>modifiers</em> and <em>compliments</em>, etc. We can only tell which part of the speech and sentence the word is in the context of a whole sentence:</p>

<ul>
  <li>An alarm <em>is set</em> to 12 o’clock - here, <em>set</em> is a verb,</li>
  <li>This function returns an infinite <em>set</em> - here, <em>set</em> is a noun and an object,</li>
  <li>The <em>set</em> has the cardinality of 2 - here, <em>set</em> is a noun and a subject,</li>
  <li>All is <em>set</em> and done - here, <em>set</em> is an adverb and a modifier.</li>
</ul>

<p>As we can see the same work might be a completely different thing depending on the context. This might be a problem when we try to process the sentence bottom-up, just like we (supposedly) do when we analyze them in English lessons. <em>This is a noun. That is a verb. This noun is subject, this verb is an object. This is how subsentences relate to one another. Now we can analyze the nice tree of relations between words and understand the meaning.</em> As humans, we can understand the relationship between the words on the fly, the whole exercise is only about formalizing our intuition.</p>

<p>But machines have no intuition. They can only follow the rules, we establish for them. And when dealing with computers we quite often establish them using the divide-and-conquer strategy: split the big problem into smaller ones, and then combine the solutions. With <strong>natural languages</strong> the context makes it quite challenging, which is why no simple solution appeared even though we were regularly trying. Current progress was made mostly using machine learning, which tackles the whole problem at once, trying to fit whole parts of the sentence as patterns, without analyzing what is what. However, when it comes to communication with a computer, ambiguities can be avoided, simply by designing a language in a way that doesn’t allow them. But how to design a language?</p>

<p>One of the first researchers, that made the progress possible was Noam Chomsky. Interestingly, he is not considered a computer scientist - he is (among others) linguists, who is credited with <a href="https://en.wikipedia.org/wiki/Cognitive_revolution">cognitive revolution</a>. Chomsky believes, that how we structure languages is rooted in how our brains process speech, reading, etc. Therefore similarities between languages’ structures (parts of speech, parts of sentences, structuring ideas into sentences in the first place, grammar cases) are a result of how processes inside our brain. While he wasn’t the first one who tried to formalize a language into a <strong>formal grammar</strong> (we know of e.g. <a href="https://en.wikipedia.org/wiki/P%C4%81%E1%B9%87ini">Pāṇini</a>), Chomsky was the first to formalize <strong>generative grammars</strong>, that is grammars where you define a set of rules, and create a language by combining the rules.</p>

<p>How can we define these rules? Well, we want to be able to express each <em>text</em> in such grammar as a tree - at leaves, we’ll have <em>words</em> or <em>punctuation marks</em> of sorts. Then, there will be nodes aggregating words/punctuation marks by their function (part of a sentence). At the top of the tree we’ll have a root, which might be (depending on grammar) a sentence/a statement/an expression, or maybe a sequence of sentences (a <em>program</em>). The definitions will work this way: take a node (starting with root) and add some children to it: the rules will say how the specific node (or nodes) can have children appended (and what kind of children). The grammar definitions will rarely be expressed with specific values (e.g. you won’t write down all possible names), but rather using symbols:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>→</mo><mi>S</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi><mtext>&nbsp;</mtext><mi>O</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">Sentence \rightarrow Subject\ verb\ Object .</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo>→</mo><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><mi>r</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mo>∣</mo><mi>n</mi><mi>i</mi><mi>c</mi><mi>k</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Subject \rightarrow name\ surname \mid nickname</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo>→</mo><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mo>∣</mo><mi>a</mi><mi>n</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">Object \rightarrow item \mid animal</annotation></semantics></math></span></span></span>

<p>Here, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Sentence</annotation></semantics></math></span></span> could be a <strong>start symbol</strong>. We would build a sentence by unrolling notes according to rules. Here there is only one rule going from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Sentence</annotation></semantics></math></span></span> - one that allows adding <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Subject</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">verb</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Object</annotation></semantics></math></span></span> and the dot sign (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">.</annotation></semantics></math></span></span>) children (order matters!). <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">verb</annotation></semantics></math></span></span> is written with a small capital because it is (or eventually will be) a leaf - since unrolling ends (terminates) at leaves, we would call symbols allowed to be leaves as <strong>terminal symbols</strong>. As you might guess, nodes become <strong>nonterminal symbols</strong>. Terminal symbols will eventually be replaced with an actual word, unless they are <strong>keywords</strong> (have you noticed, how <em>if</em>, <em>else</em>, <em>function</em>, <em>class</em>, … get special treatment in many languages?) or special symbols (<code>;</code>, <code>(</code>,  <code>)</code>, <code>,</code>, …).</p>

<p>Having, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi><mtext>&nbsp;</mtext><mi>O</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">Subject\ verb\ Object.</annotation></semantics></math></span></span>, we can continue unrolling. Our second rule lets us turn <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Subject</annotation></semantics></math></span></span> into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><mi>r</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">name\ surname</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>i</mi><mi>c</mi><mi>k</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">nickname</annotation></semantics></math></span></span> (the vertical line <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∣</mo></mrow><annotation encoding="application/x-tex">\mid</annotation></semantics></math></span></span> is a shortcut - <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>B</mi><mo>∣</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A \rightarrow B \mid C</annotation></semantics></math></span></span> should be understood as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A \rightarrow B</annotation></semantics></math></span></span> <em>or</em> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A \rightarrow C</annotation></semantics></math></span></span>). And our third rule allows us to turn <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>b</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Object</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">item</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>n</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">animal</annotation></semantics></math></span></span>. We can go both times with the first option and obtain <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><mi>r</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi><mtext>&nbsp;</mtext><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">name\ surname\ verb\ item.</annotation></semantics></math></span></span> (e.g. <em>John Smith eats cereals.</em>). We might go both times with the second option - <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>i</mi><mi>c</mi><mi>k</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi><mtext>&nbsp;</mtext><mi>a</mi><mi>n</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">nickname\ verb\ animal.</annotation></semantics></math></span></span> (<em>Johnny likes cats.</em>). And so on.</p>

<p>Notice that in the end, we’ll always end up with a sequence of terminals. If we couldn’t, there would be something wrong with a language. This definition that takes a sequence of symbols and returns another sequence of symbols is called <strong>production rules</strong>. We can describe each <strong>formal language</strong> as a quadruple <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>=</mo><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi><mo separator="true">,</mo><mi>P</mi><mo separator="true">,</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G = (N, \Sigma, P, S)</annotation></semantics></math></span></span>, where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span> is a finite set of nonterminal symbols, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span></span> a finite set of terminal symbols,  <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span></span> is a set of production rules and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">S \in \Sigma</annotation></semantics></math></span></span> is a start symbol.</p>

<p>Besides formalization of generative grammars, Chomsky did something else. He was responsible for the organization of formal languages in a hierarchy called after him the <strong>Chomsky hierarchy</strong>.</p>

<h2 id="the-chomsky-hierarchy">The Chomsky hierarchy</h2>

<p>On the top of the hierarchy are <strong>type-0 languages</strong> or <strong>unrestricted languages</strong>. There is no restriction placed upon how we define such language. A production rule might be any sequence of terminals and nonterminals into any sequence of terminals and nonterminals (in the earlier example there was always nonterminal symbol on the left side - that is not a rule in general!). These languages are hard to deal with, so we try to define data format and programming languages in term of a bit more restrained grammars, that are easier to analyze.</p>

<p>First restriction appears with <strong>type-1 languages</strong> or <strong>context-sensitive grammars</strong> (<strong>CSG</strong>). They require, that all production rules would be in form of:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>α</mi><mi>A</mi><mi>β</mi><mo>→</mo><mi>α</mi><mi>γ</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">\alpha A \beta \rightarrow \alpha \gamma \beta</annotation></semantics></math></span></span></span>

<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">A \in N</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo separator="true">,</mo><mi>β</mi><mo>∈</mo><mo stretchy="false">(</mo><mi>N</mi><mo>∪</mo><mi mathvariant="normal">Σ</mi><msup><mo stretchy="false">)</mo><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\alpha, \beta \in (N \cup \Sigma)^*</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>∈</mo><mo stretchy="false">(</mo><mi>N</mi><mo>∪</mo><mi mathvariant="normal">Σ</mi><msup><mo stretchy="false">)</mo><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\gamma \in (N \cup \Sigma)^+</annotation></semantics></math></span></span> (where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> are <a href="https://kubuszok.com/2018/algebras-we-love/#free-monoids">Kleene star and Kleene plus</a>). In other words, we can perform <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">A \rightarrow \gamma</annotation></semantics></math></span></span> only, if immediately before <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span></span> and immediately after is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span></span> (rule is applied in <em>context</em>). But, even these grammars appears to be difficult to deal with. That is why we apply even more restrictions to grammars we use in our everyday life.</p>

<p>More specifically, we might want our grammars to be independent of context. <strong>Type-2 languages</strong> or <strong>context-free grammars</strong> (<strong>CFG</strong>), are CSGs where context is always empty, or in other words, where each production rule is in form of:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>→</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">A \rightarrow \gamma</annotation></semantics></math></span></span></span>

<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">A \in N</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>∈</mo><mo stretchy="false">(</mo><mi>N</mi><mo>∪</mo><mi mathvariant="normal">Σ</mi><msup><mo stretchy="false">)</mo><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\gamma \in (N \cup \Sigma)^+</annotation></semantics></math></span></span>. These grammars, are quite well researched, so we have plenty of tools helping us analyze them, check if something belongs to language, how to generate parser etc. That’s why the majority (all?) of programming languages and data inputs are defined using CFGs.</p>

<p>To be precise, when it comes to programming languages, we quite often deal with context-sensitive grammars, but it is easier to deal with them as if they were context-free - call that <strong>syntactical analysis</strong> (what meaning we can attribute to a words basing on their position in a sentence) - and then take the generated tree, called <strong>abstract syntax tree</strong>, and check if makes <strong>semantic</strong> sense (is the name a function, a variable or a type? Does it makes sense to use it in the <em>context</em> it was placed?). If we expressed it as a context-sensitive grammar we could do much (all?) of semantic analysis in the same time we check syntax, but the grammar could get too complex for us for understand it (or at least to handle it efficiently).</p>

<p>To illustrate the difference between syntax and semantics we can get back to your earlier example.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>n</mi><mi>i</mi><mi>c</mi><mi>k</mi><mi>n</mi><mi>a</mi><mi>m</mi><mi>e</mi><mtext>&nbsp;</mtext><mi>v</mi><mi>e</mi><mi>r</mi><mi>b</mi><mtext>&nbsp;</mtext><mi>i</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">nickname\ verb\ item.</annotation></semantics></math></span></span></span>

<p>It is a correct semantics in the language. Let’s substitute terminals with some specific values.</p>

<blockquote>
  <p>Johnny eat integral.</p>
</blockquote>

<p>What we got is correct according to the rules based on words’ positions in the sentence (syntax), but as a whole - when you analyze the function of each word (semantics) - it makes no sense. Theoretically, we could define our language in an elaborate way, that would make sure that there would always be e.g. <em>eat<strong>s</strong></em> after the third person in a sentence and something edible after some form of <em>to eat</em> verb, but you can easily imagine, that the number of production rules would explode.</p>

<p>Finally, there is the most restricted kind of grammar in the Chomsky hierarchy. <strong>Type-3 grammar</strong> or <strong>regular grammar</strong> is a language, where you basically either prepend or append terminals. That is each production rule must be in the form of one of:</p>

<ul>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">A \rightarrow a</annotation></semantics></math></span></span> - where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">A \in N</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∈</mo><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">a \in \Sigma</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">A \rightarrow \epsilon</annotation></semantics></math></span></span>, where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span> in an empty string,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>a</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">A \rightarrow aB</annotation></semantics></math></span></span> - where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">B \in N</annotation></semantics></math></span></span>.</li>
</ul>

<p>(We call it <strong>right regular grammar</strong> - if we instead required that the third rule would be in the form <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>→</mo><mi>B</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">A \rightarrow Ba</annotation></semantics></math></span></span> it would be <strong>left regular grammar</strong>). While regular grammars are too restricted to define many programming languages on its own, is we’ll find out later on, that - when combined with CFG - they allow us to build modern parsers.</p>

<h2 id="regular-languages">Regular languages</h2>

<p>Let’s start with the most limited grammars, that is regular grammars. No matter how we define production rules, we will end up with a tree of form:</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="176pt" height="308pt" viewBox="0.00 0.00 175.91 307.85" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 303.85)">
<!-- N1 -->
<g id="node1">
<title>N1</title>
<ellipse fill="lightgrey" stroke="black" cx="53.22" cy="-274.95" rx="24.9" ry="24.9"></ellipse>
<text text-anchor="middle" x="53.22" y="-270.28" font-family="FiraCode-Regular" font-size="14.00">N1</text>
</g>
<!-- t1 -->
<g id="node2">
<title>t1</title>
<ellipse fill="lightgrey" stroke="black" cx="21.22" cy="-189.15" rx="21.22" ry="21.22"></ellipse>
<text text-anchor="middle" x="21.22" y="-184.47" font-family="FiraCode-Regular" font-size="14.00">t1</text>
</g>
<!-- N1&#45;&gt;t1 -->
<g id="edge1">
<title>N1-&gt;t1</title>
<path fill="none" stroke="black" d="M44.64,-251.49C40.9,-241.68 36.45,-230.03 32.44,-219.53"></path>
<polygon fill="black" stroke="black" points="35.46,-218.63 28.62,-210.53 28.92,-221.12 35.46,-218.63"></polygon>
</g>
<!-- N2 -->
<g id="node3">
<title>N2</title>
<ellipse fill="lightgrey" stroke="black" cx="85.22" cy="-189.15" rx="24.9" ry="24.9"></ellipse>
<text text-anchor="middle" x="85.22" y="-184.47" font-family="FiraCode-Regular" font-size="14.00">N2</text>
</g>
<!-- N1&#45;&gt;N2 -->
<g id="edge2">
<title>N1-&gt;N2</title>
<path fill="none" stroke="black" d="M61.8,-251.49C65.14,-242.73 69.04,-232.52 72.69,-222.97"></path>
<polygon fill="black" stroke="black" points="76.21,-224.55 76.51,-213.96 69.67,-222.05 76.21,-224.55"></polygon>
</g>
<!-- t2 -->
<g id="node4">
<title>t2</title>
<ellipse fill="lightgrey" stroke="black" cx="53.22" cy="-103.34" rx="21.22" ry="21.22"></ellipse>
<text text-anchor="middle" x="53.22" y="-98.67" font-family="FiraCode-Regular" font-size="14.00">t2</text>
</g>
<!-- N2&#45;&gt;t2 -->
<g id="edge3">
<title>N2-&gt;t2</title>
<path fill="none" stroke="black" d="M76.64,-165.69C72.9,-155.87 68.45,-144.22 64.44,-133.73"></path>
<polygon fill="black" stroke="black" points="67.46,-132.82 60.62,-124.73 60.92,-135.32 67.46,-132.82"></polygon>
</g>
<!-- N3 -->
<g id="node5">
<title>N3</title>
<ellipse fill="lightgrey" stroke="black" cx="117.22" cy="-103.34" rx="24.9" ry="24.9"></ellipse>
<text text-anchor="middle" x="117.22" y="-98.67" font-family="FiraCode-Regular" font-size="14.00">N3</text>
</g>
<!-- N2&#45;&gt;N3 -->
<g id="edge4">
<title>N2-&gt;N3</title>
<path fill="none" stroke="black" d="M93.8,-165.69C97.14,-156.93 101.04,-146.71 104.69,-137.16"></path>
<polygon fill="black" stroke="black" points="108.21,-138.74 108.51,-128.15 101.67,-136.25 108.21,-138.74"></polygon>
</g>
<!-- t3 -->
<g id="node6">
<title>t3</title>
<ellipse fill="lightgrey" stroke="black" cx="87.22" cy="-21.22" rx="21.22" ry="21.22"></ellipse>
<text text-anchor="middle" x="87.22" y="-16.54" font-family="FiraCode-Regular" font-size="14.00">t3</text>
</g>
<!-- N3&#45;&gt;t3 -->
<g id="edge5">
<title>N3-&gt;t3</title>
<path fill="none" stroke="black" d="M108.7,-79.6C105.47,-70.95 101.73,-60.97 98.29,-51.79"></path>
<polygon fill="black" stroke="black" points="101.22,-50.63 94.44,-42.49 94.67,-53.09 101.22,-50.63"></polygon>
</g>
<!-- ... -->
<g id="node7">
<title>...</title>
<ellipse fill="lightgrey" stroke="black" cx="147.22" cy="-21.22" rx="20.69" ry="20.69"></ellipse>
<text text-anchor="middle" x="147.22" y="-16.54" font-family="FiraCode-Regular" font-size="14.00">...</text>
</g>
<!-- N3&#45;&gt;... -->
<g id="edge6">
<title>N3-&gt;...</title>
<path fill="none" stroke="black" d="M125.74,-79.6C129.06,-70.72 132.91,-60.44 136.42,-51.06"></path>
<polygon fill="black" stroke="black" points="139.97,-52.56 140.2,-41.97 133.42,-50.1 139.97,-52.56"></polygon>
</g>
</g>
</svg>

</p>

<p>Of course, it doesn’t mean, that each such tree would be the same. For instance we could define our grammar like this:</p>

<ul>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>→</mo><mi>a</mi><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_0 \rightarrow a A_1</annotation></semantics></math></span></span></span>
  </li>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>→</mo><mi>a</mi><msub><mi>A</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">A_1 \rightarrow a A_2</annotation></semantics></math></span></span></span>
  </li>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mn>2</mn></msub><mo>→</mo><mi>a</mi><msub><mi>A</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">A_2 \rightarrow a A_3</annotation></semantics></math></span></span></span>
  </li>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mn>3</mn></msub><mo>→</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">A_3 \rightarrow \epsilon</annotation></semantics></math></span></span></span>
  </li>
</ul>

<p>If we started from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">A_0</annotation></semantics></math></span></span>, the only possible sentence in such language would be <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>a</mi><mi>a</mi><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">aaa\epsilon</annotation></semantics></math></span></span>. And - since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span> represents an empty string, it would be actually just <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>a</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">aaa</annotation></semantics></math></span></span>. Another example could be grammar like this:</p>

<ul>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mo>→</mo><mi>a</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">S \rightarrow a B</annotation></semantics></math></span></span></span>
  </li>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mo>→</mo><mi>b</mi><mi>B</mi><mo>∣</mo><mi>b</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">B \rightarrow bB \mid bC</annotation></semantics></math></span></span></span>
  </li>
  <li>
    <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">C \rightarrow c</annotation></semantics></math></span></span></span>
  </li>
</ul>

<p>If our starting symbol would be <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span></span>, the sentences we could accept as belonging to grammar would be <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">abc</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi><mi>b</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">abbc</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi><mi>b</mi><mi>b</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">abbbc</annotation></semantics></math></span></span>, … If you’ve been programming for a while and you ever had to find some pattern in a text, you should have a feeling that looks familiar. Indeed, the regular language is formalism used to describe the <strong>regular expressions</strong>.</p>

<p>The first example you be described just as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>a</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">aaa</annotation></semantics></math></span></span>, while the second as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>b</mi><mo>+</mo><mo stretchy="false">)</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a(b+)c</annotation></semantics></math></span></span> (or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi><mo stretchy="false">(</mo><mi>b</mi><mo>∗</mo><mo stretchy="false">)</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">ab(b*)c)</annotation></semantics></math></span></span>. Here, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> corresponds directly with Kleene star and Kleene plus. Now, that we know we are talking about regexpes, we can provide another definition of what could be a regular language, that would be equivalent to production-rule-based, but easier to work with.</p>

<p>A regular expression is anything build using the following rules:</p>

<ul>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span> is a regular expression accepting the empty word as belonging to the language,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> is a regular expression accepting <code>'a'</code>  belonging to some alphabet <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> (nonterminals) as a word belonging to the language,</li>
  <li>when you <strong>concatenate</strong> two regular expressions, e.g. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">AB</annotation></semantics></math></span></span>, you accept words made by concatenating all valid words in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> with all valid words in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> (e.g. if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> accepts only <code>"a"</code> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> accepts only <code>"b"</code>, then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">ab</annotation></semantics></math></span></span> accepts <code>"ab"</code>),</li>
  <li>you can <strong>sum up</strong> regular languages <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∣</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A \mid B</annotation></semantics></math></span></span>, to accept all words valid either in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> or in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> (e.g. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∣</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a \mid b</annotation></semantics></math></span></span> would accept <code>"a"</code> or <code>"b"</code>, but not <code>"ab"</code>),</li>
  <li>you can use Kleene star <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">A^*</annotation></semantics></math></span></span> and Kleene plus <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">A^+</annotation></semantics></math></span></span>, to define (respectively) <em>any number of occurrences</em> or <em>at least one occurrence</em> of a pattern <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> as words accepted by regular language (e.g. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><msup><mi>b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a(b^+)c</annotation></semantics></math></span></span>).</li>
</ul>

<p>That is enough to define all regular expressions, though usually, we would have some utilities provided by regexp engines, e.g. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo>−</mo><mi>z</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a-z]</annotation></semantics></math></span></span>, which is a shortcut for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∣</mo><mi>b</mi><mo>∣</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>∣</mo><mi>y</mi><mo>∣</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">a \mid b \mid ... \mid y \mid z</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo stretchy="false">?</mo></mrow><annotation encoding="application/x-tex">A?</annotation></semantics></math></span></span> which is a shortcut for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∣</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">A \mid \epsilon</annotation></semantics></math></span></span>. Just in case, I’ll also mention, that some implementations of regexp allows so-called <em>backreferences</em> - expression build using there are no longer regular languages, which has some practical implications. What are these implications?</p>

<p>Well, we haven’t discussed it so far, but there are some very close relationships between types of formal grammars and computation models. It just happens, that if we wanted to define a function checking whether a word/sentence/etc belongs to a regular grammar/a regular expression - which is equivalent to defining the language - is done by defining a <strong>finite-state automaton</strong> (<strong>FSA</strong>), that accepts this language. And vice-versa, each FSA defines a regular language. That correspondence dictates, how we implement regexp patterns - basically, each time we compile a regexp pattern, we are building a FSA, that would accept all words of grammar and only them.</p>

<p>In case you’ve never met FSA, let us remind what they are. Finite-state automaton or <strong>finite-state machine</strong> (<strong>FSM</strong>) is a 5-tuple <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi><mo separator="true">,</mo><mi>δ</mi><mo separator="true">,</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><mi>F</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Q, \Sigma, \delta, q_0, F)</annotation></semantics></math></span></span>, where:</p>

<ul>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span> is a finite set of <strong>states</strong>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span></span> is a finite set of <strong>input symbols</strong> (an <strong>alphabet</strong> - equal to set of terminals without <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span>),</li>
  <li>a <strong>transition function</strong> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>:</mo><mi>Q</mi><mo>×</mo><mi mathvariant="normal">Σ</mi><mo>→</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">\delta: Q \times \Sigma \rightarrow Q</annotation></semantics></math></span></span>, which would take the current state and next input symbol to return the next state,</li>
  <li>an <strong>initial state</strong> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>0</mn></msub><mo>∈</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">q_0 \in Q</annotation></semantics></math></span></span>,</li>
  <li>a set of accepting states <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>⊆</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">F \subseteq Q</annotation></semantics></math></span></span>.</li>
</ul>

<blockquote>
  <p>On a side note: <em>an automaton</em> - singular, meaning <em>a machine</em>, <em>automata</em> - plural, meaning <em>machine<strong>s</strong></em>. Other nerdy words which works like that: <em>a criterion</em> vs <em>criteria</em>.</p>
</blockquote>

<p>For instance: our alphabet contains 3 possible characters <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi><mo>=</mo><mo stretchy="false">{</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Sigma = \{a,b,c\}</annotation></semantics></math></span></span>. We want to build a finite state machine accepting regular expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><msup><mi>b</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a(b^*)c</annotation></semantics></math></span></span>. Such machine:</p>

<ul>
  <li>would have to start with a state indicating that nothing was yet matched, but also that nothing is wrong yet. Let’s mark it as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">q_0</annotation></semantics></math></span></span>,</li>
  <li>if first incoming input symbol is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>, everything is OK, and we can move on to matching <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><msup><mo stretchy="false">)</mo><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">(b)^*</annotation></semantics></math></span></span>. However, if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span></span> arrives, we can already tell, that the result is wrong. Let’s mark error as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>. On <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span> no matter, what comes next, we’ll just stay at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span> state,</li>
  <li>in this particular case we can safely assume, that if things started to go wrong, there is no way to recover, but it is not a general rule (if there was e.g. an alternative, then failing to match one expression, wouldn’t mean that we will fail to match the other expression),</li>
  <li>to indicate that we matched <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>, let’s create a new state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span></span>. We have to do it, because FSM (which shares its acronym with its noodle excellency Flying Spaghetti Monster) can only remember the current state it is in, so we want to change the behavior (and when we move to match <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">b^*</annotation></semantics></math></span></span> we will), we can only achieve that, by creating a different state for each behavior (and step of the algorithm) and using state transition to indicate progress of computation,</li>
  <li>OK, we arrived at state <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span></span>, so <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> was matched, and we want to match <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">b^*</annotation></semantics></math></span></span>. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">b^*</annotation></semantics></math></span></span> means that there could be 0 or more occurrences of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span>. In case there is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span>, we have to match whatever is immediately after <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">b^*</annotation></semantics></math></span></span>, that is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span></span>. Accidentally, that would be the case when we are accepting input. Let’s mark that case as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span></span> and let’s put it into the set accepting states,</li>
  <li>In case we are in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> arrives, we can… simply keep the current state. Until anything from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi><mo>−</mo><mo stretchy="false">{</mo><mi>b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Sigma - \{b\}</annotation></semantics></math></span></span> arrives, we can reuse current state,</li>
  <li>if we are in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> arrives, input is wrong and we’ll go to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>,</li>
  <li>at this point, we are at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span></span> (or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span> which means that things mismatched and we cannot recover). <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span></span> is accepting state, so, if there is nothing else, we matched the input. However, if there is anything else incoming, this means we have e.g. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>b</mi><mi>b</mi><mi>c</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">abbca</annotation></semantics></math></span></span> which shouldn’t be matched. So no matter what will come, we are moving to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>.</li>
</ul>

<p>What we defined right, now could be described like this:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Σ</mi><mo>=</mo><mo stretchy="false">{</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Sigma = \{a,b,c\}</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>e</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">Q = \{q_0, q_1, q_2, e\}</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>δ</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>→</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>→</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>→</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><mi>e</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><mi>e</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><mi>e</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>→</mo><mi>e</mi><mo stretchy="false">}</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\delta = \{ (q_0, a) \rightarrow q_1, \\
            (q_0, b) \rightarrow e, \\
            (q_0, c) \rightarrow e, \\
            (q_1, a) \rightarrow e, \\
            (q_1, b) \rightarrow q_1, \\
            (q_1, c) \rightarrow q_2, \\
            (q_2, a) \rightarrow e, \\
            (q_2, b) \rightarrow e, \\
            (q_2, c) \rightarrow e, \\
            (e, a) \rightarrow e, \\
            (e, b) \rightarrow e, \\
            (e, c) \rightarrow e \}
\end{aligned}</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>q</mi><mn>2</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">F = \{q_2\}</annotation></semantics></math></span></span></span>

<p>We could also make it more visual (bold border for accepting state):</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="182pt" height="364pt" viewBox="0.00 0.00 182.10 364.10" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 360.1)">
<!-- q0 -->
<g id="node1">
<title>q0</title>
<ellipse fill="lightgrey" stroke="black" cx="100.35" cy="-315" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="100.35" y="-310.33" font-family="FiraCode-Regular" font-size="14.00">q0</text>
<text text-anchor="middle" x="38.25" y="-342.8" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- q1 -->
<g id="node3">
<title>q1</title>
<ellipse fill="lightgrey" stroke="black" cx="61.35" cy="-214.05" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="61.35" y="-209.38" font-family="FiraCode-Regular" font-size="14.00">q1</text>
</g>
<!-- q0&#45;&gt;q1 -->
<g id="edge1">
<title>q0-&gt;q1</title>
<path fill="none" stroke="black" d="M91.89,-292.53C86.61,-279.14 79.72,-261.66 73.82,-246.7"></path>
<polygon fill="black" stroke="black" points="76.85,-245.84 69.93,-237.82 70.34,-248.41 76.85,-245.84"></polygon>
<text text-anchor="middle" x="87.48" y="-259.85" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e -->
<g id="node4">
<title>e</title>
<ellipse fill="lightgrey" stroke="black" cx="104.35" cy="-18" rx="18" ry="18"></ellipse>
<text text-anchor="middle" x="104.35" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">e</text>
</g>
<!-- q0&#45;&gt;e -->
<g id="edge2">
<title>q0-&gt;e</title>
<path fill="none" stroke="black" d="M108.11,-292.02C112.99,-276.99 118.83,-256.51 121.35,-237.9 130.61,-169.54 118.28,-88.43 110.26,-46.76"></path>
<polygon fill="black" stroke="black" points="113.52,-46.22 108.13,-37.1 106.66,-47.59 113.52,-46.22"></polygon>
<text text-anchor="middle" x="135.85" y="-158.9" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q2 -->
<g id="node2">
<title>q2</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="44.35" cy="-113.1" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="44.35" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">q2</text>
</g>
<!-- q2&#45;&gt;e -->
<g id="edge6">
<title>q2-&gt;e</title>
<path fill="none" stroke="black" d="M45.48,-88.28C46.94,-77.14 50.06,-64.13 56.6,-54 62.19,-45.34 70.72,-38.1 79.04,-32.48"></path>
<polygon fill="black" stroke="black" points="80.49,-35.08 87.17,-26.86 76.82,-29.13 80.49,-35.08"></polygon>
<text text-anchor="middle" x="74.23" y="-57.95" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q1&#45;&gt;q2 -->
<g id="edge4">
<title>q1-&gt;q2</title>
<path fill="none" stroke="black" d="M57.41,-190.1C55.27,-177.67 52.59,-162.06 50.21,-148.23"></path>
<polygon fill="black" stroke="black" points="53.53,-147.88 48.39,-138.61 46.63,-149.06 53.53,-147.88"></polygon>
<text text-anchor="middle" x="58.1" y="-158.9" font-family="FiraCode-Regular" font-size="14.00">c</text>
</g>
<!-- q1&#45;&gt;q1 -->
<g id="edge3">
<title>q1-&gt;q1</title>
<path fill="none" stroke="black" d="M83.74,-223.33C94.13,-224.34 103.2,-221.25 103.2,-214.05 103.2,-209.55 99.66,-206.66 94.46,-205.37"></path>
<polygon fill="black" stroke="black" points="94.92,-201.83 84.74,-204.77 94.53,-208.82 94.92,-201.83"></polygon>
<text text-anchor="middle" x="107.7" y="-209.38" font-family="FiraCode-Regular" font-size="14.00">b</text>
</g>
<!-- q1&#45;&gt;e -->
<g id="edge5">
<title>q1-&gt;e</title>
<path fill="none" stroke="black" d="M66.37,-190.41C74.29,-154.65 89.68,-85.2 98.24,-46.58"></path>
<polygon fill="black" stroke="black" points="101.81,-47.63 100.56,-37.11 94.98,-46.11 101.81,-47.63"></polygon>
<text text-anchor="middle" x="93.48" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e&#45;&gt;e -->
<g id="edge7">
<title>e-&gt;e</title>
<path fill="none" stroke="black" d="M121.01,-25.84C130.98,-27.59 140.35,-24.97 140.35,-18 140.35,-13.75 136.87,-11.12 131.9,-10.11"></path>
<polygon fill="black" stroke="black" points="132,-6.61 122.01,-10.16 132.03,-13.61 132,-6.61"></polygon>
<text text-anchor="middle" x="157.23" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
</g>
</svg>

</p>

<p>As we can see, each state has to have defined transition for every possible letter of the alphabet (even if that transition is returning the current state as the next state). So, the size of machine definition (all possible transitions) is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∣</mo><mi>Q</mi><mo>∣</mo><mo>×</mo><mo>∣</mo><mi mathvariant="normal">Σ</mi><mo>∣</mo></mrow><annotation encoding="application/x-tex">\mid Q \mid \times \mid \Sigma \mid</annotation></semantics></math></span></span>.</p>

<p>Additionally, constructing the machine required some effort. We would like to automate the generation of FSM from regular expressions, and creating it in the final version might be troublesome. What we created is actually called <strong>deterministic finite state machine</strong> / <strong>deterministic finite automaton</strong> (<strong>DFA</strong>). It guarantees, that every single time we will deterministically get accepted a state for accepted input and non-accepted state for non-accepted input.</p>

<p>In practice, it is usually easier to define a <strong>non-deterministic finite automaton</strong> (<strong>NFA</strong>). The difference is that NFA <strong>can have several possible state moves for each state-input pair and picks one at random</strong>. So, it cannot match the right input always. However, we can say that <strong>it accepts input if there exists path within a graph, that accepts the whole input</strong>, or it <strong>accepts input if there is a non-zero probability of ending up in accepting state</strong>.</p>

<p>Let’s say we want to parse <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup><mo>∣</mo><mi>a</mi><mi>b</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">a^* \mid aba</annotation></semantics></math></span></span>. It’s an alternative of two regular expressions. The first could be expressed as:</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="178pt" height="162pt" viewBox="0.00 0.00 178.10 162.20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 158.2)">
<!-- q0 -->
<g id="node1">
<title>q0</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="100.35" cy="-113.1" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="100.35" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">q0</text>
<text text-anchor="middle" x="38.25" y="-140.9" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- q0&#45;&gt;q0 -->
<g id="edge1">
<title>q0-&gt;q0</title>
<path fill="none" stroke="black" d="M123.17,-122.42C133.37,-123.3 142.2,-120.2 142.2,-113.1 142.2,-108.77 138.92,-105.93 134.05,-104.57"></path>
<polygon fill="black" stroke="black" points="134.39,-101.02 124.17,-103.78 133.89,-108 134.39,-101.02"></polygon>
<text text-anchor="middle" x="146.33" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e -->
<g id="node2">
<title>e</title>
<ellipse fill="lightgrey" stroke="black" cx="100.35" cy="-18" rx="18" ry="18"></ellipse>
<text text-anchor="middle" x="100.35" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">e</text>
</g>
<!-- q0&#45;&gt;e -->
<g id="edge2">
<title>q0-&gt;e</title>
<path fill="none" stroke="black" d="M100.35,-88.61C100.35,-76.02 100.35,-60.44 100.35,-47.2"></path>
<polygon fill="black" stroke="black" points="103.85,-47.31 100.35,-37.31 96.85,-47.31 103.85,-47.31"></polygon>
<text text-anchor="middle" x="110.85" y="-57.95" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- e&#45;&gt;e -->
<g id="edge3">
<title>e-&gt;e</title>
<path fill="none" stroke="black" d="M117.01,-25.84C126.98,-27.59 136.35,-24.97 136.35,-18 136.35,-13.75 132.87,-11.12 127.9,-10.11"></path>
<polygon fill="black" stroke="black" points="128,-6.61 118.01,-10.16 128.03,-13.61 128,-6.61"></polygon>
<text text-anchor="middle" x="153.23" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
</g>
</svg>

</p>

<p>and the second as:</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="181pt" height="465pt" viewBox="0.00 0.00 181.41 465.05" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 461.05)">
<!-- q0 -->
<g id="node1">
<title>q0</title>
<ellipse fill="lightgrey" stroke="black" cx="122.41" cy="-415.95" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="122.41" y="-411.28" font-family="FiraCode-Regular" font-size="14.00">q0</text>
<text text-anchor="middle" x="60.31" y="-443.75" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- q1 -->
<g id="node3">
<title>q1</title>
<ellipse fill="lightgrey" stroke="black" cx="67.41" cy="-315" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="67.41" y="-310.33" font-family="FiraCode-Regular" font-size="14.00">q1</text>
</g>
<!-- q0&#45;&gt;q1 -->
<g id="edge1">
<title>q0-&gt;q1</title>
<path fill="none" stroke="black" d="M111.01,-394.45C103.2,-380.39 92.7,-361.5 83.96,-345.78"></path>
<polygon fill="black" stroke="black" points="86.71,-344.52 78.79,-337.48 80.59,-347.92 86.71,-344.52"></polygon>
<text text-anchor="middle" x="101.53" y="-360.8" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e -->
<g id="node4">
<title>e</title>
<ellipse fill="lightgrey" stroke="black" cx="77.41" cy="-18" rx="18" ry="18"></ellipse>
<text text-anchor="middle" x="77.41" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">e</text>
</g>
<!-- q0&#45;&gt;e -->
<g id="edge2">
<title>q0-&gt;e</title>
<path fill="none" stroke="black" d="M132.57,-394.27C141.27,-374.62 152.41,-344.01 152.41,-316 152.41,-316 152.41,-316 152.41,-112.1 152.41,-79.05 123.39,-51.09 101.45,-34.68"></path>
<polygon fill="black" stroke="black" points="103.76,-31.32 93.59,-28.37 99.7,-37.02 103.76,-31.32"></polygon>
<text text-anchor="middle" x="162.91" y="-209.38" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q3 -->
<g id="node2">
<title>q3</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="42.41" cy="-113.1" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="42.41" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">q3</text>
</g>
<!-- q3&#45;&gt;e -->
<g id="edge7">
<title>q3-&gt;e</title>
<path fill="none" stroke="black" d="M45.34,-88.61C47.2,-77.79 50.13,-64.96 54.66,-54 56.32,-49.97 58.46,-45.9 60.76,-42.04"></path>
<polygon fill="black" stroke="black" points="64.13,-44.28 66.62,-33.98 58.25,-40.47 64.13,-44.28"></polygon>
<text text-anchor="middle" x="71.28" y="-57.95" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q1&#45;&gt;e -->
<g id="edge4">
<title>q1-&gt;e</title>
<path fill="none" stroke="black" d="M54.27,-294.51C29.26,-254.84 -20.15,-162.28 9.41,-89.25 18.44,-66.95 38.31,-47.8 54.26,-35.16"></path>
<polygon fill="black" stroke="black" points="55.76,-37.65 61.62,-28.83 51.54,-32.08 55.76,-37.65"></polygon>
<text text-anchor="middle" x="13.53" y="-158.9" font-family="FiraCode-Regular" font-size="14.00">a|c</text>
</g>
<!-- q2 -->
<g id="node5">
<title>q2</title>
<ellipse fill="lightgrey" stroke="black" cx="67.41" cy="-214.05" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="67.41" y="-209.38" font-family="FiraCode-Regular" font-size="14.00">q2</text>
</g>
<!-- q1&#45;&gt;q2 -->
<g id="edge3">
<title>q1-&gt;q2</title>
<path fill="none" stroke="black" d="M67.41,-290.8C67.41,-278.27 67.41,-262.57 67.41,-248.72"></path>
<polygon fill="black" stroke="black" points="70.91,-249.11 67.41,-239.11 63.91,-249.11 70.91,-249.11"></polygon>
<text text-anchor="middle" x="71.91" y="-259.85" font-family="FiraCode-Regular" font-size="14.00">b</text>
</g>
<!-- e&#45;&gt;e -->
<g id="edge8">
<title>e-&gt;e</title>
<path fill="none" stroke="black" d="M94.07,-25.84C104.03,-27.59 113.41,-24.97 113.41,-18 113.41,-13.75 109.93,-11.12 104.95,-10.11"></path>
<polygon fill="black" stroke="black" points="105.06,-6.61 95.07,-10.16 105.09,-13.61 105.06,-6.61"></polygon>
<text text-anchor="middle" x="130.28" y="-13.32" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q2&#45;&gt;q3 -->
<g id="edge5">
<title>q2-&gt;q3</title>
<path fill="none" stroke="black" d="M61.74,-190.6C58.52,-177.87 54.44,-161.71 50.85,-147.53"></path>
<polygon fill="black" stroke="black" points="54.08,-146.99 48.23,-138.15 47.29,-148.7 54.08,-146.99"></polygon>
<text text-anchor="middle" x="59.53" y="-158.9" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- q2&#45;&gt;e -->
<g id="edge6">
<title>q2-&gt;e</title>
<path fill="none" stroke="black" d="M74.31,-190.88C82.98,-160.11 95.89,-102.73 88.41,-54 87.99,-51.25 87.39,-48.41 86.68,-45.6"></path>
<polygon fill="black" stroke="black" points="89.79,-44.74 83.61,-36.14 83.07,-46.72 89.79,-44.74"></polygon>
<text text-anchor="middle" x="101.28" y="-108.43" font-family="FiraCode-Regular" font-size="14.00">a|b</text>
</g>
</g>
</svg>

</p>

<p>Now, if we wanted to simply merge these two DFAs, we would have a problem: they both start with accepting <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>, so we would have to know beforehand which one to choose in order to accept a valid input. With NFA we can make some (even all!) of transitions non-deterministic, because we are checking <strong>if a path exists</strong>, and we don’t require that we will always walk it on valid input. So let’s say we have 2 valid choices from an initial state - with an empty string  <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span> go into the first machine or the second machine (yes, we can use the empty string as well!):</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="307pt" height="629pt" viewBox="0.00 0.00 307.00 628.53" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 624.53)">
<g id="clust1">
<title>cluster_astar</title>
<polygon fill="none" stroke="gray" points="8,-310.33 8,-499.17 122,-499.17 122,-310.33 8,-310.33"></polygon>
<text text-anchor="middle" x="65" y="-481.87" font-family="FiraCode-Regular" font-size="14.00" fill="gray">a*</text>
</g>
<g id="clust2">
<title>cluster_aba</title>
<polygon fill="none" stroke="gray" points="130,-8 130,-499.7 291,-499.7 291,-8 130,-8"></polygon>
<text text-anchor="middle" x="210.5" y="-482.4" font-family="FiraCode-Regular" font-size="14.00" fill="gray">aba</text>
</g>
<!-- qa -->
<g id="node1">
<title>qa</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="51" cy="-442.6" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="51" y="-437.93" font-family="FiraCode-Regular" font-size="14.00">qa</text>
</g>
<!-- qa&#45;&gt;qa -->
<g id="edge3">
<title>qa-&gt;qa</title>
<path fill="none" stroke="black" d="M73.11,-451.88C83.36,-452.89 92.32,-449.8 92.32,-442.6 92.32,-438.22 89,-435.35 84.08,-434.02"></path>
<polygon fill="black" stroke="black" points="84.31,-430.46 74.11,-433.32 83.87,-437.45 84.31,-430.46"></polygon>
<text text-anchor="middle" x="96.45" y="-437.93" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e1 -->
<g id="node2">
<title>e1</title>
<ellipse fill="lightgrey" stroke="black" cx="39" cy="-341.65" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="39" y="-336.97" font-family="FiraCode-Regular" font-size="14.00">e1</text>
</g>
<!-- qa&#45;&gt;e1 -->
<g id="edge4">
<title>qa-&gt;e1</title>
<path fill="none" stroke="black" d="M48.22,-418.65C46.68,-405.95 44.73,-389.93 43.03,-375.88"></path>
<polygon fill="black" stroke="black" points="46.41,-375.64 41.73,-366.13 39.46,-376.48 46.41,-375.64"></polygon>
<text text-anchor="middle" x="56.5" y="-387.45" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- e1&#45;&gt;e1 -->
<g id="edge5">
<title>e1-&gt;e1</title>
<path fill="none" stroke="black" d="M60.69,-350.88C71.12,-352.02 80.32,-348.95 80.32,-341.65 80.32,-337.09 76.73,-334.18 71.48,-332.91"></path>
<polygon fill="black" stroke="black" points="71.84,-329.38 61.69,-332.42 71.51,-336.37 71.84,-329.38"></polygon>
<text text-anchor="middle" x="97.2" y="-336.97" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q0 -->
<g id="node3">
<title>q0</title>
<ellipse fill="lightgrey" stroke="black" cx="201" cy="-442.6" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="201" y="-437.93" font-family="FiraCode-Regular" font-size="14.00">q0</text>
</g>
<!-- q1 -->
<g id="node4">
<title>q1</title>
<ellipse fill="lightgrey" stroke="black" cx="201" cy="-341.65" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="201" y="-336.97" font-family="FiraCode-Regular" font-size="14.00">q1</text>
</g>
<!-- q0&#45;&gt;q1 -->
<g id="edge6">
<title>q0-&gt;q1</title>
<path fill="none" stroke="black" d="M201,-418.4C201,-405.87 201,-390.17 201,-376.32"></path>
<polygon fill="black" stroke="black" points="204.5,-376.7 201,-366.7 197.5,-376.7 204.5,-376.7"></polygon>
<text text-anchor="middle" x="205.12" y="-387.45" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e2 -->
<g id="node7">
<title>e2</title>
<ellipse fill="lightgrey" stroke="black" cx="208" cy="-39.32" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="208" y="-34.65" font-family="FiraCode-Regular" font-size="14.00">e2</text>
</g>
<!-- q0&#45;&gt;e2 -->
<g id="edge7">
<title>q0-&gt;e2</title>
<path fill="none" stroke="black" d="M211.87,-420.99C233.59,-377.38 279.19,-272.31 266,-181.6 259.26,-135.28 256.27,-122.84 236,-80.65 233.76,-76 231.02,-71.29 228.13,-66.81"></path>
<polygon fill="black" stroke="black" points="230.66,-65.31 222.12,-59.04 224.89,-69.27 230.66,-65.31"></polygon>
<text text-anchor="middle" x="278.5" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q2 -->
<g id="node5">
<title>q2</title>
<ellipse fill="lightgrey" stroke="black" cx="182" cy="-240.7" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="182" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">q2</text>
</g>
<!-- q1&#45;&gt;q2 -->
<g id="edge8">
<title>q1-&gt;q2</title>
<path fill="none" stroke="black" d="M196.69,-318.2C194.23,-305.38 191.1,-289.08 188.36,-274.82"></path>
<polygon fill="black" stroke="black" points="191.68,-274.57 186.36,-265.41 184.81,-275.89 191.68,-274.57"></polygon>
<text text-anchor="middle" x="196.5" y="-286.5" font-family="FiraCode-Regular" font-size="14.00">b</text>
</g>
<!-- q1&#45;&gt;e2 -->
<g id="edge9">
<title>q1-&gt;e2</title>
<path fill="none" stroke="black" d="M209.81,-319.2C225.12,-279.13 253.66,-190.25 239,-115.9 235.92,-100.27 229.57,-83.8 223.42,-70.24"></path>
<polygon fill="black" stroke="black" points="226.25,-69.04 218.81,-61.5 219.92,-72.03 226.25,-69.04"></polygon>
<text text-anchor="middle" x="252.12" y="-185.55" font-family="FiraCode-Regular" font-size="14.00">a|c</text>
</g>
<!-- q3 -->
<g id="node6">
<title>q3</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="162" cy="-139.75" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="162" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">q3</text>
</g>
<!-- q2&#45;&gt;q3 -->
<g id="edge10">
<title>q2-&gt;q3</title>
<path fill="none" stroke="black" d="M177.46,-217.25C174.89,-204.52 171.62,-188.36 168.76,-174.17"></path>
<polygon fill="black" stroke="black" points="172.07,-173.91 166.66,-164.8 165.21,-175.3 172.07,-173.91"></polygon>
<text text-anchor="middle" x="177.12" y="-185.55" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- q2&#45;&gt;e2 -->
<g id="edge11">
<title>q2-&gt;e2</title>
<path fill="none" stroke="black" d="M189.13,-217.9C197.75,-190.32 211.74,-141.19 217,-97.9 217.99,-89.75 217.45,-80.99 216.25,-72.81"></path>
<polygon fill="black" stroke="black" points="219.54,-72.35 214.28,-63.15 212.65,-73.62 219.54,-72.35"></polygon>
<text text-anchor="middle" x="224.5" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q3&#45;&gt;e2 -->
<g id="edge12">
<title>q3-&gt;e2</title>
<path fill="none" stroke="black" d="M169.15,-115.97C172.87,-105.07 177.78,-91.96 183.25,-80.65 185.22,-76.57 187.49,-72.38 189.84,-68.32"></path>
<polygon fill="black" stroke="black" points="193.19,-70.53 195.36,-60.16 187.2,-66.92 193.19,-70.53"></polygon>
<text text-anchor="middle" x="199.88" y="-84.6" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- e2&#45;&gt;e2 -->
<g id="edge13">
<title>e2-&gt;e2</title>
<path fill="none" stroke="black" d="M229.69,-48.46C240.12,-49.59 249.32,-46.54 249.32,-39.32 249.32,-34.81 245.73,-31.93 240.48,-30.68"></path>
<polygon fill="black" stroke="black" points="240.83,-27.15 230.69,-30.19 240.52,-34.14 240.83,-27.15"></polygon>
<text text-anchor="middle" x="266.2" y="-34.65" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q00 -->
<g id="node8">
<title>q00</title>
<ellipse fill="lightgrey" stroke="black" cx="125" cy="-573.11" rx="30.16" ry="30.16"></ellipse>
<text text-anchor="middle" x="125" y="-568.44" font-family="FiraCode-Regular" font-size="14.00">q00</text>
<text text-anchor="middle" x="56.59" y="-607.23" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- q00&#45;&gt;qa -->
<g id="edge1">
<title>q00-&gt;qa</title>
<path fill="none" stroke="black" d="M110.2,-546.42C98,-525.23 80.7,-495.18 67.95,-473.03"></path>
<polygon fill="black" stroke="black" points="70.64,-471.69 62.61,-464.77 64.57,-475.18 70.64,-471.69"></polygon>
<text text-anchor="start" x="96" y="-511.65" font-family="FiraCode-Regular" font-size="14.00">ϵ</text>
</g>
<!-- q00&#45;&gt;q0 -->
<g id="edge2">
<title>q00-&gt;q0</title>
<path fill="none" stroke="black" d="M140.02,-546.72C152.6,-525.44 170.58,-495.05 183.75,-472.77"></path>
<polygon fill="black" stroke="black" points="187.17,-474.86 189.25,-464.47 181.15,-471.29 187.17,-474.86"></polygon>
<text text-anchor="start" x="163" y="-511.65" font-family="FiraCode-Regular" font-size="14.00">ϵ</text>
</g>
</g>
</svg>

</p>

<p>(<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">q_0</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>s were relabelled to distinct which one came from which automaton).</p>

<p>What would we have to do to make it deterministic? In this particular case, we can notice, that:</p>

<ul>
  <li>correct input is either empty or starts with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>,</li>
  <li>if it starts with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> what comes next is either a sequence of more <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>s or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">ba</annotation></semantics></math></span></span>.</li>
</ul>

<p>Let’s modify our NFA for that observation:</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="395pt" height="556pt" viewBox="0.00 0.00 394.75 556.31" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 552.31)">
<g id="clust1">
<title>cluster_astar</title>
<polygon fill="none" stroke="gray" points="177,-108.42 177,-297.27 291,-297.27 291,-108.42 177,-108.42"></polygon>
<text text-anchor="middle" x="234" y="-279.97" font-family="FiraCode-Regular" font-size="14.00" fill="gray">a*</text>
</g>
<g id="clust2">
<title>cluster_aba</title>
<polygon fill="none" stroke="gray" points="8,-8 8,-540.31 169,-540.31 169,-8 8,-8"></polygon>
<text text-anchor="middle" x="88.5" y="-523.01" font-family="FiraCode-Regular" font-size="14.00" fill="gray">aba</text>
</g>
<!-- qa -->
<g id="node1">
<title>qa</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="213" cy="-240.7" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="213" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">qa</text>
</g>
<!-- qa&#45;&gt;qa -->
<g id="edge6">
<title>qa-&gt;qa</title>
<path fill="none" stroke="black" d="M235.11,-249.98C245.36,-250.99 254.32,-247.9 254.32,-240.7 254.32,-236.31 251,-233.45 246.08,-232.12"></path>
<polygon fill="black" stroke="black" points="246.31,-228.56 236.11,-231.42 245.87,-235.55 246.31,-228.56"></polygon>
<text text-anchor="middle" x="258.45" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e1 -->
<g id="node2">
<title>e1</title>
<ellipse fill="lightgrey" stroke="black" cx="208" cy="-139.75" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="208" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">e1</text>
</g>
<!-- qa&#45;&gt;e1 -->
<g id="edge7">
<title>qa-&gt;e1</title>
<path fill="none" stroke="black" d="M211.83,-216.5C211.19,-203.88 210.39,-188.05 209.69,-174.12"></path>
<polygon fill="black" stroke="black" points="213.15,-174.27 209.15,-164.46 206.16,-174.63 213.15,-174.27"></polygon>
<text text-anchor="middle" x="220.5" y="-185.55" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- e1&#45;&gt;e1 -->
<g id="edge16">
<title>e1-&gt;e1</title>
<path fill="none" stroke="black" d="M229.69,-148.98C240.12,-150.12 249.32,-147.04 249.32,-139.75 249.32,-135.19 245.73,-132.28 240.48,-131.01"></path>
<polygon fill="black" stroke="black" points="240.84,-127.48 230.69,-130.52 240.51,-134.47 240.84,-127.48"></polygon>
<text text-anchor="middle" x="266.2" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q0 -->
<g id="node3">
<title>q0</title>
<ellipse fill="lightgrey" stroke="black" cx="61" cy="-483.21" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="61" y="-478.54" font-family="FiraCode-Regular" font-size="14.00">q0</text>
</g>
<!-- q1 -->
<g id="node4">
<title>q1</title>
<ellipse fill="lightgrey" stroke="black" cx="40" cy="-370.16" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="40" y="-365.49" font-family="FiraCode-Regular" font-size="14.00">q1</text>
</g>
<!-- q0&#45;&gt;q1 -->
<g id="edge9">
<title>q0-&gt;q1</title>
<path fill="none" stroke="black" d="M56.7,-459.47C53.71,-443.68 49.68,-422.37 46.33,-404.64"></path>
<polygon fill="black" stroke="black" points="49.59,-404.05 44.29,-394.87 42.71,-405.35 49.59,-404.05"></polygon>
<text text-anchor="middle" x="56.12" y="-421.75" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e2 -->
<g id="node7">
<title>e2</title>
<ellipse fill="lightgrey" stroke="black" cx="57" cy="-39.32" rx="23.32" ry="23.32"></ellipse>
<text text-anchor="middle" x="57" y="-34.65" font-family="FiraCode-Regular" font-size="14.00">e2</text>
</g>
<!-- q0&#45;&gt;e2 -->
<g id="edge10">
<title>q0-&gt;e2</title>
<path fill="none" stroke="black" d="M65.2,-459.57C68.04,-443.07 71.53,-420.13 73,-399.8 82.7,-265.81 64.01,-232.11 58,-97.9 57.65,-90.09 57.42,-81.69 57.27,-73.77"></path>
<polygon fill="black" stroke="black" points="60.76,-73.98 57.11,-64.03 53.76,-74.08 60.76,-73.98"></polygon>
<text text-anchor="middle" x="85.5" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q2 -->
<g id="node5">
<title>q2</title>
<ellipse fill="lightgrey" stroke="black" cx="136" cy="-240.7" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="136" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">q2</text>
</g>
<!-- q1&#45;&gt;q2 -->
<g id="edge11">
<title>q1-&gt;q2</title>
<path fill="none" stroke="black" d="M54.82,-351.07C66.51,-336.67 83.09,-315.91 97,-297.27 103.59,-288.44 110.57,-278.64 116.78,-269.77"></path>
<polygon fill="black" stroke="black" points="120.09,-272.14 122.92,-261.93 114.34,-268.15 120.09,-272.14"></polygon>
<text text-anchor="middle" x="94.5" y="-309.22" font-family="FiraCode-Regular" font-size="14.00">b</text>
</g>
<!-- q1&#45;&gt;e2 -->
<g id="edge12">
<title>q1-&gt;e2</title>
<path fill="none" stroke="black" d="M34.85,-346.51C24.57,-297.08 4.75,-176.31 32,-80.65 33.27,-76.19 35.19,-71.75 37.41,-67.52"></path>
<polygon fill="black" stroke="black" points="40.87,-69.55 42.98,-59.17 34.85,-65.97 40.87,-69.55"></polygon>
<text text-anchor="middle" x="29.12" y="-185.55" font-family="FiraCode-Regular" font-size="14.00">a|c</text>
</g>
<!-- q3 -->
<g id="node6">
<title>q3</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="137" cy="-139.75" rx="23.85" ry="23.85"></ellipse>
<text text-anchor="middle" x="137" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">q3</text>
</g>
<!-- q2&#45;&gt;q3 -->
<g id="edge13">
<title>q2-&gt;q3</title>
<path fill="none" stroke="black" d="M136.23,-216.5C136.36,-204.27 136.51,-189.03 136.65,-175.43"></path>
<polygon fill="black" stroke="black" points="140.16,-175.53 136.76,-165.49 133.16,-175.45 140.16,-175.53"></polygon>
<text text-anchor="middle" x="141.12" y="-185.55" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- q2&#45;&gt;e2 -->
<g id="edge14">
<title>q2-&gt;e2</title>
<path fill="none" stroke="black" d="M120.71,-222.17C108.69,-207.49 92.46,-185.47 83,-163.6 70.45,-134.57 63.78,-99 60.35,-73.55"></path>
<polygon fill="black" stroke="black" points="63.75,-73.45 59.04,-63.96 56.8,-74.32 63.75,-73.45"></polygon>
<text text-anchor="middle" x="93.5" y="-135.07" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q3&#45;&gt;e2 -->
<g id="edge15">
<title>q3-&gt;e2</title>
<path fill="none" stroke="black" d="M121.95,-120.24C109.62,-105.06 92.01,-83.4 78.24,-66.46"></path>
<polygon fill="black" stroke="black" points="80.46,-64.64 71.44,-59.09 75.03,-69.06 80.46,-64.64"></polygon>
<text text-anchor="middle" x="118.88" y="-84.6" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- e2&#45;&gt;e2 -->
<g id="edge17">
<title>e2-&gt;e2</title>
<path fill="none" stroke="black" d="M78.69,-48.46C89.12,-49.59 98.32,-46.54 98.32,-39.32 98.32,-34.81 94.73,-31.93 89.48,-30.68"></path>
<polygon fill="black" stroke="black" points="89.83,-27.15 79.69,-30.19 89.52,-34.14 89.83,-27.15"></polygon>
<text text-anchor="middle" x="115.2" y="-34.65" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
<!-- q00 -->
<g id="node8">
<title>q00</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="287" cy="-483.21" rx="30.16" ry="30.16"></ellipse>
<text text-anchor="middle" x="287" y="-478.54" font-family="FiraCode-Regular" font-size="14.00">q00</text>
<text text-anchor="middle" x="218.59" y="-517.33" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- q0a -->
<g id="node9">
<title>q0a</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="227" cy="-370.16" rx="29.64" ry="29.64"></ellipse>
<text text-anchor="middle" x="227" y="-365.49" font-family="FiraCode-Regular" font-size="14.00">q0a</text>
</g>
<!-- q00&#45;&gt;q0a -->
<g id="edge1">
<title>q00-&gt;q0a</title>
<path fill="none" stroke="black" d="M272.63,-455.61C264.7,-440.95 254.76,-422.54 246.18,-406.67"></path>
<polygon fill="black" stroke="black" points="248.88,-405.29 241.05,-398.16 242.72,-408.62 248.88,-405.29"></polygon>
<text text-anchor="middle" x="264.12" y="-421.75" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- e -->
<g id="node10">
<title>e</title>
<ellipse fill="lightgrey" stroke="black" cx="317" cy="-240.7" rx="18" ry="18"></ellipse>
<text text-anchor="middle" x="317" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">e</text>
</g>
<!-- q00&#45;&gt;e -->
<g id="edge2">
<title>q00-&gt;e</title>
<path fill="none" stroke="black" d="M290.68,-452.72C296.51,-405.99 307.79,-315.53 313.5,-269.73"></path>
<polygon fill="black" stroke="black" points="317.1,-270.2 314.86,-259.84 310.15,-269.33 317.1,-270.2"></polygon>
<text text-anchor="middle" x="314.5" y="-365.49" font-family="FiraCode-Regular" font-size="14.00">b|c</text>
</g>
<!-- q0a&#45;&gt;qa -->
<g id="edge3">
<title>q0a-&gt;qa</title>
<path fill="none" stroke="black" d="M223.79,-339.92C221.69,-320.78 218.93,-295.71 216.73,-275.69"></path>
<polygon fill="black" stroke="black" points="220.12,-275.42 215.54,-265.86 213.16,-276.18 220.12,-275.42"></polygon>
<text text-anchor="middle" x="225.12" y="-309.22" font-family="FiraCode-Regular" font-size="14.00">a</text>
</g>
<!-- q0a&#45;&gt;q2 -->
<g id="edge4">
<title>q0a-&gt;q2</title>
<path fill="none" stroke="black" d="M208.9,-345.77C198.25,-331.84 184.63,-313.71 173,-297.27 166.9,-288.66 160.46,-279.14 154.69,-270.45"></path>
<polygon fill="black" stroke="black" points="157.17,-268.85 148.75,-262.43 151.33,-272.71 157.17,-268.85"></polygon>
<text text-anchor="middle" x="195.5" y="-309.22" font-family="FiraCode-Regular" font-size="14.00">b</text>
</g>
<!-- q0a&#45;&gt;e -->
<g id="edge5">
<title>q0a-&gt;e</title>
<path fill="none" stroke="black" d="M249.54,-349.57C264.04,-336.04 282.45,-316.98 295,-297.27 300.59,-288.5 305.18,-278.07 308.69,-268.63"></path>
<polygon fill="black" stroke="black" points="312.22,-270.13 312.19,-259.54 305.61,-267.84 312.22,-270.13"></polygon>
<text text-anchor="middle" x="291.75" y="-309.22" font-family="FiraCode-Regular" font-size="14.00">c</text>
</g>
<!-- e&#45;&gt;e -->
<g id="edge8">
<title>e-&gt;e</title>
<path fill="none" stroke="black" d="M332.92,-249.41C343.15,-251.69 353,-248.78 353,-240.7 353,-235.65 349.15,-232.62 343.77,-231.61"></path>
<polygon fill="black" stroke="black" points="343.79,-228.14 333.92,-231.98 344.03,-235.14 343.79,-228.14"></polygon>
<text text-anchor="middle" x="369.88" y="-236.02" font-family="FiraCode-Regular" font-size="14.00">a|b|c</text>
</g>
</g>
</svg>

</p>

<p>Let us think for a moment what happened here. We now have a <strong>deterministic</strong> version of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup><mo>∣</mo><mi>a</mi><mi>b</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">a^* \mid aba</annotation></semantics></math></span></span> expression! In order to remove non-determinism, we had to look ahead to determine which branch we should go with. That was achieved by introducing and using extra states - which could be mapped into a corresponding state in either of branches - until we received the first piece of information, that would make it clear, which branch we need to go from now on because the other is no longer an option:</p>

<ul>
  <li>if we just started we could assume that if nothing arrives we are OK,</li>
  <li>however if we got <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>, there is uncertainty - should we expect following <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">a^*</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">ba</annotation></semantics></math></span></span>, so we carry on the information that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> arrived and we will delay our decision,</li>
  <li>if nothing else arrives we are at valid input so we accept the state,</li>
  <li>if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> arrives we finally resolved ambiguity - from now on, we can simply go into a branch directly copy-pasted from the original DFA that created.</li>
</ul>

<p>Of course, this could be optimized a bit - states <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>,  <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span></span> could be merged into one, while states <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">q_0</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span></span> are inaccessible so we can remove them. This way we would arrive at the final DFA.</p>

<p>The process, that we showed here is called <strong>determination of NFA</strong>. In practice, this tracing of things until we have enough data to finally decide, requires us to create a node for each combination of “it can go here” and “it can go there”, so we effectively end up <a href="https://en.wikipedia.org/wiki/Powerset_construction">building a powerset</a>. This means that in the worst case we would have to turn our <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>-state NFA into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^n</annotation></semantics></math></span></span> DFA before we even run optimizer! Once we’ve done that, testing if a string is accepted by the language is relatively cheap and requires going through the whole input once. This is an important observation, because using regular expressions is so simple nowadays, that we can forget that building a matcher is itself a costly operation (<strong>very costly</strong>).</p>

<p>That explains, why in older generations of compilers the proffered flow was to <a href="https://www.gnu.org/software/flex/">generate source code with already build DFA</a> which could be compiled into a native code, that didn’t require any building in the runtime - you paid the cost of building DFA once before you even started the compilation of a program.</p>

<p>However, it is not the most comfortable flow, especially, since now we have a bit faster computers and a bit higher requirements about the speed of delivery and software maintenance. For that reason, we have 2 alternatives: <a href="https://swtch.com/~rsc/regexp/regexp1.html">one based on a lazy evaluation</a> - you build the required pieces of DFA lazily as you go through the parsed input, or with the usage of backtracking. The former is done by simulating NFA internally and building DFA states on demand. The later is probably the easiest way to implement regular expression, though the resulting implementation is no longer <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Θ</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Theta(n)</annotation></semantics></math></span></span> but <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(2^n)</annotation></semantics></math></span></span>. (Confusingly, the algorithm is called NFA, though the implementation is not a finite-state automaton at all).</p>

<h3 id="regular-expressions-in-practice">Regular expressions in practice</h3>

<p>The format(s) used to describe regular expressions are directly taken from, how regular languages are defined: each symbol normally represents itself (so regexp <code>a</code> would match <code>a</code>), <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span>/<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> after an expression represent Kleenie star/plus (0 or more, 1 or more repetitions of an input - <code>a*</code> would match empty string, <code>a</code>, <code>aa</code>, …), concatenation of expressions represents concatenated language (<code>aa</code> would match <code>aa</code>, <code>a+b</code> would match <code>ab</code>, <code>aab</code>, …). Or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∣</mo></mrow><annotation encoding="application/x-tex">\mid</annotation></semantics></math></span></span> or a sum of regular languages is represented by <code>|</code> (<code>a|b</code> matches <code>a</code>, <code>b</code>).  Parenthesis can be used to clarify in which order regular expression are concatenated (<code>ab+</code> means <code>(ab)+</code>, so if we wanted <code>a(b+)</code> the parenthesis helps us achieve what we want). There are also some utilities like <code>[abc]</code> which translates to <code>(a|b|c)</code> and allows us to use ranges instead of listing all characters manually (e.g. <code>[a-z]</code> represents <code>(a|b|c|...|z)</code>), <code>?</code> which means zero or one occurrence (<code>a?</code> is the same as<code>(|a)</code>) or predefined sets of symbols like <code>\s</code> (whitespace character), <code>\S</code> (non-whitespace character) and so on. For details, you can always consult the manual for the particular implementation that you are using.</p>

<p>If you are interested about the process of implementing regular expressions and building finite state machines out of the regexp format I recommend getting a book like <em>Compilers: Principles, Techniques, and Tools</em> by Aho, Lam, Sethi, and Ullman. There are too many details about implementations which aren’t interesting to the majority of the readers to justify rewriting and shortening them just so they would fit into this short article.</p>

<p>Since we got familiar with RE, we can try out a bit more powerful category of languages.</p>

<h2 id="context-free-grammars-and-push-down-automata">Context-Free Grammars and Push-Down Automata</h2>

<p>Any finite state machine can store a constant amount of information - namely the current state, which is a single element of a set of values defined upfront. It doesn’t let us dynamically store some additional data for the future and then retrieve data stored somewhere in the past.</p>

<p>An example of a problem, that could be solved, if we had this ability is checking if a word is a <em>palindrome</em>, that is you read it the same way left-to-right and right-to-left. <em>Anna</em>, <em>exe</em>, <em>yay</em> would be palindromes (assuming case doesn’t matter). <em>Anne</em>, <em>axe</em>, <em>ay-ay</em> would not be. If we wanted to check for some specific palindrome, we could use a finite state machine. But if we wanted to check for any? <em>A</em>. <em>Aba</em>.  <em>Ab(5-million b’s)c(5-million b’s)ba</em>. No matter what kind of FSA we came up with is easy to find a word that it would not match, but which is a valid palindrome.</p>

<p>But let’s say, we are a bit more flexible than finite state automaton. What kind of information would be helpful in deciding if we are on the right track? We could, for instance, write each letter on a piece of paper, e.g. sticky notes. We met <em>a</em>, we write down <em>a</em> and stick it to someplace. Then, we see <em>b</em>, we write it down and stick it on top of a previous sticky note. Now, let’s go non-deterministic. It some point if we see the same letter arriving as we see on the top of the sticky notes stack, we don’t add a new one, but take the top one instead - we are <em>guessing</em>, that we are in the middle of a palindrome. Then each time top note patches with an incoming letter you take it off. If you had an even-length palindrome you should end up with an empty stack. Well, we would have to think a bit more to handle the odd-length case as well, but hey! We are on the right track as the length of the word is no longer an issue!</p>

<p>What helped us get there? We had a state-machine of sorts with 2 states: <em>insert-card-mode</em> (push) and <em>take-matching-card-mode</em> (pop) (for odd-length palindrome we could use a third state for skipping over one letter - the middle one - without pushing and popping anything). Then we had a <strong>stack</strong> that we can push things on top, take a look at the top element, and take an element from the top. Actually, this data structure (which could be also thought of as a <em>last-in-first-out queue</em>) is <strong>really named stack</strong>. In combination with finite state automaton, it creates <strong>push-down automaton</strong> (<strong>PDA</strong>).</p>

<p>As a matter of the fact, what we defined for our palindrome problem is an example of <strong>non-deterministic push-down automaton</strong>. We could define deterministic PDAs (DPDA) as a 7-tuple <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi><mo separator="true">,</mo><mi mathvariant="normal">Γ</mi><mo separator="true">,</mo><mi>δ</mi><mo separator="true">,</mo><msub><mi>q</mi><mn>0</mn></msub><mo separator="true">,</mo><mi>Z</mi><mo separator="true">,</mo><mi>F</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Q, \Sigma, \Gamma, \delta, q_0, Z, F)</annotation></semantics></math></span></span>, where:</p>

<ul>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span> is a finite set of <strong>states</strong>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span></span> is a finite set of <strong>input symbols</strong> or an <strong>input alphabet</strong>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> is a finite set of <strong>stack symbols</strong> or a <strong>stack alphabet</strong> (because we can use different sets for input and stack, e.g. the later could be a superset of the former),</li>
  <li>a <strong>transition function</strong> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>:</mo><mi>Q</mi><mo>×</mo><mi mathvariant="normal">Σ</mi><mo>×</mo><mi mathvariant="normal">Γ</mi><mo>→</mo><mi>Q</mi><mo>×</mo><msup><mi mathvariant="normal">Γ</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\delta: Q \times \Sigma \times \Gamma \rightarrow Q \times \Gamma^*</annotation></semantics></math></span></span>, which would take the current state, the top (popped) stack symbol and next input symbol (possibly empty) to return the next state and what to push to stack (which can be represented as a word made of a stack alphabet) ,</li>
  <li>an <strong>initial state</strong> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>0</mn></msub><mo>∈</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">q_0 \in Q</annotation></semantics></math></span></span>,</li>
  <li>an initial stack symbol <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>∈</mo><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">Z \in \Gamma</annotation></semantics></math></span></span>,</li>
  <li>a set of accepting states <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>⊆</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">F \subseteq Q</annotation></semantics></math></span></span>.</li>
</ul>

<p>A non-deterministic version (NDPDA) would allow <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span></span> as a valid symbol in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span></span>, and return several possible values in transition function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span></span> instead of one.</p>

<p>The palindrome example showed us that there are problems that PDA can solve that FSA cannot. However, PDA can solve all problems that FSA - all you need to do is basically ignore the stack in your transition function, and you get the FSA. Therefore, <strong>push-down automata are a strict superset of finite-state automata</strong>.</p>

<p>But we were supposed to talk about formal languages. Just like finite-state machines are related to regular languages, pushdown automata are related to <strong>context-free grammars</strong>. Reminder: it’s a formal language where all production rules are in the form of:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>→</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">A \rightarrow \gamma</annotation></semantics></math></span></span></span>

<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">A \in N</annotation></semantics></math></span></span> (non-terminals) and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>∈</mo><mo stretchy="false">(</mo><mi>N</mi><mo>∪</mo><mi mathvariant="normal">Σ</mi><msup><mo stretchy="false">)</mo><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\gamma \in (N \cup \Sigma)^+</annotation></semantics></math></span></span> (non-terminals and terminals). Another reminder: with CFG we are parsing structures, that are basically trees (in case of programming languages, where this tree represent the language’s syntax it’s called <strong>abstract syntax tree</strong>), and terminals are these parts of the syntax which are leaves of the tree, while non-terminals are nodes. The names come from the fact, that when you expand the tree according to production rules, you have to end up with terminals in all leaves. They are <em>the ends</em> of the tree.</p>

<p>Thing is, when we are parsing, we are actually given a sequence of terminals, and we must combine them into non-terminals until we get to the root of the project. Kind of opposite to what we are given in language description. How could that look like? Let’s do some motivating example.</p>

<p>Normally when we describe the order of arithmetic operations like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo></mrow><annotation encoding="application/x-tex">-</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>÷</mo></mrow><annotation encoding="application/x-tex">\div</annotation></semantics></math></span></span> we are inserting them in-between numbers. Because operations have priorities (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span></span>/<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>÷</mo></mrow><annotation encoding="application/x-tex">\div</annotation></semantics></math></span></span> before <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span>/<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo></mrow><annotation encoding="application/x-tex">-</annotation></semantics></math></span></span>) if we want to change the default order we have to use parenthesis (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>+</mo><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 + 2 \times 2</annotation></semantics></math></span></span> vs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">(2 + 2) \times 2</annotation></semantics></math></span></span>). This is called <strong>infix notation</strong> as the operator is between operands. But, you could use alternative notations: one where operator is before operands (<strong>prefix notation</strong> aka <a href="https://en.wikipedia.org/wiki/Polish_notation"><strong>Polish notation</strong></a>) or after operands (<strong>postfix notation</strong> aka <a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation"><strong>Reverse Polish notation</strong>/<strong>RPN</strong></a>). Both of them doesn’t require usage of parenthesis, as the order of operation is unambiguous due to their position. The later is quite useful when you are working with compilers.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mn>3</mn><mo>+</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1 + 2) \times (3 + 4)</annotation></semantics></math></span></span></span>

<p>becomes</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>1</mn><mtext>&nbsp;</mtext><mn>2</mn><mtext>&nbsp;</mtext><mo>+</mo><mtext>&nbsp;</mtext><mn>3</mn><mtext>&nbsp;</mtext><mn>4</mn><mtext>&nbsp;</mtext><mo>+</mo><mtext>&nbsp;</mtext><mo>×</mo></mrow><annotation encoding="application/x-tex">1\ 2\ +\ 3\ 4\ +\ \times</annotation></semantics></math></span></span></span>

<p>When it comes to calculating the value of such expression, we can use stack:</p>

<ul>
  <li>we start with an empty stack,</li>
  <li>when we see the number, we push it to the stack,</li>
  <li>when we see <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> we take the top 2 elements on the stack, we add them and we push the result to the stack,</li>
  <li>same with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span></span>, take 2 top elements from the stack, multiply them and push the result to the stack,</li>
  <li>at the end the result of our calculation would be on top of a stack.</li>
</ul>

<p>Let’s check for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext>&nbsp;</mtext><mn>2</mn><mtext>&nbsp;</mtext><mo>+</mo><mtext>&nbsp;</mtext><mn>3</mn><mtext>&nbsp;</mtext><mn>4</mn><mtext>&nbsp;</mtext><mo>+</mo><mtext>&nbsp;</mtext><mo>×</mo></mrow><annotation encoding="application/x-tex">1\ 2\ +\ 3\ 4\ +\ \times</annotation></semantics></math></span></span>:</p>

<ul>
  <li>we start with an empty stack,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> arrives, we push it to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span></span> arrives, we push it to the stack,</li>
  <li>stack is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext>&nbsp;</mtext><mn>2</mn></mrow><annotation encoding="application/x-tex">1\ 2</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> arrives, we take 2 top elements from the stack (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext>&nbsp;</mtext><mn>2</mn></mrow><annotation encoding="application/x-tex">1\ 2</annotation></semantics></math></span></span>), add them (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span></span>) and push the result to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span></span> arrives, we push it to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mtext>&nbsp;</mtext><mn>3</mn></mrow><annotation encoding="application/x-tex">3\ 3</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span></span> arrives, we push it to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mtext>&nbsp;</mtext><mn>3</mn><mtext>&nbsp;</mtext><mn>4</mn></mrow><annotation encoding="application/x-tex">3\ 3\ 4</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> arrives, we take 2 top elements from the stack (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mtext>&nbsp;</mtext><mn>4</mn></mrow><annotation encoding="application/x-tex">3\ 4</annotation></semantics></math></span></span>), add them (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span></span>) and push the result to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mtext>&nbsp;</mtext><mn>7</mn></mrow><annotation encoding="application/x-tex">3\ 7</annotation></semantics></math></span></span>,</li>
  <li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span></span> arrives, we take 2 top elements from the stack (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mtext>&nbsp;</mtext><mn>7</mn></mrow><annotation encoding="application/x-tex">3\ 7</annotation></semantics></math></span></span>), multiply them (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span>) and push the result to the stack,</li>
  <li>stack is: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span>,</li>
  <li>input ends, so our result is the only number on stack (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span>).</li>
</ul>

<p>If you ever wrote (or will write) a compiler, that outputs assembler or bytecode, or something similar low-level - that’s basically how you write down expressions. If there is an expression in an infix form, you translate it into postfix, as it pretty much aligns with how mnemonics works in many architectures.</p>

<blockquote>
  <p>To be precise, quite a lot of them would require you to have the added/multiplied/etc values in registers instead of stack, however to implement a whole expression you probably use stack and copy data from stack to registers and vice-versa, but is an implementation detail irrelevant to what we want to show here.</p>
</blockquote>

<p>Of course, the example above is not a valid grammar. We cannot have a potentially infinite number of non-terminals (numbers) and production rules (basically all results of addition/multiplication/etc). But we can describe the general idea of postfix arithmetics:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>r</mi><mi>y</mi><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo>→</mo><mo>+</mo><mo>∣</mo><mo>−</mo><mo>∣</mo><mo>×</mo><mo>∣</mo><mo>÷</mo></mrow><annotation encoding="application/x-tex">BinaryOperator \rightarrow + \mid - \mid \times \mid \div</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>→</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">∣</mi><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>B</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>r</mi><mi>y</mi><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">Expression \rightarrow Number | Expression\ Expression\ BinaryOperator</annotation></semantics></math></span></span></span>

<p>We have terminals <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi><mo>=</mo><mo stretchy="false">{</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mo>+</mo><mo separator="true">,</mo><mo>−</mo><mo separator="true">,</mo><mo>×</mo><mo separator="true">,</mo><mo>÷</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Sigma = \{ Number, +, -, \times, \div \}</annotation></semantics></math></span></span> and non-terminals <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mo stretchy="false">{</mo><mi>B</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>r</mi><mi>y</mi><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo separator="true">,</mo><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">N = \{BinaryOperator, Expression\}</annotation></semantics></math></span></span>. We could create an ADT:</p>

<div><pre><code><span>sealed</span> <span>trait</span> <span>Terminal</span>

<span>final</span> <span>case</span> <span>class</span> <span>Number</span><span>(</span><span>value</span><span>:</span> <span>java.lang.Number</span><span>)</span>
    <span>extends</span> <span>Terminal</span>

<span>sealed</span> <span>trait</span> <span>BinaryOperator</span>
<span>case</span> <span>object</span> <span>Plus</span> <span>extends</span> <span>BinaryOperator</span> <span>with</span> <span>Terminal</span>
<span>case</span> <span>object</span> <span>Minus</span> <span>extends</span> <span>BinaryOperator</span> <span>with</span> <span>Terminal</span>
<span>case</span> <span>object</span> <span>Times</span> <span>extends</span> <span>BinaryOperator</span> <span>with</span> <span>Terminal</span>
<span>case</span> <span>object</span> <span>Div</span> <span>extends</span> <span>BinaryOperator</span> <span>with</span> <span>Terminal</span>

<span>sealed</span> <span>trait</span> <span>Expression</span>
<span>final</span> <span>case</span> <span>class</span> <span>FromNumber</span><span>(</span><span>number</span><span>:</span> <span>Number</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>final</span> <span>case</span> <span>class</span> <span>FromBinary</span><span>(</span><span>operand1</span><span>:</span> <span>Expression</span><span>,</span>
                            <span>operand2</span><span>:</span> <span>Expression</span><span>,</span>
                            <span>bin</span><span>:</span> <span>BinaryOperator</span><span>)</span>
    <span>extends</span> <span>Expression</span>
</code></pre></div>

<p>and now it should be possible to somehow translate <code>List[Terminal]</code> into <code>Expression</code>. (Assuming the input is a correct example of this grammar - if it isn’t we should fail). In this very simple example, it could actually be done in a similar way we evaluated the expression:</p>

<ul>
  <li>if <code>Terminal</code> is <code>Number</code>, wrap it with <code>FromNumber</code> push it to the stack,</li>
  <li>if <code>Terminal</code> is <code>BinaryOperation,</code> we take 2 <code>Expression</code>s from the stack, put it as <code>operand1</code> and <code>operand2</code>, and together with <code>BinaryOperator</code> put it into <code>FromBinary</code> and push to stack,</li>
  <li>if the input is correct, we should end up with a stack with a single element,</li>
  <li>if the input is incorrect, we should end up with a stack with more than one element, or during one of the operations we will miss some <code>Expression</code>s while popping on a stack.</li>
</ul>

<p>It is <em>almost</em> enough to represent our language as PDA. To create a binary operation we look at the two elements on top of the stack, while it is legal to only know one. But we could, represent that as a state. Initial stack symbol could be a single <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>m</mi><mi>p</mi><mi>t</mi><mi>y</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">EmptyStack</annotation></semantics></math></span></span>. Actually, we could also make sure that we end up with an empty stack at the end - if there are elements on stack, it’s an error (becasue no operator consumed some elements). If at some point we are missing some elements it’s also an error. We could end up with something like:</p>

<p>
  <!-- Generated by graphviz version 8.0.5 (20230430.1635)
 -->
<!-- Pages: 1 -->
<svg width="1179pt" height="1013pt" viewBox="0.00 0.00 1179.21 1012.91" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 1008.91)">
<!-- CheckingMode -->
<g id="node1">
<title>CheckingMode</title>
<ellipse fill="lightgrey" stroke="black" stroke-width="2" cx="330.46" cy="-309.93" rx="82.77" ry="82.77"></ellipse>
<text text-anchor="middle" x="330.46" y="-305.25" font-family="FiraCode-Regular" font-size="14.00">CheckingMode</text>
</g>
<!-- Error -->
<g id="node5">
<title>Error</title>
<ellipse fill="lightgrey" stroke="black" cx="477.46" cy="-34.9" rx="34.9" ry="34.9"></ellipse>
<text text-anchor="middle" x="477.46" y="-30.22" font-family="FiraCode-Regular" font-size="14.00">Error</text>
</g>
<!-- CheckingMode&#45;&gt;Error -->
<g id="edge8">
<title>CheckingMode-&gt;Error</title>
<path fill="none" stroke="black" d="M248.54,-293.55C132.78,-268.29 -56.81,-211.78 16.71,-123.05 69.14,-59.77 325.44,-42.1 431.44,-37.45"></path>
<polygon fill="black" stroke="black" points="431.56,-40.91 441.41,-36.99 431.27,-33.91 431.56,-40.91"></polygon>
<text text-anchor="start" x="17.46" y="-143.8" font-family="FiraCode-Regular" font-size="14.00">Number|+|-|×|÷, pop: x, push: x</text>
</g>
<!-- CheckingMode&#45;&gt;Error -->
<g id="edge9">
<title>CheckingMode-&gt;Error</title>
<path fill="none" stroke="black" d="M284.68,-240.3C266.16,-203.29 253.94,-158.15 276.96,-123.05 311.13,-70.93 383.96,-49.81 431.79,-41.37"></path>
<polygon fill="black" stroke="black" points="432.18,-44.69 441.48,-39.62 431.05,-37.79 432.18,-44.69"></polygon>
<text text-anchor="start" x="277.46" y="-143.8" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: Number, push: Number</text>
</g>
<!-- OK -->
<g id="node6">
<title>OK</title>
<ellipse fill="lightgrey" stroke="black" cx="528.46" cy="-148.48" rx="25.43" ry="25.43"></ellipse>
<text text-anchor="middle" x="528.46" y="-143.8" font-family="FiraCode-Regular" font-size="14.00">OK</text>
</g>
<!-- CheckingMode&#45;&gt;OK -->
<g id="edge10">
<title>CheckingMode-&gt;OK</title>
<path fill="none" stroke="black" d="M395.02,-256.94C430.86,-228.07 473.59,-193.66 500.86,-171.7"></path>
<polygon fill="black" stroke="black" points="502.55,-174.03 508.15,-165.03 498.16,-168.57 502.55,-174.03"></polygon>
<text text-anchor="start" x="475.46" y="-195.85" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: EmptyStack, push: EmptyStack</text>
</g>
<!-- PushSymbol -->
<g id="node2">
<title>PushSymbol</title>
<ellipse fill="lightgrey" stroke="black" cx="516.46" cy="-517.15" rx="71.2" ry="71.2"></ellipse>
<text text-anchor="middle" x="516.46" y="-512.48" font-family="FiraCode-Regular" font-size="14.00">PushSymbol</text>
<text text-anchor="middle" x="407.01" y="-592.3" font-family="FiraCode-Regular" font-size="14.00">initial state</text>
</g>
<!-- PushSymbol&#45;&gt;CheckingMode -->
<g id="edge3">
<title>PushSymbol-&gt;CheckingMode</title>
<path fill="none" stroke="black" d="M469.04,-463.84C446.02,-438.44 418.05,-407.57 393.28,-380.24"></path>
<polygon fill="black" stroke="black" points="396.35,-378.32 387.05,-373.26 391.17,-383.02 396.35,-378.32"></polygon>
<text text-anchor="start" x="435.46" y="-414.65" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: x, push: x</text>
</g>
<!-- PushSymbol&#45;&gt;PushSymbol -->
<g id="edge1">
<title>PushSymbol-&gt;PushSymbol</title>
<path fill="none" stroke="black" d="M586.02,-534.2C597.64,-531.82 605.66,-526.13 605.66,-517.15 605.66,-511.12 602.04,-506.58 596.14,-503.52"></path>
<polygon fill="black" stroke="black" points="597.61,-499.99 587.02,-500.11 595.38,-506.62 597.61,-499.99"></polygon>
<text text-anchor="middle" x="724.53" y="-512.48" font-family="FiraCode-Regular" font-size="14.00">Number, pop: x, push: x+Number</text>
</g>
<!-- Pop2Numbers -->
<g id="node3">
<title>Pop2Numbers</title>
<ellipse fill="lightgrey" stroke="black" cx="848.46" cy="-924.76" rx="80.14" ry="80.14"></ellipse>
<text text-anchor="middle" x="848.46" y="-920.09" font-family="FiraCode-Regular" font-size="14.00">Pop2Numbers</text>
</g>
<!-- PushSymbol&#45;&gt;Pop2Numbers -->
<g id="edge2">
<title>PushSymbol-&gt;Pop2Numbers</title>
<path fill="none" stroke="black" d="M521.86,-588.6C529.72,-648.38 549.03,-733.43 596.46,-791.37 638.82,-843.12 706.81,-877.16 761.5,-897.74"></path>
<polygon fill="black" stroke="black" points="759.96,-901.27 770.55,-901.43 762.37,-894.7 759.96,-901.27"></polygon>
<text text-anchor="start" x="596.46" y="-711.81" font-family="FiraCode-Regular" font-size="14.00">+|-|×|÷, pop: x, push: x</text>
</g>
<!-- Pop1Number -->
<g id="node4">
<title>Pop1Number</title>
<ellipse fill="lightgrey" stroke="black" cx="848.46" cy="-716.49" rx="74.88" ry="74.88"></ellipse>
<text text-anchor="middle" x="848.46" y="-711.81" font-family="FiraCode-Regular" font-size="14.00">Pop1Number</text>
</g>
<!-- Pop2Numbers&#45;&gt;Pop1Number -->
<g id="edge4">
<title>Pop2Numbers-&gt;Pop1Number</title>
<path fill="none" stroke="black" d="M848.46,-844.31C848.46,-830.69 848.46,-816.5 848.46,-802.74"></path>
<polygon fill="black" stroke="black" points="851.96,-802.83 848.46,-792.83 844.96,-802.83 851.96,-802.83"></polygon>
<text text-anchor="start" x="848.46" y="-813.32" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: Number</text>
</g>
<!-- Pop2Numbers&#45;&gt;Error -->
<g id="edge5">
<title>Pop2Numbers-&gt;Error</title>
<path fill="none" stroke="black" d="M918.09,-884.25C971.26,-848.35 1035.46,-789.99 1035.46,-717.49 1035.46,-717.49 1035.46,-717.49 1035.46,-147.48 1035.46,-43.34 657.02,-35.05 523.46,-35.37"></path>
<polygon fill="black" stroke="black" points="523.77,-31.87 513.79,-35.41 523.8,-38.87 523.77,-31.87"></polygon>
<text text-anchor="start" x="1035.46" y="-414.65" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: EmptyStack</text>
</g>
<!-- Pop1Number&#45;&gt;PushSymbol -->
<g id="edge6">
<title>Pop1Number-&gt;PushSymbol</title>
<path fill="none" stroke="black" d="M784.44,-677.44C727.75,-643.74 645.13,-594.63 586.64,-559.87"></path>
<polygon fill="black" stroke="black" points="588.86,-556.52 578.47,-554.42 585.28,-562.54 588.86,-556.52"></polygon>
<text text-anchor="start" x="691.46" y="-610.3" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: Number</text>
</g>
<!-- Pop1Number&#45;&gt;Error -->
<g id="edge7">
<title>Pop1Number-&gt;Error</title>
<path fill="none" stroke="black" d="M861.03,-642.63C866.4,-605.49 871.46,-559.54 871.46,-518.15 871.46,-518.15 871.46,-518.15 871.46,-147.48 871.46,-120.23 877.61,-106.13 857.46,-87.8 809.4,-44.09 613.86,-36.86 523.57,-35.89"></path>
<polygon fill="black" stroke="black" points="523.86,-32.39 513.83,-35.8 523.8,-39.39 523.86,-32.39"></polygon>
<text text-anchor="start" x="871.46" y="-305.25" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: EmptyStack</text>
</g>
<!-- Error&#45;&gt;Error -->
<g id="edge13">
<title>Error-&gt;Error</title>
<path fill="none" stroke="black" d="M510.78,-46.43C521.68,-46.37 530.36,-42.53 530.36,-34.9 530.36,-30.01 526.79,-26.68 521.37,-24.89"></path>
<polygon fill="black" stroke="black" points="522.17,-21.33 511.78,-23.36 521.17,-28.26 522.17,-21.33"></polygon>
<text text-anchor="start" x="530.36" y="-30.22" font-family="FiraCode-Regular" font-size="14.00">Number|+|-|×|÷, pop: x, push: x</text>
</g>
<!-- OK&#45;&gt;Error -->
<g id="edge12">
<title>OK-&gt;Error</title>
<path fill="none" stroke="black" d="M506.44,-134.88C496.01,-127.62 484.57,-117.47 478.71,-105.05 475.18,-97.57 473.45,-89.12 472.82,-80.75"></path>
<polygon fill="black" stroke="black" points="476.3,-80.81 472.56,-70.89 469.3,-80.98 476.3,-80.81"></polygon>
<text text-anchor="start" x="479.46" y="-91.75" font-family="FiraCode-Regular" font-size="14.00">Number|+|-|×|÷, pop: EmptyStack, push: EmptyStack</text>
</g>
<!-- OK&#45;&gt;OK -->
<g id="edge11">
<title>OK-&gt;OK</title>
<path fill="none" stroke="black" d="M552.13,-158.08C562.72,-159 571.89,-155.8 571.89,-148.48 571.89,-143.9 568.31,-140.93 563.04,-139.58"></path>
<polygon fill="black" stroke="black" points="563.34,-136.02 553.13,-138.87 562.89,-143.01 563.34,-136.02"></polygon>
<text text-anchor="start" x="571.89" y="-143.8" font-family="FiraCode-Regular" font-size="14.00">ϵ, pop: EmptyStack, push: EmptyStack</text>
</g>
</g>
</svg>

</p>

<p>This PDA doesn’t calculate the value of RPN. It only checks if it is valid. We are pushing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">Number</annotation></semantics></math></span></span>s on a stack, and on a binary operation, we consume 2 <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">Number</annotation></semantics></math></span></span>s from the stack. At any point we can start “checking” - if we are at the end of input, a stack is empty (meaning that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>m</mi><mi>p</mi><mi>t</mi><mi>y</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">EmptyStack</annotation></semantics></math></span></span> is the top element) we can assume that the input was correct so we move to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">OK</annotation></semantics></math></span></span> through <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>h</mi><mi>e</mi><mi>c</mi><mi>k</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">CheckingMode</annotation></semantics></math></span></span>. However, if we start checking and there is some input left or there are elements on the stack - we are erring.</p>

<p>To make sure we understand what happened here we should remember that this is non-deterministic PDA - so for each valid input there <em>should exist</em> a valid path (and each path ending in an accepted state should describe a valid input), but we don’t have to necessarily walk it each time. The other thing is that on each step of PDA we have to pop from stack - if we don’t want to change stack we have to pop the same element back, if we want to add something we can pop 2 elements or more and if we want to get rid of top elements, then we simply don’t pop it back.</p>

<h3 id="parsers-in-practice">Parsers in practice</h3>

<p>Actually, there are 2 approaches to parsing context-free grammars:</p>

<ul>
  <li><strong>top-down</strong> approach: We start from the root of the AST tree and take a look at the possible transitions. We try to make a prediction - if we get the next alphabet element, do we know, which transition to go? If that is not enough you could try to look at transitions going from these transitions and check if any prediction is possible to do know, etc. We don’t necessarily look <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> symbol ahead to determine our path - we could set some <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> and assume that we can look up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> symbols ahead before making a decision (which would be potentially reflected in the number of states). If our language contains recursion it might affect how we can and what is the minimal number of lookahead to decide. We are parsing input <strong>left-to-right</strong>, and the top-down strategy with lookahead will make us choose branch basing on <strong>leftmost</strong> non-terminal. That is why this approach is called <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> (left-to-right, leftmost derivation). The <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> parser with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> tokens lookahead is called <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LL(k)</annotation></semantics></math></span></span>,</li>
  <li><strong>bottom-up</strong> approach: We start with terminals and look at the production rules in reverse - we try to combine incoming terminals into terminals and then terminals and non-terminals until we get to the root. (This is what we have done in the PDA example above). Just like with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> we might need to make some predictions so we can look ahead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> elements. Just like with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> we read <strong>left-to-right</strong>. However, <em>contrary</em> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> we can make a decision when we get <em>the last element</em> of a production rule, <strong>rightmost</strong> non-terminal. This is why this approach is called <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LR</annotation></semantics></math></span></span> and if our parser requires <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> tokens lookahead it is an example of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LR(k)</annotation></semantics></math></span></span> parser. For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span></span> we can use some specific, simple implementation like <em>Simple LR</em> (<em>SLR</em>). There is also general implementation of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LR(k)</annotation></semantics></math></span></span> called <em>look-ahead <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LR(k)</annotation></semantics></math></span></span></em> (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>A</mi><mi>L</mi><mi>R</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LALR(k)</annotation></semantics></math></span></span>) which, for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span></span> are called simply <em>LALR</em>.</li>
</ul>

<p>Both approaches are usually used to build a parsing table, though they differ in how you arrive at the final table.</p>

<p>With <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LL(k)</annotation></semantics></math></span></span> you can pretend that you can look ahead <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> chars while simply applying production rules - that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-symbol lookahead is simulated by adding additional states. When we simulate seeing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>th symbol ahead, we are actually already at this symbol, but with state transitions arranged, so that we end up in a state that we should end up if we really were <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> symbols ago and made the decision based on a prediction. Notice, that for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span></span> this basically means that we are always following first matching production rule and never going back, which results in a quite simple parser.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LR(k)</annotation></semantics></math></span></span>, on the other hand, uses things called <strong>shift</strong> and <strong>reduce</strong>. Shift advances parsing by one symbol (<em>shifts</em> it by one symbol) (which doesn’t apply any production rule), while reduce combines (<em>reduces</em>) several non-terminals and/or terminals into a single terminal (goes into the reverse direction of production rule). When an algorithm generates such a table for an input we passed it, we might see a complaint about <em>shift-reduction conflict</em> - since well-defined LR grammar should for each PDA assign either a <em>shift</em> operation or a <em>reduce</em> operation, it shows that there is an ambiguity in the grammar, that the parser generator managed to resolve (and produce a working code), but which will bite us by <em>parsing some inputs not the way we wanted</em>.</p>

<p>For defining context-free grammars parser generators quite often use syntax heavily influenced by <strong>(extended) Backus-Naur form</strong> ((E)BNF). In EBNF, the previous example:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>r</mi><mi>y</mi><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo>→</mo><mo>+</mo><mo>∣</mo><mo>−</mo><mo>∣</mo><mo>×</mo><mo>∣</mo><mo>÷</mo></mrow><annotation encoding="application/x-tex">BinaryOperator \rightarrow + \mid - \mid \times \mid \div</annotation></semantics></math></span></span></span>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>→</mo><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">∣</mi><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>E</mi><mi>x</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>B</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>r</mi><mi>y</mi><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">Expression \rightarrow Number | Expression\ Expression\ BinaryOperator</annotation></semantics></math></span></span></span>

<p>could look like this:</p>

<div><pre><code>binary operator = "+" | "-" | "*" | "/" ;
digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;
number = number, digit | digit ;
expression = number, | expression, expression binary operator ;
</code></pre></div>

<p>Notice, that here terminal symbols are defined as digits. It might be quite inconvenient, which is why a lot of parser generators would rather:</p>

<ul>
  <li>assume that terminals are results of regular expression matching - the input would be matched against a set of regular expressions, each of which would be related to a terminal symbol. We would require them to accept whole input as a sequence of words matched by any of regular expressions. This way we would turn a sequence of input symbols into a sequence of terminal symbols. The part of a program responsible for this <strong>tokenization</strong> is called <strong>lexer</strong>.  Such approach is seen e.g. with parser generators based on <code>lex</code> (lexer) and <code>yacc</code> (Yet Another Compiler-Compiler) and their GNU reimplementations <code>flex</code> (free lex) and <code>bison</code> (an allusion to gnu as a lot of GNU tooling is based on <code>bison</code>). (It should also explain why certain languages have weird rules regarding class/method/function/variable names - since tokenization takes place in the very beginning, it has to reliable classify each piece of code unambiguously as a terminal symbol),</li>
  <li>alternatively allow you to use regular expressions directly in a parser-defining syntax. As this approach is much more readable it was also used in <em>parser combinators</em>.</li>
</ul>

<p>Right, we haven’t mentioned parser combinators. What are they, and why they became more popular recently?</p>

<h3 id="parser-combinators">Parser combinators</h3>

<p>When computer resources were really scarce, we didn’t have the comfort of building parsers in the most convenient way - the idea behind parsing generators was generating fast, ready to use PDA which would parse input with linear time and memory (that is, directly proportional to the input). Overhead had to be limited to the minimum, so the best way was to do all the calculations (both lexing and parsing) during code generation, so when we would run the program, it would be able to parse as soon as the code was loaded from the disk to the memory. All in all generating imperative code was the way to go.</p>

<p>But nowadays the situation is different. We have much faster computers with a lot more memory. And the requirements we have regarding programs are much higher, so the process of validating the parsed input became much more complex - so small overhead for parsing is not as painful. Additionally, we made much more progress when it comes to functional programming.</p>

<p>This opened the gate to an alternative approach called parser combinators (which is <em>not that new</em> considering, that it was described in <em>Recursive programming Techniques</em> by Burge from 1975 as <em>parsing functions</em>). What we do is basically, a function composition.</p>

<p>Let’s try by example. This time we’ll try to implement infix syntax. At first we’ll do something about lexing terminal symbols (and using spaces for separation):</p>

<div><pre><code><span>def</span> <span>number</span><span>(</span><span>input</span><span>:</span> <span>String</span><span>)</span> <span>=</span> <span>"""\s*([0-9]+)(\s*)"""</span>
    <span>.</span><span>r</span>
    <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
    <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
       <span>val</span> <span>terminal</span> <span>=</span> <span>Number</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>1</span><span>).</span><span>toInt</span><span>)</span>
       <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
      <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
    <span>}</span>

<span>def</span> <span>plus</span><span>(</span><span>input</span><span>:</span> <span>String</span><span>)</span> <span>=</span> <span>"""\s*(\+)(\s*)"""</span>
    <span>.</span><span>r</span>
    <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
    <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
       <span>val</span> <span>terminal</span> <span>=</span> <span>Plus</span>
       <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
      <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
    <span>}</span>

<span>def</span> <span>minus</span><span>(</span><span>input</span><span>:</span> <span>String</span><span>)</span> <span>=</span> <span>"""\s*(-)(\s*)"""</span>
    <span>.</span><span>r</span>
    <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
    <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
       <span>val</span> <span>terminal</span> <span>=</span> <span>Minus</span>
       <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
      <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
    <span>}</span>

<span>def</span> <span>times</span><span>(</span><span>input</span><span>:</span> <span>String</span><span>)</span> <span>=</span> <span>"""\s*(\*)(\s*)"""</span>
    <span>.</span><span>r</span>
    <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
    <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
       <span>val</span> <span>terminal</span> <span>=</span> <span>Times</span>
       <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
      <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
    <span>}</span>

<span>def</span> <span>div</span><span>(</span><span>input</span><span>:</span> <span>String</span><span>)</span> <span>=</span> <span>"""\s*(\/)(\s*)"""</span>
    <span>.</span><span>r</span>
    <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
    <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
       <span>val</span> <span>terminal</span> <span>=</span> <span>Div</span>
       <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
      <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
    <span>}</span>
</code></pre></div>

<p>It’s quite repetitive so we can introduce a helper utility:</p>

<div><pre><code><span>type</span> <span>Parser</span><span>[</span><span>+A</span><span>]</span> <span>=</span> <span>String</span> <span>=&gt;</span> <span>Option</span><span>[(</span><span>A</span>, <span>String</span><span>)]</span>

<span>object</span> <span>Parser</span><span>{</span>
  
  <span>def</span> <span>apply</span><span>[</span><span>A</span><span>](</span><span>re</span><span>:</span> <span>String</span><span>)(</span><span>f</span><span>:</span> <span>String</span> <span>=&gt;</span> <span>A</span><span>)</span><span>:</span> <span>Parser</span><span>[</span><span>A</span><span>]</span> <span>=</span>
    <span>input</span> <span>=&gt;</span> <span>s</span><span>"""\\s*($re)(\\s*)"""</span><span>.</span><span>r</span>
      <span>.</span><span>findPrefixMatchOf</span><span>(</span><span>input</span><span>)</span>
      <span>.</span><span>map</span> <span>{</span> <span>n</span> <span>=&gt;</span>
        <span>val</span> <span>terminal</span> <span>=</span> <span>f</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>1</span><span>))</span>
        <span>val</span> <span>unmatched</span> <span>=</span> <span>input</span><span>.</span><span>substring</span><span>(</span><span>n</span><span>.</span><span>group</span><span>(</span><span>0</span><span>).</span><span>length</span><span>)</span>
        <span>terminal</span> <span>-&gt;</span> <span>unmatched</span>
      <span>}</span>
<span>}</span>
</code></pre></div>

<p>and simplify definitions a bit:</p>

<div><pre><code><span>val</span> <span>number</span> <span>=</span> <span>Parser</span><span>[</span><span>Number</span><span>](</span><span>"""[0-9]+"""</span><span>)(</span><span>n</span> <span>=&gt;</span> <span>Number</span><span>(</span><span>n</span><span>.</span><span>toInt</span><span>))</span>
<span>val</span> <span>plus</span> <span>=</span> <span>Parser</span><span>[</span><span>Plus.</span><span>type</span><span>](</span><span>"""\+"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>Plus</span><span>)</span>
<span>val</span> <span>minus</span> <span>=</span> <span>Parser</span><span>[</span><span>Minus.</span><span>type</span><span>](</span><span>"""-"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>Minus</span><span>)</span>
<span>val</span> <span>times</span> <span>=</span> <span>Parser</span><span>[</span><span>Times.</span><span>type</span><span>](</span><span>"""\*"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>Times</span><span>)</span>
<span>val</span> <span>div</span> <span>=</span> <span>Parser</span><span>[</span><span>Div.</span><span>type</span><span>](</span><span>"""\/"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>Div</span><span>)</span>
</code></pre></div>

<p>then we could start combining them:</p>

<div><pre><code><span>val</span> <span>binaryOperator</span><span>:</span> <span>Parser</span><span>[</span><span>BinaryOperator</span><span>]</span> <span>=</span> <span>in</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span><span>in</span><span>.</span><span>isEmpty</span><span>)</span> <span>None</span>
  <span>else</span> <span>plus</span><span>(</span><span>in</span><span>)</span> <span>orElse</span> <span>minus</span><span>(</span><span>in</span><span>)</span> <span>orElse</span> <span>times</span><span>(</span><span>in</span><span>)</span> <span>orElse</span> <span>div</span><span>(</span><span>in</span><span>)</span>
<span>}</span>
</code></pre></div>

<p>The curious reader might notice that this is a good candidate for a ReaderT/Kleisli composition, but we’ll try to keep this example as simple as possible. That is why we’ll create some specific utility for this case:</p>

<div><pre><code><span>implicit</span> <span>class</span> <span>ParserOps</span><span>[</span><span>A</span><span>](</span><span>parser</span><span>:</span> <span>Parser</span><span>[</span><span>A</span><span>])</span> <span>{</span>
  
  <span>// making another by-name param helps to prevent</span>
  <span>// stack overflow in some recursive definitions</span>
  
  <span>def</span> <span>|</span><span>[</span><span>B</span> <span>&gt;:</span> <span>A</span><span>](</span><span>another</span><span>:</span> <span>=&gt;</span> <span>Parser</span><span>[</span><span>B</span><span>])</span><span>:</span> <span>Parser</span><span>[</span><span>B</span><span>]</span> <span>=</span>
    <span>input</span> <span>=&gt;</span> <span>if</span> <span>(</span><span>input</span><span>.</span><span>isEmpty</span><span>)</span> <span>None</span>
             <span>else</span> <span>parser</span><span>(</span><span>input</span><span>)</span> <span>orElse</span> <span>another</span><span>(</span><span>input</span><span>)</span>
<span>}</span>
</code></pre></div>

<p>and rewrite <code>binaryOperator</code> as:</p>

<div><pre><code><span>val</span> <span>binaryOperator</span><span>:</span> <span>Parser</span><span>[</span><span>BinaryOperator</span><span>]</span> <span>=</span>
  <span>plus</span> <span>|</span> <span>minus</span> <span>|</span> <span>times</span> <span>|</span> <span>div</span>
</code></pre></div>

<p>Now we are missing the concatenation - or moving input forward as we matched something already:</p>

<div><pre><code><span>def</span> <span>expression</span><span>:</span> <span>Parser</span><span>[</span><span>Expression</span><span>]</span> <span>=</span> <span>{</span>
  <span>val</span> <span>fromNumber</span><span>:</span> <span>Parser</span><span>[</span><span>FromNumber</span><span>]</span> <span>=</span> <span>in</span> <span>=&gt;</span> <span>{</span>
    <span>number</span><span>(</span><span>in</span><span>).</span><span>map</span> <span>{</span> <span>case</span> <span>(</span><span>n</span><span>,</span> <span>in2</span><span>)</span> <span>=&gt;</span> <span>FromNumber</span><span>(</span><span>n</span><span>)</span> <span>-&gt;</span> <span>in2</span> <span>}</span>
  <span>}</span>  
  
  <span>def</span> <span>fromBinary</span><span>:</span> <span>Parser</span><span>[</span><span>FromBinary</span><span>]</span> <span>=</span> <span>in</span> <span>=&gt;</span> <span>for</span> <span>{</span>
    <span>(</span><span>ex1</span><span>,</span> <span>in2</span><span>)</span> <span>&lt;-</span> <span>(</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)(</span><span>in</span><span>)</span>
    <span>(</span><span>bin</span><span>,</span> <span>in3</span><span>)</span> <span>&lt;-</span> <span>binaryOperator</span><span>(</span><span>in2</span><span>)</span>
    <span>(</span><span>ex2</span><span>,</span> <span>in4</span><span>)</span> <span>&lt;-</span> <span>(</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)(</span><span>in3</span><span>)</span>
  <span>}</span> <span>yield</span> <span>FromBinary</span><span>(</span><span>ex1</span><span>,</span> <span>ex2</span><span>,</span> <span>bin</span><span>)</span> <span>-&gt;</span> <span>in4</span>
  
  <span>fromBinary</span> <span>|</span> <span>fromNumber</span>
<span>}</span>

<span>def</span> <span>inParenthesis</span><span>:</span> <span>Parser</span><span>[</span><span>Expression</span><span>]</span> <span>=</span> <span>in</span> <span>=&gt;</span> <span>for</span> <span>{</span>
  <span>(</span><span>_</span><span>,</span> <span>in2</span><span>)</span> <span>&lt;-</span> <span>Parser</span><span>[</span><span>Unit</span><span>](</span><span>"""\("""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>())(</span><span>in</span><span>)</span>
  <span>(</span><span>ex</span><span>,</span> <span>in3</span><span>)</span> <span>&lt;-</span> <span>expression</span><span>(</span><span>in2</span><span>)</span>
  <span>(</span><span>_</span><span>,</span> <span>in4</span><span>)</span> <span>&lt;-</span> <span>Parser</span><span>[</span><span>Unit</span><span>](</span><span>"""\)"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>())(</span><span>in3</span><span>)</span>
<span>}</span> <span>yield</span> <span>ex</span> <span>-&gt;</span> <span>in4</span>
</code></pre></div>

<p>If we tested that code (which now looks like a candidate for a state monad) we would find that it parses one step of the way (so it doesn’t run recursion infinitely):</p>

<div><pre><code><span>expression</span><span>(</span><span>""" 12  + 23 """</span><span>)</span>
<span>res1</span><span>:</span> <span>Option</span><span>[(</span><span>Expression</span>, <span>String</span><span>)]</span> <span>=</span>
  <span>Some</span><span>((</span><span>FromBinary</span><span>(</span><span>FromNumber</span><span>(</span><span>Number</span><span>(</span><span>12</span><span>)),</span> <span>FromNumber</span><span>(</span><span>Number</span><span>(</span><span>23</span><span>)),</span> <span>Plus</span><span>),</span> <span>""</span><span>))</span>
</code></pre></div>

<p>We can prettify the code a bit:</p>

<div><pre><code><span>implicit</span> <span>class</span> <span>ParserOps</span><span>[</span><span>A</span><span>](</span><span>parser</span><span>:</span> <span>Parser</span><span>[</span><span>A</span><span>])</span> <span>{</span>
  
  <span>def</span> <span>|</span><span>[</span><span>B</span> <span>&gt;:</span> <span>A</span><span>](</span><span>another</span><span>:</span> <span>=&gt;</span> <span>Parser</span><span>[</span><span>B</span><span>])</span><span>:</span> <span>Parser</span><span>[</span><span>B</span><span>]</span> <span>=</span>
    <span>input</span> <span>=&gt;</span> <span>if</span> <span>(</span><span>input</span><span>.</span><span>isEmpty</span><span>)</span> <span>None</span>
             <span>else</span> <span>parser</span><span>(</span><span>input</span><span>)</span> <span>orElse</span> <span>another</span><span>(</span><span>input</span><span>)</span>
  
  <span>def</span> <span>&amp;</span><span>[</span><span>B</span><span>](</span><span>another</span><span>:</span> <span>=&gt;</span> <span>Parser</span><span>[</span><span>B</span><span>])</span><span>:</span> <span>Parser</span><span>[(</span><span>A</span>, <span>B</span><span>)]</span> <span>=</span>
    <span>input</span> <span>=&gt;</span> <span>if</span> <span>(</span><span>input</span><span>.</span><span>isEmpty</span><span>)</span> <span>None</span>
             <span>else</span> <span>for</span> <span>{</span>
               <span>(</span><span>a</span><span>,</span> <span>in2</span><span>)</span> <span>&lt;-</span> <span>parser</span><span>(</span><span>input</span><span>)</span>
               <span>(</span><span>b</span><span>,</span> <span>in3</span><span>)</span> <span>&lt;-</span> <span>another</span><span>(</span><span>in2</span><span>)</span>
             <span>}</span> <span>yield</span> <span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>in3</span>
  
  <span>def</span> <span>map</span><span>[</span><span>B</span><span>](</span><span>f</span><span>:</span> <span>A</span> <span>=&gt;</span> <span>B</span><span>)</span><span>:</span> <span>Parser</span><span>[</span><span>B</span><span>]</span> <span>=</span>
    <span>input</span> <span>=&gt;</span> <span>parser</span><span>(</span><span>input</span><span>).</span><span>map</span> <span>{</span> <span>case</span> <span>(</span><span>a</span><span>,</span> <span>in2</span><span>)</span> <span>=&gt;</span> <span>f</span><span>(</span><span>a</span><span>)</span> <span>-&gt;</span> <span>in2</span> <span>}</span>
<span>}</span>
</code></pre></div>

<div><pre><code><span>def</span> <span>expression</span><span>:</span> <span>Parser</span><span>[</span><span>Expression</span><span>]</span> <span>=</span> <span>{</span>
  <span>def</span> <span>fromNumber</span> <span>=</span>
    <span>number</span><span>.</span><span>map</span><span>(</span><span>FromNumber</span><span>(</span><span>_</span><span>))</span>
  
  <span>def</span> <span>fromBinary</span> <span>=</span> 
    <span>((</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)</span> <span>&amp;</span>
      <span>binaryOperator</span> <span>&amp;</span>
     <span>(</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)).</span><span>map</span> <span>{</span>
      <span>case</span> <span>((</span><span>ex1</span><span>,</span> <span>bin</span><span>),</span> <span>ex2</span><span>)</span> <span>=&gt;</span> <span>FromBinary</span><span>(</span><span>ex1</span><span>,</span> <span>ex2</span><span>,</span> <span>bin</span><span>)</span>
    <span>}</span>
  
  <span>fromBinary</span> <span>|</span> <span>fromNumber</span>
<span>}</span>

<span>def</span> <span>inParenthesis</span><span>:</span> <span>Parser</span><span>[</span><span>Expression</span><span>]</span> <span>=</span> 
  <span>(</span><span>Parser</span><span>[</span><span>Unit</span><span>](</span><span>"""\("""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>())</span> <span>&amp;</span>
   <span>expression</span> <span>&amp;</span>
   <span>Parser</span><span>[</span><span>Unit</span><span>](</span><span>"""\)"""</span><span>)(</span><span>_</span> <span>=&gt;</span> <span>())).</span><span>map</span> <span>{</span>
    <span>case</span> <span>((</span><span>_</span><span>,</span> <span>ex</span><span>),</span> <span>_</span><span>)</span> <span>=&gt;</span> <span>ex</span>
  <span>}</span>
</code></pre></div>

<div><pre><code><span>expression</span><span>(</span><span>""" 12 + 23 """</span><span>).</span><span>map</span><span>(</span><span>_</span><span>.</span><span>_1</span><span>).</span><span>foreach</span><span>(</span><span>println</span><span>)</span>
<span>// FromBinary(FromNumber(Number(12)),FromNumber(Number(23)),Plus)</span>
</code></pre></div>

<p>(Complete example you can see on <a href="https://gist.github.com/MateuszKubuszok/dda5253281e59c75b7b669a1164a3db8">gist</a>).</p>

<p>Not bad! It already shows us the potential of <strong>creating small parsers and composing them as higher order functions</strong>. It should also explain to us why such a concept was named <strong>parser combinators</strong>.</p>

<p>But, can we have parser combinators out-of-the-box? We would need an implementation which:</p>

<ul>
  <li>is statically typed,</li>
  <li>gives us concatenation <code>&amp;</code>, alternative <code>|</code>, and <code>map</code>ping of parsers,</li>
  <li>let us gives suggestions if certain matching should be <em>greedy</em> (match whatever it can, potentially indefinitely) or <em>lazy</em> (finish ASAP),</li>
  <li>is probably more complex than a simple function from input into output with the unmatched part. It could e.g. make use of lookahead,</li>
  <li>give us a lot of utilities like e.g. regular expression support.</li>
</ul>

<p>Luckily for us, such implementation already exists, so we can just use it. <a href="http://www.lihaoyi.com/fastparse">FastParse</a> is a parser combinator library written by Li Haoyi (the same guy who created Ammonite and Mill). While it provides us a nice, functional interface, it uses Scala macros to generate fast code with little overhead (which gives us hardly any reason for considering parser generators, at least for Scala).</p>

<p>Our parser can be rewritten into fastparse this way:</p>

<div><pre><code><span>// import $ivy.`com.lihaoyi::fastparse:2.1.0`</span>
<span>import</span> <span>fastparse._</span>
<span>import</span> <span>ScalaWhitespace._</span> <span>// gives us Scala commens</span>
                         <span>// and whitespaces out-of-the-box</span>

<span>object</span> <span>Parsers</span> <span>{</span>
  
  <span>// terminals</span>
  <span>def</span> <span>number</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span>
    <span>P</span><span>(</span> <span>CharIn</span><span>(</span><span>"0-9"</span><span>).</span><span>rep</span><span>(</span><span>1</span><span>).!).</span><span>map</span><span>(</span><span>n</span> <span>=&gt;</span> <span>Number</span><span>(</span><span>n</span><span>.</span><span>toInt</span><span>)</span> <span>)</span>
                      <span>// ! makes parser catch input as String</span>
  <span>def</span> <span>plus</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span><span>"+"</span><span>).</span><span>map</span><span>(</span><span>_</span> <span>=&gt;</span> <span>Plus</span><span>)</span>
  <span>def</span> <span>minus</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span><span>"-"</span><span>).</span><span>map</span><span>(</span><span>_</span> <span>=&gt;</span> <span>Minus</span><span>)</span>
  <span>def</span> <span>times</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span><span>"*"</span><span>).</span><span>map</span><span>(</span><span>_</span> <span>=&gt;</span> <span>Times</span><span>)</span>
  <span>def</span> <span>div</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span><span>"/"</span><span>).</span><span>map</span><span>(</span><span>_</span> <span>=&gt;</span> <span>Div</span><span>)</span>

  <span>// non-terminals</span>
  <span>def</span> <span>binaryOperator</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span><span>plus</span> <span>|</span> <span>minus</span> <span>|</span> <span>times</span> <span>|</span> <span>div</span><span>)</span>
  <span>def</span> <span>fromNumber</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span><span>:</span> <span>P</span><span>[</span><span>FromNumber</span><span>]</span> <span>=</span>
    <span>P</span><span>(</span><span>number</span><span>.</span><span>map</span><span>(</span><span>FromNumber</span><span>(</span><span>_</span><span>)))</span>
  <span>def</span> <span>fromBinary</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span><span>:</span> <span>P</span><span>[</span><span>FromBinary</span><span>]</span> <span>=</span>
    <span>P</span><span>(((</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)</span> <span>~</span>
        <span>binaryOperator</span> <span>~</span>
       <span>(</span><span>fromNumber</span> <span>|</span> <span>inParenthesis</span><span>)).</span><span>map</span> <span>{</span>
      <span>case</span> <span>(</span><span>ex1</span><span>,</span> <span>op</span><span>,</span> <span>ex2</span><span>)</span> <span>=&gt;</span> <span>FromBinary</span><span>(</span><span>ex1</span><span>,</span> <span>ex2</span><span>,</span> <span>op</span><span>)</span>
    <span>})</span>
  <span>def</span> <span>expression</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span>
    <span>P</span><span>(</span><span>fromBinary</span> <span>|</span> <span>fromNumber</span><span>)</span>
  <span>def</span> <span>inParenthesis</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span>
    <span>P</span><span>(</span><span>"("</span> <span>~</span> <span>expression</span> <span>~</span> <span>")"</span><span>)</span>

  <span>def</span> <span>program</span><span>[</span><span>_</span> <span>:</span> <span>P</span><span>]</span> <span>=</span> <span>P</span><span>(</span> <span>(</span><span>expression</span> <span>|</span> <span>inParenthesis</span> <span>)</span> <span>~</span> <span>End</span><span>)</span>
<span>}</span>

<span>parse</span><span>(</span><span>"12 + 23"</span><span>,</span> <span>Parsers</span><span>.</span><span>program</span><span>(</span><span>_</span><span>))</span>
</code></pre></div>

<p>Before we jump the hype train - parser combinators are not equal to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> parsers and/or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LR</annotation></semantics></math></span></span> parsers. As we saw, we could define a parser accepting reverse Polish notation. However, if we tried to write a parser combinator that would accept it, then we would find, that recursive definition of <code>expression</code> would translate into a recursive function call without a terminating condition (parser combinators are just higher-order functions after all). <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LR</annotation></semantics></math></span></span> parser would push a symbol on the stack and take an input symbol from the input sequence, so at some point, they would have to stop (at least when the input finished). A parser combinator would need some <em>hint</em> e.g. closing block (which means that usually, it is not a problem), but we can see that parser combinators are not covering all context-free grammars.</p>

<p>Actually, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> parsers are not equal to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LR</annotation></semantics></math></span></span> parser either. Seeing how they work, one might argue that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">LL</annotation></semantics></math></span></span> parsers correspond to Polish notation (because they make a decision at leftmost symbol - a prefix) while <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">LR</annotation></semantics></math></span></span> corresponds to reverse Polish notation (because they take a decision at rightmost symbol - a postfix). (See a nice post about it: <a href="http://blog.reverberate.org/2013/07/ll-and-lr-parsing-demystified.html">LL and LR parsing demysitfied</a>). Both can be treated as special cases of PDA, while it a set of all PDAs that corresponds with a whole CFG set.</p>

<h2 id="turing-machines-linear-bounded-automata-unrestrained-and-context-sensitive-grammars">Turing machines, linear-bounded automata, unrestrained and context-sensitive grammars</h2>

<p>For the sake of completion, we can mention remaining computational models and grammar types, though this post is supposed to talk about parsing, so I’ll try to keep it short.</p>

<h3 id="turning-machines-and-unrestrained-grammars">Turning machines and unrestrained grammars</h3>

<p>A finite state machine at any given time remembers only in which one of a finite number of states it is. We read each symbol in the input once.</p>

<p>A push-down automaton remembers a current state and the last thing it put on a stack  - it can “remember” things from a stack in reverse order in which it stored them there for later. You cannot remember something from the middle of the stack without forgetting everything that was stacked before it. In a way, you can think that you can read each input element twice - once in incoming order, once in reverse order, and the only nuance is how you entangle these two modes.</p>

<p>A <strong>Turing machine</strong> (defined by Alan Turing, the same guy who designed <a href="https://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma#British_bombe">cryptologic bombe against German Navy’s improved Enigma</a>, the cryptologic bombe against <a href="https://en.wikipedia.org/wiki/Bomba_(cryptography)">original Enigma was designed by Polish Cipher Bureau</a>) improved upon, that by using infinite tape, where the automaton could read and store  symbol in one cell of that tape, and then move forward or backward. This allows us to “remember” something as many times as we need it.</p>

<p>Because of that ability to read the thing as many times as we want, it is possible that your machine will get into an infinite loop and never end. The question whether we can guess if a specific machine will ever return for a given input is called the <a href="https://en.wikipedia.org/wiki/Halting_problem"><strong>halting problem</strong></a> (<strong>HP</strong>) and is proven to be in impossible to solve for a general case. The proof assumes, that you have a program that could use the halting problem solver on itself and loop if solvers says it should return and returns if solvers says it should loop - so it shows by contradiction that such thing cannot be constructed. A halting problem is used in a lot of proofs, that certain problem is impossible to solve - a reduction from the halting problem makes you use that problem to solve HP - since it is impossible to solve HP the problem is also unsolvable.</p>

<p>Turing machines are equal to <strong>unrestrained grammars</strong>, that is formal grammars that have no restriction about how you define a production rule. They are also equivalent to lambda calculus, register machine, and several other models. Usually, if we want to have a universal programming language, we make it Turing-complete (equal in power to TM, allowing you to simulate TM on it).</p>

<h3 id="linear-bounded-automata-and-context-sensitive-grammars">Linear-Bounded Automata and Context-Sensitive Grammars</h3>

<p>Between push-down automata and Turing machines lies <strong>linear-bounded automata</strong> (<strong>LBA</strong>). I decided to describe them after TMs because they are basically restricted form of TM. It puts some limits on both sides of the infinite tape, that your automaton cannot cross.</p>

<p>It was proven that LBAs are equal to context-sensitive grammars, that is grammars in the form of:</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>α</mi><mi>A</mi><mi>β</mi><mo>→</mo><mi>α</mi><mi>B</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">\alpha A \beta \rightarrow \alpha B \beta</annotation></semantics></math></span></span></span>

<p>meaning that you can turn <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> only if it appears in the context of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span></span>.</p>

<h2 id="back-to-parsing">Back to parsing</h2>

<p>Majority of programming languages are Turing-complete. However, the first part of interpretation or compilation doesn’t require that we have this much power.</p>

<p>Some very simple interpreters can be build when you lexing (tokenization) and parsing and on reduction you immediately evaluate the computation inside parser. However, it is quite messy to maintain in the long run.</p>

<p>After all, parsers and context-free grammars can only take care of syntax analysis. So, you could preserve the results of syntax analysis into a data structure - abstract syntax tree - and then perform semantic analysis. Was variable with this name already defined? Is this identifier describing a class, object, constant? Actually, when you take into consideration how complex some of these things are, you might not be surprised, that certain compilers could decide to introduce several steps of a whole compilation process - just for verifying, that the AST is correct. <code>scalac</code> has over 20 phases in total:</p>

<div><pre><code>$ scalac -Xshow-phases
    phase name  id  description
    ----------  --  -----------
        parser   1  parse source into ASTs, perform simple desugaring
         namer   2  resolve names, attach symbols to named trees
packageobjects   3  load package objects
         typer   4  the meat and potatoes: type the trees
        patmat   5  translate match expressions
superaccessors   6  add super accessors in traits and nested classes
    extmethods   7  add extension methods for inline classes
       pickler   8  serialize symbol tables
     refchecks   9  reference/override checking, translate nested objects
       uncurry  10  uncurry, translate function values to anonymous classes
        fields  11  synthesize accessors and fields, add bitmaps for lazy vals
     tailcalls  12  replace tail calls by jumps
    specialize  13  @specialized-driven class and method specialization
 explicitouter  14  this refs to outer pointers
       erasure  15  erase types, add interfaces for traits
   posterasure  16  clean up erased inline classes
    lambdalift  17  move nested functions to top level
  constructors  18  move field definitions into constructors
       flatten  19  eliminate inner classes
         mixin  20  mixin composition
       cleanup  21  platform-specific cleanups, generate reflective calls
    delambdafy  22  remove lambdas
           jvm  23  generate JVM bytecode
      terminal  24  the last phase during a compilation run
</code></pre></div>

<blockquote>
  <p>By the way, this is a good moment to mention what compilation <em>actually is</em>. From the point of view of formal languages theory, a compilation is just translation work from one formal grammar into another. Scala into JVM byte code, C++ into binary code, Elm into JavaScript, TypeScript into JavaScript, ECMAScript 6 into ECMAScript 5… There is no need to introduce something like <em>transpiler</em> to describe compilation from one language to another. If we would use this word, then only to specify a compiler that translates into another high-level language, not because a <em>compiler</em> doesn’t cover that case.</p>

  <p>Interpreter would be something, that instead of translating into another formal grammar, translates directly into a computation. However, if we assume that we want to be <em>pure</em>, we would return something, that could be turned into a computation - e.g. free algebra. That explains, why <em>Typed Tagless Final Interpreter</em> has <em>interpreter</em> in its name, even though it doesn’t necessarily run computations immediately.</p>
</blockquote>

<p>Separation of phases serves two purposes. One is maintainability. The other is that we can separate front-end of a compiler (parsing and validating AST) and back-end (using AST to generate output). For instance, in case of Scala, we can have one front-end and several back-ends: JVM Scala, Scala.js and Native Scala (though, truth to be told Scala.js and Native Scala need to expand a language a bit).</p>

<p>If we go fully functional with all the phases (so each phase is a function working on AST element), then we have option to <em>compose</em> functions (<em>phase fusion</em>) - if our language of choice allows us to optimize combined functions, then we can obtain a compiler which is both maintainable and performant.</p>

<p>Of course, the parser doesn’t have to be a part of a compiler. The resulting tree might be our goal after all. XML, JSON or YML parsers exist in order to take some text representation and turn it into a tree of objects that is easier to work on. Notice, that grammars of languages like XML or HTML are too complex to be handled by something like <a href="https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags">regular expression</a>, so if you want to use it, you’d better grab a parser.</p>

<h2 id="error-handling">Error handling</h2>

<p>If you want to discover and return to a user all errors, possibly with some meaningful description of what could go wrong and how they could fix it, it is problematic.</p>

<p>As you noticed our naive parser combinator simply returned unmatched part of the input - hardly helpful. fastparse is slightly better - it can also tell you around which character things broke and what terminal/non-terminal it was (especially if you use <em>cuts</em>, to tell the parser where it <em>should not perform a backtracking</em>).</p>

<p>With parsers created by generators, the situation is similar - out of the box you usually only get the information that parsing failed. So, how come all these compilers and document parsers can give you meaningful messages? More meaningful than <em>things broke at n-th character</em>?</p>

<p>When it comes to parser generators like Bison, <a href="https://www.gnu.org/software/bison/manual/html_node/Error-Recovery.html">you have a special terminal symbol</a> - <code>error</code>. When you match it, you can extract the position in text and create an element of AST which could mock the element, that should be there but put the error element instead. Whether you do it by having each element of AST being a coproduct of valid and invalid version, or if you will make each step of the way something like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo><mo>→</mo><mi>E</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mo stretchy="false">[</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo separator="true">,</mo><mi>E</mi><mi>l</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">(A,B,C) \rightarrow Either[Error, Element]</annotation></semantics></math></span></span> is up to you. If that sound, as if you had to predict all possible ways a user can break the code and putting <code>error</code> there - that is exactly what you have to do there.</p>

<p>With parser combinators like fastparse, things are similar - you can tell the parser to <em>consume</em> some input after your current match, so you could e.g. try to match all right cases and - if they fail - consume the part of the input, that would fail and turn it into invalid AST element version.</p>

<p>Now, you should understand why this is not something, that you get for every language and why only some of them have user-friendly error handling. It increases the effort related to parser maintenance tremendously.</p>

<h2 id="summary">Summary</h2>

<p>In this post, we had a rather high-level overview of parsing (text) into AST. We briefly talked about the Chomsky hierarchy and relations between regular languages and different models of computation. We talked a little more about regular languages and context-free grammars, though without an in-depth description of algorithms used to create those.</p>

<p>How regular languages, computational models and compilers work in greater detail you can learn from books like <em>Compilers: Principles, Techniques, and Tools</em> by Aho, Lam, Sethi, and Ullman or <em>Structure and Interpretation of Computer Programs</em> by  Abelson,  Sussman, and Sussman.</p>

<p>I hope, that it will help you appreciate how many thoughts and effort went into letting us build REPLs, a plethora of languages - and all of that with much better syntax, than those of the first programming languages, which very unwelcome. This unblocked us from thinking about how to <em>design</em> the language to be friendly and readable. And, while we are still trying to figure out better ways of designing our tools, we should remember that all of that was possible thanks to pioneers in the formal languages theory.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A “meta-optics” camera that is the size of a grain of salt (214 pts)]]></title>
            <link>https://cacm.acm.org/news/a-camera-the-size-of-a-grain-of-salt-could-change-imaging-as-we-know-it/</link>
            <guid>42212992</guid>
            <pubDate>Fri, 22 Nov 2024 11:39:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cacm.acm.org/news/a-camera-the-size-of-a-grain-of-salt-could-change-imaging-as-we-know-it/">https://cacm.acm.org/news/a-camera-the-size-of-a-grain-of-salt-could-change-imaging-as-we-know-it/</a>, See on <a href="https://news.ycombinator.com/item?id=42212992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en"><section id="sec1"><p id="p-1">When it comes to cameras, size matters, but not in the way you think.</p><p id="p-2">Any time a new smartphone is released, it is easy to drool over the latest, greatest, and biggest features that allow you to take even more stunning selfies composed of even more megapixels. However, in the world of cameras, smaller cameras could end up having a far greater impact on the world at large—and enable a ton of positive applications in society—than the next iPhone camera. Work from researchers at Princeton University and the University of Washington is pointing the way.</p><p id="p-3">A team of researchers from both institutions has published work that uses innovative methods and materials to create a “meta-optics” camera that is the size of a single grain of salt.</p><figure id="attachment_762770" aria-describedby="caption-attachment-762770"><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg" data-type="image" data-caption="" href="https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg">
				<img decoding="async" src="https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg?w=1024" alt="ultracompact camera system" width="1024" height="576" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg 1200w, https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/11/111924.News_.A-Camera-the-Size.jpg?resize=1024,576 1024w" sizes="(max-width: 1024px) 100vw, 1024px">
			</a><figcaption id="caption-attachment-762770">The ultracompact camera system developed by researchers at Princeton University and the University of Washington relies on a technology called a metasurface, which is studded with 1.6 million cylindrical posts and can be produced much like a computer chip.</figcaption></figure><p id="p-4">The meta-optics camera is the first device of its kind to produce full-color images that are equal in quality to those produced by conventional cameras, which are an order of magnitude larger. In fact, the meta-optics camera is 500,000 times smaller than conventional cameras that capture the same level of image quality.</p><p id="p-5">The approach the researchers used to create this meta-optics camera’s small form factor is a huge deal.</p><p id="p-6">They used nano-structures called “metasurfaces” and novel approaches to hardware design to build a meta-optics camera far superior to past efforts, as well as implementing unique AI-powered image post-processing to create high-quality images from the camera.</p><p id="p-7">Their work is impressive on its own for breaking through past limitations of meta-optics imaging devices. Yet it is also notable because it opens the door to the creation of extremely small cameras that can create high-fidelity images for a range of industries and use-cases (for instance, by enabling the use of less-invasive medical imaging without compromising image quality).</p><p id="p-8">This work also unlocks the science-fiction-like possibilities of turning entire surfaces into cameras made up of thousands of such devices, and launching high-quality, ultra-light telescopes into space.</p><p id="p-9">Here’s how they did it—and why it could change the world of imaging as we know it.</p></section><section id="sec2"><h2>From conventional lenses to metasurfaces</h2><p id="p-10">All camera designers and engineers, no matter the type(s) of cameras they design, share the same challenge: they want to make their cameras as compact as possible while still allowing it to record as much light as possible.</p><p id="p-11">Smartphone cameras present a great example of the trade-offs inherent in solving this challenge. Each new smartphone packs more computational firepower into smaller and thinner frames, to the point where the newest generations of smartphones look positively futuristic. However, smartphone cameras are still obviously large and obtrusive on otherwise sleek smartphone frames because camera designers are packing more and more lenses into them so they can take higher-quality pictures.</p><p id="p-12">This means researchers are always on the hunt for ways to compress more optical power into smaller form factors, said Ethan Tseng, a researcher at Princeton who was part of the team that produced the salt-grain-sized meta-optics camera.</p><p id="p-13">“Metasurfaces have emerged as a promising candidate for performing this task,” Tseng said.</p><p id="p-14">A metasurface, Tseng explained, is an artificial, man-made material that allows us to affect light in unique ways. It is an ultrathin, flat surface just half a millimeter wide and studded with millions of cylindrical posts, which are called “nano-antennas.” These nano-antennas can be individually tuned by researchers to shape light in certain ways so that, together, they are capable of producing images just like standard refractive glass lenses—but in a device that is much, much smaller.</p><p id="p-15">“Using metasurfaces enables us to open a large design space of optics that we only hardly were able to access before with conventional refractive optics,” said Felix Heide, a Princeton professor who is the senior author of the study that produced the salt-grain-sized meta-optics camera.</p><p id="p-16">With a standard refractive lens, you can only really shape the surface of the lens and vary the material to get better results. However, with metasurfaces, researchers are able to modulate light at the sub-wavelength level, said Heide.</p><p id="p-17">In the salt-grain-sized camera, the research team was able to create a single metasurface that has more light-steering power than a traditional lens, dramatically reducing the overall size of the camera while still achieving similar results. The meta-optic lens itself is 0.5 millimeters in size, while the sensor is 1 millimeter in size, making the entire camera much, much smaller than traditional lenses.</p><p id="p-18">The researchers did not invent the concept of using metasurfaces for cameras, but they did determine how to make the approach work in a way that was actually useful in the real world. Meta-optics cameras have been designed before, but none of them can produce images that are of sufficient quality to deploy for imaging use cases.</p><p id="p-19">“Existing approaches have been unable to design a meta-optics camera that can capture crisp, wide-field-of-view full-color images,” said Tseng.</p><p id="p-20">The research team’s work changed that. Their meta-optics camera is the first high-quality, polarization-insensitive nano-optic imager for full-color, wide field-of-view imaging.</p><p id="p-21">“We addressed the shortcomings of previous meta-optics imaging systems through advances in both hardware design and software post-processing,” said Tseng. To do that, the researchers used artificial intelligence to address two challenges: lens design and image processing.</p><p id="p-22">First, the team used novel AI optimization algorithms to design the nano-antennas on the actual metasurface. Simulating the optical response of a metasurface and calculating the corresponding gradients can be quite computationally expensive, Tseng said, so the team created essentially fast “proxies” for metasurface physics that allowed them to compute how to design the metasurface very quickly.</p><p id="p-23">Then, a physics-based neural network was used to process the images captured by the meta-optics camera. Because the neural network was trained on metasurface physics, it can remove aberrations produced by the camera.</p><p id="p-24">“We were the first to treat the metasurface as an optimizable, differentiable layer that can perform computation with light,” said Heide. “This made it possible to effectively treat metasurfaces like layers in optical neural networks and piggyback on the large toolbox of AI to optimize these layers.”</p><p id="p-25">Finally, the metasurface physics simulator and the post-processing algorithm were combined into a single pipeline to fabricate the actual meta-optic camera, and then to reconstruct the images it captures into high-quality, full-color images.</p><p id="p-26">This innovative combination of hardware and software means that the researchers’ meta-optics camera produces images that could actually be used in real-world contexts, like medical imaging.</p><p id="p-27">“Only combined with computation were we able to explore this design space and make our lenses work for broadband applications,” said Heide.</p></section><section id="sec3"><h2>Better endoscopes, smartphone cameras, telescopes</h2><p id="p-28">The potential real-world applications of the research are vast.</p><p id="p-29">The most obvious one is medical imaging, which directly benefits from cameras that are as small as possible so as not to be invasive. “We are very excited about miniaturized optics in endoscopes, which could allow for novel non-invasive diagnosis and surgery,” said Heide.</p><p id="p-30">Ultra-compact endoscopes powered by a meta-optics camera could even image regions of the body that are difficult to reach with today’s technology.</p><p id="p-31">Another major area of interest for using meta-optics cameras—or cameras that incorporate meta-optics techniques—is consumer hardware. The ability to design cameras and lenses that are an order of magnitude smaller than those in devices today opens up exciting possibilities across smartphones, wearables, and augmented reality (AR) and virtual reality (VR) headsets.</p><p id="p-32">Your smartphone screen or the back of your phone itself could become a camera, says Heide. Wearables could bake high-quality cameras right into the surfaces of, say, eyeglasses. Or, VR headsets could become dramatically lighter and sleeker, leading to higher adoption and greater use of these devices on the go.</p><p id="p-33">Drones also could benefit from significantly smaller cameras. All drones require cameras of some type to perform their work, whether for military purposes like reconnaissance or civilian ones like order delivery. Much smaller cameras would result in far lighter drones that consume far less battery power, said Tseng.</p><p id="p-34">In fact, with a breakthrough like the meta-optics camera, the very nature of cameras can be rethought entirely.</p><p id="p-35">“Our tiny cameras have also recently allowed us to rethink large cameras as flat arrays of salt-grain cameras—effectively turning surfaces into cameras,” said Heide. Larger metasurfaces could even replace the lenses needed for telescopes, making it not only easier to build them but also to send more powerful lenses into space.</p><p id="p-36">While researchers are still in the early stages of brainstorming and engineering potential real-world applications for meta-optics cameras, the way in which metasurfaces are produced has them excited.</p><p id="p-37">“Metasurfaces are especially interesting because they can be made using the same mature technology used to produce computer chips,” said Tseng. Today’s computer chips are produced on wafers, and each wafer contains hundreds of identical copies of the chip. Metasurfaces are produced in an identical way, which holds the promise of greatly reducing the individual cost per metasurface produced, he said.</p><p id="p-38">Not to mention, while the exact materials used to make metasurfaces vary, the researchers used a silica wafer for their mounting surface and silicon nitride for their nano-antennas. Both materials are compatible with today’s semiconductor manufacturing techniques that pump out computer chips.</p><p id="p-39">This means going from sophisticated computer chips to meta-optics cameras might be easier than we think. If so, the picture for how to use these devices in many different industries could get much, much clearer.</p><h2 id="FurtherReading">Further Reading:</h2><ul id="reflist-1"><li></li><li></li><li></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TIL: Some surprising code execution sources in bash (101 pts)]]></title>
            <link>https://yossarian.net/til/post/some-surprising-code-execution-sources-in-bash</link>
            <guid>42212700</guid>
            <pubDate>Fri, 22 Nov 2024 10:43:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yossarian.net/til/post/some-surprising-code-execution-sources-in-bash">https://yossarian.net/til/post/some-surprising-code-execution-sources-in-bash</a>, See on <a href="https://news.ycombinator.com/item?id=42212700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>I ran across two surprising sources of code execution in <code>bash</code> (and probably
other shells) recently.</p>
<p>In a historic context these probably weren't <em>too</em>
serious of a problem, but in the context of CI systems where everything is
a rats' nest of shell and YAML they could be useful execution primitives.</p>
<p><strong>Edit 2024-11-22</strong>: the <a href="https://mywiki.wooledge.org/BashPitfalls">Bash Pitfalls</a> page in the Wooledge Bash Guide
contains examples of these, among other sources of surprising evaluations.</p>
<h2>Source 1: arithmetic expressions (a.k.a. "white-collar eval")</h2>
<p>Leading question aside, do you think this snippet of <code>bash</code><sup><a href="#fn-source" id="fnref-source" data-footnote-ref="">1</a></sup> can run
arbitrary code?</p>
<pre><code><span><span><span>function</span> <span>guess</span><span>(</span><span>)</span> <span>{</span>
  <span>num</span><span>=</span><span><span><span>"</span><span><span>$</span><span>{</span></span><span><span>1</span></span><span><span>}</span></span><span>"</span></span></span>
  <span>if</span> <span><span>[[</span> <span><span>"</span><span><span>$</span><span>{</span></span><span><span>num</span></span><span><span>}</span></span><span>"</span></span> <span><span>-</span>eq</span> 42 <span>]]</span></span>
  <span>then</span>
    <span><span>echo</span></span><span> <span><span>"</span>Correct<span>"</span></span></span>
  <span>else</span>
    <span><span>echo</span></span><span> <span><span>"</span>Wrong<span>"</span></span></span>
  <span>fi</span>
<span>}</span></span>
</span></code></pre>
<p>Most people (including experienced shell programmers<sup><a href="#fn-poll" id="fnref-poll" data-footnote-ref="">2</a></sup>) say "no": they
recognize that there <em>could</em> have been a splatting bug if it was <code>$num</code> instead
of <code>"${num}"</code>, but the double quoting should firmly prevent any evaluation
of the <code>num</code> variable itself.</p>
<p>But nope: because of <code>-eq</code>, <code>num</code> is treated with <code>bash</code>'s arithmetic evaluation
rules, meaning that this works:</p>
<pre><code><span><span><span>$</span></span><span> guess <span><span>'</span>a[$(cat /etc/passwd &gt; /tmp/pwned)] + 42<span>'</span></span></span>
<span><span>Correct</span></span>
<span><span>$</span></span><span> cat /tmp/pwned</span>
</span></code></pre>
<p>Note the single quotes: <code>$(cat /etc/passwd &gt; ~/pwned)</code> is <strong>not</strong> executed
eagerly as a parameter to <code>guess</code>, but as part of the evaluation of <code>-eq</code>
within <code>[[</code>.</p>
<p>Unlike the case below, this doesn't appear to work with <code>[</code> or <code>test</code>.</p>
<h2>Source 2: <code>test -v</code></h2>
<p>The same surprising code execution source exists with <code>test -v var</code>, under
the same conditions as arithmetic expressions (needs to use the builtin,
not the standard binary):</p>
<pre><code><span><span><span>$</span></span><span> <span>[</span><span>[</span> <span>-</span>v <span><span>'</span>x[$(cat /etc/passwd &gt; /tmp/pwned)]<span>'</span></span> <span>]</span><span>]</span></span>
<span><span>$</span></span><span> cat /tmp/pwned</span>
</span></code></pre>
<p>This <em>also</em> works with <code>[</code> and <code>test</code>, so long as their builtin variants
are used instead of their external binary variants. <code>/usr/bin/[</code> and
<code>/usr/bin/test</code> will of course not work, since they have no access to the
context of the shell that spawned them.</p>
<p>I'm not 100% sure <em>why</em> this is the case, since <code>-v var</code> is documented as
testing whether <code>var</code> is set and it shouldn't be necessary to evaluate
a subscript to determine that.</p>
<p><strong>Edit 2024-11-22</strong>: Multiple people have pointed out that <code>-v var[...]</code>
checks for the subscript's presence, hence the "need" to evaluate expressions.
This is not well documented anywhere, as far as I can tell.</p>
<section data-footnotes="">
<ol>
<li id="fn-source">
<p>Minimized and tweaked from <a href="https://www.vidarholen.net/contents/blog/?p=716">Vidar Holen's blog</a>, where I learned about this! <a href="#fnref-source" data-footnote-backref="" data-footnote-backref-idx="1" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="fn-poll">
<p>I polled my coworkers: of 17 respondents, 16 through this snippet was fine and 1 thought it contained a potential vulnerability. <a href="#fnref-poll" data-footnote-backref="" data-footnote-backref-idx="2" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Marble Madness-inspired WebGL game we built for Netlify (458 pts)]]></title>
            <link>https://5-million-devs.netlify.com/</link>
            <guid>42212644</guid>
            <pubDate>Fri, 22 Nov 2024 10:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://5-million-devs.netlify.com/">https://5-million-devs.netlify.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42212644">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rebels in the sky – Terminal game about space pirates (169 pts)]]></title>
            <link>https://github.com/ricott1/rebels-in-the-sky</link>
            <guid>42212071</guid>
            <pubDate>Fri, 22 Nov 2024 08:21:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ricott1/rebels-in-the-sky">https://github.com/ricott1/rebels-in-the-sky</a>, See on <a href="https://news.ycombinator.com/item?id=42212071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Rebels in the Sky</h2><a id="user-content-rebels-in-the-sky" aria-label="Permalink: Rebels in the Sky" href="#rebels-in-the-sky"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description demo_v1.0.18.mp4">demo_v1.0.18.mp4</span>
    <span></span>
  </summary>

  <video src="https://github.com/user-attachments/assets/aaa02f04-06db-4da5-8fa4-732b60083e66" data-canonical-src="https://github.com/user-attachments/assets/aaa02f04-06db-4da5-8fa4-732b60083e66" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">It's the year 2101. Corporations have taken over the world.
The only way to be free is to join a pirate crew and start plundering the galaxy. The only mean of survival is to play basketball.</p>
<p dir="auto">Now it's your turn to go out there and make a name for yourself. Create your crew and start wandering the galaxy in search of worthy basketball opponents.</p>
<p dir="auto">The game is under heavy development and breaking changes are often introduced. If you can't continue an old game because the save file is invalid, you probably need to start a new one or open an issue to check if the save file can be migrated.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Just try it out!</h2><a id="user-content-just-try-it-out" aria-label="Permalink: Just try it out!" href="#just-try-it-out"></a></p>
<p dir="auto">Connect via SSH to try the game.</p>
<p dir="auto"><code>ssh rebels.frittura.org -p 3788</code></p>
<p dir="auto">Save files are deleted after 2 days of inactivity.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build</h3><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto">You need to have the rust toolchain installed --&gt; <a href="https://www.rust-lang.org/tools/install" rel="nofollow">https://www.rust-lang.org/tools/install</a>. Then you can clone the repo and build the game with</p>
<p dir="auto"><code>cargo build --release</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With cargo</h3><a id="user-content-with-cargo" aria-label="Permalink: With cargo" href="#with-cargo"></a></p>
<p dir="auto"><code>cargo install rebels</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">From the latest release page</h3><a id="user-content-from-the-latest-release-page" aria-label="Permalink: From the latest release page" href="#from-the-latest-release-page"></a></p>
<ul dir="auto">
<li>Download the latest release asset for your platform from <a href="https://rebels.frittura.org/" rel="nofollow">https://rebels.frittura.org</a>;</li>
<li>Give execution permissions to the executable with <code>chmod +x rebels</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Distro Packages</h3><a id="user-content-distro-packages" aria-label="Permalink: Distro Packages" href="#distro-packages"></a></p>
<details>
  <summary>Packaging status</summary>
<p dir="auto"><a href="https://repology.org/project/rebels-in-the-sky/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/215eb0238498ff1dd9cb718b7e49c7e1ab1b8c2ea204728011c1ccb821c79ef2/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f726562656c732d696e2d7468652d736b792e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/rebels-in-the-sky.svg"></a></p>
</details>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch Linux</h4><a id="user-content-arch-linux" aria-label="Permalink: Arch Linux" href="#arch-linux"></a></p>
<p dir="auto"><code>rebels-in-the-sky</code> can be installed from the <a href="https://archlinux.org/packages/extra/x86_64/rebels-in-the-sky/" rel="nofollow">official repositories</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pacman -S rebels-in-the-sky"><pre>pacman -S rebels-in-the-sky</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run</h2><a id="user-content-run" aria-label="Permalink: Run" href="#run"></a></p>
<p dir="auto">This game runs as a terminal application, meaning that you just need to run the executable from your terminal with</p>
<p dir="auto"><code>./rebels</code></p>
<p dir="auto">Suggested minimal terminal size: 160x48. Not all terminals support the game colors nicely, so you might need to try different ones. Here is a list of tested terminals:</p>
<ul dir="auto">
<li>Linux: whatever the default terminal is, it should work</li>
<li>MacOs: <a href="https://iterm2.com/" rel="nofollow">iTerm2</a>, <a href="https://tabby.sh/" rel="nofollow">tabby</a>, <a href="https://wezfurlong.org/wezterm/index.html" rel="nofollow">WezTerm</a></li>
<li>Windows: <a href="https://tabby.sh/" rel="nofollow">tabby</a></li>
</ul>
<p dir="auto"><strong>Important</strong>: currently local bot teams are generated by default to make the game more enjoyable. This behaviour can be disabled by passing the <code>-f</code> flag to the executable. In the future, when more players will be available, the game will default to online teams only.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Music</h2><a id="user-content-music" aria-label="Permalink: Music" href="#music"></a></p>
<p dir="auto">Previous versions had the option to play music directly in the game, but this was removed to reduce the binary size and now music is streamed from internet radios. Nevertheless, you can still listen to the game soundtrack directly by connecting to <code>https://radio.frittura.org/rebels.ogg</code>!</p>
<p dir="auto">You can add more radio stations by including them in <code>assets/data/stream_data.json</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Planet gifs were generated using the <a href="https://deep-fold.itch.io/pixel-planet-generator" rel="nofollow">pixel planet generator</a> by <a href="https://deep-fold.itch.io/" rel="nofollow">Deep Fold</a>.</li>
<li>Special thanks to <a href="https://www.ildeposito.org/" rel="nofollow">Il Deposito</a> for inspiration and the great musical archive.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribution</h2><a id="user-content-contribution" aria-label="Permalink: Contribution" href="#contribution"></a></p>
<p dir="auto">Join the <a href="https://discord.gg/ebjp33UrrV" rel="nofollow">discord</a>! There is no fixed roadmap for the game yet, anyone is welcome to participate with ideas.</p>
<p dir="auto">It is almost guaranteed that you will encounter bugs along your journey. If you do, please open an issue and describe what happened. If you are a developer and want to contribute, feel free to open a pull request.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This software is released under the <a href="https://www.gnu.org/licenses/gpl-3.0.en.html" rel="nofollow">GPLv3</a> license.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Story of the two thousand stolen Playdate handhelds (175 pts)]]></title>
            <link>https://podcast.play.date/episodes/s01e31/</link>
            <guid>42211689</guid>
            <pubDate>Fri, 22 Nov 2024 06:53:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://podcast.play.date/episodes/s01e31/">https://podcast.play.date/episodes/s01e31/</a>, See on <a href="https://news.ycombinator.com/item?id=42211689">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<article id="s01e31">
							<header>
							
							<p><time datetime="2024-11-19T07:30:00.000Z">
									Tuesday, November 19, 2024
								</time>

								•

								54 minutes
							</p>
						</header>


	


	<p><audio controls="">
			<source src="https://download.panic.com/playdate_podcast/PlaydatePodcast-s01e31-True-Crime-Edition.mp3" type="audio/mpeg">

			Your browser does not support the <code>audio</code> element.
		</audio>
	</p>

	<p>Earlier this year, our Financial Controller, Jen, realized our Playdate inventory was 2,000 units short. How did that eventually lead us to a Circle K in North Las Vegas, and just how much should you tip for a roofing consultation, anyway?
Buckle up, because we are going for a ride—in Magnum P.I.'s cool car.</p>
<h2 id="show-notes" tabindex="-1">Show Notes</h2>
<ul>
<li><a href="https://gdcvault.com/play/1034707/The-Playdate-Story-What-Was">Cabel’s GDC Talk</a></li>
<li><a href="https://en.wikipedia.org/wiki/Magnum%2C_P.I.">Magnum, P.I.</a></li>
<li><a href="https://en.wikipedia.org/wiki/Froster">Circle K Froster</a></li>
<li><a href="https://podcast.play.date/episodes/s01e31/">Episode page with photos</a></li>
<li><a href="https://podcast.play.date/episodes/s01e31/transcript/">Episode transcript</a></li>
</ul>



	


	
	
	

<a href="https://podcast.play.date/episodes/s01e31/">Listen Now</a></article>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple will now be treated like a bank (105 pts)]]></title>
            <link>https://9to5mac.com/2024/11/21/apple-will-now-be-treated-like-a-bank-says-us-consumer-financial-protection-bureau/</link>
            <guid>42211525</guid>
            <pubDate>Fri, 22 Nov 2024 06:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2024/11/21/apple-will-now-be-treated-like-a-bank-says-us-consumer-financial-protection-bureau/">https://9to5mac.com/2024/11/21/apple-will-now-be-treated-like-a-bank-says-us-consumer-financial-protection-bureau/</a>, See on <a href="https://news.ycombinator.com/item?id=42211525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1500" height="750" src="https://9to5mac.com/wp-content/uploads/sites/6/2024/11/Apple-will-now-be-treated-like-a-bank-says-US-Consumer-Financial-Protection-Bureau.webp?w=1500" alt="Apple will now be treated like a bank, says US&nbsp;Consumer Financial Protection Bureau | In-store Apple Pay transaction on Square terminal" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/11/Apple-will-now-be-treated-like-a-bank-says-US-Consumer-Financial-Protection-Bureau.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/11/Apple-will-now-be-treated-like-a-bank-says-US-Consumer-Financial-Protection-Bureau.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/11/Apple-will-now-be-treated-like-a-bank-says-US-Consumer-Financial-Protection-Bureau.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/11/Apple-will-now-be-treated-like-a-bank-says-US-Consumer-Financial-Protection-Bureau.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>The popularity of <a href="https://9to5mac.com/guides/apple-pay/" target="_blank" rel="noreferrer noopener">Apple Pay</a> will now see the Cupertino company regulated by the US&nbsp;Consumer Financial Protection Bureau (CFPB), a watchdog whose role is normally limited to banks and financial services companies.</p>



<p>The decision means that the bureau will have the power to monitor and regulate <a href="https://9to5mac.com/guides/aapl/" target="_blank" rel="noreferrer noopener">Apple’s</a> policies and practices in regard to its mobile wallet services …</p>



<h2 id="h-the-consumer-financial-protection-bureau">The&nbsp;Consumer Financial Protection Bureau</h2>



<p>The CFPB is a US agency responsible for enforcing federal consumer financial law, but also has a broader role as a regulator to ensure that consumer financial products are “fair, transparent, and competitive.”</p>



<blockquote>
<p>We aim to make consumer financial markets work for consumers, responsible providers, and the economy as a whole. We protect consumers from unfair, deceptive, or abusive practices and take action against companies that break the law. We arm people with the information, steps, and tools that they need to make smart financial decisions.</p>
</blockquote>



<p>It was always able to ensure that mobile wallet services like Apple Pay and Google Pay complied with the law, but last year proposed that these services be treated much more like banks, giving the CFPB broader powers to enforce fairness and deal with consumer complaints.</p>



<h2 id="h-apple-pay-will-be-regulated-from-next-month">Apple Pay will be regulated from next month</h2>



<p><em><a href="https://www.bloomberg.com/news/articles/2024-11-21/apple-pay-other-tech-firms-come-under-cfpb-regulatory-oversight?embedded-checkout=true" target="_blank" rel="noreferrer noopener">Bloomberg</a></em> reports that the proposal has been finalized, and will take effect from next month.</p>



<blockquote>
<p>The top US consumer watchdog will supervise&nbsp;<a href="https://www.bloomberg.com/quote/AAPL:US" target="_blank" rel="noreferrer noopener">Apple Inc.</a>&nbsp;and other major technology firms that offer digital wallets and payment apps, finalizing a proposal from last year with several changes.</p>



<p>The US&nbsp;Consumer Financial Protection Bureau&nbsp;will now treat those companies more like banks as long as they handle more than 50 million transactions a year, conducted in US dollars, according to a statement Thursday.&nbsp;</p>
</blockquote>



<p>The agency’s director says the decision was made because mobile wallet services are now an integral part of people’s financial lives.</p>



<blockquote>
<p>“Digital payments have gone from novelty to necessity and our oversight must reflect this reality,” CFPB Director&nbsp;Rohit Choprasaid in the statement.</p>
</blockquote>



<p>More than 60% of the US population now uses a mobile wallet, with Apple Pay the most popular choice.</p>



<h2 id="h-9to5mac-s-take">9to5Mac’s Take</h2>



<p>Apple typically doesn’t change its policies to address legislative concerns until it is forced to do so in each of the countries and regions in which it operates, but on this occasion chose to act ahead of time.</p>



<p>The European Union required Apple to open up access to the NFC payment chip to banks and payment card companies, and it was likely that the CFPB would have imposed the same requirement on the company. Instead of limiting the change to the EU, the iPhone maker made the change globally, getting ahead of the game.</p>



<p>It’s more than a decade <a href="https://9to5mac.com/2013/09/17/why-touch-id-is-bigger-news-than-any-of-us-appreciated/" target="_blank" rel="noreferrer noopener">since I first speculated</a> that <a href="https://9to5mac.com/2015/06/22/opinion-apple-bank/" target="_blank" rel="noreferrer noopener">Apple may end up becoming a bank</a>. While that hasn’t happened yet, we have seen <a href="https://9to5mac.com/2023/05/02/apple-bank/" target="_blank" rel="noreferrer noopener">significant movement in this direction</a>. It already had to obtain banking licenses to <a href="https://9to5mac.com/guides/apple-pay-later/" target="_blank" rel="noreferrer noopener">launch Apple Pay Later</a>, though it later <a href="https://9to5mac.com/2024/06/17/apple-pay-later-united-states-ending/" target="_blank" rel="noreferrer noopener">withdrew the service</a> when it seemed likely to be subject to <a href="https://9to5mac.com/2024/06/19/apple-pay-later-withdrawal-reason/" target="_blank" rel="noreferrer noopener">even more regulation</a>. Today’s CFPB announcement means that whatever labels Apple chooses to use, Apple Pay will now be subject to bank-like regulatory oversight.</p>



<p><em>Photo by&nbsp;<a href="https://unsplash.com/@christiannkoepke?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" target="_blank" rel="noreferrer noopener">Christiann Koepke</a>&nbsp;on&nbsp;<a href="https://unsplash.com/photos/person-browsing-on-white-monitor-WiE01mC9AtY?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" target="_blank" rel="noreferrer noopener">Unsplash</a></em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon S3 now supports the ability to append data to an object (189 pts)]]></title>
            <link>https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-express-one-zone-append-data-object/</link>
            <guid>42211280</guid>
            <pubDate>Fri, 22 Nov 2024 04:46:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-express-one-zone-append-data-object/">https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-express-one-zone-append-data-object/</a>, See on <a href="https://news.ycombinator.com/item?id=42211280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="aws-page-content" data-page-alert-target="true"> 
   <main id="aws-page-content-main" role="main" tabindex="-1"> 
    <div data-eb-tpl-root="" data-reactroot="" data-eb-tpl-n="awsm-whats-new/whats-new-post" data-eb-tpl-v="1.0.0" data-eb-ce="" data-eb-c-scope="d105f9bc-63d3-11ee-8c99-0242ac120002" data-eb-d-scope="DIRECTORIES" data-eb-locale="en-US" data-eb-1e70fe18="" data-eb-ssr-ce="" data-eb-tpl-ns="awsmWhatsNew" data-eb-slot="d105f9bc-63d3-11ee-8c99-0242ac120002" data-eb-slot-meta="{'version':'1.0','slotId':'d105f9bc-63d3-11ee-8c99-0242ac120002','experienceId':'d105f9bc-63d3-11ee-8c99-0242ac120002','allowBlank':false,'hasAltExp':false,'isRTR':false,'filters':{'limit':1,'query':'id \u003d \'v1578391091\''}}"> 
         <main> 
           
           
          <div><p>Amazon S3 Express One Zone now supports the ability to append data to an object. For the first time, applications can add data to an existing object in S3.</p><p>  Applications that continuously receive data over a period of time need the ability to add data to existing objects. For example, log-processing applications continuously add new log entries to the end of existing log files. Similarly, media-broadcasting applications add new video segments to video files as they are transcoded and then immediately stream the video to viewers. Previously, these applications needed to combine data in local storage before copying the final object to S3. Now, applications can directly append new data to existing objects and then immediately read the object, all within S3 Express One Zone.</p><p>  You can append data to objects in S3 Express One Zone in all AWS Regions where the storage class is <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html" target="_blank">available</a>. You can get started using the AWS SDK, the AWS CLI, or Mountpoint for Amazon S3 (version 1.12.0 or higher). To learn more, visit the <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/directory-buckets-objects-append.html" target="_blank">S3 User Guide</a>.</p></div> 
         </main> 
        </div> 
   </main> 
  </div><div data-lb-comp="modal" data-lb-modal-id="ie-deprecation-msg" data-ie10-deprecation-msg="You are using an outdated browser. Please upgrade to a modern browser to improve your experience."> 
      
     <p>
       AWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. 
      <a href="https://aws.amazon.com/blogs/aws/heads-up-aws-support-for-internet-explorer-11-is-ending/" rel="noopener">Learn more »</a> 
     </p> 
      
    </div></div>]]></description>
        </item>
    </channel>
</rss>