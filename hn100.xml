<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 27 Apr 2024 02:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Court upholds New York law that says ISPs must offer $15 broadband (132 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/04/court-upholds-new-york-law-that-says-isps-must-offer-15-broadband/</link>
            <guid>40174424</guid>
            <pubDate>Fri, 26 Apr 2024 21:18:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/04/court-upholds-new-york-law-that-says-isps-must-offer-15-broadband/">https://arstechnica.com/tech-policy/2024/04/court-upholds-new-york-law-that-says-isps-must-offer-15-broadband/</a>, See on <a href="https://news.ycombinator.com/item?id=40174424">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/gavel-money-800x575.jpg" alt="A judge's gavel resting on a pile of one-dollar bills">
      <figcaption><p>Getty Images | Creativeye99</p></figcaption>  </figure>

  




<!-- cache hit 449:single/related:aad10c94f12a5779af7abeb242fdcb75 --><!-- empty -->
<p>A federal appeals court today reversed a ruling that prevented New York from enforcing a law requiring Internet service providers to sell $15 broadband plans to low-income consumers. The <a href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.55129/gov.uscourts.ca2.55129.232.0.pdf">ruling</a> is a loss for six trade groups that represent ISPs, although it isn't clear right now whether the law will be enforced.</p>
<p>New York's Affordable Broadband Act (ABA) was <a href="https://arstechnica.com/tech-policy/2021/06/ny-cant-force-isps-to-offer-15-low-income-broadband-plans-judge-rules/">blocked</a> in June 2021 by a US District Court judge who ruled that the state law is rate regulation and preempted by federal law. Today, the US Court of Appeals for the 2nd Circuit reversed the ruling and vacated the permanent injunction that barred enforcement of the state law.</p>
<p>For consumers who qualify for means-tested government benefits, the state law requires ISPs to offer "broadband at no more than $15 per month for service of 25Mbps, or $20 per month for high-speed service of 200Mbps," the ruling noted. The law allows for price increases every few years and makes exemptions available to ISPs with fewer than 20,000 customers.</p>
<p>"First, the ABA is not field-preempted by the Communications Act of 1934 (as amended by the Telecommunications Act of 1996), because the Act does not establish a framework of rate regulation that is sufficiently comprehensive to imply that Congress intended to exclude the states from entering the field," a panel of appeals court judges stated in a 2-1 opinion.</p>
<p>Trade groups claimed the state law is preempted by former Federal Communications Commission Chairman Ajit Pai's repeal of net neutrality rules. Pai's repeal placed ISPs under the more forgiving Title I regulatory framework instead of the common-carrier framework in Title II of the Communications Act.</p>
<p>2nd Circuit judges did not find this argument convincing:</p>
<blockquote><p>Second, the ABA is not conflict-preempted by the Federal Communications Commission's 2018 order classifying broadband as an information service. That order stripped the agency of its authority to regulate the rates charged for broadband Internet, and a federal agency cannot exclude states from regulating in an area where the agency itself lacks regulatory authority. Accordingly, we REVERSE the judgment of the district court and VACATE the permanent injunction.</p></blockquote>
<h2>                                            
                                                        </h2>
<h2>Be careful what you lobby for</h2>
<p>The judges' reasoning is similar to what a different appeals court said in 2019 when it <a href="https://arstechnica.com/tech-policy/2019/10/net-neutrality-still-dead-but-judges-rule-that-fcc-cant-preempt-state-laws/">rejected Pai's attempt</a> to preempt all state net neutrality laws. In that case, the US Court of Appeals for the District of Columbia Circuit said that "in any area where the Commission lacks the authority to regulate, it equally lacks the power to preempt state law." In a related case, ISPs were <a href="https://arstechnica.com/tech-policy/2022/04/isps-cant-find-any-judges-who-will-block-california-net-neutrality-law/">unable to block</a> a California net neutrality law.</p>
<p>Several of the trade groups that sued New York "vociferously lobbied the FCC to classify broadband Internet as a Title I service in order to prevent the FCC from having the authority to regulate them," today's 2nd Circuit ruling said. "At that time, Supreme Court precedent was already clear that when a federal agency lacks the power to regulate, it also lacks the power to preempt. The Plaintiffs now ask us to save them from the foreseeable legal consequences of their own strategic decisions. We cannot."</p>
<p>Judges noted that there are several options for ISPs to try to avoid regulation:</p>
<blockquote><p>If they believe a requirement to provide Internet to low-income families at a reduced price is unfair or misguided, they have several pathways available to them. They could take it up with the New York State Legislature. They could ask Congress to change the scope of the FCC's Title I authority under the Communications Act. They could ask the FCC to revisit its classification decision, as it has done several times before But they cannot ask this Court to distort well-established principles of administrative law and federalism to strike down a state law they do not like.</p></blockquote>
<p>Coincidentally, the 2nd Circuit issued its opinion one day after current FCC leadership <a href="https://arstechnica.com/tech-policy/2024/04/fcc-restores-net-neutrality-rules-that-ban-blocking-and-throttling-in-3-2-vote/">reclassified</a> broadband again in order to restore net neutrality rules. ISPs might now have a better case for preempting the New York law. The FCC itself won't necessarily try to preempt New York's law, but the agency's <a href="https://docs.fcc.gov/public/attachments/DOC-401676A1.pdf">net neutrality order</a> does specifically reject rate regulation at the federal level.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3 years of fulltime Rust game development, and why we're leaving Rust behind (898 pts)]]></title>
            <link>https://loglog.games/blog/leaving-rust-gamedev/</link>
            <guid>40172033</guid>
            <pubDate>Fri, 26 Apr 2024 17:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loglog.games/blog/leaving-rust-gamedev/">https://loglog.games/blog/leaving-rust-gamedev/</a>, See on <a href="https://news.ycombinator.com/item?id=40172033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p><em><strong>Disclaimer: This post is a very long collection of thoughts and problems I've had over the years, and also addresses some of the arguments I've been repeatedly told. This post expresses my opinion the has been formed over using Rust for gamedev for many thousands of hours over many years, and multiple finished games. This isn't meant to brag or indicate success, but rather just show there has been more than enough effort put into Rust, to dispel the the commonly said "once you gain enough experience it'll all make sense" argument.</strong></em></p>
<p><em>This post isn't a scientific evaluation or an A/B study. It's my personal opinion after trying to make Rust gamedev work for us, a small indie developer (2 people), trying to make enough money to fund our development with it. We're not one of those developers that have infinite money from an investor and years to burn. If you're in that category and are happy to build systems for years, none of the below will apply. I'm looking at things from the perspective of "I want to make a game in 3-12 months maximum and release it so that people can play it and I can make some money from it.". This is not written from a perspective of "I want to learn Rust and gamedev seems fun", which even though is a valid goal, is not in any way aligned with what we want, which is doing gamedev in a commercially viable and self-sufficient way.</em></p>
<p><em>We've released a few games across Rust, Godot, Unity, and Unreal Engine, and many people played them on Steam. We also made our own 2d game engine with a simple renderer from scratch, and we also used Bevy and Macroquad for many projects over the years, some being very much non-trivial. I've also used Rust full-time at work as a backend developer. This post is not based on a short-sighted opinion of just going through a few tutorials or trying to make a small game for a game jam. We're well over 100k lines of Rust code written over 3+ years.</em></p>
<p><em>The goal of this post is to serve as a reference to dispel commonly said arguments that get repeated over and over. But again, this is a subjective opinion, and in big part being written so that I don't have to continually explain the same things over and over again when people ask. I'd like this to be a reference for why we're likely abandoning Rust as a gamedev tool. We're in no way stopping with game development, we're just stopping with game development in Rust.</em></p>
<p><em>If your goal is to learn Rust because it seems interesting and you like the technical challenge, that's completely fine. Part of what I want to appeal with this post is however how Rust gamedev is often presented, and advice that people often give out to others, without knowing whether they're building a tech demo or attempting to ship something. The community as a whole is overwhelmingly focused on tech, to the point where the "game" part of game development is secondary. As an example of this, I remember one time a discussion around the Rust Gamedev Meetup, that while was probably done jokingly was still imo illustrative of the issue, with something like "someone wants to present a game at the meetup, is that even allowed?" ... I'm not trying to say that people should have the same goals as we do, but I think maybe the way some things are communicated could be clearer, and that people should be more honest about what it is they're doing.</em></p>
<h2 id="once-you-get-good-at-rust-all-of-these-problems-will-go-away">Once you get good at Rust all of these problems will go away</h2>
<p>Learning Rust is an interesting experience, because while many things initially feel like "this is a special problem only I'm having", later one realizes that there's a few fundamental patterns that are universal, and that everyone learning has to re-discover and internalize in order to be productive. This may include simple things like <code>&amp;str</code> vs <code>String</code>, or <code>.iter()</code> vs <code>.into_iter()</code> and having to constantly use those, or just the realization of how partial borrows often go against certain abstractions.</p>
<p>Many of these things are just learning pains, and once enough experience is acquired the user can fully anticipate them without thinking and be productive. I've very much enjoyed my time writing various utilities and CLI tools in Rust, where I found it more productive than Python for anything but a few lines of code.</p>
<p>That being said, there is an overwhelming force in the Rust community that when anyone mentions they're having problems with <em>Rust the language</em> on a fundamental level, the answer is "you just don't get it yet, I promise once you get good enough things will make sense". This is not just with Rust, if you try using ECS you're told the same thing. If you try to use Bevy you'll be told the same thing. If you try to make GUIs with whichever framework you choose (be it one of the reactive solutions or immediate mode), you'll be told the same thing. <em>The problem you're having is only a problem because you haven't tried hard enough.</em></p>
<p>I believed this for years. I tried, very hard, for years. I've definitely seen this happen on many levels with the language, and I've found myself to be very productive in certain areas, and learned to be able to anticipate what the language and type system wants in order to avoid these issues.</p>
<p>But, and I say this having spent the past ~3 years and written over 100k lines of game-related code in it across the whole ecosystem of frameworks/engines and having made my own, many if not most of the problems don't go away if one isn't willing to constantly refactor their code and treat programming as a puzzle solving process, rather than just a tool to get things done.</p>
<p>The most fundamental issue is that the borrow checker <em>forces</em> a refactor at the most inconvenient times. Rust users consider this to be a positive, because it makes them "write good code", but the more time I spend with the language the more I doubt how much of this is true. Good code is written by iterating on an idea and trying things out, and while the borrow checker can force more iterations, that does not mean that this is a desirable way to write code. I've often found that being unable to just <em>move on for now</em> and solve my problem and fix it later was what was truly hurting my ability to write good code.</p>
<p>In other languages one can write code with "I can throw this away later" in mind, which I've found to be the most useful approach in terms of getting good code. An example being say that I'm implementing a player controller. I just want the player to move and do things, so that I can start building my level and enemies. I don't need a good controller, I just need it to do things. I can surely delete it and make a better one later. In Rust, sometimes just doing a thing is not possible, because the thing you might need to do is not available in the place where you're doing the thing, and you end up being <em>made</em> to refactor by the compiler, even if you know the code is mostly throwaway.</p>
<h2 id="rust-being-great-at-big-refactorings-solves-a-largely-self-inflicted-issues-with-the-borrow-checker">Rust being great at big refactorings solves a largely self-inflicted issues with the borrow checker</h2>
<p>It's very often said that one of Rust's greatest strengths is ease of refactoring. This is most definitely true, and I have had many experiences where I could fearlessly refactor significant parts of the codebase, with everything working afterwards. Everything works as advertised?</p>
<p>The thing is, Rust is also a language that will force the user to refactor much more often than other languages. It doesn't take a lot to suddenly be backed in a corner with the borrow checker and realize "wait I can't add this new thing because things will no longer compile, and there's no workaround other than code restructuring".</p>
<p>This is where experienced people will often say that this becomes less of an issue once you get better at the language. My take is, while that is 100% true, there's a fundamental problem of games being complex state machines where requirements change all the time. Writing a CLI or a server API in Rust is a very different experience than writing an indie game. Assuming the goal is to build a good experience for players rather than an inert set of general purpose systems, the requirements might change from day to day just after having people play the game and you realize some things need to fundamentally change. Rust's very static and overly-checked nature fights directly against this.</p>
<p>Many people would counter-argue that if you end up fighting the borrow checker and have to refactor your code it's actually good, because this makes your code better. I think this is a valid point to raise for something where you know what you're building. But in the majority of cases, I don't want "better code", I want "game faster" so that I can test it sooner and realize if the idea was good. It's not uncommon to be forced to make a choice between "do I break my flow and spend the next 2 hours refactoring this to test an idea, or do I make the codebase objectively worse?".</p>
<p>I'd argue as far as <em>maintainability being the wrong value for indie games</em>, as what we should strive for is iteration speed. Other languages allow much easier workarounds for immediate problems without necessarily sacrificing code quality. In Rust, it's always a choice of <em>do I add an 11th parameter to this function, or add another <code>Lazy&lt;AtomicRefCell&lt;T&gt;&gt;</code>, or do I put this in another god object, or do I add indirection and worsen my iteration experience, or do I spend time redesigning this part of code yet again</em>.</p>
<h2 id="indirection-only-solves-some-problems-and-always-at-the-cost-of-dev-ergonomics">Indirection only solves some problems, and always at the cost of dev ergonomics</h2>
<p>One fundamental solution that Rust really likes and that very often works is adding a layer of indirection. A canonical example of this is <a href="https://bevy-cheatbook.github.io/programming/events.html">Bevy's events</a>, which are the <em>go-to suggested solution for anything related to "my system needs to have 17 parameters to do its thing"</em>. I've tried to be on both sides of this, even specifically in the context of Bevy of trying to use events more heavily, and trying to just put everything in a single system. That being said, this is just one example.</p>
<p>Many issues with the borrow checker can simply be worked around by doing something indirectly. Or by copying/moving something out, then doing the thing, then moving it back. Or by storing it in a command buffer and doing it later. This can often lead to interesting discoveries in terms of design patterns, for example one thing I found quite neat is how a very large portion of issues can be solved by reserving entity ids ahead of time (e.g. <a href="https://docs.rs/hecs/latest/hecs/struct.World.html#method.reserve_entity">World::reserve in <code>hecs</code></a>, note the <code>&amp;world</code> and not <code>&amp;mut world</code>), combined with a command buffer.  These patterns are amazing when they work, and they solve otherwise very difficult problems. Another example is a seemingly very specialized <a href="https://docs.rs/thunderdome/latest/thunderdome/struct.Arena.html#method.get2_mut">get2_mut in <code>thunderdome</code></a> that seems like a random idea at first, until one realizes that this is something that comes up all the time and that solves many unexpected issues.</p>
<p>I won't get into arguing whether the learning curve to being productive is reasonable. It is certainly not, but this whole post is about the problems persisting on a fundamental level even after enough experience is acquired.</p>
<p>Back to the point, while some of the above can solve specific problems, there's very often going to be a situation that can't be solved with a specialized and well-thought-out library function. This is where solving problems with "just do the problematic thing later" with a command buffer or event queue becomes something many will suggest, and it certainly works.</p>
<p>The problem with games specifically is that we often care about inter-connected events, specific timings, and just overall managing a lot of state at once. Moving data across an event barrier means the code logic for a thing is suddenly split into two part, where even if the business logic might be "one chunk", it has to be cognitively regarded as two.</p>
<p>Anyone who's been in the community long enough have had the experience of being told that this is <em>actually a good thing</em>, separation of concerns, code is "cleaner", etc. You see, Rust was designed in a smart way, and if something can't be done, it's because the design is wrong, and it just wants to force you down the right path ... right?</p>
<p>What would be 3 lines of code in C# suddenly becomes 30 lines of Rust split into two places. The most canonical example here is something like: "while I'm iterating over this query I want to check a component on this other thing and touch a bunch of related systems" (spawn particles, play audio, etc.). I can already hear people telling me <em>well duh, this is obviously an <code>Event</code>, you shouldn't be writing that code inline</em>.</p>
<p>Just imagine the horror of wanting to do something like (Unity code coming, brace yourselves, or just pretend it's Godot):</p>
<pre data-lang="csharp"><code data-lang="csharp"><span>if (Physics.Raycast(..., out RayHit hit, ...)) {
</span><span>  if (hit.TryGetComponent(out Mob mob)) {
</span><span>    Instantiate(HitPrefab, (mob.transform.position + hit.point) / 2).GetComponent&lt;AudioSource&gt;().clip = mob.HitSounds.Choose();
</span><span>  }
</span><span>}
</span></code></pre>
<p>This is a relatively simple example, but it is something one might want to write. And especially when implementing a new mechanic and testing things, it is something that you can just write. There is no <em>maintainability</em> to think about, I just want to do very simple things, and I want to do them in the place where they are supposed to happen. I don't want a <code>MobHitEvent</code>, because maybe there's 5 other things I may want to check the raycast against.</p>
<p>I also don't want to check "is there a <code>Transform</code> on the <code>Mob</code>"? Of course there is one, I'm making a game. All of my entities have a transform. But Rust won't let me have a <code>.transform</code>, let alone in a way that would <em>never</em> crash with a double borrow error if I'm accidentally inside queries with overlapping archetypes.</p>
<p>I also maybe don't want to check if the audio source is there. Sure I could <code>.unwrap().unwrap()</code>, but the more observant 🦀's will notice the lack of <code>world</code> being passed around, are we just assuming a global world? Aren't we using dependency injection to write out our query as another parameter in the system with everything laid out up front? Is <code>.Choose</code> assuming a global random number generator? What about threads??? And where exactly is the physics world, are we seriously assuming that to be a global too?</p>
<p>If you're thinking "but this won't scale" or "it might crash later" or "you can't assume global world because XYZ" or "what if multiplayer" or "this is just bad code" ... I hear you. But by the time you finished explaining to me that I'm wrong I've already finished implementing my feature and moved on. I wrote my code in single pass without thinking about the code, and as I was writing it I was thinking about the gameplay feature I was implementing and how it affects the player. I wasn't thinking "what's the right way to get a random generator in here" or "can I assume this being single threaded" or "am I in a nested query and what if my archetypes overlap", and I also didn't get a compiler error afterwards, and I also didn't get a runtime borrow checker crash. I used a dumb language in a dumb engine and just thought about the game the whole time I was writing the code.</p>
<h2 id="ecs-solves-the-wrong-kind-problem">ECS solves the wrong kind problem</h2>
<p>Because of the way Rust's type system and borrow checker works, ECS comes up as a naturally occurring solution to the problem of "how do we have stuff reference other stuff". Unfortunately, I think there's quite a bit of terminology mixup, and not only do different people mean different things, but also that the large part of the community attributes some things to ECS that aren't actually ECS. Let's try to separate things out.</p>
<p>Firstly, let's mention a few things which we can't really do for various reasons (there's some nuance, but simplified since this article is already way too long):</p>
<ul>
<li>Pointer-y data with actual pointers. The problem here is simple, if character A follows B, and B gets deleted (and de-allocated), the pointer would be invalid.</li>
<li><code>Rc&lt;RefCell&lt;T&gt;&gt;</code> combined with weak pointers. While this could work, in games performance matters, and the overhead of these is non-trivial due to memory locality.</li>
<li>Indexing into arrays of entities. In the first case we'd have an invalid pointer, in this case if we have an index and we remove an element, the index might still remain valid, but point to something else.</li>
</ul>
<p>Now comes a magic solution that gets rid of all these problems, generational arenas, as best shown by <a href="https://docs.rs/thunderdome"><code>thunderdome</code></a>, which by the way is a library I'd highly recommend as it's small and lightweight and does what it's supposed to while keeping its codebase readable, the last point being quite rare in the Rust ecosystem.</p>
<p>Generational arena is basically just an array, except instead of having our id be an index, it's a tuple of <code>(index, generation)</code>. The array itself then stores tuples of <code>(generation, value)</code>, and we to keep things simple we can just imagine that every time something is deleted at an index we simply bump up the <code>generation</code> counter at that index. Then we just need to make sure that indexing into the arena always checks if the generation of the provided index matches the generation in the array. If the item was deleted, the slot would have a higher generation, and the index would then be "invalid" and act as if the item doesn't exist. There's some other reasonably simple problems to solve, such as keeping a free list of slots where we might want to insert to make insertion fast, but none of that is really that relevant for the user.</p>
<p>The key point being, this allows a language like Rust to completely side-step the borrow checker and allow us to do "manual memory management with arenas" without actually touching any hairy pointers, and while remaining 100% safe. If there was one thing to point at that I like about Rust, it'd be this. Especially with a library like <code>thunderdome</code> it really feels that this is a great match, and that this data structure very well fits the language as it was intended.</p>
<p>Now comes the fun part. What most people attribute as benefits of ECS are for the most part benefits of generational arenas. When people say "ECS gives me great memory locality", but their only query around mobs look like <code>Query&lt;Mob, Transform, Health, Weapon&gt;</code>, what they're doing is basically equivalent to <code>Arena&lt;Mob&gt;</code> where the struct is defined as</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Mob {
</span><span>  </span><span>typ</span><span>: MobType,
</span><span>  </span><span>transform</span><span>: Transform,
</span><span>  </span><span>health</span><span>: Health,
</span><span>  </span><span>weapon</span><span>: Weapon
</span><span>}
</span></code></pre>
<p>Now of course defining things in this way doesn't have all the benefits of ECS, but I feel it should be very explicitly pointed out that just because we're in Rust and just because we don't want to have everything be <code>Rc&lt;RefCell&lt;T&gt;&gt;</code> does not mean we need ECS, it could just mean that what we really want is a generational arena.</p>
<p>Back to ECS, there are few different ways to look at ECS that are very different:</p>
<p><strong>ECS as dynamic composition</strong>, allowing combinations of components to be stored and queried and modified together without having to be tied in a single type. The obvious example here that many people end up doing in Rust (because there's no other good way of doing this) is tagging entities with "state" components. One example might be that we want to query all <code>Mob</code>s, but maybe some of them have been morphed into a different type. We could simply do <code>world.insert(entity, MorphedMob)</code>, and then in our query we can either query <code>(Mob, MorphedMob)</code>, or something like <code>(Mob, Not&lt;MorphedMob&gt;)</code> or <code>(Mob, Option&lt;MorphedMob&gt;)</code> or check the presence of said component in code. Those might end up doing different things depending on different ECS implementations, but in practice we're using this to "tag" or "split" entities.</p>
<p>Composition can be much richer than this. The example before also fits in this, where instead of having one big struct <code>Mob</code>, we can have this be a separate <code>Transform</code>, <code>Health</code>, <code>Weapon</code>, and maybe other things. Maybe a mob without a weapon doesn't have the <code>Weapon</code> component, and once it picks up a weapon we insert it into the entity. This would allow us to iterate over all mobs with a weapon in a separate system.</p>
<p>I'll also include Unity's "EC" approach in the dynamic composition, as while it may not be the traditional purist "ECS with systems", it very much uses components for composition, and performance concerns aside, it ends up allowing for very similar things as if it was "pure ECS". I'd also like to give an honorable mention to Godot's node system, where child nodes are often used as "components", and while that has nothing to do with ECS, it has everything to do with "dynamic composition", as it allows nodes to be inserted/removed at runtime, and the behavior of entities to be altered because of this.</p>
<p>It should also be noted that the approach of "splitting up components into as small as possible for maximum reuse" is something that is very often cited as a virtue. I've been in countless arguments where someone tried to convince me how I absolutely should be separating <code>Position</code> and <code>Health</code> out of my objects, and how my code is spaghetti if I'm not doing that.</p>
<p>Having tried those approaches quite a few times, I'm now very much on the <em>hard disagree</em> side in complete generality, unless maximum performance is of concern, and then I'd concede on this point only for those entities where this performance concern matters. Having also tried the other approach of having "fat components", both before and after the "separated" approach, I feel that the "fat components" approach much better fits into <em>games</em> that have lots of logic that is unique to what is happening. For example, modelling <code>Health</code> as a general purpose mechanism might be useful in a simple simulation, but in every game I end up wanting very different logic for player health and enemy health. I also often end up wanting different logic for different types of non-player entities, e.g. wall health and mob health. If anything I've found that trying to generalize this as "one health" leads to unclear code full of <code>if player { ... } else if wall { ... }</code> inside my health system, instead of having those just be part of the big fat player or wall systems.</p>
<p><strong>ECS as dynamic structure of arrays</strong>, where due to how components are stored in ECS we get the benefit of iterating over say just <code>Health</code> components and having them next to each other in memory. For the uninitiated, this would mean instead of <code>Arena&lt;Mob&gt;</code>, we'd instead have:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Mobs {
</span><span>  </span><span>typs</span><span>: Arena&lt;MobType&gt;,
</span><span>  </span><span>transforms</span><span>: Arena&lt;Transform&gt;,
</span><span>  </span><span>healths</span><span>: Arena&lt;Health&gt;,
</span><span>  </span><span>weapons</span><span>: Arena&lt;Weapon&gt;,
</span><span>}
</span></code></pre>
<p>and where values at the same index would belong to the same "entity". Doing this by hand is annoying, and depending on your background and which languages you've used in the past you may have had to do this by hand at some point. But thanks to modern ECS, we can kind of get this for free by just writing out our types in a tuple, and have the underlying storage magic put the right things together.</p>
<p>I'd also call this use case <strong>ECS as performance</strong>, where the point of doing things this was is not "because we want composition", but "because we want more memory locality". This may actually have some valid applications, but I'd say for the vast majority of indie games that get shipped, this is not necessary. I'm intentionally saying "that get shipped", because of course it's easy to build mindblowingly complex prototypes that will require this, but those will also be infinitely far from ever being "played" by other people, and thus aren't of concern for this article.</p>
<p><strong>ECS as a solution to the Rust borrow checker</strong>, which is what I think most people using ECS are actually doing, or rather the reason why they're using ECS. If anything, ECS is a very popular solution and recommendation to give in Rust, because it tends to work around a lot of the issues. We don't need to care about lifetimes of things if we're just passing around <code>struct Entity(u32, u32)</code>, since it's all nice and <code>Copy</code>, just like Rust likes it.</p>
<p>The reason I have this as a separate point, is that many times people use ECS because it solves the particular problem of "where do I put my objects", without really using it for composition, and without really needing its performance. There's nothing wrong with that, only when such people end up getting into arguments all over the internet trying to convince other people that their approach of doing things is wrong, and that they should be using ECS a certain way because reasons mentioned above, without actually needing it in the first place.</p>
<p><strong>ECS as dynamically created generational arenas</strong>, which is something I kind of wanted to exist and tried to <a href="https://github.com/darthdeus/plushy">hack together</a>, only to realize that to truly get what I'd want I'd have to re-invent many ugly interior-mutability related things that I wanted to avoid doing in the first place, just to allow doing things like <code>storage.get_mut::&lt;Player&gt;()</code> and <code>storage.get_mut::&lt;Mob&gt;</code> at the same time. Rust has this nice property that while you do things the way you want it to it's all fun and pretty, but once you want something it doesn't really like, things quickly turn into "I need to re-implement my own <code>RefCell</code> that does this specific thing" or worse.</p>
<p>What I really mean by this point is that while generational arenas are nice, one of the big annoying downsides is that one has to define a variable and a type for every arena they intend to use. This can of course be solved by ECS if one just uses a single component in every query, but it would be nice and neat if one didn't need a full archetypical ECS just to get an arena-per-type on demand. There are ways to do this of course, but I'm way past burnout on trying to re-invent parts of the ecosystem to do this myself, and way past caring enough to force myself to do it.</p>
<p><strong>ECS because Bevy</strong>, which is partly meant as a joke, but I think due to Bevy's popularity and it's all-encompassing approach it should be mentioned as a separate view of ECS. Because for most engines/frameworks, ECS is a choice, it's a library that one decides to use. But as far as Bevy games are concerned, this isn't something optional that is used only for some things, the whole game <em>is</em> ECS.</p>
<p>It should be noted in the most positive way, that while I may disagree on many things, it's hard to deny how much improvement has Bevy done to ECS APIs and the ergonomics of <em>ECS itself</em>. Anyone that has seen or even used things like <a href="https://github.com/amethyst/specs"><code>specs</code></a> understands how much better Bevy is at making ECS nice to use and approachable, and how much it improved over the years.</p>
<p>That being said, I think this is also the core cause of the problem I have with how the Rust ecosystem views ECS, and especially how Bevy does. ECS is a tool, a very specific tool that solves very specific problems, and that does not come for free.</p>
<p>I'll take a sidestep here and let's talk about Unity for a second. Regardless of what happened with its licensing, leadership or what its business model is, it'd be foolish to think of Unity as anything but one of the main things that made indie gamedev the success that it is. Looking at <a href="https://steamdb.info/tech/">SteamDB charts</a> there are now almost 44 000 games in Unity on Steam, with the second engine being Unreal at 12 000, and the rest falling well behind.</p>
<p>Anyone that has been following Unity in the recent years knows about <a href="https://unity.com/dots">Unity DOTS</a>, which is essentially their "ECS" (and other data oriented things). Now as a past, present and future user of Unity, I'm very excited by this, and one of the main reasons I find it exciting is that this co-exists with the existing game object approach. There's many intricacies, but at its core, things are what one could expect. A single game can use DOTS for some things, while also using the standard game object scene tree as it was before, and these two go well together.</p>
<p>I don't think one would find a person in the Unity space who understands what DOTS things and thinks it's a bad feature that shouldn't exist. But I also don't think one would find a person who thinks DOTS is all there should be in the future, and that game objects should be erased from existence, and all of Unity should be moved to DOTS. Even ignoring maintenance and backwards compatibility, this would be remarkably stupid, as there are so many workflows that naturally fit into game objects.</p>
<p>Those that have used Godot can probably see a similar view, especially those that used <code>gdnative</code> (e.g. via <code>godot-rust</code>), where while node trees maybe not the best data structure for everything, they for sure are extremely convenient for quite a few things.</p>
<p>Taking this back to Bevy, what I don't think many people realize, is just how all-encompassing the "ECS everything" approach is. An obvious example and in my opinion a large failure point here is Bevy's UI system, which has been a pain point for a while, especially combined with the "we'll start working on the editor this year for sure!" types of promises. If you take a look at <a href="https://bevyengine.org/examples/#ui-user-interface">Bevy's UI examples</a> it becomes very quickly obvious that there isn't much there, and taking a look at the source code for something simple as <a href="https://bevyengine.org/examples/UI%20(User%20Interface)/button/">a button that changes color when hovered and clicked</a> quickly reveals why. Having actually tried to use Bevy UI for something non-trivial, I can confirm that the pain is even greater than it looks, as the amount of ceremony required by the ECS to do anything UI related is just completely insane. As a result, Bevy's closest thing that exists to an editor is a <a href="https://github.com/jakobhellermann/bevy_editor_pls">3rd party crate that uses <code>egui</code></a>. I'm simplifying things a bit, and of course there's more that goes into making an editor than just UI, but I do think that the insistence of putting everything into ECS, including UI, is definitely not helping here.</p>
<p>ECS in Rust has this tendency of turning from something that is considered a tool in other language to become almost a religious belief. Something that should be used because it is pure and correct, and because doing that is the right way.</p>
<p>Programming language communities often have certain tendencies, and having been a serial language hopper over the years I find it interesting to compare these. The closest thing to Rust's view on ECS I can think of is Haskell, except, and I know this is an oversimplification but I'll say it anyway, I do feel that the overall community in Haskell is a lot more mature, and that people in general tend to be more reasonable about the existence of other approaches, and view Haskell as a "fun tool to solve problems where it fits well".</p>
<p>Rust on the other hand often feels like when you talk to a teenager about their preference about anything. What comes out are often very strong opinions and not a lot of nuance. Programming is a very nuanced activity, where one has to often make suboptimal choices to arrive at a result in a timely manner. The prevalence of perfectionism and obsession with "the correct way" in the Rust ecosystem often makes me feel that the language attracts people who are newer to programming, and are easily impressionable. Again, I understand this doesn't apply to everyone, but I think the overall obsession with ECS is in some sense a product of this.</p>
<h2 id="generalized-systems-don-t-lead-to-fun-gameplay">Generalized systems don't lead to fun gameplay</h2>
<p>A very commonly offered solution to many issues preventing here is more generalization through systems. If only components were more granularly split up and proper systems were used, surely all those special-cased problems would've been avoided, right?</p>
<p>Strong argument that is tough to say much against, other than "general solutions lead to boring gameplay". Having been quite active in the Rust gamedev community I've seen a lot of projects others were building, of course often the suggestions they offer do actually correlate with the game they're working on. People who tend to have neatly designed systems that operate in complete generality tend to have games that aren't really games, they're simulations that will eventually become a game, where often something like "I have a character that moves around" is considered gameplay, and where the core focus is on having one or more of the following:</p>
<ul>
<li>Procedurally generated world, planets, space, dungeons.</li>
<li>Voxel based anything, with deep focus on voxels themselves, rendering voxels, world size and performance.</li>
<li>Generalized interactions where "anything can do X with anything else".</li>
<li>Rendering in the most optimal way possible, if you're not using draw indirect are you even making a game?</li>
<li>Having good types and "framework" for building games.</li>
<li>Building an engine for making more games like the one that is about to be built.</li>
<li>Multiplayer.</li>
<li>Lots of GPU particles, the more particles the better the VFX.</li>
<li>Well structured ECS and clean code.</li>
<li>... and many more</li>
</ul>
<p><em>All of these are fine goals in terms of playing around with tech and learning Rust, but I want to re-iterate what was said at the top of this article. I'm not evaluating Rust from the perspective of technical curiosities or "this scratches the right brain itch". I want to make real games that will get shipped to real people (not developers) in reasonable amount of time, that those people will pay for and play, and have an actual chance of hitting the front page of Steam. To clarify, this isn't a cold blooded "make money at all costs" scheme, but it's also not a "I'm just doing this for the lulz". The whole article is written from a perspective of wanting to be a serious game developer who cares about games, gameplay and players, and not just tech enthusiasm.</em></p>
<p><em>Again, nothing wrong with tech enthusiasm, but I think people should be very careful about what their actual goals are, and above all be honest with why they're doing what they're doing. Sometimes I feel like the way some projects present themselves are the way people talk about those projects is false advertising that creates an illusion that commercial goals can be attained with said approaches, instead of making it more clear that "I'm just doing this for the tech itself".</em></p>
<p>Now back to generalized systems. Here's a few things that I think create good games, that are going directly or indirectly against generalized ECS approaches:</p>
<ul>
<li>Mostly hand-designed playthrough of a level. This does not mean "linear" or "story", but it does mean "lots of control over when the player sees what".</li>
<li>Carefully crafted individual interactions throughout the levels.</li>
<li>VFX that are not based on having lots of same-y particles, but time synchronized events (e.g. multiple different emitters firing on a hand-designed schedule) working across all the game's systems.</li>
<li>Iterated playtesting with multiple passes on gameplay features, experimentation and throwing away what doesn't work.</li>
<li>Shipping the game to players as fast as possible so that it can be tested and iterated on. The longer nobody sees it, the bigger chance nobody cares about it when it comes out.</li>
<li>Unique and memorable experience.</li>
</ul>
<p>I understand that reading this many people would think I'm imagining an artsy-fartsy game made by a painter and <em>not a real programmer who wants to make a game like Factorio</em>, but this isn't true. I still like systemic games, I like code, I want to make something that is driven by programming, because I do feel like I'm mainly a programmer.</p>
<p>What I think most people get wrong is mistaking carefully thinking through player interactions and designing them as something artistic. I'd argue that this is what <em>game development</em> actually is. Game development isn't building a physics simulation, it's not building a renderer, or building a game engine, or designing a scene tree, or a reactive UI with data bindings.</p>
<p>A good example game here would be <a href="https://store.steampowered.com/app/113200/The_Binding_of_Isaac/">The Binding of Isaac</a>, which is a very simple roguelike with <a href="https://tboi.com/">hundreds of upgrades</a> that modify the game in very involved, interactive and deeply complex ways. It's a game with many systems that play into each other, but it's also something that's not at all generic. It's not a game with 500 upgrades of the "+15% damage" variety, but many upgrades are of the "bombs stick to enemies" or "you shoot a laser instead of projectiles" or "first enemy you kill each level will never spawn again".</p>
<p>Looking at a game like this retrospectively may make it look like it's something you could design up front with general purpose systems, but I think this is also something where most people go completely wrong with game development. You don't make a good game like this by sitting in a dungeon for a year, thinking through all the edge cases and building a general system and then PCGing all the upgrades. You build a prototype with some small amount of mechanics and have people play it, see that the core things work, and then add more things and have people play again. Some of these interactions have to be discovered through deep knowledge of the game after playing a lesser version of the game for many hours and trying many different things.</p>
<p>Rust is the type of language where wanting to do a new type of upgrade might lead you down a path of refactoring all of the systems, and many would even say "that's great, now my code is much better and can accommodate so many more things!!!". It sounds like a very convincing argument, one that I've heard many times, and one that has also caused me to waste a lot of time chasing down solutions to the wrong problems.</p>
<p>A more flexible language would allow the game developer to <em>immediately</em> implement the new feature in a hacky way, and then play the game, test it and see if the feature is actually fun, and potentially do a bunch of these iterations in a short amount of time. By the time the Rust developer is finished with their refactoring, the C++/C#/Java/JavaScript developer has implemented many different gameplay features, played the game a bunch and tried them all out, and has a better understanding of which direction should their game be taking.</p>
<p><a href="https://www.youtube.com/watch?v=o5K0uqhxgsE">Jonas Tyroller explains this extremely well in his video on game design as a search</a>, which I'd 100% recommend every game developer to watch, because it feels like the best explanation of why so many games people make (myself included) are profoundly terrible. A good game is not made in a lab where careful types are crafted, it is made by a developer who is a grandmaster player at the genre, and who understands every aspect of the design and has tried and failed many things before reaching upon the final design. A good game is made through scraping a lot of bad ideas, through a non-linear process.</p>
<h2 id="making-a-fun-interesting-games-is-about-rapid-prototyping-and-iteration-rust-s-values-are-everything-but-that">Making a fun &amp; interesting games is about rapid prototyping and iteration, Rust's values are everything but that</h2>
<p>To better define this point we have to define what is meant by "game development" in this article. We're not talking about AAA, or large scale very long term projects in general. I don't think anyone can realistically think they're going to build a successful 5 year game project unless they already have a lot of prior experience with both game development and the tooling they're using. We're talking about indie games made by individuals or small teams on relatively tight budgets/timelines.</p>
<p>Secondly, there are many reasons one could make a game, but our intention is to make something other people will play and consider to be good, without knowing which technology/engine/framework/ideology was used to create it, without knowing or relating to the author, and without having any prior exposure. I feel like this especially needs to be stressed out, because while the Rust community is overall very supportive, it often creates a very false idea that "this is so cool, people will love a game like this". It's not a problem only Rust struggles with, and many gamedevs end up showing their games to other gamedevs and gamedev communities, and thus fall for the same fallacy.</p>
<p>Because of the general vibes in the Rust community it's very common for people to receive very positive reinforcement on what they're building. This is nice in terms of mental health and short term motivation, but having gone through the process of releasing something on Steam publicly more than once, I feel like many people are headed for a bitter realization once people who aren't in their friend group/community see their game. The reason I'm saying this is that I think the community as a whole has adopted this idea of relentless positivity and praise towards everything Rust related, shielding itself completely from the outside world.</p>
<p>But the real world of gamers is not as nice. Gamers on Steam don't care if something is made in Rust, they don't care if it took 5 years to make, they don't care if the code is opensource. <strong>They care about looking at the game, and within <em>a few seconds</em> being able to tell if this is going to be a waste of time, or something potentially interesting.</strong></p>
<p>I've seen many people dismiss these things as <em>the young generation</em> and <em>attention spans</em> and <em>ADHD this/that</em> and <em>people <strong>should</strong> appreciate XYZ</em>. I don't find any of these views helpful, because everyone does this, we as game developers are just biased when it's about <em>our games</em>. When you're shopping at a grocery store and look at bananas and some of them have a slightly ugly color or look a bit damaged you'll pick the ones that look better instead. When going to a restaurant you'll pick one that looks like they'll have good food at a good price, or at least delivers an experience you care about.</p>
<p>I'd even say that it is correct and desirable that players do not care about the developer and just look at the game for a few seconds, but at least that keeps us honest. It keeps the games be about the game itself and nothing else, because ultimately, it is the game and the experience of playing it that matters.</p>
<p>It also reveals the values one as a game developer should appeal to. If you're showcasing your game and the response is anything but "can I please play this?", the game was not interesting to the person who you showed it to. At least not in the sense that truly matters for the purposes of making commercially successful games.</p>
<p>People would often argue that Rust appeals to values like "maintainability" and how this leads to better games that don't crash, but I think the problem here is completely different scales. Surely we can all agree that a game crashing when someone presses play is bad, and it is definitely bad when you corrupt a save file and the player loses progress.</p>
<p>But I think all of this completely misses the point of what matters to players. There are many cases where people would get their progress wiped and they'd still come back to the game and play it again, because the game was that good. I've done this more than once as a player.</p>
<p>Rust as both language and community is so preoccupied with avoiding problems at all cost that it completely loses sight of what matters, delivering an experience that is so good that whatever problems are there aren't really important. This doesn't mean "ship crap games", it means focusing on the game being a good game, not on the code being good code.</p>
<h2 id="procedural-macros-are-not-even-we-have-reflection-at-home">Procedural macros are not even "we have reflection at home"</h2>
<p>Game development as a domain of programming often requires one to write more than one type of code. We have system-y code for things like collisions, physics, particles. We have gameplay code for "scripting" entity behaviors. We have UI, VFX, audio. And then we also have tools. Depending on the game that is being built the size of each category may vary, but after working on enough of different genres of games I'd say it's generally universal that some amount of effort will have to be spent on every aspect.</p>
<p>Rust fits very nicely in the low level algorithmic areas where one knows exactly what the problem is and just needs to solve it. Unfortunately, a lot of gamedev requires more dynamic approaches, and this becomes especially painful around level editing, tooling and debugging.</p>
<p>Even something as simple as "print this object" is not a problem that can be reasonably solved without either writing code, or creating procedural macros. Now many languages have macros, and for those who haven't used Rust for long enough, they might not know that there's two types of macros in Rust:</p>
<ul>
<li><strong>Declarative macros:</strong> These are relatively simple to create and very useful, but unfortunately quite limited. As many things in Rust, "safety" is above all else, and things that would be completely fine in C preprocessor macros become an impossible issue. The simplest example here is concatenating tokens, which now has a famous <a href="https://docs.rs/paste/latest/paste/"><code>paste</code> crate</a> that gives a partial solution using a procedural macro. At a surface level you'd think <em>great, problem solved, right?</em> ... but unfortunately not even close, for example things like nesting and mixing procedural and declarative macros together isn't always going to work, and it's not even obvious what's possible and why until <em>a lot</em> of time is spent on figuring out the technicalities.</li>
<li><strong>Procedural macros</strong>: As a core idea procedural macros basically allow the programmer to run code at compile time, consume Rust's AST, and generate new code. There are <em>many</em> issues with this unfortunately. Firstly, proc macros aren't really cached and get re-run on recompiles. This ends up forcing your code to be split up in multiple crates, which isn't always possible, and if you rely on proc macros more heavily your compile times will suffer by a huge amount. There's many convenient proc macros like <a href="https://docs.rs/profiling/latest/profiling/attr.function.html"><code>profiling</code>'s <code>function</code> macro</a> which are very very useful, but ultimately unusable, because they destroy incremental build times. Secondly, procedural macros are incredibly difficult to write, and most people end up using very heavy helper crates, such as <a href="https://docs.rs/syn/latest/syn/"><code>syn</code></a>, which is a very heavy Rust parser that eagerly evaluates everything it's applied to. For example, if you want to annotate a function and just parse its name in your macro, <code>syn</code> will end up parsing the whole function body regardless. There's also the case where the author of <code>syn</code> is also the author of <a href="https://docs.rs/serde"><code>serde</code></a>, a popular Rust serialization crate, <a href="https://www.reddit.com/r/rust/comments/15va70a/serde_has_started_shipping_precompiled_binaries/">which at some point last year started shipping a binary blob with its installation in a patch release</a>, rejecting the community backlash. This isn't really a case against Rust, but I feel it should be mentioned, because it shows how a big part of the ecosystem is built on libraries made by single developers who can make potentially dangerous decisions. Of course this can happen in any language, but in terms of procedural macros this is <em>very</em> important, because almost everything in the ecosystem uses crates made by this specific author (<code>syn</code>, <code>serde</code>, <code>anyhow</code>, <code>thiserror</code>, <code>quote</code>, ...).</li>
</ul>
<p>Even ignoring the above, procedural macros have a very steep learning curve, and they <em>have to</em> be defined in a separate crate. This means that unlike with declarative macros where you can just create one as if you were making a function you can't easily just make a new procedural macro.</p>
<p>In contrast, using reflection in C# is <em>extremely easy</em>, and if performance is of no concern (which it often isn't in cases where reflection is used) it can be a very quick and useful option for building tools or debugging. Rust doesn't offer anything of the sort, and the last approach for <a href="https://soasis.org/posts/a-mirror-for-rust-a-plan-for-generic-compile-time-introspection-in-rust/">compile time reflection</a> has been basically cancelled in one of last year's Rust dramas.</p>
<p>As this article aims to remain technical I don't see much value in explaining the drama in detail or trying to take sides, because while all those are of varying importance to different people, practically the consensus in the community is that there is no more compile time reflection in sight in the near future, which is incredibly sad for everyone involved with the language. Procedural macros are a big and powerful tool, but their utility for indie game development is incredibly low, as their development cost and complexity is a bit too high to be used to solve minor issues that could've been solved by reflection with little to no effort.</p>
<h2 id="hot-reloading-is-more-important-for-iteration-speed-than-people-give-it-credit-for">Hot reloading is more important for iteration speed than people give it credit for</h2>
<p>Before we get into Rust and hot reloading, I'd like to mention a few things.</p>
<p>Firstly, if you haven't seen <a href="https://www.youtube.com/watch?v=72y2EC5fkcE">Tomorrow Corporation Tech Demo</a>, I would 100% recommend every single game developer to watch this video to see what is possible in terms of hot reloading, reversible debugging, and overall tooling for game development. If you think you know what these things are, watch the video anyway. I have long felt that hot reloading was important at least to some extent, but seeing what these guys have built on their own really makes me feel ashamed of ever feeling that certain workflows were adequate for developing interactive experiences.</p>
<p>For those who haven't watched the video, here's what the guys at Tomorrow Corporation have done:</p>
<ul>
<li>Built their own programming language, code editor, game engine, debugger, and games.</li>
<li>Built support for hot reloading across the whole stack.</li>
<li>Reversible time-travel debugging with a timeline that can scrub across game states.</li>
<li>... just watch the video :) I promise you won't regret it</li>
</ul>
<p>I understand that building something like this into an existing platform like .NET, or into a native language like C++ or Rust is borderline impossible in complete generality, but I also refuse the argument that just because it's hard and won't work 100% we shouldn't strive to want these things.</p>
<p>There are <em>many</em> existing platforms/languages that support hot reloading to various extents. During my exploration I went as far as making a game in Common Lisp in order to get a feel for its hot reloading capabilities. I wouldn't necessarily advise people do that, but one does not have to go that far.</p>
<p>Since .NET 6, it is now possible to do hot reloading in any C# project. Now I've heard people report mixed experiences on this, but I've also tried it myself, and it's a bit tough for me to take some of the arguments seriously, especially when they're from more recent times and not from "I tried it when it came out". In the context of Unity, there now is <a href="https://hotreload.net/">hotreload.net</a>, which is a custom implementation made specifically for Unity, which I've been using for about 4 months now, and which has been completely amazing in terms of productivity. This is actually the #1 reason we're moving back to Unity. It's not the reason we're abandoning Rust, but it is a reason we're going to Unity and not Godot or UE5. (At the time of writing Godot does not support .NET hot reload, and UE still only has blueprints and C++.)</p>
<p>For the purposes of this article, we can just focus on hot reloading bodies of functions, that is the only valid operation would be changing code inside of a function, and hot reloading that. Somehow this is a controversial topic in the Rust ecosystem, and many people will happily argue that it's not useful if it doesn't do everything, or that it's too restricted to be useful, or that the potential for bugs outweighs any possible benefits.</p>
<p>I have a very hard time emphasising with any of this in the context of game development. Games are anything but stateless data processors.</p>
<p>Few cases where hot reloading becomes incredibly useful:</p>
<ul>
<li>Immediate mode anything, be it UI or drawing. Even with fast compile times the iteration speed is significantly improved as one doesn't have to constantly re-enter the same state.</li>
<li>Debugging with immediate mode drawing/geometry. This is probably my favorite use case, especially around debugging character controllers and physics, where I might enter an unexpected/buggy state, and with hot reloading I can simply add a line few lines to draw the relevant values in-game to see what's happening without having to reproduce the issue again.</li>
<li>Tweaking constants that affect gameplay. While in some cases restarting the game with a new value would lead to a different result, games aren't scientific experiments. We don't need reproducibility, we need <em>fun</em>. It's much easier to optimize for fun when I can tweak values while playing. Crates like <a href="https://docs.rs/inline_tweak"><code>inline_tweak</code></a> are useful here, but they require foresight. Hot reloading allows me to work on an unrelated feature and randomly get an idea "I wonder what if" and just do it, without it being a detour in what I was doing before.</li>
</ul>
<p>It should be noted that Rust does in fact have a solution in the form of <a href="https://docs.rs/hot-lib-reloader/latest/hot_lib_reloader/"><code>hot-lib-reloader</code></a>, but having tried it it's nowhere near perfect, even for the very simple use case of just reloading functions. I've had it break on many random occasions, and ultimately gave up as it was causing me more effort to play around with it than it was saving. Even if this crate worked without any issues it doesn't solve the issue of randomly tweaking things, as it still requires planning and foresight, which reduces potential creative usage.</p>
<p>Many people counter hot reloading with "but the compiler does XYZ", to which I'd love to suggest something that would never get merged, but would be nice to have. What if there was a compiler flag ... and yes, I can already see people scream "the poor compiler team" ... I guess we'll never have this.</p>
<p>There many partial workarounds, but none of them get close to the utility of <em>true hot reloading</em>, which is what I'd call what .NET and Unity currently have. Scripting languages are a partial solution and problematic in Rust for many reasons, manually implemented hot reloading with dylibs is limited, and any form of state serialization and restarting again only works for big code changes, and not just tweakability. Not to say these things aren't useful, but I think we as game developers should desire higher level of tooling than just "I can reload a few structs in my code", especially when other mature platforms can support much more general workflows.</p>
<h2 id="abstraction-isn-t-a-choice">Abstraction isn't a choice</h2>
<p>This section is motivated by a very simple code sample I just wrote while working on our game. I have a UI with a list of characters, and a detail page that appears when a character (duck) is selected.</p>
<p>The way the UI is structured I just have helper functions for each state of the UI, as we're using <a href="https://egui.rs/"><code>egui</code></a> and immediate mode requires most things to be available in most places. This actually works great, because things like this will work</p>
<pre data-lang="rust"><code data-lang="rust"><span>egui::SidePanel::left("</span><span>left_panel</span><span>").</span><span>frame</span><span>(frame).</span><span>show_inside</span><span>(
</span><span>    ui,
</span><span>    |</span><span>ui</span><span>| {
</span><span>        ui.</span><span>vertical_centered</span><span>(|</span><span>ui</span><span>| {
</span><span>            </span><span>character_select_list_ducks</span><span>(egui, ui, gs, </span><span>self</span><span>);
</span><span>        });
</span><span>    },
</span><span>);
</span><span>
</span><span>egui::SidePanel::right("</span><span>right_panel</span><span>").</span><span>frame</span><span>(frame).</span><span>show_inside</span><span>(
</span><span>    ui,
</span><span>    |</span><span>ui</span><span>| {
</span><span>        </span><span>character_select_recover_builds</span><span>(ui, gs, </span><span>self</span><span>);
</span><span>    },
</span><span>);
</span><span>
</span><span>egui::TopBottomPanel::bottom("</span><span>bottom_panel</span><span>")
</span><span>    .</span><span>frame</span><span>(frame)
</span><span>    .</span><span>show_inside</span><span>(ui, |</span><span>ui</span><span>| {
</span><span>        </span><span>character_select_missing_achievements</span><span>(
</span><span>            egui, ui, gs, </span><span>self</span><span>,
</span><span>        );
</span><span>    });
</span></code></pre>
<p>But let's say some of these have conditional state, and their implementation is actually quite non-trivial. This is the case when selecting a specific duck. Initially, my code was the following</p>
<pre data-lang="rust"><code data-lang="rust"><span>egui::CentralPanel::default().</span><span>frame</span><span>(frame).</span><span>show_inside</span><span>(
</span><span>    ui,
</span><span>    |</span><span>ui</span><span>| {
</span><span>        </span><span>character_select_duck_detail</span><span>(ui, gs, </span><span>self</span><span>);
</span><span>    }
</span><span>});
</span><span>
</span><span>fn </span><span>character_select_duck_detail</span><span>(..., </span><span>state</span><span>: ...) {
</span><span>	</span><span>if let </span><span>Some(character) = state.selected_duck {
</span><span>	    </span><span>// some UI
</span><span>	} </span><span>else </span><span>{
</span><span>		</span><span>// other UI
</span><span>	}
</span><span>}
</span></code></pre>
<p>This again works fine, problem is <code>egui</code> will often require <em>very</em> deep nesting just because almost every layout operation is a closure. It would be very nice if we could reduce the nesting and move the <code>if</code> outside. As a result we'd also separate out two clearly separate things ... first instinct:</p>
<pre data-lang="rust"><code data-lang="rust"><span>if let </span><span>Some(character) = &amp;</span><span>self</span><span>.selected_duck {
</span><span>&nbsp; &nbsp; </span><span>character_select_duck_detail</span><span>(.., character, </span><span>self</span><span>);
</span><span>} </span><span>else </span><span>{
</span><span>   </span><span>character_select_no_duck</span><span>(...);
</span><span>}
</span></code></pre>
<p>But here we get slapped on the wrist, did I actually think I could get away with passing <code>self</code> around while also borrowing a field on <code>self</code>?</p>
<p>Even years into using Rust I still sometimes use too much of my brain thinking about the UI or game, and too little thinking about how I should be structuring my code, and end up with a problem like this. The Rust-y instinct would say "clearly you need to separate your state and not pass around a big struct", but this is a great example of how Rust clashes with the most natural way of doing things.</p>
<p>Because in this case we're building a single UI window. I don't want to spend any of my brain cycles thinking about what parts of the UI need what parts of the state, I just want to pass my state around, it's not that big. I also don't want to spend extra time passing around more fields when I add more fields 15 minutes down the line, which I'm almost certain I'll do. I also don't want to be separating things into more than one struct, because there's more than one thing I might want to do an <code>if</code> on, and having gone down the "splitting structs" path before, it rarely works out on first try.</p>
<p>The solution? As many things in Rust, we feel a bit of the 🤡 emotion (clown emoji for those who don't have the right installed), and then change the code to this:</p>
<pre data-lang="rust"><code data-lang="rust"><span>if let </span><span>Some(character) = &amp;</span><span>self</span><span>.selected_duck.</span><span>clone</span><span>() {
</span><span>&nbsp; &nbsp; </span><span>character_select_duck_detail</span><span>(.., character, </span><span>self</span><span>);
</span><span>} </span><span>else </span><span>{
</span><span>   </span><span>character_select_no_duck</span><span>(...);
</span><span>}
</span></code></pre>
<p>Everything now works, the borrow checker is happy, and we're cloning a string every frame. It won't show up in the profiler, so it really doesn't matter in the grand scheme of things. But it's especially sad for a language that aims to be so fast and optimal to have to resolve to wasting cycles on re-allocating memory more often than one would like, just to stay productive.</p>
<p>I only mention this specific case because it's quite indicative of my overall experience writing Rust, and where <em>many</em> problems are simply solved by extra copying or cloning. It's something most Rust developers are familiar with, but that came as a surprise to many people I was helping learn Rust. Their usual response is "wait I thought Rust was supposed to be very fast and efficient" ... all one can say to that is "oh it is fast, don't worry, in this case cloning the string every frame is totally harmless" and then feel the 🤡 emotion again.</p>
<h2 id="gui-situation-in-rust-is-terrible">GUI situation in Rust is terrible</h2>
<p>Just like there's a running joke of Rust having 5 games and 50 game engines, we probably need another joke for GUI frameworks. People are trying many different approaches, which in the complete generality of Rust as a language makes sense. But in this article we're focusing on gamedev, and I feel like this is something where we're not only seriously lacking, but I don't even see a way out.</p>
<p>Now when I say UI, I don't mean UI to build an editor, I mean in-game UI specifically. Something that has to be highly stylized and visual. At least in my experience, the hardest part about building game UI isn't figuring out how to do data binding, or how to make things reactively update, or even how to best describe my layout. It is customizing the look and feel of the UI.</p>
<p>This doesn't even touch on things like <em>particles in UI</em>, or various effects the user might want. Obviously a GUI library that is completely agnostic of everything can't have fancy shader effects and particles, but I think that's also part of the overall issue in approach. GUI libraries push all of this onto the user to figure out, and then every user is left to re-invent the wheel in their own framework/engine of choice.</p>
<p>We ended up doing the majority of our UI in <a href="https://egui.rs/"><code>egui</code></a>, which while sub-optimal and confusing in many ways at least provides a decent <a href="https://docs.rs/egui/latest/egui/struct.Painter.html"><code>Painter</code></a> interface for completely custom UI.</p>
<p>When mentioning this and saying how much better the UI situation is in Unity or Godot people always say something like <em>oh I tried Unity, it was terrible, I'm so much happier doing things in pure code</em>. A very common response, and one that I also used to say, which completely misses the point that building a UI is a skill, and doing so in a complex UI toolkit like Unity or Godot provide is complex and annoying because it is something that has to be learned.</p>
<h2 id="reactive-ui-is-not-the-answer-to-making-highly-visual-unique-and-interactive-game-ui">Reactive UI is not the answer to making highly visual, unique and interactive game UI</h2>
<p><a href="https://egui.rs/">There</a> <a href="https://areweguiyet.com/">are</a> <a href="https://github.com/linebender/druid">many</a> <a href="https://iced.rs/">GUI</a> <a href="https://dioxuslabs.com/">libraries</a> <a href="https://github.com/tauri-apps/tauri">in</a> <a href="https://github.com/lapce/floem">Rust</a>, with many different approaches. Some are bindings to existing GUI libraries, some are immediate mode, some are reactive, and some even retained mode. Some try to use flexbox, while others don't really deal with layout on a fundamental level.</p>
<p>The problem is that as far as game development is concerned, I'm not really sure if we have anything that approaches things the correct way. The reason we have so many libraries is the same reason we have so many game engines, it's because very few people in the Rust ecosystem are actually making games.</p>
<p>At least in my view, game GUI doesn't really care that much about data being updated the fastest, about having reactive re-rendering, data bindings, or the fanciest declarative way to describe a layout.</p>
<p>What I'd want instead is to have a very pretty GUI, with lots of custom sprites, animations, vector shapes, particles, effects, flashes, etc. I want my button to wiggle when it's clicked, I want my text to animate as it's hovered, I want to be able to use a custom shader and distort it with a noise texture. I want particles to fly around when a character box is selected.</p>
<p>I understand that some games might want to render a table with a million elements, but I don't think that should be a goal of a game GUI. I also understand many if not all of the ones linked above are not marketing themselves as a game GUI, but that is partly my point in this section.</p>
<p>As far as I'm aware, there isn't a single solution in the Rust ecosystem that would make it its goal to "be good at making game GUIs". I understand that having something like "particles and shaders" in a GUI is not going to be easy for a library that probably wants to be engine-agnostic, but this again might be another reason for why the situation is unlikely to improve.</p>
<p>I do think that most games want to have buttons that wiggle, text that is animated, boxes that rotate in all the weird ways, and maybe even some kind of ungodly blur effect for when that happens. Is that crazy to want such things?</p>
<h2 id="orphan-rule-should-be-optional">Orphan rule should be optional</h2>
<p>This section can probably be quite short, because I think anyone who's tried to write a decent amount of userland Rust will feel the pain of orphan rule. It's a great example of something I'd call "muh safety", a desire for perfection and complete avoidance of all problems at all costs, even if it means significantly worse developer ergonomics.</p>
<p>There are mostly valid reasons for wanting the orphan rule for things such as libraries uploaded to <a href="https://crates.io/">crates.io</a>, and I am willing to concede that crates published there should obey this.</p>
<p>But I have a very hard time caring about this rule for applications and libraries developed in end products. I'm explicitly not saying <em>binary crates</em>, because most bigger projects will be composed of more than one crate, and many will be more than one workspace.</p>
<p>Practically, I'd say this should be something we could disable even for published libraries, as some are not really libraries that are consumed by further downstream libraries. Game engines and frameworks are a good example of this, as people using libraries like <a href="https://macroquad.rs/">Macroquad</a> or <a href="https://comfyengine.org/">Comfy</a> really don't need those to uphold the orphan rule in their codebase. It'd be very beneficial for "framework-y" libraries to be able to extend existing things without forking, and provide more unified experience to end users.</p>
<p>But unfortunately, like many things in Rust, "perfection is only in the absolute", and just because there is chance that someone could possibly implemented a conflicting trait we must prohibit this for everyone in every circumstance with no option to disable it.</p>
<ul>
<li>Coroutines/async and closures have terrible ergonomics compared to higher level languages</li>
<li>Debugging in Rust is terrible no matter what tools you use or what OS you're on</li>
</ul>
<h2 id="compile-times-have-improved-but-not-with-proc-macros">Compile times have improved, but not with proc macros</h2>
<p>It's been a few years since Rust had truly terrible compile times, and the situation as a whole has certainly improved, at least on Linux. Incremental builds on Windows are still significantly slower, to the point where we initially ended up migrating to Linux (3-5x difference), but alas, at least after purchasing a new high end desktop it only takes a few seconds to build our 10k LoC codebase.</p>
<p>That is, after having spent extensive amounts of time optimizing compile times, removing proc macros, and moving things into their respective crates.</p>
<p>As a good example here, the only reason <a href="https://docs.rs/comfy-ldtk/latest/comfy_ldtk/"><code>comfy-ldtk</code></a> exists is to <a href="https://github.com/darthdeus/comfy/blob/master/comfy-ldtk/src/quicktype.rs">wrap a single file</a> and <a href="https://github.com/darthdeus/comfy/blob/master/comfy-ldtk/src/lib.rs#L10-L14"><em>ensure <code>serde</code>'s monomorphisation happens in a separate crate</em></a>. This might seem like a petty detail, but at least on my desktop this has resulted in incremental times of +10s instead of just 2s on Linux. A pretty gigantic difference for 1600 lines of struct definitions.</p>
<p>Now I understand, serialization isn't a trivial thing, and I understand <code>serde</code> has a lot of feature. But I also don't think there's any universe where paying 8 second to compile 1600 lines of code is anywhere near reasonable. Especially when you look at the code and see it's all just simple structs. There's no complex generic magic, all of this comes down to <code>serde</code> being slow.</p>
<p>I've seen many people not care about things like this, and having personally raised the issue of incremental compile times many times in many different contexts, and there's always a decent chunk of people who will convince me that it's fine, that their build takes 20-30 seconds or longer and that they're still being productive.</p>
<p>At the risk of angering some, I can only attribute this to lack of experience with better tooling, or simply their game not having reached a stage where they actually need to iterate quickly. Or at the very least, I feels like some people realize how much more polish could their games have if their compile times were 0.5s instead of 30s. Things like GUI are inherently tweak-y, and anyone but users of <a href="https://godot-rust.github.io/"><code>godot-rust</code></a> are going to be at the mercy of restarting their game multiple times in order to make things look good. If your experience here differs, I'd love to see an example of a very well polished and non-trivial amount of GUI that was built with a +30s incremental build time.</p>
<h2 id="rust-gamedev-ecosystem-lives-on-hype">Rust gamedev ecosystem lives on hype</h2>
<p>It's no news that the Rust gamedev ecosystem is young. When you ask around inside the community most people will admit this when issues are mentioned, and I'd say at least in 2024 we don't have an awareness issue as much anymore.</p>
<p>I would say that the outside world has a very different view though, and I will attribute this to very good marketing on the side of Bevy and a few others. Just a few days ago <a href="https://www.youtube.com/watch?v=EYt6uDr-PHQ">Brackeys released their video about coming back to gamedev to do Godot development</a>. As I've been watching this and started hearing about all the amazing opensource game engines I already had a feeling. At around 5:20 a picture of a <em>Game Engine Market Map</em> is shown, and I can only say I was truly shocked by seeing three Rust game engines there, and specifically which three: <a href="https://bevyengine.org/">Bevy</a>, <a href="https://github.com/aretegames/arete-engine">Arete</a> and <a href="https://github.com/ambientrun/ambient">Ambient</a>.</p>
<p>Now I want to make this extra clear, this blog post is not an attempt to take a stab at any specific project, and I understand those projects are not responsible for what other people are doing with their videos. But at the same time, this has become such a theme, or maybe even a meme, in the Rust world, that I feel it should be talked about.</p>
<p>The way the Rust ecosystem generally works is whichever project can make the most amount of promises, shows the best website/readme, has the flashiest gifs, and most importantly appeals to the right abstract values, gets widely praised, regardless of the usability of said project. Then there are other projects which are often under the radar, because they're not sexy and are not promising undeliverable features, but instead are just trying to do a thing in a way that works, and those end up almost never being mentioned, or when they are they're mentioned as second class choices.</p>
<p>The first example here is <a href="https://macroquad.rs/">Macroquad</a>, which is a very practical 2D game library, which runs on basically all platforms and has very simple API, compiles incredibly fast and has almost no dependencies, and was built by a single person. There's also an accompanying library <a href="https://github.com/not-fl3/miniquad"><code>miniquad</code></a> which provides a graphics abstraction on top of Windows/Linux/MacOS/Android/iOS and WASM. Macroquad has however committed the one of the highest crimes in the Rust ecosystem, and that is using global state, and even <a href="https://github.com/not-fl3/macroquad/issues/333">being potentially unsound</a>. I say potentially, even thoughI  understand that purists will say "no this isn't a question, it is wrong", because for all intents and purposes it is completely safe to use unless you decide to use the lowest level API to touch the OpenGL context. Having used Macroquad for almost 2 years now, I've never ran into this being an issue. It is however something that will forever be mentioned whenever it is suggested, because it does not appeal to the ultimate Rust value, 100% safety and correctness.</p>
<p>The second example is <a href="https://fyrox.rs/">Fyrox</a>, which is a 3D game engine with an actual full 3D scene editor, animation system, and seemingly everything needed to make a game. This project was also made by a single person, who is also making a full 3D game in said engine. Personally I have not used Fyrox, because just like this section mentions, I've been personally guilty of falling for the hype and picking projects that have pretty websites, lots of github stars, and present themselves a certain way. Fyrox has been gaining some traction on reddit lately, but it is truly sad for me how it almost never gets mentioned in any videos, despite having a full editor, which is something Bevy has been repeatedly promising for years now.</p>
<p>The third example is <a href="https://godot-rust.github.io/"><code>godot-rust</code></a>, which are Rust bindings to the <a href="https://godotengine.org/">Godot Engine</a>. The most serious crime committed by this library is that it's not a pure Rust solution, but instead just bindings to a filthy C++ engine. I'm exaggerating a bit, but those that are looking at Rust from the outside may be surprised how close to reality this sometimes is. Rust is pure, Rust is correct, Rust is safe. C++ is bad and old and ugly and unsafe and complex. That's why in Rust gamedev we don't use SDL, we have <a href="https://docs.rs/winit/latest/winit/"><code>winit</code></a>, we don't use OpenGL, we have <a href="https://wgpu.rs/"><code>wgpu</code></a>, we don't use Box2D or PhysX, we have <a href="https://rapier.rs/"><code>rapier</code></a>, we have <a href="https://docs.rs/kira/latest/kira/"><code>kira</code></a> for game audio, we don't use <a href="https://github.com/ocornut/imgui">Dear ImGUI</a>, we have <a href="https://egui.rs/"><code>egui</code></a>, and above all we surely can't use an existing game engine that's written in C++. That would be a violation of the sacred crab code that everyone who uses <code>rustup default nightly</code> to get faster compile times agrees on in the license (the same one that prohibits us from using the <a href="https://www.reddit.com/r/rust/comments/12lb0am/can_someone_explain_to_me_whats_happening_with/">logo (tm)(c) <del>officially</del> endorsed by the Rust foundation</a>).</p>
<p>If anyone is actually serious about making a real game in Rust, especially in 3D, my #1 recommendation would be to use Godot and <code>godot-rust</code>, because at least they end up having a fighting chance of delivering all the features they need to, because they can lean onto a real engine to help them deliver. We spent a year building <a href="https://store.steampowered.com/app/1673940/BITGUN/">BITGUN</a> with Godot 3 and gdnative using <code>godot-rust</code>, and while the experience has been painful in many ways, it wasn't the fault of the bindings, but rather trying to mix large amounts of GDScript and Rust in all the possible and dynamic ways. This was our first and biggest Rust project and what lead us down the Rust path, and ultimately I'd say <em>every</em> game we made using Rust afterwards was less of a game, simply because we spent a lot of time trying to figure out irrelevant technical issues with Rust-the-language, some part of the ecosystem, or just some design decision that ended up being difficult to solve because of the rigidity of the language. I'm not going to say GDScript and Rust interop was easy, it was definitely not. But at least there was the option of "just do the thing and move on" provided by Godot. I feel this is something most people who try code-only solutions don't value, especially in Rust where the language can get in the way of creativity in so many inconvenient ways.</p>
<p>I don't have much to say about Ambient because it is fairly new, and I have not used it, but again, I don't know of anyone else who has used it, and yet it made it into Brackeys video.</p>
<p><a href="https://www.reddit.com/r/rust/comments/16m3vzh/announcing_arete_a_rust_game_engine_1000x_faster/">Arete came out a few months ago with version 0.1</a>, and actually received a relatively negative response from the Rust community due to being very vague about its claims and being closed source at the same time. Despite that, I've seen it mentioned by outsiders on many occasions, often with very bold claims.</p>
<p>As far as Bevy is concerned, I do believe it being showcased as the "main" Rust game engine is mostly justified, if anything just because of the scale of the project and the number of people involved. They have managed to build a remarkably large community, and while I may disagree with their promises and some choices of the leadership, I can't deny the fact that Bevy is popular.</p>
<p>The purpose of this section is nothing but to bring some awareness to the strange state of things, where outsiders will often just look at how well is each engine marketing itself and what it says in their announcement blog posts. The reason I feel the need to mention all these things, is because I've followed this path more than once, and more than once saw very convincing things people would say, only to later realize that they're just very good at talking, but not as good at delivering on those features.</p>
<p>One notable mention that isn't a game engine is <a href="https://rapier.rs/"><code>rapier</code></a>, a physics engine that is <em>very often</em> recommended, as it promises to be a pure Rust solution to physics, a great alternative to the ugly outside world of Box2D, PhysX, and others. After all, Rapier is written in pure Rust, and thus enjoys all the benefits of WASM support, while also being blazingly fast, parallel at its core, and of course very safe ... right?</p>
<p>My experience here mostly comes from 2D, where while basic things do work, some of the more advanced APIs are fundamentally broken, for example <a href="https://github.com/dimforge/rapier/issues/377">convex decomposition crashing on relatively simple data</a>, or <a href="https://github.com/dimforge/rapier/issues/382">multibody joints causing a crash when they're removed</a>. The latter being especially funny, because this makes me feel like I was the first person to try to remove a joint, which doesn't seem like such advanced usage. These might seem like edge cases, but overall I've also found the simulation to be quite unstable, to the point where I ended up writing <a href="https://github.com/darthdeus/blobs">my own 2D physics engine</a>, and at least in my testing found it to cause less issues on simple things like "prevent enemies from overlapping".</p>
<p>This isn't an ad for my physics library, please don't use it, as it's not very well tested. The point is that if a newcomer to Rust asks for a recommendation for physics, they will be recommended rapier, and many will say it's a great and popular library. It also has a nice website and is widely known in the community. Having been that person and having really struggled for months and thinking <em>it must be me, I must be the one doing something wrong</em> the only reason I feel like I "found out" was because I tried to re-implement it myself.</p>
<p>A lot of the Rust ecosystem has a property of making the user feel like they're doing something fundamentally wrong, that they shouldn't be wanting to do a certain thing, that the project they want to build is undesirable or incorrect. It's a feeling similar to using Haskell and wanting to do side effects ... it's just not a thing "you're supposed to want".</p>
<p>Except in Rust's case, the problem is that very often libraries that end up causing the user to feel this way will get universal praise and recognition, because most of the ecosystem lives on hype, rather than shipped projects.</p>
<h2 id="global-state-is-annoying-inconvenient-for-the-wrong-reasons-games-are-single-threaded">Global state is annoying/inconvenient for the wrong reasons, games are single threaded.</h2>
<p>I know that just by saying "global state" I'm immediately triggering many people who have strong opinions on this being wrong. I feel this is one of those things where the Rust community has created a really harmful and unpractical rules to put on projects/people. Different projects have vastly different requirements, and at least in the context of game development I feel that many people are mis-judging what are the actual problems. The overall "hate" towards global state is a spectrum, and most won't be arguing 100% against it, but I still feel there's many things where the whole community is just going in a wrong direction. Just to reiterate, we're not talking about making engines, toolkits, libraries, simulations, or anything of the sort. We're talking about <em>games</em>.</p>
<p>As far as a game is concerned, there is only one audio system, one input system, one physics world, one <code>deltaTime</code>, one renderer, one asset loader. Maybe for some edge cases it would be slightly more convenient if some things weren't global, and maybe if you're making a physics based MMO your requirements are different. But most people are either building a 2D platformer, a top down shooter, or a voxel based walking simulator.</p>
<p>Having actually tried the <em>pure</em> approach where everything is injected as parameters multiple times over the years (starting with Bevy 0.4, up to 0.10), and having tried building <a href="https://comfyengine.org/">my own engine</a> where everything is global and playing a sound is just <code>play_sound("beep")</code>, my stance on what is more useful is quite clear.</p>
<p>This isn't meant to be specifically against Bevy, I do think a large part of the ecosystem is guilty of this, with the only exception being <a href="https://macroquad.rs/">macroquad</a>, but I'm using Bevy as an example because it sits on the other end of the spectrum where everything is passed around explicitly.</p>
<p>Here's some things I found very useful to have in Comfy that I use <em>all the time</em> in our games, that make use of global state:</p>
<ul>
<li><code>play_sound("beep")</code> for playing one off SFX. If more control is needed, one can use <code>play_sound_ex(id: &amp;str, params: PlaySoundParams)</code>.</li>
<li><code>texture_id("player")</code> for creating a <code>TextureHandle</code> to refer to an asset. There is no asset server to pass around, because at worst I could use paths as identifiers, and since paths are unique, obviously the identifiers will be too.</li>
<li><code>draw_sprite(texture, position, ...)</code>  or <code>draw_circle(position, radius, color)</code> for drawing. Since every non-toy engine will batch draw calls anyway, it's not like any of these would do much more than just push a draw command into a queue somewhere. I'm more than happy to have a global queue, because why would I care about passing around anything just to push a "draw circle" into a queue.</li>
</ul>
<p>If you're reading this as a Rust developer who isn't necessarily a game developer, you might be thinking "but what about threads???", and yes, this is also where Bevy servers as a good example. Because Bevy asked this question and tried to answer it in the most general way possible, <em>what if we just made all our systems run in parallel</em>.</p>
<p>This is a neat theoretical idea, and might seem appealing to many who are new to gamedev, because just like in backend land where things are all async and run on threadpools it might seem this would lead to free performance.</p>
<p>But unfortunately, I feel this is one of the biggest mistakes Bevy has made, and having been asking about this I feel many are starting to realize it too, although few really admit it. Bevy's parallel systems model is so flexible it doesn't maintain consistent ordering even across frames (at least last time I checked). If one wants to maintain ordering, they should specify a constraint.</p>
<p>This again seems reasonable at first, but having tried to make a non-trivial game in Bevy on more than one occasion (months of dev time, tens of thousands of lines of code), what ended up happening is the user ends up specifying a ton of dependencies anyway, because things in a game tend to need to happen in a specific order in order to avoid stuff being randomly delayed by one frame depending on what runs first, or even worse things just sometimes behaving weird because you got AB instead of BA. When you raise an issue about this, you'll be heavily argued against because what Bevy does is <em>technically correct</em>, but for the purposes of actually making a game ends up being a huge amount of pointless ceremony.</p>
<p>Now surely there must be an upside to this? Surely, all of this free parallelism is useful and makes games run blazingly faster?</p>
<p>Unfortunately, after all the work that one has to put into ordering their systems it's not like there is going to be much left to parallelize. And in practice, what little one might gain from this will amount to parallelizing a purely data driven system that could've been done trivially with data parallelism using <a href="https://docs.rs/rayon/latest/rayon/"><code>rayon</code></a>.</p>
<p>Looking back at all of gamedev over the years, I've written a lot more parallel code in Unity using Burst/Jobs than I have ever achieved in Rust games, both in Bevy and in custom code, simply because most of the work on games ends up being <em>the game</em>, with enough mental energy left to solve interesting problems. While in almost every Rust project I feel most of my mental energy is spent fighting the language, or designing things around the language, or at least making sure I don't lose too much developer ergonomics because something is done in a specific way because Rust requires it to be that way.</p>
<p>Global state is a perfect example in this category, and while this section is long, I feel like it really has to be explained a bit further. Let's begin by just defining the problem. In Rust as a language, there's generally a few options:</p>
<ul>
<li><code>static mut</code>, this is unsafe, meaning every usage needs <code>unsafe</code>, which gets very ugly and in the case of accidental misuse leads to UB.</li>
<li><code>static X: AtomicBool</code> (or <code>AtomicUsize</code>, or any other supported type) ... a decent solution that while a bit annoying at least isn't too annoying to use, but only works for simple types</li>
<li><code>static X: Lazy&lt;AtomicRefCell&lt;T&gt;&gt; = Lazy::new(|| AtomicRefCell::new(T::new()))</code> ... this ends up being necessary for the majority of types, and is not only annoying in terms of defining it and using it, but also leads to potential crashes at runtime due to double borrows.</li>
<li>... and of course "just pass it around, don't use global state"</li>
</ul>
<p>I can't count the number of cases where I've accidentally caused a crash because of a double borrow on something, and not because the code was "poorly designed to begin with", but because something else in the codebase forced a refactor, and as I was refactoring I ended up needing to also restructure my use of global state, leading to unexpected crashes.</p>
<p>Rust users would say that this means my code was doing something wrong and that it actually caught a bug for me, and that this is a good example of why global state is bad and should be avoided. This isn't completely false, and there are bugs that can happen and that would be prevented by this sort of checking. But practically speaking, and in terms of the types of errors I run into when using a language with easy global state like C#, I'd say that in the context of gamedev it's quite rare that any of these problems actually occur in real code.</p>
<p>On the other hand, crashes due to double borrows when doing <em>anything</em> with dynamic borrow checking are something that can happen very easily, and very often for the wrong reasons. One example being queries on overlapping archetypes with ECS. For the uninitiated, something like this is going to be a problem in Rust (simplified a bit for readability):</p>
<pre data-lang="rust"><code data-lang="rust"><span>for </span><span>(entity, mob) in world.query::&lt;&amp;</span><span>mut</span><span> Mob&gt;().</span><span>iter</span><span>() {
</span><span>  </span><span>if let </span><span>Some(hit) = physics.</span><span>overlap_query</span><span>(mob.position, </span><span>2.0</span><span>) {
</span><span>    println!("</span><span>hit a mob: </span><span>{}</span><span>", world.get::&lt;&amp;</span><span>mut</span><span> Mob&gt;(hit.entity));
</span><span>  }
</span><span>}
</span></code></pre>
<p>The problem being, we're touching the same thing from two different places. An even easier example would be iterating over pairs by doing something like this (again simplified)</p>
<pre data-lang="rust"><code data-lang="rust"><span>for</span><span> mob1 in world.query::&lt;&amp;</span><span>mut</span><span> Mob&gt;() {
</span><span>  </span><span>for</span><span> mob2 in world.query::&lt;&amp;</span><span>mut</span><span> Mob&gt;() {
</span><span>    </span><span>// ...
</span><span>  }
</span><span>}
</span></code></pre>
<p>Rust's rules prohibit having two mutable references to the same object, and anything that could potentially lead to this can't be allowed. In the above cases we'd get a runtime crash. Some ECS solutions work around this, e.g. in Bevy one can at least do partial overlaps when the queries are disjoint, e.g. <code>Query&lt;(Mob, Player)&gt;</code> and <code>Query&lt;(Mob, Not&lt;Player&gt;)&gt;</code>, but that only solves the case where nothing overlaps.</p>
<p>I'm mentioning this in a section on global state, because the existence of such limitations becomes especially apparent once things are made global, because it becomes very easy to accidentally touch a <code>RefCell&lt;T&gt;</code> that another part of the codebase is touching through some global reference. Again, Rust developers will say <em>this is good, you're preventing a potential bug!</em>, but I'll again defer to saying that I don't think I've felt many cases where this has actually saved me from doing something wrong, or where doing this in a language without such restrictions would cause an issue.</p>
<p>There's still the question of threading, but I think the main fallacy is where Rust game developers assume that games are the same as backend services where everything must run async in order to perform well. In game code one ends up having to wrap things in a <code>Mutex&lt;T&gt;</code> or <code>AtomicRefCell&lt;T&gt;</code> not to "avoid issues they'd run into otherwise if they were writing C++ and forgot to synchronize access", but rather just to satisfy the compiler's all encompassing desire to make <em>everything threadsafe</em>, even when there isn't a single <code>thread::spawn</code> in the whole codebase.</p>
<h2 id="dynamic-borrow-checking-causes-unexpected-crashes-after-refactorings">Dynamic borrow checking causes unexpected crashes after refactorings</h2>
<p>As I'm writing this I just discovered yet another case of our game crashing because of an overlapping <a href="https://docs.rs/hecs/latest/hecs/struct.World.html#method.query_mut"><code>World::query_mut</code></a>. We've been using <code>hecs</code> for about 2 years now, these aren't the trivial sort of "oh I accidentally nested two queries, oopsie" you run into when you first start using the library. But rather one part of the code being top level that runs a system that does something, and then an independent part of the code doing something simple with ECS somewhere deep down, and then through a large scale refactoring these end up overlapping unexpectedly.</p>
<p>It's not the first time I've had this happen, and the commonly suggested solution is "your code is just poorly structured, that's why you're running into these issues, you have to refactor and design it properly". Countering such arguments is relatively difficult, because at the core they're not wrong, this happens because some parts of the codebase were suboptimally designed. The problem is, it's yet another case of Rust forcing a refactoring where no other language would. Overlapping archetypes aren't necessarily a crime, and non-Rust ECS solutions like <a href="https://github.com/SanderMertens/flecs">flecs</a> are happy to allow this.</p>
<p>But this issue isn't limited to just ECS. We've had it happen time and time again with the use of <code>RefCell&lt;T&gt;</code>, where two <code>.borrow_mut()</code> end up overlapping and causing an unexpected crash.</p>
<p>The thing is, these aren't always just because of "bad code". People will say "borrow for the shortest amount you can" to work around the issue, but this isn't free. Obviously this again depends on having the code structured in the right way, but at this point I hope we've established that gamedev isn't server development, and code isn't always organized optimally. Sometimes one might have a loop that needs to use something from a <code>RefCell</code>, and it makes a lot of sense to extend the borrow over the whole loop instead of just borrowing where it's needed. This can immediately lead to an issue if the loop is large enough and calls a system that might need the same cell somewhere inside, usually with some conditional logic. Once could again argue "just use indirection and do the conditional thing through an event", but then again we're taking a tradeoff of having the gameplay logic spread over the codebase instead of just having 20 lines of obviously readable code.</p>
<p>In a perfect world everything would be tested on every refactoring, every branch would be evaluated, and code flow would be nicely linear and top down where these things don't ever occur. One wouldn't have to use a <code>RefCell</code> but would carefully design their functions so they can pass down the right context object or only the needed parameters.</p>
<p>Unfortunately, I don't see this being even remotely realistic for indie game development. Time spent refactoring a feature that might get removed 2 weeks down the line is time wasted, making <code>RefCell</code>s a desirable solution to partial borrows where otherwise data would have to be re-organized into differently shaped context structs, or function parameters would have to be changed all over the place to drill down the right parameters, or indirection would have to be employed to separate things out.</p>
<h2 id="context-objects-aren-t-flexible-enough">Context objects aren't flexible enough</h2>
<p>Since Rust has a relatively unique set of constraints on programmers, it ends up creating a lot of self-inflicted issues that end up having solutions that don't necessarily come up in other languages as often.</p>
<p>An example of this is a <em>context</em> object that gets passed around. In almost every other language it's not a big problem to introduce global state, be it in the form of global variables or singletons. Rust does unfortunately make that quite a bit more difficult for all sorts of reasons mentioned above.</p>
<p>First solution that one would come up with is "just store the references to whatever you need for later", but anyone who has used Rust for more than a few days will recognize that this is just not going to be possible. The borrow checker will require every reference field to have its lifetime tracked, and because lifetimes become generics that poison every single usage point of the type, it's not even something that can be easily experimented with.</p>
<p>There's more than one problem here, but I feel the need to point this out a bit more explicitly, as it may not be obvious to those who haven't tried. On a surface level, it may seem that "what if I just use the lifetimes?", e.g.</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Thing&lt;</span><span>'a</span><span>&gt;
</span><span>  x: &amp;'a i32
</span><span>}
</span></code></pre>
<p>The problem is, what if we now want a <code>fn foo(t: &amp;Thing)</code> ... well of course we can't, <code>Thing</code> is generic over a lifetime, so this has to become <code>fn foo&lt;'a&gt;(t: &amp;Thing&lt;'a&gt;)</code> or worse. Same thing if we try to store <code>Thing</code> in another struct, now we end up with</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Potato&lt;</span><span>'a</span><span>&gt;,
</span><span>  size: f32,
</span><span>  thing: Thing&lt;'a&gt;,
</span><span>}
</span></code></pre>
<p>and even though <code>Potato</code> might not really care about <code>Thing</code>, being in Rust lifetimes are to be taken with utmost seriousness, and we can't just ignore them. Things are actually much worse than they seem, because lets say you do end up going down this road, and try to figure out things with lifetimes.</p>
<p>Rust also does not allow unused lifetimes, so say that you have</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Foo&lt;</span><span>'a</span><span>&gt; {
</span><span>    </span><span>x</span><span>: &amp;</span><span>'a i32</span><span>,
</span><span>}
</span></code></pre>
<p>but as you're refactoring your codebase you end up wanting to change this to</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Foo&lt;</span><span>'a</span><span>&gt; {
</span><span>    </span><span>x</span><span>: </span><span>i32</span><span>,
</span><span>}
</span></code></pre>
<p>now that is of course completely prohibited, because you'd have an unused lifetime, and we can't have that. This may seem very minor, and <a href="https://github.com/ziglang/zig/issues/335">in some languages this is somehow desired even in simpler cases</a>, but the problem is lifetimes often require a decent amount of "problem solving" and "debugging" where one tries a few different things, and trying things with lifetimes often means adding or removing lifetimes, and removing lifetimes very often means "oh this is now unused, you have to remove it <em>everywhere</em>", leading to gigantic cascading refactorings. I have tried going down this road a few times over the years, and honestly, one of the most infuriating things is trying to iterate on a very simple change with lifetimes only to be forced to change 10 different places on every single change.</p>
<p>But even if the above wasn't the case, in many cases we can't just "store a reference to something" anyway, because the lifetimes wouldn't work out.</p>
<p>One alternative that Rust provides here is shared ownership, in the way of <code>Rc&lt;T&gt;</code> or <code>Arc&lt;T&gt;</code>. This of course works, but is heavily frowned upon. One of the things I've realized after using Rust for a while is that using these can actually save one quite a bit of sanity, although it does require not telling your Rust friends about the code you write anymore, or at least <a href="https://github.com/search?q=repo%3Adarthdeus%2Fcomfy+refcell&amp;type=code">hiding it and pretending it doesn't exist</a>.</p>
<p>Unfortunately, there are still many cases where shared ownership is just the bad solution, possibly for performance reasons, but sometimes you just don't have control over the ownership and can only get a reference.</p>
<p>The #1 trick in Rust gamedev is "if you pass in references top down every frame, all your lifetime/reference problems disappear". This actually works very well, and is similar to React's props being passed top down. There's only one issue, and that is that now you need to pass <em>everything</em> into <em>every</em> function that needs it.</p>
<p>At first it seems obvious and easy, just design your code correctly and you won't have any issues, lol. Or at least that's what many would say, and specifically "if you're having issues with this, your code is ugly/wrong/bad/spaghetti" or "you shouldn't be doing it that way" and you know, the usual.</p>
<p>Lucky for us, there is an actual solution, which is to create a <em>context</em> struct that is passed around and that contains all those references. This ends up having a lifetime, but only one, and ends up looking something like this:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>Context&lt;</span><span>'a</span><span>&gt; {
</span><span>  </span><span>player</span><span>: &amp;</span><span>'a mut</span><span> Player,
</span><span>  </span><span>camera</span><span>: &amp;</span><span>'a mut</span><span> Camera,
</span><span>  </span><span>// ...
</span><span>}
</span></code></pre>
<p>Every function in your game can then just accept a simple <code>c: &amp;mut Context</code> and get what it needs. Great, right?</p>
<p>Well, only as long as you don't end up borrowing anything. Imagine you want to run a player system, but also hold onto the camera. The <code>player_system</code> just like everything in the game wants <code>c: &amp;mut Context</code>, because you want to be consistent and avoid having to pass 10 different parameters into things. But when you try doing this:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> cam = c.camera;
</span><span>
</span><span>player_system</span><span>(c);
</span><span>
</span><span>cam.</span><span>update</span><span>();
</span></code></pre>
<p>you'll just be met with the usual "can't borrow <code>c</code> because it's already borrowed", as we touched a field, and the rules of partial borrows say that if you touch a thing the whole thing is borrowed.</p>
<p>It doesn't matter if <code>player_system</code> only touches <code>c.player</code>, Rust doesn't care what's on the inside, it only cares about the type, and the type says it wants <code>c</code>, so it must get <code>c</code>. This may seem like a dumb example, but in larger projects with larger context objects it becomes unfortunately quite common to want some subset of the fields somewhere, while also conveniently wanting to pass the rest of the fields elsewhere.</p>
<p>Now lucky for us, Rust isn't completely dumb, and it would allow us to do <code>player_system(c.player)</code>, because partial borrows allow us to borrow disjoint fields.</p>
<p>This is where defenders of the borrow checker will say that you simply designed your context object wrong, and that you should be splitting it up either into multiple context objects, or group your fields based on their usage so that partial borrows can be utilized. Maybe all the camera stuff is in one field, all the player stuff is in another field, and then we can just pass that field into <code>player_system</code> and not the whole <code>c</code> and everyone is happy, right?</p>
<p>Unfortunately, this falls under the #1 problem this article tries to address, and that is that what I want to be doing is working on my game. I'm not making games to have fun with the type system and figure out the best way to organize my struct to make the compiler happy. There is absolutely nothing I'm gaining in terms of maintainability of my single threaded code when I reorganize my context object. Having done this exact thing quite a few times I'm very much certain that the next time I have a playtest and get new suggestions for my game I'll probably have to change the design again.</p>
<p>The problem here is, the code is not being changed because the business logic is changing, it's being changed because the compiler isn't happy with something that is fundamentally correct. It may not follow the way the borrow checker works because it only looks at types, but it is correct in the sense that if we instead passed all the fields we're using it would compile just fine. Rust is making us make a choice between passing 7 different parameters or refactoring our struct any time something is moved around, where both of those options are annoying and wasting time.</p>
<p>Rust doesn't have a structural type system where we could say "a type that has these fields", or any other solution to this problem that would work without having to redefine the struct and everything that uses it. It simply forces the programmer to do the "correct" thing.</p>
<h2 id="positives-of-rust">Positives of Rust</h2>
<p>Despite the whole article being very much against Rust, I'd like to list a few things that I found as positives, and that really helped us during development.</p>
<p><strong>If it compiles it often kinda just works</strong>. This is both a meme but in some sense not really. There have been many times where I was surprised by how far one can take "compiler driven development" and actually succeed. Rust's biggest strength by far is that when one is writing code that is fitting for Rust, things go <em>very</em> well, and the language guides the user along the right path.</p>
<p>From my perspective the biggest strength here are CLI tools, data manipulation and algorithms. I've spent a non-trivial amount of time basically writing "Python scripts in Rust", where what would usually be small utilities that most would use Python or Bash for I chose to use Rust (both for learning and seeing if it'd work), and quite often I was surprised that this actually worked. I definitely would <em>not</em> want to be doing the same in C++.</p>
<p><strong>Performance by default</strong>. As we're moving back to C#, I ended up looking a bit into Rust vs C# performance at the more granular level, trying to match specific algorithms 1:1 between the two languages and tried to get performance as close as possible. Still, Rust would come out on top by a rough order of 1:1.5-2.5 after some efforts on the C# front. This probably isn't too surprising to those who consume benchmarks on a daily basis, but having gone through this myself and having really tried, I was very pleasantly surprised how naturally occurring Rust code would just be really fast.</p>
<p>I do want to point out that <a href="https://docs.unity3d.com/Packages/com.unity.burst@0.2/manual/index.html">Unity's Burst compiler</a> improves on C#'s performance quite a bit, but I don't have enough A/B data to provide specific numbers, and have only observed significant speedups on C# alone.</p>
<p>That being said, in all the years of Rust I've been continually pleasantly surprised how well the code runs, even despite doing very stupid things, which I often like to do. I will note that this is all predicated on having the following in <code>Cargo.toml</code></p>
<pre data-lang="toml"><code data-lang="toml"><span>[profile.dev]
</span><span>opt-level </span><span>= </span><span>1
</span><span>[profile.dev.package."</span><span>*</span><span>"]
</span><span>opt-level </span><span>= </span><span>1
</span></code></pre>
<p>As I've seen many many many people asking about things being slow, only to find they're just making a debug build. And just as Rust is very fast with optimizations turned on, it is <em>very slow</em> with optimizations turned off. I use <code>opt-level = 1</code> instead of <code>3</code> because in my testing I haven't noticed a difference in speed, but <code>3</code> compiled a bit slower, at least on the code I tested on.</p>
<p><strong>Enums are really nicely implemented</strong>. Everyone using Rust probably knows this, and I will say that as time passes I tend to move to more dynamic structuring of things rather than strictly with enums and pattern matching, but at least for the cases where enums fit, they end up being very nice to work with, and probably my favorite implementation across the languages I've used.</p>
<p><strong>Rust analyzer</strong>. I wasn't sure if I should put this in the positives or negatives. I'm putting it in the positives because I would 100% not be able to write Rust without it anymore. Having first started with Rust in 2013 or so, the tooling around the language has improved dramatically, to the point where it's actually very very useful.</p>
<p>The reason I considered putting it in the negatives is that it is still one of the more broken language servers I have used. I understand that this is because Rust is a complicated language, and having spoken to a lot of people about this, I think my projects might be just a bit cursed (it's probably my fault) because it tends to crash and not work for me all the time (yes I have updated, it's been happening for over a year across machines/projects). But despite all that, it's still incredibly useful and helpful, and significantly helps with writing Rust.</p>
<p><strong>Traits</strong>. While I'm not fully a fan of banishing inheritance completely, I do think the trait system is quite nice, and fits Rust very well. If only we could get some relaxation on the orphan rule things would be really great. Still, being able to use extension traits is one of my favorite things in the language.</p>
<h2 id="closing-thoughts">Closing thoughts</h2>
<p>We've been using Rust on basically all of our games since mid 2021. This was when <a href="https://store.steampowered.com/app/1673940/BITGUN/">BITGUN</a> initially started as a Godot/GDScript only project, and as we ran into issues with Godot's pathfinding (both performance and functionality wise) I looked into alternatives, found <code>gdnative</code>, and then was recommended <code>godot-rust</code>. It wasn't the first time I've seen or used Rust, but it was the first serious usage for game development, being preceeded only by game-jam-y projects.</p>
<p>Since then Rust was the langauge I used for everything. I got excited about things like building my own renderer/framework/engine, and early versions of <a href="https://comfyengine.org/">Comfy</a> were born. Many things followed, from <a href="https://logloggames.itch.io/bitmob-1-bit-jam">small game jam prototypes of CPU raytracing</a>, playing around with <a href="https://github.com/darthdeus/procedural-spider">simple 2D IK</a>, trying to write a <a href="https://github.com/darthdeus/blobs">physics engine</a>, implementing <a href="https://github.com/darthdeus/behavior-tree">behavior trees</a>, implementing a <a href="https://github.com/darthdeus/koryto">single threaded coroutine focused async executor</a>, to building <a href="https://store.steampowered.com/app/2326430/NANOVOID">simulation-y NANOVOID</a>, and finally <a href="https://store.steampowered.com/app/2331980/Unrelaxing_Quacks">Unrelaxing Quacks</a>, our first and last Comfy game to be released, which actually goes out today on Steam, at the same time as this article.</p>
<p>This article is in large part inspired by our struggles while working on NANOVOID and Unrelaxing Quacks, as these projects were unburdened by the lack of knowledge of Rust that we had while working on BITGUN initially. These projects also had the benefit of trying most of the Rust gamedev ecosystem on more than one occasion. We tried Bevy at more than one occasion, with BITGUN being the first game we tried to port, and Unrelaxing Quacks being the last. During the two years of developing what would become Comfy the renderer was rewritten from <a href="https://docs.rs/glow">OpenGL</a> to <a href="https://docs.rs/glow">wgpu</a> to OpenGL to wgpu again. At the time of writing this, I've been programming for roughly 20 years, starting with C++, and moving through all sorts of languages, spanning PHP, Java, Ruby, JavaScript, Haskell, Python, Go, C#, and having released a game on Steam in <a href="https://store.steampowered.com/app/1473870/Hell_Loop/">Unity</a>, <a href="https://store.steampowered.com/app/1561430/Urban_Mage/">Unreal Engine 4</a>, and <a href="https://store.steampowered.com/app/1673940/BITGUN/">Godot</a>. I'm the type of person who likes to experiment and try all sorts of approaches just to make sure I'm not missing something. Our games may not be the greatest by most measures, but we have thoroughly explored the options available with the hope of finding the most preferrable solution.</p>
<p>I'm saying all of this to dispel any ideas that there wasn't enough effort put into trying Rust, and that the article isn't written from a point of ignorance or not trying the <em>correct approach</em>. The #1 argument I hear people say when someone points out issues with Rust as a language is, jokingly, "you just don't have enough experience to appreciate this". We repeatedly tried both more dynamic and fully static approaches to doing things. We tried pure ECS, and we also tried no ECS.</p>
<p>For those reading this who are concerned about the future of Comfy, here's my thoughts on it.</p>
<p>Comfy has been largely "finished" from the perspective of 2D games. This should be evidenced that we're releasing a full game in it, and I want to clarify that our game runs against the master branch. If your goals are to build something of similar complexity and quality, it should be pretty obvious that you can.</p>
<p>That being said, there are still things that are desirable that Comfy does not currently provide, namely improvements on custom shaders and post processing passes. There's also the question of "maintenance future" since I won't be working on any more Rust games.</p>
<p>Those that have been active on our Discord already know that the plan is to port Comfy's renderer to <a href="https://macroquad.rs/">Macroquad</a>, which means completely removing all traces of <code>wgpu</code> and <code>winit</code>, and instead using Macroquad for windowing, input, and rendering. There's a few reasons and benefits we get from this:</p>
<ul>
<li>A large portion of the codebase can be just deleted, along with many weird edge cases. Users don't gain anything from "having a custom wgpu renderer", what matters is functionality, and that won't change.</li>
<li>Shaders and post processing become a lot more flexible, just by the fact that Macroquad already has everything in place.</li>
<li>More platforms supported, as Macroquad/Miniquad has the widest reach in the ecosystem, and Comfy currently runs only on things that wgpu runs on.</li>
<li>Stable future, where Comfy can become a high level convenience layer on top of something that is maintained by an existing community where people know what they're doing.</li>
</ul>
<p>Some maybe asking why this wasn't done in the first place. Initially, some of our Comfy projects were written on top of Macroquad, but at some point I wanted to have HDR and Bloom, which Macroquad did not support. Comfy was created by copy-pasting Macroquad's APIs and extending them with z-indexing and y-sorting, and re-implementing the whole renderer underneath.</p>
<p><a href="https://github.com/not-fl3/miniquad/commit/04c0c76547dbaac2985bc3263fcef34739a210e6#diff-34b433796cb09381278b47772e25e075eec7fc7115447b0735b3a19aee3f3c4f">But as of recently, Miniquad/Macroquad now does support <code>f16</code> textures</a>, which means we can get all of that without needing a custom renderer. There's already an <a href="https://github.com/darthdeus/comfy/pull/97">ongoing effort to port things</a>, but has been largely stale due to our attempt to release Unrelaxing Quacks in a timely manner. I do however plan to resume working on this after the release, and considering basic things already work there, I'm hopeful the port shouldn't end up being too complicated.</p>
<hr>
<p>Lastly, I will do a shameless plug for our latest game, because after almost a year of working on it it would be stupid not to :)</p>
<p><a href="https://store.steampowered.com/app/2331980/Unrelaxing_Quacks/">Unrelaxing Quacks</a> is a survivors game, but fast. It's a game that puts you straight into action and doesn't waste your time. Thanks to Rust we managed to have <em>lots</em> of enemies and projectiles while still achieving great performance.</p>
<p><img src="https://loglog.games/blog/leaving-rust-gamedev/endgame.gif" alt="./endgame.gif"></p>
<p>We've also put a lot of effort into polishing the absolute core mechanics such as movement and shooting, to make sure everything <em>felt good</em>.</p>
<p><img src="https://loglog.games/blog/leaving-rust-gamedev/potato-duck.gif" alt="./potato-duck.gif"></p>
<p><strong>If you liked the article and would want to support us, buy the game and review it on Steam. It doesn't have to be positive, be honest about how you felt when playing!</strong> Reviews greatly help the developer as Steam will increase the game's visibility once it reaches 10 reviews, regardless of whether they're positive or negative.</p>
<p><img src="https://loglog.games/blog/leaving-rust-gamedev/corruption.gif" alt="./corruption.gif"></p>

<hr>
<p>If you'd like to comment on the article, the respective discussion is here on <a href="https://www.reddit.com/r/programming/comments/1cdqd3m/lessons_learned_after_3_years_of_fulltime_rust/">/r/programming</a> and <a href="https://www.reddit.com/r/rust/comments/1cdqdsi/lessons_learned_after_3_years_of_fulltime_rust/">/r/rust</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Data breach at Kaiser Permanente affects 13.4M people (104 pts)]]></title>
            <link>https://restoreprivacy.com/data-breach-at-kaiser-permanente-affects-13-4-million-people/</link>
            <guid>40171909</guid>
            <pubDate>Fri, 26 Apr 2024 17:15:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restoreprivacy.com/data-breach-at-kaiser-permanente-affects-13-4-million-people/">https://restoreprivacy.com/data-breach-at-kaiser-permanente-affects-13-4-million-people/</a>, See on <a href="https://news.ycombinator.com/item?id=40171909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<figure><img fetchpriority="high" decoding="async" width="900" height="450" src="https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People.jpg" alt="Data Breach at Kaiser Permanente Affects 13.4 Million People" srcset="https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People-300x150.jpg 300w, https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People-768x384.jpg 768w, https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People.jpg 900w" sizes="(max-width: 900px) 100vw, 900px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20900%20450'%3E%3C/svg%3E" data-lazy-srcset="https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People-300x150.jpg 300w, https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People-768x384.jpg 768w, https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People.jpg 900w" data-lazy-src="https://cdn-resprivacy.pressidium.com/wp-content/uploads/2024/04/Data-Breach-at-Kaiser-Permanente-Affects-13.4-Million-People.jpg"></figure>



<p>Kaiser Permanente, a leading healthcare organization in the United States, has disclosed a data breach impacting approximately 13.4 million of its members and patients.</p>



<p>The breach involved unintended transmission of personal information to third-party vendors, including major tech companies Google, Microsoft Bing, and X (formerly Twitter), via installed online technologies on Kaiser’s websites and mobile apps.</p>



<p>Kaiser Permanente is renowned for its integrated healthcare services, offering both healthcare plans and medical services to millions across the country. It operates as a non-profit healthcare provider with a network that includes numerous hospitals and a comprehensive range of medical facilities.</p>



<p>The data exposure was discovered following an internal investigation conducted voluntarily by Kaiser Permanente. The company discovered that online trackers used on its websites and mobile applications were transmitting certain types of personal data when users interacted with its services.</p>



<p>The information potentially shared includes:</p>



<ul>
<li>IP addresses</li>



<li>Names of users</li>



<li>Indicators of a user being logged into a Kaiser account</li>



<li>User interactions and navigation details on the sites and apps</li>



<li>Search terms entered into Kaiser’s health encyclopedia</li>
</ul>



<p>Kaiser Permanente noted in a statement shared with RestorePrivacy that sensitive data such as usernames, passwords, Social Security numbers, and financial details were not part of the data transmitted to third parties.</p>



<p>In response to these alarming findings, the organization removed the offending technologies from all its platforms. Additional security measures have been adopted to prevent similar incidents based on the guidance provided by the contracted cybersecurity experts.</p>



<p>Despite no evidence suggesting the misuse of the disclosed data, Kaiser Permanente has opted to inform all <a href="https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf" target="_blank" rel="noreferrer noopener">13.4 million</a> of the potentially affected individuals as a precautionary measure.</p>



<p>Kaiser Permanente members and patients are advised to remain vigilant by monitoring their account statements and health services interactions for any unusual activity. Although financial data was not compromised, staying informed about the latest updates from Kaiser regarding this incident is advisable as later-stage investigation findings may expand the scope of the impact.</p>



<p>The American healthcare system has been plagued by the widespread use of online trackers that extract sensitive medical information from healthcare portals and distribute it to a broad network of advertisers, as numerous high-profile cases have brought this issue to light.</p>



<p>RestorePrivacy has previously highlighted similar exposures at <a href="https://restoreprivacy.com/wakemed-informs-half-million-americans-their-data-was-exposed/" target="_blank" rel="noreferrer noopener">WakeMed</a>, <a href="https://restoreprivacy.com/ftc-fines-goodrx-1-5m-for-sharing-health-data-with-google-facebook/" target="_blank" rel="noreferrer noopener">GoodRx</a>, and <a href="https://restoreprivacy.com/cerebral-to-pay-7-million-for-using-trackers-on-its-site/" target="_blank" rel="noreferrer noopener">Cerebral</a>, while UCSF Medical Center, Dignity Health Medical Foundation, Novant Health, and Advocate Aurora Health have also reported high-volume exposures from trackers.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The brutal business practices of Amazon (121 pts)]]></title>
            <link>https://www.vanityfair.com/news/story/inside-amazon-business-practices</link>
            <guid>40171551</guid>
            <pubDate>Fri, 26 Apr 2024 16:49:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vanityfair.com/news/story/inside-amazon-business-practices">https://www.vanityfair.com/news/story/inside-amazon-business-practices</a>, See on <a href="https://news.ycombinator.com/item?id=40171551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In May of 2020, seven members of the House Judiciary Antitrust Subcommittee penned a letter to then CEO of Amazon <strong>Jeff Bezos.</strong> “On April 23,” their message began, <em>The Wall Street Journal</em> “reported that Amazon employees used sensitive business information from third-party sellers on its platform to develop competing products.” The article contradicted previous sworn testimony from the company’s general counsel, possibly rendering the testimony “false or perjurious,” the seven congressional leaders wrote.</p><p>The <em>Journal</em>’s exposé, which ultimately spurred Bezos’s first-ever congressional testimony, was written by <strong>Dana Mattioli</strong> as part of the paper’s wide-ranging investigation into Amazon’s business practices. At the time, Mattioli, a longtime business reporter, had recently moved into the Amazon beat, her interest piqued by the corporation’s tentacular infiltration of nearly every aspect of American economic life. Now, four years later, she’s out with <em><a data-offer-url="https://www.amazon.com/Everything-War-Dana-Mattioli/dp/0316269778" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Everything-War-Dana-Mattioli/dp/0316269778&quot;}" href="https://www.amazon.com/Everything-War-Dana-Mattioli/dp/0316269778" rel="noopener" target="_blank">The Everything War</a>,</em> a new book-length examination of Amazon that explores everything from its rise to power to its lobbying efforts and the brewing backlash against it.</p><p>In this interview with <em>Vanity Fair,</em> edited for length and clarity, Mattioli and I spoke about the challenges of reporting on an infamously secretive and combative company, Amazon’s forays into political-influence peddling, its new foe in the Biden administration, and which candidate she thinks Amazon execs want to see back in the White House come January 2025.</p><p><strong><em>Vanity Fair:</em> What first got you interested in covering Amazon?</strong></p><p><em>Dana Mattioli:</em> I was <em>The</em> <em>Wall Street Journal</em>’s mergers-and-acquisitions reporter for six years, and in that role, my job was to cover which companies are buying other companies across industries globally. Something fascinating happened during my tenure in that role. It wasn’t just retail companies that were nervous about Amazon. I’d speak to the bankers, the lawyers, the CEOs, the board members at different companies, and they started talking about how they were worried about Amazon invading their industry. Over the course of those six years, those questions got louder. It started bleeding into other sectors where you wouldn’t even really think about Amazon at the time. The company seemed to stretch into every vertical and its tentacles kept spreading. It occurred to me that this was the most interesting company, but also one of the most secretive companies in business history. That to me seemed like such a fun challenge to dig in and see what was going on behind the scenes.</p><p><strong>What are the sorts of challenges reporters covering the company face?</strong></p><p>I would say that, as it relates to me, they didn’t provide access, but that doesn't mean I didn’t get access. I spoke to 17 S-team members—the most senior people at the company—for this book, without the company knowing. I spoke to hundreds of people in and around the company. I had hundreds of pages of internal documents. They didn’t really cooperate for the book in setting up interviews, and I understand why. Some of my investigations at the <em>Journal</em> had been very hard-hitting. One of them was the basis for Jeff Bezos’s being called to testify to Congress for the first time in his career. So they didn't participate on an official basis, but I of course did a full fact-check. Out of fairness, I incorporate their PR statements and rebuttals very generously throughout. But it is an interesting company from a PR standpoint. There was an <a href="https://www.motherjones.com/politics/2021/06/amazon-journalists-pr-tactics/" target="_blank">investigation from <em>Mother Jones</em></a> about the company bullying reporters, how they have lied to reporters in the past, and how that makes things difficult for reporters trying to cover the company. And that investigation questions whether that’s a tactic to get people to back off and not even want to cover them in the first place.</p><p><strong>What do you think it is about Amazon’s internal culture that made so many employees willing to talk to you?</strong></p><p>Amazon is the most interesting company culture and the most aggressive one I’ve ever covered. It’s a giant company. More than a million people work there. The turnover and the burnout is much higher than at most other companies. People tend not to last, because it’s very aggressive and it can be bruising. As a result of that, a lot of people have come to me—both people still there and people that have left—to tell me their experiences.</p><p>When I delve into what goes on behind the scenes and the anticompetitive business behaviors that make Amazon win so often, a lot of it is the product of this culture. A lot of the shocking behaviors are because of this company’s culture. If you’re auditioning for your job every day, and you’re auditioning against every other brilliant employee there, and you know that at the end of the year, 6% of you are going to get cut no matter what, and at the same time, you have access to unrivaled data on partners, sellers, and competitors, you might be tempted to look at that data to get an edge and keep your job and get to your restricted stock units. If you’re at [Amazon] and you’re meeting with [outside companies] on the dealmaking side or the Alexa venture capital side, you might be tempted to not forget what you learned in those meetings and use it on a product to have a home run.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun's New Crash Reporter (229 pts)]]></title>
            <link>https://bun.sh/blog/bun-report-is-buns-new-crash-reporter</link>
            <guid>40171183</guid>
            <pubDate>Fri, 26 Apr 2024 16:20:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.sh/blog/bun-report-is-buns-new-crash-reporter">https://bun.sh/blog/bun-report-is-buns-new-crash-reporter</a>, See on <a href="https://news.ycombinator.com/item?id=40171183">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>At the time of writing, Bun has over <a href="https://github.com/oven-sh/bun">2,600 open GitHub issues</a>. We love having users and feedback, but some issues are really hard for us to reproduce and debug.</p><p>Apps and SaaS products get to use wonderful crash reporting services like <a href="https://sentry.io/">Sentry</a>, but for CLI tooling like Bun, uploading core dumps has privacy, performance, and executable size tradeoffs that are harder to justify.</p><p>That's why in Bun v1.1.5, I wrote a compact new format for Zig and C++ crash reports. The crash report fits in a ~150 byte URL containing zero personal information.</p><figure><a href="https://bun.sh/images/crash-report-1.png"><img src="https://bun.sh/images/crash-report-1.png" alt=""></a></figure><h2 level="2" anchor-id="why-not-just-use-the-os-crash-reporter" id="why-not-just-use-the-os-crash-reporter"><a name="why-not-just-use-the-os-crash-reporter"></a><a href="#why-not-just-use-the-os-crash-reporter">Why not just use the OS crash reporter?</a></h2><p>Some operating systems like macOS have built-in crash reporters, but that usually means shipping debug symbols with the application. For Linux, these debug symbols are around 30 MB and macOS around 9 MB.</p><p>And on Windows, the <code>.pdb</code> file is over 250 MB</p><div><pre><code><span><span>(gi bun.pdb).Length </span><span>/</span><span> </span><span>1</span><span>mb</span></span></code></pre></div><p>30 MB - 250 MB is a huge amount of bloat to add to every install of Bun.</p><p>But without debug symbols, crashes are pretty limited. And with <a href="https://en.wikipedia.org/wiki/Address_space_layout_randomization">Address space layout randomization</a> in the mix, all of the function addresses are made useless.</p><div><pre><code><span><span>uh-oh: reached unreachable code</span></span>
<span><span>bun will crash now 😭😭😭</span></span>
<span><span></span></span>
<span><span>----- bun meta -----</span></span>
<span><span>Bun v1.1.0 (5903a614) Windows x64</span></span>
<span><span>AutoCommand:</span></span>
<span><span>Builtins: "bun:main"</span></span>
<span><span>Elapsed: 27ms | User: 0ms | Sys: 0ms</span></span>
<span><span>RSS: 91.69MB | Peak: 91.69MB | Commit: 0.14GB | Faults: 22579</span></span>
<span><span>----- bun meta -----</span></span>
<span><span></span></span>
<span><span>Search GitHub issues https://bun.sh/issues or join in #windows channel in https://bun.sh/discord</span></span>
<span><span></span></span>
<span><span>thread 104348 panic: reached unreachable code</span></span>
<span><span>???:?:?: 0x7ff62a629f17 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62a907a83 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62a61f392 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62ade7ff1 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62ab2193c in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62ab21166 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62cd3ddeb in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62b7a4bb6 in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x7ff62b7a33bd in ??? (bun.exe)</span></span>
<span><span>???:?:?: 0x1bab9ca115d in ??? (???)</span></span>
<span><span>???:?:?: 0x1bab9ca111f in ??? (???)</span></span>
<span><span></span></span></code></pre></div><h2 level="2" anchor-id="the-new-crash-reporter" id="the-new-crash-reporter"><a name="the-new-crash-reporter"></a><a href="#the-new-crash-reporter">The new crash reporter</a></h2><p>In Bun v1.1.5, when a crash or panic occurs, Bun prints a message like this:</p><div><pre><code><span><span>Bun v1.1.5 (0989f1a) Windows x64</span></span>
<span><span>Args: "C:\Users\dave\.bun\bin\bun.exe", ".\crash.js"</span></span>
<span><span>Builtins: "bun:main"</span></span>
<span><span>Elapsed: 40ms | User: 15ms | Sys: 15ms</span></span>
<span><span>RSS: 92.80MB | Peak: 92.80MB | Commit: 0.14GB | Faults: 22857</span></span>
<span><span></span></span>
<span><span>panic(main thread): Internal assertion failure</span></span>
<span><span>oh no: Bun has crashed. This indicates a bug in Bun, not your code.</span></span>
<span><span></span></span>
<span><span>To send a redacted crash report to Bun's team,</span></span>
<span><span>please file a GitHub issue using the link below:</span></span>
<span><span></span></span>
<span><span>https://bun.report/1.1.5/wa10989f1aAAg6xyL+rqoIwzn0F+oqC0v5R+52pGkr6Om7h+Oy3voK+9qoKA0eNrzzCtJLcpLzFFILC5OLSrJzM9TSEvMzCktSgUAiSkKPg</span></span>
<span><span></span></span></code></pre></div><p>This <code>bun.report</code> link, when clicked, redirects to open a pre-filled GitHub issue form, with the remapped stack trace encoded in the URL.</p><figure><a href="https://github.com/oven-sh/bun/assets/24465214/18867c15-663b-469a-ba98-1088e6bbd424"><img src="https://github.com/oven-sh/bun/assets/24465214/18867c15-663b-469a-ba98-1088e6bbd424" alt=""></a></figure><h2 level="2" anchor-id="making-addresses-useful" id="making-addresses-useful"><a name="making-addresses-useful"></a><a href="#making-addresses-useful">Making addresses useful</a></h2><p>The function addresses are pointers in memory to where the application code is loaded, which includes a randomized offset for security reasons. This means if we try and demangle these, we get nothing.</p><div><pre><code><span><span>llvm-symbolizer --exe ./bun.pdb 0x7ff62a629f17 0x7ff62a907a83</span></span></code></pre></div><p>The trick is to simply subtract the address from the base address of the binary.</p><div><pre><code><span><span>pub</span><span> </span><span>fn</span><span> </span><span>getRelativeAddress</span><span>(address: </span><span>usize</span><span>) ?</span><span>usize</span><span> {</span></span>
<span><span>    </span><span>const</span><span> module = </span><span>getModuleFromAddress</span><span>(address) </span><span>orelse</span><span> {</span></span>
<span><span>      </span><span>// Could not resolve address! This can be hit for some</span></span>
<span><span>      </span><span>// Windows internals, as well as JIT'd JavaScript.</span></span>
<span><span>      </span><span>return</span><span> </span><span>null</span><span>;</span></span>
<span><span>    };</span></span>
<span></span>
<span><span>    </span><span>return</span><span> address </span><span>-</span><span> module.base_address;</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>In reality, this function is <a href="https://github.com/oven-sh/bun/blob/2abe6e7c3f6f66771bb9eac6365699353590bfa9/src/crash_handler.zig#L803">a lot more complicated</a>, as there are different APIs for each platform.</p><p><strong>Note</strong> – What I referred to as a "module" above is only the case for Windows. It called an "image" on macOS, and a "shared object" on Linux. They all refer to the same concept of a loaded library or executable in memory. For simplicity, I'll continue to refer to them as "modules".</p><ul><li><strong>Windows</strong>: Call <a href="https://learn.microsoft.com/en-us/windows/win32/api/libloaderapi/nf-libloaderapi-getmodulehandleexw"><code>GetModuleHandleExW</code></a> with the <code>GET_MODULE_HANDLE_EX_FLAG_FROM_ADDRESS</code> flag. The base address is the pointer of the module.</li><li><strong>Linux</strong>: Use <a href="https://man7.org/linux/man-pages/man3/dl_iterate_phdr.3.html"><code>dl_iterate_phdr</code></a> to iterate over the loaded modules, once you find one that the raw address is contained in, <code>.dlpi_addr</code> on the <code>dl_phdr_info</code> struct will be the base address.</li><li><strong>macOS</strong>: The functions <a href="https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/dyld.3.html"><code>_dyld_image_count</code></a> and <code>_dyld_get_image_header</code> can be used to iterate over modules, and then <code>_dyld_get_image_vmaddr_slide</code> gets the ASLR slide.<ul><li>The resulting address still includes an offset to the image (for Bun it is <code>0x100000000</code>, can list these in lldb with <code>image list</code>). To encode a shorter URL, this offset is removed, but it <a href="https://github.com/oven-sh/bun.report/blob/7ff10116749b38bacc17fe0de7c47d7633b10d01/backend/remap.ts#L94">must be re-added before remapping</a> or else <code>llvm-symbolizer</code> will fail.</li></ul></li></ul><p>For Linux and MacOS, the first module refers to the main application binary. On Windows, you can compare the module's name to <a href="https://learn.microsoft.com/en-us/windows/win32/api/winternl/ns-winternl-rtl_user_process_parameters#members"><code>peb.ProcessParameters.ImagePathName</code></a> to determine if it is the main binary.</p><p>Normally, once the module and relative address are resolved, the application will immediately open debug symbols and demangle the function. To avoid the cost of downloading and parsing debug symbols, let's offload demangling to a server. This server could cache all of the debug symbols, and demangle stack traces within seconds. At the same time, it can serve as the link to open a new GitHub issue.</p><h2 level="2" anchor-id="bun-report-s-url-structure" id="bun-report-s-url-structure"><a name="bun-report-s-url-structure"></a><a href="#bun-report-s-url-structure">bun.report's URL Structure</a></h2><figure><a href="https://bun.sh/images/crash-report-1.png"><img src="https://bun.sh/images/crash-report-1.png" alt=""></a></figure><p>Let's take another look at this URL, and break down how it is been encoded:</p><ul><li><strong>Platform</strong>: A single character indicating the platform. <code>w</code> is for x86_64 Windows, <code>M</code> is for aarch64 macOS, and <a href="https://github.com/oven-sh/bun/blob/2abe6e7c3f6f66771bb9eac6365699353590bfa9/src/crash_handler.zig#L778">so on</a>.</li><li><strong>Subcommand</strong>: A single character indicating the <a href="https://github.com/oven-sh/bun/blob/2abe6e7c3f6f66771bb9eac6365699353590bfa9/src/cli.zig#L2028">subcommand</a>, such as <code>bun test</code>, <code>bun install</code>, or <code>bun run</code>.</li><li><strong>Commit SHA</strong>: The commit SHA of the current version of Bun. This is used to fetch debug symbols later.</li><li><strong>Feature Flags</strong>: Indicators for what APIs and features were used before Bun crashed.</li><li><strong>Stack Trace Addresses</strong>: The addresses calculated earlier.</li><li><strong>Crash Type</strong>: A single character indicating the <a href="https://github.com/oven-sh/bun/blob/2abe6e7c3f6f66771bb9eac6365699353590bfa9/src/crash_handler.zig#L54">type of crash</a>.</li><li><strong>Crash Message</strong>: The message from the crash, the format of this depending on the type.</li></ul><p><strong>Note</strong> – The version number in the URL is actually just for show. This is so that given just the info above, one can figure out a lot about the crash by hand. For example, you can quickly identify a windows crash by the <code>w</code> platform identifier. Less trivially, you could identify a segmentation fault by looking for <code>A2</code> near the end of the string.</p><h2 level="2" anchor-id="vlqs-are-fun" id="vlqs-are-fun"><a name="vlqs-are-fun"></a><a href="#vlqs-are-fun">VLQs are fun</a></h2><p>To keep the URL reasonably short, the stack trace addresses are encoded using base64 <a href="https://en.wikipedia.org/wiki/Variable-length_quantity">Variable Length Quantity</a> numbers. This allows small numbers to be encoded with less characters, while still being able to encode large numbers. This is the same technique used in JavaScript source maps for storing line numbers.</p><p>The transformation looks like this. Notice how the VLQ encodes smaller addresses as smaller numbers.</p><figure><a href="https://bun.sh/images/crash-report-2.png"><img src="https://bun.sh/images/crash-report-2.png" alt=""></a></figure><p>The server can <a href="https://github.com/oven-sh/bun.report/blob/7ff10116749b38bacc17fe0de7c47d7633b10d01/lib/parser.ts#L104">decode these back into relative addresses</a>, <a href="https://github.com/oven-sh/bun.report/blob/7ff10116749b38bacc17fe0de7c47d7633b10d01/backend/debug-store.ts#L46">download debug symbols</a> using the commit hash and platform, and use <code>llvm-symbolizer</code> to demangle the function names.</p><figure><a href="https://bun.sh/images/crash-report-3.png"><img src="https://bun.sh/images/crash-report-3.png" alt=""></a></figure><p>It now becomes plainly obvious what happened: There is a tripped assertion in <code>dirInfoCachedMaybeLog</code>, which came from part of the module resolver code on Windows.</p><h2 level="2" anchor-id="what-are-features" id="what-are-features"><a name="what-are-features"></a><a href="#what-are-features">What are "Features"</a></h2><p>The URL also encodes a 64-bit integer, where each bit corresponds to if a certain feature in Bun was used. These flags give a hint as to what APIs and systems could have led the crash. For example, the <code>dotenv</code> feature is set when any <code>.env</code> file is automatically loaded, <code>fetch</code> is set when <code>fetch()</code> is used, and so on. (<a href="https://github.com/oven-sh/bun/blob/e3689e7e83507ae9c63dac7d785e41884daead66/src/analytics/analytics_thread.zig#L82-L109">Full list</a>)</p><p>Zig's compile-time metaprogramming makes creating this bitfield easy. We already had a container of global variables for tracking features.</p><div><pre><code><span><span>pub</span><span> </span><span>const</span><span> </span><span>Features</span><span> = </span><span>struct</span><span> {</span></span>
<span><span>    </span><span>pub</span><span> </span><span>var</span><span> bunfig: </span><span>usize</span><span> = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>pub</span><span> </span><span>var</span><span> http_server: </span><span>usize</span><span> = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>pub</span><span> </span><span>var</span><span> shell: </span><span>usize</span><span> = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>pub</span><span> </span><span>var</span><span> spawn: </span><span>usize</span><span> = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>pub</span><span> </span><span>var</span><span> macros: </span><span>usize</span><span> = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>// ... and so on</span></span>
<span><span>};</span></span>
<span></span></code></pre></div><p>And inside various APIs, we would increment these numbers to mark usage of a feature.</p><p>For encoding these into a single <code>u64</code> integer, we can use <code>std.meta</code> to iterate over the list of features and create a list.</p><div><pre><code><span><span>pub</span><span> </span><span>const</span><span> feature_list = brk: {</span></span>
<span><span>    </span><span>const</span><span> decls = std.meta.</span><span>declarations</span><span>(</span><span>Features</span><span>);</span></span>
<span><span>    </span><span>var</span><span> names: [decls.len][:</span><span>0</span><span>]</span><span>const</span><span> </span><span>u8</span><span> = </span><span>undefined</span><span>;</span></span>
<span><span>    </span><span>var</span><span> i = </span><span>0</span><span>;</span></span>
<span><span>    </span><span>for</span><span> (decls) </span><span>|</span><span>decl</span><span>|</span><span> {</span></span>
<span><span>        </span><span>if</span><span> (</span><span>@TypeOf</span><span>(</span><span>@field</span><span>(</span><span>Features</span><span>, decl.name)) </span><span>==</span><span> </span><span>usize</span><span>) {</span></span>
<span><span>            names[i] = decl.name;</span></span>
<span><span>            i </span><span>+=</span><span> </span><span>1</span><span>;</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>const</span><span> names_const = names[</span><span>0</span><span>..i].</span><span>*</span><span>;</span></span>
<span><span>    </span><span>break</span><span> :brk names_const;</span></span>
<span><span>};</span></span>
<span></span></code></pre></div><p>Then, a packed struct can be created dynamically derivied to use one bit per feature. This structure functions like an integer, but interacts like a struct.</p><div><pre><code><span><span>// note: some fields omitted for brevity</span></span>
<span><span>pub</span><span> </span><span>const</span><span> </span><span>PackedFeatures</span><span> = </span><span>@Type</span><span>(.{</span></span>
<span><span>    .</span><span>Struct</span><span> = .{</span></span>
<span><span>        .layout = .@"packed",</span></span>
<span><span>        .backing_integer = </span><span>u64</span><span>,</span></span>
<span><span>        .fields = brk: {</span></span>
<span><span>            </span><span>var</span><span> fields: [</span><span>64</span><span>]</span><span>StructField</span><span> = </span><span>undefined</span><span>;</span></span>
<span><span>            </span><span>for</span><span> (feature_list, </span><span>0</span><span>..) </span><span>|</span><span>name, i</span><span>|</span><span> {</span></span>
<span><span>                fields[i] = .{ .name = name, .</span><span>type</span><span> = </span><span>bool</span><span> };</span></span>
<span><span>            }</span></span>
<span><span>            fields[feature_list.len] = .{</span></span>
<span><span>                .name = </span><span>"__padding"</span><span>,</span></span>
<span><span>                .</span><span>type</span><span> = </span><span>@Type</span><span>(.{ .</span><span>Int</span><span> = .{ .bits = </span><span>64</span><span> </span><span>-</span><span> feature_list.len } }),</span></span>
<span><span>            };</span></span>
<span><span>            </span><span>break</span><span> :brk fields[</span><span>0</span><span>..feature_list.len </span><span>+</span><span> </span><span>1</span><span>];</span></span>
<span><span>        },</span></span>
<span><span>    },</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>And finally, when Bun crashes, the bitfield can be constructed very trivially using <code>inline for</code>, a way to iterate over something at compile time, but perform the inner contents at runtime.</p><div><pre><code><span><span>pub</span><span> </span><span>fn</span><span> </span><span>packedFeatures</span><span>() </span><span>PackedFeatures</span><span> {</span></span>
<span><span>    </span><span>var</span><span> bits = </span><span>PackedFeatures</span><span>{};</span></span>
<span><span>    </span><span>inline</span><span> </span><span>for</span><span> (feature_list) </span><span>|</span><span>name</span><span>|</span><span> {</span></span>
<span><span>        </span><span>if</span><span> (</span><span>@field</span><span>(</span><span>Features</span><span>, name) &gt; </span><span>0</span><span>) {</span></span>
<span><span>            </span><span>@field</span><span>(bits, name) = </span><span>true</span><span>;</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>return</span><span> bits;</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>Now, adding a new feature to the original struct <code>Features</code> will properly handle it in the crash reporter, without needing to repeat ourselves.</p><p>Doing this sort of thing is possible with C or Rust via macros, but I feel like it's so much simpler and readable with Zig <code>comptime</code>.</p><h2 level="2" anchor-id="how-does-this-compare-to-a-core-dump" id="how-does-this-compare-to-a-core-dump"><a name="how-does-this-compare-to-a-core-dump"></a><a href="#how-does-this-compare-to-a-core-dump">How does this compare to a core dump?</a></h2><p>Core dumps have a lot more information, but they are massive, need debug symbols to be useful, and include lots of potentially sensitive or confidential information.</p><p>We wanted to avoid the possibility of sending any JavaScript/TypeScript source code, environment variables, or other sensitive information in the reports. This is why we only send the Zig/C++ stack trace and a few other details. Instead of sending everything by default, this approach sends only what we (probably) need to diagnose the issue. If we need more information, we can ask the user to provide it, but this is so much better than nothingness of a bunch of unmapped addresses we had before.</p><h2 level="2" anchor-id="demo" id="demo"><a name="demo"></a><a href="#demo">Demo</a></h2><p>To put it all together, I wrote a small webapp that lets you test out the crash reporter, which is available at the homepage, <a href="https://bun.report/1.1.5/wa10989f1aAAg6xyL+rqoIwzn0F+oqC0v5R+52pGkr6Om7h+Oy3voK+9qoKA0eNrzzCtJLcpLzFFILC5OLSrJzM9TSEvMzCktSgUAiSkKPg/view">bun.report</a>. It is also where you end up if you append <code>/view</code> to the end of any crash report URL.</p><h2 level="2" anchor-id="bun-is-hiring-in-san-francisco" id="bun-is-hiring-in-san-francisco"><a name="bun-is-hiring-in-san-francisco"></a><a href="#bun-is-hiring-in-san-francisco">Bun is hiring in San Francisco</a></h2><p>If you're interested in working on projects like this, we're hiring engineers in San Francisco! We're looking for systems engineers to help build the future of JavaScript. <strong><a href="https://bun.sh/careers">Apply here</a></strong></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jon Pretty wins in court against sexual harassment claims by Scala community (120 pts)]]></title>
            <link>https://pretty.direct/statement.html</link>
            <guid>40169578</guid>
            <pubDate>Fri, 26 Apr 2024 14:05:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pretty.direct/statement.html">https://pretty.direct/statement.html</a>, See on <a href="https://news.ycombinator.com/item?id=40169578">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <h2>Jon Pretty, 26 April 2024</h2>
  <p>
   I am a Scala developer and speaker who was cancelled three years ago.
   Yesterday I attended the High Court in London to hear an apology from several
   prominent members of the Scala community for making untrue claims about me on
   27 April 2021. I sued them for libel, and they admitted fault and settled,
   paying me costs and damages.
  </p>
  <p>
   Their allegations were sensational and squalid, but unfounded. Their source was
   the resentment of one woman following a relationship in 2018, which I ended
   against her wishes. She fabricated or was offered an alternative narrative, which developed
   into claims of a pattern of behaviour, and culminated in the defendants’
   publication of an open letter, which they now agree is defamatory.
  </p>
  <p>
   In two years of legal action, the defendants never presented any evidence to
   support their allegations, and admitted in court that they had no proper reason
   to make them. They have given undertakings to the court not to publish further
   or similar defamatory statements, or have anyone else do so on their behalf.
  </p>
  <p>
   No signatory contacted me about the allegations before publication. I received
   no warning, and had no knowledge of the claims’ substance. I only discovered
   what I was accused of at the same time as I learned of my indefinite exclusion
   from the community; at the same time everyone else found out. I had no
   opportunity to defend myself. It is no coincidence that the absence of due
   process led to an abject injustice.
  </p>
  <p>
   The experience of cancellation and enduring the online hysteria was traumatic.
   I responded by withdrawing from the life I knew. Its consequences hurt me and
   people close to me, and have been immiserating.
  </p>
  <p>
   My employment opportunities were obliterated. My charitable and educational
   projects, and my small business, could not continue. Despite my transferable
   skills, the allegations were a transferrable red flag recognised across
   programming communities and industries, and I have barely earned a living
   since. It has taken two years of legal action to receive fair scrutiny in a
   forum reliant on facts. This outcome finally vindicates me.
  </p>
  <p>
   Many familiar with the open letter will be surprised by this outcome, given the
   certainty expressed by some of the letter’s supporters. But they should
   question why no defence of my libel claim was ever offered. They should seek
   answers for how so many people became so convinced without evidence. And the
   defendants’ co-signatories should reassess the credibility of everything that
   compelled them to support the open letter.
  </p>
  <p>
   Nonetheless, I believe the open letter’s authors were convinced it was the
   right thing to do. I believe that they wished to show their kindness in
   response to a story which shocked them. Many of them I have known for years,
   and know to be good, moral people who were mistaken, and would not wish to be
   mistaken.
  </p>
  <p>
   Good people can make mistakes, without becoming bad people. So, I offer them
   the respect and compassion I believe they deserve. I recognise their good
   intent, and I interpret its consequences charitably. We owe each other civility
   in ceding the time and space necessary to reflect upon this in open enquiry,
   without coercion or urgency, so everyone can reach a better understanding of
   this outcome, and of one another.
  </p>
  <p>
   I have avoided naming any third parties here, and I urge others to do the same.
   I know too well how it feels to be the subject of online harassment, and I do
   not wish it upon anyone. I reject the culture of blame and escalation.
  </p>
  <p>
   I have not been idle since 2021. I’ve spent much of my time writing Scala 3,
   which I believe is an exceptional platform for software development, and
   deserves far greater success. I am motivated to be part of that success, and I
   will start sharing my work again soon.
  </p>
  <p>
   █
  </p>
  <p>
   <a href="https://pretty.direct/consentorder.pdf"><b>Consent Order and Statement in Open Court</b> (The Honourable Mrs Justice Steyn DBE)</a>
  </p>
  
 


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[GM collects driver behavior data then sells access to insurance companies (103 pts)]]></title>
            <link>https://www.techdirt.com/2024/04/26/people-are-slowly-realizing-their-auto-insurance-rates-are-skyrocketing-because-their-car-is-covertly-spying-on-them/</link>
            <guid>40169341</guid>
            <pubDate>Fri, 26 Apr 2024 13:46:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/04/26/people-are-slowly-realizing-their-auto-insurance-rates-are-skyrocketing-because-their-car-is-covertly-spying-on-them/">https://www.techdirt.com/2024/04/26/people-are-slowly-realizing-their-auto-insurance-rates-are-skyrocketing-because-their-car-is-covertly-spying-on-them/</a>, See on <a href="https://news.ycombinator.com/item?id=40169341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-436887">


<h3>from the <i>everything-you-own-is-spying-on-you</i> dept</h3>

<p>Last month the New York Times’ Kashmir Hill&nbsp;<a href="https://www.nytimes.com/2024/03/14/technology/gm-lexis-nexis-driving-data.html">published a major story</a>&nbsp;on how GM collects driver behavior data then sells access (through LexisNexis) to insurance companies, which will then jack up your rates.</p>
<p>The&nbsp;<strong>absolute bare minimum</strong>&nbsp;you could could expect from the auto industry here is that they’re doing this in a way that’s clear to car owners. But of course they aren’t; they’re burying “consent” deep in the mire of some hundred-page end user agreement nobody reads, usually not related to the car purchase — but the apps consumers use to manage roadside assistance and other features.</p>
<p>Since Kashmir’s story was published, <a href="https://www.nytimes.com/2024/04/23/technology/general-motors-spying-driver-data-consent.html">she says she’s been inundated with complaints</a> by consumers about similar behavior. She’s even discovered that she’s one of the folks GM spied on and tattled to insurers about. In a <a href="https://www.nytimes.com/2024/04/23/technology/general-motors-spying-driver-data-consent.html">follow up story</a>, she recounts how she and her husband bought a Chevy Bolt, were auto-enrolled in a driver assistance program, then had their data (which they couldn’t access) sold to insurers. </p>
<p>GM’s now facing 10 different federal lawsuits from customers pissed off that they were surreptitiously tracked and then forced to pay significantly more for insurance:</p>
<blockquote>
<p><em>“In 10 federal lawsuits filed in the last month, drivers from across the country say they did not knowingly sign up for Smart Driver but recently learned that G.M. had provided their driving data to LexisNexis. According to one of the complaints, <span>a Florida owner of a 2019 Cadillac CTS-V who drove it around a racetrack for events saw his insurance premium nearly double, an increase of more than $5,000 per year.”</span></em></p>
</blockquote>
<p>GM (and some apologists) will of course proclaim that <em>this is only fair</em> that reckless drivers pay more, but that’s generally not how it works. Pressured for unlimited quarterly returns, insurance companies will use absolutely anything they find in the data to justify rising rates. </p>
<p>And as the sector is getting automated by sloppy AI, those determinations <a href="https://www.techdirt.com/2023/11/21/ai-is-supercharging-our-broken-healthcare-systems-worst-tendencies/">aren’t going to go in your favor</a> (see: AI’s rushed implementation in healthcare). That’s before the fact that consumers aren’t being told about the surveillance, and aren’t given a clear option to stop it. Or that the data is also being sold to a litany of dodgy data brokers who, in turn, see minimal oversight.</p>
<p>If this follows historical precedent, GM will pay out a relative pittance in legal fees and fines, claim they’ve changed their behavior, then simply rename these programs into something else after heavy consultation with their legal department. Something more carefully crafted, with bare-bones consumer alerts, to exploit the fact that the U.S. remains too corrupt to pass even a baseline modern privacy law. </p>
<p>Automakers — which have long had some of the <a href="https://www.techdirt.com/2023/09/07/mozilla-modern-cars-are-a-privacy-shitshow/">worst privacy reputations in all of tech</a> — are one of countless industries that lobbied relentlessly for decades to ensure Congress never passed a federal privacy law or regulated dodgy data brokers. And that the FTC — the over-burdened regulator tasked with privacy oversight — lacks the staff, resources, or legal authority to police the problem at any real scale.</p>
<p>The end result is just a parade of scandals. And if Hill were so inclined, she could write a similar story about every tech sector in America, given everything from your smart TV and electricity meter to refrigerator and kids’ toys now monitor your behavior and sell access to those insights to a wide range of dodgy data broker middlemen, all with nothing remotely close to ethics or competent oversight. </p>
<p>And despite the fact that this free for all environment is resulting in <a href="https://www.vice.com/en/article/8xwngb/t-mobile-put-my-life-in-danger-says-victim-of-black-market-location-data">no limit</a> of dangerous <a href="https://www.techdirt.com/2024/02/15/wyden-data-broker-used-abortion-clinic-visitor-location-data-to-help-send-targeted-misinformation-to-vulnerable-women/">real-world harms</a>, our Congress has been lobbied into gridlock by a cross-industry coalition of companies with near-unlimited budgets, all desperately hoping that their <a href="https://www.techdirt.com/2024/03/15/a-tiktok-ban-is-a-pointless-political-turd-for-democrats/">performative concerns about TikTok</a> will distract everyone from the fact we live in a country too corrupt to pass a real privacy law.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/auto/" rel="tag">auto</a>, <a href="https://www.techdirt.com/tag/auto-insurance/" rel="tag">auto insurance</a>, <a href="https://www.techdirt.com/tag/auto-insurance-rates/" rel="tag">auto insurance rates</a>, <a href="https://www.techdirt.com/tag/car/" rel="tag">car</a>, <a href="https://www.techdirt.com/tag/data-brokers/" rel="tag">data brokers</a>, <a href="https://www.techdirt.com/tag/privacy/" rel="tag">privacy</a>, <a href="https://www.techdirt.com/tag/surveillance/" rel="tag">surveillance</a>
<br>
Companies: <a href="https://www.techdirt.com/company/gm/" rel="category tag">gm</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK's Investigatory Powers Bill to become law despite tech world opposition (188 pts)]]></title>
            <link>https://www.theregister.com/2024/04/26/investigatory_powers_bill/</link>
            <guid>40168765</guid>
            <pubDate>Fri, 26 Apr 2024 12:45:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/04/26/investigatory_powers_bill/">https://www.theregister.com/2024/04/26/investigatory_powers_bill/</a>, See on <a href="https://news.ycombinator.com/item?id=40168765">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The UK's contentious Investigatory Powers (Amendment) Bill (IPB) 2024 has officially received the King's nod of approval and will become law.</p>
<p>Dubbed the "snooper's charter" by critics, it aims to widen the digital surveillance powers of the existing Investigatory Powers Act 2016 (IPA) used by UK intelligence services, the police, government, and some emergency services.</p>
<p>Before the <a target="_blank" href="https://www.gov.uk/government/collections/investigatory-powers-amendment-bill">latest amendments</a> came into force, the IPA already allowed authorized parties to gather swathes of information on UK citizens and tap into telecoms activity – phone calls and SMS texts.</p>

    

<p>The IPB's amendments add to the Act's existing powers and help authorities trawl through more data, which the government claims is a way to tackle "modern" threats to national security and the abuse of children.</p>

        


        

<p>"The world-leading Investigatory Powers regime is crucial to keeping the public safe," said security minister Tom Tugendhat. "That's why we're making urgent, targeted changes to the Investigatory Powers Act to ensure our laws keep pace with rapidly changing technology and to guard against modern threats to national security.&nbsp;&nbsp;&nbsp;</p>
<p>"These changes mean that not only will our citizens be better protected from serious dangers such as terrorism and child sexual abuse online – their privacy will be better protected too."</p>

        

<p>The UK government has positioned the changes, which include an expanded remit to collect data on UK citizens en masse, as a means to afford intelligence agencies and the National Crime Agency (NCA) "greater agility and speed" in responding to threats.</p>
<p>Among those alterations is the ability for authorities to surveil targets by gathering their internet connection records. This will allow investigators to determine who connected to what service – such as an app or website – what phone number they dialed, where they were at the time, and when they did so.</p>
<p>The amendments also expand authorities' ability to gather bulk datasets of personal information on individuals who have a low or no expectation of privacy. This includes data such as CCTV footage or images posted to social media.</p>

        

<p>There was hope among the Bill's opposers that some of the more controversial changes would be repealed following loud concerns over privacy infringements, but the UK's hardline stance on national security has prevailed.</p>
<p>Will Richmond-Coggan, privacy and data protection partner at national law firm Freeths, told <em>The Register</em>: "The amendments made to the Investigatory Powers (Amendment) Bill were ultimately welcomed by the House of Lords, but are unlikely to be welcomed by campaigners or tech companies who were concerned about the wide-ranging scope of notice provisions in relation to the introduction of new privacy-enhancing technologies which would also have the effect of impeding lawful surveillance.&nbsp;</p>
<p>"Additional safeguards have been introduced – notably, in the most recent round of amendments, a 'triple-lock' authorization process for surveillance of parliamentarians – but ultimately, the key elements of the Bill are as they were in early versions – the final version of the Bill still extends the scope to collect and process bulk datasets that are publicly available, for example."</p>
<p>Naturally, privacy campaigners strongly oppose the IPB and the changes that it brings to UK law, saying they expand an already robust arsenal of tools to collect data on UK citizens in bulk.</p>
<p>Tech trade body techUK <a target="_blank" href="https://www.techuk.org/resource/joint-statement-concerns-regarding-the-investigatory-powers-amendment-bill.html" rel="nofollow">said</a> in a March statement that it had "substantial concerns" about the Bill, which was being "rushed" through parliament without proper scrutiny.</p>
<p>It believes the IPB will weaken the safety rails that guide the intelligence services when collecting data in bulk, and that it could lead to the wider data harvesting of millions of facial images, internet records, and social media data.</p>
<p>techUK told <em>The Register</em> this week: "As the Investigatory Powers (Amendment) Bill receives Royal Assent, we are disappointed that the government did not address the widespread concerns about its potential negative impacts.&nbsp;</p>
<p>"We remain concerned that these reforms will weaken privacy protections, expand surveillance powers, hinder security innovation, and risk exacerbating international conflicts of law without sufficient safeguards.&nbsp;</p>
<p>"As we look towards the next steps for this legislation, with consultations on how these regulations will work in practice, we look forward to further engagement to ensure a more workable and proportionate regime."</p>
<ul>

<li><a href="https://www.theregister.com/2023/09/20/uk_online_safety_bill_passes/">UK Online Safety Bill to become law – and encryption busting clause is still there</a></li>

<li><a href="https://www.theregister.com/2018/05/14/encryption_hindering_law_enforcement_says_nca/">Wah, encryption makes policing hard, cries UK's National Crime Agency</a></li>

<li><a href="https://www.theregister.com/2023/09/07/uk_government_clause_online_safety_bill/">UK admits 'spy clause' can't be used for scanning encrypted chat – it's not 'feasible'</a></li>

<li><a href="https://www.theregister.com/2016/06/06/gchq_oversight/">Letters prove GCHQ bends laws to spy at will. So what's the point of privacy safeguards?</a></li>
</ul>
<p>Privacy International said: "Sadly, but not surprisingly, [the IPB] has changed little from the government's original proposal, which means its becoming law is a major concern.&nbsp;</p>
<p>"The Bill waters down already insufficient safeguards in the Investigatory Powers Act. It makes mass surveillance easier and gives the UK the option to attempt to control, and perhaps lessen, the security and privacy of internet services used by billions of people around the world."</p>
<h3>Potential threat to security updates in commercial software</h3>
<p>Other key concerns revolve around the IPB's amendment that would <a target="_blank" href="https://www.theregister.com/2023/11/07/ukgov_wants_prior_notice_of/">force tech companies to consult the UK government</a> before rolling out security updates to software.&nbsp;</p>
<p>It's a big one that opposers of the Bill think will undermine the security posture of the UK, and potentially lead to unnecessarily protracted delays in rolling out key security features, thus making the country a more popular target for cybercriminals.</p>
<p>Apple, for example – a company that famously <a target="_blank" href="https://www.theregister.com/2016/02/17/apple_help_fbi_san_bernardino/">refused to bend even to the FBI</a> after they wanted to crack open the San Bernadino shooter's iPhone, said it would consider pulling iMessage and FaceTime from the UK over fears they would be forced to weaken security.</p>
<p>The company branded the IPB's rule "an unprecedented overreach by the government," adding it believes the changes are an "attempt to secretly veto new user protections globally, preventing us from ever offering them to customers."</p>
<p>Abigail Burke, platform power program manager at the Open Rights Group, previously told <em>The Register</em>, before the IPB was debated in parliament, that the proposals amounted to an "attack on technology."</p>
<p>The IPB, of course, goes hand-in-hand with the <a target="_blank" href="https://www.theregister.com/2018/05/14/encryption_hindering_law_enforcement_says_nca/">long-running calls to break end-to-end encryption (E2EE)</a>, which the government also claims impedes its efforts to tackle national security threats. It once again <a target="_blank" href="https://www.nationalcrimeagency.gov.uk/who-we-are/publications/712-joint-declaration-of-the-european-police-chiefs/file" rel="nofollow">echoed these views</a> [PDF] just this week, in fact.</p>
<p>The Online Safety Bill was also <a target="_blank" href="https://www.theregister.com/2023/09/20/uk_online_safety_bill_passes/">passed last year</a> after a rocky process that garnered equally loud concerns from privacy campaigners about a so-called "spy clause" that aimed to capture encrypted private messages.</p>
<p>Although the UK government admitted that scanning encrypted chats <a target="_blank" href="https://www.theregister.com/2023/09/07/uk_government_clause_online_safety_bill/">wasn't "technically feasible"</a>, it didn't rule out the possibility of invoking a request for companies to do so in the future, perhaps at a time when, or if, E2EE becomes illegal in the UK, for example. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm creating PBR Textures and 3D models since 2018 and sharing them for free (360 pts)]]></title>
            <link>https://www.sharetextures.com/</link>
            <guid>40168519</guid>
            <pubDate>Fri, 26 Apr 2024 12:23:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sharetextures.com/">https://www.sharetextures.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40168519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next" data-reactroot=""><div><p><span><span></span><img alt="Logo of sharetextures" src="https://www.sharetextures.com/logo.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><div><div><div><form action="#"></form></div><div><p><h4>by &nbsp;<span translate="no">sharetextures</span></h4></p><div><svg width="24" height="24" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64"><path d="M32 60.444a17.777 17.777 0 0 1-17.778-17.777V21.333a17.778 17.778 0 0 1 35.556 0v21.334A17.778 17.778 0 0 1 32 60.444Zm0-53.333a14.222 14.222 0 0 0-14.222 14.222v21.334a14.222 14.222 0 0 0 28.444 0V21.333A14.222 14.222 0 0 0 32 7.111Z" fill="#fff"></path><path d="M32 26.667a1.778 1.778 0 0 1-1.778-1.778v-7.111a1.778 1.778 0 1 1 3.556 0v7.11A1.778 1.778 0 0 1 32 26.668Z" fill="#fff"></path></svg><p>for more, <b>please scroll down.</b></p></div></div></div><div><p><span>Artwork by: <a href="https://www.behance.net/olga_antonenko" rel="noreferrer nofollow" target="_blank"><b>Olga Antonenko</b></a></span></p></div></div><div><div><h2><span>High</span><br><span>Quality &amp; Quantity</span></h2><p>“We provide high-quality 3D models and 1000+ textures that you can use on your projects.“</p></div></div><div><div><div><p>Latest Atlases</p></div><p><b>37</b>&nbsp;<!-- -->atlases<!-- --> and increasing every day</p></div><div><div><p>Latest Textures</p></div><p><b>1502</b>&nbsp;<!-- -->textures<!-- --> and increasing every day</p></div><div><div><p>Latest Models</p></div><p><b>184</b>&nbsp;<!-- -->models<!-- --> and increasing every day</p></div></div><div><div><h2><span>Completely</span><br><span>Free</span></h2><p>“All of our content is copyright-free. It means, you can use them anywhere you want which includes commercial projects too.”</p></div></div><div><div><div><div><p><span>0</span></p><p><span>patrons</span></p></div><div><p><span>0</span></p><p><span>assets</span></p></div><div><p><span>$</span><span>0</span></p><p><span>per month</span></p></div></div></div><p><a href="https://www.patreon.com/join/sharetextures" target="_blank" rel="noreferrer">Become a Patron</a></p></div><div><div><div><p>Supported By</p></div><p><a href="https://www.unrealengine.com/en-US/megagrants" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/e8b37cfa-f4bc-4be2-8f2a-db5c067918dc.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p><p><a href="https://eyecadvr.com/" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/dd54632e-3253-417a-91d0-572c036b5d05.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a><a href="https://www.blenderkit.com/r/sharetextures/" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/32895212-f5d0-420f-a4f7-465fccf97467.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a><a href="https://www.migenius.com/" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/66736218-0a54-4786-9ec3-67a3245ecb89.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p><p><a href="https://www.vfxgrace.com/" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/e0ea5444-deb5-45e9-9228-dff5f8b7cc3d.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a><a href="https://www.blendermarket.com/creators/true-vfx/?ref=595" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/eefa91a6-50d0-473e-98dc-3b6e03c36f39.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a><a href="https://www.youtube.com/@GrzegorzBaranArt" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/d3d64dc1-1037-4a2b-853f-a4639071e722.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a><a href="https://scanspace.nz/" target="_blank" rel="nofollow noreferrer"><span><span></span><img alt="" src="https://images.sharetextures.com/u/6bcecc29-375d-48bf-8116-7f347bdb09cf.webp" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><div><p><span>Created With</span><span><svg width="26" height="26" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64"><path d="M31.997 55.995c13.129-5.52 22.63-14.943 27.756-24.484C64.8 22.01 65.51 12.547 61.015 6.87 56.954 1.783 51.67-.149 46.309.01c-5.363.158-10.567 2.484-14.312 5.756C28.25 2.493 23.047.167 17.684.01 12.322-.15 7.04 1.783 2.978 6.869c-4.494 5.678-3.785 15.14 1.34 24.642 5.048 9.541 14.55 18.964 27.679 24.484Z"></path></svg></span></p><p><span>of</span><span>Patrons</span></p></div></div><div><div><p><span>Keep</span>&nbsp;<span>in touch<span>:</span><span>)</span></span></p></div><div><a target="_blank" href="https://patreon.com/sharetextures" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://ko-fi.com/sharetextures" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://twitter.com/ShareTextures" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://facebook.com/sharetexture" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://discord.gg/cYWDr4FHJ4" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://youtube.com/sharetextures" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://reddit.com/user/ShareTexture" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://pinterest.com/sharetextures/" rel="noreferrer noopener nofollow"></a><a target="_blank" href="https://pexels.com/@share-textures-3167406/" rel="noreferrer noopener nofollow"></a></div></div><div><a href="https://www.sharetextures.com/"><span><span>Home</span></span></a><a href="https://www.sharetextures.com/assets"><span><span>Assets</span></span></a><a href="https://www.sharetextures.com/textures"><span><span>Textures</span></span></a><a href="https://www.sharetextures.com/models"><span><span>3D Models</span></span></a><a href="https://www.sharetextures.com/blog"><span><span>Blog</span></span></a><p><a href="https://www.sharetextures.com/p/license"><span><span>License</span></span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PEP 686 – Make UTF-8 mode default (217 pts)]]></title>
            <link>https://peps.python.org/pep-0686/</link>
            <guid>40168242</guid>
            <pubDate>Fri, 26 Apr 2024 11:55:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://peps.python.org/pep-0686/">https://peps.python.org/pep-0686/</a>, See on <a href="https://news.ycombinator.com/item?id=40168242">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="pep-content">

<dl>
<dt>Author<span>:</span></dt>
<dd>Inada Naoki &lt;songofacandy at gmail.com&gt;</dd>
<dt>Discussions-To<span>:</span></dt>
<dd><a href="https://discuss.python.org/t/14737">Discourse thread</a></dd>
<dt>Status<span>:</span></dt>
<dd><abbr title="Normative proposal accepted for implementation">Accepted</abbr></dd>
<dt>Type<span>:</span></dt>
<dd><abbr title="Normative PEP with a new feature for Python, implementation change for CPython or interoperability standard for the ecosystem">Standards Track</abbr></dd>
<dt>Created<span>:</span></dt>
<dd>18-Mar-2022</dd>
<dt>Python-Version<span>:</span></dt>
<dd>3.15</dd>
<dt>Post-History<span>:</span></dt>
<dd><a href="https://discuss.python.org/t/14435" title="Discourse thread">18-Mar-2022</a>,
<a href="https://discuss.python.org/t/14737" title="Discourse thread">31-Mar-2022</a></dd>
<dt>Resolution<span>:</span></dt>
<dd><a href="https://discuss.python.org/t/14737/9">Discourse message</a></dd>
</dl>
<hr>
<section id="contents">
<details><summary>Table of Contents</summary><ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#specification">Specification</a><ul>
<li><a href="#enable-utf-8-mode-by-default">Enable UTF-8 mode by default</a></li>
<li><a href="#locale-getencoding"><code><span>locale.getencoding()</span></code></a></li>
<li><a href="#fixing-encoding-locale-option">Fixing <code><span>encoding="locale"</span></code> option</a></li>
</ul>
</li>
<li><a href="#backward-compatibility">Backward Compatibility</a></li>
<li><a href="#preceding-examples">Preceding examples</a></li>
<li><a href="#rejected-alternative">Rejected Alternative</a><ul>
<li><a href="#deprecate-implicit-encoding">Deprecate implicit encoding</a></li>
<li><a href="#use-pythonioencoding-for-pipes">Use <code><span>PYTHONIOENCODING</span></code> for PIPEs</a></li>
</ul>
</li>
<li><a href="#how-to-teach-this">How to teach this</a></li>
<li><a href="#copyright">Copyright</a></li>
</ul>
</details></section>
<section id="abstract">
<h2><a href="#abstract" role="doc-backlink">Abstract</a></h2>
<p>This PEP proposes enabling <a href="https://peps.python.org/pep-0540/" title="PEP 540 – Add a new UTF-8 Mode">UTF-8 mode</a> by default.</p>
<p>With this change, Python consistently uses UTF-8 for default encoding of
files, stdio, and pipes.</p>
</section>
<section id="motivation">
<h2><a href="#motivation" role="doc-backlink">Motivation</a></h2>
<p>UTF-8 becomes de facto standard text encoding.</p>
<ul>
<li>The default encoding of Python source files is UTF-8.</li>
<li>JSON, TOML, YAML use UTF-8.</li>
<li>Most text editors, including Visual Studio Code and Windows Notepad use
UTF-8 by default.</li>
<li>Most websites and text data on the internet use UTF-8.</li>
<li>And many other popular programming languages, including Node.js, Go, Rust,
and Java uses UTF-8 by default.</li>
</ul>
<p>Changing the default encoding to UTF-8 makes it easier for Python to
interoperate with them.</p>
<p>Additionally, many Python developers using Unix forget that the default
encoding is platform dependent.
They omit to specify <code><span>encoding="utf-8"</span></code> when they read text files encoded
in UTF-8 (e.g. JSON, TOML, Markdown, and Python source files).
Inconsistent default encoding causes many bugs.</p>
</section>
<section id="specification">
<h2><a href="#specification" role="doc-backlink">Specification</a></h2>
<section id="enable-utf-8-mode-by-default">
<h3><a href="#enable-utf-8-mode-by-default" role="doc-backlink">Enable UTF-8 mode by default</a></h3>
<p>Python will enable UTF-8 mode by default from Python 3.15.</p>
<p>Users can still disable UTF-8 mode by setting <code><span>PYTHONUTF8=0</span></code> or
<code><span>-X</span> <span>utf8=0</span></code>.</p>
</section>
<section id="locale-getencoding">
<h3><a href="#locale-getencoding" role="doc-backlink"><code><span>locale.getencoding()</span></code></a></h3>
<p>Since UTF-8 mode affects <code><span>locale.getpreferredencoding(False)</span></code>,
we need an API to get locale encoding regardless of UTF-8 mode.</p>
<p><code><span>locale.getencoding()</span></code> will be added for this purpose.
It returns locale encoding too, but ignores UTF-8 mode.</p>
<p>When <code><span>warn_default_encoding</span></code> option is specified,
<code><span>locale.getpreferredencoding()</span></code> will emit <code><span>EncodingWarning</span></code> like
<code><span>open()</span></code> (see also <a href="https://peps.python.org/pep-0597/" title="PEP 597 – Add optional EncodingWarning">PEP 597</a>).</p>
<p>This API was added in Python 3.11.</p>
</section>
<section id="fixing-encoding-locale-option">
<h3><a href="#fixing-encoding-locale-option" role="doc-backlink">Fixing <code><span>encoding="locale"</span></code> option</a></h3>
<p><a href="https://peps.python.org/pep-0597/" title="PEP 597 – Add optional EncodingWarning">PEP 597</a> added the <code><span>encoding="locale"</span></code> option to the <code><span>TextIOWrapper</span></code>.
This option is used to specify the locale encoding explicitly.
<code><span>TextIOWrapper</span></code> should use locale encoding when the option is specified,
regardless of default text encoding.</p>
<p>But <code><span>TextIOWrapper</span></code> uses <code><span>"UTF-8"</span></code> in UTF-8 mode even if
<code><span>encoding="locale"</span></code> is specified for now.
This behavior is inconsistent with the <a href="https://peps.python.org/pep-0597/" title="PEP 597 – Add optional EncodingWarning">PEP 597</a> motivation.
It is because we didn’t expect making UTF-8 mode default when Python
changes its default text encoding.</p>
<p>This inconsistency should be fixed before making UTF-8 mode default.
<code><span>TextIOWrapper</span></code> should use locale encoding when <code><span>encoding="locale"</span></code> is
passed even in UTF-8 mode.</p>
<p>This issue was fixed in Python 3.11.</p>
</section>
</section>
<section id="backward-compatibility">
<h2><a href="#backward-compatibility" role="doc-backlink">Backward Compatibility</a></h2>
<p>Most Unix systems use UTF-8 locale and Python enables UTF-8 mode when its
locale is C or POSIX.
So this change mostly affects Windows users.</p>
<p>When a Python program depends on the default encoding, this change may cause
<code><span>UnicodeError</span></code>, mojibake, or even silent data corruption.
So this change should be announced loudly.</p>
<p>This is the guideline to fix this backward compatibility issue:</p>
<ol>
<li>Disable UTF-8 mode.</li>
<li>Use <code><span>EncodingWarning</span></code> (<a href="https://peps.python.org/pep-0597/" title="PEP 597 – Add optional EncodingWarning">PEP 597</a>) to find every places UTF-8 mode
affects.<ul>
<li>If <code><span>encoding</span></code> option is omitted, consider using <code><span>encoding="utf-8"</span></code>
or <code><span>encoding="locale"</span></code>.</li>
<li>If <code><span>locale.getpreferredencoding()</span></code> is used, consider using
<code><span>"utf-8"</span></code> or <code><span>locale.getencoding()</span></code>.</li>
</ul>
</li>
<li>Test the application with UTF-8 mode.</li>
</ol>
</section>
<section id="preceding-examples">
<h2><a href="#preceding-examples" role="doc-backlink">Preceding examples</a></h2>
<ul>
<li>Ruby <a href="https://bugs.ruby-lang.org/issues/16604">changed</a> the default <code><span>external_encoding</span></code>
to UTF-8 on Windows in Ruby 3.0 (2020).</li>
<li>Java <a href="https://openjdk.java.net/jeps/400">changed</a> the default text encoding
to UTF-8 in JDK 18. (2022).</li>
</ul>
<p>Both Ruby and Java have an option for backward compatibility.
They don’t provide any warning like <a href="https://peps.python.org/pep-0597/" title="PEP 597 – Add optional EncodingWarning">PEP 597</a>’s <code><span>EncodingWarning</span></code>
in Python for use of the default encoding.</p>
</section>
<section id="rejected-alternative">
<h2><a href="#rejected-alternative" role="doc-backlink">Rejected Alternative</a></h2>
<section id="deprecate-implicit-encoding">
<h3><a href="#deprecate-implicit-encoding" role="doc-backlink">Deprecate implicit encoding</a></h3>
<p>Deprecating the use of the default encoding is considered.</p>
<p>But there are many cases that the default encoding is used for reading/writing
only ASCII text.
Additionally, such warnings are not useful for non-cross platform applications
run on Unix.</p>
<p>So forcing users to specify the <code><span>encoding</span></code> everywhere is too painful.
Emitting a lot of <code><span>DeprecationWarning</span></code> will lead users ignore warnings.</p>
<p><a href="https://peps.python.org/pep-0387/" title="PEP 387 – Backwards Compatibility Policy">PEP 387</a> requires adding a warning for backward incompatible changes.
But it doesn’t require using <code><span>DeprecationWarning</span></code>.
So using optional <code><span>EncodingWarning</span></code> doesn’t violate the <a href="https://peps.python.org/pep-0387/" title="PEP 387 – Backwards Compatibility Policy">PEP 387</a>.</p>
<p>Java also rejected this idea in <a href="https://openjdk.java.net/jeps/400">JEP 400</a>.</p>
</section>
<section id="use-pythonioencoding-for-pipes">
<h3><a href="#use-pythonioencoding-for-pipes" role="doc-backlink">Use <code><span>PYTHONIOENCODING</span></code> for PIPEs</a></h3>
<p>To ease backward compatibility issue, using <code><span>PYTHONIOENCODING</span></code> as the
default encoding of PIPEs in the <code><span>subprocess</span></code> module is considered.</p>
<p>With this idea, users can use legacy encoding for
<code><span>subprocess.Popen(text=True)</span></code> even in UTF-8 mode.</p>
<p>But this idea makes “default encoding” complicated.
And this idea is also backward incompatible.</p>
<p>So this idea is rejected. Users can disable UTF-8 mode until they replace
<code><span>text=True</span></code> with <code><span>encoding="utf-8"</span></code> or <code><span>encoding="locale"</span></code>.</p>
</section>
</section>
<section id="how-to-teach-this">
<h2><a href="#how-to-teach-this" role="doc-backlink">How to teach this</a></h2>
<p>For new users, this change reduces things that need to teach.
Users don’t need to learn about text encoding in their first year.
They should learn it when they need to use non-UTF-8 text files.</p>
<p>For existing users, see the <a href="#backward-compatibility">Backward compatibility</a> section.</p>
</section>
<section id="copyright">
<h2><a href="#copyright" role="doc-backlink">Copyright</a></h2>
<p>This document is placed in the public domain or under the
CC0-1.0-Universal license, whichever is more permissive.</p>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cult of the Dead Cow – Veilid (2023) (173 pts)]]></title>
            <link>https://cultdeadcow.com/tools/veilid.html</link>
            <guid>40167905</guid>
            <pubDate>Fri, 26 Apr 2024 11:06:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cultdeadcow.com/tools/veilid.html">https://cultdeadcow.com/tools/veilid.html</a>, See on <a href="https://news.ycombinator.com/item?id=40167905">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<pre>          ....:::::::::::::::::::::::::: :::::::::::::::::::::::::....
     ..::'''' '                                                  ` ````::..
   .::'                              .__.__  .__    .___                 `::.               
  .::                   ___  __ ____ |__|  | |__| __| _/                   ::.   
 .::                    \  \/ // __ \|  |  | |  |/ __ |                     ::.
 .:.                     \   /\  ___/|  |  |_|  / /_/ |                     .:.  
 ::                       \_/  \___  &gt;__|____/__\____ |                      :: 
 ..                                \/                \/                      ..

                                TAKE BACK CONTROL
         _   _                                                    _   _
        ((___))                                                  ((___))     
        [ x x ]       _ _/ <a href="https://cultdeadcow.com/">cDc</a> GRAND IMPERIAL DYNASTY \_ _       [ x x ]
         \   /        _ _        MCMLXXXIV A.D.        _ _        \   /
         (' ')           \  VOLANDO, REPTILIA SPERNO  /           (' ')
          (U)                                                      (U)

        [<a href="#about">about</a>] | [<a href="#foundation">veilid foundation</a>] | [<a href="#contributors">contributors</a>] | [<a href="#pr">press releases</a>]                         
         [<a href="#events">launch events</a>] | [<a href="https://veilid.com/">veilid.com</a>] | [<a href="https://gitlab.com/veilid/veilid">code</a>] | [<a href="https://discord.gg/5Qx3B9eedU">discord</a>] | [<a href="#links">links</a>]
		 
        ..:-:                                                              
    :=+++++++.                :-.                                          
    .++++++++=              =%:*@-                                         
     -++++++++:            :@--@#                                          
      +++++++++            *+:@%.                                          
      -++++++++:          #*.%@-                                           
       +++++++++         .* #@+             =#*  :#@@-   :##.        +#@@. 
       :++++++++:       +%.+@#                     %@-                 @@. 
        +++++++++      %@:-@%.    .---:    ::::    %@-  .:::      .:---@@. 
        .++++++++-    .@=.%@=   -%%+=+%@=  =*@%    %@-  -+@@.   =@@+==+@@. 
         =++++++++.  -#+ #@*   =@%     @@.  -@%    %@-   .@@.  +@#     @@. 
         .++++++++= =@* *@%.   #@%#######:  -@%    %@-   .@@.  %@=     @@. 
          -++++++++=@# +@@:    *@#          -@%    %@-   .@@.  #@+     @@. 
           ++++++++*%:#@@+     .%@#-.:-+*   =@@.  .%@=   :@@:  :@@+:.-*@@- 
           -++++++++#@@@%        :+***+-   +++++-:+++++ =++++=   =***=.-*+=
            ++++++++*@@@=           .___                          .                                        
            :++++++++#@*            [__ ._. _.._ _  _ .    , _ ._.;_/
             ++++++++*#             |   [  (_][ | )(/, \/\/ (_)[  | \
             .+++++++=.             

<a id="about"></a>                                ...:::::::::...
                               ::::: about :::::
                                ```:::::::::'''

    <a href="https://veilid.com/">Veilid</a> (pronounced Vay-Lid, from "Valid and Veiled Identification")

    We built <a href="https://veilid.com/">Veilid</a> because when the Internet was young and new, we viewed
    it as an endless and open realm of possibility.

    Instead, the Internet we know now has been heavily commercialized,
    with users and their data being the most sought-after commodity.  The
    only ways to opt-out of becoming the product for billionaires to
    exploit are either too technical for the average user, or to simply not
    go online. 

    We believe that people should be able to forge relationships, learn,
    create, and build online -- without being monetized.

    (<a href="#top">top</a>)

<a id="foundation"></a>                          ...:::::::::::::::::::::...
                         ::::: veilid foundation :::::
                          ```:::::::::::::::::::::'''
    
    * Christien Rioux
    * Katelyn Bowden
    * Paul Miller
	
    (<a href="#top">top</a>)	

<a id="contributors"></a>                             ...::::::::::::::::...
                            ::::: contributors :::::
                             ```::::::::::::::::'''

    Veilid contributors include coders, admins, writers, legal, and more.

    * TC Johnson
    * Jun34u, cDc
    * Deth Veggie, cDc
    * Beka Valentine
    * signal9
    * Obscure, cDc
    * Kirk 'Teknique' Strauser
    * Alice 'c0debabe' Rhodes
    * Abbie 'antijingoist' Gonzalez
    * snowchyld, NSF
    * John 'Wrewdison' Whelan 
    * Robert 'LambdaCalculus' Menes
    * Glenn Kurtzrock
    * Daniel Meyerson
    * CylentKnight
    * Robert 'Slugnoodle' Notarfrancesco
    * Yer mom

    (<a href="#top">top</a>)

<a id="events"></a>                            ...:::::::::::::::::...
                           ::::: launch events :::::
                            ```:::::::::::::::::'''
    
    We're releasing Veilid at <a href="https://defcon.org/html/defcon-31/dc-31-index.html">DEF CON 31</a> in Las Vegas.  You should come
    hang out.

    2023-08-12 - "<a target="_blank" href="https://forum.defcon.org/node/246329">Veilid Demo Lab</a>," 10:00 � 11:55, Committee Boardroom,
                 Caesars Forum

    2023-08-11 - "<a target="_blank" href="https://cultdeadcow.com/news/veilidparty20230622.html">CULT OF THE DEAD COW Breaks The Internet (and you can</a>
                 <a target="_blank" href="https://cultdeadcow.com/news/veilidparty20230622.html">too!)</a>," PAR-TAY!, 20:00 - ??:??, Track 1, Caesars Forum

    2023-08-11 - "<a target="_blank" href="https://forum.defcon.org/node/246124">The Internals of Veilid, a New Decentralized Application</a>
                 <a target="_blank" href="https://forum.defcon.org/node/246124">Framework</a>," 09:00 - 09:45, Track 1, Caesars Forum

    (<a href="#top">top</a>)

<a id="pr"></a>                            ...::::::::::::::::::...
                           ::::: press releases :::::
                            ```::::::::::::::::::'''

    2023-06-22 - <a target="_blank" href="https://cultdeadcow.com/news/veilidparty20230622.html">CULT OF THE DEAD COW Breaks The Internet (and you can</a>
                 <a target="_blank" href="https://cultdeadcow.com/news/veilidparty20230622.html">too!)</a>

    (<a href="#top">top</a>)

<a id="links"></a>                                ...:::::::::...
                               ::::: links :::::
                                ```:::::::::'''

    <a href="https://cultdeadcow.com/">https://cultdeadcow.com</a>
    <a href="https://veilid.com/">https://veilid.com</a>
    <a href="https://gitlab.com/veilid/veilid">https://gitlab.com/veilid/veilid</a>
    <a href="https://discord.gg/5Qx3B9eedU">https://discord.gg/5Qx3B9eedU</a>
    Twitter:  <a href="https://twitter.com/cdc_pulpit">@cdc_pulpit</a> &amp; <a href="https://twitter.com/VeilidNetwork">@veilidnetwork</a>
    Bluesky:  <a href="https://bsky.app/profile/cultdeadcow.bsky.social">@cultdeadcow.bsky.social</a>
    Fediverse:  <a href="https://hackers.town/@veilidnetwork">@VeilidNetwork@hackers.town</a>

    (<a href="#top">top</a>)

                            <a href="https://cultdeadcow.com/">xXx / RULE BOVINIA \ xXx</a>
 ..                         ____                     ____                    ..
 ..                      __|    |__               __|    |__                 ..
 ::                   .\_\__    __/_/___________\_\__   ___/_                ::
____      ____        |    |    |    ____          \|   \_   \.____  _____   ..
  _/    __\__ \.    __|    |    :   |   /      |\   :    :    |    |/  __/ ____
  \   ./   _/  |   /       |        |  /       |_\__.         |    :  _) ./   _
   \  |    :   |  /        |        | /        _/   |        \\       \  |    |
    \ |        | /         |        |/    /|   |    |         \        \ |    |
\    \|    .   |/    /|    |    .________/ |   |    |    .    |    .    \|    |
 \_________|________/ |    |_   |b5!ACiD   |___|    |    |____|    |\_________|
 ..  - ---------------|_____/   |-------------------|    :----|_____/ --- -  ..
 ..                  _____ |____|                   :  _____                 ..
 ::                  \_   \. _____        _______   .  \_   \.               ::
 ..             ______|    |/  __/ _______\__    \ _____|    |               ..
 ::           _(   ___     :  _) ./   _/  ___.       ___     | ____          ::
 ::           \    \  |       \  |    :   \  |       \  |    ||   /          ::
 ::            \    \ |        \ |         \ |        \ |    || _/           ::
 ::             \_   \|    .    \|    .     \|    .    \|    ||_)            ::
 ::              (_________|\_________|\__________|\_________|               ::
 ..                   .                                  .                   ..
 ::                   :                                  :                   ::
 ::                 _____      _ ________________    ______                  ::
 ::               _/   _/    _____    ____ \_    \../    _/                  ::
 ::             __\    \   ./   _/   |   /  :     ||     | __ __             ::
 ::         _ _\\_\\    \  |    :    |  /         ||     |/ //_//_ _         ::
 ::.             (_\\    \ |         | /    .     /\       //_)             .::
 .:.                 \    \|    .    |/    /|     /\     _/                 .:.
  ::.                 \_________|_________/ |___ /  \ ___)                 .::
   ::.                .                        \/    \/  .                .::
    `::.              |                                  |              .::'
      `:::...         |                                  |         ...:::'
 `       ```:::::.. . |    . .::::::::::::::::::::. .    | . ..:::::'''       '
  `.            ```   |      ::::::::::::::::::::::      |   '''            .'
    `-._              |    . :::::::::::::::::::::: .    |              _.-'
        ```---...___ _|_   . :::::::::::::::::::::: .   _|_ ___...---'''
                      :    : :::::::::::::::::::::: :    :
                           : :::::::::::::::::::::: :
               .  . .......: :::::::::::::::::::::: :.. . .. .  .
             ................::::::::::::::::::::::................
            :::'''''':'::'::::::::::::::::::::::::::::::::::::::::::
            :: :::::::::::::::::::::::::::::::::::::::::::::::::::::
            :: :::::::::::::::::::::::::::::::::::::::::::::::::::::
            ::':::::::::::::::::::::::::::::::::::::::::::::::::::::
            :::::::::::::::::::::::::::::::::::::::::::::::::::::'::
            ::.:::::::::::::::::::::::::::::::::::::::::::::::::::::
            :::::::::::::::::::::::::::::::::::::::::::::::::::::.::
            ::::::::::::::::::::::::::::::::::::::::::::::::::::: ::
            ::::::::::::::::::::.:::::::::::::::::::::::::::::::: ::
            :::::::::::::::::::::::::::::::::::.:::::'::':'''''''.::
            `::::::::::::::::::::::::::::::::::::::::::::::::::::::'
               .  . ........ :::.::::::::::::::.::: ........ .  .
                           : ::: :::::::::::::: ::: :
                           : ::: .............. ::: :
                      .    : ::: :::::::::::::: ::: :
                      .    . ::: .............. ::: .    .
                      :      :::                :::      .
                    : |    . :::                ::: .    | :
                 ___| |     .::' . .......... . `::.     | |___
         ________\  __|   .:::'                  `:::.   |__  /________
 ________\  _______ \  ..:::'                      `:::..  / _______  /________
 \  _______ \      \ \  :::                          :::  / /      / _______  /
 __ \      \ \      \ \  :::                        :::  / /      / /      / __
   \ \      \ \      \ \  :::                      :::  / /      / /      / /
    \ \      \ \      \ \  :::                    :::  / /      / /      / /
     \ \      \ \      \ \  :::                  :::  / /      / /      / /
      \ \      \ \      \ \  :::                :::  / /      / /      / /
 \     \ \      \ \      \ \  :::              :::  / /      / /      / /     /
  \     \ \      \ \      \ \  :::            :::  / /      / /      / /     /
   \_____\ \      \ \      \ \  :::          :::  / /      / /      / /_____/
            \      \ \      \ \  :::        :::  / /      / /      /
             \      \ \      \ \  :::      :::  / /      / /      /
              \______\ \      \ \  :::    :::  / /      / /______/
                        \      \ \  :::  :::  / /      /
                         \      \ \  ::::::  / /      /
                          \______\ \  ::::  / /______/
                                    \  ::  /
                                     \    /
                                      \  /
                                       \/
</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen1.5-110B (111 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen1.5-110b/</link>
            <guid>40167884</guid>
            <pubDate>Fri, 26 Apr 2024 11:01:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen1.5-110b/">https://qwenlm.github.io/blog/qwen1.5-110b/</a>, See on <a href="https://news.ycombinator.com/item?id=40167884">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p><a href="https://github.com/QwenLM/Qwen1.5" target="_blank">GITHUB</a>
<a href="https://huggingface.co/Qwen" target="_blank">HUGGING FACE</a>
<a href="https://modelscope.cn/organization/qwen" target="_blank">MODELSCOPE</a>
<a href="https://huggingface.co/spaces/Qwen/Qwen1.5-110B-Chat-Demo" target="_blank">DEMO</a>
<a href="https://discord.gg/yPEP2vHTu4" target="_blank">DISCORD</a></p><h2 id="introduction">Introduction</h2><p>Recently we have witnessed a burst of large-scale models with over 100 billion parameters in the opensource community. These models have demonstrated remarkable performance in both benchmark evaluation and chatbot arena. Today, we release the first 100B+ model of the Qwen1.5 series, Qwen1.5-110B, which achieves comparable performance with Meta-Llama3-70B in the base model evaluation, and outstanding performance in the chat evaluation, including MT-Bench and AlpacaEval 2.0.</p><h2 id="model-features">Model Features</h2><p>Qwen1.5-110B is similar to other Qwen1.5 models and built with the same Transformer decoder architecture. It consists of grouped query attention (GQA) and it can be efficient in model serving. The model supports the context length 32K tokens, and the model is still multilingual, supporting a large number of languages including English, Chinese, French, Spanish, German, Russian, Korean, Japanese, Vietnamese, Arabic, etc.</p><h2 id="model-quality">Model Quality</h2><p>We conduct a series of evaluations for the base language models, and we compare with Meta-Llama3-70B, the recent SOTA language model as well as Mixtral-8x22B.</p><table><thead><tr><th></th><th>Qwen1.5-110B</th><th>Qwen1.5-72B</th><th>Llama-3-70B</th><th>Mixtral-8x22B</th></tr></thead><tbody><tr><td>MMLU</td><td>80.4</td><td>77.5</td><td>79.5</td><td>77.8</td></tr><tr><td>TheoremQA</td><td>34.9</td><td>29.3</td><td>32.0</td><td>35.9</td></tr><tr><td>GPQA</td><td>35.9</td><td>36.3</td><td>36.4</td><td>34.3</td></tr><tr><td>Hellaswag</td><td>87.5</td><td>86.0</td><td>88.0</td><td>88.7</td></tr><tr><td>BBH</td><td>74.8</td><td>65.5</td><td>76.6</td><td>69.2</td></tr><tr><td>ARC-C</td><td>69.6</td><td>65.9</td><td>68.8</td><td>70.7</td></tr><tr><td>GSM8K</td><td>85.4</td><td>79.5</td><td>79.2</td><td>78.6</td></tr><tr><td>MATH</td><td>49.6</td><td>34.1</td><td>41.0</td><td>41.7</td></tr><tr><td>HumanEval</td><td>52.4</td><td>41.5</td><td>45.7</td><td>45.1</td></tr><tr><td>MBPP</td><td>58.1</td><td>53.4</td><td>55.1</td><td>71.2</td></tr></tbody></table><p>The above results show that the new 110B model is at least competitive with the Llama-3-70B model in terms of base capabilities. In terms of this model, we did not change the pretraining and posttraining recipes drastically, and thus we believe that the performance improvement compared with 72B comes from increasing model size.</p><p>We also test the chat models on MT-Bench and AlpacaEval 2.0.</p><table><tbody><tr><th rowspan="2">Models</th><th colspan="1">MT-Bench</th><th colspan="1">AlpacaEval 2.0</th></tr><tr><th>Avg. Score</th><th>LC Win Rate</th></tr><tr><td>Llama-3-70B-Instruct</td><td>8.85</td><td>34.40</td></tr><tr><td>Qwen1.5-72B-Chat</td><td>8.61</td><td>36.60</td></tr><tr><td>Qwen1.5-110B-Chat</td><td>8.88</td><td>43.90</td></tr></tbody></table><p>Compared with the previously released 72B model, on the two benchmark evaluation for chat models the 110B performs significantly better. The consistent improvement in the evaluation indicates that stronger and larger base language models can lead to better chat models even without changing the post-training recipes much.</p><h2 id="develop-with-qwen15-110b">Develop with Qwen1.5-110B</h2><p>We advise you to read our blog for <a href="https://qwenlm.github.io/blog/qwen1.5/">Qwen1.5</a> to figure out the usages with Transformers, vLLM, llama.cpp, Ollama, etc.</p><h2 id="conclusion">Conclusion</h2><p>The Qwen1.5-110B is the largest model in the Qwen1.5 series, and it is also the first one with over 100 billion parameters in the series. It demonstrates competitive performance against the very recently released SOTA model Llama-3-70B and it is significantly better than the 72B model. This tells us that there is still a lot of room in model size scaling for better performance. While the releease of Llama-3 indicates the significance of data scaling to an extremely large scale, we believe we can get the best of both worlds by scaling both data and model size in our future release. Stay tuned for Qwen2!</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pharo 12 (206 pts)]]></title>
            <link>https://pharo.org/news/2024-04-26-pharo12-released.html</link>
            <guid>40167742</guid>
            <pubDate>Fri, 26 Apr 2024 10:41:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pharo.org/news/2024-04-26-pharo12-released.html">https://pharo.org/news/2024-04-26-pharo12-released.html</a>, See on <a href="https://news.ycombinator.com/item?id=40167742">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">
                    
                    <p>Dear Pharo users and dynamic language lovers:</p><p>We have released <a href="https://pharo.org/">Pharo</a> version 12!</p><h2>What is Pharo?</h2><p>Pharo is a pure object-oriented programming language and a powerful environment focused on simplicity and immediate feedback.</p><p><img src="https://pharo.org/news/Pharo12.png"></p><ul><li>Simple &amp; powerful language: No constructors, no types declaration, no interfaces, no primitive types. Yet a powerful and elegant language with a full syntax fitting in one postcard! Pharo is objects and messages all the way down.</li><li>Live, immersive environment: Immediate feedback at any moment of your development: Developing, testing, debugging. Even in production environments, you will never be stuck in compiling and deploying steps again!</li><li>Amazing debugging experience: Pharo environment includes a debugger unlike anything you've seen before. It allows you to step through code, restart the execution of methods, create methods on the fly, and much more!</li><li>Pharo is yours: Pharo is made by an incredible community, with more than 100 contributors for the last revision of the platform and hundreds of people constantly contributing with frameworks and libraries.</li><li>Fully open-source: Pharo full stack is released under <a href="https://opensource.org/licenses/MIT">MIT</a> License and available on <a href="https://github.com/pharo-project/pharo">GitHub</a></li></ul><p>... more on the <a href="http://www.pharo.org/features">Pharo Features page</a>.</p><p>In this iteration of Pharo, we continue working on our objectives of improvement, clean-up and modularization.
Also, we included a number of usability and speed improvements.
A complete list of changes and improvements is available in our <a href="https://github.com/pharo-project/pharo-changelogs/blob/master/Pharo120ChangeLogs.md">Changelog</a></p><p>Some highlights of this amazing version:</p><h2>Highlights</h2><h3>New breakpoint system</h3><p>The debug point system is a breakpoint model that supersedes the previous implementation of breakpoints and watchpoints. They are configurable, composable, and extensible. The traditional breakpoints remain available, including conditional breakpoints, one-time breakpoints, and object-centric breakpoints. Additionally, there are new types of breakpoints, such as chained-breakpoints, which condition the activation of certain breakpoints on the triggering of others (e.g., breakpoint B only activates if breakpoint A is hit first). Debug points also feature a dedicated browser and integration options.</p><p><img src="https://pharo.org/news/Pharo12DebugPoints.png"></p><h3>Tools</h3><ul><li>Scalable fluid class syntax is now the default one</li><li>Preparing the introduction of the Bloc graphic system by migrating more tools to Spec2 widgets</li><li>Spec2 UI framework enhancements to support GTK 4</li><li>Leaner version of the Metacello package manager</li><li>More robust and strict mode for FFI</li></ul><h3>System</h3><ul><li>New architecture for refactorings and domain specific transformations</li><li>Code loading speed improvement</li><li>Fast browsing via fully optimized package tags</li><li>Optmized memory usage via optimized method protocols</li><li>Compiler simplifications and improvements
 </li></ul><h3>Virtual machine</h3><ul><li>Massive image support with permanent space</li><li>String/ByteArray comparison speed up</li></ul><h2>Development Effort</h2><p>This new version is the result of 1895 Pull Requests integrated just in the Pharo repository.
We have closed 865 issues and received contributions from more than 70 different contributors.
We have also a lot of work in the separate projects that are included in each Pharo release:</p><ul><li><a href="https://github.com/pharo-spec/NewTools">http://github.com/pharo-spec/NewTools</a></li><li><a href="https://github.com/pharo-spec/NewTools-DocumentBrowser">http://github.com/pharo-spec/NewTools-DocumentBrowser</a></li><li><a href="https://github.com/pharo-spec/Spec">http://github.com/pharo-spec/Spec</a></li><li><a href="https://github.com/pharo-vcs/Iceberg">http://github.com/pharo-vcs/Iceberg</a></li><li><a href="https://github.com/pharo-graphics/Roassal">https://github.com/pharo-graphics/Roassal</a></li><li><a href="https://github.com/pillar-markup/Microdown">http://github.com/pillar-markup/Microdown</a></li><li><a href="https://github.com/pillar-markup/BeautifulComments">http://github.com/pillar-markup/BeautifulComments</a></li><li><a href="https://github.com/pharo-project/pharo-vm">http://github.com/pharo-project/pharo-vm</a></li></ul><h2>Contributors</h2><p>We always say Pharo is yours. It is yours because we made it for you, but most importantly because it is made by the invaluable contributions of our great community (yourself).
A large community of people from all around the world contributed to Pharo 12.0 by making pull requests, reporting bugs, participating in discussion threads, providing feedback, and a lot of helpful tasks in all our community channels.
Thank you all for your contributions.</p><p>The Pharo Team</p><p>Discover Pharo: <a href="https://pharo.org/features">https://pharo.org/features</a></p><p>Try Pharo: <a href="https://pharo.org/download">http://pharo.org/download</a></p><p>Learn Pharo: <a href="https://pharo.org/documentation">http://pharo.org/documentation</a></p>
                    <p>26 April 2024</p>
                  			
                  	
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[H5N1 prevalence in milk suggest US bird flu outbreak in cows is widespread (131 pts)]]></title>
            <link>https://www.statnews.com/2024/04/25/h5n1-bird-flu-cows-outbreak-likely-widespread/</link>
            <guid>40167315</guid>
            <pubDate>Fri, 26 Apr 2024 09:13:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statnews.com/2024/04/25/h5n1-bird-flu-cows-outbreak-likely-widespread/">https://www.statnews.com/2024/04/25/h5n1-bird-flu-cows-outbreak-likely-widespread/</a>, See on <a href="https://news.ycombinator.com/item?id=40167315">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
	<p><span><span>A</span></span>ndrew Bowman, a veterinary epidemiologist at Ohio State University, had a hunch. He had been struck by the huge amounts of H5N1 virus he’d seen in milk from cows infected with the bird flu and thought that at least some virus was getting off of farms and going downstream — onto store shelves.</p>
<p>He knew the Food and Drug Administration was working on its own national survey of the milk supply. But he was impatient. So he and a graduate student went on a road trip: They collected 150 commercial milk products from around the Midwest, representing dairy processing plants in 10 different states, including some where herds have tested positive for H5N1. Genetic testing found viral RNA in 58 samples, he told STAT.</p>
<p>The researchers expect additional lab studies currently underway to show that those samples don’t contain live virus with the capability to cause human infections, meaning that the <a href="https://www.statnews.com/2024/04/24/h5n1-bird-flu-pasteurized-milk-grocery-stores-safety/">risk of pasteurized milk to consumer health</a> is still very low. But the prevalence of viral genetic material in the products they sampled suggest that the H5N1 outbreak is likely far more widespread in dairy cows than official counts indicate. So far, the U.S. Department of Agriculture has reported 33 herds in eight states have tested positive for H5N1.</p>
<p>“The fact that you can go into a supermarket and 30% to 40% of those samples test positive, that suggests there’s more of the virus around than is currently being recognized,” said Richard Webby, an influenza virologist who has been analyzing the samples at St. Jude’s Children’s Research Hospital in Memphis, Tenn., where he heads the WHO Collaborating Center for Studies on the Ecology of Influenza in Animals.</p>
		
		
<p>Earlier this week, the FDA announced that its effort had found evidence of the H5N1 virus in samples of milk purchased from store shelves, but it provided no detailed results. On Thursday, during an online symposium hosted by the Association of State and Territorial Health Officials, the FDA disclosed a high-level readout from the agency’s investigation. Results returned Thursday morning showed PCR-positive milk in 20% of samples, “maybe with some preponderance for areas with known herds,” said Donald Prater, acting director of the FDA’s Center for Food Safety and Applied Nutrition. He did not say how many samples the FDA had analyzed or from what geographic area.</p>
<p>The testing by PCR — polymerase chain reaction — turned up only genetic traces of the virus, not evidence that it’s alive or infectious. The FDA has been adamant that H5N1, which is heat-sensitive, is very likely killed through the process of pasteurization.</p>
<p>The agency is still assessing those samples for viral viability by attempting to grow virus from milk found to contain RNA from H5N1. The FDA plans to release results of those studies in the coming days. On Wednesday, Jeanne Marrazzo, the new director of the National Institute of Allergy and Infectious Diseases, told reporters that a team of NIAID-funded researchers had early data to <a href="https://www.statnews.com/2024/04/24/h5n1-bird-flu-usda-orders-dairy-cow-testing/">suggest that pasteurization does appear to be effective</a>.</p>
<p>The team that produced that data — the St. Jude and OSU groups — told STAT that it has so far analyzed four samples of store-bought milk that had tested positive via PCR for H5N1 genetic material. “We’ve done the viral growth assays to see if we can recover any virus from them and we can’t,” Webby said.</p>
<p>Those four samples came from an initial collection of 22 commercial milk products purchased in the Columbus, Ohio, area. “It was basically just me hitting up the five grocery stores between campus and my house,” said Bowman.</p>

<p>PCR testing at OSU revealed three of those 22 products to be positive for viral RNA. Bowman sent them to Webby to inject into plates of mammalian cells and embryonated chicken eggs and look for any signs of active viral replication. In order to do that, Webby needed a negative control, so he went and bought milk at a store near his lab in Memphis. But PCR testing found H5N1 RNA in that sample too, making it useless as a negative control, but an additional data point showing a lack of live virus.</p>
<p>That sample is still in Webby’s fridge at home. He used it to make dinner earlier this week. “I’m not concerned about it all,” he said.</p>
<p>Although the risk of infection from dairy products is very low, the worry is that the wider H5N1 spreads in cows, the more opportunities the virus has to adapt to transmit efficiently in mammalian hosts. It also increase the chances H5N1 could get into pigs, where it could swap genes and form hybrids with other flu viruses. Viruses that mutate to be able to spread easily through one species of mammals could find it easier to infect people.</p>
<p>The St. Jude group is now repeating its analyses with the additional samples Bowman and his graduate student bought around the Midwest. Their early findings provide further evidence that H5N1 is spreading broadly among dairy cows in the U.S.</p>
<p>This week, researchers examining <a href="https://www.statnews.com/2024/04/21/usda-releases-h5n1-bird-flu-genetic-data-eagerly-awaited-by-scientists/">viral genome sequences released Sunday</a> by the USDA found that the outbreak has likely been underway <a href="https://www.statnews.com/2024/04/23/h5n1-bird-flu-genetic-analysis/">for months longer than previously known</a>. “Both of these data — the milk data and the genetic data that shows this has been around since December of last year — suggests that the outbreak is probably much bigger than we know,” said Angie Rasmussen, a virologist who studies emerging zoonotic pathogens at the Vaccine and Infectious Disease Organization at the University of Saskatchewan in Canada.</p>
<p>It may also signal that herds can be infectious with only mild symptoms or no symptoms at all, which would complicate the response and make containment much more difficult.</p>
<p>“This is telling us that we’re probably already seeing that milk from asymptomatically infected cows does have some virus in there,” said Andrew Pekosz, a molecular microbiologist who studies respiratory viruses at Johns Hopkins Bloomberg School of Public Health.</p>
<p>So far, there has been only <a href="https://www.nytimes.com/2024/04/19/health/bird-flu-usda-cattle.html" target="_blank" rel="noopener">one report</a> of H5N1 infections in a cattle herd with no symptoms — in North Carolina. But USDA officials have not disclosed further details beyond the fact that milk from infected but asymptomatic cows seems unchanged.</p>
		
		
<p>In H5N1-infected cows, the first thing that tends to happen is their appetite disappears and their activity goes down. Then their milk production dries up. In some animals, the milk they do produce turns yellow and thick. “It’s an odd thing that seems to be unique to this particular virus,” said Keith Poulsen, director of the Wisconsin Veterinary Diagnostic Laboratory. And it’s one of the chief red flags that dairy farmers are supposed to be on the lookout for when deciding whether to test their herds. If milk from asymptomatic or pre-symptomatic cows looks normal but can carry virus, it would obscure the need for testing.</p>
<p>To really understand the scale of spread as well as possible mechanisms of viral transmission, it’s necessary to conduct widespread testing of animals with and without symptoms, said Jennifer Nuzzo, an epidemiologist and director of Brown University’s Pandemic Center. “If we’re only testing cows with outward symptoms, we’re missing infections in those without.”</p>
<p>Up until this week, USDA policy did not require testing of any animals, and only recommended it for dairy cows greater than 3 years of age that have been lactating for at least 150 days and are showing severe clinical symptoms like fever, lethargy, abnormal milk production, and loose stool.</p>
<p>On Wednesday, the agency <a href="https://www.statnews.com/2024/04/24/h5n1-bird-flu-usda-orders-dairy-cow-testing/">issued a federal order</a> requiring an animal to test negative for the virus before it can be transported across state lines. It also requires laboratories and state veterinarians to report to the USDA any animals that have tested positive for H5N1 or any other influenza A virus. But outside of interstate travel, testing remains voluntary and encouraged only for visibly ill animals.</p>
<p>Public health experts told STAT that such narrow testing criteria are likely distorting the true extent of the outbreak. “I have not seen evidence that makes me want to discard the fear that testing practices are absolutely shaping what we think we know about this virus,” Nuzzo said. “We just don’t have the right data right now to tell us what’s going on.”</p>
<p>The situation is reminiscent, she said, of the Covid-19 pandemic. In the early weeks of that outbreak, testing policies were narrow —&nbsp;limited to symptomatic individuals who had traveled to China. Meanwhile, the SARS-CoV-2 virus <a href="https://www.statnews.com/2020/03/03/washington-state-risks-seeing-explosion-in-coronavirus-without-dramatic-action-new-analysis-says/">was spreading undetected</a> throughout the U.S., as genomic analyses would later show. Later, when at-home tests became widely available, <a href="https://www.statnews.com/2021/12/07/growing-use-of-home-covid19-tests-leaves-health-agencies-in-the-dark/">official counts became unreliable</a>, leaving state and local health departments in the dark.</p>
<p>“At least with Covid, <a href="https://www.statnews.com/2020/05/28/wastewater-testing-gains-support-as-covid19-early-warning/">wastewater surveillance</a> eventually kicked in to supplement our picture,” Nuzzo said. “With H5N1, we don’t have that.”</p>
<p>On Wednesday, the Centers for Disease Control and Prevention said it is exploring wastewater testing for H5N1, but noted significant hurdles, including farms not being linked to municipal wastewater systems and the potential for infected wild birds to confound testing of water around farms.</p>
<p>Requiring dairy farms to regularly test all their animals, including asymptomatic ones, is not logistically feasible given the current capacity of state veterinary diagnostic laboratories, Poulsen said. He and other lab directors are already bracing for the massive ramp-up in testing they expect to begin when the USDA order goes into effect Monday. But he does think more has to be done at the federal level to encourage farmers to test their herds.</p>
<p>“At this point, farms just aren’t volunteering samples because they don’t have any incentives to raise their hand,” Poulsen said. That information blackout makes it much more challenging for epidemiologists to trace the virus and understand how it’s spreading, the exact mechanisms of which are still unclear.</p>
<p>“We need to do what we can now to understand it and contain it so it doesn’t turn into a pathogen of pandemic potential,” Poulsen said. “That is a real risk if we continue to ignore it.”</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Rewired My Brain to Become Fluent in Math (2014) (271 pts)]]></title>
            <link>https://nautil.us/how-i-rewired-my-brain-to-become-fluent-in-math-235085/</link>
            <guid>40167163</guid>
            <pubDate>Fri, 26 Apr 2024 08:44:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/how-i-rewired-my-brain-to-become-fluent-in-math-235085/">https://nautil.us/how-i-rewired-my-brain-to-become-fluent-in-math-235085/</a>, See on <a href="https://news.ycombinator.com/item?id=40167163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>I</span> was a wayward kid who grew up on the literary side of life, treating math and science as if they were pustules from the plague. So it’s a little strange how I’ve ended up now—someone who dances daily with triple integrals, Fourier transforms, and that crown jewel of mathematics, Euler’s equation. It’s hard to believe I’ve flipped from a virtually congenital math-phobe to a professor of engineering.</p><p>One day, one of my students asked me how I did it—how I changed my brain. I wanted to answer <i>Hell—with lots of difficulty!</i> After all, I’d flunked my way through elementary, middle, and high school math and science. In fact, I didn’t start studying remedial math until I left the Army at age 26. If there were a textbook example of the potential for adult neural plasticity, I’d be Exhibit A.</p>

<p>Learning math and then science as an adult gave me passage into the empowering world of engineering. But these hard-won, adult-age changes in my brain have also given me an insider’s perspective on the neuroplasticity that underlies adult learning. Fortunately, my doctoral training in systems engineering—tying together the big picture of different STEM (Science, Technology, Engineering, Math) disciplines—and then my later research and writing focusing on how humans think have helped me make sense of recent advances in neuroscience and cognitive psychology related to learning.</p><p>In the years since I received my doctorate, thousands of students have swept through my classrooms—students who have been reared in elementary school and high school to believe that understanding math through active discussion is the talisman of learning. If you can explain what you’ve learned to others, perhaps drawing them a picture, the thinking goes, you must<br> understand it.</p>
<p>Japan has become seen as a much-admired and emulated exemplar of these active, “understanding-centered” teaching methods. But what’s often missing from the discussion is the rest of the story: Japan is also home of the Kumon method of teaching mathematics, which emphasizes memorization, repetition, and rote learning hand-in-hand with developing the child’s mastery over the material. This intense afterschool program, and others like it, is embraced by millions of parents in Japan and around the world who supplement their child’s participatory education with plenty of practice, repetition, and yes, intelligently designed rote learning, to allow them to gain hard-won fluency with the material.</p><blockquote><p>Teachers can inadvertently set their students up for failure as those students blunder in illusions of competence.</p></blockquote><p>In the United States, the emphasis on understanding sometimes seems to have replaced rather than complemented older teaching methods that scientists are—and have been—telling us work with the brain’s natural process to learn complex subjects like math and science.</p><p>The latest wave in educational reform in mathematics involves the Common Core—an attempt to set strong, uniform standards across the U.S., although critics are weighing in to say the standards fail by comparison with high-achieving countries. At least superficially, the standards seem to show a sensible perspective. They propose that in mathematics, students should gain equal facility in conceptual understanding, procedural skills and fluency, and application.</p>
<p>The devil, of course, lies in the details of implementation. In the current educational climate, memorization and repetition in the STEM disciplines (as opposed to in the study of language or music), are often seen as demeaning and a waste of time for students and teachers alike. Many teachers have long been taught that conceptual understanding in STEM trumps everything else. And indeed, it’s easier for teachers to induce students to discuss a mathematical subject (which, if done properly, can do much to help promote understanding) than it is for that teacher to tediously grade math homework. What this all means is that, despite the fact that procedural skills and fluency, along with application, are supposed to be given equal emphasis with conceptual understanding, all too often it doesn’t happen. Imparting a conceptual understanding reigns supreme—especially during precious class time.</p><p>The problem with focusing relentlessly on understanding is that math and science students can often grasp essentials of an important idea, but this understanding can quickly slip away without consolidation through practice and repetition. Worse, students often believe they understand something when, in fact, they don’t. By championing the importance of understanding, teachers can inadvertently set their students up for failure as those students blunder in illusions of competence. As one (failing) engineering student recently told me: “I just don’t see how I could have done so poorly. I understood it when you taught it in class.” My student may have thought he’d understood it at the time, and perhaps he did, but he’d never practiced using the concept to truly internalize it. He had not developed any kind of procedural fluency or ability to apply what he thought he understood.</p><p>There is an interesting connection between learning math and science, and learning a sport. When you learn how to swing a golf club, you perfect that swing from lots of repetition over a period of years. Your body knows what to do from a single thought—one chunk—instead of having to recall all the complex steps involved in hitting a ball.</p><p>In the same way, once you understand why you do something in math and science, you don’t have to keep re-explaining the how to yourself every time you do it. It’s not necessary to go around with 25 marbles in your pocket and lay out 5 rows of 5 marbles again and again so that you get that 5 x 5 = 25. At some point, you just know it fluently from memory. You memorize the idea that you simply add exponents—those little superscript numbers—when multiplying numbers that have the same base (10<sup>4</sup> x 10<sup>5</sup> = 10<sup>9</sup>). If you use the procedure a lot, by doing many different types of problems, you will find that you understand both the why and the how behind the procedure very well indeed. The greater understanding results from the fact that your mind constructed the patterns of meaning. Continually focusing on understanding itself actually gets in the way.</p>
<figure><img decoding="async" src="https://assets.nautil.us/4385_65f148c815a4ebfaf8eb150460ba94fc.jpg" alt=""></figure><p><span>I</span> learned these things about math and the process of learning not in the K-12 classroom but in the course of my life, as a kid who grew up reading Madeleine L’Engle and Dostoyevsky, who went on to study language at one of the world’s leading language institutes, and then to make the dramatic shift to become a professor of engineering.</p><p>As a young woman with a yen for learning language and no money or skills to speak of, I couldn’t afford to go to college (college loans weren’t then in the picture). So I launched directly from high school into the Army. I had loved learning new languages in high school, and the Army seemed to be a place where people could actually get paid for their language study, even as they attended the top-ranked Defense Language Institute—a place that had made language- learning a science. I chose Russian because it was very different from English, but not so difficult that I could study it for a lifetime only to perhaps gain the fluency of a 4-year-old. Besides, the Iron Curtain was mysteriously appealing—could I somehow use my knowledge of Russian to peer behind it?</p>
<p>After leaving the service, I became a translator for the Russians on Soviet trawlers on the Bering Sea. Working for the Russians was fun and engrossing—but it was also a superficially glamorous form of migrant work. You go to sea during fishing season, make a decent salary while getting drunk all the time, then go back to port when the season’s over and hope they’ll rehire you next year. There was pretty much only one other alternative for a Russian language speaker—working for the National Security Agency. (My Army contacts kept pointing me that way, but it wasn’t for me.)</p><p>I began to realize that while knowing another language was nice, it was also a skill with limited opportunities and potential. People weren’t pounding down my door looking for my Russian declension abilities. Unless, that is, I was willing to put up with seasickness and sporadic malnutrition out on stinking trawlers in the middle of the Bering Sea. I couldn’t help but reflect back on the West Point-trained engineers I’d worked with in the Army. Their mathematically and scientifically based approach to problem-solving was clearly useful for the real world—far more useful than my youthful misadventures with math had been able to imagine. </p><p>So, at age 26, as I was leaving the Army and casting about for fresh opportunities, it occurred to me: If I really wanted to try something new, why not tackle something that could open a whole world of new perspectives for me? Something like engineering? That meant I would be trying to learn another very different language—the language of calculus.</p><blockquote><p>You go to sea during fishing season, make a decent salary while getting drunk all the time, then go back to port when the season’s over.</p></blockquote>
<p>With my poor understanding of even the simplest math, my post-Army retraining efforts began with not-for-credit remedial algebra and trigonometry. This was way below mathematical ground zero for most college students. Trying to reprogram my brain sometimes seemed like a ridiculous idea—especially when I looked at the fresh young faces of my younger classmates and realized that many of them had already dropped their hard math and science classes—and here I was heading right for them. But in my case, from my experience becoming fluent in Russian as an adult, I suspected—or maybe I just hoped—that there might be aspects to language learning that I might apply to learning in math and science.</p><p>What I had done in learning Russian was to emphasize not just understanding of the language, but fluency. Fluency of something whole like a language requires a kind of familiarity that only repeated and varied interaction with the parts can develop. Where my language classmates had often been content to concentrate on simply understanding Russian they heard or read, I instead tried to gain an internalized, deep-rooted fluency with the words and language structure. I wouldn’t just be satisfied to know that понимать meant “to understand.” I’d practice with the verb—putting it through its paces by conjugating it repeatedly with all sorts of tenses, and then moving on to putting it into sentences, and then finally to understanding not only when to use this form of the verb, but also when not to use it. I practiced recalling all these aspects and variations quickly. After all, through practice, you can understand and translate dozens—even thousands— of words in another language. But if you aren’t fluent, when someone throws a bunch of words at you quickly, as with normal speaking (which always sounds horrifically fast when you’re learning a new language), you have no idea what they’re actually saying, even though technically you understand all the component words and structure. And you certainly can’t speak quickly enough yourself for native speakers to find it enjoyable to listen to you.</p><p>This approach—which focused on fluency instead of simple understanding—put me at the top of the class. And I didn’t realize it then, but this approach to learning language had given me an intuitive understanding of a fundamental core of learning and the development of expertise—chunking.</p><p>Chunking was originally conceptualized in the groundbreaking work of Herbert Simon in his analysis of chess—chunks were envisioned as the varying neural counterparts of different chess patterns. Gradually, neuroscientists came to realize that experts such as chess grand masters are experts because they have stored thousands of chunks of knowledge about their area of expertise in their long-term memory. Chess masters, for example, can recall tens of thousands of different chess patterns. Whatever the discipline, experts can call up to consciousness one or several of these well-knit-together, chunked neural subroutines to analyze and react to a new learning situation. This level of true understanding, and ability to use that understanding in new situations, comes only with the kind of rigor and familiarity that repetition, memorization, and practice can foster.</p>
<p>As studies of chess masters, emergency room physicians, and fighter pilots have shown, in times of critical stress, conscious analysis of a situation is replaced by quick, subconscious processing as these experts rapidly draw on their deeply ingrained repertoire of neural subroutines—chunks. At some point, self-consciously “understanding” why you do what you do just slows you down and interrupts flow, resulting in worse decisions. When I felt intuitively that there might be a connection between learning a new language and learning mathematics, I was right. Day-by-day, sustained practice of Russian fired and wired together my neural circuits, and I gradually began to knit together chunks of Slavic insight that I could call into working memory with ease. By interleaving my learning—in other words, practicing so that I knew not only when to use that word, but when not to use it, or to use a different variant of it—I was actually using the same approaches that expert practitioners use to learn in math and science.</p><p>When learning math and engineering as an adult, I began by using the same strategy I’d used to learn language. I’d look at an equation, to take a very simple example, Newton’s second law of <i>f</i> = <i>ma</i>. I practiced feeling what each of the letters meant—<i>f</i> for force was a push, <i>m</i> for mass was a kind of weighty resistance to my push, and <i>a</i> was the exhilarating feeling of acceleration. (The equivalent in Russian was learning to physically sound out the letters of the Cyrillic alphabet.) I memorized the equation so I could carry it around with me in my head and play with it. If <i>m</i> and <i>a</i> were big numbers, what did that do to <i>f</i> when I pushed it through the equation? If <i>f</i> was big and <i>a</i> was small, what did that do to <i>m</i>? How did the units match on each side? Playing with the equation was like conjugating a verb. I was beginning to intuit that the sparse outlines of the equation were like a metaphorical poem, with all sorts of beautiful symbolic representations embedded within it. Although I wouldn’t have put it that way at the time, the truth was that to learn math and science well, I had to slowly, day by day, build solid neural “chunked” subroutines—such as surrounding the simple equation <i>f</i> = <i>ma</i>—that I could easily call to mind from long term memory, much as I’d done with Russian.</p><p>Time after time, professors in mathematics and the sciences have told me that building well-ingrained chunks of expertise through practice and repetition was absolutely vital to their success. Understanding doesn’t build fluency; instead, fluency builds understanding. In fact, I believe that true understanding of a complex subject comes only from fluency.</p><p>In other words, in science and math education in particular, it’s easy to slip into teaching methods that emphasize understanding and that avoid the sometimes painful repetition and practice that underlie fluency. I learned Russian not just by understanding it—understanding, after all, is facile, and can easily slip away. (What did that word понимать mean?) I learned Russian by gaining fluency through practice, repetition, and rote learning—but rote learning that emphasized the ability to think flexibly and quickly. I learned math and science by applying precisely those same ideas. Language, math, and science, as with almost all areas of human expertise, draw on the same reservoir of brain mechanisms.</p>
<p><span>A</span>s I forayed into a new life, becoming an electrical engineer and, eventually, a professor of engineering, I left the Russian language behind. But 25 years after I’d last raised an inebriated glass on the Soviet trawlers, my family and I decided to take the trans-Siberian railway across Russia. Although I was excited to take the long-dreamed-of trip, I was also worried. I’d barely uttered a word of Russian in all that time. What if I’d lost it all? What had those years of gaining fluency really bought me?</p><p>Sure enough, when we first got on the train, I spoke Russian like a 2-year-old. I’d grasp for words, my declensions and conjugations were all wrong, and my formerly near-perfect accent sounded dreadful. But the foundation was there, and day by day, my Russian improved. And even with my rudimentary Russian, I could handle the day-to-day needs of our traveling. Soon, tour guides were coming to me for help translating for the other passengers. When we finally arrived in Moscow, we hopped in a taxi. The driver, I soon discovered, was intent on ripping us off—heading directly the wrong way and trapping us in a logjam of cars, where he expected us ignorant foreigners to quietly acquiesce to an unnecessary extra hour of meter time. Suddenly, Russian words I hadn’t spoken for decades flew from my mouth. I hadn’t even consciously known I knew those words.</p><p>Underneath it all, when it was needed, the fluency was there—and it quickly got us out of trouble (and into another taxi). Fluency allows understanding to become embedded, emerging when needed.</p>
<p>As I look today at the shortage of science and math majors in this country, and our current trend in how we teach people to learn, and as I reflect on my own pathway, knowing what I know now about the brain, it occurs to me that we can do better. As parents and teachers, we can use simple, accessible methods for deepening understanding and making it useful and flexible. We can encourage others and ourselves to try new disciplines that we thought were too hard—math, dance, physics, language, chemistry, music—opening new worlds for ourselves and others.</p><p>As I discovered, having a basic, deep-seated fluency in math and science—not just an “understanding,” is critical. It opens doors for many of life’s most intriguing jobs. Looking back, I realize that I didn’t have to just blindly follow my initial inclinations and passions. The “fluency” part of me that loved literature and language was also the same part of me that ultimately fell in love with math and science—and transformed and enriched my life.</p><p><i>Barbara Oakley is a professor of engineering at Oakland University, Rochester, Michigan, and the author of, most recently,</i> A Mind for Numbers: How to Excel at Math and Science (Even If  You Flunked Algebra). <i>She is also co-instructor, with Terrence Sejnowski, the Francis Crick Professor at the Salk Institute, of one of the world’s largest online courses, “Learning How to Learn,” with Coursera.</i></p>
<p><i>This article originally appeared in the Fall 2014</i> Nautilus Quarterly.</p><div>
<p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
<h4>Get the Nautilus newsletter</h4>
<p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
</div>

</div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Radicle is an open source, peer-to-peer code collaboration stack built on Git (146 pts)]]></title>
            <link>https://radicle.xyz/</link>
            <guid>40166736</guid>
            <pubDate>Fri, 26 Apr 2024 07:28:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://radicle.xyz/">https://radicle.xyz/</a>, See on <a href="https://news.ycombinator.com/item?id=40166736">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>
      <strong>Radicle</strong> is a sovereign
      <span id="definition">{code forge}</span> built on Git.
    </p>
    <nav>
      <span>
        <a href="#get-started">Get started ↓</a>
        <a href="https://radicle.xyz/guides/seeder">Run a seed →</a>
      </span>
      <span>
        <a href="https://radicle.xyz/guides">Guides</a>
        <a href="https://radicle.xyz/faq">FAQ</a>
        <a href="https://radicle.zulipchat.com/" target="_blank">Community</a>
        <a href="https://twitter.com/radicle" target="_blank">Tweets</a>
      </span>
    </nav>
    <h2 id="synopsis">Synopsis</h2>

<p>Radicle is an open source, peer-to-peer code collaboration stack built on Git.
Unlike centralized code hosting platforms, there is no single entity
controlling the network. Repositories are replicated across peers in a
decentralized manner, and users are in full control of their data and workflow.</p>

<p><a href="https://app.radicle.xyz/nodes/seed.radicle.xyz/rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5" target="_blank" title="Heartwood is the latest generation of the Radicle protocol">
  <img src="https://radicle.xyz/assets/images/web-app-screenshot.png">
</a>
<small>
  The Radicle <code>heartwood</code> repository. Repository ID
  <code>rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5</code>.
</small></p>



<h2 id="get-started">Get started</h2>



<blockquote id="release">
  <strong>Latest release</strong> 💾
  <span></span>
  <span>
    <a href="https://files.radicle.xyz/latest" id="release-info"></a>
    <span>·</span>
    <span id="release-timestamp"></span>
  </span>
</blockquote>



<p>To install Radicle on your system, simply run the <a href="https://radicle.xyz/install">install
script</a> from a POSIX shell. For now, Radicle only works on
Linux, macOS and BSD variants.</p>

<p>The following command downloads and runs the installation script on your
system:</p>



<p><code id="install-command">curl -sSf https://radicle.xyz/install | sh</code>
  <span id="install-copy">
    <svg width="16" height="16" viewBox="0 0 192 192" fill="none" xmlns="http://www.w3.org/2000/svg">
      <rect x="60" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="72" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="84" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="96" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="120" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="132" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="24" width="12" height="12" fill="currentColor"></rect>
      <rect x="60" y="36" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="36" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="48" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="36" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="48" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="60" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="72" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="84" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="96" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="60" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="72" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="72" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="72" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="84" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="84" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="84" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="96" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="96" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="96" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="108" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="108" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="108" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="120" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="120" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="120" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="132" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="132" width="12" height="12" fill="currentColor"></rect>
      <rect x="132" y="132" width="12" height="12" fill="currentColor"></rect>
      <rect x="144" y="132" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="144" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="144" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="156" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="156" width="12" height="12" fill="currentColor"></rect>
      <rect x="24" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="36" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="48" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="60" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="72" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="84" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="96" y="168" width="12" height="12" fill="currentColor"></rect>
      <rect x="108" y="168" width="12" height="12" fill="currentColor"></rect>
    </svg>
  </span>
</p>

<p>Alternatively, you can build from <a href="https://app.radicle.xyz/nodes/seed.radicle.xyz/rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5">source</a> or get the <a href="https://files.radicle.xyz/latest">binaries</a>.</p>

<p><a href="https://radicle.xyz/guides/user">Follow the guide →</a></p>

<h2 id="how-it-works">How it works</h2>

<p>The Radicle protocol leverages cryptographic identities for code and social
artifacts, utilizes Git for efficient data transfer between peers, and employs
a custom gossip protocol for exchanging repository metadata.</p>

<p><a href="https://radicle.xyz/guides/protocol">Learn more →</a></p>

<h2 id="your-data-forever-and-secure">Your Data, Forever and Secure</h2>

<p>All social artifacts are stored in Git, and signed using public-key
cryptography. Radicle verifies the authenticity and authorship of all data
for you.</p>

<h2 id="unparalleled-autonomy">Unparalleled Autonomy</h2>

<p>Radicle enables users to run their own nodes, ensuring censorship-resistant
code collaboration and fostering a resilient network without reliance on
third-parties.</p>

<h2 id="local-first">Local-first</h2>

<p>Radicle is <a href="https://www.inkandswitch.com/local-first/">local-first</a>, providing always-available functionality even
without internet access. Users own their data, making migration, backup, and
access easy both online and offline.</p>

<h2 id="evolvable--extensible">Evolvable &amp; Extensible</h2>

<p>Radicle’s <a href="https://radicle.xyz/guides/protocol#collaborative-objects">Collaborative Objects</a> (COBs) provide Radicle’s <em>social
primitive</em>. This enables features such as issues, discussions and code review
to be implemented as Git objects. Developers can extend Radicle’s capabilities
to build any kind of collaboration flow they see fit.</p>

<h2 id="modular-by-design">Modular by Design</h2>

<p>The Radicle Stack comes with a CLI, web interface and TUI, that are backed by
the Radicle Node and HTTP Daemon. It’s modular, so any part can be swapped out
and other clients can be developed.</p>

<pre>┌─────────────────┐┌────────────────┐
│  Radicle CLI    ││ Radicle Web    │
└─────────────────┘└────────────────┘
┌───────────────────────────────────┐
│  Radicle Repository               │
│ ┌────────┐ ┌────────┐ ┌─────────┐ │
│ │  code  │ │ issues │ │ patches │ │
│ └────────┘ └────────┘ └─────────┘ │
├───────────────────────────────────┤
│  Radicle Storage (Git)            │
└───────────────────────────────────┘
┌────────────────┐┌─────────────────┐
│  Radicle Node  ││  Radicle HTTPD  │
├────────────────┤├─────────────────┤
│    NoiseXK     ││   HTTP + JSON   │
└────────────────┘└─────────────────┘
</pre>

<p><a href="https://app.radicle.xyz/nodes/seed.radicle.xyz">Browse our repositories ↗</a></p>

<h2 id="updates">Updates</h2>

<ul>
  <li>26.03.2024 <a href="https://twitter.com/radicle/status/1772659708978991605">Radicle 1.0.0-rc.1</a> released! ✨</li>
  <li>10.03.2024 New Radicle homepage!</li>
  <li>05.03.2024 <a href="https://radicle.xyz/guides">Radicle Guides</a> launch.</li>
  <li>05.03.2024 <a href="https://news.ycombinator.com/item?id=39600810">Radicle makes it to the top of Hacker News</a>!</li>
  <li>18.04.2023 <a href="https://x.com/radicle/status/1648336186862194693?s=20">Radicle heartwood is announced</a>.</li>
</ul>

<h2 id="contributing">Contributing</h2>

<p>Radicle is <em>free and open source</em> software under the MIT and Apache 2.0
licenses. Get involved by <a href="https://app.radicle.xyz/nodes/seed.radicle.xyz/rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5/tree/CONTRIBUTING.md">contributing code</a>.</p>



<p>Follow us on <a href="https://twitter.com/radicle">Twitter</a> to stay updated, or join our <a href="https://radicle.zulipchat.com/">Zulip</a>.</p>

<div><pre><code>                                                         .
                                                   *
                        .
              *                              --O--
                                              /|\
                 ,                     .
                                           .
..-.--*--.__-__..._.--..-._.---....~__..._.--..~._.---.--..____.--_--'`_---..
       -.--~--._  __..._.--..~._.--- - -.____.--_--'`_---..~.----_~
</code></pre></div>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenVoice: Instant Voice Cloning (235 pts)]]></title>
            <link>https://github.com/myshell-ai/OpenVoice</link>
            <guid>40166690</guid>
            <pubDate>Fri, 26 Apr 2024 07:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/myshell-ai/OpenVoice">https://github.com/myshell-ai/OpenVoice</a>, See on <a href="https://news.ycombinator.com/item?id=40166690">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">OpenVoice V1</h3><a id="user-content-openvoice-v1" aria-label="Permalink: OpenVoice V1" href="#openvoice-v1"></a></p>
<p dir="auto">As we detailed in our <a href="https://arxiv.org/abs/2312.01479" rel="nofollow">paper</a> and <a href="https://research.myshell.ai/open-voice" rel="nofollow">website</a>, the advantages of OpenVoice are three-fold:</p>
<p dir="auto"><strong>1. Accurate Tone Color Cloning.</strong>
OpenVoice can accurately clone the reference tone color and generate speech in multiple languages and accents.</p>
<p dir="auto"><strong>2. Flexible Voice Style Control.</strong>
OpenVoice enables granular control over voice styles, such as emotion and accent, as well as other style parameters including rhythm, pauses, and intonation.</p>
<p dir="auto"><strong>3. Zero-shot Cross-lingual Voice Cloning.</strong>
Neither of the language of the generated speech nor the language of the reference speech needs to be presented in the massive-speaker multi-lingual training dataset.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">OpenVoice V2</h3><a id="user-content-openvoice-v2" aria-label="Permalink: OpenVoice V2" href="#openvoice-v2"></a></p>
<p dir="auto">In April 2024, we released OpenVoice V2, which includes all features in V1 and has:</p>
<p dir="auto"><strong>1. Better Audio Quality.</strong>
OpenVoice V2 adopts a different training strategy that delivers better audio quality.</p>
<p dir="auto"><strong>2. Native Multi-lingual Support.</strong>
English, Spanish, French, Chinese, Japanese and Korean are natively supported in OpenVoice V2.</p>
<p dir="auto"><strong>3. Free Commercial Use.</strong>
Starting from April 2024, both V2 and V1 are released under MIT License. Free for commercial use.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description openvoice.mp4">openvoice.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/40556743/291004056-3cba936f-82bf-476c-9e52-09f0f417bb2f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQxNDM5MDUsIm5iZiI6MTcxNDE0MzYwNSwicGF0aCI6Ii80MDU1Njc0My8yOTEwMDQwNTYtM2NiYTkzNmYtODJiZi00NzZjLTllNTItMDlmMGY0MTdiYjJmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI2VDE1MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUxMTk5NzQxNGU4NzU0YmE1YTNkMWQxMzhjOTM4YWQ0NmY1YmQwMmI1Y2ZiMDQ5ZGYyYWU0MDRhYjUxOGZmYjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.9L6iXGO84Zoe_OJsTiehaiGvzHV3y5drKy9rV4RCtfY" data-canonical-src="https://private-user-images.githubusercontent.com/40556743/291004056-3cba936f-82bf-476c-9e52-09f0f417bb2f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQxNDM5MDUsIm5iZiI6MTcxNDE0MzYwNSwicGF0aCI6Ii80MDU1Njc0My8yOTEwMDQwNTYtM2NiYTkzNmYtODJiZi00NzZjLTllNTItMDlmMGY0MTdiYjJmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI2VDE1MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUxMTk5NzQxNGU4NzU0YmE1YTNkMWQxMzhjOTM4YWQ0NmY1YmQwMmI1Y2ZiMDQ5ZGYyYWU0MDRhYjUxOGZmYjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.9L6iXGO84Zoe_OJsTiehaiGvzHV3y5drKy9rV4RCtfY" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">OpenVoice has been powering the instant voice cloning capability of <a href="https://app.myshell.ai/explore" rel="nofollow">myshell.ai</a> since May 2023. Until Nov 2023, the voice cloning model has been used tens of millions of times by users worldwide, and witnessed the explosive user growth on the platform.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Main Contributors</h2><a id="user-content-main-contributors" aria-label="Permalink: Main Contributors" href="#main-contributors"></a></p>
<ul dir="auto">
<li><a href="https://www.qinzy.tech/" rel="nofollow">Zengyi Qin</a> at MIT and MyShell</li>
<li><a href="https://wl-zhao.github.io/" rel="nofollow">Wenliang Zhao</a> at Tsinghua University</li>
<li><a href="https://yuxumin.github.io/" rel="nofollow">Xumin Yu</a> at Tsinghua University</li>
<li><a href="https://twitter.com/ethan_myshell" rel="nofollow">Ethan Sun</a> at MyShell</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to Use" href="#how-to-use"></a></p>
<p dir="auto">Please see <a href="https://github.com/myshell-ai/OpenVoice/blob/main/docs/USAGE.md">usage</a> for detailed instructions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Common Issues</h2><a id="user-content-common-issues" aria-label="Permalink: Common Issues" href="#common-issues"></a></p>
<p dir="auto">Please see <a href="https://github.com/myshell-ai/OpenVoice/blob/main/docs/QA.md">QA</a> for common questions and answers. We will regularly update the question and answer list.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Join Our Community</h2><a id="user-content-join-our-community" aria-label="Permalink: Join Our Community" href="#join-our-community"></a></p>
<p dir="auto">Join our <a href="https://discord.gg/myshell" rel="nofollow">Discord community</a> and select the <code>Developer</code> role upon joining to gain exclusive access to our developer-only channel! Don't miss out on valuable discussions and collaboration opportunities.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<div data-snippet-clipboard-copy-content="@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}"><pre><code>@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">OpenVoice V1 and V2 are MIT Licensed. Free for both commercial and research use.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">This implementation is based on several excellent projects, <a href="https://github.com/coqui-ai/TTS">TTS</a>, <a href="https://github.com/jaywalnut310/vits">VITS</a>, and <a href="https://github.com/daniilrobnikov/vits2">VITS2</a>. Thanks for their awesome work!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A BSD person tries Alpine Linux (247 pts)]]></title>
            <link>https://rubenerd.com/a-bsd-pserson-trying-alpine-linux/</link>
            <guid>40166670</guid>
            <pubDate>Fri, 26 Apr 2024 07:13:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubenerd.com/a-bsd-pserson-trying-alpine-linux/">https://rubenerd.com/a-bsd-pserson-trying-alpine-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=40166670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In February last year I wrote about <a href="https://rubenerd.com/its-worth-running-a-freebsd-or-netbsd-desktop/">running a FreeBSD desktop</a>, and concluded that sometimes you need to give yourself permission to tinker.</p>
<p>Well recently I’ve started tinkering with <a href="https://www.alpinelinux.org/">Alpine Linux</a>! It’s been recommended to me for years, so I’m finally getting around to checking it out. There’s a lot to like if you come from BSD, which we’ll dig into here.</p>
<figure><p><a target="_BLANK" href="https://rubenerd.com/files/2024/alpine-ovm-boot.png"><img src="https://rubenerd.com/files/2024/alpine-ovm-boot.png" alt="Booting a new Alpine ISO on OrionVM"></a></p></figure>
<h3 id="a-potted-history">A potted history</h3>
<p>The Alpine website <a href="https://www.alpinelinux.org/about/">describes it as</a>:</p>
<blockquote>
<p>an independent, non-commercial, general purpose Linux distribution designed for power users who appreciate security, simplicity and resource efficiency.</p>
</blockquote>
<p>Its small footprint and design decisions also make it more secure:</p>
<blockquote>
<p>All userland binaries are compiled as Position Independent Executables (PIE) with stack smashing protection. These proactive security features prevent exploitation of entire classes of zero-day and other vulnerabilities.</p>
</blockquote>
<p>Natanael Copa discussed the genesis of the project back in 2005, making it older than I realised. Like the BSDs, it’s found its way into embedded systems, routers, and mobile devices, as well as general purpose servers and desktops.</p>
<p>Alpine is also a popular base for use in Linux containers, owing to its compact size and limited dependencies. There are also <a href="https://github.com/alpinelinux/alpine-chroot-install/">toolchains</a> for easily running it in a <code>chroot(8)</code>, which is interesting for someone who uses <a href="https://man.netbsd.org/chroot.8">NetBSD chroots(8)</a> and <a href="https://docs.freebsd.org/en/books/handbook/jails/">FreeBSD jails</a> extensively for testing and deployments.</p>
<h3 id="installation">Installation</h3>
<p>Alpine comes in a <a href="https://alpinelinux.org/downloads/">few different versions</a>, including builds for ARM, PPC64, x86, and x86_64.</p>
<p>I downloaded the Xen ISO image because I was booting it on a VM at work, before realising I misread <em>Dom0</em> as <em>DomU</em>. The former refers to a Xen hypervisor, not a guest. Either way, it booted and installed the same as a standard ISO.</p>
<p>The install process is about as simple as you could make it. You log into the live environment with <code>root</code> and no password, then execute <code>setup-alpine</code>.</p>
<p>You’re asked basic questions for your keymap, networking, timezone, and root authentication. You can also inject an SSH key from the start, which is useful if you’re deploying a fleet of VMs or servers with an orchestration tool after the fact, or you’re deploying to a mediocre hosting provider that doesn’t give you an OOB console.</p>
<p>You’re also given the choice of a few different SSH servers and ntp clients, which let me choose my preferred OpenSSH and openntpd. It also correctly identified it was operating under Xen.</p>
<figure><p><a target="_BLANK" href="https://rubenerd.com/files/2024/alpine-install.png"><img src="https://rubenerd.com/files/2024/alpine-install.png" alt="Screenshot of a portion of the Alpine Linux installer, showing the mirror selection, user config, and Xen installation."></a></p></figure>
<p>It can also configure an LVM, but I stuck with what Alpine calls standard <code>sys</code> partitions for now. This uses <code>ext4</code>.</p>
<h3 id="post-install-and-exploration">Post-install and exploration</h3>
<p>Booting into Alpine for the first time, your given a hint as to why it’s special: <code>dmesg(1)</code> informs you you’re running <a href="https://github.com/OpenRC/openrc">OpenRC</a>! It’s portable, small, fast, efficient, transparent, and secure. It’s also very familiar to a BSD person used to writing rc scripts. <code>/etc/rc.conf</code> and <code>crond(8)</code>!? <strong>Yes!!!</strong></p>
<p>At the risk of embellishing my feelings about this, it is <em>such</em> a relief that there are Linux distros like Devuan, Gentoo, and Alpine using this. It’s a breath of alpine air, and has legitimately made Linux fun again.</p>
<figure><p><a target="_BLANK" href="https://rubenerd.com/files/2024/alpine-openrc.png"><img src="https://rubenerd.com/files/2024/alpine-openrc.png" alt="Screenshot showing dmesg output on first boot."></a></p></figure>
<p>Along with OpenRC, Alpine is bundled with <a href="https://wiki.alpinelinux.org/wiki/Musl">musl</a>, and runs busybox. Both are obviously more limited than GCC and the GNU coreutils, but they further contribute to the base system’s smaller size and attack surface. <a href="https://pkgs.alpinelinux.org/package/edge/main/x86_64/llvm-runtimes">llvm</a> is also available, as is the <a href="https://pkgs.alpinelinux.org/package/edge/main/x86_64/mksh">MirBSD Korn shell</a>, one of my two preferred interactive shells.</p>
<blockquote>
<p>Um, Ruben, I’d like to interject for a moment. What you are referring to as Linux, is in fact, GNU/Linux, or as I’ve recently taken to calling it, a GNU grilled cheese sandwich merely featuring Linux as the…</p>
</blockquote>
<p>… nope!</p>
<h3 id="packages">Packages</h3>
<p>Speaking of installing packages, let’s take a look at that. Alpine’s default package manager is <a href="https://docs.alpinelinux.org/user-handbook/0.1a/Working/apk.html" title="Working with the Alpine Package Keeper">apk</a>. As is normal on Linux, this handles updating the base system and all packages, because it makes no distinction. I’d be interested to see if I could also run an unprivileged copy of this as I like to do on the BSDs, but I haven’t checked yet. There’s also <a href="https://www.pkgsrc.org/#index2h3">pkgsrc</a>, so no biggie.</p>
<p>Configuration is in <code>/etc/apk/repositories</code>, where you can enable the community repo by uncommenting the second URL supplied by the installer. Alpine also has a <code>testing</code> repo, and you can add your own.</p>
<p>Usage is easy, though I’ve still been mistyping <code>apt install</code> instead of <code>apk add</code>, because old habits die hard. There’s an official <a href="https://pkgs.alpinelinux.org/">web interface</a>, and Alpine repos are on <a href="https://alpine.pkgs.org/">pkgs.org</a>.</p>
<p>A few packages later, and I had my “essentials” going, like I do on my <a href="https://rubenerd.com/my-freebsd-laptop-with-just-tmux/" title="My FreeBSD laptop... without a GUI!?">console-only laptop</a>:</p>
<figure><p><a href="https://rubenerd.com/files/2024/alpine-stuff.png"><img src="https://rubenerd.com/files/2024/alpine-stuff.png" alt="Alpine running tmux, htop, zpool, and cmatrix."></a></p></figure>
<p>Perhaps the package I was most surprised about was zfs. It was literally two commands to install and load the kernel module (though obviously root on ZFS would be more involved). What that would look like after an upgrade I’d have to see, but thus far I’m impressed.</p>
<pre><code># apk add zfs zfs-lts
# modprobe zfs
</code></pre>
<h3 id="conclusion">Conclusion</h3>
<p>I’ve barely scratched the surface, but there’s enough here for me to seriously consider a switch to it as my primary Linux distro for testing and servers. I love that <code>htop(1)</code> and <code>lsof(1)</code> only shows a small list of recognisable processes, that it uses OpenRC, that package management seems straight forward, and that it’s so simple to configure. I’ve wondered what a modern, functional “Occam’s Linux” would look like. This is it.</p>
<p>I’d be interested in seeing if <a href="https://github.com/uutils/coreutils">uutils</a> runs if I need something more than busybox, but for a server I doubt it.</p>
<figure><p><img src="https://rubenerd.com/files/2024/alpine-alpine.png" alt="Alpine running the Alpine mail client"></p></figure>
<p><em>I heard you liked Alpine, so I etc…</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minister defends arrest power for people feared to commit a hate crime in future (146 pts)]]></title>
            <link>https://www.theglobeandmail.com/politics/article-justice-minister-defends-house-arrest-power-for-people-feared-to/</link>
            <guid>40166653</guid>
            <pubDate>Fri, 26 Apr 2024 07:09:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theglobeandmail.com/politics/article-justice-minister-defends-house-arrest-power-for-people-feared-to/">https://www.theglobeandmail.com/politics/article-justice-minister-defends-house-arrest-power-for-people-feared-to/</a>, See on <a href="https://news.ycombinator.com/item?id=40166653">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content-gate" data-sophi-feature="article body"><figure><a href="https://www.theglobeandmail.com/resizer/v2/HWZCTFEANFGOXEB4PPNTNT24QI.jpg?auth=16920e7331d82a3fa2aad648055643ff0ddaee4dc655ab549d63e347035af8ca&amp;width=600&amp;quality=80" aria-haspopup="true" data-photo-viewer-index="0"><span>Open this photo in gallery:</span><p><img alt="" height="389" sizes="(min-width: 80rem) 940px,(min-width: 48rem) 690px,100vw" src="https://www.theglobeandmail.com/resizer/v2/HWZCTFEANFGOXEB4PPNTNT24QI.jpg?auth=16920e7331d82a3fa2aad648055643ff0ddaee4dc655ab549d63e347035af8ca&amp;width=600&amp;quality=80" srcset="https://www.theglobeandmail.com/resizer/v2/HWZCTFEANFGOXEB4PPNTNT24QI.jpg?auth=16920e7331d82a3fa2aad648055643ff0ddaee4dc655ab549d63e347035af8ca&amp;width=1200&amp;quality=80 1200w,https://www.theglobeandmail.com/resizer/v2/HWZCTFEANFGOXEB4PPNTNT24QI.jpg?auth=16920e7331d82a3fa2aad648055643ff0ddaee4dc655ab549d63e347035af8ca&amp;width=900&amp;quality=80 900w,https://www.theglobeandmail.com/resizer/v2/HWZCTFEANFGOXEB4PPNTNT24QI.jpg?auth=16920e7331d82a3fa2aad648055643ff0ddaee4dc655ab549d63e347035af8ca&amp;width=600&amp;quality=80 600w" width="600" fetchpriority="high"></p></a><figcaption><div><p><span>Justice Minister Arif Virani said online harms bill would strike a balance and that content that is 'awful but lawful' would remain online.</span><span>Sean Kilpatrick/The Canadian Press</span></p></div></figcaption></figure><p>Justice Minister Arif Virani has defended a new power in the <a href="https://www.theglobeandmail.com/politics/article-online-harms-bill-law/" target="_blank">online harms bill</a> to impose house arrest on someone who is feared to commit a hate crime in the future – even if they have not yet done so already.</p><p>The person could be made to wear an electronic tag, if the attorney-general requests it, or ordered by a judge to remain at home, the bill says.</p><p>Mr. Virani, who is Attorney-General as well as Justice Minister, said it is important that any peace bond be “calibrated carefully,” saying it would have to meet a high threshold to apply.</p><p>But he said the new power, which would require the attorney-general’s approval as well as a judge’s, could prove “very, very important” to restrain the behaviour of someone with a track record of hateful behaviour who may be targeting certain people or groups.</p><p>If “there’s a genuine fear of an escalation, then an individual or group could come forward and seek a peace bond against them and to prevent them from doing certain things.”</p><p>The peace bond could have conditions that include not being close to a synagogue or a mosque, he said. It could also lead to restrictions on internet usage and behaviour. “That would help to deradicalize people who are learning things online and acting out in the real world violently – sometimes fatally.”</p><p>Mr. Virani said the bill would strike a balance, though, and would mean that content that is “awful but lawful” would remain online.</p><p>“There’s a lot of bad stuff out there. But this is not about the bad stuff. This is a much higher level,” he said.</p><p>Bill C-63 is designed to curb the proliferation of hate online, but it also establishes a new hate-crime offence, which would carry a maximum penalty of life imprisonment.</p><p>Mr. Virani said the hate-crime offence would only be applied if coupled with another crime and the life sentence would only apply in the most serious of cases – not, for example, for mischief to a garage door.</p><p>“What’s really critical is that it gives the judge a wonderful range of sentences. This is not a mandatory minimum of a life sentence, this is just a larger range, including what would be the maximum sentence,” he said.</p><p>The bill also would make online platforms swiftly take down child sexual-abuse material, as well as sexual content posted without consent. But the government stepped back from forcing platforms to take down hate speech within 24 hours, introducing other tools to deal with this, including through a complaint to a new ombudsperson.</p><p>The bill’s predecessor, Bill C-36, died before the last election and the subsequent consultation would have forced social-media platforms to take down a wide range of content deemed harmful within 24 hours.</p><p data-sophi-feature="interstitial"><a href="https://www.theglobeandmail.com/politics/article-online-harms-bill-law/">What to know about Bill C-63, Canada’s new online harms bill to protect children and prosecute hate crimes</a></p><p>Mr. Virani said the current bill followed studies of the experiences of other countries, including Britain, France and Germany, which have produced similar legislation. Some have had to reverse course after challenges and criticism.</p><p>Since it was published on Monday, some lawyers and constitutional experts have raised fears that Bill C-63 could chill free speech.</p><p>The bill would allow people to file complaints to the Canadian Human Rights Commission over what they perceive as hate speech online – including, for example, off-colour jokes by comedians. People found guilty of posting hate speech could have to pay victims up to $20,000 in compensation.</p><p>But experts including internet law professor Michael Geist have said even a threat of a civil complaint – with a lower burden of proof than a court of law – and a fine could have <a href="https://www.theglobeandmail.com/politics/article-online-harms-bills-proposed-changes-risk-silencing-free-speech-experts/" target="_blank">a chilling effect</a> on freedom of expression.</p><p>Mr. Virani said as Justice Minister he has sworn to uphold the Constitution, which includes freedom of expression.</p><p>“Of course, I’m concerned about any chilling [of] freedom of expression. I heard those concerns, to a great extent,” he said.</p><p>He said the bill includes various safeguards to allow the human-rights commission to throw out frivolous complaints, including a kind of “summary dismissal mechanism” if a complaint does not hit the threshold for hatred or if someone files a complaint in bad faith. Costs could also be issued.</p><p>Mr. Virani said for those categories of harm online that would not need to be taken down within 24 hours, he would expect the response of the regulator, ombudsperson or other body examining a complaint to be “prompt.” Fears have been expressed that they could take months or even years to adjudicate on whether posts should be removed.</p><p>“Time is of the essence and we know how horrible material can go viral very, very quickly,” he said. He added for this reason it is critical that the bill progresses through Parliament to committee swiftly so the government can look at amendments.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's Been a Year and Georgia.gov Continues to Be Hacked (152 pts)]]></title>
            <link>https://boehs.org/node/medicicnes</link>
            <guid>40166468</guid>
            <pubDate>Fri, 26 Apr 2024 06:29:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://boehs.org/node/medicicnes">https://boehs.org/node/medicicnes</a>, See on <a href="https://news.ycombinator.com/item?id=40166468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><dl><dt><strong><a href="https://boehs.org/locations/">in</a></strong></dt><dd><a href="https://boehs.org/in/blog">blog</a></dd><dt><strong><a href="https://boehs.org/tags/">tags</a></strong></dt><dd><ul><li><a href="https://boehs.org/tag/civics">civics</a></li></ul></dd><dt><strong>date</strong></dt><dd><span itemprop="datePublished" content="Fri Apr 26 2024 00:00:00 GMT+0000 (Coordinated Universal Time)">4/26/2024</span></dd></dl><hr><p>Exactly one year ago, I was searching Google to see what government websites somehow wound up using ChatGPT programmatically:</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426012007.png"></p><p>Lo and behold, one did! It was the state of Georgia!</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426012253.png"></p><p>Now, unfortunately, I do not have screenshots of what the Google results looked like, but <code>medicicnes</code> might give you a good idea what the pages were about: They redirected to sites that illegally sold dubious medicine.</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426013140.png"></p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426013437.png"></p><p>I thought this was pretty interesting, so I contacted the New York Times and also fired an email off to the contact link listed on the Georgia website. Both parties ignored me and I forgot about it. Until now.</p><p>This time around, the results were much harder to find, as since then a <em>lot</em> of government websites have been infiltrated by AI. A little history sleuthing, however, lead me back to the fatal misspelling of medicine that I couldn’t quite remember. Are the redirects still up?</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426013643.png"></p><p>Dang.</p><p><a href="http://team.georgia.gov/">team.georgia.gov</a> is reportedly <em>For State of Georgia Employees</em>. I don’t think it’s fair to make government employees share their space with hackers. This is a bad look — especially as it’s been unpatched for a year now. It’s a bad look that my contact attempt was ignored. Step it up, Georgia.</p><p>I was curious if I could figure out how this happened. I’m also curious how this ended up in the Google index (as <code>sitemap.xml</code> is empty and ahrefs reports zero backlinks). Visiting <a href="http://team.georgia.gov/medicicnes">team.georgia.gov/medicicnes</a> directly shows an Apache 404 page:</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426014630.png"></p><p>It’s interesting because every other 404 route just shows an empty page:</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426014705.png"></p><p>You can detect the version of Apache by doing a <code>HEAD</code> request. I’ve done a head request for these two different paths:</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426014954.png"></p><p>This indicates to me that someone with access to Georgia’s servers did this on an Apache level, instead of within WordPress. All these software versions are outdated, so it’s possible that an attacker did this, I suppose… It’s just all a wee bit odd.</p><p>Further investigation shows that this page <em>only</em> works if the referrer is google:</p><p><img src="https://boehs.org/assets/Pasted%20image%2020240426082251.png"></p><p>Which makes this a very deliberate attempt to hide the attack.</p><p><em>If you are aware of other unpatched government tomfoolery, or have more information on this story, please <a href="https://boehs.org/contact">reach out</a>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple Displays on a Mac Sucks (245 pts)]]></title>
            <link>https://wadetregaskis.com/multiple-displays-on-a-mac-sucks/</link>
            <guid>40166268</guid>
            <pubDate>Fri, 26 Apr 2024 05:46:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wadetregaskis.com/multiple-displays-on-a-mac-sucks/">https://wadetregaskis.com/multiple-displays-on-a-mac-sucks/</a>, See on <a href="https://news.ycombinator.com/item?id=40166268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<div id="toc_container"><p>Contents</p><ul><li><a href="#The_Mac_operating_system_still_Just_Fucking_Sucks_at_remembering_where_windows_were_when_relaunching_apps">The Mac operating system still Just. Fucking. Sucks. at remembering where windows were, when relaunching apps.</a></li><li><a href="#Full-screen_apps_mostly_games_don8217t_handle_the_additional_displays_correctly">Full-screen apps (mostly games) don’t handle the additional display(s) correctly.</a></li><li><a href="#Side_Docks_aren8217t_practical">Side Docks aren’t practical.</a></li><li><a href="#The_menu_bar_is_particularly_petulant_when_multiple_displays_are_in_use">The menu bar is particularly petulant when multiple displays are in use.</a></li><li><a href="#Windows_appear_on_the_wrong_display_sometimes">Windows appear on the wrong display sometimes.</a></li><li><a href="#Multi-display_ergonomics_tend_to_suck">Multi-display ergonomics tend to suck.</a></li><li><a href="#Splitting_work_across_multiple_displays_is_hard">Splitting work across multiple displays is hard.</a></li></ul></div><p>So many people I’ve worked with have used multiple displays – typically a matched pair side-by-side – and sworn by them. It’s always mystified me, to be honest.</p>
<p>I’ve attempted the multi-display lifestyle a few times over the last thirty years. At first as a bourgeois indulgence, back when even having a single 17″ display was considered luxurious<sup data-fn="f3ad31a4-54b3-4c05-9f1f-e3057f4f8a73"><a href="#f3ad31a4-54b3-4c05-9f1f-e3057f4f8a73" id="f3ad31a4-54b3-4c05-9f1f-e3057f4f8a73-link">1</a></sup>, let-alone two displays. Just because I could. Then sporadically over the years in more practical attempts to expand my screen real estate.</p>
<p>The debut of 5k displays in 2014 relieved that pressure for a long while. It’s hard to overstate how profound that first 5k iMac was.</p>
<p>But in the last year or so I’ve felt a bit cramped – particularly as I’ve spent increasing amounts of time in Xcode, which is <em>okay</em> on a 5k display but not great. Especially if you try to do GUI design, whether AppKit or SwiftUI. Let-alone if you start working with iPad Pro simulators and the like.</p>
<p>So I’ve been considering, yet again, my options.</p>
<p>Sadly:</p>
<ol>
<li>I have an iMac Pro. Even if I were willing to waste the built-in display, I cannot – Apple does not allow iMacs to disable their internal displays.<p>I wouldn’t necessarily mind replacing the iMac Pro (it’s been a pretty shitty computer since the day it was made) but <a href="https://wadetregaskis.com/apples-timing-problem/" data-wpel-link="internal">Apple keep conspiring to discourage me from doing so</a><sup data-fn="2d929093-1c10-4680-a4bd-383b85a98e88"><a href="#2d929093-1c10-4680-a4bd-383b85a98e88" id="2d929093-1c10-4680-a4bd-383b85a98e88-link">2</a></sup>.</p></li>
<li>There aren’t any great options for larger displays.<p>Available 6k displays aren’t great<sup data-fn="85221166-1dce-4d95-b6be-6b7fa2b7c644"><a href="#85221166-1dce-4d95-b6be-6b7fa2b7c644" id="85221166-1dce-4d95-b6be-6b7fa2b7c644-link">3</a></sup>, although I’m glad there’s at least a couple of half-decent options. I never thought I’d be thankful that <em>Dell</em>, of all hardware companies, is still around and making better products than Apple.</p><p>8k displays practically don’t exist – I don’t have the physical space to use an 8k TV<sup data-fn="31755725-c69f-4729-b5d0-d0e1d2833f9f"><a href="#31755725-c69f-4729-b5d0-d0e1d2833f9f" id="31755725-c69f-4729-b5d0-d0e1d2833f9f-link">4</a></sup>, which is otherwise actually the best way to go, and <a href="https://www.dell.com/en-us/shop/dell-ultrasharp-32-8k-monitor-up3218k/apd/210-alez/monitors-monitor-accessories" data-wpel-link="external" target="_blank" rel="external noopener">the one 8k computer display</a> I know of is far too physically small for its resolution<sup data-fn="329e19a1-f614-448f-8975-7365a698f75a"><a href="#329e19a1-f614-448f-8975-7365a698f75a" id="329e19a1-f614-448f-8975-7365a698f75a-link">5</a></sup>.</p></li>
</ol>
<p>As it happened, I had an extra 5k display left over from working at LinkedIn (they wouldn’t provide decent displays to employees while I was there, so I had to buy my own out of my own pocket<sup data-fn="3f8979d6-ea6a-4991-afc8-845186aeb8a5"><a href="#3f8979d6-ea6a-4991-afc8-845186aeb8a5" id="3f8979d6-ea6a-4991-afc8-845186aeb8a5-link">6</a></sup>). So far as multi-display setups go it’s arguably ideal, since it’s basically the exact same panel as the iMac Pro’s display, so it should match quite well<sup data-fn="9cf23db5-75b6-40a4-88cd-48d1ad743001"><a href="#9cf23db5-75b6-40a4-88cd-48d1ad743001" id="9cf23db5-75b6-40a4-88cd-48d1ad743001-link">7</a></sup>. So a few months ago I went to some effort to rearrange my working space to accomodate it, and set to work with it.</p>
<p>And not a lot has changed in thirty years.</p>
<h2><span id="The_Mac_operating_system_still_Just_Fucking_Sucks_at_remembering_where_windows_were_when_relaunching_apps">The Mac operating system <em>still</em> Just. Fucking. Sucks. at remembering where windows were, when relaunching apps.</span></h2>
<p>For the first month or so it was mostly fine – a couple of apps would be <em>occasionally</em> problematic, but it was tolerable. Mostly. Xcode in particularly pisses me off in that it <em>always</em> forgets where the documentation window was, every time you open it<sup data-fn="08475590-6d49-4fed-ab6b-99455053ae2a"><a href="#08475590-6d49-4fed-ab6b-99455053ae2a" id="08475590-6d49-4fed-ab6b-99455053ae2a-link">8</a></sup>.</p>
<p>But then, something invisible to me apparently happened, and since then <em>every single boot every single window resets its position onto the built-in display</em>. Every single boot I have to spend a bunch of time digging buried windows out from the over-crowded main display and shifting them back to their correct positions on the second display.</p>
<p>I might dismiss this as particular bad luck, except I know from decades of experience that this is in fact normal.  It <em>always</em> happens, sooner or later.  And at some point it will unfuck itself and start [mostly] remembering where windows go.  Only to inevitably repeat the vicious cycle.</p>
<h2><span id="Full-screen_apps_mostly_games_don8217t_handle_the_additional_displays_correctly">Full-screen apps (mostly games) don’t handle the additional display(s) correctly.</span></h2>
<p>i.e. they ignore them, typically. It’s very distracting having a bright display right next to one on which you’re trying to play a game. Every time I launch or exit such an app I have to manually open System Settings, go to Display settings, click the secondary display, and manually changes its brightness.</p>
<p>My secondary display (<a href="https://www.lg.com/us/monitors/lg-27md5kl-b-5k-uhd-led-monitor" data-wpel-link="external" target="_blank" rel="external noopener">LG 5k</a>) doesn’t have a power button, and I found out real quick that unplugging the Thunderbolt cable confuses the hell out of macOS, resulting in windows going wild and some apps outright crashing.</p>
<h2><span id="Side_Docks_aren8217t_practical">Side Docks aren’t practical.</span></h2>
<p>When the Dock is on the side, it only appears on the display that is farthest to that side.  Having to move the mouse across <em>multiple</em> displays just to get to the Dock is untenably slow and awkward.</p>
<p>I have the Dock set to auto-hide, because I’m not a monster.  But that does mean I have to be careful about mouse movements near its edge of the screen.</p>
<p>I prefer having the Dock on the left-hand side because it’s the least intrusive place – there’s relatively little you have to mouse to or interact with on the left edge (the right side is second-best, but notably is the home of scrollbars).  It’s also slightly easier to mouse left (or right) than down, because moving the mouse ‘down’ (towards me) has extra tension from the USB cable.</p>
<p>With multiple monitors (in a typical horizontal arrangement), I’m forced to use a bottom Dock, which is the worst place to have the Dock because so much stuff is placed right at the bottom of the screen – window resize widgets, toolbars &amp; their buttons, horizontal scrollbars, etc.  It’s immensely irritating to have to finesse minute mouse movements in order to avoid triggering the Dock while somehow still getting the cursor within a few pixels of the edge of the screen.  Sometimes it’s necessary to move the entire window just to interact with its bottom parts – which can in turn require first resizing it from the top, in order to allow it to be moved upwards.</p>
<h2></h2>
<p>I have the menu bar set to auto-hide, partly for reasons of visual cleanliness and to save a little screen space, but also because the menubar ruined my previous iMac’s display by burning in, hard.</p>
<p>I also use the menubar a lot more than for just activating menus with the mouse – I have iStat Menus and a host of other monitoring utilities in there as well.  So I’m frequently mousing up to the top of the screen to reveal the menubar.  Which is not a burden in itself – flicking the mouse to the top of the screen is a completely trivial operation.</p>
<p>But it doesn’t work half the time, when you have multiple displays, because the menubar will only deign to reveal itself on the “active” display, which is often at a glance visually indistinguishable from the “inactive” display (thanks to Apple’s long-running war against clarity).</p>
<p>That defeats the instinct and muscle-memory to just flick the cursor to the top of the display in order to see the menubar.  Worse, since macOS has some design flaws regarding menu bar reveal (e.g. it refuses to reveal if the frontmost application’s main thread runloop isn’t idle, and whenever an application is launching), you can’t immediately tell if it’s refusing to reveal itself because the cursor’s on the “wrong” display.  So inevitably there’s wasted, distracting moments of pause and investigation, and possibly movement to a whole different display.  For an operation that happens hundreds of times a day, wasted seconds add up.</p>
<h2><span id="Windows_appear_on_the_wrong_display_sometimes">Windows appear on the wrong display sometimes.</span></h2>
<p>Enough said, really.  I have no idea why they appear in the wrong places, but then so much about macOS’s window management is inexplicably buggy like this, such as why some modal dialogs appear <em>behind</em> all existing windows.</p>
<h2><span id="Multi-display_ergonomics_tend_to_suck">Multi-display ergonomics tend to suck.</span></h2>
<p>If – in a typical horizontal arrangement – you give the two displays equal priority in placement, you end up with one to your left and one to your right, with a very irritating gap between them in the one place it’s natural to look – straight ahead of you.  Neither display is aligned with the keyboard or mouse, which I find impairs typing and mousing accuracy (especially with a treadmill desk where I’m constantly moving).  And I find I get a sore neck no matter what, because I’m spending all my time looking anywhere but centre.</p>
<p>If you keep a “primary” display front and centre, and put a second one off to a side, the second display becomes <em>much</em> less useful because it’s even more uncomfortable to actually look at.  Which couples with the fact that…</p>
<h2><span id="Splitting_work_across_multiple_displays_is_hard">Splitting work across multiple displays is <em>hard</em>.</span></h2>
<p>More so than it seems it should be. But in practice there’s a <em>big</em> difference between two windows side-by-side on one display, and two windows on separate displays (<em>especially</em> if the displays aren’t identical, or aren’t aligned on horizontal or vertical axes). Maybe it’s as a simple as the difference between moving your eyes and moving your head.</p>
<p>Whatever it is, I just cannot get comfortable moving between displays frequently. That then forces me to not put anything <em>important</em> on the second display (especially if it has an ergonomically inferior position compared to the primary display), so it ends up being kind of a dumping ground for stuff I don’t actually use that often – e.g. calendar, clipboard viewers, calculators, etc.</p>
<p>And since I don’t actually use them that often, there’s really not much advantage to having them on a second display, versus just bringing them to the front on the main display and then hiding them again when I’m done. In fact, sometimes it’s counter-productive as irrelevant animations on the second display distract me, whereas they’d be safely out of sight behind other windows on the main display.</p>
<p>The only meaningful use-case I have so far for genuine simultaneous use is moving information references – e.g. Xcode’s documentation window – to the second display. In fact that was the specific use-case that made me go to the trouble of hooking up the second display, since it’s practically impossible to fit a non-trivial Xcode project into just half a 5k display, and having to constantly toggle between code &amp; documentation is irritating and a little disruptive – there’s often a <em>lot</em> of rapid back-and-forth between code &amp; docs, which is of course much easier if they’re simultaneously visible.</p>
<ol><li id="f3ad31a4-54b3-4c05-9f1f-e3057f4f8a73">Apple’s first so-called 17″ display (it was actually only 16.5″) was the <a href="https://everymac.com/monitors/apple/multiple_scan/specs/multiple_scan_17.html" data-wpel-link="external" target="_blank" rel="external noopener">Apple Multiple Scan 17</a>, released in 1994 for USD$1,100 (not counting taxes). That’s equivalent to about $2,500 today. For a display that could do just 1024×768 – but, in a time when 640×480 was the vastly dominant standard, so that was a <em>huge</em> leap up in display resolution – 156%! It’s the same as going from a 4k to 6k display. <a href="#f3ad31a4-54b3-4c05-9f1f-e3057f4f8a73-link" aria-label="Jump to footnote reference 1">↩︎</a></li><li id="2d929093-1c10-4680-a4bd-383b85a98e88">I say that with some sense of humility and humour, of course. But the effect is real, even if arguably irrational. Nobody likes buying something that they know is about to be replaced, nor something that’s a bit outdated even at its start, irrespective of whether it’s functionally sufficient for their needs. <a href="#2d929093-1c10-4680-a4bd-383b85a98e88-link" aria-label="Jump to footnote reference 2">↩︎</a></li><li id="85221166-1dce-4d95-b6be-6b7fa2b7c644"><a href="https://www.apple.com/pro-display-xdr/" data-wpel-link="external" target="_blank" rel="external noopener">Apple’s 6k display</a> is stupidly over-priced, even by Apple standards, and uses a severely compromised design with its coarse backlight zoning system. That results in significant blooming, which is annoying even for casual use but particularly problematic for photography and videography. I’d rather have a uniform display with lower contrast – like existing 5k displays – as the lesser of the two evils, since that more faithfully reproduces images.<p><a href="https://www.dell.com/en-us/shop/dell-ultrasharp-32-6k-monitor-u3224kb/apd/210-bhbz/monitors-monitor-accessories#techspecs_section" data-wpel-link="external" target="_blank" rel="external noopener">Dell’s 6k display</a> is a better option, having made better decisions on key design compromises, but it’s still a bit pricey and it’s a bit dim at just 450 cd/m². Good enough for coding in a not too brightly lit room, but it’s pretty useless for working with HDR imagery. <a href="#85221166-1dce-4d95-b6be-6b7fa2b7c644-link" aria-label="Jump to footnote reference 3">↩︎</a></p></li><li id="31755725-c69f-4729-b5d0-d0e1d2833f9f">The smallest I can find is 65″, which would mean sitting at least a metre away from it to avoid seeing its individual pixels. Not <em>impossible</em>, but deeper than most people’s desks. And a corner desk (like mine) has a lot less usable depth due to the angle of the walls, making it completely impossible to fit a 65″ display at all, let-alone while maintaining a practical viewing distance. <a href="#31755725-c69f-4729-b5d0-d0e1d2833f9f-link" aria-label="Jump to footnote reference 4">↩︎</a></li><li id="329e19a1-f614-448f-8975-7365a698f75a">Apple pretty much nailed it with their 5k displays, right from the start; 27″ is a good size for them. At a healthy viewing distance of about 70cm, it’s about 111 PPD (pixels per degree) which is close enough to the limit of even excellent human vision (~130 PPD) to make it genuinely a ‘retina’ display (where you can’t typically distinguish individual pixels) for most people without <em>wasting</em> a lot of pixels. And if you have exceptionally good vision, situating yourself a little farther away is plausible in most setups. <p><a href="https://www.dell.com/en-us/shop/dell-ultrasharp-32-8k-monitor-up3218k/apd/210-alez/monitors-monitor-accessories" data-wpel-link="external" target="_blank" rel="external noopener">Dell’s 8k display</a>, on the other hand, is a mere 32″, yielding a PPD of 143 – <em>way</em> higher than necessary and meaning you can’t <em>actually</em> utilise its full resolution at typical viewing distances – it’d require being within 50cm, which might not sound all that bad but try it; 50cm is <em>really</em> close to any computer display, let-alone a relatively large one at 32″.</p><p>8k displays <em>should</em> be about 44″, to be optimal. <a href="#329e19a1-f614-448f-8975-7365a698f75a-link" aria-label="Jump to footnote reference 5">↩︎</a></p></li><li id="3f8979d6-ea6a-4991-afc8-845186aeb8a5">And lest you think I was just a fussy princess, know that quite a lot of my colleagues did the same. You could look around the office and get a pretty good idea about who really <em>cared</em> about their work (or at least their eyes), by looking at whether they had the company-issued displays or not. <a href="#3f8979d6-ea6a-4991-afc8-845186aeb8a5-link" aria-label="Jump to footnote reference 6">↩︎</a></li><li id="9cf23db5-75b6-40a4-88cd-48d1ad743001">In practice it doesn’t – they differ substantially in temperature, with the LG display being too warm, but I could probably fix that by properly calibrating the LG display… I just haven’t bothered. I <em>used</em> to obsess over monitor calibration, years ago, until I became more aware of just how incredibly situational and subjective human colour perception is anyway (and how well-calibrated Apple’s displays usually are already, out of the box).<p>It’s largely pointless stressing over small errors in colour when you have no control over the viewing context anyway – let-alone the fact that most people view content on tiny little phone displays that are comically not colour-accurate, and can’t see anything anyway. <a href="#9cf23db5-75b6-40a4-88cd-48d1ad743001-link" aria-label="Jump to footnote reference 7">↩︎</a></p></li><li id="08475590-6d49-4fed-ab6b-99455053ae2a">But then, it essentially forgets the windows contents themselves, anyway. It preserves <em>only</em> the first open tab, not any of the others. When I’m in the middle of development and I accidentally close the documentation window – losing a dozen open tabs that were very precisely tied to what I was working at that exact moment – I want to throw my whole god damn computer through a wall.<p>So, Xcode is an infuriating piece of shit even on one display, in that respect. Somehow that’s little consolation. <a href="#08475590-6d49-4fed-ab6b-99455053ae2a-link" aria-label="Jump to footnote reference 8">↩︎</a></p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passkeys: A Shattered Dream (588 pts)]]></title>
            <link>https://fy.blackhats.net.au/blog/2024-04-26-passkeys-a-shattered-dream/</link>
            <guid>40165998</guid>
            <pubDate>Fri, 26 Apr 2024 04:36:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fy.blackhats.net.au/blog/2024-04-26-passkeys-a-shattered-dream/">https://fy.blackhats.net.au/blog/2024-04-26-passkeys-a-shattered-dream/</a>, See on <a href="https://news.ycombinator.com/item?id=40165998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>At around 11pm last night my partner went to change our lounge room lights with our home
light control system. When she tried to login, her account couldn't be accessed. Her Apple
Keychain had deleted the Passkey she was using on that site.</p>
<p>This is just the icing on a long trail of <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification</a>
that has undermined Webauthn. I'm over it at this point, and I think it's time to pour one out
for Passkeys. The irony is not lost on me that I'm about to release a new major version of
<a href="https://crates.io/crates/webauthn-rs">webauthn-rs</a> today as I write this.</p>
<h2 id="the-dream">The Dream</h2>
<p>In 2019 I flew to my mates place in Sydney and spent a week starting to write what is now
<em>the</em> Webauthn library for Rust. In that time I found a number of issues in the standard and
contributed improvements to the Webauthn workgroup, even though it took a few years
for those issues to be resolved. I started to review things and participate more.</p>
<p>At the time there was a lot of optimism that this technology could be the end of passwords. You had
three major use cases:</p>
<ul>
<li>Second Factor</li>
<li>Passwordless</li>
<li>Usernameless</li>
</ul>
<p>Second Factor was a stepping stone toward the latter two. Passwordless is where you would still type
in an account name then authenticate with PIN+Touch to your security key, and usernameless is where
the identity for your account was resident (discoverable) on the key. This was (from my view) seen
as a niche concept by developers since really - how hard is it for a site to have a checkbox that
says "remember me"?</p>
<p>This library ended up with Kanidm being (to my knowledge) the very first OpenSource IDM to implement
passwordless (now passkeys). The experience was wonderful. You went to Kanidm, typed
in your username and then were prompted to type your PIN and touch your key. Simple, fast, easy.</p>
<p>For devices like your iPhone or Android, you would do similar - just use your Touch ID and you're in.</p>
<p>It was so easy, so accessible, I remember how it almost felt impossible. That authentication could
be cryptographic in nature, but so usable and trivial for consumers. There really was the idea and
goal within FIDO and Webauthn that this could be "the end of passwords".</p>
<p>This is what motivated me to continue to improve webauthn-rs. It's reach has gone beyond what I
expected with parts of it being used in Firefox's authenticator-rs, a whole microcosm of Rust Identity Providers (IDPs)
being created from this library and my work, and even <em>other</em> language's Webauthn implementations
and password managers using our library as <em>the</em> reference implementation to test against. I can
not understate how humbled I am of the influence webauthn-rs has had.</p>
<h2 id="the-warnings">The Warnings</h2>
<p>However warnings started to appear that the standard was not as open as people envisaged. The issue
we have is well known - Chrome controls a huge portion of the browser market, and development is
tightly controlled by Google.</p>
<p>An example of this was the <a href="https://www.w3.org/TR/webauthn-1/#sctn-authenticator-selection-extension">Authenticator Selection Extension</a>.</p>
<p>This extension is <em>important</em> for sites that have strict security requirements because they will
attest the make and model of the authenticator in use. If you know that the attestation will only
accept certain devices, then the browser should filter out and only allow those devices to participate.</p>
<p>However Chrome simply never implemented it leading to it being <a href="https://github.com/w3c/webauthn/issues/1386">removed</a>.
And it was removed because Chrome never implemented it. As a result, if Chrome doesn't like something
in the specification they can just veto it without consequence.</p>
<p>Later the <a href="https://github.com/w3c/webauthn/issues/1688#issuecomment-1011516074">justification</a> for
this not being implemented was: "We have never implemented it because we don't feel that authenticator
discrimination is broadly a good thing. ... they [users] <em>should</em> have the expectation that a given
security key will broadly work where they want to use it."</p>
<p><em>I want you to remember this quote and it's implications.</em></p>
<p><em>Users should be able to use any device they choose without penalty.</em></p>
<p>Now I certainly agree with this notion for general sites on the internet, but within a business where
we have policy around what devices may be acceptable the ability to filter devices does matter.</p>
<p>This makes it very possible that you can go to a corporate site, enroll a security key and it appears to work
but then it will fail to register (even better if this burns one of your resident key slots that can
not be deleted without a full reset of your device) since the
IDP rejected the device attestation. That's right, even without this, IDP's can still "discriminate"
against devices without this extension, but the user experience is much worse, and the consequences far
more severe in some cases.</p>
<p>The kicker is that Chrome has internal feature flags that they can use for Google's needs. They
can simply enable their own magic features that control authenticator models for their policy, while
everyone else has to have a lesser experience.</p>
<p>The greater warning here is that many of these decisions are made at "F2F" or Face to Face meetings
held in the US. This excludes the majority of international participants leading some voices to be
stronger than others. It's hard to convince someone when you aren't in the room, even more so
when the room is in a country that has a list of <a href="https://www.smartraveller.gov.au/destinations/americas/united-states-america">travel advisories</a>
including "Violent crime is more common in the US than in Australia", "There is a persistent threat
of mass casualty violence and terrorist attacks in the US" and "Medical costs in the US are extremely
high. You may need to pay up-front for medical assistance". (As an aside, there are countries that
have a "do not travel" warning for less, but somehow the US gets a pass ...).</p>
<h2 id="the-descent">The Descent</h2>
<p>In 2022 Apple annouced <a href="https://appleinsider.com/articles/22/06/07/apple-passkey-feature-will-be-our-first-taste-of-a-truly-password-less-future">Passkeys</a>.</p>
<p>At the time this was just a really nice "marketing" term for passwordless, and Apple's Passkeys had
the ability to oppurtunistically be usernameless. It was all in all very polished and well done.</p>
<p>But of course, thought leaders exist, and Apple hadn't defined what a Passkey was. One of those
thought leaders took to the FIDO conference stage and announced "Passkeys are resident keys", at
the same time as the unleashed a passkeys dev website (I won't link to it out of principal).</p>
<p>The issue is described in detail in another of <a href="https://fy.blackhats.net.au/blog/2023-02-02-how-hype-will-turn-your-security-key-into-junk/">my blog posts</a>
but to summarise, this push to resident keys means that security keys are excluded because they often
have extremely low limits on storage, the highest being 25 for yubikeys. That simply won't cut it for
most people where they have more than 25 accounts.</p>
<p>Now with resident keys as passkeys as users we certainly don't have the expectation that our
security keys will work when we want to use them!</p>
<h2 id="the-enshittocene-period">The Enshittocene Period</h2>
<p>Since then Passkeys are now seen as a way to capture users and audiences into a platform. What better
way to encourage long term entrapment of users then by locking all their credentials into your platform,
and even better, credentials that can't be extracted or exported in any capacity.</p>
<p>Both Chrome and Safari will try to force you into using either hybrid (caBLE) where you scan a QR code
with your phone to authenticate - you have to click through menus to use a security key. caBLE is
not even a good experience, taking more than 60 seconds work in most cases. The UI is beyond
obnoxious at this point. Sometimes I think <a href="https://neal.fun/password-game/">the password game has a better ux</a>.</p>
<p>The more egregious offender is Android, which <a href="https://github.com/kanidm/webauthn-rs/issues/365#issuecomment-1756605203">won't even activate your security key</a>
if the website sends the set of options that are needed for Passkeys. This means the IDP gets to
choose what device you enroll without your input. And of course, all the developer examples only
show you the options to activate "Google Passkeys stored in Google Password Manager". After all,
why would you want to use anything else?</p>
<p>A sobering pair of reads are the <a href="https://github.com/orgs/community/discussions/54450">Github Passkey Beta</a>
and <a href="https://github.com/orgs/community/discussions/67791">Github Passkey</a> threads. There are instances of
users whose security keys are not able to be enrolled as the resident key slots are filled. Multiple
users describe that Android can not create Passkeys due to platform bugs. Some devices need firmware
resets to create Passkeys. Keys can be saved on the client but not the server leading to duplicate
account presence and credentials that don't work, or worse lead users to delete the
<a href="https://bugs.webkit.org/show_bug.cgi?id=270553">real credentials</a>.</p>
<p>The helplessness of users on these threads is obvious - and these are technical early adopters. The
users we need to be advocates for changing from passwords to passkeys. If these users can't make it
work how will people from other disciplines fare?</p>
<p>Externally there are other issues. Apple Keychain has personally wiped out all my Passkeys on
<em>three separate occasions</em>. There are external reports we have recieved of other users who's
Keychain Passkeys have been wiped just like mine.</p>
<p>Now as users we have the expectation that keys won't be created or they will have disappeared
when we need them most.</p>
<p>In order to try to resolve this the workgroup seems to be doubling down on more complex JS apis to
try to patch over the issues that they created in the first place. All this extra complexity comes
with fragility and more bad experiences, but without resolving the core problems.</p>
<p>It's a mess.</p>
<h2 id="the-future">The Future</h2>
<p>At this point I think that Passkeys will fail in the hands of the general consumer population. We
missed our golden chance to eliminate passwords through a desire to capture markets and promote hype.</p>
<p>Corporate interests have overruled good user experience once again. Just like ad-blockers, I predict
that Passkeys will only be used by a small subset of the technical population, and consumers will
generally reject them.</p>
<p>To reiterate - my partner, who is extremely intelligent, an avid computer gamer and <em>veterinary surgeon</em>
has sworn off Passkeys because the user experience is so shit. She wants to go back to passwords.</p>
<p>And I'm starting to agree - a password manager gives a better experience than passkeys.</p>
<p>That's right. I'm here saying <em>passwords are a better experience than passkeys</em>. Do you know how much
it pains me to write this sentence? (and yes, that means MFA with TOTP is still important for
passwords that require memorisation outside of a password manager).</p>
<p>So do yourself a favour. Get something like <a href="https://bitwarden.com/">bitwarden</a> or if you like
self hosting get <a href="https://github.com/dani-garcia/vaultwarden">vaultwarden</a>. Let it generate your
passwords and manage them. If you really want passkeys, put them in a password manager you control.
But don't use a platform controlled passkey store, and be very careful with security keys.</p>
<p>And if you do want to use a security key, just use it to unlock your password manager and your email.</p>
<p>Within enterprise there still is a place for attested security keys where you can
control the whole experience to avoid the vendor lockin parts. It still has
rough edges though. Just today I found a browser that has broken attestation which is not good. You still
have to dive through obnoxious UX elements that attempt to force you through caBLE even though
your IDP will only accept certain security models, so you're still likely to have some confused
users.</p>
<p>But at this point, in Kanidm we are looking into device certificates and smartcards instead. The UI
is genuinely better. Which says a lot considering the PKCS11 and PIV specifications. But at least
PIV won't fall prone to attempts to enshittify it.</p>

    </div></div>]]></description>
        </item>
    </channel>
</rss>