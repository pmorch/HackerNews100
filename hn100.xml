<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 25 Oct 2024 02:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Bitwarden SDK relicensed from proprietary to GPLv3 (142 pts)]]></title>
            <link>https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</link>
            <guid>41940580</guid>
            <pubDate>Thu, 24 Oct 2024 22:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b">https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</a>, See on <a href="https://news.ycombinator.com/item?id=41940580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
      <tr data-position="0">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HL1" data-line-number="..."></td>
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HR1" data-line-number="..."></td>
    <td>@@ -1,6 +1,6 @@</td>
  </tr>

    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L1" data-line-number="1"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R1" data-line-number="1"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L2" data-line-number="2"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R2" data-line-number="2"></td>

  <td>
    <span data-code-marker=" "><span>resolver</span> = <span><span>"</span>2<span>"</span></span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L3" data-line-number="3"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R3" data-line-number="3"></td>

  <td>
    <span data-code-marker="+"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span><span>, </span><span><span>"</span><span>bitwarden_license/*</span><span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L4" data-line-number="4"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R4" data-line-number="4"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L5" data-line-number="5"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R5" data-line-number="5"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> Global settings for all crates should be defined here</span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L6" data-line-number="6"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R6" data-line-number="6"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>.<span>package</span>]</span></td>
</tr>




      <tr data-position="8">
    <td colspan="2">
        <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand All" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;in_wiki_context=&amp;last_left=6&amp;last_right=6&amp;left=27&amp;left_hunk_size=7&amp;mode=100644&amp;path=Cargo.toml&amp;right=27&amp;right_hunk_size=7" data-left-range="7-15" data-right-range="7-15">
          
        </a>
        <tool-tip id="tooltip-eb6421d3-fc5b-410b-915a-7bc615cd006b" for="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -27,7 +27,7 @@ bitwarden-exporters = { path = "crates/bitwarden-exporters", version = "=1.0.0"</td>
  </tr>

    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L27" data-line-number="27"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R27" data-line-number="27"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-fido</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-fido<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L28" data-line-number="28"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R28" data-line-number="28"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-generators</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-generators<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L29" data-line-number="29"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R29" data-line-number="29"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-send</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-send<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L30" data-line-number="30"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>crates</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R30" data-line-number="30"></td>

  <td>
    <span data-code-marker="+"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>bitwarden_license</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L31" data-line-number="31"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R31" data-line-number="31"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-vault</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-vault<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L32" data-line-number="32"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R32" data-line-number="32"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L33" data-line-number="33"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R33" data-line-number="33"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> External crates that are expected to maintain a consistent version across all crates</span></span></td>
</tr>




  <tr data-position="">
    <td colspan="2">
          <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand Down" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=33&amp;last_right=33&amp;left=90&amp;left_hunk_size=&amp;mode=100644&amp;path=Cargo.toml&amp;right=90&amp;right_hunk_size=" data-left-range="34-89" data-right-range="34-89">
            
          </a>
          <tool-tip id="tooltip-2604fbf7-a6c0-4f9d-8ac6-fbd948d0e347" for="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
    </td>
    <td></td>
  </tr>


                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing 787s must be reset every 51 days or 'misleading data' is shown to pilots (102 pts)]]></title>
            <link>https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/</link>
            <guid>41939318</guid>
            <pubDate>Thu, 24 Oct 2024 20:19:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/">https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/</a>, See on <a href="https://news.ycombinator.com/item?id=41939318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The US Federal Aviation Administration has ordered Boeing 787 operators to switch their aircraft off and on every 51 days to prevent what it called "several potentially catastrophic failure scenarios" – including the crashing of onboard network switches.</p>
<p>The <a target="_blank" href="https://ad.easa.europa.eu/ad/US-2020-06-14">airworthiness directive</a>, due to be enforced from later this month, orders airlines to power-cycle their B787s before the aircraft reaches the specified days of continuous power-on operation.</p>
<p>The power cycling is needed to prevent stale data from populating the aircraft's systems, a problem that has occurred on different 787 systems in the past.</p>

    

<p>According to the directive itself, if the aircraft is powered on for more than 51 days this can lead to "display of misleading data" to the pilots, with that data including airspeed, attitude, altitude and engine operating indications. On top of all that, the stall warning horn and overspeed horn also stop working.</p>

        


        

<p>This alarming-sounding situation comes about because, for reasons the directive did not go into, the 787's common core system (CCS) stops filtering out stale data from key flight control displays. That stale data-monitoring function going down in turn "could lead to undetected or unannunciated loss of common data network (CDN) message age validation, combined with a CDN switch failure".</p>
<div>
<h2 title="Have you turned it off and on again? That's the way to stop the plane becoming a brick">Boeing 787 software bug can shut down planes' generators IN FLIGHT</h2>
<p><a href="https://www.theregister.com/2015/05/01/787_software_bug_can_shut_down_planes_generators/"><span>READ MORE</span></a></p></div>
<p>Solving the problem is simple: power the aircraft down completely before reaching 51 days. It is usual for commercial airliners to spend weeks or more continuously powered on as crews change at airports, or ground power is plugged in overnight while cleaners and maintainers do their thing.</p>
<p>The CDN is a Boeing avionics term for the 787's internal Ethernet-based network. It is built to a slightly more stringent aviation-specific standard than common-or-garden Ethernet, that standard being called ARINC 664. More about ARINC 664 can be read <a target="_blank" rel="nofollow" href="https://www.aim-online.com/products-overview/tutorials/afdx-arinc664p7-tutorial/">here</a>.</p>
<p>Airline pilots were sanguine about the implications of the failures when <i>El Reg</i> asked a handful about the directive. One told us: "Loss of airspeed data combined with engine instrument malfunctions isn't unheard of," adding that there wasn't really enough information in the doc to decide whether or not the described failure would be truly catastrophic. Besides, he said, the backup speed and attitude instruments are – for obvious reasons – completely separate from the main displays.</p>

        

<p>Another mused that loss of engine indications would make it harder to adopt the fallback drill of setting a known pitch and engine power <i>(see sidenote)</i> setting that guarantees safe straight-and-level flight while the pilots consult checklists and manuals to find a fix.</p>

<p>A third commented, tongue firmly in cheek: "Anything like that with the aircraft is unhealthy!"</p>
<p>A previous software bug forced airlines to <a target="_blank" href="https://www.theregister.com/2015/05/01/787_software_bug_can_shut_down_planes_generators/">power down</a> their 787s every 248 days for fear electrical generators could shut down in flight.</p>
<p>Airbus suffers from similar issues with its A350, with a relatively recent but since-patched bug <a target="_blank" href="https://www.theregister.com/2019/07/25/a350_power_cycle_software_bug_149_hours/">forcing power cycles every 149 hours</a>.</p>
<p>Persistent or unfiltered stale data is a known 787 problem. In 2014 a Japan Airlines 787 caught fire because of the (entirely separate, and since fixed) <a target="_blank" href="https://www.theregister.com/2013/01/17/faa_grounds_boeing_787_batteries/">lithium-ion battery problem</a>. Investigators realised the black boxes <a target="_blank" rel="nofollow" href="https://www.flightglobal.com/ntsb-details-issues-with-787-flight-and-data-recorder/115282.article">had been recording false information</a>, hampering their task, because they were falsely accepting stale old data as up-to-the-second real inputs.</p>

        

<p>More seriously, another 787 stale data problem in years gone by saw superseded backup flight plans persisting in standby navigation computers, and activating occasionally.</p>
<p>Activation caused the autopilot to wrongly decide it was halfway through flying a previous journey – and manoeuvre to regain the "correct" flight path. Another symptom was for the flight management system to simply go blank and freeze, triggered by selection of a standard arrival path (STAR) with exactly 14 waypoints – such as the BIMPA 4U approach to Poland's rather busy Warsaw Airport. The Polish air safety regulator <a target="_blank" href="https://regmedia.co.uk/2020/04/02/akt.pdf">published this mildly alarming finding in 2016</a> [2-page PDF, in Polish].</p>
<p>This was fixed through a software update, <a target="_blank" rel="nofollow" href="https://www.federalregister.gov/documents/2019/02/15/2019-02160/airworthiness-directives-the-boeing-company-airplanes">as the US Federal Aviation Administration reiterated last year</a>. In addition, Warsaw's BIMPA 4U approach has since been superseded.</p>
<p><i>The Register</i> asked Boeing to comment. ®</p>
<p>
  <i><b>Editor's note:</b> An earlier version of this article mentioned the Boeing 787 CCS uses a Wind River VxWorks real-time OS product at its heart. While this is true, Wind River has been in touch to remind us "the CCS is made up of 80 to 100 applications," as well as VxWorks, and said the bug described in this article is not the fault of its operating system.</i>
</p>
<p>
  <i>"The functions of VxWorks have nothing to do with the data issue you are highlighting in the 787," a spokesperson added. We are happy to clarify our coverage.</i>
</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Israel launched a dozen attacks on UN troops in Lebanon, says leaked report (126 pts)]]></title>
            <link>https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e</link>
            <guid>41938822</guid>
            <pubDate>Thu, 24 Oct 2024 19:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e">https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e</a>, See on <a href="https://news.ycombinator.com/item?id=41938822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offer-596bb8f3-5b5a-405d-8131-9d2f83fa19ba" data-component="heroOffer" data-component-unique-name="Hero offer"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Limited time offer</span></h2><h2><strong><span>Save 50% on Standard Digital</span></strong></h2></p><p><span>was </span><span>CHF660</span><span> </span><span>now </span><span>CHF329</span><span> for your first year, equivalent to </span><span>CHF27.42</span><span> per month.
Make up your own mind. Build robust opinions with the FT’s trusted journalism.
Take this offer before 24 October.</span></p></div></div><div id="recommendedOffers-Recommended offers-970a735c-9068-41df-9018-9dfe0b917fe9" data-component="recommendedOffers" data-component-unique-name="Recommended offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_trial.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF1</span><span> for 4 weeks</span></p><p><span>Then </span><span>CHF85</span><span> per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_weekend_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF85</span><span> per month</span></p><p><span>Get Premium &amp; FT Weekend Print edition for the price of Premium. Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_print.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF345</span><span> for your first year</span></p><p><span>FT newspaper delivered Monday-Saturday, plus FT Digital Edition delivered to your device Monday-Saturday.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=151eb482-6415-48a8-bf3f-baed00018c4e">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quantized Llama models with increased speed and a reduced memory footprint (270 pts)]]></title>
            <link>https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1</link>
            <guid>41938473</guid>
            <pubDate>Thu, 24 Oct 2024 18:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1">https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1</a>, See on <a href="https://news.ycombinator.com/item?id=41938473">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>At <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" data-lnfb-mode="ie"><u>Connect 2024</u></a> last month, we open sourced Llama 3.2 1B and 3B—our smallest models yet—to address the demand for on-device and edge deployments. Since their release, we’ve seen not just how the community has adopted our lightweight models, but also how grassroots developers are quantizing them to save capacity and memory footprint, often at a tradeoff to performance and accuracy.</p><p>As we’ve <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" data-lnfb-mode="ie"><u>shared before</u></a>, we want to make it easier for more developers to build with Llama, without needing significant compute resources and expertise. Today, we’re sharing quantized versions of Llama 3.2 1B and 3B models. These models offer a reduced memory footprint, faster on-device inference, accuracy, and portability—all while maintaining quality and safety for developers to deploy on resource-constrained devices. Given the limited runtime memory available on mobile devices, we prioritized short-context applications up to 8K for these new quantized models. Our results show we can achieve superior accuracy by training with quantization as opposed to post-processing. The models we are sharing today have 2-4x speedup and an average reduction of 56% in model size compared to the original format, based on testing with Android OnePlus 12 models. We also reduce memory usage by an average of 41%. Starting today, the community can deploy our <a href="https://www.llama.com/" target="_blank" data-lnfb-mode="ie"><u>quantized models</u></a> onto more mobile CPUs, giving them the opportunity to build unique experiences that are fast and provide more privacy since interactions stay entirely on device.</p><p>We developed these state-of-the-art models using Quantization-Aware Training with LoRA adaptors (QLoRA) to optimize performance in low-precision environments. We also used SpinQuant, a technique that enables us to determine the best possible combination for compression while retaining the most possible quality. As a result of the close collaborative work with our industry-leading partners, QLoRA and SpinQuant Llama models are available on Qualcomm and MediaTek SoCs with Arm CPUs. The performance of the quantized models has been optimized for mobile CPUs using Kleidi AI kernels, and we’re currently collaborating with our partners to utilize NPUs for even greater performance for Llama 1B/3B.</p><br></div><p>Our quantization setup</p><div><p>We designed the current quantization scheme with <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>PyTorch’s ExecuTorch inference framework</u></a> and <a href="https://www.arm.com/products/development-tools/embedded-and-software/kleidi-libraries" target="_blank" data-lnfb-mode="ie"><u>Arm CPU backend</u></a> in mind, taking into account metrics including model quality, prefill/decoding speed, and memory footprint. Our quantization scheme involves three parts:</p><ul><li>We quantize all linear layers in all transformer blocks to a 4-bit groupwise scheme (with a group size of 32) for weights and 8-bit per-token dynamic quantization for activations.</li><li>The classification layer is quantized to 8-bit per-channel for weight and 8-bit per-token dynamic quantization for activation.</li><li>We employ an 8-bit per-channel quantization for embedding.</li></ul><br></div><p>Quantization-Aware Training and LoRA</p><div><p>We employ Quantization-Aware Training (QAT) to simulate the effects of quantization during the training of Llama 3.2 models, enabling us to optimize their performance in low-precision environments. To initialize QAT, we utilize BF16 Llama 3.2 model checkpoints obtained after supervised fine-tuning (SFT) and perform an additional full round of SFT training with QAT. We then freeze the backbone of the QAT model and perform another round of SFT with low-rank adaptation (LoRA) adaptors applied to all layers within the transformer block. Meanwhile, the LoRA adaptors' weights and activations are maintained in BF16. Because our approach is similar to QLoRA in principle (i.e., quantization followed by LoRA adapters), we refer to it as QLoRA in this post.</p><p>Finally, we fine-tune the resulting model (both backbone and LoRA adaptors) using direct preference optimization (DPO). The resulting model is a highly efficient model that achieves competitive accuracy to the BF16 model, while maintaining a comparable speed and memory footprint to other quantization methods (see below figure).</p><p>We used <a href="https://github.com/pytorch/ao" target="_blank" data-lnfb-mode="ie"><u>torchao APIs</u></a> to do QAT. Developers can further use QAT as a foundational model and use LoRA to fine-tune Llama for their bespoke use cases, saving time and computational cost.</p><br></div><p>SpinQuant</p><div><p>Although QAT gives the best results, some people might want to quantize their fine-tuned 1B and 3B models or quantize the models for different targets with different quantization settings. For this reason we are also releasing the models and method of <a href="https://arxiv.org/abs/2405.16406" target="_blank" data-lnfb-mode="ie"><u>SpinQuant</u></a>, which is a state-of-the-art technique for post-training quantization.</p><p>While the method is less accurate than QAT + LoRA, a key advantage of SpinQuant is its portability and ability to operate without requiring access to training datasets, which are often private. It’s an attractive solution for applications where data availability or computational resources are limited. Developers can use this method to take their own fine-tuned Llama models and quantize them for different hardware targets and use cases, using the <a href="https://github.com/facebookresearch/SpinQuant" target="_blank" data-lnfb-mode="ie"><u>open source repository</u></a> that is fully compatible with <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>ExecuTorch</u></a> and <a href="https://github.com/meta-llama/llama-stack" target="_blank" data-lnfb-mode="ie"><u>Llama Stack</u></a>.</p><p>In our experiments, we utilize WikiText, a small calibration dataset, to learn rotation matrices in SpinQuant. These matrices enable the smoothing of outliers and facilitate more effective quantization. After this, best practices in quantization such as range setting and generative post-training quantization are applied. The SpinQuant matrices are optimized for the quantization scheme similar to QAT + LoRA.</p><br></div><p>Results</p><p>In the table below, we show comprehensive evaluation of the models quantized with vanilla post-training quantization (PTQ), SpinQuant, which produces the state-of-the-art PTQ quality, as well as QLoRA, which gives the best quality of all.</p></div><div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/463869105_1326616764996070_7210673116645317812_n.png?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=wGOZrBGxyFsQ7kNvgHPND3p&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYB0luXoDpLjhHrmyFz6JtwB63gvIs5W_4f4tnmrMGj8lQ&amp;oe=6734F2EF" alt="" id="u_0_5_PC"></p><div><p>Percentage difference in relation to the average value for BF16.</p></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/463977359_1182562752841690_4137380685967841470_n.png?_nc_cat=102&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=vbjUvQqeTkoQ7kNvgGG8krR&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYBa9DdglkoYt4jKS97avd525-WhGpbd_5ug56KNpbGYwg&amp;oe=6734E7D4" alt="" id="u_0_6_J8"></p><div><p>Percentage difference in relation to the average value for BF16.</p></div><div><p>In the table below, we compare the performance metrics of different quantization methods (SpinQuant and QAT + LoRA) with the BF16 baseline. The evaluation was done using the <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>ExecuTorch</u></a> framework as the inference engine, with the ARM CPU as a backend. The quantized models were optimized primarily for Arm CPU architecture by leveraging Kleidi AI library.</p></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/464307751_477718101949854_4588809159017166700_n.png?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=viOQ-r8IQlgQ7kNvgHuFj8m&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYAbPnZBRvVF30mRWeG6YtpHYuvW9R_HwPUsTfE7Rsasyw&amp;oe=67351977" alt="" id="u_0_7_FE"></p><div><p>The performance measurement is done using an adb binary-based approach and is measured on an Android OnePlus 12 device. Time-to-first-token (TTFT) is measured with prompt length=64.</p></div></div><div><div><p>Decode latency improved by 2.5x and prefill latency improved by 4.2x on average, while model size decreased by 56% and memory usage reduced by 41% on average. The benchmarks can be reproducible today via ExecuTorch <a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md" target="_blank" data-lnfb-mode="ie"><u>Llama instructions</u></a>. The table above shows results using an Android OnePlus 12 device—however, we’ve also verified similar relative performance on Samsung S24+ for 1B and 3B and Samsung S22 for 1B. For iOS devices, we’ve verified these models run with comparable accuracy but haven’t evaluated performance.</p><p>Besides CPU, we’re currently collaborating with partners to utilize NPUs for these quantized models for even greater performance. Our partners have already integrated foundational components in the ExecuTorch open source ecosystem to leverage NPUs, and work is underway to specifically enable quantization on NPU for Llama 1B/3B.</p><br></div><p>Looking to the future</p><div><p>We’ve been inspired and encouraged by the excitement and progress the community has achieved with Llama in just a short span of time. This year, <a href="https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/" target="_blank" data-lnfb-mode="ie"><u>Llama has achieved 10x growth</u></a> and become the standard for responsible innovation. Llama also continues to lead on openness, modifiability, and cost efficiency and is competitive with closed models—even leading in some areas. As always, we can’t wait to see what the community builds using Llama and the powerful experiences they’ll enable on mobile devices.</p><p><i>We’re making Llama 3.2 models available for download on </i><a href="https://llama.com/" target="_blank" data-lnfb-mode="ie"><i><u>llama.com</u></i></a> and <a href="https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf" target="_blank" data-lnfb-mode="ie"><i><u>Hugging Face</u></i></a>.</p><p><i>We’d like to acknowledge the close collaboration of our partners: Arm, Hugging Face, MediaTek, Ollama, and Qualcomm.</i></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zigler: Zig NIFs in Elixir (147 pts)]]></title>
            <link>https://github.com/E-xyza/zigler</link>
            <guid>41937815</guid>
            <pubDate>Thu, 24 Oct 2024 17:53:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/E-xyza/zigler">https://github.com/E-xyza/zigler</a>, See on <a href="https://news.ycombinator.com/item?id=41937815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Zigler</h2><a id="user-content-zigler" aria-label="Permalink: Zigler" href="#zigler"></a></p>
<p dir="auto">Library test status:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Installation: Elixir</h2><a id="user-content-installation-elixir" aria-label="Permalink: Installation: Elixir" href="#installation-elixir"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Obtaining Zig dependency</h3><a id="user-content-obtaining-zig-dependency" aria-label="Permalink: Obtaining Zig dependency" href="#obtaining-zig-dependency"></a></p>
<p dir="auto">Run <code>mix zig.get</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main Installation</h3><a id="user-content-main-installation" aria-label="Permalink: Main Installation" href="#main-installation"></a></p>
<p dir="auto">Zigler is <a href="https://hex.pm/packages/zigler" rel="nofollow">available in Hex</a>, and the package can be installed
by adding <code>zigler</code> to your list of dependencies in <code>mix.exs</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def deps do
  [
    {:zigler, &quot;~> 0.13.2&quot;, runtime: false}
  ]
end"><pre><span>def</span> <span>deps</span> <span>do</span>
  <span>[</span>
    <span>{</span><span>:zigler</span><span>,</span> <span>"~&gt; 0.13.2"</span><span>,</span> <span>runtime: </span><span>false</span><span>}</span>
  <span>]</span>
<span>end</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation: Erlang</h2><a id="user-content-installation-erlang" aria-label="Permalink: Installation: Erlang" href="#installation-erlang"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Zig dependency</h3><a id="user-content-zig-dependency" aria-label="Permalink: Zig dependency" href="#zig-dependency"></a></p>
<p dir="auto">TBD.</p>
<p dir="auto"><code>~/.cache/zigler/zig-linux-&lt;arch&gt;-0.13.0</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main Installation</h3><a id="user-content-main-installation-1" aria-label="Permalink: Main Installation" href="#main-installation-1"></a></p>
<p dir="auto">Erlang is only supported via rebar3.  You must enable the rebar_mix plugin and
add zigler to your deps in rebar3.</p>
<p dir="auto">Note that erlang support is highly experimental.  Please submit issues if you
have difficulty.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{plugins, [rebar_mix]}.

{deps, [{zigler, &quot;0.13&quot;}]}.
"><pre>{<span>plugins</span>, [<span>rebar_mix</span>]}.

{<span>deps</span>, [{<span>zigler</span>, <span><span>"</span>0.13<span>"</span></span>}]}.
</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Docs can be found at <a href="https://hexdocs.pm/zigler" rel="nofollow">https://hexdocs.pm/zigler</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Currently supported platforms</h2><a id="user-content-currently-supported-platforms" aria-label="Permalink: Currently supported platforms" href="#currently-supported-platforms"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Linux</p>
</li>
<li>
<p dir="auto">FreeBSD (tested, but not subjected to CI)</p>
</li>
<li>
<p dir="auto">MacOS</p>
</li>
<li>
<p dir="auto">Nerves cross-compilation is supported out of the box.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zig Nifs made easy</h2><a id="user-content-zig-nifs-made-easy" aria-label="Permalink: Zig Nifs made easy" href="#zig-nifs-made-easy"></a></p>
<p dir="auto">Wouldn't it be nice if you could make NIFs as easily as you can use the <code>asm</code>
keyword in C?</p>
<p dir="auto">This is now possible, using the magic of Zig.</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule ExampleZig do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  pub fn example_fun(value1: f64, value2: f64) bool {
    return value1 > value2;
  }
  &quot;&quot;&quot;
end

test &quot;example nifs&quot; do
  assert ExampleZig.example_fun(0.8, -0.8)
  refute ExampleZig.example_fun(0.1, 0.4)
end"><pre><span>defmodule</span> <span>ExampleZig</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  pub fn example_fun(value1: f64, value2: f64) bool {</span>
<span>    return value1 &gt; value2;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"example nifs"</span> <span>do</span>
  <span>assert</span> <span>ExampleZig</span><span>.</span><span>example_fun</span><span>(</span><span>0.8</span><span>,</span> <span>-</span><span>0.8</span><span>)</span>
  <span>refute</span> <span>ExampleZig</span><span>.</span><span>example_fun</span><span>(</span><span>0.1</span><span>,</span> <span>0.4</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">Zigler will do automatic type marshalling between Elixir code and Zig code.
It will also convert trickier types into types you care about, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule ZigCollections do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  pub fn string_count(string: []u8) i64 {
    return @intCast(string.len);
  }

  pub fn list_sum(array: []f64) f64 {
    var sum: f64 = 0.0;
    for(array) | item | {
      sum += item;
    }
    return sum;
  }
  &quot;&quot;&quot;
end

test &quot;type marshalling&quot; do
  assert 9 == ZigCollections.string_count(&quot;hello zig&quot;)
  assert 6.0 == ZigCollections.list_sum([1.0, 2.0, 3.0])
end"><pre><span>defmodule</span> <span>ZigCollections</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  pub fn string_count(string: []u8) i64 {</span>
<span>    return @intCast(string.len);</span>
<span>  }</span>
<span></span>
<span>  pub fn list_sum(array: []f64) f64 {</span>
<span>    var sum: f64 = 0.0;</span>
<span>    for(array) | item | {</span>
<span>      sum += item;</span>
<span>    }</span>
<span>    return sum;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"type marshalling"</span> <span>do</span>
  <span>assert</span> <span>9</span> <span>==</span> <span>ZigCollections</span><span>.</span><span>string_count</span><span>(</span><span>"hello zig"</span><span>)</span>
  <span>assert</span> <span>6.0</span> <span>==</span> <span>ZigCollections</span><span>.</span><span>list_sum</span><span>(</span><span>[</span><span>1.0</span><span>,</span> <span>2.0</span><span>,</span> <span>3.0</span><span>]</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">Memory allocation with zigler is easy!  A standard BEAM allocator is provided for you,
so any zig code you import will play nice with the BEAM.</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule Allocations do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  const beam = @import(&quot;beam&quot;);

  pub fn double_atom(string: []u8) !beam.term {
    var double_string = try beam.allocator.alloc(u8, string.len * 2);
    defer beam.allocator.free(double_string);

    for (string, 0..) | char, i | {
      double_string[i] = char;
      double_string[i + string.len] = char;
    }

    return beam.make_into_atom(double_string, .{});
  }
  &quot;&quot;&quot;
end

test &quot;allocations&quot; do
  assert :foofoo == Allocations.double_atom(&quot;foo&quot;)
end"><pre><span>defmodule</span> <span>Allocations</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  const beam = @import("beam");</span>
<span></span>
<span>  pub fn double_atom(string: []u8) !beam.term {</span>
<span>    var double_string = try beam.allocator.alloc(u8, string.len * 2);</span>
<span>    defer beam.allocator.free(double_string);</span>
<span></span>
<span>    for (string, 0..) | char, i | {</span>
<span>      double_string[i] = char;</span>
<span>      double_string[i + string.len] = char;</span>
<span>    }</span>
<span></span>
<span>    return beam.make_into_atom(double_string, .{});</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"allocations"</span> <span>do</span>
  <span>assert</span> <span>:foofoo</span> <span>==</span> <span>Allocations</span><span>.</span><span>double_atom</span><span>(</span><span>"foo"</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">It is a goal for Zigler to make using <em>it</em> to bind C libraries easier
than using C to bind C libraries.  Here is an example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if {:unix, :linux} == :os.type() do
  defmodule Blas do
    use Zig,     
      otp_app: :zigler,
      c: [link_lib: {:system, &quot;blas&quot;}]
  
    ~Z&quot;&quot;&quot;
    const beam = @import(&quot;beam&quot;);
    const blas = @cImport({
        @cInclude(&quot;cblas.h&quot;);
    });

    const BadArgs = error { badarg };
  
    pub fn blas_axpy(a: f64, x: []f64, y: []f64) ![]f64 {
        if (x.len != y.len) return error.badarg;
    
        blas.cblas_daxpy(@intCast(x.len), a, x.ptr, 1, y.ptr, 1);
    
        return y;
    }
    &quot;&quot;&quot;
  end
  
  test &quot;we can use a blas shared library&quot; do
    # returns aX+Y
    assert [11.0, 18.0] == Blas.blas_axpy(3.0, [2.0, 4.0], [5.0, 6.0])
  end
end"><pre><span>if</span> <span>{</span><span>:unix</span><span>,</span> <span>:linux</span><span>}</span> <span>==</span> <span>:os</span><span>.</span><span>type</span><span>(</span><span>)</span> <span>do</span>
  <span>defmodule</span> <span>Blas</span> <span>do</span>
    <span>use</span> <span>Zig</span><span>,</span>     
      <span>otp_app: </span><span>:zigler</span><span>,</span>
      <span>c: </span><span>[</span><span>link_lib: </span><span>{</span><span>:system</span><span>,</span> <span>"blas"</span><span>}</span><span>]</span>
  
    <span>~Z<span>"""</span></span>
<span>    const beam = @import("beam");</span>
<span>    const blas = @cImport({</span>
<span>        @cInclude("cblas.h");</span>
<span>    });</span>
<span></span>
<span>    const BadArgs = error { badarg };</span>
<span>  </span>
<span>    pub fn blas_axpy(a: f64, x: []f64, y: []f64) ![]f64 {</span>
<span>        if (x.len != y.len) return error.badarg;</span>
<span>    </span>
<span>        blas.cblas_daxpy(@intCast(x.len), a, x.ptr, 1, y.ptr, 1);</span>
<span>    </span>
<span>        return y;</span>
<span>    }</span>
<span>    <span>"""</span></span>
  <span>end</span>
  
  <span>test</span> <span>"we can use a blas shared library"</span> <span>do</span>
    <span># returns aX+Y</span>
    <span>assert</span> <span>[</span><span>11.0</span><span>,</span> <span>18.0</span><span>]</span> <span>==</span> <span>Blas</span><span>.</span><span>blas_axpy</span><span>(</span><span>3.0</span><span>,</span> <span>[</span><span>2.0</span><span>,</span> <span>4.0</span><span>]</span><span>,</span> <span>[</span><span>5.0</span><span>,</span> <span>6.0</span><span>]</span><span>)</span>
  <span>end</span>
<span>end</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Documentation (Elixir-only)</h3><a id="user-content-documentation-elixir-only" aria-label="Permalink: Documentation (Elixir-only)" href="#documentation-elixir-only"></a></p>
<p dir="auto">You can document nif functions, local functions, zig structs, variables, and types.
If you document a nif function, it will be a part of the module documentation, and
accessible using the iex <code>h</code> method, etc.</p>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule Documentation do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  /// a zero-arity function which returns 47.
  pub fn zero_arity() i64 {
    return 47;
  }
  &quot;&quot;&quot;
end"><pre><span>defmodule</span> <span>Documentation</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  /// a zero-arity function which returns 47.</span>
<span>  pub fn zero_arity() i64 {</span>
<span>    return 47;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Formatting (Elixir-only)</h3><a id="user-content-formatting-elixir-only" aria-label="Permalink: Formatting (Elixir-only)" href="#formatting-elixir-only"></a></p>
<p dir="auto">Zigler ships with a formatter.  To activate the formatter, adapt the following to your
<code>.formatter.exs</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[
  inputs: ~w[
    {mix,.formatter,.credo}.exs
    {config,lib,rel,test}/**/*.{ex,exs,zig}
    installer/**/*.{ex,exs}
  ],
  plugins: [Zig.Formatter]
]"><pre><span>[</span>
  <span>inputs: </span><span>~w<span>[</span></span>
<span>    {mix,.formatter,.credo}.exs</span>
<span>    {config,lib,rel,test}/**/*.{ex,exs,zig}</span>
<span>    installer/**/*.{ex,exs}</span>
<span>  <span>]</span></span><span>,</span>
  <span>plugins: </span><span>[</span><span>Zig.Formatter</span><span>]</span>
<span>]</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Erlang support (highly experimental)</h2><a id="user-content-erlang-support-highly-experimental" aria-label="Permalink: Erlang support (highly experimental)" href="#erlang-support-highly-experimental"></a></p>
<p dir="auto">Use of Zigler with erlang is possible using parse transforms.  You must obtain
zigler using the <code>rebar3</code> and the <code>rebar_mix</code> plugin.  Modules with zigler
nifs should inculde code into one or more <code>zig_code</code> attribute and pass
zigler options (identical to the elixir options) into a <code>zig_opts</code> attribute.<br>
Zigler will then create appropriate functions matching the zig functions as
it does with elixir.  Please not that some features (such as integers &gt; 64
bits) are not currently supported in erlang, although nearly full feature parity
is planned.</p>
<div dir="auto" data-snippet-clipboard-copy-content="-module(erlang_zigler_module).
-compile({parse_transform, zigler}). 
-export([foo/1, foo/0]).

-zig_code(&quot;
pub fn foo() i32 {
    return 47;
}
&quot;).

-zig_opts([{otp_app, zigler}]).

foo(X) ->
    47 + X."><pre>-<span>module</span>(<span>erlang_zigler_module</span>).
-<span>compile</span>({<span>parse_transform</span>, <span>zigler</span>}). 
-<span>export</span>([<span>foo</span>/<span>1</span>, <span>foo</span>/<span>0</span>]).

-<span>zig_code</span>(<span><span>"</span></span>
<span>pub fn foo() i32 {</span>
<span>    return 47;</span>
<span>}</span>
<span><span>"</span></span>).

-<span>zig_opts</span>([{<span>otp_app</span>, <span>zigler</span>}]).

<span>foo</span>(<span>X</span>) <span>-&gt;</span>
    <span>47</span> <span>+</span> <span>X</span>.</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zigler Principles</h2><a id="user-content-zigler-principles" aria-label="Permalink: Zigler Principles" href="#zigler-principles"></a></p>
<ol dir="auto">
<li>Make being a good citizen of the BEAM easy.</li>
<li>Use magic, but sparingly, only to prevent errors.</li>
<li>Let the user see behind the curtain.</li>
<li>Let the user opt out of magic.</li>
<li>Magic shouldn't get in the way.</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cable companies ask 5th Circuit to block FTC's click-to-cancel rule (198 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/</link>
            <guid>41937666</guid>
            <pubDate>Thu, 24 Oct 2024 17:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/">https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/</a>, See on <a href="https://news.ycombinator.com/item?id=41937666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>The FTC declined to comment on the lawsuits today. The agency's rule is not enforced yet, as it is scheduled to take full effect 180 days after publication in the Federal Register.</p>
<h2>Cable firms don’t want canceling to be easy</h2>
<p>The NCTA cable lobby group, which represents companies like Comcast and Charter, have complained about the rule's impact on their ability to talk customers out of canceling. NCTA CEO Michael Powell <a href="https://arstechnica.com/tech-policy/2024/01/cable-firms-to-ftc-we-shouldnt-have-to-let-users-cancel-service-with-a-click/">claimed during a January 2024 hearing</a> that "a consumer may easily misunderstand the consequences of canceling and it may be imperative that they learn about better options" and that the rule's disclosure and consent requirements raise "First Amendment issues."</p>
<p>The Interactive Advertising Bureau argued at the same hearing that the rule would "restrict innovation without any corresponding benefit" and "constrain companies from being able to adapt their offerings to the needs of their customers."</p>
<p>The FTC held firm, adopting its proposed rule without major changes. In addition to the click-to-cancel provision, the FTC set out other requirements for "negative option" features in which a consumer's silence or failure to take action to reject or cancel an agreement is interpreted by the seller as acceptance of an offer.</p>
<p>The FTC said its rule "prohibits misrepresentations of any material fact made while marketing using negative option features; requires sellers to provide important information prior to obtaining consumers' billing information and charging consumers; [and] requires sellers to obtain consumers' unambiguously affirmative consent to the negative option feature prior to charging them."</p>
<p>The FTC will have to defend its authority to issue the rule in court. The agency decision cites authority under Section 18 of the FTC Act to make "rules that define with specificity acts or practices that are unfair or deceptive" and "prescribe requirements for the purpose of preventing these unfair or deceptive acts and practices."</p>
<p>"Too often, businesses make people jump through endless hoops just to cancel a subscription," FTC Chair Lina Khan said. "The FTC's rule will end these tricks and traps, saving Americans time and money. Nobody should be stuck paying for a service they no longer want."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Security research on Private Cloud Compute (192 pts)]]></title>
            <link>https://security.apple.com/blog/pcc-security-research/</link>
            <guid>41937664</guid>
            <pubDate>Thu, 24 Oct 2024 17:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.apple.com/blog/pcc-security-research/">https://security.apple.com/blog/pcc-security-research/</a>, See on <a href="https://news.ycombinator.com/item?id=41937664">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p><span><figure><picture><source srcset="https://security.apple.com/assets/image/generated/xlarge_pcc-vre-launch-bug-image-blog-post-light.png 2500w, https://security.apple.com/assets/image/generated/large_pcc-vre-launch-bug-image-blog-post-light.png 1650w, https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post-light.png 1300w, https://security.apple.com/assets/image/generated/small_pcc-vre-launch-bug-image-blog-post-light.png 840w, https://security.apple.com/assets/image/generated/xsmall_pcc-vre-launch-bug-image-blog-post-light.png 560w" media="(prefers-color-scheme: light)" decoding="async" loading="lazy"><img alt="The high-level architecture of Private Cloud Compute" src="https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post~dark@2x.png" srcset="https://security.apple.com/assets/image/generated/xlarge_pcc-vre-launch-bug-image-blog-post~dark@2x.png 2500w, https://security.apple.com/assets/image/generated/large_pcc-vre-launch-bug-image-blog-post~dark@2x.png 1650w, https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post~dark@2x.png 1300w, https://security.apple.com/assets/image/generated/small_pcc-vre-launch-bug-image-blog-post~dark@2x.png 840w, https://security.apple.com/assets/image/generated/xsmall_pcc-vre-launch-bug-image-blog-post~dark@2x.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></picture></figure></span></p>
<p>Private Cloud Compute (PCC) fulfills computationally intensive requests for Apple Intelligence while providing groundbreaking privacy and security protections — by bringing our industry-leading device security model into the cloud. In our previous post <a href="https://security.apple.com/blog/private-cloud-compute/">introducing Private Cloud Compute</a>, we explained that to build public trust in the system, we would take the extraordinary step of allowing security and privacy researchers to inspect and verify the end-to-end security and privacy promises of PCC. In the weeks after we announced Apple Intelligence and PCC, we provided third-party auditors and select security researchers early access to the resources we created to enable this inspection, including the PCC Virtual Research Environment (VRE).</p>
<p>Today we’re making these resources publicly available to invite all security and privacy researchers — or anyone with interest and a technical curiosity — to learn more about PCC and perform their own independent verification of our claims. And we’re excited to announce that we’re expanding Apple Security Bounty to include PCC, with significant rewards for reports of issues with our security or privacy claims.</p>
<h3>Security guide</h3>
<p><span><figure><img alt="Security Guide Icon" src="https://security.apple.com/assets/image/generated/medium_security-guide.png" srcset="https://security.apple.com/assets/image/generated/xlarge_security-guide.png 2500w, https://security.apple.com/assets/image/generated/large_security-guide.png 1650w, https://security.apple.com/assets/image/generated/medium_security-guide.png 1300w, https://security.apple.com/assets/image/generated/small_security-guide.png 840w, https://security.apple.com/assets/image/generated/xsmall_security-guide.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>To help you understand how we designed PCC’s architecture to accomplish each of our core requirements, we’ve published the <a href="https://security.apple.com/documentation/private-cloud-compute">Private Cloud Compute Security Guide</a>. The guide includes comprehensive technical details about the components of PCC and how they work together to deliver a groundbreaking level of privacy for AI processing in the cloud. The guide covers topics such as: how PCC attestations build on an immutable foundation of features implemented in hardware; how PCC requests are authenticated and routed to provide non-targetability; how we technically ensure that you can inspect the software running in Apple’s data centers; and how PCC’s privacy and security properties hold up in various attack scenarios.</p>
<h3>Virtual Research Environment</h3>
<p><span><figure><img alt="Virtual Research Environment Icon" src="https://security.apple.com/assets/image/generated/medium_vre.png" srcset="https://security.apple.com/assets/image/generated/xlarge_vre.png 2500w, https://security.apple.com/assets/image/generated/large_vre.png 1650w, https://security.apple.com/assets/image/generated/medium_vre.png 1300w, https://security.apple.com/assets/image/generated/small_vre.png 840w, https://security.apple.com/assets/image/generated/xsmall_vre.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>For the first time ever, we’ve created a Virtual Research Environment (VRE) for an Apple platform. The VRE is a set of tools that enables you to perform your own security analysis of Private Cloud Compute right from your Mac. This environment enables you to go well beyond simply understanding the security features of the platform. You can confirm that Private Cloud Compute indeed maintains user privacy in the ways we describe.</p>
<p>The VRE runs the PCC node software in a virtual machine with only minor modifications. Userspace software runs identically to the PCC node, with the boot process and kernel adapted for virtualization. The VRE includes a virtual Secure Enclave Processor (SEP), enabling security research in this component for the first time — and also uses the built-in macOS support for paravirtualized graphics to enable inference.</p>
<p>You can use the VRE tools to:</p>
<ul>
<li>List and inspect PCC software releases</li>
<li>Verify the consistency of the transparency log</li>
<li>Download the binaries corresponding to each release</li>
<li>Boot a release in a virtualized environment</li>
<li>Perform inference against demonstration models</li>
<li>Modify and debug the PCC software to enable deeper investigation</li>
</ul>
<div><figure><img alt="The Virtual Research Environment for Private Cloud Compute" src="https://security.apple.com/assets/image/generated/medium_PCC_VRE.png" srcset="https://security.apple.com/assets/image/generated/xlarge_PCC_VRE.png 2500w, https://security.apple.com/assets/image/generated/large_PCC_VRE.png 1650w, https://security.apple.com/assets/image/generated/medium_PCC_VRE.png 1300w, https://security.apple.com/assets/image/generated/small_PCC_VRE.png 840w, https://security.apple.com/assets/image/generated/xsmall_PCC_VRE.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></div>
<p>The VRE is available in the latest macOS Sequoia 15.1 Developer Preview and requires a Mac with Apple silicon and 16GB or more unified memory. Learn how to <a href="https://security.apple.com/documentation/private-cloud-compute/vresetup">get started with the Private Cloud Compute Virtual Research Environment</a>.</p>
<h3>Private Cloud Compute source code</h3>
<p><span><figure><img alt="Source Code Icon" src="https://security.apple.com/assets/image/generated/medium_source-code.png" srcset="https://security.apple.com/assets/image/generated/xlarge_source-code.png 2500w, https://security.apple.com/assets/image/generated/large_source-code.png 1650w, https://security.apple.com/assets/image/generated/medium_source-code.png 1300w, https://security.apple.com/assets/image/generated/small_source-code.png 840w, https://security.apple.com/assets/image/generated/xsmall_source-code.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>We’re also making available the source code for certain key components of PCC that help to implement its security and privacy requirements. We provide this source under a limited-use license agreement to allow you to perform deeper analysis of PCC.</p>
<p>The projects for which we’re releasing source code cover a range of PCC areas, including:</p>
<ul>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/CloudAttestation/CloudAttestation">CloudAttestation</a> project, which is responsible for constructing and validating the PCC node’s attestations.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/Thimble">Thimble</a> project, which includes the privatecloudcomputed daemon that runs on a user’s device and uses CloudAttestation to enforce verifiable transparency.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/darwinOSBits/splunkloggingd">splunkloggingd</a> daemon, which filters the logs that can be emitted from a PCC node to protect against accidental data disclosure.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/srd_tools">srd_tools</a> project, which contains the VRE tooling and which you can use to understand how the VRE enables running the PCC code.</li>
</ul>
<p>You can find the available PCC source code in the <a href="https://github.com/apple/security-pcc">apple/security-pcc</a> project on GitHub.</p>
<h3>Apple Security Bounty for Private Cloud Compute</h3>
<p><span><figure><img alt="Bug Bounty Icon" src="https://security.apple.com/assets/image/generated/medium_bug-bounty.png" srcset="https://security.apple.com/assets/image/generated/xlarge_bug-bounty.png 2500w, https://security.apple.com/assets/image/generated/large_bug-bounty.png 1650w, https://security.apple.com/assets/image/generated/medium_bug-bounty.png 1300w, https://security.apple.com/assets/image/generated/small_bug-bounty.png 840w, https://security.apple.com/assets/image/generated/xsmall_bug-bounty.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>To further encourage your research in Private Cloud Compute, we’re expanding Apple Security Bounty to include rewards for vulnerabilities that demonstrate a compromise of the fundamental security and privacy guarantees of PCC.</p>
<p>Our new PCC bounty categories are aligned with the <a href="https://security.apple.com/documentation/private-cloud-compute/attacks">most critical threats</a> we describe in the Security Guide:</p>
<ul>
<li><strong>Accidental data disclosure</strong>: vulnerabilities leading to unintended data exposure due to configuration flaws or system design issues.</li>
<li><strong>External compromise from user requests</strong>: vulnerabilities enabling external actors to exploit user requests to gain unauthorized access to PCC.</li>
<li><strong>Physical or internal access</strong>: vulnerabilities where access to internal interfaces enables a compromise of the system.</li>
</ul>
<p>Because PCC extends the industry-leading security and privacy of Apple devices into the cloud, the rewards we offer are comparable to those for iOS. We award maximum amounts for vulnerabilities that compromise user data and inference request data outside the PCC trust boundary.</p>

<p><em>Apple Security Bounty: Private Cloud Compute</em></p>
<table><thead><tr><th>Category</th>
<th>Description</th>
<th>Maximum Bounty</th></tr></thead><tbody><tr><td rowspan="2">Remote attack on request data</td>
<td>Arbitrary code execution with arbitrary entitlements</td>
<td>$1,000,000</td></tr><tr><td>Access to a user's request data or sensitive information about the user's requests outside the trust boundary</td>
<td>$250,000</td></tr><tr><td rowspan="3">Attack on request data from a privileged network position</td>
<td>Access to a user's request data or other sensitive information about the user outside the trust
boundary</td>
<td>$150,000</td></tr><tr><td>Ability to execute unattested code</td>
<td>$100,000</td></tr><tr><td>Accidental or unexpected data disclosure due to deployment or configuration issue</td>
<td>$50,000</td></tr></tbody></table>

<p>Because we care deeply about any compromise to user privacy or security, we will consider any security issue that has a significant impact to PCC for an Apple Security Bounty reward, even if it doesn’t match a published category. We’ll evaluate every report according to the quality of what's presented, the proof of what can be exploited, and the impact to users. Visit our <a href="https://security.apple.com/bounty">Apple Security Bounty</a> page to learn more about the program and to submit your research.</p>
<h3>In closing</h3>
<p>We designed Private Cloud Compute as part of Apple Intelligence to take an extraordinary step forward for privacy in AI. This includes providing verifiable transparency — a unique property that sets it apart from other server-based AI approaches. Building on our experience with the <a href="https://security.apple.com/research-device/">Apple Security Research Device Program</a>, the tooling and documentation that we released today makes it easier than ever for anyone to not only study, but verify PCC’s critical security and privacy features. We hope that you’ll dive deeper into PCC’s design with our Security Guide, explore the code yourself with the Virtual Research Environment, and report any issues you find through Apple Security Bounty. We believe Private Cloud Compute is the most advanced security architecture ever deployed for cloud AI compute at scale, and we look forward to working with the research community to build trust in the system and make it even more secure and private over time.</p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Architecture is here (138 pts)]]></title>
            <link>https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here</link>
            <guid>41937591</guid>
            <pubDate>Thu, 24 Oct 2024 17:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here">https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here</a>, See on <a href="https://news.ycombinator.com/item?id=41937591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p>React Native 0.76 with the New Architecture by default is now available on npm!</p>
<p>In the <a href="https://reactnative.dev/blog/2024/10/23/release-0.76-new-architecture">0.76 release blog post</a>, we shared a list of significant changes included in this version. In this post, we provide an overview of the New Architecture and how it shapes the future of React Native.</p>
<p>The New Architecture adds full support for modern React features, including <a href="https://react.dev/blog/2022/03/29/react-v18#new-suspense-features" target="_blank" rel="noopener noreferrer">Suspense</a>, <a href="https://react.dev/blog/2022/03/29/react-v18#new-feature-transitions" target="_blank" rel="noopener noreferrer">Transitions</a>, <a href="https://react.dev/blog/2022/03/29/react-v18#new-feature-automatic-batching" target="_blank" rel="noopener noreferrer">automatic batching</a>, and <a href="https://react.dev/reference/react/useLayoutEffect" target="_blank" rel="noopener noreferrer"><code>useLayoutEffect</code></a>. The New Architecture also includes new <a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Module</a> and <a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Component</a> systems that let you write type-safe code with direct access to native interfaces without a bridge.</p>
<p>This release is the result of a ground-up rewrite of React Native we’ve been working on since 2018, and we’ve taken extra care to make the New Architecture a gradual migration for most apps. In 2021, we created <a href="https://github.com/reactwg/react-native-new-architecture/" target="_blank" rel="noopener noreferrer">the New Architecture Working Group</a> to collaborate with the community on ensuring a smooth upgrade experience for the entire React ecosystem.</p>
<p>Most apps will be able to adopt React Native 0.76 with the same level of effort as any other release. The most popular React Native libraries already support the New Architecture. The New Architecture also includes an automatic interoperability layer to enable backward compatibility with libraries targeting the old architecture.</p>
<p>Over the past several years of development, our team has publicly shared our vision for the New Architecture. If you missed any of these talks, check them out here:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=52El0EUI6D0" target="_blank" rel="noopener noreferrer">React Native EU 2019 - The New React Native</a></li>
<li><a href="https://www.youtube.com/watch?v=FZ0cG47msEk" target="_blank" rel="noopener noreferrer">React Conf 2021 - React 18 Keynote</a></li>
<li><a href="https://www.youtube.com/watch?v=Q6TkkzRJfUo" target="_blank" rel="noopener noreferrer">App.js 2022 - Bringing the New React Native Architecture to the OSS Community</a></li>
<li><a href="https://www.youtube.com/watch?v=Q5SMmKb7qVI" target="_blank" rel="noopener noreferrer">React Conf 2024 - Day 2 Keynote</a></li>
</ul>
<h2 id="what-is-the-new-architecture">What is the New Architecture<a href="#what-is-the-new-architecture" aria-label="Direct link to What is the New Architecture" title="Direct link to What is the New Architecture">​</a></h2>
<p>The New Architecture is a complete rewrite of the major systems that underpin React Native, including how components are rendered, how JavaScript abstractions communicates with native abstractions, and how work is scheduled across different threads. Although most users should not have to think about how these systems work, these changes bring improvements and new capabilities.</p>
<p>In the old architecture, React Native communicated with the native platform using an asynchronous bridge. To render a component or call a native function, React Native needed to serialize and enqueue native functions calls with the bridge, which would be processed asynchronously. The benefit of this architecture is that the main thread was never blocked for rendering updates or handling native module function calls, since all work was done on a background thread.</p>
<p>However, users expect immediate feedback to interactions to feel like a native app. This means some updates need to render synchronously in response to user input, potentially interrupting any in-progress render. Since the old architecture was only asynchronous, we needed to rewrite it to allow for both asynchronous and synchronous updates.</p>
<p>Additionally, in the old architecture, serializing function calls over the bridge quickly became a bottleneck, especially for frequent updates or large objects. This made it hard for apps to achieve 60+ FPS reliably. There were also synchronization issues: when the JavaScript and native layer got out of sync, it was impossible to reconcile them synchronously, resulting bugs like lists showing frames of empty space and visual UI jumps due to intermediate states rendering.</p>
<p>Finally, since the old architecture kept a single copy of the UI using the native hierarchy, and mutated that copy in place, layout could only be computed on a single thread. This made it impossible to process urgent updates like user inputs, and layout could not be read synchronously, such as reading in a layout effect to update the position of a tooltip.</p>
<p>All of these problems meant that it was not possible to properly support React’s concurrent features. To solve these problems, the New Architecture includes four main parts:</p>
<ul>
<li>The New Native Module System</li>
<li>The New Renderer</li>
<li>The Event Loop</li>
<li>Removing the Bridge</li>
</ul>
<p>The New Module system allows the React Native Renderer to have synchronous access to the native layer, which allows it to handle events, schedule updates, and read layout both asynchronously and synchronously. The new Native Modules are also lazily loaded by default, giving apps a significant performance gain.</p>
<p>The New Renderer can handle multiple in progress trees across multiple threads, which allows React to process multiple concurrent update priorities, either on the main thread or a background thread. It also supports reading layout from multiple threads synchronously or asynchronously, to support more responsive UIs without jank.</p>
<p>The new Event Loop can process tasks on the JavaScript thread in a well-defined order. This allows React to interrupt rendering to process events so urgent user events can take priority over lower priority UI transitions. The Event Loop also aligns with web specifications, so we can support for browser features like microtasks, <code>MutationObserver</code>, and <code>IntersectionObserver</code>.</p>
<p>Finally, removing the bridge allows for faster startup and direct communication between JavaScript and the native runtime, so that the cost of switching work is minimized. This also allows for better error reporting, debugging, and reducing crashes from undefined behavior.</p>
<p>The New Architecture is now ready to be used in production. It is already used at scale at Meta in the Facebook app and in other products. We successfully used React Native and the New Architecture in the Facebook and Instagram app we developed for our <a href="https://engineering.fb.com/2024/10/02/android/react-at-meta-connect-2024/" target="_blank" rel="noopener noreferrer">Quest devices</a>.</p>
<p>Our partners have already been using the New Architecture in production for months now: have a look at these success stories by <a href="https://blog.swmansion.com/sunrising-new-architecture-in-the-new-expensify-app-729d237a02f5" target="_blank" rel="noopener noreferrer">Expensify</a> and <a href="https://blog.kraken.com/product/engineering/how-kraken-fixed-performance-issues-via-incremental-adoption-of-the-react-native-new-architecture" target="_blank" rel="noopener noreferrer">Kraken</a>, and give <a href="https://github.com/bluesky-social/social-app/releases/tag/1.92.0-na-rc.2" target="_blank" rel="noopener noreferrer">BlueSky</a> a shot with their new release.</p>
<h3 id="new-native-modules">New Native Modules<a href="#new-native-modules" aria-label="Direct link to New Native Modules" title="Direct link to New Native Modules">​</a></h3>
<p>The new Native Module System is a major rewrite of how JavaScript and the native platform communicate. It’s written entirely in C++, which unlocks many new capabilities:</p>
<ul>
<li>Synchronous access to and from the native runtime</li>
<li>Type safety between JavaScript and native code</li>
<li>Code sharing across platforms</li>
<li>Lazy module loading by default</li>
</ul>
<p>In the new Native Module system, JavaScript and the native layer can now synchronously communicate with each other through the JavaScript Interface (JSI), without the need to use an asynchronous bridge. This means your custom Native Modules can now synchronously call a function, return a value, and pass that value back to another Native Module function.</p>
<p>In the old architecture, in order to handle a response from native function calls, you needed to provide a callback, and the value returned needed to be serializable:</p>
<div><pre tabindex="0"><code><span><span>// ❌ Sync callback from Native Module</span><span></span><br></span><span><span>nativeModule</span><span>.</span><span>getValue</span><span>(</span><span>value </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ❌ value cannot reference a native object</span><span></span><br></span><span><span>  nativeModule</span><span>.</span><span>doSomething</span><span>(</span><span>value</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>In the New Architecture, you can make synchronous calls to native functions:</p>
<div><pre tabindex="0"><code><span><span>// ✅ Sync response from Native Module</span><span></span><br></span><span><span></span><span>const</span><span> value </span><span>=</span><span> nativeModule</span><span>.</span><span>getValue</span><span>(</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ✅ value can be a reference to a native object</span><span></span><br></span><span><span>nativeModule</span><span>.</span><span>doSomething</span><span>(</span><span>value</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>With the New Architecture, you can finally leverage the full power of a C++ native implementation while still accessing it from JavaScript/TypeScript APIs. The New Module System supports <a href="https://reactnative.dev/docs/next/the-new-architecture/pure-cxx-modules">modules written in C++</a> so you can write your module once, and it works across all platforms, including Android, iOS, Windows, and macOS. Implementing modules in C++ allows for more fine-grained memory management and performance optimizations.</p>
<p>Additionally, with <a href="https://reactnative.dev/docs/next/the-new-architecture/what-is-codegen">Codegen</a>, your modules can define a strongly typed contract between the JavaScript layer and the native layer. From our experience, cross-boundary type errors are one of the most common sources of crashes in cross-platform apps. Codegen lets you overcome those problems while also generating boilerplate code for you.</p>
<p>Finally, modules are now lazily loaded: they are loaded in memory only when they’re effectively needed rather than at startup. This reduces the app startup time and keeps it low as the application grows in complexity.</p>
<p>Popular libraries such as <a href="https://github.com/mrousavy/react-native-mmkv" target="_blank" rel="noopener noreferrer">react-native-mmkv</a> have already seen benefits from migrating to the new Native Modules:</p>
<blockquote>
<p>“The new Native Modules greatly simplified setup, autolinking, and initialization for <code>react-native-mmkv</code>. Thanks to the New Architecture, <code>react-native-mmkv</code> is now a pure C++ Native Module, which allows it to work on any platform. The new Codegen allows MMKV to be fully type-safe, which fixed a long-standing <code>NullPointerReference</code> issue by enforcing null-safety, and being able to call Native Module functions synchronously allowed us to replace custom JSI access with the new Native Module API.”</p>
<p><a href="https://twitter.com/mrousavy" target="_blank" rel="noopener noreferrer">Marc Rousavy</a>, creator of <code>react-native-mmkv</code></p>
</blockquote>
<h3 id="new-renderer">New Renderer<a href="#new-renderer" aria-label="Direct link to New Renderer" title="Direct link to New Renderer">​</a></h3>
<p>We've also completely rewritten the Native Renderer, adding several benefits:</p>
<ul>
<li>Updates can be rendered on different threads at different priorities.</li>
<li>Layout can be read synchronously and across different threads.</li>
<li>The renderer is written in C++ and shared across all platforms.</li>
</ul>
<p>The updated Native Renderer now stores the view hierarchy in an immutable tree structure. This means that the UI is stored in a way that cannot be changed directly, allowing for thread-safe processing of updates. This allows it to handle multiple in-progress trees, each representing a different version of the user interface. As a result, updates can be rendered in the background without blocking the UI (such as during transitions) or on the main thread (in response to user input).</p>
<p>By supporting multiple threads, React can interrupt a low-priority update to render an urgent one, such as those generated by user inputs, and then resume the low-priority update as needed. The new renderer can also read layout information synchronously and across different threads. This enables background computation for low-priority updates and synchronous reads when needed, such as repositioning a tooltip.</p>
<p>Finally, rewriting the renderer in C++ allows it to be shared across all platforms. This ensures that the same code runs on iOS, Android, Windows, macOS, and any other React Native-supported platform, providing consistent rendering capabilities without needing re-implementation for each platform.</p>
<p>This is a significant step towards our <a href="https://reactnative.dev/blog/2021/08/26/many-platform-vision">Many Platform Vision</a>. For example, View Flattening was an Android-only optimisation to avoid deep layout trees. The new renderer, with shared C++ core, <a href="https://github.com/reactwg/react-native-new-architecture/discussions/110" target="_blank" rel="noopener noreferrer">brings this feature to iOS</a>. This optimisation is automatic and does not require setup, it comes for free with the shared renderer.</p>
<p>With these changes, React Native now fully supports Concurrent React features like Suspense and Transitions, making it easier to build complex user interfaces that respond quickly to user input without jank, delays, or visual jumps. In the future, we will leverage these new capabilities to bring more improvements to built-in components such as FlatList and TextInput.</p>
<p>Popular libraries like <a href="https://docs.swmansion.com/react-native-reanimated/" target="_blank" rel="noopener noreferrer">Reanimated</a> are already taking advantage of the New Renderer:</p>
<blockquote>
<p>“Reanimated 4, currently in development, introduces a new animation engine that works directly with the New Renderer, allowing it to handle animations and manage layout across different threads. The New Renderer’s design is what truly enables these features to be built without relying on numerous workarounds. Moreover, because it’s implemented in C++ and shared across platforms, large portions of Reanimated can be written once, reducing platform-specific issues, minimizing the codebase, and streamlining adoption for out-of-tree platforms.”</p>
<p><a href="https://x.com/kzzzf" target="_blank" rel="noopener noreferrer">Krzysztof Magiera</a>, creator of <a href="https://docs.swmansion.com/react-native-reanimated/" target="_blank" rel="noopener noreferrer">Reanimated</a></p>
</blockquote>
<h3 id="the-event-loop">The Event Loop<a href="#the-event-loop" aria-label="Direct link to The Event Loop" title="Direct link to The Event Loop">​</a></h3>
<p>The New Architecture allowed us to implement a well-defined event loop processing model, as described in this <a href="https://github.com/react-native-community/discussions-and-proposals/blob/main/proposals/0744-well-defined-event-loop.md" target="_blank" rel="noopener noreferrer">RFC</a>. This RFC follows the specifications described in the <a href="https://html.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model" target="_blank" rel="noopener noreferrer">HTML Standard</a>, and it describes how React Native should perform tasks on the JavaScript thread.</p>
<p>Implementing a well-defined event loop closes gaps between React DOM and React Native: the behavior of a React Native application is now closer to the behavior of a React DOM application, making it easier to learn once, and write anywhere.</p>
<p>The event loop brings many benefits to React Native:</p>
<ul>
<li>The ability to interrupt rendering to process events and tasks</li>
<li>Closer alignment with web specifications</li>
<li>Foundation for more browser features</li>
</ul>
<p>With the Event Loop, React is able to predictably order updates and events. This allows React to interrupt a low priority update with an urgent user event, and the New Renderer allows us to render those updates independently.</p>
<p>The Event Loops also aligns the behavior of events and task like timers with web specifications, which means React Native works more like what users are familiar with in the Web, and allows for better code sharing between React DOM and React Native.</p>
<p>It also allows for the implementation of more compliant browser features like microtasks, <code>MutationObserver</code>, and <code>IntersectionObserver</code>. These features are not ready to use in React Native yet, but we are working on bringing them to you in the future.</p>
<p>Finally, the Event Loop and the New Renderer changes to support reading layout synchronously allow React Native to add proper support for <code>useLayoutEffect</code> to read layout information synchronously and update the UI in the same frame. This allows you to position elements correctly before they are displayed to the user.</p>
<p>See <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#uselayouteffect"><code>useLayoutEffect</code></a> for more details.</p>
<h3 id="removing-the-bridge">Removing the Bridge<a href="#removing-the-bridge" aria-label="Direct link to Removing the Bridge" title="Direct link to Removing the Bridge">​</a></h3>
<p>In the New Architecture, we've also fully removed React Native's dependency on the bridge, replacing it with direct, efficient communication between JavaScript and native code using JSI:</p>
<p><img decoding="async" loading="lazy" src="https://reactnative.dev/assets/images/0.76-bridge-diagram-a653d794d04871e5b7a026e35d8edf03.png" width="1143" height="736"></p>
<p>Removing the bridge improves startup time by avoiding bridge initialization. For example, in the old architecture, in order to provide global methods to JavaScript, we would need to initialize a module in JavaScript on startup, causing a small delay in app startup time:</p>
<div><pre tabindex="0"><code><span><span>// ❌ Slow initialization</span><span></span><br></span><span><span></span><span>import</span><span> </span><span>{</span><span>NativeTimingModule</span><span>}</span><span> </span><span>from</span><span> </span><span>'NativeTimingModule'</span><span>;</span><span></span><br></span><span><span>global</span><span>.</span><span>setTimeout</span><span> </span><span>=</span><span> </span><span>timer</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>NativeTimingModule</span><span>.</span><span>setTimeout</span><span>(</span><span>timer</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// App.js</span><span></span><br></span><span><span></span><span>setTimeout</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span> </span><span>100</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>In the New Architecture, we can directly bind methods from C++:</p>
<div><pre tabindex="0"><code><span><span>// ✅ Initialize directly in C++</span><span></span><br></span><span><span>runtime</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>setProperty</span><span>(</span><span>runtime</span><span>,</span><span> </span><span>"setTimeout"</span><span>,</span><span> createTimer</span><span>)</span><span>;</span><br></span></code></pre></div>
<div><pre tabindex="0"><code><span><span>// App.js</span><span></span><br></span><span><span></span><span>setTimeout</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span> </span><span>100</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>The rewrite also improves error reporting, particularly for JavaScript crashes at startup, and reduces crashes from undefined behavior. If crashes occur, the new <a href="https://reactnative.dev/docs/next/react-native-devtools">React Native DevTools</a> simplify debugging and support the New Architecture.</p>
<p>The bridge remains for backward compatibility to support gradual migration to the New Architecture. In the future, we will remove the bridge code completely.</p>
<h3 id="gradual-migration">Gradual Migration<a href="#gradual-migration" aria-label="Direct link to Gradual Migration" title="Direct link to Gradual Migration">​</a></h3>
<p>We expect most apps can upgrade to 0.76 with the same effort as any other release.</p>
<p>When you upgrade to 0.76, the New Architecture and React 18 are enabled by default. However, to use concurrent features and gain the full benefits of the New Architecture, your app and libraries will need to be gradually migrated to fully support the New Architecture.</p>
<p>When you first upgrade, your app will run on the New Architecture with an automatic interoperability layer with the old architecture. For most apps, this will work without any changes, but there are <a href="https://github.com/reactwg/react-native-new-architecture/discussions/237" target="_blank" rel="noopener noreferrer">known limitations</a> with the interop layer, as it does not support accessing custom Shadow Nodes or concurrent features.</p>
<p>To use concurrent features, apps will also need to be updated to support <a href="https://react.dev/blog/2022/03/29/react-v18#what-is-concurrent-react" target="_blank" rel="noopener noreferrer">Concurrent React</a> by following the <a href="https://react.dev/reference/rules" target="_blank" rel="noopener noreferrer">Rules of React</a>. To migrate your JavaScript code to React 18 and its semantics, follow the <a href="https://react.dev/blog/2022/03/08/react-18-upgrade-guide" target="_blank" rel="noopener noreferrer">React 18 Upgrade guide</a>.</p>
<p>The overall strategy is to get your application running on the New Architecture without breaking existing code. You can then gradually migrate your app at your own pace. For new surfaces that have migrated all modules to the New Architecture, you can start using concurrent features immediately. For existing surfaces, you may need to address some issues and migrate modules before adding concurrent features.</p>
<p>We've collaborated with the most popular React Native libraries to ensure support for the New Architecture. More than 850 libraries are already compatible, including all libraries with over 200K weekly downloads (~10% of downloaded libraries). You can check library compatibility with the New Architecture on the <a href="https://reactnative.directory/" target="_blank" rel="noopener noreferrer">reactnative.directory</a> website:</p>
<p><img decoding="async" loading="lazy" src="https://reactnative.dev/assets/images/0.76-directory-85387cf0da638f887bbf996c39db432d.png" width="1999" height="785"></p>
<p>For more details on upgrading, see <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#how-to-upgrade">How to Upgrade</a> below.</p>
<h2 id="new-features">New Features<a href="#new-features" aria-label="Direct link to New Features" title="Direct link to New Features">​</a></h2>
<p>The New Architecture includes full support for React 18, concurrent features, and <code>useLayoutEffect</code> in React Native. For a full list of React 18 features, please see the <a href="https://react.dev/blog/2021/12/17/react-conf-2021-recap#react-18-and-concurrent-features" target="_blank" rel="noopener noreferrer">React 18 blog post</a>.</p>
<h3 id="transitions">Transitions<a href="#transitions" aria-label="Direct link to Transitions" title="Direct link to Transitions">​</a></h3>
<p>Transitions are a new concept in React 18 to distinguish between urgent and non-urgent updates.</p>
<ul>
<li><strong>Urgent updates</strong> reflect direct interaction, like typing and pressing.</li>
<li><strong>Transition updates</strong> transition the UI from one view to another.</li>
</ul>
<p>Urgent updates need immediate response to match our intuitions about how physical objects behave. However, transitions are different because the user doesn’t expect to see every intermediate value on screen. In the New Architecture, React Native is able to support rendering urgent updates and transition updates separately.</p>
<p>Typically, for the best user experience, a single user input should result in both an urgent update and a non-urgent one. Similar to ReactDOM, events like <code>press</code> or <code>change</code> are handled as urgent and rendered immediately. You can use the <code>startTransition</code> API inside an input event to inform React which updates are “transitions” and can be deferred to the background:</p>
<div><pre tabindex="0"><code><span><span>import</span><span> </span><span>{</span><span>startTransition</span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// Urgent: Show the slider value</span><span></span><br></span><span><span></span><span>setCount</span><span>(</span><span>input</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// Mark any state updates inside as transitions</span><span></span><br></span><span><span></span><span>startTransition</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// Transition: Show the results</span><span></span><br></span><span><span>  </span><span>setNumberOfTiles</span><span>(</span><span>input</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>Separating urgent events from transitions allows for a more responsive user interface, and a more intuitive user experience.</p>
<p>Here's a comparison of the old architecture without transitions and the new architecture with transitions. Imagine that each tile isn't a trivial view with a background color, but a rich component containing images and other components that are expensive to render. <strong>After</strong> using <code>useTransition</code> you avoid thrashing your app with updates and falling behind.</p>

<p>For more information, see <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#support-for-concurrent-renderer-and-features">Support for Concurrent Renderer and Features</a>.</p>
<h3 id="automatic-batching">Automatic Batching<a href="#automatic-batching" aria-label="Direct link to Automatic Batching" title="Direct link to Automatic Batching">​</a></h3>
<p>When upgrading to the New Architecture, you will benefit from automatic batching from React 18.</p>
<p>Automatic batching allows React to batch together more state updates when rendering to avoid the rendering of intermediate states. This allows React Native to be faster and less susceptible to lags, without any additional code from the developer.</p>

<p>In the old architecture, more intermediate states are rendered, and the UI keeps updating even when the slider stops moving. The New Architecture, renders fewer intermediate states and completes the rendering much sooner thanks to automatically batching the updates.</p>
<p>For more information, see <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#support-for-concurrent-renderer-and-features">Support for Concurrent Renderer and Features</a>.</p>
<h3 id="uselayouteffect">useLayoutEffect<a href="#uselayouteffect" aria-label="Direct link to useLayoutEffect" title="Direct link to useLayoutEffect">​</a></h3>
<p>Building on the Event Loop and the ability to read layout synchronously, in the New Architecture we added proper support for <code>useLayoutEffect</code> in React Native.</p>
<p>In the old architecture, you needed to use the asynchronous <code>onLayout</code> event to read layout information of a view (which was also asynchronous). As a result there would be at least one frame where the layout was incorrect until the layout was read and updated, causing issues like tooltips placed in the wrong position:</p>
<div><pre tabindex="0"><code><span><span>// ❌ async onLayout after commit</span><span></span><br></span><span><span></span><span>const</span><span> onLayout </span><span>=</span><span> </span><span>React</span><span>.</span><span>useCallback</span><span>(</span><span>event </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ❌ async callback to read layout</span><span></span><br></span><span><span>  ref</span><span>.</span><span>current</span><span>?.</span><span>measureInWindow</span><span>(</span><span>(</span><span>x</span><span>,</span><span> y</span><span>,</span><span> width</span><span>,</span><span> height</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>    </span><span>setPosition</span><span>(</span><span>{</span><span>x</span><span>,</span><span> y</span><span>,</span><span> width</span><span>,</span><span> height</span><span>}</span><span>)</span><span>;</span><span></span><br></span><span><span>  </span><span>}</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ...</span><span></span><br></span><span><span></span><span>&lt;</span><span>ViewWithTooltip</span><span></span><br></span><span><span>  </span><span>onLayout</span><span>=</span><span>{</span><span>onLayout</span><span>}</span><span></span><br></span><span><span>  </span><span>ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span></span><br></span><span><span>  </span><span>position</span><span>=</span><span>{</span><span>position</span><span>}</span><span></span><br></span><span><span></span><span>/&gt;</span><span>;</span><br></span></code></pre></div>
<p>The New Architecture fixes this by allowing synchronous access to layout information in <code>useLayoutEffect</code>:</p>
<div><pre tabindex="0"><code><span><span>// ✅ sync layout effect during commit</span><span></span><br></span><span><span></span><span>useLayoutEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ✅ sync call to read layout</span><span></span><br></span><span><span>  </span><span>const</span><span> rect </span><span>=</span><span> ref</span><span>.</span><span>current</span><span>?.</span><span>getBoundingClientRect</span><span>(</span><span>)</span><span>;</span><span></span><br></span><span><span>  </span><span>setPosition</span><span>(</span><span>rect</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ...</span><span></span><br></span><span><span></span><span>&lt;</span><span>ViewWithTooltip</span><span> </span><span>ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span> </span><span>position</span><span>=</span><span>{</span><span>position</span><span>}</span><span> </span><span>/&gt;</span><span>;</span><br></span></code></pre></div>
<p>This change allows you to read layout information synchronously and update the UI in the same frame, allowing you to position elements correctly before they are displayed to the user:</p>

<p>For more information, see the docs for <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#synchronous-layout-and-effects">Synchronous Layout and Effects</a>.</p>
<h3 id="full-support-for-suspense">Full Support for Suspense<a href="#full-support-for-suspense" aria-label="Direct link to Full Support for Suspense" title="Direct link to Full Support for Suspense">​</a></h3>
<p>Suspense lets you declaratively specify the loading state for a part of the component tree if it’s not yet ready to be displayed:</p>
<div><pre tabindex="0"><code><span><span>&lt;</span><span>Suspense</span><span> </span><span>fallback</span><span>=</span><span>{</span><span>&lt;</span><span>Spinner</span><span> </span><span>/&gt;</span><span>}</span><span>&gt;</span><span></span><br></span><span><span>  </span><span>&lt;</span><span>Comments</span><span> </span><span>/&gt;</span><span></span><br></span><span><span></span><span>&lt;/</span><span>Suspense</span><span>&gt;</span><br></span></code></pre></div>
<p>We introduced a limited version of Suspense several years ago, and React 18 added full support. Until now, React Native was not able to support concurrent rendering for Suspense.</p>
<p>The New Architecture includes full support for Suspense introduced in React 18. This means that you can now use Suspense in React Native to handle loading states for your components, and the suspended content will render in the background while the loading state is displayed, giving higher priority to user input on visible content.</p>
<p>For more, see the <a href="https://github.com/reactjs/rfcs/blob/main/text/0213-suspense-in-react-18.md" target="_blank" rel="noopener noreferrer">RFC for Suspense in React 18</a>.</p>
<h2 id="how-to-upgrade">How to Upgrade<a href="#how-to-upgrade" aria-label="Direct link to How to Upgrade" title="Direct link to How to Upgrade">​</a></h2>
<p>To upgrade to 0.76, follow the steps in the <a href="https://reactnative.dev/blog/2024/10/23/release-0.76-new-architecture#upgrade-to-076">release post</a>. Since this release also upgrades to React 18, you will also need to follow the <a href="https://react.dev/blog/2022/03/08/react-18-upgrade-guide" target="_blank" rel="noopener noreferrer">React 18 Upgrade guide</a>.</p>
<p>These steps should be enough for most apps to upgrade to the New Architecture thanks to the interop layer with the old architecture. However, to take full advantage of the New Architecture and to start using concurrent features, you will need to migrate your custom Native Modules and Native Components to support the new Native Module and Native Component APIs.</p>
<p>Without migrating your custom Native Modules, you will not get the benefits of shared C++, synchronous method calls, or type-safety from codegen. Without migrating your Native Components, you will not be able to use concurrent features. We recommend migrating all Native Components and Native Modules to the New Architecture as soon as possible.</p>
<div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</p><p>In a future release, we will remove the interop layer and modules will need to support the New Architecture.</p></div>
<h3 id="apps">Apps<a href="#apps" aria-label="Direct link to Apps" title="Direct link to Apps">​</a></h3>
<p>If you are an app developer, to fully support the New Architecture, you will need to upgrade your libraries, custom Native Components, and custom Native Modules to fully support the New Architecture.</p>
<p>We've collaborated with the most popular React Native libraries to ensure support for the New Architecture. You can check library compatibility with the New Architecture on the <a href="https://reactnative.directory/" target="_blank" rel="noopener noreferrer">reactnative.directory</a> website.</p>
<p>If any of the libraries your app depends on are not compatible yet, you can:</p>
<ul>
<li>Open an issue with the library and ask the author to migrate to the New Architecture.</li>
<li>If the library is not maintained, consider alternative libraries with the same features.</li>
<li><a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#opt-out">Opt-out from the New Architecture</a> while those libraries are migrated.</li>
</ul>
<p>If your app has custom Native Modules or custom Native Components, we expect them to work fine, thanks to our <a href="https://github.com/reactwg/react-native-new-architecture/discussions/135" target="_blank" rel="noopener noreferrer">interop layer</a>. However, we recommend upgrading them to the new Native Module and Native Component APIs to fully support the New Architecture and adopt concurrent features.</p>
<p>Please follow these guides to migrate your modules and components to the New Architecture:</p>
<ul>
<li><a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Modules</a></li>
<li><a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Components</a></li>
</ul>
<h3 id="libraries">Libraries<a href="#libraries" aria-label="Direct link to Libraries" title="Direct link to Libraries">​</a></h3>
<p>If you are a library maintainer, please first test that your library works with the interop layer. If it does not, please open an issue on the <a href="https://github.com/reactwg/react-native-new-architecture/" target="_blank" rel="noopener noreferrer">New Architecture Working Group</a>.</p>
<p>To fully support the New Architecture, we recommend migrating your library to the new Native Module and Native Component APIs as soon as possible. This will allow users of your library to take full advantage of the New Architecture and support concurrent features.</p>
<p>You can follow these guides to migrate your modules and components to the New Architecture:</p>
<ul>
<li><a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Modules</a></li>
<li><a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Components</a></li>
</ul>
<h3 id="opt-out">Opt-out<a href="#opt-out" aria-label="Direct link to Opt-out" title="Direct link to Opt-out">​</a></h3>
<p>If, for any reason, the New Architecture is not behaving properly in your application, there is always the option to opt-out from it until you are ready to turn it on again.</p>
<p>To opt-out from the New Architecture:</p>
<ul>
<li>On Android, modify the <code>android/gradle.properties</code> file and turn off the <code>newArchEnabled</code> flag</li>
</ul>
<div><pre tabindex="0"><code><span><span>-</span><span>newArchEnabled=true</span><br></span><span><span></span><span>+</span><span>newArchEnabled=false</span><br></span></code></pre></div>
<ul>
<li>On iOS, you can reinstall the dependencies by running the command:</li>
</ul>
<div><pre tabindex="0"><code><span><span>RCT_NEW_ARCH_ENABLED</span><span>=</span><span>0</span><span> bundle </span><span>exec</span><span> pod </span><span>install</span><br></span></code></pre></div>
<h2 id="thanks">Thanks<a href="#thanks" aria-label="Direct link to Thanks" title="Direct link to Thanks">​</a></h2>
<p>Delivering the New Architecture to the OSS community has been a huge effort that took us several years of research and development. We want to take a moment to thank all the current and past members of the React team who helped us achieve this result.</p>
<p>We are also extremely grateful to all the partners who collaborated with us to make this happen. Specifically, we would like to call out:</p>
<ul>
<li><a href="https://expo.dev/" target="_blank" rel="noopener noreferrer">Expo</a>, for adopting the New Architecture early on, and for supporting the work on migrating the most popular libraries.</li>
<li><a href="https://swmansion.com/" target="_blank" rel="noopener noreferrer">Software Mansion</a>, for maintaining crucial libraries in the ecosystem, for migrating them to the New Architecture early and for all the help in investigating and fixing various issues.</li>
<li><a href="https://www.callstack.com/" target="_blank" rel="noopener noreferrer">Callstack</a>, for maintaining crucial libraries in the ecosystem, for migrating them to the New Architecture early and for the support with the work on the Community CLI.</li>
<li><a href="https://opensource.microsoft.com/" target="_blank" rel="noopener noreferrer">Microsoft</a>, for adding the New Architecture implementation for <code>react-native-windows</code> and <code>react-native-macos</code> as well as in several other developer tools.</li>
<li><a href="https://www.expensify.com/" target="_blank" rel="noopener noreferrer">Expensify</a>, <a href="https://www.kraken.com/" target="_blank" rel="noopener noreferrer">Kraken</a>, <a href="https://bsky.app/" target="_blank" rel="noopener noreferrer">BlueSky</a> and <a href="https://www.brigad.co/" target="_blank" rel="noopener noreferrer">Brigad</a> for pioneering the adoption of the New Architecture and reporting various issues so that we could fix them for everyone else.</li>
<li>All the independent library maintainers and developers who contributed to the New Architecture by testing it, fixing some of the issues, and opening questions on unclear matters so that we could clear them.</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lion of St. Mark's Square in Venice Is Chinese (107 pts)]]></title>
            <link>https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/</link>
            <guid>41937443</guid>
            <pubDate>Thu, 24 Oct 2024 17:08:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/">https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/</a>, See on <a href="https://news.ycombinator.com/item?id=41937443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A new study has revealed that the iconic bronze-winged lion in St. Mark’s Square, Venice, may have originated in 8th-century China.</p><figure id="attachment_42823" aria-describedby="caption-attachment-42823"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDI0IiBoZWlnaHQ9Ijc2OCIgdmlld0JveD0iMCAwIDEwMjQgNzY4Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" fetchpriority="high" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="1024" height="768" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg 1024w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-300x225.jpg 300w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-768x576.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-150x113.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-750x563.jpg 750w" data-sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-42823">Lion of Venice, Piazzetta San Marco. Credit: Didier Descouens (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>)</figcaption></figure><p>The discovery comes from a multidisciplinary team of experts in geology, chemistry, archaeology, and art history from the University of Padua, the Ca’ Foscari University of Venice, and the International Association for Mediterranean and Oriental Studies (Ismeo). Through advanced metallurgical analysis, the team discovered that a significant portion of the bronze used in the lion came from the lower Yangtze River basin in southeastern China, and it was likely cast during the Tang Dynasty (618-907 CE).</p><p>Lions were initially introduced to the <a href="https://archaeologymag.com/tag/han-dynasty/">Han</a> court by emissaries from <a href="https://archaeologymag.com/tag/ancient-iran/">Persia</a> (modern-day Iran) and had become widely represented as guardian figures.</p><p>Lead isotope analysis of the bronze alloy provided indisputable evidence of the <a href="https://archaeologymag.com/tag/ancient-china/">Chinese origin</a> of the materials used in the statue. The results were announced on September 11, 2024, during an international conference on Marco Polo, part of Venice’s celebrations marking the 700th anniversary of the famous merchant’s death. Scholars have long debated the lion’s origins, with previous theories suggesting it could have been made in Anatolia during the Hellenistic era. However, the new evidence points directly to China.</p><figure id="attachment_42824" aria-describedby="caption-attachment-42824"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iNjAwIiB2aWV3Qm94PSIwIDAgODAwIDYwMCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2NmZDRkYjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="800" height="600" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg 800w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-300x225.jpg 300w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-768x576.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-150x113.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-750x563.jpg 750w" data-sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-42824">The Lion in the 1870s. Credit: Carlo Naya, Public domain</figcaption></figure><p>Stylistic analysis further supports this theory. Researchers found that the lion shares several design features with zhenmushou (镇墓兽), or “tomb guardian” figures, typical of the Tang Dynasty. These guardian sculptures, often placed at tomb gates to ward off evil spirits, had distinct characteristics that mirror those of the St. Mark’s lion. For instance, the lion’s wide nostrils, upturned mustache, wide-open mouth with prominent canines, and truncated orbital sockets, where horns or antlers were once mounted, are all common features of zhenmushou statues. The lion’s ears also appear to have been modified to make them look more like those of a typical lion, rather than the pointed ears seen on zhenmushou.</p><p>The lion likely traveled west along the Silk Road, a trade route that connected China with Europe for centuries. It may have passed through India, Afghanistan, and Iran before arriving in Venice, possibly in pieces, where it was reassembled and modified to fit the standard iconography of the winged lion, a symbol of Venice and Mark the Evangelist. There is no historical record of when or how the lion arrived in Venice, but it was already installed atop the column in St. Mark’s Square by the time Marco Polo returned from China in 1295.</p><figure id="attachment_42825" aria-describedby="caption-attachment-42825"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjgwIiBoZWlnaHQ9IjE1OTkiIHZpZXdCb3g9IjAgMCAxMjgwIDE1OTkiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNjZmQ0ZGI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="1280" height="1599" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg 1280w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-240x300.jpg 240w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-820x1024.jpg 820w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-768x959.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-1230x1536.jpg 1230w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-150x187.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-750x937.jpg 750w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-1140x1424.jpg 1140w" data-sizes="(max-width: 1280px) 100vw, 1280px"></a><figcaption id="caption-attachment-42825">Bronze lion of Saint Marc in Venice. Credit: Jakub Hałun (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>)</figcaption></figure><p>The circumstances of its arrival remain mysterious, with some speculating that the lion could have been brought to Venice by Marco Polo’s father, Nicolò, and his uncle, Maffeo, who visited the Mongol court in Beijing between 1264 and 1266. Others believe it may have arrived earlier, perhaps during a time of intense trade along the Silk Road. The first known reference to the lion dates back to 1293, but its exact journey remains unknown.</p><p>Over the centuries, the lion has undergone several restorations. In the 1790s, Napoleon looted the statue and transported it to Paris, where it was damaged during its return to Venice in 1815. The Venetian sculptor Bartolomeo Ferrari restored the statue, making additions like the lead book beneath its paws, while retaining most of the original structure.</p><p>The lion’s Chinese origins highlight the deep cultural and economic exchanges between East and West. According to researchers from the University of Padua and Ca’ Foscari University, the lion’s journey exemplifies the far-reaching influence of the Silk Road, which connected Eastern Eurasia with Venice and the broader Mediterranean world.</p><p><em><a href="https://www.unipd.it/news/leone-piazza-s-marco-venezia-made-china" target="_blank" rel="noreferrer noopener">University of Padova</a></em></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Post World War II Food (158 pts)]]></title>
            <link>https://www.nps.gov/articles/post-wwii-food.htm</link>
            <guid>41937319</guid>
            <pubDate>Thu, 24 Oct 2024 16:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nps.gov/articles/post-wwii-food.htm">https://www.nps.gov/articles/post-wwii-food.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41937319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cs_control_536382" title=""><div id="cs_control_7575149">
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{122}" paraid="1577140712">World War II brought several changes to what and how we eat. For example, members of the military traveled the globe during World War II, encountering different cuisines. When they returned, they brought back memories of those dishes. French, Italian, and Chinese food soon became popular in America beyond immigrant neighborhoods like Chinatowns and Little Italys.[1]  </p>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{154}" paraid="1144356723">Other changes were spurred by foods included in military rations and food produced using technologies developed during the war. There are also recipes born from rationing and Victory gardens that “stuck.” </p>
</div><div id="cs_control_7575053">
<figure>
<a href="https://en.wikipedia.org/wiki/File:KRation_Breakfast.JPG">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-2-K-Ration.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Black and white with the contents of the K-Ration breakfast arranged in front of the striped box they came in." src="https://www.nps.gov/articles/images/Post-War-Image-2-K-Ration.jpg?maxwidth=650&amp;autorotate=false" title="A K-Ration breakfast. It includes a packet of Nescafe instant coffee, energy biscuits (they look like crackers), gum, a tin of chopped ham and eggs, the key to open the can, and cigarettes. US Army Signal Corps, 1943.">
</picture>
</a>
<figcaption>A K-Ration breakfast. It includes a packet of Nescafe instant coffee, energy biscuits (they look like crackers), gum, a tin of chopped ham and eggs, the key to open the can, and cigarettes. <p>US Army Signal Corps, 1943.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h2 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{122}" paraid="1577140712">The Taste of Rations </h2>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{192}" paraid="1382648765">The US military had a system of rations for feeding troops in the field. This system was designed to “maintain the health and effectiveness” of the troops.[2] K-Rations and C-Rations were both issued to troops in combat. They provided between 3,000 and 3,600 calories per day. Within these rations, soldiers found candy, freeze dried coffee, and canned meat.[3] In civilian life, we know these as M&amp;Ms, instant coffee, and Spam. </p>
<h3 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{232}" paraid="979546918">M&amp;M’s</h3>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{232}" paraid="979546918">M&amp;Ms – the chocolate candy surrounded by a hard candy shell – were patented by Forrest Mars on March 1, 1941. By making a deal with Bruce Murrie of the Hershey Corporation, Mars had access to rationed chocolate. M&amp;M candies, named for the first initials of each partners’ last name, went on sale late in 1941. When the US went to war, Mars got an exclusive contract with the US military to provide M&amp;Ms for C-Rations. The candy was perfect for this use – they traveled well, and because of the candy coating, did not melt at high temperatures. Soldiers returned with a taste for the colorful candies, and M&amp;Ms became available to the general public.[4] </p>
</div><div id="cs_control_7575064">
<figure>
<a href="https://www.flickr.com/photos/nestle/23956997132/in/album-72157662980454395/">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-3-Resize592.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="B&amp;W ad illustrated with a woman and girl in matching aprons. The girl is pouring hot water into a cup. A jar of Nescafe coffee is in the lower right. “A perfect cup of coffee every time. So simple a child can make it. Always delicious, always the same.”" src="https://www.nps.gov/articles/images/Post-War-Image-3-Resize592.jpg?maxwidth=650&amp;autorotate=false" title="A ca. 1945 advertisement for Nescafé proclaims how tasty and easy it is to make. It also reminds buyers that the armed forces are taking nearly all the coffee they can manufacture. Copyright Nestlé S.A. Collection of the Nestlé Historical Archives.">
</picture>
</a>
<figcaption>A ca. 1945 advertisement for Nescafé proclaims how tasty and easy it is to make. It also reminds buyers that the armed forces are taking nearly all the coffee they can manufacture. <p>Copyright Nestlé S.A. Collection of the Nestlé Historical Archives.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{248}" paraid="12913587">Instant Coffee</h3>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{248}" paraid="12913587">Instant (or soluble) coffee existed before World War I. It was a dried, concentrated coffee extract that you prepared by adding hot water to it. In 1936, the Nestlé company developed their Nescafé brand instant coffee. Spurred by a desire to transform surplus coffee beans from Brazil into a quick-to-use, low-waste product, Nestlé discovered a way to make a more flavorful instant coffee. They called it Nescafé, a combination of the words Nestlé and café.[5] In 1941, Nestlé began supplying Nescafé for inclusion in American field rations. When American soldiers returned home after the war, they had a taste for the instant coffee.[6]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{45}" paraid="1227546861">After the war ended, Nestlé provided Nescafé for the care packages sent to Europe and Japan. These packages provided food and other necessities while the countries got back on their feet. This boosted global demand for Nescafé.[7] There is, however, more to the story. During the war, Nestlé companies supplied both the Axis and the Allies. In 2000, the company agreed to pay millions of dollars to settle claims that a German company they purchased used forced labor during the war. [8]  </p>
<h3 paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{77}" paraid="1215181569">Spam</h3>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{77}" paraid="1215181569">Spam is a tinned pork product. It was first introduced by the Hormel company in Austin, Minnesota in 1937. It became entrenched in American culture in World War II, when the US military contracted with Hormel (and other canned meat providers) to supply it for military rations. Hormel estimates they shipped more than 100 million pounds of Spam during the war.[9] Not all those who encountered it loved it – or even enjoyed it. Hormel kept a “scurrilous file” of hate mail from service members who were eating it three times a day. Others refused to even have it in their house decades after the war.[10]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{107}" paraid="577255852">For those on the Pacific home front (including American Samoa, the Philippines, Guam, and Hawai’i), Spam holds a special place. American GIs would share their rations with locals, and it was available for purchase in the post exchanges.[11] When the Japanese incarceration camps in the Philippines and on Guam were liberated by American forces, soldiers found starving prisoners. Many shared their rations on the spot. And with the extensive damage from the war, many Pacific islands were unable to provide enough food for their residents. There were also delays in the transition to commercial shipping, further limiting choices. To feed people, many of whom were on the point of starvation, the US issued rations, including Spam.[12] </p>
<blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{107}" paraid="577255852">“The Chamorro people have this love of Spam, corned beef, and pork and beans because that was the food they were given right after the war… We who were born right after the war, we remember. We grew up eating it every day.” – Linda Calvo, Guam[13]  </p>
</blockquote>
</div><div id="cs_control_7575065">
<figure>
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-4-Visiting-Spam.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Two people in Hawaiian shirts pose beside a smiling character (a can of Spam with a face and legs, wearing sneakers). Behind them are surfboards." src="https://www.nps.gov/articles/images/Post-War-Image-4-Visiting-Spam.jpg?maxwidth=650&amp;autorotate=false" title="Visitors to the Spam Museum in Austin, Minnesota post with a can of Spam. Photo courtesy of Jade Ryerson.">
</picture>
<figcaption>Visitors to the Spam Museum in Austin, Minnesota post with a can of Spam. <p>Photo courtesy of Jade Ryerson. All Rights Reserved.</p></figcaption>
</figure><!-- floating-image alignment  -->
<blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{151}" paraid="970620718">“to the people of Hawaii, Spam meant precious nourishment in a time of uncertainty and chaos. Thus, they prepared it with an immense amount of love. We cut it up, we sautéed it, we simmered with shoyu and sugar; we turned it into something else that was beautiful.”[14]  </p>
</blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{151}" paraid="970620718">In Hawai’i, Spam became popular after the US restricted the fishing industry during the war. They were afraid residents would use the boats to communicate with the Japanese. Because there were so many people of Japanese descent living in the Hawaiian Islands, the federal government could not incarcerate all of them (<a href="https://www.nps.gov/articles/000/terminology-and-the-mass-incarceration-of-japanese-americans-during-world-war-ii.htm" id="CP___PAGEID=7019921,terminology-and-the-mass-incarceration-of-japanese-americans-during-world-war-ii.htm,31093|">like they did for those living along the west coast of the mainland</a>). Instead, the US imposed martial law. Spam and other shelf-stable, shippable foods replaced fresh fish in the Hawaiian diet.[15] </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{176}" paraid="1523779306">Regardless of how it was introduced, Spam has remained an important part of the culture of these places ever since. In Guam, each person eats an average of 16 cans of spam per year, while Hawaiians consume an average of 5 cans per year. It has also been incorporated into regional menus at fast food restaurants like McDonald’s and Wendy’s. For example, you can order Spam, Eggs, and Rice for breakfast in Hawai’i, American Samoa, and Guam.[16] Importing Spam to Pacific islands like the Philippines is expensive. Seeing a can of Spam in these homes suggests they can afford it, or that they have connections to those in the US who send it.[17]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{228}" paraid="772802371">Among Spam’s benefits is that it is shelf stable, and can be eaten cooked or straight out of the can, in case of emergencies like hurricanes.[18] It’s downsides include its role in the dependence of these places on imported canned and processed foods, and the accompanying health impacts such as the prevalence of diabetes and heart disease in these places since the war.[19] </p>
</div><div id="cs_control_7575091">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Spam_Meal.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-5-Spamsilog.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="A color photo showing spamsilog served on a colorful plate. A mug of tea is to the left of the plate." src="https://www.nps.gov/articles/images/Post-War-Image-5-Spamsilog.jpg?maxwidth=650&amp;autorotate=false" title="Spamsilog. Fried Spam served with garlic fried rice and an egg. Photo by Bing Ramos, Quezon City, Philippines. CC-BY-SA 2.0">
</picture>
</a>
<figcaption>Spamsilog. Fried Spam served with garlic fried rice and an egg. <p>Photo by Bing Ramos, Quezon City, Philippines. CC-BY-SA 2.0.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h4 paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{248}" paraid="282757872">Recipes </h4>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{254}" paraid="722523982"><strong>Spam Fried Rice (Guam):</strong> Fry half of a chopped onion until soft. Then add half a can of Spam, cubed, and fry until golden brown. Add 3 cups of cooked rice and fry until it is shiny (about five minutes) before adding 2 teaspoons of soy sauce and frying an additional 5 minutes. Serve on a platter topped with two scrambled eggs (chopped up) and chopped green onions, if desired.[20] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{47}" paraid="1023638739"><strong>Spam Musabi (Hawai’i):</strong> a “sushi” of Spam, sometimes using the Spam can as a form to shape it. There are many versions; this one makes 2 servings, and is modified from the Spam website: In a large skillet, fry two slices of Spam (3/8” thick each) until crispy on each side. Drizzle with a glaze of your choice (for example, a soy-based sauce or sweet ginger sesame sauce – you can buy or make your own). Line the inside and bottom of an empty Spam can that has both ends removed with plastic wrap. Press 1.5oz of cooked white rice (or sushi rice) firmly into the can. The rice can be seasoned with toasted sesame seeds and furikake if desired (furikake is a Japanese rice seasoning. You can buy it, or make your own). Place a slice of the cooked Spam on top of the rice, and press firmly. Remove from the can, and repeat for the second slice. Cut two strips from a sheet of nori (seaweed). If you like the taste of nori, you can cut a wider strip. With the strip of nori laying shiny side down, top it with the pressed Spam and rice. Wrap the nori around it, and repeat with the second piece. Serve immediately.[21] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{81}" paraid="316359139"><strong>Spamsilog (Philippines): </strong>a combination of fried Spam, garlic fried rice, and egg often served for breakfast, especially with banana ketchup.[22] </p>
<h2 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{81}" paraid="316359139">Wartime Food Innovations </h2>
<p>Most wartime food innovations were geared to provide the military with nutritious, easy-to-ship, and long-lasting foods for rations. Some of the innovations made it into production during the war years; others did not. Regardless, several, including powdered cheese and orange juice concentrate went on to shape the civilian food landscape. </p>
</div><div id="cs_control_7575092">
<figure>
<a href="https://collections.si.edu/search/detail/edanmdm:saam_1986.65.277">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-6-Minute-Maid.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Color photo. Can (black, orange, and green) reads “Minute Maid Concentrated Orange Juice. Makes 1-1/2 Pints.” Arms, legs, and feet are colored orange. The hat, also from a can, reads “Minute Maid.” Face made of painted wood." src="https://www.nps.gov/articles/images/Post-War-Image-6-Minute-Maid.jpg?maxwidth=650&amp;autorotate=false" title="An articulated figure made from a Minute Maid concentrated orange juice can, ca. 1950s. When placed on a thin board that was tapped on, these figures “danced.” Collection of the Smithsonian American Art Museum (1986.65.277).">
</picture>
</a>
<figcaption>An articulated figure made from a Minute Maid concentrated orange juice can, ca. 1950s. When placed on a thin board that was tapped on, these figures “danced.” <p>Collection of the Smithsonian American Art Museum, Gift of Herbert Waide Hemphill, Jr. and museum purchase made possible by Ralph Cross Johnson (1986.65.277).</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{107}" paraid="274184130">Powdered Cheese</h3>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{139}" paraid="851445772">Cheese was a convenient way to ship dairy.[23] The military was always looking for ways to reduce the weight and volume of foods as ways to increase how much could be transported at one time.[24] In 1943, USDA scientist George Sanders developed the first real cheese powder. Previous attempts to dehydrate cheese had failed, because the application of heat caused the milk fats to melt and separate. Sanders solved the problem with a two-step process. By first grating the cheese and drying it at a low temperature. This resulted in a barrier forming around the fats. In the second step, the cheese was ground into a powder and dehydrated again before being pressed into cakes.[25] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{191}" paraid="276145264">When the war ended in 1945, the military had huge stockpiles of food, including powdered cheese. The government liquidated these stockpiles, sometimes for pennies on the dollar, to private industry. Companies like Frito (later Frito-Lay), Kraft, and others found ways to use these wartime products. In 1948, the Frito company coated puffed cornmeal pieces with dehydrated cheese, and Cheetos were born.[26] </p>
<h3 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{207}" paraid="1156262895">Orange Juice Concentrate</h3>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{207}" paraid="1156262895">Research began in 1942 for a way to economically ship orange juice to soldiers on the front lines. It was important that they got enough Vitamin C to say healthy. The military had been issuing lemon crystals, but because of their unpleasant taste, soldiers tended to ignore them. Initial attempts to concentrate orange juice left it tasting bland. In 1945, just as the war was ending, the process of making tasty orange juice concentrate was perfected. Fresh juice added to the concentrate restored the taste of fresh juice. The resulting process removed 80% of the water in orange juice. When ready to drink, users only had to add back the water to the frozen concentrate. Producers quickly pivoted the product to the consumer market, and Minute Maid hit the shelves.[27] </p>
</div><div id="cs_control_7575122">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Julia_Child_portrait_by_%C2%A9Lynn_Gilbert,_1978.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-1-Resize358.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Black and white photo of Julia Child standing by her stove. She is tasting something with a spoon. A skillet on her stove has something cooking in it. She has a towel tucked into her apron strings. She is surrounded by cooking utensils." src="https://www.nps.gov/articles/images/Post-War-Image-1-Resize358.jpg?maxwidth=650&amp;autorotate=false" title="Julia Child in her kitchen in 1978. Photo copyright Lynn Gilbert, CC by SA 4.0">
</picture>
</a>
<figcaption>Julia Child in her kitchen in 1978. Julia was in France in World War II working with the Office of Strategic Services (it became the CIA). She fell in love with French food. She learned to cook it there, and brought it back to the US. Her cookbooks and TV shows made it accessible to home cooks. <p>Photo copyright Lynn Gilbert, CC by SA 4.0</p></figcaption>
</figure><!-- floating-image alignment  -->
<h2 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{14}" paraid="149373720">Ration Recipes </h2>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{20}" paraid="555050844">After the war and rationing ended, Americans still faced some challenges in grocery shopping. A lot of foods were being sent to Europe and elsewhere to feed Allies whose farmlands had been devastated or neglected. As food choices and availability improved after the war many Americans compensated for wartime scarcity by eating meat- and butter-rich meals. Grilling a steak became the height of entertaining.[28] But some wartime foods (including some with roots in earlier times of shortage, like the Great Depression) stuck. Among these are stuffed peppers; Kraft macaroni and cheese; and fruit cobbler. </p>
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{74}" paraid="707689482">Stuffed Peppers</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{74}" paraid="707689482">Stuffed peppers (and their close cousins, stuffed cabbage leaves and stuffed tomatoes) were filled with a mixture of a little ground beef extended with rice, seasonings, and other vegetables (which in season, could come right from the cook’s Victory garden). Ground beef was popular during wartime, because it needed fewer ration stamps than other cuts of meat. In one stuffed pepper recipe, a quarter pound of beef made four servings of stuffed peppers.[29] </p>
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{112}" paraid="1760533394">Kraft Macaroni and Cheese</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{112}" paraid="1760533394">Kraft macaroni and cheese was invented in 1937 during the Great Depression, but its popularity boomed during the War. The powder is a cheese sauce that has been partially defatted and dehydrated. By adding milk and/or butter during cooking, you replace the moisture and fats.[30] Kraft macaroni and cheese was inexpensive, filling, and you could get two boxes for a single ration point. It was also quick and easy to make – an important consideration as women who were in the workforce had little time at home.[31] Kraft sold 50 million boxes of its macaroni and cheese during World War II.[32] </p>
</div><div id="cs_control_7575148">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Apple_cobbler.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-7-Apple-Cobbler.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="A square baking pan sitting on top of a white gas stove. In the pan is apple cobbler – slices of apples covered with a thin crust." src="https://www.nps.gov/articles/images/Post-War-Image-7-Apple-Cobbler.jpg?maxwidth=650&amp;autorotate=false" title="Apple cobbler. Wikimedia Commons.">
</picture>
</a>
<figcaption>Apple cobbler. <p>Wikimedia Commons.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{162}" paraid="88193390">Fruit Cobbler</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{162}" paraid="88193390">Fruit cobblers and crisps became popular during World War II. Seasonal fruits made up most of the dish, needing only a little rationed sugar. These desserts had no bottom crust, saving on the butter, lard, or shortening needed. The thin toppings of cake, biscuit, pastry, or crumble used very little fat. The result was a ration-friendly dessert that is still popular.[33] </p>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{180}" paraid="2105063441">Dishes like those described here – from Spamsilog to Fruit Cobbler -- have become staples in American culture. The reasons may include being comfort foods, being inexpensive or easy options when money or time was tight, or perhaps from a sense of patriotism or nostalgia. </p>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{212}" paraid="1922726276"><em>** Any mention of trade names does not imply endorsement of these brands, companies, or products. They are included solely for historical understanding. </em></p>
</div><div id="cs_control_7575173">
<hr>
<p><em>This article was written by Megan E. Springate, Assistant Research Professor, Department of Anthropology, University of Maryland, for the NPS Cultural Resources Office of Interpretation and Education. It was funded by the </em><a href="https://ncph.org/" id="https://ncph.org/|">National Council on Public History's</a><em> cooperative agreement with the National Park Service. </em></p>
<hr>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Skyvern (YC S23) – open-source AI agent for browser automations (243 pts)]]></title>
            <link>https://github.com/Skyvern-AI/Skyvern</link>
            <guid>41936745</guid>
            <pubDate>Thu, 24 Oct 2024 15:51:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Skyvern-AI/Skyvern">https://github.com/Skyvern-AI/Skyvern</a>, See on <a href="https://news.ycombinator.com/item?id=41936745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div dir="auto"><h2 tabindex="-1" dir="auto">
 <a href="https://www.skyvern.com/" rel="nofollow">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern_logo.png">
    <img height="120" src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern_logo_blackbg.png">
  </picture></themed-picture>
 </a>
 <br>
</h2><a id="user-content----------------" aria-label="Permalink: " href="#---------------"></a></div>
<p dir="auto">
🐉 Automate Browser-based workflows using LLMs and Computer Vision 🐉
</p>
<p dir="auto">
  <a href="https://www.skyvern.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/30e5dad0d7d42d3589d13557447b68649394f756261b8aa07003dfa55a6a8297/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f576562736974652d626c75653f6c6f676f3d676f6f676c656368726f6d65266c6f676f436f6c6f723d626c61636b" data-canonical-src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;logoColor=black"></a>
  <a href="https://docs.skyvern.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/902647da8997506912d82ca5388489eb2c5f41bf576e892552b1e6607df85957/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63732d79656c6c6f773f6c6f676f3d676974626f6f6b266c6f676f436f6c6f723d626c61636b" data-canonical-src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;logoColor=black"></a>
  <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow"><img src="https://camo.githubusercontent.com/3c085828c0041e3dbb8564da90484a448cc9834a6b0452d3d95d692b6c533d92/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313231323438363332363335323631373533343f6c6f676f3d646973636f7264266c6162656c3d646973636f7264" data-canonical-src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;label=discord"></a>
  
  <a href="https://github.com/skyvern-ai/skyvern"><img src="https://camo.githubusercontent.com/654dadaebf01f1b41e35b7870319ece6693b4bceacd2fc860f589cad13737767/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736b797665726e2d61692f736b797665726e" data-canonical-src="https://img.shields.io/github/stars/skyvern-ai/skyvern"></a>
  <a href="https://github.com/Skyvern-AI/skyvern/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/3d0723f2a77501a1715ecc8a9c350c1501c02d9140d6ff630af7692d24261a7c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f736b797665726e2d61692f736b797665726e" data-canonical-src="https://img.shields.io/github/license/skyvern-ai/skyvern"></a>
  <a href="https://twitter.com/skyvernai" rel="nofollow"><img src="https://camo.githubusercontent.com/aa77bd615cc96f559d58865f90c8ba4e9e5afbea043e312ebeff1079b6aff9e5/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f736b797665726e61693f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/follow/skyvernai?style=social"></a>
  <a href="https://www.linkedin.com/company/95726232" rel="nofollow"><img src="https://camo.githubusercontent.com/ad4bbddfd4c0b43f42830b8919b58aa0759ac46b89ab2f3a6386a542a8d79bc4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f77253230206f6e2532304c696e6b6564496e2d3841324245323f6c6f676f3d6c696e6b6564696e" data-canonical-src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin"></a>
</p>
<p dir="auto"><a href="https://www.skyvern.com/" rel="nofollow">Skyvern</a> automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/geico_shu_recording_cropped.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/geico_shu_recording_cropped.gif" data-animated-image=""></a>
</p>
<p dir="auto">Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.</p>
<p dir="auto">Instead of only relying on code-defined XPath interactions, Skyvern relies on prompts in addition to computer vision and LLMs to the mix to parse items in the viewport in real-time, create a plan for interaction and interact with them.</p>
<p dir="auto">This approach gives us a few advantages:</p>
<ol dir="auto">
<li>Skyvern can operate on websites it’s never seen before, as it’s able to map visual elements to actions necessary to complete a workflow, without any customized code</li>
<li>Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate</li>
<li>Skyvern is able to take a single workflow and apply it to a large number of websites, as it’s able to reason through the interactions necessary to complete the workflow</li>
<li>Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include:
<ol dir="auto">
<li>If you wanted to get an auto insurance quote from Geico, the answer to a common question “Were you eligible to drive at 18?” could be inferred from the driver receiving their license at age 16</li>
<li>If you were doing competitor analysis, it’s understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)</li>
</ol>
</li>
</ol>
<p dir="auto">Want to see examples of Skyvern in action? Jump to <a href="#real-world-examples-of-skyvern">#real-world-examples-of-skyvern</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">Skyvern was inspired by the Task-Driven autonomous agent design popularized by <a href="https://github.com/yoheinakajima/babyagi">BabyAGI</a> and <a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a> -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like <a href="https://playwright.dev/" rel="nofollow">Playwright</a>.</p>
<p dir="auto">Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:</p>
<ol dir="auto">
<li><strong>Interactable Element Agent</strong>: This agent is responsible for parsing the HTML of a website and extracting the interactable elements.</li>
<li><strong>Navigation Agent</strong>: This agent is responsible for planning the navigation to complete a task. Examples include clicking buttons, inserting text, selecting options, etc.</li>
<li><strong>Data Extraction Agent</strong>: This agent is responsible for extracting data from a website. It's capable of reading the tables and text on the page, and extract the output in a user-defined structured format</li>
<li><strong>Password Agent</strong>: This agent is responsible for filling out password forms on a website. It's capable of reading the username and password from a password manager, and filling out the form while preserving the privacy of the user-defined secrets.</li>
<li><strong>2FA Agent</strong>: This agent is responsible for filling out 2FA forms on a website. It's capable of  intercepting website requests for 2FAs, and either requesting user-defined APIs for 2FA codes or waiting for users to feed 2FA codes into it, and then completing the login process.</li>
<li><strong>Dynamic Auto-complete Agent</strong>: This agent is responsible for filling out dynamic auto-complete forms on a website. It's capable of reading the options presented to it, and selecting the appropriate option based on the user's input, adjusting its inputs based on the feedback from inside the form. Popular examples include: Address forms, university dropdowns, and more.</li>
</ol>
<themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern-system-diagram-dark.png">
  <img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern-system-diagram-light.png">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>

<details open="">
  <summary>
    
    <span aria-label="Video description skyvern_demo_video_v2.1.mp4">skyvern_demo_video_v2.1.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/3853670/379523585-5cab4668-e8e2-4982-8551-aab05ff73a7f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk3OTQ5MDMsIm5iZiI6MTcyOTc5NDYwMywicGF0aCI6Ii8zODUzNjcwLzM3OTUyMzU4NS01Y2FiNDY2OC1lOGUyLTQ5ODItODU1MS1hYWIwNWZmNzNhN2YubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjRUMTgzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmVjNzhiZjhlOTk3ZTA0OTIzZThhYjgzNTQ0ZTY5YzkwNTM0ZDcwYjc4OTRmMjlhY2Q2MTYxY2VjMGY2MDllNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.jL15GNKDNigdn3d4arUZbid6fXasRWswQCEWMvXW8DI" data-canonical-src="https://private-user-images.githubusercontent.com/3853670/379523585-5cab4668-e8e2-4982-8551-aab05ff73a7f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk3OTQ5MDMsIm5iZiI6MTcyOTc5NDYwMywicGF0aCI6Ii8zODUzNjcwLzM3OTUyMzU4NS01Y2FiNDY2OC1lOGUyLTQ5ODItODU1MS1hYWIwNWZmNzNhN2YubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjRUMTgzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmVjNzhiZjhlOTk3ZTA0OTIzZThhYjgzNTQ0ZTY5YzkwNTM0ZDcwYjc4OTRmMjlhY2Q2MTYxY2VjMGY2MDllNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.jL15GNKDNigdn3d4arUZbid6fXasRWswQCEWMvXW8DI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Cloud</h2><a id="user-content-skyvern-cloud" aria-label="Permalink: Skyvern Cloud" href="#skyvern-cloud"></a></p>
<p dir="auto">We offer a managed cloud version of Skyvern that allows you to run Skyvern without having to manage the infrastructure. It allows to you run multiple Skyvern instances in parallel to automate your workflows at scale. In addition, Skyvern cloud comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solving to allow you to complete more complicated workflows.</p>
<p dir="auto">If you'd like to try it out,</p>
<ol dir="auto">
<li>Navigate to <a href="https://app.skyvern.com/" rel="nofollow">app.skyvern.com</a></li>
<li>Create an account &amp; Get $5 of credits on us</li>
<li>Kick off your first task and see Skyvern in action!</li>
</ol>
<p dir="auto">Here are some tips that may help you on your adventure:</p>
<ol dir="auto">
<li>Skyvern is really good at carrying out a single goal. If you give it too many instructions to do, it has a high likelihood of getting confused along the way.</li>
<li>Being really explicit about goals is very important. For example, if you're generating an insurance quote, let it know very clearly how it can identify it's accomplished its goals. Use words like "COMPLETE" or "TERMINATE" to indicate success and failure modes, respectively.</li>
<li>Workflows can be used if you'd like to do more advanced things such as chaining multiple instructions together, or securely logging in. If you need any help with this, please feel free to book some time with us! We're always happy to help</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">This quickstart guide will walk you through getting Skyvern up and running on your local machine.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker Compose setup (Recommended)</h2><a id="user-content-docker-compose-setup-recommended" aria-label="Permalink: Docker Compose setup (Recommended)" href="#docker-compose-setup-recommended"></a></p>
<ol dir="auto">
<li>Make sure you have <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">Docker Desktop</a> installed and running on your machine</li>
<li>Make sure you don't have postgres running locally (Run <code>docker ps</code> to check)</li>
<li>Clone the repository and navigate to the root directory</li>
<li>Fill in the LLM provider key on the <a href="https://github.com/Skyvern-AI/skyvern/blob/main/docker-compose.yml">docker-compose.yml</a>. <em>If you want to run skyvern on a remote server, make sure you set the correct server ip for the UI container in <a href="https://github.com/Skyvern-AI/skyvern/blob/main/docker-compose.yml">docker-compose.yml</a>.</em></li>
<li>Run the following command via the commandline:

</li>
<li>Navigate to <code>http://localhost:8080</code> in your browser to start using the UI</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Full Setup (Contributors) - Prerequisites</h2><a id="user-content-full-setup-contributors---prerequisites" aria-label="Permalink: Full Setup (Contributors) - Prerequisites" href="#full-setup-contributors---prerequisites"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji> MAKE SURE YOU ARE USING PYTHON 3.11 <g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji></h3><a id="user-content-warning-warning-make-sure-you-are-using-python-311-warning-warning" aria-label="Permalink: :warning: :warning: MAKE SURE YOU ARE USING PYTHON 3.11 :warning: :warning:" href="#warning-warning-make-sure-you-are-using-python-311-warning-warning"></a></p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji> Only well-tested on MacOS <g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji></p>
<p dir="auto">Before you begin, make sure you have the following installed:</p>
<ul dir="auto">
<li><a href="https://brew.sh/" rel="nofollow">Brew (if you're on a Mac)</a></li>
<li><a href="https://python-poetry.org/docs/#installation" rel="nofollow">Poetry</a>
<ul dir="auto">
<li><code>brew install poetry</code></li>
</ul>
</li>
<li><a href="https://nodejs.org/en/download/" rel="nofollow">node</a></li>
<li><a href="https://docs.docker.com/engine/install/" rel="nofollow">Docker</a></li>
</ul>
<p dir="auto">Note: Our setup script does these two for you, but they are here for reference.</p>
<ul dir="auto">
<li><a href="https://www.python.org/downloads/" rel="nofollow">Python 3.11</a>
<ul dir="auto">
<li><code>poetry env use 3.11</code></li>
</ul>
</li>
<li><a href="https://www.postgresql.org/download/" rel="nofollow">PostgreSQL 14</a> (if you're on a Mac, setup script will install it for you if you have homebrew installed)
<ul dir="auto">
<li><code>brew install postgresql</code></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup (Contributors)</h2><a id="user-content-setup-contributors" aria-label="Permalink: Setup (Contributors)" href="#setup-contributors"></a></p>
<ol dir="auto">
<li>Clone the repository and navigate to the root directory</li>
<li>Open Docker Desktop (Works for Windows, macOS, and Linux) or run Docker Daemon</li>
<li>Run the setup script to install the necessary dependencies and setup your environment

</li>
<li>Start the server

</li>
<li>You can start sending requests to the server, but we built a simple UI to help you get started. To start the UI, run the following command:

</li>
<li>Navigate to <code>http://localhost:8080</code> in your browser to start using the UI</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional Setup for Contributors</h2><a id="user-content-additional-setup-for-contributors" aria-label="Permalink: Additional Setup for Contributors" href="#additional-setup-for-contributors"></a></p>
<p dir="auto">If you're looking to contribute to Skyvern, you'll need to install the pre-commit hooks to ensure code quality and consistency. You can do this by running the following command:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Functionality</h2><a id="user-content-supported-functionality" aria-label="Permalink: Supported Functionality" href="#supported-functionality"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Tasks</h2><a id="user-content-skyvern-tasks" aria-label="Permalink: Skyvern Tasks" href="#skyvern-tasks"></a></p>
<p dir="auto">Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.</p>
<p dir="auto">Tasks require you to specify a <code>url</code>, <code>navigation_goal</code>, and optionally <code>data_extraction_goal</code> if you'd like to extract data from the website, and a <code>navigation_payload</code> if you'd like to provide additional context to help Skyvern fill information or answer questions presented by a website.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/task_creation_form_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/task_creation_form_example.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Workflows</h2><a id="user-content-skyvern-workflows" aria-label="Permalink: Skyvern Workflows" href="#skyvern-workflows"></a></p>
<p dir="auto">Workflows are a way to chain multiple tasks together to form a cohesive unit of work.</p>
<p dir="auto">For example, if you wanted to download all invoics newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligilble invoices, and iterated through each invoice to download it.</p>
<p dir="auto">Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, added it to cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.</p>
<p dir="auto">Supported workflow features include:</p>
<ol dir="auto">
<li>Tasks (+ chained tasks)</li>
<li>Loops</li>
<li>File parsing</li>
<li>Uploading files to block storage</li>
<li>Sending emails</li>
<li>Text Prompts</li>
<li>(Coming soon) Conditionals</li>
<li>(Coming soon) Custom Code Block</li>
</ol>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/invoice_downloading_workflow_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/invoice_downloading_workflow_example.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Livestreaming</h2><a id="user-content-livestreaming" aria-label="Permalink: Livestreaming" href="#livestreaming"></a></p>
<p dir="auto">Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Form Filling</h2><a id="user-content-form-filling" aria-label="Permalink: Form Filling" href="#form-filling"></a></p>
<p dir="auto">Skyvern is natively capable of filling out form inputs on websites. Passing in information via the <code>navigation_goal</code> or <code>navigation_payload</code> will allow Skyvern to comprehend the information and fill out the form accordingly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data Extraction</h2><a id="user-content-data-extraction" aria-label="Permalink: Data Extraction" href="#data-extraction"></a></p>
<p dir="auto">Skyvern is also capable of extracting data from a website. Specifying a <code>data_extraction_goal</code> will allow Skyvern to extract the data and return it to you in the response.</p>
<p dir="auto">You can also specify a <code>data_extraction_schema</code> to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">File Downloading</h2><a id="user-content-file-downloading" aria-label="Permalink: File Downloading" href="#file-downloading"></a></p>
<p dir="auto">Skyvern is also capable of downloading files from a website. Specifying a <code>file_download_goal</code> will allow Skyvern to download the file and return a link to the file in the response.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Authentication</h2><a id="user-content-authentication" aria-label="Permalink: Authentication" href="#authentication"></a></p>
<p dir="auto">Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Password Manager Integrations</h3><a id="user-content-password-manager-integrations" aria-label="Permalink: Password Manager Integrations" href="#password-manager-integrations"></a></p>
<p dir="auto">Skyvern currently supports the following password manager integrations:</p>
<ul>
<li> Bitwarden</li>
<li> 1Password</li>
<li> LastPass</li>
</ul>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/secure_password_task_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/secure_password_task_example.png"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2FA</h3><a id="user-content-2fa" aria-label="Permalink: 2FA" href="#2fa"></a></p>
<p dir="auto">Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.</p>
<p dir="auto">Examples include:</p>
<ol dir="auto">
<li>QR-based 2FA (e.g. Google Authenticator, Authy)</li>
<li>Email based 2FA</li>
<li>SMS based 2FA</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Real-world examples of Skyvern</h2><a id="user-content-real-world-examples-of-skyvern" aria-label="Permalink: Real-world examples of Skyvern" href="#real-world-examples-of-skyvern"></a></p>
<p dir="auto">We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!</p>
<p dir="auto">You'll need to have Skyvern running locally if you want to try these examples out. Please run the following command after going through the quickstart guide:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Invoice Downloading on many different websites</h2><a id="user-content-invoice-downloading-on-many-different-websites" aria-label="Permalink: Invoice Downloading on many different websites" href="#invoice-downloading-on-many-different-websites"></a></p>
<p dir="auto"><a href="https://meetings.hubspot.com/skyvern/demo" rel="nofollow">Book a demo to see it live</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/invoice_downloading.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/invoice_downloading.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Automate the job application process</h2><a id="user-content-automate-the-job-application-process" aria-label="Permalink: Automate the job application process" href="#automate-the-job-application-process"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/job_application" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/job_application_demo.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/job_application_demo.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Automate materials procurement for a manufacturing company</h2><a id="user-content-automate-materials-procurement-for-a-manufacturing-company" aria-label="Permalink: Automate materials procurement for a manufacturing company" href="#automate-materials-procurement-for-a-manufacturing-company"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/finditparts" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/finditparts_recording_crop.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/finditparts_recording_crop.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Navigating to government websites to register accounts or fill out forms</h2><a id="user-content-navigating-to-government-websites-to-register-accounts-or-fill-out-forms" aria-label="Permalink: Navigating to government websites to register accounts or fill out forms" href="#navigating-to-government-websites-to-register-accounts-or-fill-out-forms"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/california_edd" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/edd_services.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/edd_services.gif" data-animated-image=""></a>
</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Filling out random contact us forms</h2><a id="user-content-filling-out-random-contact-us-forms" aria-label="Permalink: Filling out random contact us forms" href="#filling-out-random-contact-us-forms"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/contact_us_forms" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/contact_forms.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/contact_forms.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Retrieving insurance quotes from insurance providers in any language</h2><a id="user-content-retrieving-insurance-quotes-from-insurance-providers-in-any-language" aria-label="Permalink: Retrieving insurance quotes from insurance providers in any language" href="#retrieving-insurance-quotes-from-insurance-providers-in-any-language"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/bci_seguros" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/bci_seguros_recording.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/bci_seguros_recording.gif" data-animated-image=""></a>
</p>
<p dir="auto"><a href="https://app.skyvern.com/create/geico" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/geico_shu_recording_cropped.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/geico_shu_recording_cropped.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">More extensive documentation can be found on our <a href="https://docs.skyvern.ai/" rel="nofollow">documentation website</a>. Please let us know if something is unclear or missing by opening an issue or reaching out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported LLMs</h2><a id="user-content-supported-llms" aria-label="Permalink: Supported LLMs" href="#supported-llms"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Provider</th>
<th>Supported Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpenAI</td>
<td>gpt4-turbo, gpt-4o, gpt-4o-mini</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)</td>
</tr>
<tr>
<td>Azure OpenAI</td>
<td>Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)</td>
</tr>
<tr>
<td>AWS Bedrock</td>
<td>Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)</td>
</tr>
<tr>
<td>Ollama</td>
<td>Coming soon (contributions welcome)</td>
</tr>
<tr>
<td>Gemini</td>
<td>Coming soon (contributions welcome)</td>
</tr>
<tr>
<td>Llama 3.2</td>
<td>Coming soon (contributions welcome)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Environment Variables</h4><a id="user-content-environment-variables" aria-label="Permalink: Environment Variables" href="#environment-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
<th>Type</th>
<th>Sample Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ENABLE_OPENAI</code></td>
<td>Register OpenAI models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_ANTHROPIC</code></td>
<td>Register Anthropic models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_AZURE</code></td>
<td>Register Azure OpenAI models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_BEDROCK</code></td>
<td>Register AWS Bedrock models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>LLM_KEY</code></td>
<td>The name of the model you want to use</td>
<td>String</td>
<td>Currently supported llm keys: <code>OPENAI_GPT4_TURBO</code>, <code>OPENAI_GPT4V</code>, <code>OPENAI_GPT4O</code>, <code>OPENAI_GPT4O_MINI</code>, <code>ANTHROPIC_CLAUDE3</code>, <code>ANTHROPIC_CLAUDE3_OPUS</code>, <code>ANTHROPIC_CLAUDE3_SONNET</code>, <code>ANTHROPIC_CLAUDE3_HAIKU</code>, <code>ANTHROPIC_CLAUDE3.5_SONNET</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_OPUS</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_SONNET</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_HAIKU</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3.5_SONNET</code>, <code>AZURE_OPENAI</code></td>
</tr>
<tr>
<td><code>OPENAI_API_KEY</code></td>
<td>OpenAI API Key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>OPENAI_API_BASE</code></td>
<td>OpenAI API Base, optional</td>
<td>String</td>
<td><code>https://openai.api.base</code></td>
</tr>
<tr>
<td><code>OPENAI_ORGANIZATION</code></td>
<td>OpenAI Organization ID, optional</td>
<td>String</td>
<td><code>your-org-id</code></td>
</tr>
<tr>
<td><code>ANTHROPIC_API_KEY</code></td>
<td>Anthropic API key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>AZURE_API_KEY</code></td>
<td>Azure deployment API key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>AZURE_DEPLOYMENT</code></td>
<td>Azure OpenAI Deployment Name</td>
<td>String</td>
<td><code>skyvern-deployment</code></td>
</tr>
<tr>
<td><code>AZURE_API_BASE</code></td>
<td>Azure deployment api base url</td>
<td>String</td>
<td><code>https://skyvern-deployment.openai.azure.com/</code></td>
</tr>
<tr>
<td><code>AZURE_API_VERSION</code></td>
<td>Azure API Version</td>
<td>String</td>
<td><code>2024-02-01</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature Roadmap</h2><a id="user-content-feature-roadmap" aria-label="Permalink: Feature Roadmap" href="#feature-roadmap"></a></p>
<p dir="auto">This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.</p>
<ul>
<li> <strong>Open Source</strong> - Open Source Skyvern's core codebase</li>
<li> <strong>[BETA] Workflow support</strong> - Allow support to chain multiple Skyvern calls together</li>
<li> <strong>Improved context</strong> - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt</li>
<li> <strong>Cost Savings</strong> - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern</li>
<li> <strong>Self-serve UI</strong> - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern</li>
<li> <strong>Workflow UI Builder</strong> - Introduce a UI to allow users to build and analyze workflows visually</li>
<li> <strong>Chrome Viewport streaming</strong> - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)</li>
<li> <strong>Past Runs UI</strong> - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results</li>
<li> <strong>Prompt Caching</strong> - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)</li>
<li> <strong>Web Evaluation Dataset</strong> - Integrate Skyvern with public benchmark tests to track the quality our models over time</li>
<li> <strong>Improved Debug mode</strong> - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt</li>
<li> <strong>Auto workflow builder ("Observer") mode</strong> - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows</li>
<li> <strong>Chrome Extension</strong> - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)</li>
<li> <strong>Skyvern Action Recorder</strong> - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it</li>
<li> <strong>Interactable Livestream</strong> - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)</li>
<li> <strong>Integrate LLM Observability tools</strong> - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time</li>
<li> <strong>Langchain Integration</strong> - Create langchain integration in langchain_community to use Skyvern as a "tool".</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.
Please have a look at our <a href="https://github.com/Skyvern-AI/skyvern/blob/main/CONTRIBUTING.md">contribution guide</a> and
<a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22">"Help Wanted" issues</a> to get started!</p>
<p dir="auto">If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out <a href="https://sage.storia.ai/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=skyvern-readme" rel="nofollow">Code Sage</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Telemetry</h2><a id="user-content-telemetry" aria-label="Permalink: Telemetry" href="#telemetry"></a></p>
<p dir="auto">By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the <code>SKYVERN_TELEMETRY</code> environment variable to <code>false</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the <a href="https://github.com/Skyvern-AI/skyvern/blob/main/LICENSE">AGPL-3.0 License</a>, with the exception of anti-bot measures available in our managed cloud offering.</p>
<p dir="auto">If you have any questions or concerns around licensing, please <a href="mailto:founders@skyvern.com">contact us</a> and we would be happy to help.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://star-history.com/#Skyvern-AI/skyvern&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/27c8134ddcfec58a858504b3025ae5f5bf39afb638f19eea8b9aeaf1ed42b5a6/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d536b797665726e2d41492f736b797665726e26747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;type=Date"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lost Silk Road Cities Discovered High in the Mountains of Central Asia (108 pts)]]></title>
            <link>https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/</link>
            <guid>41936316</guid>
            <pubDate>Thu, 24 Oct 2024 15:12:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/">https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/</a>, See on <a href="https://news.ycombinator.com/item?id=41936316">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block="sciam/paragraph">Hidden in the towering mountains of Central Asia, along what has been called <a href="https://www.scientificamerican.com/article/archaeologists-uncover-another-branch-of-the-silk-road/">the Silk Road</a>, archaeologists are <a href="https://www.scientificamerican.com/article/archaeologists-uncover-another-branch-of-the-silk-road/">uncovering</a> two medieval cities that may have bustled with inhabitants a thousand years ago.</p><p data-block="sciam/paragraph">A team first noticed one of the lost cities in 2011 while hiking the grassy mountains of eastern Uzbekistan in search of untold history. The archaeologists trekked along the riverbed and spotted burial sites along the way to the top of one of the mountains. Once there, a plateau dotted with strange mounds spread before them. To the untrained eye, these mounds wouldn't have looked like much. But “as archaeologists..., [we] recognize them as anthropogenic places, as places where people live,” says Farhod Maksudov of the National Center of Archaeology of the Uzbekistan Academy of Sciences.</p><p data-block="sciam/paragraph">The ground, too, was littered with thousands of pottery shards. “We were kind of blown away,” says Michael Frachetti, an archaeologist at Washington University in St. Louis. He and Maksudov had been in search of archaeological evidence of nomadic cultures that grazed their herds on the mountain pastures. The researchers never expected to find a 30-acre medieval city in a relatively inhospitable climate around 7,000 feet above sea level.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">But this site, called Tashbulak, after the area’s present-day name, was only the beginning. While excavating in 2015, Frachetti met with one of the region’s only current inhabitants—a forestry inspector who lives with his family a few miles from Tashbulak. “He said, ‘In my backyard, I’ve seen ceramics like that,’” Frachetti recalls. So the archaeologists drove to the forestry inspector’s farmstead, where they found that his home rested on a familiar-looking mound.</p><p data-block="sciam/paragraph">“Sure enough, he’s living on a medieval citadel,” Frachetti says. From there, the researchers looked out at the landscape and saw even more mounds. “And we’re like, ‘Oh my gosh, this place is humongous,’” Frachetti adds.</p><p data-block="sciam/paragraph">This second site, named Tugunbulak, is <a href="http://dx.doi.org/10.1038/s41586-024-08086-5">described for the first time</a> in a study published on October 23 in <i>Nature. </i>The researchers used remote-sensing technology to map what they describe as a sprawling, nearly 300-acre medieval city three miles from Tashbulak that was integrated into the network of trade routes known as the Silk Road.</p><p data-block="sciam/paragraph">“It’s a pretty remarkable discovery,” says Zachary Silvia, an archaeologist at Brown University, who researches this period of Central Asian history and culture. (Silvia was not involved in the new work, but he authored a <a href="https://doi.org/10.1038/d41586-024-03315-3">commentary</a> about it that was published in the same issue of <i>Nature.</i>) Though more excavations are needed to confirm Tugunbulak’s scope and density, “even if it turns out to be half the size [estimated here], that’s still a huge discovery,” he says—and one that could force a rethink of just how sprawling the Silk Road networks were.</p><figure data-block="contentful/image"><picture><source media="(min-width: 750px)" srcset="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=600 600w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=750 750w" sizes="(min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Map shows the conventional representation of the Silk Routes through Asia and marks the location of Tugunbulak and Tashbulak in the mountains of southeastern Uzbekistan." decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900" width="2917" height="1750" srcset="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=600 600w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=750 750w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption></figcaption></figure><p data-block="sciam/paragraph">On conventional maps of the Silk Road, trade routes spanning the Eurasian continent tend to avoid the mountains of Central Asia as much as possible. Low-lying cities such as Samarkand and Tashkent, which have the arable land and irrigation necessary to support their bustling populations, are seen as having been the real destinations for trade. On the other hand, the nearby Pamir mountains, where Tashbulak and Tugunbulak are located, are rugged and mostly nonarable because of their elevation. (Today less than 3 percent of the world’s population lives more than 2,000 meters, or about 6,500 feet, above sea level.)</p><p data-block="sciam/paragraph">Yet despite the limited resources and frigid winters, people did live at Tashbulak and Tugunbulak from the eighth to 11th centuries C.E., during the Middle Ages. Eventually, whether slowly or all at once, the settlements were abandoned and left to the elements. In the mountains, the landscape changed quickly, and the remains of the cities were worn down by erosion and blanketed with sediment. A thousand years later, what’s left are mounds, plateaus and ridges that are hard to map comprehensively with the naked eye.</p><figure data-block="contentful/image" data-disable-apple-news="true"><picture><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=600 600w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=750 750w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Drone view of grassy mountain peaks" decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900" width="3413" height="1920" srcset="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=600 600w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=750 750w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption><p>A drone view of Tugunbulak.</p><p>M. Frachetti</p></figcaption></figure><p data-block="sciam/paragraph">To get a detailed lay of the land, Frachetti and Maksudov equipped a drone with remote-sensing technology called lidar (light detection and ranging). Drones are tightly regulated in Uzbekistan, but the researchers managed to get the necessary permits to fly one at the site. A lidar scanner uses laser pulses to map the features of land below. The technology has been increasingly used in archaeology—in the past few years it has helped uncover a <a href="https://www.scientificamerican.com/article/lasers-reveal-massive-650-square-mile-maya-site-hidden-beneath-guatemalan-rainforest/">lost Maya city sprawling beneath the rainforest canopy</a> in Guatemala.</p><p data-block="sciam/paragraph">At Tashbulak and Tugunbulak, the result was a relief map of the sites with inch-level detail. With the help of computer algorithms, manual tracings and excavations, the researchers mapped out subtle ridges that likely represented walls and other buried structures.</p><p data-block="sciam/paragraph">This method has its limitations, Silvia says—namely, it often turns up false positives. It’s also impossible to confirm which features come from which time period without more excavation. Such work has been ongoing at Tashbulak but has only just begun at Tugunbulak. (The scans and some excavation were completed in 2022, and Frachetti’s team returned to Tugunbulak this past summer to continue excavation. The researchers have yet to publish their findings.) For now, the lidar map of Tugunbulak appears to show a massive medieval complex, complete with a citadel, buildings, courtyards, plazas and pathways, bounded by fortified walls. Along with pottery, the team has excavated kilns, as well as clues that workers in the city smelted iron ores, Frachetti says.</p><figure data-block="contentful/image" data-disable-apple-news="true"><picture><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=600 600w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=750 750w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Archeologists excavate a large medieval pot" decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900" width="2881" height="1920" srcset="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=600 600w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=750 750w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption><p>Medieval pottery excavated at Tugunbulak.</p><p>M. Frachetti</p></figcaption></figure><p data-block="sciam/paragraph">Metallurgy may be a key part of how the city could sustain itself at such a high altitude. The mountains are rich in iron ore and have dense juniper forests, which could be burned to fuel the smelting process. The researchers have also uncovered coins from across modern-day Uzbekistan, Maksudov says, suggesting the city may have been a hub for trade. It doesn’t appear to have been strictly a mining settlement, either—at Tashbulak, a cemetery contains the remains of women, elderly people and infants.</p><p data-block="sciam/paragraph">“We have realized that this was a large urban center, which was integrated into the Silk Road network and dragged the Silk Road caravans toward mountains ... because they had their own products to offer,” Maksudov says.</p><p data-block="sciam/paragraph">“There is a relationship between these cities” in the highlands and those in the lowlands, says Sanjyot Mehendale, an archaeologist and chair of the Tang Center for Silk Road Studies at the University of California, Berkeley. The trading networks of the Silk Road were “very, very fluid,” and societies once considered peripheral and remote, such as those of Tashbulak and Tugunbulak, “were part of a network that stretched all across Eurasia,” she says. “You can no longer look at these areas and perceive them as remote or less developed.”</p><p data-block="sciam/paragraph">Mehendale became involved with the work at Tugunbulak after the lidar study was completed, and she went to the site to excavate this past summer. She’s now most interested in reconstructing what the city was like across its life span. Who were the inhabitants? How did the population change over seasons or centuries?</p><p data-block="sciam/paragraph">The answers to all these questions are likely there, buried in the sediment. The research team, Silvia says, “has got a lifetime of work.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JetBrains Rider is now free for non-commercial use (665 pts)]]></title>
            <link>https://www.jetbrains.com/rider/</link>
            <guid>41936001</guid>
            <pubDate>Thu, 24 Oct 2024 14:43:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jetbrains.com/rider/">https://www.jetbrains.com/rider/</a>, See on <a href="https://news.ycombinator.com/item?id=41936001">Hacker News</a></p>
<div id="readability-page-1" class="page">

        <!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->

<div class="page">
    
            <div>
            







  <div id="js-menu-second">
        

        <div id="js-menu-second-desktop">
            <div>
                <p><a href="https://www.jetbrains.com/rider/">
                    
                    <span>Rider</span>
                </a>
            </p></div>

            <div>
                        
                                                    <p><a href="https://www.jetbrains.com/rider/download/">
                                Download
                            </a>
                                            </p></div>
        </div>
    </div>



        </div>
    
    

            
    </div>

          
      
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Which Animal Shares Your Body Fat Percentage? (138 pts)]]></title>
            <link>https://animalbodyfatmatch.netlify.app/</link>
            <guid>41935166</guid>
            <pubDate>Thu, 24 Oct 2024 13:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animalbodyfatmatch.netlify.app/">https://animalbodyfatmatch.netlify.app/</a>, See on <a href="https://news.ycombinator.com/item?id=41935166">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 2048 turned 10 this year, I built an updated version to celebrate (466 pts)]]></title>
            <link>https://play2048.co</link>
            <guid>41934746</guid>
            <pubDate>Thu, 24 Oct 2024 12:15:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play2048.co">https://play2048.co</a>, See on <a href="https://news.ycombinator.com/item?id=41934746">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Goodbye from a Linux Community Volunteer (208 pts)]]></title>
            <link>https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/T/#u</link>
            <guid>41932225</guid>
            <pubDate>Thu, 24 Oct 2024 05:29:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/T/#u">https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/T/#u</a>, See on <a href="https://news.ycombinator.com/item?id=41932225">Hacker News</a></p>
<div id="readability-page-1" class="page"><pre><a href="#edef37a4707eca10bf6e3a58271d28767d280c5ee" id="mdef37a4707eca10bf6e3a58271d28767d280c5ee">*</a> <u id="u"><b>linux: Goodbye from a Linux community volunteer</b></u>
<b>@ 2024-10-24  4:27 Serge Semin</b>
  2024-10-24  6:55 ` <a href="#m84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">Reimar Döffinger</a>
  2024-10-24  7:32 ` <a href="#m6a9c83cfd814e024be3dccd02345ed25b61954a1">Philipp Stanner</a>
  <a href="#rdef37a4707eca10bf6e3a58271d28767d280c5ee">0 siblings, 2 replies; 3+ messages in thread</a>
From: Serge Semin @ 2024-10-24  4:27 UTC (<a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/">permalink</a> / <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/raw">raw</a>)
  To: Jon Mason, Dave Jiang, Allen Hubbe, <a href="https://lore.kernel.org/ntb/?t=20241024042750">ntb</a>, Andy Shevchenko,
	Andy Shevchenko, Kory Maincent, Cai Huoqing, <a href="https://lore.kernel.org/dmaengine/?t=20241024042750">dmaengine</a>,
	Mark Brown, <a href="https://lore.kernel.org/linux-spi/?t=20241024042750">linux-spi</a>, Damien Le Moal, <a href="https://lore.kernel.org/linux-ide/?t=20241024042750">linux-ide</a>, Paul Burton,
	Thomas Bogendoerfer, Arnd Bergmann, Jiaxun Yang, <a href="https://lore.kernel.org/linux-mips/?t=20241024042750">linux-mips</a>,
	Bjorn Helgaas, Manivannan Sadhasivam, Yoshihiro Shimoda,
	<a href="https://lore.kernel.org/linux-pci/?t=20241024042750">linux-pci</a>, David S. Miller, Jakub Kicinski, Paolo Abeni,
	Andrew Lunn, Russell King, Vladimir Oltean, Keguang Zhang,
	Yanteng Si, <a href="https://lore.kernel.org/netdev/?t=20241024042750">netdev</a>, Rob Herring, Krzysztof Kozlowski,
	Guenter Roeck, <a href="https://lore.kernel.org/linux-hwmon/?t=20241024042750">linux-hwmon</a>, Borislav Petkov, <a href="https://lore.kernel.org/linux-edac/?t=20241024042750">linux-edac</a>,
	Greg Kroah-Hartman, <a href="https://lore.kernel.org/linux-serial/?t=20241024042750">linux-serial</a>
  Cc: Andrew Halaney, Nikita Travkin, Ivan Kokshaysky, Alexander Shiyan,
	Dmitry Kozlov, Sergey Shtylyov, Evgeniy Dushistov,
	Geert Uytterhoeven, Sergio Paracuellos, Nikita Shubin,
	<a href="https://lore.kernel.org/linux-renesas-soc/?t=20241024042750">linux-renesas-soc</a>, <a href="https://lore.kernel.org/lkml/?t=20241024042750">linux-kernel</a>

Hello Linux-kernel community,

I am sure you have already heard the news caused by the recent Greg' commit
6e90b675cf942e ("MAINTAINERS: Remove some entries due to various compliance
requirements."). As you may have noticed the change concerned some of the
Ru-related developers removal from the list of the official kernel maintainers,
including me.

The community members rightly noted that the _quite_ short commit log contained
very vague terms with no explicit change justification. No matter how hard I
tried to get more details about the reason, alas the senior maintainer I was
discussing the matter with haven't given an explanation to what compliance
requirements that was. I won't cite the exact emails text since it was a private
messaging, but the key words are "sanctions", "sorry", "nothing I can do", "talk
to your (company) lawyer"... I can't say for all the guys affected by the
change, but my work for the community has been purely _volunteer_ for more than
a year now (and less than half of it had been payable before that). For that
reason I have no any (company) lawyer to talk to, and honestly after the way the
patch has been merged in I don't really want to now. Silently, behind everyone's
back, _bypassing_ the standard patch-review process, with no affected
developers/subsystem notified - it's indeed the worse way to do what has been
done. No gratitude, no credits to the developers for all these years of the
devoted work for the community. No matter the reason of the situation but
haven't we deserved more than that? Adding to the GREDITS file at least, no?..

I can't believe the kernel senior maintainers didn't consider that the patch
wouldn't go unnoticed, and the situation might get out of control with
unpredictable results for the community, if not straight away then in the middle
or long term perspective. I am sure there have been plenty ways to solve the
problem less harmfully, but they decided to take the easiest path. Alas what's
done is done. A bifurcation point slightly initiated a year ago has just been
fully implemented. The reason of the situation is obviously in the political
ground which in this case surely shatters a basement the community has been built
on in the first place. If so then God knows what might be next (who else might
be sanctioned...), but the implemented move clearly sends a bad signal to the
Linux community new comers, to the already working volunteers and hobbyists like
me.

Thus even if it was still possible for me to send patches or perform some
reviews, after what has been done my motivation to do that as a volunteer has
simply vanished. (I might be doing a commercial upstreaming in future though).
But before saying goodbye I'd like to express my gratitude to all the community
members I have been lucky to work with during all these years. Specifically:

NTB-folks, Jon, Dave, Allen. NTB was my starting point in the kernel upstream
work. Thanks for the initial advices and despite of very-very-very tough reviews
with several complete patchset refactorings, I learned a lot back then. That
experience helped me afterwards. Thanks a lot for that. BTW since then I've got
several thank-you letters for the IDT NTB and IDT EEPROM drivers. If not for you
it wouldn't have been possible.

Andy, it's hard to remember who else would have given me more on my Linux kernel
journey as you have. We first met in the I2C subsystem review of my DW I2C
driver patches. Afterwards we've got to be frequently meeting here and there -
GPIO, SPI, TTY, DMA, NET, etc, clean/fixes/features patch(set)s. Quite heat
discussions in your first reviews drove me crazy really. But all the time we
managed to come up with some consensus somehow. And you never quit the
discussions calmly explaining your point over and over. You never refused to
provide more detailed justification to your requests/comments even though you
didn't have to. Thanks to that I learned how to be patient to reviewers
and reviewees. And of course thank you for the Linux-kernel knowledges and all
the tips and tricks you shared.

* Andy, please note due to the situation I am not going to work on my DW DMAC
fixes patchset anymore. So if you ever wish to have DW UART stably working with the
DW DMA-engine driver, then feel free to pick the series up:
Link: <a href="https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/">https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/</a>

Linus (Walleij), after you merged one of my pretty much heavy patchset in you
suggested to me to continue the DW APB GPIO driver maintaining. It was a first
time I was asked to maintain a not-my driver. Thank you for the trust. I'll
never forget that.

Mark, thank you very much for entrusting the DW APB SSI driver maintenance to
me. I've put a lot of efforts into making it more generic and less errors-prune,
especially when it comes working under a DMA-engine control or working in the
mem-ops mode. I am sure the results have been beneficial to a lot of DW
SPI-controller users since then.

Damien, our first and last meeting was at my generic AHCI-platform and DW AHCI
SATA driver patches review. You didn't make it a quick and easy path. But still
all the reviews comments were purely on the technical basis, and the patches
were eventually merged in. Thank you for your time and experience I've got from
the reviews.

Paul, Thomas, Arnd, Jiaxun, we met several times in the mailing list during my
MIPS P5600 patches and just generic MIPS patches review. It was always a
pleasure to discuss the matters with such brilliant experts in the field. Alas
I've spent too much time working on the patches for another subsystems and
failed to submit all the MIPS-related bits. Sorry I didn't keep my promise, but
as you can see the circumstances have suddenly drawn its own deadline.

Bjorn, Mani, we were working quite a lot with you in the framework of the DW
PCIe RC drivers. You reviewed my patches. I helped you to review another patches
for some time. Despite of some arguing it was always a pleasure to work with
you.  Mani, special thanks for the cooperative DW eDMA driver maintenance. I
think we were doing a great work together.

Paolo, Jakub, David, Andrew, Vladimir, Russell. The network subsystem and
particularly the STMMAC driver (no doubt the driver sucks) have turned to be a
kind of obstacle on which my current Linux-kernel activity has stopped. I really
hope that at least in some way my help with the incoming STMMAC and DW XPCS
patches reviews lightened up your maintainance duty. I know Russell might
disagree, but I honestly think that all our discussions were useful after all,
at least for me. I also think we did a great work working together with Russell
on the DW GMAC/QoS ETH PCS patches. Hopefully you'll find a time to finish it up
after all. 

Rob, Krzysztof, from your reviews I've learned a lot about the most hardwary part
of the kernel - DT sources and DT-bindings. All your comments have been laconic
and straight to the point. That made reviews quick and easy. Thank you very
much for that.

Guenter, special thanks for reviewing and accepting my patches to the hwmon and
watchdog subsystems. It was pleasure to be working with you.

Borislav, we disagreed and argued a lot. So my DW uMCTL2 DDRC EDAC patches even
got stuck in limbo for quite a long time. Anyway thank you for the time
you spent reviewing my patches and trying to explain your point.

* Borislav, it looks like I won't be able to work on my Synopsys EDAC patchsets
anymore. If you or somebody else could pick them up and finish up the work it
would be great (you can find it in the lore archive). The patches convert the
mainly Zynq(MP)-specific Synopsys EDAC driver to supporting the generic DW
uMCTL2 DDRC. It would be very beneficial for each platform based on that
controller.

Greg, we met several times in the mailing lists. You reviewed my patches sent
for the USB and TTY subsystems, and all the time the process was straight,
highly professional, and simpler than in the most of my other case.
Thank you very much for that.

Yoshihiro, Keguang, Yanteng, Kory, Cai and everybody I was lucky to meet in the
kernel mailing lists, but forgot to mention here. Thank you for the time spent
for our cooperative work on making the Linux kernel better. It was a pleasure to
meet you here.

I also wish to say huge thanks to the community members trying to
defend the kicked off maintainers and for support you expressed in
these days. It means a lot.

A little bit statics of my kernel-work at the end:

Signed-off patches:		518
Reviewed and Acked patches:	253
Tested patches:			80

You might say not the greatest achievement for seven years comparing to some
other developers. Perhaps. But I meant each of these tags, be sure.

I guess that's it. If you ever need some info or consultation regarding the
drivers I used to maintain or the respective hardware or the Synopsys IP-cores
(about which I've got quite comprehensive knowledge by this time), feel free to
reach me out via this email. I am always willing to help to the community
members.

Hope we'll meet someday in more pleasant circumstances and drink a
couple or more beers together. But now it's time to say good bye.
Sorry for a long-read text. I wish good luck on your Linux-way.

Best Regards,
-Serge(y)

<a href="#mdef37a4707eca10bf6e3a58271d28767d280c5ee" id="edef37a4707eca10bf6e3a58271d28767d280c5ee">^</a> <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/">permalink</a> <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/raw">raw</a> <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/#R">reply</a>	[<a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/t/#u">nested</a>] <a href="#rdef37a4707eca10bf6e3a58271d28767d280c5ee">3+ messages in thread</a></pre><hr><pre><a href="#e84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f" id="m84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">*</a> <b>Re: linux: Goodbye from a Linux community volunteer</b>
  2024-10-24  4:27 <a href="#mdef37a4707eca10bf6e3a58271d28767d280c5ee">linux: Goodbye from a Linux community volunteer</a> Serge Semin
<b>@ 2024-10-24  6:55 ` Reimar Döffinger</b>
  2024-10-24  7:32 ` <a href="#m6a9c83cfd814e024be3dccd02345ed25b61954a1">Philipp Stanner</a>
  <a href="#r84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">1 sibling, 0 replies; 3+ messages in thread</a>
From: Reimar Döffinger @ 2024-10-24  6:55 UTC (<a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/">permalink</a> / <a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/raw">raw</a>)
  To: Serge Semin
  Cc: Jon Mason, Dave Jiang, Allen Hubbe, <a href="https://lore.kernel.org/ntb/?t=20241024065657">ntb</a>, Andy Shevchenko,
	Andy Shevchenko, Kory Maincent, Cai Huoqing, <a href="https://lore.kernel.org/dmaengine/?t=20241024065657">dmaengine</a>,
	Mark Brown, <a href="https://lore.kernel.org/linux-spi/?t=20241024065657">linux-spi</a>, Damien Le Moal, <a href="https://lore.kernel.org/linux-ide/?t=20241024065657">linux-ide</a>, Paul Burton,
	Thomas Bogendoerfer, Arnd Bergmann, Jiaxun Yang, <a href="https://lore.kernel.org/linux-mips/?t=20241024065657">linux-mips</a>,
	Bjorn Helgaas, Manivannan Sadhasivam, Yoshihiro Shimoda,
	<a href="https://lore.kernel.org/linux-pci/?t=20241024065657">linux-pci</a>, David S. Miller, Jakub Kicinski, Paolo Abeni,
	Andrew Lunn, Russell King, Vladimir Oltean, Keguang Zhang,
	Yanteng Si, <a href="https://lore.kernel.org/netdev/?t=20241024065657">netdev</a>, Rob Herring, Krzysztof Kozlowski,
	Guenter Roeck, <a href="https://lore.kernel.org/linux-hwmon/?t=20241024065657">linux-hwmon</a>, Borislav Petkov, <a href="https://lore.kernel.org/linux-edac/?t=20241024065657">linux-edac</a>,
	Greg Kroah-Hartman, <a href="https://lore.kernel.org/linux-serial/?t=20241024065657">linux-serial</a>, Andrew Halaney, Nikita Travkin,
	Ivan Kokshaysky, Alexander Shiyan, Dmitry Kozlov, Sergey Shtylyov,
	Evgeniy Dushistov, Geert Uytterhoeven, Sergio Paracuellos,
	Nikita Shubin, <a href="https://lore.kernel.org/linux-renesas-soc/?t=20241024065657">linux-renesas-soc</a>, <a href="https://lore.kernel.org/lkml/?t=20241024065657">linux-kernel</a>

Hello Serge!
I do not have many contributions to show to give it extra weight nor do
I actually know you.
Nevertheless I still wanted to say thank you for your nice message even if
it is for a sad occasion, and share your sentiment of hoping
for more pleasant circumstances.

Best regards,
Reimar

(and apologies if anyone is annoyed by the wide CC list, but I think it's
important for at least some thank yous to be public and nobody else seems
to have written one yet)

<span>&gt; On 24 Oct 2024, at 06:27, Serge Semin &lt;fancer.lancer@gmail.com&gt; wrote:
&gt; 
&gt; Hello Linux-kernel community,
&gt; 
&gt; I am sure you have already heard the news caused by the recent Greg' commit
&gt; 6e90b675cf942e ("MAINTAINERS: Remove some entries due to various compliance
&gt; requirements."). As you may have noticed the change concerned some of the
&gt; Ru-related developers removal from the list of the official kernel maintainers,
&gt; including me.
&gt; 
&gt; The community members rightly noted that the _quite_ short commit log contained
&gt; very vague terms with no explicit change justification. No matter how hard I
&gt; tried to get more details about the reason, alas the senior maintainer I was
&gt; discussing the matter with haven't given an explanation to what compliance
&gt; requirements that was. I won't cite the exact emails text since it was a private
&gt; messaging, but the key words are "sanctions", "sorry", "nothing I can do", "talk
&gt; to your (company) lawyer"... I can't say for all the guys affected by the
&gt; change, but my work for the community has been purely _volunteer_ for more than
&gt; a year now (and less than half of it had been payable before that). For that
&gt; reason I have no any (company) lawyer to talk to, and honestly after the way the
&gt; patch has been merged in I don't really want to now. Silently, behind everyone's
&gt; back, _bypassing_ the standard patch-review process, with no affected
&gt; developers/subsystem notified - it's indeed the worse way to do what has been
&gt; done. No gratitude, no credits to the developers for all these years of the
&gt; devoted work for the community. No matter the reason of the situation but
&gt; haven't we deserved more than that? Adding to the GREDITS file at least, no?..
&gt; 
&gt; I can't believe the kernel senior maintainers didn't consider that the patch
&gt; wouldn't go unnoticed, and the situation might get out of control with
&gt; unpredictable results for the community, if not straight away then in the middle
&gt; or long term perspective. I am sure there have been plenty ways to solve the
&gt; problem less harmfully, but they decided to take the easiest path. Alas what's
&gt; done is done. A bifurcation point slightly initiated a year ago has just been
&gt; fully implemented. The reason of the situation is obviously in the political
&gt; ground which in this case surely shatters a basement the community has been built
&gt; on in the first place. If so then God knows what might be next (who else might
&gt; be sanctioned...), but the implemented move clearly sends a bad signal to the
&gt; Linux community new comers, to the already working volunteers and hobbyists like
&gt; me.
&gt; 
&gt; Thus even if it was still possible for me to send patches or perform some
&gt; reviews, after what has been done my motivation to do that as a volunteer has
&gt; simply vanished. (I might be doing a commercial upstreaming in future though).
&gt; But before saying goodbye I'd like to express my gratitude to all the community
&gt; members I have been lucky to work with during all these years. Specifically:
&gt; 
&gt; NTB-folks, Jon, Dave, Allen. NTB was my starting point in the kernel upstream
&gt; work. Thanks for the initial advices and despite of very-very-very tough reviews
&gt; with several complete patchset refactorings, I learned a lot back then. That
&gt; experience helped me afterwards. Thanks a lot for that. BTW since then I've got
&gt; several thank-you letters for the IDT NTB and IDT EEPROM drivers. If not for you
&gt; it wouldn't have been possible.
&gt; 
&gt; Andy, it's hard to remember who else would have given me more on my Linux kernel
&gt; journey as you have. We first met in the I2C subsystem review of my DW I2C
&gt; driver patches. Afterwards we've got to be frequently meeting here and there -
&gt; GPIO, SPI, TTY, DMA, NET, etc, clean/fixes/features patch(set)s. Quite heat
&gt; discussions in your first reviews drove me crazy really. But all the time we
&gt; managed to come up with some consensus somehow. And you never quit the
&gt; discussions calmly explaining your point over and over. You never refused to
&gt; provide more detailed justification to your requests/comments even though you
&gt; didn't have to. Thanks to that I learned how to be patient to reviewers
&gt; and reviewees. And of course thank you for the Linux-kernel knowledges and all
&gt; the tips and tricks you shared.
&gt; 
&gt; * Andy, please note due to the situation I am not going to work on my DW DMAC
&gt; fixes patchset anymore. So if you ever wish to have DW UART stably working with the
&gt; DW DMA-engine driver, then feel free to pick the series up:
&gt; Link: <a href="https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/">https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/</a>
&gt; 
&gt; Linus (Walleij), after you merged one of my pretty much heavy patchset in you
&gt; suggested to me to continue the DW APB GPIO driver maintaining. It was a first
&gt; time I was asked to maintain a not-my driver. Thank you for the trust. I'll
&gt; never forget that.
&gt; 
&gt; Mark, thank you very much for entrusting the DW APB SSI driver maintenance to
&gt; me. I've put a lot of efforts into making it more generic and less errors-prune,
&gt; especially when it comes working under a DMA-engine control or working in the
&gt; mem-ops mode. I am sure the results have been beneficial to a lot of DW
&gt; SPI-controller users since then.
&gt; 
&gt; Damien, our first and last meeting was at my generic AHCI-platform and DW AHCI
&gt; SATA driver patches review. You didn't make it a quick and easy path. But still
&gt; all the reviews comments were purely on the technical basis, and the patches
&gt; were eventually merged in. Thank you for your time and experience I've got from
&gt; the reviews.
&gt; 
&gt; Paul, Thomas, Arnd, Jiaxun, we met several times in the mailing list during my
&gt; MIPS P5600 patches and just generic MIPS patches review. It was always a
&gt; pleasure to discuss the matters with such brilliant experts in the field. Alas
&gt; I've spent too much time working on the patches for another subsystems and
&gt; failed to submit all the MIPS-related bits. Sorry I didn't keep my promise, but
&gt; as you can see the circumstances have suddenly drawn its own deadline.
&gt; 
&gt; Bjorn, Mani, we were working quite a lot with you in the framework of the DW
&gt; PCIe RC drivers. You reviewed my patches. I helped you to review another patches
&gt; for some time. Despite of some arguing it was always a pleasure to work with
&gt; you.  Mani, special thanks for the cooperative DW eDMA driver maintenance. I
&gt; think we were doing a great work together.
&gt; 
&gt; Paolo, Jakub, David, Andrew, Vladimir, Russell. The network subsystem and
&gt; particularly the STMMAC driver (no doubt the driver sucks) have turned to be a
&gt; kind of obstacle on which my current Linux-kernel activity has stopped. I really
&gt; hope that at least in some way my help with the incoming STMMAC and DW XPCS
&gt; patches reviews lightened up your maintainance duty. I know Russell might
&gt; disagree, but I honestly think that all our discussions were useful after all,
&gt; at least for me. I also think we did a great work working together with Russell
&gt; on the DW GMAC/QoS ETH PCS patches. Hopefully you'll find a time to finish it up
&gt; after all. 
&gt; 
&gt; Rob, Krzysztof, from your reviews I've learned a lot about the most hardwary part
&gt; of the kernel - DT sources and DT-bindings. All your comments have been laconic
&gt; and straight to the point. That made reviews quick and easy. Thank you very
&gt; much for that.
&gt; 
&gt; Guenter, special thanks for reviewing and accepting my patches to the hwmon and
&gt; watchdog subsystems. It was pleasure to be working with you.
&gt; 
&gt; Borislav, we disagreed and argued a lot. So my DW uMCTL2 DDRC EDAC patches even
&gt; got stuck in limbo for quite a long time. Anyway thank you for the time
&gt; you spent reviewing my patches and trying to explain your point.
&gt; 
&gt; * Borislav, it looks like I won't be able to work on my Synopsys EDAC patchsets
&gt; anymore. If you or somebody else could pick them up and finish up the work it
&gt; would be great (you can find it in the lore archive). The patches convert the
&gt; mainly Zynq(MP)-specific Synopsys EDAC driver to supporting the generic DW
&gt; uMCTL2 DDRC. It would be very beneficial for each platform based on that
&gt; controller.
&gt; 
&gt; Greg, we met several times in the mailing lists. You reviewed my patches sent
&gt; for the USB and TTY subsystems, and all the time the process was straight,
&gt; highly professional, and simpler than in the most of my other case.
&gt; Thank you very much for that.
&gt; 
&gt; Yoshihiro, Keguang, Yanteng, Kory, Cai and everybody I was lucky to meet in the
&gt; kernel mailing lists, but forgot to mention here. Thank you for the time spent
&gt; for our cooperative work on making the Linux kernel better. It was a pleasure to
&gt; meet you here.
&gt; 
&gt; I also wish to say huge thanks to the community members trying to
&gt; defend the kicked off maintainers and for support you expressed in
&gt; these days. It means a lot.
&gt; 
&gt; A little bit statics of my kernel-work at the end:
&gt; 
&gt; Signed-off patches: 518
&gt; Reviewed and Acked patches: 253
&gt; Tested patches: 80
&gt; 
&gt; You might say not the greatest achievement for seven years comparing to some
&gt; other developers. Perhaps. But I meant each of these tags, be sure.
&gt; 
&gt; I guess that's it. If you ever need some info or consultation regarding the
&gt; drivers I used to maintain or the respective hardware or the Synopsys IP-cores
&gt; (about which I've got quite comprehensive knowledge by this time), feel free to
&gt; reach me out via this email. I am always willing to help to the community
&gt; members.
&gt; 
&gt; Hope we'll meet someday in more pleasant circumstances and drink a
&gt; couple or more beers together. But now it's time to say good bye.
&gt; Sorry for a long-read text. I wish good luck on your Linux-way.
&gt; 
&gt; Best Regards,
&gt; -Serge(y)
&gt; 
</span>

<a href="#m84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f" id="e84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">^</a> <a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/">permalink</a> <a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/raw">raw</a> <a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/#R">reply</a>	[<a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/netdev/D454EE83-DFB9-4A2D-821E-EF709350D5BB@gmx.de/t/#u">nested</a>] <a href="#r84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">3+ messages in thread</a></pre><hr><pre><a href="#e6a9c83cfd814e024be3dccd02345ed25b61954a1" id="m6a9c83cfd814e024be3dccd02345ed25b61954a1">*</a> <b>Re: linux: Goodbye from a Linux community volunteer</b>
  2024-10-24  4:27 <a href="#mdef37a4707eca10bf6e3a58271d28767d280c5ee">linux: Goodbye from a Linux community volunteer</a> Serge Semin
  2024-10-24  6:55 ` <a href="#m84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">Reimar Döffinger</a>
<b>@ 2024-10-24  7:32 ` Philipp Stanner</b>
  <a href="#r6a9c83cfd814e024be3dccd02345ed25b61954a1">1 sibling, 0 replies; 3+ messages in thread</a>
From: Philipp Stanner @ 2024-10-24  7:32 UTC (<a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/">permalink</a> / <a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/raw">raw</a>)
  To: Serge Semin, Jon Mason, Dave Jiang, Allen Hubbe, <a href="https://lore.kernel.org/ntb/?t=20241024073258">ntb</a>,
	Andy Shevchenko, Andy Shevchenko, Kory Maincent, Cai Huoqing,
	<a href="https://lore.kernel.org/dmaengine/?t=20241024073258">dmaengine</a>, Mark Brown, <a href="https://lore.kernel.org/linux-spi/?t=20241024073258">linux-spi</a>, Damien Le Moal, <a href="https://lore.kernel.org/linux-ide/?t=20241024073258">linux-ide</a>,
	Paul Burton, Thomas Bogendoerfer, Arnd Bergmann, Jiaxun Yang,
	<a href="https://lore.kernel.org/linux-mips/?t=20241024073258">linux-mips</a>, Bjorn Helgaas, Manivannan Sadhasivam,
	Yoshihiro Shimoda, <a href="https://lore.kernel.org/linux-pci/?t=20241024073258">linux-pci</a>, David S. Miller, Jakub Kicinski,
	Paolo Abeni, Andrew Lunn, Russell King, Vladimir Oltean,
	Keguang Zhang, Yanteng Si, <a href="https://lore.kernel.org/netdev/?t=20241024073258">netdev</a>, Rob Herring,
	Krzysztof Kozlowski, Guenter Roeck, <a href="https://lore.kernel.org/linux-hwmon/?t=20241024073258">linux-hwmon</a>, Borislav Petkov,
	<a href="https://lore.kernel.org/linux-edac/?t=20241024073258">linux-edac</a>, Greg Kroah-Hartman, <a href="https://lore.kernel.org/linux-serial/?t=20241024073258">linux-serial</a>
  Cc: Andrew Halaney, Nikita Travkin, Ivan Kokshaysky, Alexander Shiyan,
	Dmitry Kozlov, Sergey Shtylyov, Evgeniy Dushistov,
	Geert Uytterhoeven, Sergio Paracuellos, Nikita Shubin,
	<a href="https://lore.kernel.org/linux-renesas-soc/?t=20241024073258">linux-renesas-soc</a>, <a href="https://lore.kernel.org/lkml/?t=20241024073258">linux-kernel</a>

On Thu, 2024-10-24 at 07:27 +0300, Serge Semin wrote:
<span>&gt; Hello Linux-kernel community,
&gt; 
&gt; I am sure you have already heard the news caused by the recent Greg'
&gt; commit
&gt; 6e90b675cf942e ("MAINTAINERS: Remove some entries due to various
&gt; compliance
&gt; requirements."). As you may have noticed the change concerned some of
&gt; the
&gt; Ru-related developers removal from the list of the official kernel
&gt; maintainers,
&gt; including me.
&gt; 
&gt; The community members rightly noted that the _quite_ short commit log
&gt; contained
&gt; very vague terms with no explicit change justification. No matter how
&gt; hard I
&gt; tried to get more details about the reason, alas the senior
&gt; maintainer I was
&gt; discussing the matter with haven't given an explanation to what
&gt; compliance
&gt; requirements that was. I won't cite the exact emails text since it
&gt; was a private
&gt; messaging, but the key words are "sanctions", "sorry", "nothing I can
&gt; do", "talk
&gt; to your (company) lawyer"... I can't say for all the guys affected by
&gt; the
&gt; change, but my work for the community has been purely _volunteer_ for
&gt; more than
&gt; a year now (and less than half of it had been payable before that).
&gt; For that
&gt; reason I have no any (company) lawyer to talk to, and honestly after
&gt; the way the
&gt; patch has been merged in I don't really want to now. Silently, behind
&gt; everyone's
&gt; back, _bypassing_ the standard patch-review process, with no affected
&gt; developers/subsystem notified - it's indeed the worse way to do what
&gt; has been
&gt; done. No gratitude, no credits to the developers for all these years
&gt; of the
&gt; devoted work for the community. No matter the reason of the situation
&gt; but
&gt; haven't we deserved more than that? Adding to the GREDITS file at
&gt; least, no?..
&gt; 
&gt; I can't believe the kernel senior maintainers didn't consider that
&gt; the patch
&gt; wouldn't go unnoticed, and the situation might get out of control
&gt; with
&gt; unpredictable results for the community, if not straight away then in
&gt; the middle
&gt; or long term perspective. I am sure there have been plenty ways to
&gt; solve the
&gt; problem less harmfully, but they decided to take the easiest path.
&gt; Alas what's
&gt; done is done. A bifurcation point slightly initiated a year ago has
&gt; just been
&gt; fully implemented. The reason of the situation is obviously in the
&gt; political
&gt; ground which in this case surely shatters a basement the community
&gt; has been built
&gt; on in the first place. If so then God knows what might be next (who
&gt; else might
&gt; be sanctioned...), but the implemented move clearly sends a bad
&gt; signal to the
&gt; Linux community new comers, to the already working volunteers and
&gt; hobbyists like
&gt; me.
</span>
I'm also quite shocked and even baffled about how this has been
handled. This is not how leaders should communicate difficult or big
decisions. It's the most disappointing event I have witnessed in the
project.

There is the form and there is the content – about the content one
cannot do much, when the state he or his organization resides in gives
an order.

But about the form one can indeed do much. No "Thank you!", no "I hope
we can work together again once the world has become sane(r)"... srsly,
what the hell.

No idea why they felt the need to do it that way, but it certainly is
not the open source way, neither is it decent or honorable.


That said, thank you for all your work, Serge!

I believe that nothing that has been accomplished with a candid mindset
and decent intentions is ever done for nothing, although it often pays
off way differently than expected.
So I hope this will be the case for you, too.

Take care,
Philipp


<span>&gt; 
&gt; Thus even if it was still possible for me to send patches or perform
&gt; some
&gt; reviews, after what has been done my motivation to do that as a
&gt; volunteer has
&gt; simply vanished. (I might be doing a commercial upstreaming in future
&gt; though).
&gt; But before saying goodbye I'd like to express my gratitude to all the
&gt; community
&gt; members I have been lucky to work with during all these years.
&gt; Specifically:
&gt; 
&gt; NTB-folks, Jon, Dave, Allen. NTB was my starting point in the kernel
&gt; upstream
&gt; work. Thanks for the initial advices and despite of very-very-very
&gt; tough reviews
&gt; with several complete patchset refactorings, I learned a lot back
&gt; then. That
&gt; experience helped me afterwards. Thanks a lot for that. BTW since
&gt; then I've got
&gt; several thank-you letters for the IDT NTB and IDT EEPROM drivers. If
&gt; not for you
&gt; it wouldn't have been possible.
&gt; 
&gt; Andy, it's hard to remember who else would have given me more on my
&gt; Linux kernel
&gt; journey as you have. We first met in the I2C subsystem review of my
&gt; DW I2C
&gt; driver patches. Afterwards we've got to be frequently meeting here
&gt; and there -
&gt; GPIO, SPI, TTY, DMA, NET, etc, clean/fixes/features patch(set)s.
&gt; Quite heat
&gt; discussions in your first reviews drove me crazy really. But all the
&gt; time we
&gt; managed to come up with some consensus somehow. And you never quit
&gt; the
&gt; discussions calmly explaining your point over and over. You never
&gt; refused to
&gt; provide more detailed justification to your requests/comments even
&gt; though you
&gt; didn't have to. Thanks to that I learned how to be patient to
&gt; reviewers
&gt; and reviewees. And of course thank you for the Linux-kernel
&gt; knowledges and all
&gt; the tips and tricks you shared.
&gt; 
&gt; * Andy, please note due to the situation I am not going to work on my
&gt; DW DMAC
&gt; fixes patchset anymore. So if you ever wish to have DW UART stably
&gt; working with the
&gt; DW DMA-engine driver, then feel free to pick the series up:
&gt; Link:
&gt; <a href="https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/">https://lore.kernel.org/dmaengine/20240911184710.4207-1-fancer.lancer@gmail.com/</a>
&gt; 
&gt; Linus (Walleij), after you merged one of my pretty much heavy
&gt; patchset in you
&gt; suggested to me to continue the DW APB GPIO driver maintaining. It
&gt; was a first
&gt; time I was asked to maintain a not-my driver. Thank you for the
&gt; trust. I'll
&gt; never forget that.
&gt; 
&gt; Mark, thank you very much for entrusting the DW APB SSI driver
&gt; maintenance to
&gt; me. I've put a lot of efforts into making it more generic and less
&gt; errors-prune,
&gt; especially when it comes working under a DMA-engine control or
&gt; working in the
&gt; mem-ops mode. I am sure the results have been beneficial to a lot of
&gt; DW
&gt; SPI-controller users since then.
&gt; 
&gt; Damien, our first and last meeting was at my generic AHCI-platform
&gt; and DW AHCI
&gt; SATA driver patches review. You didn't make it a quick and easy path.
&gt; But still
&gt; all the reviews comments were purely on the technical basis, and the
&gt; patches
&gt; were eventually merged in. Thank you for your time and experience
&gt; I've got from
&gt; the reviews.
&gt; 
&gt; Paul, Thomas, Arnd, Jiaxun, we met several times in the mailing list
&gt; during my
&gt; MIPS P5600 patches and just generic MIPS patches review. It was
&gt; always a
&gt; pleasure to discuss the matters with such brilliant experts in the
&gt; field. Alas
&gt; I've spent too much time working on the patches for another
&gt; subsystems and
&gt; failed to submit all the MIPS-related bits. Sorry I didn't keep my
&gt; promise, but
&gt; as you can see the circumstances have suddenly drawn its own
&gt; deadline.
&gt; 
&gt; Bjorn, Mani, we were working quite a lot with you in the framework of
&gt; the DW
&gt; PCIe RC drivers. You reviewed my patches. I helped you to review
&gt; another patches
&gt; for some time. Despite of some arguing it was always a pleasure to
&gt; work with
&gt; you.&nbsp; Mani, special thanks for the cooperative DW eDMA driver
&gt; maintenance. I
&gt; think we were doing a great work together.
&gt; 
&gt; Paolo, Jakub, David, Andrew, Vladimir, Russell. The network subsystem
&gt; and
&gt; particularly the STMMAC driver (no doubt the driver sucks) have
&gt; turned to be a
&gt; kind of obstacle on which my current Linux-kernel activity has
&gt; stopped. I really
&gt; hope that at least in some way my help with the incoming STMMAC and
&gt; DW XPCS
&gt; patches reviews lightened up your maintainance duty. I know Russell
&gt; might
&gt; disagree, but I honestly think that all our discussions were useful
&gt; after all,
&gt; at least for me. I also think we did a great work working together
&gt; with Russell
&gt; on the DW GMAC/QoS ETH PCS patches. Hopefully you'll find a time to
&gt; finish it up
&gt; after all. 
&gt; 
&gt; Rob, Krzysztof, from your reviews I've learned a lot about the most
&gt; hardwary part
&gt; of the kernel - DT sources and DT-bindings. All your comments have
&gt; been laconic
&gt; and straight to the point. That made reviews quick and easy. Thank
&gt; you very
&gt; much for that.
&gt; 
&gt; Guenter, special thanks for reviewing and accepting my patches to the
&gt; hwmon and
&gt; watchdog subsystems. It was pleasure to be working with you.
&gt; 
&gt; Borislav, we disagreed and argued a lot. So my DW uMCTL2 DDRC EDAC
&gt; patches even
&gt; got stuck in limbo for quite a long time. Anyway thank you for the
&gt; time
&gt; you spent reviewing my patches and trying to explain your point.
&gt; 
&gt; * Borislav, it looks like I won't be able to work on my Synopsys EDAC
&gt; patchsets
&gt; anymore. If you or somebody else could pick them up and finish up the
&gt; work it
&gt; would be great (you can find it in the lore archive). The patches
&gt; convert the
&gt; mainly Zynq(MP)-specific Synopsys EDAC driver to supporting the
&gt; generic DW
&gt; uMCTL2 DDRC. It would be very beneficial for each platform based on
&gt; that
&gt; controller.
&gt; 
&gt; Greg, we met several times in the mailing lists. You reviewed my
&gt; patches sent
&gt; for the USB and TTY subsystems, and all the time the process was
&gt; straight,
&gt; highly professional, and simpler than in the most of my other case.
&gt; Thank you very much for that.
&gt; 
&gt; Yoshihiro, Keguang, Yanteng, Kory, Cai and everybody I was lucky to
&gt; meet in the
&gt; kernel mailing lists, but forgot to mention here. Thank you for the
&gt; time spent
&gt; for our cooperative work on making the Linux kernel better. It was a
&gt; pleasure to
&gt; meet you here.
&gt; 
&gt; I also wish to say huge thanks to the community members trying to
&gt; defend the kicked off maintainers and for support you expressed in
&gt; these days. It means a lot.
&gt; 
&gt; A little bit statics of my kernel-work at the end:
&gt; 
&gt; Signed-off patches:		518
&gt; Reviewed and Acked patches:	253
&gt; Tested patches:			80
&gt; 
&gt; You might say not the greatest achievement for seven years comparing
&gt; to some
&gt; other developers. Perhaps. But I meant each of these tags, be sure.
&gt; 
&gt; I guess that's it. If you ever need some info or consultation
&gt; regarding the
&gt; drivers I used to maintain or the respective hardware or the Synopsys
&gt; IP-cores
&gt; (about which I've got quite comprehensive knowledge by this time),
&gt; feel free to
&gt; reach me out via this email. I am always willing to help to the
&gt; community
&gt; members.
&gt; 
&gt; Hope we'll meet someday in more pleasant circumstances and drink a
&gt; couple or more beers together. But now it's time to say good bye.
&gt; Sorry for a long-read text. I wish good luck on your Linux-way.
&gt; 
&gt; Best Regards,
&gt; -Serge(y)
&gt; 
</span>

<a href="#m6a9c83cfd814e024be3dccd02345ed25b61954a1" id="e6a9c83cfd814e024be3dccd02345ed25b61954a1">^</a> <a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/">permalink</a> <a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/raw">raw</a> <a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/#R">reply</a>	[<a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/T/#u"><b>flat</b></a>|<a href="https://lore.kernel.org/netdev/7be870fc2b2fa01b89708208c78cc041029252aa.camel@redhat.com/t/#u">nested</a>] <a href="#r6a9c83cfd814e024be3dccd02345ed25b61954a1">3+ messages in thread</a></pre><hr><pre>end of thread, other threads:[<a href="https://lore.kernel.org/netdev/?t=20241024073258">~2024-10-24  7:32 UTC</a> | <a href="https://lore.kernel.org/netdev/">newest</a>]

<b id="t">Thread overview:</b> 3+ messages (download: <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/t.mbox.gz">mbox.gz</a> follow: <a href="https://lore.kernel.org/netdev/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/t.atom">Atom feed</a>
-- links below jump to the message on this page --
2024-10-24  4:27 <a href="#mdef37a4707eca10bf6e3a58271d28767d280c5ee" id="rdef37a4707eca10bf6e3a58271d28767d280c5ee">linux: Goodbye from a Linux community volunteer</a> Serge Semin
2024-10-24  6:55 ` <a href="#m84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f" id="r84efcc2ab85b2435fa7fa32cda2f0458d6f7d67f">Reimar Döffinger</a>
2024-10-24  7:32 ` <a href="#m6a9c83cfd814e024be3dccd02345ed25b61954a1" id="r6a9c83cfd814e024be3dccd02345ed25b61954a1">Philipp Stanner</a>
</pre><hr><pre>This is a public inbox, see <a href="https://lore.kernel.org/netdev/_/text/mirror/">mirroring instructions</a>
for how to clone and mirror all data and code used for this inbox;
as well as URLs for NNTP newsgroup(s).</pre></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS data center latencies, visualized (480 pts)]]></title>
            <link>https://benjdd.com/aws/</link>
            <guid>41931572</guid>
            <pubDate>Thu, 24 Oct 2024 03:18:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benjdd.com/aws/">https://benjdd.com/aws/</a>, See on <a href="https://news.ycombinator.com/item?id=41931572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="info">
    <p>AWS data center latencies</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pretty.c (335 pts)]]></title>
            <link>https://github.com/aartaka/pretty.c</link>
            <guid>41931507</guid>
            <pubDate>Thu, 24 Oct 2024 03:01:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/aartaka/pretty.c">https://github.com/aartaka/pretty.c</a>, See on <a href="https://news.ycombinator.com/item?id=41931507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Pretty C: ✨Pretty✨ Scripting on Top of C</h2><a id="user-content-pretty-c-pretty-scripting-on-top-of-c" aria-label="Permalink: Pretty C: ✨Pretty✨ Scripting on Top of C" href="#pretty-c-pretty-scripting-on-top-of-c"></a></p>
<p dir="auto">Pretty C is a new scripting language compatible with C. Pretty C
  boosts your programs with dynamic typing, generic iteration, resource
  tracking and other niceties. And it’s backwards-compatible with C and
  all of its libraries! Inspired by Lua, Python, JavaScript, and
  Lisp. Here’s how a naive re-implementation of <code>head</code> utility might
  look like with Pretty C:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &quot;pretty.h&quot;

int main (int argc, string argv[])
{
    if (argc above 1)
        with (fclose, f, fopen(argv[1], &quot;r&quot;))
            fortimes (line, 10)
                with (free, buf, vector(200, char, 0))
                    when (fgets(buf, 200, f))
                        then print(buf)
                        otherwise 0;
    else
        println(&quot;Please provide an input file&quot;);
    return EXIT_SUCCESS;
}"><pre><span>#include</span> <span>"pretty.h"</span>

<span>int</span> <span>main</span> (<span>int</span> <span>argc</span>, <span>string</span> <span>argv</span>[])
{
    <span>if</span> (<span>argc</span> <span>above</span> <span>1</span>)
        <span>with</span> (<span>fclose</span>, <span>f</span>, <span>fopen</span>(<span>argv</span>[<span>1</span>], <span>"r"</span>))
            <span>fortimes</span> (<span>line</span>, <span>10</span>)
                <span>with</span> (<span>free</span>, <span>buf</span>, <span>vector</span>(<span>200</span>, <span>char</span>, <span>0</span>))
                    <span>when</span> (<span>fgets</span>(<span>buf</span>, <span>200</span>, <span>f</span>))
                        <span>then</span> <span>print</span>(<span>buf</span>)
                        <span>otherwise</span> <span>0</span>;
    <span>else</span>
        <span>println</span>(<span>"Please provide an input file"</span>);
    <span>return</span> <span>EXIT_SUCCESS</span>;
}</pre></div>
<p dir="auto">The goals for Pretty C are:</p>
<ul dir="auto">
  <li>Provide so much syntactic sugar as to cause any C developer a
    diabetes-induced heart attack.</li>
  <li>Deprecate Lua, Python, JavaScript, Ruby and a dozen other languages,
    because Pretty C is the ultimate scripting language, but
    lightning-fast and strongly typed!</li>
  <li>Including only one header (yes, Pretty C is a header-only library
    <code>#include</code>-able from arbitrary C file!)  to turn any codebase into a
    beginner friendly one.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Checkout the repository</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/aartaka/pretty.c"><pre>git clone https://github.com/aartaka/pretty.c</pre></div>
<p dir="auto">Or simply copy the <code>pretty.h</code> file—Pretty C is a header-only
  library, so you can</p>

<p dir="auto">from any file in the directory you drop <code>pretty.h</code> to. Or from any
  file really, if you specify the path to Pretty C as an include (<code>-I</code>)
  path.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Provided Conveniences</h2><a id="user-content-provided-conveniences" aria-label="Permalink: Provided Conveniences" href="#provided-conveniences"></a></p>
<p dir="auto">Here are all the pretty changes making C hip again.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Included Standard Headers</h2><a id="user-content-included-standard-headers" aria-label="Permalink: Included Standard Headers" href="#included-standard-headers"></a></p>
<ul dir="auto">
  <li><a href="https://en.cppreference.com/w/c/types/boolean" rel="nofollow">stdbool.h</a> for pretty booleans: <code>true</code>, <code>false</code>, and <code>bool</code>.</li>
  <li><a href="https://en.cppreference.com/w/c/types/integer" rel="nofollow">stdint.h</a> for fixed-width integer types like <code>uint64_t</code>.</li>
  <li><a href="https://en.cppreference.com/w/c/language/operator_alternative#Operator_macros.28C95.29" rel="nofollow">iso646.h</a> for readable alternatives to regular operators,
    including <code>and</code> for <code>&amp;&amp;</code> and <code>or</code> for <code>||</code>. Neat!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simple macros</h2><a id="user-content-simple-macros" aria-label="Permalink: Simple macros" href="#simple-macros"></a></p>
<p dir="auto">Everyone defines these, so why not provide them?</p>
<ul dir="auto">
  <li><code>max</code> and <code>min</code> of two numbers.</li>
  <li><code>len</code> for array length.</li>
  <li><code>default</code> for providing a fallback value.</li>
  <li><code>limit</code> to ensure proper value range.</li>
  <li><code>between</code> to check whether the number falls in a range.</li>
  <li><code>divisible</code> to check whether a number is modulo divisible by another number.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">New types</h2><a id="user-content-new-types" aria-label="Permalink: New types" href="#new-types"></a></p>
<p dir="auto">Type aliases:</p>
<ul dir="auto">
  <li><code>string</code> == <code>char*</code>.</li>
  <li><code>byte</code> == <code>char</code>.</li>
  <li><code>bytes</code> == <code>char*</code>.</li>
  <li><code>any</code> == <code>void*</code>.</li>
  <li>Integer shortcuts:
    <ul dir="auto">
      <li><code>uchar</code>.</li>
      <li><code>ushort</code>.</li>
      <li><code>uint</code>.</li>
      <li><code>ulong</code>.</li>
    </ul>
  </li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">New aliases</h2><a id="user-content-new-aliases" aria-label="Permalink: New aliases" href="#new-aliases"></a></p>
<p dir="auto">Mainly modeled after Lua and Lisp:</p>
<ul dir="auto">
  <li><code>eq</code>, because <code>iso646.h</code> only has <code>not_eq</code>.
    <ul dir="auto">
      <li><code>is</code> means <code>==</code> too.</li>
    </ul>
  </li>
  <li><code>bitnot</code> and <code>bitxor</code> for operations that used to be called
    inconsistently (<code>compl</code> and <code>xor</code> respectively) in <code>iso646.h</code>.</li>
  <li><code>below</code>, <code>above</code>, <code>upto</code>, and <code>downto</code> comparison operators.</li>
  <li><code>even</code>, <code>odd</code>, <code>positive</code>, <code>negative</code>, <code>zero</code>, and <code>empty</code> as predicates for numbers/data.</li>
  <li><code>nil</code> for <code>NULL</code>.</li>
  <li><code>until</code> for negated <code>while</code>.</li>
  <li><code>elif</code> for <code>else if</code>.</li>
  <li><code>ifnt</code> for <code>if(!...)</code>.</li>
  <li><code>repeat</code> from Lua as an alias for <code>do</code>.</li>
  <li><code>done</code> and <code>pass</code> as aliases for <code>break</code> and <code>continue</code>, respectively.</li>
  <li><code>always</code>, so that you can make infinite (event? server?) loops</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="always println(&quot;After all this time?&quot;);"><pre><span>always</span> <span>println</span>(<span>"After all this time?"</span>);</pre></div>
<ul dir="auto">
  <li>and <code>never</code> and <code>comment</code> to comment out some code with just one
    keyword, while still allowing the compiler to analyze/optimize it
    (similar to <a href="https://clojuredocs.org/clojure.core/comment" rel="nofollow">Clojure <code>comment</code> form</a>):</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="never println(&quot;This never runs, but never gets outdated, because compiler will shout at you if it does.&quot;);"><pre><span>never</span> <span>println</span>(<span>"This never runs, but never gets outdated, because compiler will shout at you if it does."</span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Type inference (GCC, Clang, or C23+)</h2><a id="user-content-type-inference-gcc-clang-or-c23" aria-label="Permalink: Type inference (GCC, Clang, or C23+)" href="#type-inference-gcc-clang-or-c23"></a></p>
<p dir="auto">Yes, you can do</p>
<div dir="auto" data-snippet-clipboard-copy-content="var t = time(0);
let lt = localtime(&amp;t);
local at = asctime(lt);
println(at);"><pre><span>var</span> <span>t</span> <span>=</span> <span>time</span>(<span>0</span>);
<span>let</span> <span>lt</span> <span>=</span> <span>localtime</span>(<span>&amp;</span><span>t</span>);
<span>local</span> <span>at</span> <span>=</span> <span>asctime</span>(<span>lt</span>);
<span>println</span>(<span>at</span>);</pre></div>
<p dir="auto">With Pretty C.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Generic printing (C11+)</h2><a id="user-content-generic-printing-c11" aria-label="Permalink: Generic printing (C11+)" href="#generic-printing-c11"></a></p>
<p dir="auto"><code>print</code> prints whatever you feed it. <code>println</code> adds a newline after it.</p>
<div dir="auto" data-snippet-clipboard-copy-content="println(3.1);
print(&quot;Hello world!\n&quot;);"><pre><span>println</span>(<span>3.1</span>);
<span>print</span>(<span>"Hello world!\n"</span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Generic equality (C11+)</h2><a id="user-content-generic-equality-c11" aria-label="Permalink: Generic equality (C11+)" href="#generic-equality-c11"></a></p>
<p dir="auto">Compare all the things!</p>
<div dir="auto" data-snippet-clipboard-copy-content="equal(&quot;NA&quot;, line); // true
equal(0.3, 0.2 + 0.1); // true"><pre><span>equal</span>(<span>"NA"</span>, <span>line</span>); <span>// true</span>
<span>equal</span>(<span>0.3</span>, <span>0.2</span> <span>+</span> <span>0.1</span>); <span>// true</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pretty ternaries</h2><a id="user-content-pretty-ternaries" aria-label="Permalink: Pretty ternaries" href="#pretty-ternaries"></a></p>
<p dir="auto">Ternaries are frightening, so it won’t hurt to add some plain
  text. <code>if</code> and <code>else</code> are taken, but there are proper linguistic
  alternatives that look quite Python/Lisp-like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="return when some_condition
       then do_something()
       other do_something_else();"><pre><span>return</span> <span>when</span> <span>some_condition</span>
       <span>then</span> <span>do_something</span>()
       <span>other</span> <span>do_something_else</span>();</pre></div>
<p dir="auto">It’s ternaries underneath:</p>
<ul dir="auto">
  <li><code>when</code> expands to empty string and is only provided for readability.
    <ul dir="auto">
      <li><code>unless</code> expands to <code>not</code> to be a negative version of <code>when</code>.</li>
    </ul>
  </li>
  <li><code>then</code> expands to <code>?</code>.</li>
  <li><code>other</code> / <code>otherwise</code> expands to <code>:</code>.</li>
</ul>
<p dir="auto">There’s also <code>only</code> for when the <code>otherwise</code> clause is
  unnecessary:</p>
<div dir="auto" data-snippet-clipboard-copy-content="return when done()
       then 42 only;"><pre><span>return</span> <span>when</span> <span>done</span>()
       <span>then</span> <span>42</span> <span>only</span>;</pre></div>
<p dir="auto">and <code>otherwhen</code> for the next condition</p>
<div dir="auto" data-snippet-clipboard-copy-content="return when c is 'A'
       then 'a'
       otherwhen c is 'B'
       then 'b' only;"><pre><span>return</span> <span>when</span> <span>c</span> <span>is</span> <span>'A'</span>
       <span>then</span> <span>'a'</span>
       <span>otherwhen</span> <span>c</span> <span>is</span> <span>'B'</span>
       <span>then</span> <span>'b'</span> <span>only</span>;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>for</code> Macros</h2><a id="user-content-for-macros" aria-label="Permalink: for Macros" href="#for-macros"></a></p>
<p dir="auto">These macros are aliases for certain <code>for</code> loop pattern, each
  abstracting away some of the frequent <code>for</code> loop uses.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>foreach (var, type, length, ...)</code></h3><a id="user-content-foreach-var-type-length-" aria-label="Permalink: foreach (var, type, length, ...)" href="#foreach-var-type-length-"></a></p>
<p dir="auto">This one walks an array or memory region initialized to the vararg
  expression. Every time it iterates, <code>var</code> is set to a pointer to the
  respective array element. Yes, pointer—so that you can modify the
  element in place if you have to.</p>
<div dir="auto" data-snippet-clipboard-copy-content="foreach (i, int, 10, vector(10, int, 1, 2, 3, 3, 4, 5))
        println(*i);"><pre><span>foreach</span> (<span>i</span>, <span>int</span>, <span>10</span>, <span>vector</span>(<span>10</span>, <span>int</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>3</span>, <span>4</span>, <span>5</span>))
        <span>println</span>(<span>*</span><span>i</span>);</pre></div>
<p dir="auto">Also shows the use of <code>vector</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>forthese (var, type, ...)</code></h3><a id="user-content-forthese-var-type-" aria-label="Permalink: forthese (var, type, ...)" href="#forthese-var-type-"></a></p>
<p dir="auto">Iterates over the provided varargs, binding each of these to <code>type</code>-d
  <code>var</code>. The loop above can be translated as:</p>
<div dir="auto" data-snippet-clipboard-copy-content="forthese (i, int, 1, 2, 3, 3, 4, 5)
        println(i);"><pre><span>forthese</span> (<span>i</span>, <span>int</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>3</span>, <span>4</span>, <span>5</span>)
        <span>println</span>(<span>i</span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>fortimes (var, times)</code></h3><a id="user-content-fortimes-var-times" aria-label="Permalink: fortimes (var, times)" href="#fortimes-var-times"></a></p>
<p dir="auto">A frequent case of going from 0 to some positive number. Saves you
  quite some time for your</p>
<div dir="auto" data-snippet-clipboard-copy-content="for (int i = 0; i < 28; i++)
        println(i+1);"><pre><span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>28</span>; <span>i</span><span>++</span>)
        <span>println</span>(<span>i</span><span>+</span><span>1</span>);</pre></div>
<p dir="auto">turning it into a simple</p>
<div dir="auto" data-snippet-clipboard-copy-content="fortimes (i, 28)
        println(i+1);
println(&quot;28 stab wounds, you didn't want to leave him a chance, huh?&quot;);"><pre><span>fortimes</span> (<span>i</span>, <span>28</span>)
        <span>println</span>(<span>i</span><span>+</span><span>1</span>);
<span>println</span>(<span>"28 stab wounds, you didn't want to leave him a chance, huh?"</span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>forrange (var, init, target)</code></h3><a id="user-content-forrange-var-init-target" aria-label="Permalink: forrange (var, init, target)" href="#forrange-var-init-target"></a></p>
<p dir="auto">Iterate over a range of numbers from <code>init</code> to
  <code>target</code>. Pythonesque. Here’s Celsius to Fahrenheit conversion loop
  with <code>forrange</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="forrange (c, -10, 20)
        printf(&quot;Celsius %i = Fahrenheit %f\n&quot;, c, (32 + (c * 1.8)));"><pre><span>forrange</span> (<span>c</span>, <span>-10</span>, <span>20</span>)
        <span>printf</span>(<span>"Celsius %i = Fahrenheit %f\n"</span>, <span>c</span>, (<span>32</span> <span>+</span> (<span>c</span> <span>*</span> <span>1.8</span>)));</pre></div>
<p dir="auto">Note that <code>init</code> and <code>target</code> are arbitrary integers, signed and
  unsigned. And <code>init</code> might be greater than <code>target</code> in which case the
  iteration step decreases the variable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>forrangeby (var, type, init, target, by)</code></h3><a id="user-content-forrangeby-var-type-init-target-by" aria-label="Permalink: forrangeby (var, type, init, target, by)" href="#forrangeby-var-type-init-target-by"></a></p>
<p dir="auto">Iterate <code>type</code>-d <code>var</code> from <code>iter</code> to <code>target</code>, stepping by <code>by</code> every
  time. Pythonesque.</p>
<div dir="auto" data-snippet-clipboard-copy-content="forrangeby (x, double, 1.0, 10.0, 0.5)
        println(x);"><pre><span>forrangeby</span> (<span>x</span>, <span>double</span>, <span>1.0</span>, <span>10.0</span>, <span>0.5</span>)
        <span>println</span>(<span>x</span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Allocation macros</h2><a id="user-content-allocation-macros" aria-label="Permalink: Allocation macros" href="#allocation-macros"></a></p>
<p dir="auto">These allow quick-and-dirty allocation for typical patterns. Mostly
  modeled after C++.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>new (type, ...)</code></h3><a id="user-content-new-type-" aria-label="Permalink: new (type, ...)" href="#new-type-"></a></p>
<p dir="auto">C++ <code>new</code> operator is nice, so it won’t hurt having something similar
  in C, right? Ask no more:</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct ListNode {
        int val;
        struct ListNode *next;
};

struct ListNode *node = new(struct ListNode, 2, new(struct ListNode, 1, nil));"><pre><span>struct</span> <span>ListNode</span> {
        <span>int</span> <span>val</span>;
        <span>struct</span> <span>ListNode</span> <span>*</span><span>next</span>;
};

<span>struct</span> <span>ListNode</span> <span>*</span><span>node</span> <span>=</span> <span>new</span>(<span>struct</span> <span>ListNode</span>, <span>2</span>, <span>new</span>(<span>struct</span> <span>ListNode</span>, <span>1</span>, <span>nil</span>));</pre></div>
<p dir="auto">Or, if you fancy, you can add even more syntax on top:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define cons(val, ...) new(struct ListNode, val, __VA_ARGS__)
cons(2, cons(1, nil));"><pre><span>#define</span> <span>cons</span>(<span>val</span>, ...) new(struct ListNode, val, __VA_ARGS__)
<span>cons</span>(<span>2</span>, <span>cons</span>(<span>1</span>, <span>nil</span>));</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>vector (length, type, ...)</code></h3><a id="user-content-vector-length-type-" aria-label="Permalink: vector (length, type, ...)" href="#vector-length-type-"></a></p>
<p dir="auto">C++ again. <code>std::vector</code> is an extremely useful and versatile data
  structure that’s easy to reason about. While this macro is not even
  remotely as featureful as C++ counterpart, it simplifies a frequent
  pattern of “allocate an array of that much elements and with these
  contents”:</p>
<div dir="auto" data-snippet-clipboard-copy-content="double *vec = vector(10, double, 1, 2, 3, 4, 5);"><pre><span>double</span> <span>*</span><span>vec</span> <span>=</span> <span>vector</span>(<span>10</span>, <span>double</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>delete (...)</code></h3><a id="user-content-delete-" aria-label="Permalink: delete (...)" href="#delete-"></a></p>
<p dir="auto">In case you don’t like <code>free</code>-ing the resources and prefer a fancier C++ name.</p>
<p dir="auto">Otherwise the same as <code>free</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Block utilities</h2><a id="user-content-block-utilities" aria-label="Permalink: Block utilities" href="#block-utilities"></a></p>
<p dir="auto">These establish new local bindings, ensure deferred computations, or
  otherwise act on the block after them.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>lambda (ret, name, ...)</code> (GCC, Clang, or C++)</h3><a id="user-content-lambda-ret-name--gcc-clang-or-c" aria-label="Permalink: lambda (ret, name, ...) (GCC, Clang, or C++)" href="#lambda-ret-name--gcc-clang-or-c"></a></p>
<p dir="auto">Nested functions/lambdas/closures, now in C!</p>
<div dir="auto" data-snippet-clipboard-copy-content="int *arr = vector(10, int, 23423, 23423, 234, 5233, 6, 4, 34, 643, 3, 9);
lambda (int, cmp, int *a, int *b) {
        return *a - *b;
};
qsort(arr, 10, sizeof(int), cmp);
// arr becomes {3, 4, 6, 9, 34, 234, 643, 5233, 23423, 23423}"><pre><span>int</span> <span>*</span><span>arr</span> <span>=</span> <span>vector</span>(<span>10</span>, <span>int</span>, <span>23423</span>, <span>23423</span>, <span>234</span>, <span>5233</span>, <span>6</span>, <span>4</span>, <span>34</span>, <span>643</span>, <span>3</span>, <span>9</span>);
<span>lambda</span> (<span>int</span>, <span>cmp</span>, <span>int</span> <span>*</span><span>a</span>, <span>int</span> <span>*</span><span>b</span>) {
        <span>return</span> <span>*</span><span>a</span> <span>-</span> <span>*</span><span>b</span>;
};
<span>qsort</span>(<span>arr</span>, <span>10</span>, <span>sizeof</span>(<span>int</span>), <span>cmp</span>);
<span>// arr becomes {3, 4, 6, 9, 34, 234, 643, 5233, 23423, 23423}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>with (close, var, ...)</code></h3><a id="user-content-with-close-var-" aria-label="Permalink: with (close, var, ...)" href="#with-close-var-"></a></p>
<p dir="auto">This ensures that you never have use-after-free, because you provide
  the freeing procedure (<code>close</code>) upfront. Especially useful for
  dynamically allocated objects and file designators.</p>
<div dir="auto" data-snippet-clipboard-copy-content="with (fclose, file, fopen(&quot;hello.txt&quot;, &quot;w&quot;))
        fprintf(file, &quot;Hello world!\n&quot;);"><pre><span>with</span> (<span>fclose</span>, <span>file</span>, <span>fopen</span>(<span>"hello.txt"</span>, <span>"w"</span>))
        <span>fprintf</span>(<span>file</span>, <span>"Hello world!\n"</span>);</pre></div>
<p dir="auto">One of the downsides is that the bound <code>var</code> is a <code>void *</code>, so you
  might need to coerce it to your type before using it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>defer (...)</code></h3><a id="user-content-defer-" aria-label="Permalink: defer (...)" href="#defer-"></a></p>
<p dir="auto">Offloads the code to be executed after the following block. Not at the
  end of function as in Go, because that’s <del>impossible</del> hard to
  implement in C. Still, Pretty C <code>defer</code> is useful enough.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>try</code>,, and <code>catch</code></h3><a id="user-content-try-and-catch" aria-label="Permalink: try,, and catch" href="#try-and-catch"></a></p>
<p dir="auto">Fancy error handling, now in C. Refactored example from <a href="https://en.cppreference.com/w/c/error/errno" rel="nofollow">errno reference</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="try log(0.0);
catch (NOERR)
        println(&quot;No error.&quot;);
catch (EDOM, ERANGE)
        println(&quot;Math error!&quot;);"><pre><span>try</span> <span>log</span>(<span>0.0</span>);
<span>catch</span> (<span>NOERR</span>)
        <span>println</span>(<span>"No error."</span>);
<span>catch</span> (<span>EDOM</span>, <span>ERANGE</span>)
        <span>println</span>(<span>"Math error!"</span>);</pre></div>
<p dir="auto"><code>NOERR</code> and <code>NOERROR</code> are also provided by Pretty C, for convenience
  of error switch-casing.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC Cuts Off Client After Discovering Chips Sent to Huawei (195 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-10-23/tsmc-cuts-off-client-after-discovering-chips-diverted-to-huawei</link>
            <guid>41931392</guid>
            <pubDate>Thu, 24 Oct 2024 02:39:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-10-23/tsmc-cuts-off-client-after-discovering-chips-diverted-to-huawei">https://www.bloomberg.com/news/articles/2024-10-23/tsmc-cuts-off-client-after-discovering-chips-diverted-to-huawei</a>, See on <a href="https://news.ycombinator.com/item?id=41931392">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
    </channel>
</rss>