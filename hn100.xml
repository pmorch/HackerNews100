<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 21 Jan 2025 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Invisible Electrostatic Wall at 3M plant (123 pts)]]></title>
            <link>http://amasci.com/weird/unusual/e-wall.html</link>
            <guid>42782914</guid>
            <pubDate>Tue, 21 Jan 2025 17:37:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://amasci.com/weird/unusual/e-wall.html">http://amasci.com/weird/unusual/e-wall.html</a>, See on <a href="https://news.ycombinator.com/item?id=42782914">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
<a href="https://www.reddit.com/r/AskReddit/comments/4jb24s/what_are_some_weird_real_life_xfiles_type/d35db1i/">echisholm</a> 5/2016
<br>
<i>
Have a relative (sort of) who works at a 3M plant. Shit still occasionally 
happens.<br>
&gt; You can't just say that and go away!! How are you not irresistibly <br>
&gt; interested in that?? I would've interrogated that relative so hard<br>
It just came up in passing at Thanksgiving! I don't really know him 
that 
well; he's an in-law. He mentioned being able to throw small washers and 
bolts at the field and watching them get repelled. People got 
interested, and so someone came with a voltmeter, and after throwing a 
couple more, they checked for voltage, and there was a residual charge 
after they finally caught on on a plastic sheet to prevent immediate 
grounding. It also had a very slight magnetic field. It's apparently 
fairly common, but engineering hasn't come up with a solid explanation 
why.</i> 
<br></p><p>
ALSO: <a href="https://www.reddit.com/r/AskReddit/comments/4jb24s/what_are_some_weird_real_life_xfiles_type/d35dxw1/">dc469</a> 5/2016<br>
<i>
I met this guy at an ESD meeting in austin once. He said the strength of 
the field maxed out his equipment at a distance so he couldn't get a 
maximum measurement.
<br>
After he published the paper he was contacted by NASA and all the three 
letter agencies asking for more info. He wanted to experiment around with 
it but no company had millions to throw into such a project (presumably, 
the government did). It had to be a pretty narrow window of temperature, 
pressure, humidity, etc. They kept the garage door open so that's where 
the insects and sparrows got sucked in (which obviously ruined the 
product).
<br>
He said it was actually known to the technicians for awhile before he 
experienced it and they just were kinda like "meh". Eventually they fixed 
the grounding issue on the machine and the problem never popped up again.
<br>
edit: found the ESD website. David Swenson apparently is still with them 
on their board of directors. http://centxesdassoc.homestead.com/
<br></i></p><div>
<p>
  Problems: coulomb forces would be expected to <i>attract</i> a person
  into the "chamber" formed by the PP film, and the attractive force
  should increase linearly across distance. There should be no "wall" in
  the center, a discrete wall is repulsive, also nonlinear.<br></p>

<p>If for some reason a
  person was repelled from the center of the chamber rather than being
  attracted, there still should be no "wall," since the repulsion force 
should exist over a large distance; it
  should act like a deep pillow which exerts more and more force as one
  moves deeper into it.  Large fuzzy fields, this is how
  magnets and iron behave, and this is how e-fields and conductive objects
  should also behave.
<br></p>

<p>

  A thought: unspooling of film typically generates a much higher net 
charge on
  the long piece of film than on the small surface of the spool.
  However, since charge is created in pairs, and net charge is conserved, 
the imbalances of charge <i>must</i> 
be
  equal and opposite.  The charge on the entire length of moving film 
<i>must</i>
  be equal in magnitude to the charge on the spool.  Yet the charge on the
  film is very large and is continuously increasing.  The limited
  surface-charge on the spool required that opposite charge is being 
<i>lost
  through some unseen path.</i>  
<br></p>

<p>
Very probably the spool is spewing out 
enormous quantities of ionized air with polarity opposite that of the 
charge on the moving plastic film.
<br></p>

<p>

  Charged air would be created by discharge in the cleft between film and 
spool as the 
film
  was peeled from the spool.  I wonder if film was being peeled from the 
top of
  the spool, so that any ionized air created in the cleft would be 
launched into the
"tent-chamber" region?  (If it was peeled from the bottom of the spool,
the charged air would end up outside the "tent.")  Or, if a corona
discharge arises in the cleft between film and spool, perhaps the UV and
e-fields of this corona can ionize the air on both sides of the exiting
plastic film, and spray the charged air everywhere. 
<br></p>

<p>

  So, if the charged "tent" of film is negative in the above situation,
  and if a large quantity of positively charged air is being generated
  by the spool, then perhaps the "invisible wall" is caused by a cloud of
  suspended air ions held in position by e-fields.  Perhaps it's a 
pressure gradient created by
  ionized air trapped under the tent by electrostatic attraction.  Yet
  again this effect would be expected to create a diffuse zone of 
increasing
  force, not a "wall", but an "invisible pillow."  Added note: concrete 
floors behave as conductors (resistors) in this situation.  Where 
megavolts at 
microamps are involved, the division between insulators and conductors is 
at 10^6/10^-6 =  1000 gigaohms.  Concrete resistivity is 
in the realm of megohms, so it behaves like a grounded metal sheet. 
<br></p>

<p>

  However, a volume of charged air is somewhat analogous to iron
  filings near a magnet.  If a solid sheet of iron filings is held in
  place by a magnet, then a literal "wall" is created, and this wall will
  resist penetration by nonferrous objects.  If in the above manufacturing
  plant, a sheet of highly charged air is for some reason being held in
  place by the fields created by the charged film, then a transparent
  "wall" made of charged air would come into being.  It might produce 
pressures on surfaces, and resist  penetration by human bodies. 
<br></p>

<p>

  My question is this: if the entire situation could be turned on its
  side, so the "invisible wall" became an "invisible floor", could a
  person *<i>stand</i>* on it?  Have we discovered the long-sought "Zero-G
  waterbed?"  :)    - B.B.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[0click deanonymization attack targeting Signal, Discord and other platforms (601 pts)]]></title>
            <link>https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117</link>
            <guid>42780816</guid>
            <pubDate>Tue, 21 Jan 2025 14:59:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117">https://gist.github.com/hackermondev/45a3cdfa52246f1d1201c1e8cdef6117</a>, See on <a href="https://news.ycombinator.com/item?id=42780816">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Unique 0-click deanonymization attack targeting Signal, Discord and hundreds of platform
  </p><div id="file-research-md" tabindex="0" role="region" aria-label="file-research-md">
    <article itemprop="text"><p dir="auto">hi, i'm daniel. i'm a 15-year-old high school junior. in my free time, i <a href="https://hackerone.com/daniel" rel="nofollow">hack billion dollar companies</a> and build cool stuff.</p>
<p dir="auto">3 months ago, I discovered a unique 0-click deanonymization attack that allows an attacker to grab the location of any target within a 250 mile radius. With a vulnerable app installed on a target's phone (or as a background application on their laptop), an attacker can send a malicious payload and deanonymize you within seconds--and you wouldn't even know.</p>
<p dir="auto">I'm publishing this writeup and research as a warning, especially for journalists, activists, and hackers, about this type of undetectable attack. Hundreds of applications are vulnerable, including some of the most popular apps in the world: Signal, Discord, Twitter/X, and others. Here's how it works:</p>
<p dir="auto"><h2 dir="auto">Cloudflare</h2><a id="user-content-cloudflare" aria-label="Permalink: Cloudflare" href="#cloudflare"></a></p>
<p dir="auto">By the numbers, Cloudflare is easily the most popular CDN on the market. It beats out competitors such as Sucuri, Amazon CloudFront, Akamai, and Fastly. In 2019, a major Cloudflare outage knocked most of the internet offline for over 30 minutes.</p>
<p dir="auto">One of Cloudflare's most used feature is Caching. Cloudflare's Cache stores copies of frequently accessed content (such as images, videos, or webpages) in its datacenters, reducing server load and improving website performance (<a href="https://developers.cloudflare.com/cache/" rel="nofollow">https://developers.cloudflare.com/cache/</a>).</p>
<p dir="auto">When your device sends a request for a resource that can be cached, Cloudflare retrieves the resource from its local datacenter storage, if available. Otherwise, it fetches the resource from the origin server, caches it locally, and then returns it. By default, <a href="https://developers.cloudflare.com/cache/concepts/default-cache-behavior/" rel="nofollow">some file extensions</a> are automatically cached but site operators can also configure new cache rules.</p>
<p dir="auto">Cloudflare has a vast global presence, with hundreds of datacenters in 330 cities across 120+ countries—an estimated 273% more datacenters than Google. In the U.S. East region, for example, the nearest datacenter to me is less than 100 miles. If you live in a developed country, there's a good chance the nearest datacenter to you is less than 200 miles from you.</p>
<p dir="auto">A few months ago, I had a lightbulb moment: if Cloudflare stores cached data so close to users, could this be exploited for deanonymization attacks on sites we don't control?</p>
<p dir="auto">You see, Cloudflare returns information about a request's cache status in the HTTP response.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404693583-95e1a39a-ed25-4531-9c57-a1b43c616519.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ2OTM1ODMtOTVlMWEzOWEtZWQyNS00NTMxLTljNTctYTFiNDNjNjE2NTE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MzA5ZTIyNTllOTI0MTJhOWRkY2ZlZDNhNDNkNzg1ODEwMjY0NDYwZDliNmNlZjllYmI4MGI4ZmNlNzIzNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.e9M92dBECy2m5CzJMyFp44ih3IZwDWegcPvRs65is4o"><img width="426" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404693583-95e1a39a-ed25-4531-9c57-a1b43c616519.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ2OTM1ODMtOTVlMWEzOWEtZWQyNS00NTMxLTljNTctYTFiNDNjNjE2NTE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MzA5ZTIyNTllOTI0MTJhOWRkY2ZlZDNhNDNkNzg1ODEwMjY0NDYwZDliNmNlZjllYmI4MGI4ZmNlNzIzNTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.e9M92dBECy2m5CzJMyFp44ih3IZwDWegcPvRs65is4o"></a></p>
<p dir="auto"><code>cf-cache-status</code> can be <code>HIT</code>/<code>MISS</code> and <code>cf-ray</code> includes the airport code for the closest airport to the datacenter that handles the request (in my case, IAD).</p>
<p dir="auto">If we can get a user's device to load a resource on a Cloudflare-backed site, causing it to be cached in their local datacenter, we can then enumerate all Cloudflare datacenters to identify which one cached the resource. This would provide an incredibly precise estimate of the user's location.</p>
<p dir="auto"><h2 dir="auto">Cloudflare Teleport</h2><a id="user-content-cloudflare-teleport" aria-label="Permalink: Cloudflare Teleport" href="#cloudflare-teleport"></a></p>
<p dir="auto">There was a one major hurdle I had to get through before I tested this theory.</p>
<p dir="auto">You can't simply send HTTP requests to individual Cloudflare datacenters. For "security purposes" (presumably DDoS protection), all Cloudflare IP ranges are strictly anycast. All TCP connections opened to their network are always handled by the nearest available datacenter to you, there's no way you can ask a datacenter in Canada to handle your request if you live in the US.</p>
<p dir="auto">However, after some research, I found a forum post (<a href="https://community.cloudflare.com/t/how-to-run-workers-on-specific-datacenter-colos/385851" rel="nofollow">https://community.cloudflare.com/t/how-to-run-workers-on-specific-datacenter-colos/385851</a>) from a community member showing me exactly how. The author shared a bug he found to send requests to specific Cloudflare datacenters with Cloudflare Workers.</p>
<p dir="auto">I'm still not 100% sure of the specifics of this bug, but using an IP range used internally by Cloudflare WARP (Cloudflare's VPN client), we could ask certain datacenters to handle HTTP requests. Normally, this IP range blocked inbound connections from external IP addresses but requests sent from Workers could bypass this since the connection would originate from inside Cloudflare's network.</p>
<p dir="auto">I spent a few minutes reading their post and I quickly spined up a tool for this: Cloudflare Teleport (<a href="https://github.com/hackermondev/cf-teleport">https://github.com/hackermondev/cf-teleport</a>). Certain IP ranges corresponded to different datacenters (<a href="https://github.com/hackermondev/cf-teleport/blob/main/scripts/data/colos.json">https://github.com/hackermondev/cf-teleport/blob/main/scripts/data/colos.json</a>).</p>
<p dir="auto">Cloudflare Teleport is a proxy powered by Cloudflare Workers that redirects HTTP requests to specific datacenters. For example, <a href="https://cfteleport.xyz/?proxy=https://cloudflare.com/cdn-cgi/trace&amp;colo=SEA" rel="nofollow">https://cfteleport.xyz/?proxy=https://cloudflare.com/cdn-cgi/trace&amp;colo=SEA</a> would proxy a HTTP GET request to <a href="https://cloudflare.com/cdn-cgi/trace" rel="nofollow">https://cloudflare.com/cdn-cgi/trace</a> specifically to a Seattle (SEA) datacenter.</p>
<p dir="auto">Cloudflare would end up completely patching this bug a few months later, making this tool obsolete, but more on that later. For a majority of my initial, I used this tool.</p>

<p dir="auto">As soon as the Cloudflare Teleport tool was complete, I was able to confirm my theory. I coded a simple CLI program that would send an HTTP GET request to a specified URL and list all datacenters that had the resource cache and its age.</p>
<p dir="auto">For my first test, I used Namecheap's favicon (<a href="https://www.namecheap.com/favicon.ico" rel="nofollow">https://www.namecheap.com/favicon.ico</a>). This resource has Cloudflare Caching enabled, it's just a simple static image of their logo. (This was the quickest site I could find that didn't have rigorous bot protection):</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404707140-8da57801-ae8e-4adf-9a2e-ec6feec6086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ3MDcxNDAtOGRhNTc4MDEtYWU4ZS00YWRmLTlhMmUtZWM2ZmVlYzYwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMTg5NmFkNTE1YWNkYWRjZjkyNDQzOWQ1NjYxNTBmNGVhMDRhNDUxMDMwOWI1MTY4MDU3Yzc1OWY5NzhkYzgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.989wnEI06vGtQEebz7AttCKWthW036QkaEc_6BThozE"><img width="814" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404707140-8da57801-ae8e-4adf-9a2e-ec6feec6086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ3MDcxNDAtOGRhNTc4MDEtYWU4ZS00YWRmLTlhMmUtZWM2ZmVlYzYwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMTg5NmFkNTE1YWNkYWRjZjkyNDQzOWQ1NjYxNTBmNGVhMDRhNDUxMDMwOWI1MTY4MDU3Yzc1OWY5NzhkYzgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.989wnEI06vGtQEebz7AttCKWthW036QkaEc_6BThozE"></a>
<p dir="auto">Boom, it worked. Namecheap had configured their cache age extremely low (5 minutes) but I was able to see every datacenter that had cached the their site's favicon in the last 5 minutes. Since everytime you load their site, your browser automatically downloads this favicon, this means a user from each one of this locations has visited the Namecheap.com site within the 5 minutes with the last visit from Tokyo, Japan.</p>
<p dir="auto">This was just meant to be a simple test and there's almost no impact here, but with this I confirmed my theory. This proved the concept of using Cloudflare caching for deanonymization attacks.</p>
<p dir="auto"><h2 dir="auto">Real-World Application: Signal</h2><a id="user-content-real-world-application-signal" aria-label="Permalink: Real-World Application: Signal" href="#real-world-application-signal"></a></p>
<p dir="auto">Signal, an open-source encrypted messaging service, is widely used by journalists and activists for its privacy features. Internally, the app utilizes two CDNs for serving content: <code>cdn.signal.org</code> (powered by CloudFront) for profile avatars and <code>cdn2.signal.org</code> (powered by Cloudflare) for message attachments.</p>
<p dir="auto"><h2 dir="auto">1-Click Attack</h2><a id="user-content-1-click-attack" aria-label="Permalink: 1-Click Attack" href="#1-click-attack"></a></p>
<p dir="auto">When a user sends an attachment (e.g., an image) on Signal, it is uploaded to cdn2.signal.org. Once the recipient opens the conversation, their device automatically downloads the attachment. Since Cloudflare caching is enabled for these URLs, an attacker can use the cache geolocation method to pinpoint the recipient’s location.</p>
<p dir="auto">The <code>https://cdn2.signal.org/attachments/*</code> path is configured to cache responses with Cloudflare. This means once a user's device automatically downloads an attachment, it's possible for an attacker to run a cache geolocation attack to find out which local datacenter they're near--similar to how law enforcement track mobile devices through cell phone towers.</p>
<p dir="auto">To test this, I quickly patched the Signal desktop app to remove SSL pinning and configured Burp to intercept and view HTTP requests/responses sent through the app.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404890145-51dd8b7c-375c-4bd1-936c-54c338fe6620.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTAxNDUtNTFkZDhiN2MtMzc1Yy00YmQxLTkzNmMtNTRjMzM4ZmU2NjIwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFiMDg2MmI0OTA4YzBkNWY3NDU5NDkwNTA2ODIyZmI5YzlmMWEyN2Y1OGIzZWQ3NDg0NDZjNzIyZTgxODAyZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.eBAHOyF4bJL0whN1rHtq9KaXDMZGytUuY5UIyIomcLQ"><img width="700" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404890145-51dd8b7c-375c-4bd1-936c-54c338fe6620.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTAxNDUtNTFkZDhiN2MtMzc1Yy00YmQxLTkzNmMtNTRjMzM4ZmU2NjIwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFiMDg2MmI0OTA4YzBkNWY3NDU5NDkwNTA2ODIyZmI5YzlmMWEyN2Y1OGIzZWQ3NDg0NDZjNzIyZTgxODAyZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.eBAHOyF4bJL0whN1rHtq9KaXDMZGytUuY5UIyIomcLQ"></a></p>
<p dir="auto"><h3 dir="auto">Reproduction Steps</h3><a id="user-content-reproduction-steps" aria-label="Permalink: Reproduction Steps" href="#reproduction-steps"></a></p>
<p dir="auto"><h4 dir="auto">1. Block HTTP GET requests to <code>cdn2.signal.org/attachments/*</code> in from the Signal using Burp.</h4><a id="user-content-1-block-http-get-requests-to-cdn2signalorgattachments-in-from-the-signal-using-burp" aria-label="Permalink: 1. Block HTTP GET requests to cdn2.signal.org/attachments/* in from the Signal using Burp." href="#1-block-http-get-requests-to-cdn2signalorgattachments-in-from-the-signal-using-burp"></a></p>
<p dir="auto">This ensures that the app doesn't download attachments uploaded from the our side (the attacker) since that would cache them to our local datacenter and pollute the results. The best way I found to do this with Burp is to configure intercept rules for attachments, then leave request intercept on and deny all requests.
<br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404891288-20a99d9c-ea9e-453d-85b6-13bb8482061e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTEyODgtMjBhOTlkOWMtZWE5ZS00NTNkLTg1YjYtMTNiYjg0ODIwNjFlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3N2ZjNzc1NWFmZjZhOTdmNWQ3MjE4YjYxNWJkZDUwZGIzMGY3M2I2ZjM2YjEzZWU5NGRhODRmMmIxMjc3MWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pa9g5nqedvL0cahQeMgbsNpRefoBYRycSjH_nICs6Og"><img width="809" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404891288-20a99d9c-ea9e-453d-85b6-13bb8482061e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ4OTEyODgtMjBhOTlkOWMtZWE5ZS00NTNkLTg1YjYtMTNiYjg0ODIwNjFlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3N2ZjNzc1NWFmZjZhOTdmNWQ3MjE4YjYxNWJkZDUwZGIzMGY3M2I2ZjM2YjEzZWU5NGRhODRmMmIxMjc3MWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pa9g5nqedvL0cahQeMgbsNpRefoBYRycSjH_nICs6Og"></a></p>
<p dir="auto"><h4 dir="auto">2. Send an attachment (image) to a target.</h4><a id="user-content-2-send-an-attachment-image-to-a-target" aria-label="Permalink: 2. Send an attachment (image) to a target." href="#2-send-an-attachment-image-to-a-target"></a></p>
<p dir="auto">This should work with any attachment but images are automatically downloaded when the user opens the conversation so they work best. I used a simple 1x1.png image for this test. The upload request is sent to Signal's CDN and you can see the attachment url in Burp once we send the attachment in the conversation and Signal uploads it (ex. <a href="https://cdn2.signal.org/attachments/UjLld11tvaL16M8mrd86" rel="nofollow">https://cdn2.signal.org/attachments/UjLld11tvaL16M8mrd86</a>).
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405260342-66b4c6f4-3617-4b79-9612-89a90aa7690c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUyNjAzNDItNjZiNGM2ZjQtMzYxNy00Yjc5LTk2MTItODlhOTBhYTc2OTBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRjZmQ3NzNkZDZhYWI2MTFlODU0Mjc4MjlhMTU2ZDI5ZWMxYjJhMjhmYWFmZDc5MDk1MmYxZjEyYmFiM2IzNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.tcwILTspTfoXNqLWwnfH9S6uhhub0ydVOg6Dn-5KpBo"><img src="https://private-user-images.githubusercontent.com/60828015/405260342-66b4c6f4-3617-4b79-9612-89a90aa7690c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUyNjAzNDItNjZiNGM2ZjQtMzYxNy00Yjc5LTk2MTItODlhOTBhYTc2OTBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRjZmQ3NzNkZDZhYWI2MTFlODU0Mjc4MjlhMTU2ZDI5ZWMxYjJhMjhmYWFmZDc5MDk1MmYxZjEyYmFiM2IzNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.tcwILTspTfoXNqLWwnfH9S6uhhub0ydVOg6Dn-5KpBo" alt="image"></a></p>
<p dir="auto"><h4 dir="auto">3. Attack</h4><a id="user-content-3-attack" aria-label="Permalink: 3. Attack" href="#3-attack"></a></p>
<p dir="auto">After the targets opens the conversation (verify this with read recipts), their device should download the attachment which in turn causes Cloudflare to cache the file in a local datacenter.</p>
<p dir="auto">I ran this attack on myself, used the CLI tool I mentioned earlier with the attachment url and found local datacenters that had cached the attachment.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404906566-1ae6102d-263e-4af6-9073-f3665589d753.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5MDY1NjYtMWFlNjEwMmQtMjYzZS00YWY2LTkwNzMtZjM2NjU1ODlkNzUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM3MzRlMTNiMWExMmU5N2JjOWY1OGMxOWI4MTJkMTQ5MjJiZmE4MGNlZDQyZjVhMmVjZTVkMTEwNTcyNGZhYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aqJ5KDc4E8LRYcM7AT0B7oV5qMGz5Ee5TfhQFFYzcDk"><img width="927" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404906566-1ae6102d-263e-4af6-9073-f3665589d753.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5MDY1NjYtMWFlNjEwMmQtMjYzZS00YWY2LTkwNzMtZjM2NjU1ODlkNzUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM3MzRlMTNiMWExMmU5N2JjOWY1OGMxOWI4MTJkMTQ5MjJiZmE4MGNlZDQyZjVhMmVjZTVkMTEwNTcyNGZhYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aqJ5KDc4E8LRYcM7AT0B7oV5qMGz5Ee5TfhQFFYzcDk"></a>
<p dir="auto">In my case, I'm in New York and one of the closest datacenters to me is Newark, NJ (EWR) which is about 150 miles from my actual coordinates.</p>
<p dir="auto">With an innocent-looking attachment, an attacker can deanonymize users and find their location within an approximate radius.</p>
<p dir="auto"><h2 dir="auto">0-click</h2><a id="user-content-0-click" aria-label="Permalink: 0-click" href="#0-click"></a></p>
<p dir="auto">Here's where things get interesting. Although the 1-click method works, it requires the user to open the Signal conversation. Is it possible to run this attack without a single user interaction? Enter push notifications.</p>
<p dir="auto"><h3 dir="auto">Push Notifications</h3><a id="user-content-push-notifications" aria-label="Permalink: Push Notifications" href="#push-notifications"></a></p>
<p dir="auto">Signal's mobile app has 3 push notification settings. <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404989825-fed86790-9915-43a2-9d8b-18a7e5edef62.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5ODk4MjUtZmVkODY3OTAtOTkxNS00M2EyLTlkOGItMThhN2U1ZWRlZjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM5NjhmNTEzMTdmMGY1M2JlYjA5ZDU5MDM5NzdhNmYyMGM2MTBlNjEwMWUyMjBkZTQwODI3ZDU0MmEyOTEzMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.h80OARR8R2LhuMFTFkSnMEKtoqZiVMqsv6OgHhYAktU"><img width="400" src="https://private-user-images.githubusercontent.com/60828015/404989825-fed86790-9915-43a2-9d8b-18a7e5edef62.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5ODk4MjUtZmVkODY3OTAtOTkxNS00M2EyLTlkOGItMThhN2U1ZWRlZjYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM5NjhmNTEzMTdmMGY1M2JlYjA5ZDU5MDM5NzdhNmYyMGM2MTBlNjEwMWUyMjBkZTQwODI3ZDU0MmEyOTEzMzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.h80OARR8R2LhuMFTFkSnMEKtoqZiVMqsv6OgHhYAktU"></a></p>
<p dir="auto">Push Notifications are triggered if the user receives a message while not actively on the Signal app. By default, the mobile app includes the author, and message when it sends a push notification to your device. <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404992822-f33a0364-9119-4634-ae0b-4d3af7ee53db.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTI4MjItZjMzYTAzNjQtOTExOS00NjM0LWFlMGItNGQzYWY3ZWU1M2RiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ3NjhkZTA3M2U5NjRkNDVhYzgwNDJkNmE5ODU1YTQ5OTY1Njc1OWYwYjRiZjQ2ZjMzMzBjZGNiZTFjZTFhMzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lbiey-lyN-KPKMBXZp7Oxw-xAlyGRDtd5T5mUKivu1c"><img width="612" alt="image" src="https://private-user-images.githubusercontent.com/60828015/404992822-f33a0364-9119-4634-ae0b-4d3af7ee53db.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTI4MjItZjMzYTAzNjQtOTExOS00NjM0LWFlMGItNGQzYWY3ZWU1M2RiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ3NjhkZTA3M2U5NjRkNDVhYzgwNDJkNmE5ODU1YTQ5OTY1Njc1OWYwYjRiZjQ2ZjMzMzBjZGNiZTFjZTFhMzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lbiey-lyN-KPKMBXZp7Oxw-xAlyGRDtd5T5mUKivu1c"></a></p>
<p dir="auto">The image shown on the right of the notification is the attachment sent with the message from Signal.</p>
<p dir="auto">If the target has push notifications enabled (which it is by default), they don't even have to open the Signal conversation for their device to download the attachment. Once the push notification is sent to their device, it automatically downloads the image from Signal's CDN triggering the local datacenter to cache the response.</p>
<p dir="auto">An attacker can run this deanonymization attack any time and grab a user's current location without a single interaction.</p>
<hr>
<p dir="auto">Signal, like Telegram, is used by journalists, activists, whisteblowers from all over the world. The potiental for this attack is massive. This attack can be used to track Signal accounts, correlate identities, find employees meeting with journalists and much more.</p>
<p dir="auto"><h2 dir="auto">Real-World Application: Discord</h2><a id="user-content-real-world-application-discord" aria-label="Permalink: Real-World Application: Discord" href="#real-world-application-discord"></a></p>
<p dir="auto">During my research, another app I found vulnerable to this type of attack is Discord. Discord is a free app that allows users to communicate with each other through text, voice, and video. Although the app is targeted towards gamers, Discord has been in the news recently this past year for facilitating government leaks and Discord hosts a significant portion of cybercrime on the internet.</p>
<p dir="auto">The 1-click aspect is very simple and fairly similar to Signal, I would say the impact is even wider with Discord. Discord allows users with a Nitro subscription (their $9.99/mo premium service) to use custom emojis in a variety of places: Messages, User Presence, Channels, etc. These custom emojis are loaded from Discord's CDN and are configured to be cached on Cloudflare. An attacker can use the same deanonymization attack with Signal to deanonymize users.</p>
<p dir="auto">So, instead of sending an attachment in a Discord channel, an attacker can display a custom emoji in their user status and simply wait for the target to open their profile to run a deanonymization attack.</p>
<p dir="auto">I've disclosed the <a href="https://gist.github.com/hackermondev/7d9ae6b372159de7b9d3d7bb82a32ed2">entire HackerOne report</a> I sent to Discord which has specific details, but I want to focus on the 0-click aspect here.</p>
<p dir="auto">In Discord, mobile push notifications are sent for a variety of events (not just for messages recieved like Signal). For example, sending a friend request to a Discord user triggers a push notification on the user's mobile device.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/404999739-6a013d85-1c4c-406d-8638-e77430a7c723.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTk3MzktNmEwMTNkODUtMWM0Yy00MDZkLTg2MzgtZTc3NDMwYTdjNzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlYzQ2MmZhMjgwNmJiNDRlY2Y2MTNhYTBlYTA0MzdmOWJhMzcxMGRjZTcwMjgxZTBmNjJiMGU3MjdjMmUyODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.JyXivn4opt3kZQVE1z18r16bmpRTMyHGKB8m_3daXT8"><img src="https://private-user-images.githubusercontent.com/60828015/404999739-6a013d85-1c4c-406d-8638-e77430a7c723.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDQ5OTk3MzktNmEwMTNkODUtMWM0Yy00MDZkLTg2MzgtZTc3NDMwYTdjNzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlYzQ2MmZhMjgwNmJiNDRlY2Y2MTNhYTBlYTA0MzdmOWJhMzcxMGRjZTcwMjgxZTBmNjJiMGU3MjdjMmUyODEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.JyXivn4opt3kZQVE1z18r16bmpRTMyHGKB8m_3daXT8" alt="image"></a></p>
<p dir="auto">Interestingly, even if the user is actively on Discord, friend request notifications are always sent to the user's mobile device.</p>
<p dir="auto">How would a deanonymization attack be used with a friend request notification? Well, take a look at the notification.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405000417-4eaa5e0e-4ebf-4e43-98ca-029ec7dd6591.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDA0MTctNGVhYTVlMGUtNGViZi00ZTQzLTk4Y2EtMDI5ZWM3ZGQ2NTkxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg5MDVkMDU3MjUyNGNmMTlmZDI2YjQyMTU0MjdiNjI4OTA5NzQ3MDdkMTU4ZDE3YTdhYmEwOWIwOTYzMDY5ZWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AkBWRoah9wcRf1WhHcSFOh2g5lZ_S-YVB2TnHdBR0Ls"><img src="https://private-user-images.githubusercontent.com/60828015/405000417-4eaa5e0e-4ebf-4e43-98ca-029ec7dd6591.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDA0MTctNGVhYTVlMGUtNGViZi00ZTQzLTk4Y2EtMDI5ZWM3ZGQ2NTkxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg5MDVkMDU3MjUyNGNmMTlmZDI2YjQyMTU0MjdiNjI4OTA5NzQ3MDdkMTU4ZDE3YTdhYmEwOWIwOTYzMDY5ZWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.AkBWRoah9wcRf1WhHcSFOh2g5lZ_S-YVB2TnHdBR0Ls" alt="image"></a></p>
<p dir="auto">When you recieve a friend request and Discord sends the notification to your device, it includes the user's avatar url to be shown with the notification. Your phone downloads the avatar url (without any user interaction) and displays it alongside the notification.</p>
<p dir="auto">Discord has Cloudflare caching configured on the CDN path for avatar urls, which means we can simply do the same cache location attack mentioned earlier.</p>
<p dir="auto">In Discord, the avatar URL format used in push notifications is: <code>https://cdn.discordapp.com/avatars/{user_id}/{avatar_hash}</code>. The avatar URL format used in the website to display user avatars is slightly different (it always contains an image extension) (<code>https://cdn.discordapp.com/avatars/{user_id}/{avatar_hash}.png</code>).</p>
<p dir="auto">Both URLs leads to the same image but since images displayed in the app have a different path, they're cached separately. This ensures our results are not polluted and allows us to ensure we are finding the datacenter of a device that loaded the avatar through a push notification and not just the profile on the Discord app.</p>
<p dir="auto">Just like that, we have the steps for a 0-click version of this attack for Discord:</p>
<ol dir="auto">
<li>Change your user avatar. This randomizes your avatar hash and ensures your avatar URL has not been loaded by anyone yet, increasing the accuracy of the attack.</li>
<li>Send a friend request to the target. Although there's a variety of ways to trigger push notifications with Discord, I choose friend requests because they are always sent regardless of whether the user is active on Discord. They also don't require any mutual server with the target, meaning you can practically do this with anyone on Discord.</li>
<li>Use Cloudflare Teleport tool on the user avatar and find all local datacenters that have cached the avatar</li>
</ol>
<p dir="auto"><h2 dir="auto">GeoGuesser</h2><a id="user-content-geoguesser" aria-label="Permalink: GeoGuesser" href="#geoguesser"></a></p>
<p dir="auto">I'm very familar with Discord's API and I realized I could automate every step in Discord's 0-click attack, and so I did.</p>
<p dir="auto">Introducing GeoGuesser. This is a private Discord bot with a single command that takes a username, runs an attack with the steps mentioned earlier and returns the result entirely through Discord.</p>
<p dir="auto">When the command is called, it uses my account credentials to access the Discord User API, changes the user avatar to a randomly generated image (to randomize the hash) and sends a friend request to a username specified.
Finally, it uses a private API based on the Cloudflare Teleport CLI to run the same cache enumeration attack and displays the results directly on Discord, all in less than 30 seconds.</p>
<p dir="auto">To show the extent of this attack, one of the first users I tried this attack on was Stanislav Vishnevskiy, Discord's CTO.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405007407-66914f42-880b-4d23-8902-3cb2f3170118.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDc0MDctNjY5MTRmNDItODgwYi00ZDIzLTg5MDItM2NiMmYzMTcwMTE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlOTIyODA2MTNkMWIzMTY1MTI2NmE2YTEzODEyNTJmYzMyNTUyNjM2ZTZiMWJiNDMyMmFmMDNmMDcyNjZkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.FwgvcrMsd6ou856NncFAvDFRelAEfJ44nF469sXsIeI"><img width="400" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405007407-66914f42-880b-4d23-8902-3cb2f3170118.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMDc0MDctNjY5MTRmNDItODgwYi00ZDIzLTg5MDItM2NiMmYzMTcwMTE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlOTIyODA2MTNkMWIzMTY1MTI2NmE2YTEzODEyNTJmYzMyNTUyNjM2ZTZiMWJiNDMyMmFmMDNmMDcyNjZkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.FwgvcrMsd6ou856NncFAvDFRelAEfJ44nF469sXsIeI"></a></p>
<p dir="auto">Here's the bot in action:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e6c10bf50e18f41533bdaa12626f2eb3ceb6644d65f4f11776311a454c3daa69/68747470733a2f2f6e696e6a612e646f672f4b556971684a2e676966"><img src="https://camo.githubusercontent.com/e6c10bf50e18f41533bdaa12626f2eb3ceb6644d65f4f11776311a454c3daa69/68747470733a2f2f6e696e6a612e646f672f4b556971684a2e676966" alt="geogueser live gif" data-animated-image="" data-canonical-src="https://ninja.dog/KUiqhJ.gif"></a></p>
<p dir="auto">The bot sends a friend request to Stan, then waits a couple of seconds to ensure he receives the push notification.</p>
<p dir="auto">It finds 2 local Cloudflare datacenters that have cached the avatar. This could mean he has multiple devices hooked up with his Discord account that recieved the push notification, or his device loaded the avatar twice and the requests were load balanced within different datacenters.</p>
<p dir="auto">GeoGuesser, powered by the Google Maps API, generates a likely location of the user. It finds the midpoint between the 2 datacenters and draws 2 circles that signify his radius.</p>
<p dir="auto">Discord's HQ is located in San Francisco, CA (which is in the outer circle) so this map is accurate. Stan is most likely located somewhere near the edge of the inner circle which is about ~300 miles.</p>
<p dir="auto">This entire process took less than a minute to run. I'm sure Stan saw the notification on his phone, didn't think twice and simply dismissed it. This was just a simple attack but this attack, if calibrated, can be used to track and monitor Stan's location.</p>
<p dir="auto">An attacker like this can be launched on any Discord user and it's almost undetectable.</p>
<p dir="auto"><h2 dir="auto">Bug Bounty Reports</h2><a id="user-content-bug-bounty-reports" aria-label="Permalink: Bug Bounty Reports" href="#bug-bounty-reports"></a></p>
<p dir="auto">I responsibly disclosed to the affected parties my research, hoping something would be done to protect or warn users against this type of deanonymization attack but I was mostly disappointed.</p>
<p dir="auto"><h3 dir="auto">Signal</h3><a id="user-content-signal" aria-label="Permalink: Signal" href="#signal"></a></p>
<p dir="auto">Signal instantly dismissed my report, saying it wasn't their responsibility and it was up to users to hide their identity: "Signal has never attempted to fully replicate the set of network-layer anonymity features that projects like Wireguard, Tor, and other open-source VPN software can provide".</p>
<p dir="auto">I disagree with this. Signal markets itself as a privacy-first communication platform. While it does not claim to provide network-layer anonymity like Tor, users trust Signal to minimize privacy risks.</p>
<p dir="auto">The vulnerability demonstrates that the platform unintentionally leaks information that could narrow down a user’s location within a few hundred miles. This leakage conflicts with the expectations of many privacy-conscious users who rely on Signal for more than just end-to-end encryption.</p>
<p dir="auto">Telegram, another privacy-focused application, is completely invulnerable to this attack as (1) they use a custom in-house built protocol thats not reliant on HTTP and (2) don't rely on cloud providers like Cloudflare for caching.</p>
<p dir="auto"><h3 dir="auto">Discord</h3><a id="user-content-discord" aria-label="Permalink: Discord" href="#discord"></a></p>
<p dir="auto">Initially, Discord's Security Team promised to look into this and make changes to protect their users against this type of attack but eventually they also changed their position on this, citing this as a Cloudflare issue other consumers are also vulnerable to.</p>
<p dir="auto"><h3 dir="auto">Cloudflare</h3><a id="user-content-cloudflare-1" aria-label="Permalink: Cloudflare" href="#cloudflare-1"></a></p>
<p dir="auto">Cloudflare ended up completing patching the bug used by Cloudflare Teleport to traverse datacenters. The bug had been reported to their HackerOne program a year ago by another reporter, but they hadn't done anything about it back then since they didn't see any impact of traversing datacenters until I shared my research.</p>
<p dir="auto">Cloudflare reopened the old report, resolved it and awarded a bounty to my report and the original.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405028347-30568091-c856-4dc8-a70d-335acf70f397.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMjgzNDctMzA1NjgwOTEtYzg1Ni00ZGM4LWE3MGQtMzM1YWNmNzBmMzk3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkzZjZjODRlYzEwM2EzZGRmYzZlMzk4NjMwNjdhMThjMjkwMGQ4ZDcxY2M5NDJiMDk2NDU5ZDBkYTBmMTRkYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NbJ0Q0iSGzpE42l94hAD_q5Tmq-AyQdSvsmTIYuj1JA"><img width="681" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405028347-30568091-c856-4dc8-a70d-335acf70f397.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMjgzNDctMzA1NjgwOTEtYzg1Ni00ZGM4LWE3MGQtMzM1YWNmNzBmMzk3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkzZjZjODRlYzEwM2EzZGRmYzZlMzk4NjMwNjdhMThjMjkwMGQ4ZDcxY2M5NDJiMDk2NDU5ZDBkYTBmMTRkYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NbJ0Q0iSGzpE42l94hAD_q5Tmq-AyQdSvsmTIYuj1JA"></a></p>
<p dir="auto">Although this is a step in the right direction, this doesn't actually fix the core issue here. Every attack shown in this write up has been done in the last 24 hours even though Cloudflare patched this bug weeks ago. Cloudflare patched the bug inside their network that facilitated datacenter traversal, but that's not the only way to easilly traverse datacenters all over the world.</p>
<p dir="auto">24 hours after their patch, I reprogrammed Cloudflare Teleport to use a VPN instead. Numerous VPNs provide multiple locations that users can connect to which sends their traffic through servers in different parts of the world and these servers map to different Cloudflare datacenters all over the world.</p>
<p dir="auto">I chose a VPN provider with over 3,000 servers located in various locations across 31 different countries worldwide. Using this new method, I'm able to reach about 54% of all Cloudflare datacenters again. While this doesn't sound like a lot, this covers most places in the world with significant population.</p>
<hr>
<p dir="auto">Cloudflare's final statement about this says they do not consider the deanonymization attack to be a vulnerability in their own systems and it is up to their consumers to disable caching for resources they wish to protect.
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/60828015/405032649-da8cd7ea-2c28-444c-af4e-3fc51fa14f92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMzI2NDktZGE4Y2Q3ZWEtMmMyOC00NDRjLWFmNGUtM2ZjNTFmYTE0ZjkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk4MWYwMWY4YWJjYTYwNWUxZmQzNDQwYTA5ODJlODIyZGNlNjFiY2FmOWU3OGI3MzYxMDIwYjM2NGZhM2RkZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NoMiKhLXuiig4kXDaEujpZzZYrujjBl7lJUkkEnxUSU"><img width="889" alt="image" src="https://private-user-images.githubusercontent.com/60828015/405032649-da8cd7ea-2c28-444c-af4e-3fc51fa14f92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc0NzczMDEsIm5iZiI6MTczNzQ3NzAwMSwicGF0aCI6Ii82MDgyODAxNS80MDUwMzI2NDktZGE4Y2Q3ZWEtMmMyOC00NDRjLWFmNGUtM2ZjNTFmYTE0ZjkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTIxVDE2MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk4MWYwMWY4YWJjYTYwNWUxZmQzNDQwYTA5ODJlODIyZGNlNjFiY2FmOWU3OGI3MzYxMDIwYjM2NGZhM2RkZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.NoMiKhLXuiig4kXDaEujpZzZYrujjBl7lJUkkEnxUSU"></a></p>
<p dir="auto">There's clearly a problem here as Cloudflare says consumers are responsible for protecting themselves against these types of attacks, while consumers (ex. Discord) are putting the blame on Cloudflare.</p>
<p dir="auto"><h2 dir="auto">How to Protect Yourself</h2><a id="user-content-how-to-protect-yourself" aria-label="Permalink: How to Protect Yourself" href="#how-to-protect-yourself"></a></p>
<p dir="auto">The potential for exploitation using this deanonymization attack is significant, especially for users in sensitive positions like journalists, activists, and privacy-conscious individuals. The attack leverages fundamental design decisions in caching and push notification systems, demonstrating how infrastructure meant to enhance performance can be misused for invasive tracking.</p>
<p dir="auto">Although Cloudflare has patched the Teleport bug, and some applications like Discord and Signal may have implemented mitigation measures following my disclosure, the underlying risks remain. Any app using a CDN for content delivery and caching can still be vulnerable if the proper precautions aren’t taken.</p>
<p dir="auto"><h2 dir="auto">Final Thought</h2><a id="user-content-final-thought" aria-label="Permalink: Final Thought" href="#final-thought"></a></p>
<p dir="auto">This attack highlights how complex and interconnected the digital ecosystem has become. While CDNs improve performance and scalability, they also inadvertently introduce risks that can be exploited in novel ways. By raising awareness and promoting best practices, we can work together to minimize the potential for abuse.</p>
<p dir="auto">For users in sensitive roles or those concerned about their privacy, the key takeaway is this: stay informed and vigilant. While no system is entirely foolproof, taking steps to limit your exposure can make a significant difference.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Metacognitive laziness: Effects of generative AI on learning motivation (218 pts)]]></title>
            <link>https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544</link>
            <guid>42780022</guid>
            <pubDate>Tue, 21 Jan 2025 13:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544">https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544</a>, See on <a href="https://news.ycombinator.com/item?id=42780022">Hacker News</a></p>
Couldn't get https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13544: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Organize local communities without Facebook? (223 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42779776</link>
            <guid>42779776</guid>
            <pubDate>Tue, 21 Jan 2025 13:19:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42779776">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42779776: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA['It's a nightmare': couriers mystified by the algorithms that control their jobs (127 pts)]]></title>
            <link>https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs</link>
            <guid>42779544</guid>
            <pubDate>Tue, 21 Jan 2025 12:51:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs">https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs</a>, See on <a href="https://news.ycombinator.com/item?id=42779544">Hacker News</a></p>
Couldn't get https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[People are bad at reporting what they eat. That's a problem for dietary research (213 pts)]]></title>
            <link>https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research</link>
            <guid>42779147</guid>
            <pubDate>Tue, 21 Jan 2025 11:54:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research">https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research</a>, See on <a href="https://news.ycombinator.com/item?id=42779147">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/people-are-bad-reporting-what-they-eat-s-problem-dietary-research: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Startup Winter: Hacker News Lost Its Faith (459 pts)]]></title>
            <link>https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/</link>
            <guid>42778266</guid>
            <pubDate>Tue, 21 Jan 2025 10:00:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/">https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/</a>, See on <a href="https://news.ycombinator.com/item?id=42778266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>In 2013, a failing founder posted their story on Hacker News (<a href="https://news.ycombinator.com/item?id=5255209">link</a>). The responses were overwhelmingly supportive: "Failure is just an event, not who you are." "Get back up and try again!" "This is valuable experience for next time."</p>
<p>Fast forward to 2025. Another founder shares their journey of six failed attempts (<a href="https://news.ycombinator.com/item?id=42771676">link</a>). The sentiment in the comments is strikingly different: "Would have been better to work at BigTech." "The rat race isn't worth it." "Most interesting stories remain buried while we're presented with a somewhat skewed reality."</p>
<p>This shift isn't isolated to these two posts. The same forum that championed "fail fast, fail often" now regularly questions whether the startup path makes sense at all.</p>
<p>What's changed?</p>
<ol>
<li>
<p>The human cost has become more visible. Stories of burnout, failed relationships, and mental health struggles are no longer swept under the rug of "hustle culture."</p>
</li>
<li>
<p>Big Tech compensation has transformed the risk-reward equation. When senior engineers can make $300K+ at established companies, the financial argument for startups becomes harder to justify.</p>
</li>
<li>
<p>The VC model's limitations have become apparent. The focus on hypergrowth and exits has left many founders feeling trapped between authentic business building and investor expectations.</p>
</li>
<li>
<p>The industry has matured. The low-hanging fruit of the mobile/web era has largely been picked, making truly innovative opportunities harder to find.</p>
</li>
</ol>
<p>I believe we're entering what might be called a "Startup Winter" - not because startups have stopped being created, but because the mythology around them has frozen over.</p>
<p>What might emerge from this winter could be a startup ecosystem that's less glamorous but more authentic. One where alternative paths to innovation are celebrated alongside the traditional VC-backed route.</p>

<!-- #comments -->

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Censoring '#Democrat' on Instagram (227 pts)]]></title>
            <link>https://mstdn.chrisalemany.ca/@chris/113864600222476627</link>
            <guid>42777938</guid>
            <pubDate>Tue, 21 Jan 2025 09:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mstdn.chrisalemany.ca/@chris/113864600222476627">https://mstdn.chrisalemany.ca/@chris/113864600222476627</a>, See on <a href="https://news.ycombinator.com/item?id=42777938">Hacker News</a></p>
Couldn't get https://mstdn.chrisalemany.ca/@chris/113864600222476627: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Kimi K1.5: Scaling Reinforcement Learning with LLMs (156 pts)]]></title>
            <link>https://github.com/MoonshotAI/Kimi-k1.5</link>
            <guid>42777857</guid>
            <pubDate>Tue, 21 Jan 2025 08:53:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/MoonshotAI/Kimi-k1.5">https://github.com/MoonshotAI/Kimi-k1.5</a>, See on <a href="https://news.ycombinator.com/item?id=42777857">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf"><img width="80%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/kimi_k1.5.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kimi k1.5: Scaling Reinforcement Learning with LLMs</h2><a id="user-content-kimi-k15-scaling-reinforcement-learning-with-llms" aria-label="Permalink: Kimi k1.5: Scaling Reinforcement Learning with LLMs" href="#kimi-k15-scaling-reinforcement-learning-with-llms"></a></p>
<p dir="auto">
  <b>Kimi Team</b>
</p>
<p dir="auto">
  <a href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf"><img src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/logo.png" height="16" width="16"><b> Full Report</b></a>
</p>
<p dir="auto">🚀 Introducing Kimi k1.5 --- an o1-level multi-modal model</p>
<ul dir="auto">
<li>Sota short-CoT performance, outperforming GPT-4o and Claude Sonnet 3.5 on 📐AIME, 📐MATH-500, 💻 LiveCodeBench by a large margin (up to +550%)</li>
<li>Long-CoT performance matches o1 across multiple modalities (👀MathVista, 📐AIME, 💻Codeforces, etc)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Abstract</h2><a id="user-content-abstract" aria-label="Permalink: Abstract" href="#abstract"></a></p>
<p dir="auto">Language model pretraining with next token prediction has proved effective for scaling compute but is limited to the amount of available training data. Scaling reinforcement learning (RL) unlocks a new axis for the continued improvement of artificial intelligence, with the promise that large language models (LLMs) can scale their training data by learning to explore with rewards. However, prior published work has not produced competitive results. In light of this, we report on the training practice of Kimi k1.5, our latest multi-modal LLM trained with RL, including its RL training techniques, multi-modal data recipes, and infrastructure optimization. Long context scaling and improved policy optimization methods are key ingredients of our approach, which establishes a simplistic, effective RL framework without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models. Notably, our system achieves state-of-the-art reasoning performance across multiple benchmarks and modalities---e.g., 77.5 on AIME, 96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista---matching OpenAI's o1. Moreover, we present effective long2short methods that use long-CoT techniques to improve short-CoT models, yielding state-of-the-art short-CoT reasoning results---e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on LiveCodeBench---outperforming existing short-CoT models such as GPT-4o and Claude Sonnet 3.5 by a large margin (up to +550%). The service of Kimi k1.5 on <a href="https://kimi.ai/" rel="nofollow">https://kimi.ai</a> will be available soon.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/benchmark-long.jpeg"><img width="100%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/benchmark-long.jpeg"></a>
</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/benchmark-short.jpeg"><img width="100%" src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/benchmark-short.jpeg"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Ingredients of Kimi k1.5</h2><a id="user-content-key-ingredients-of-kimi-k15" aria-label="Permalink: Key Ingredients of Kimi k1.5" href="#key-ingredients-of-kimi-k15"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/MoonshotAI/Kimi-k1.5/blob/main/images/system.png"><img src="https://github.com/MoonshotAI/Kimi-k1.5/raw/main/images/system.png" alt="The Reinforcement Learning Training System for LLM"></a>
</p>
<p dir="auto">There are a few key ingredients about the design and training of k1.5.</p>
<ul dir="auto">
<li><strong>Long context scaling</strong>. We scale the context window of RL to 128k and observe continued improvement of performance with an increased context length. A key idea behind our approach is to use partial rollouts to improve training efficiency---i.e., sampling new trajectories by reusing a large chunk of previous trajectories, avoiding the cost to re-generate the new trajectories from scratch. Our observation identifies the context length as a key dimension of the continued scaling of RL with LLMs.</li>
<li><strong>Improved policy optimization</strong>. We derive a formulation of RL with long-CoT and employ a variant of online mirror descent for robust policy optimization. This algorithm is further improved by our effective sampling strategy, length penalty, and optimization of the data recipe.</li>
<li><strong>Simplistic Framework</strong>. Long context scaling, combined with the improved policy optimization methods, establishes a simplistic RL framework for learning with LLMs. Since we are able to scale the context length, the learned CoTs exhibit the properties of planning, reflection, and correction. An increased context length has an effect of increasing the number of search steps. As a result, we show that strong performance can be achieved without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models.</li>
<li><strong>Mutimodalities</strong>. Our model is jointly trained on text and vision data, which has the capabilities of jointly reasoning over the two modalities.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test Model by API</h2><a id="user-content-test-model-by-api" aria-label="Permalink: Test Model by API" href="#test-model-by-api"></a></p>
<p dir="auto">You can test Kimi k1.5 through the Kimi OpenPlatform. Fill out the test application form in <a href="https://forms.gle/TqZ9XQnPiJPddzhV8" rel="nofollow">this link</a>. We will contact you via email to provide a test account later.</p>
<p dir="auto">Here's an example of calling Kimi k1.5</p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai import Client

client = Client(
    api_key=&quot;YOUR_KIMI_KEY&quot;,
    base_url=&quot;https://api.moonshot.ai/v1&quot;,
)

messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;The lengths of the two legs of a right triangle are 3 cm and 4 cm respectively. Find the length of the hypotenuse of this right triangle.&quot;,
    },
]

stream = client.chat.completions.create(
    model=&quot;kimi-k1.5-preview&quot;,
    messages=messages,
    temperature=0.3,
    stream=True,
    max_tokens=8192,
)

for chunk in stream:
    if chunk.choices[0].delta:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end=&quot;&quot;)
"><pre><span>from</span> <span>openai</span> <span>import</span> <span>Client</span>

<span>client</span> <span>=</span> <span>Client</span>(
    <span>api_key</span><span>=</span><span>"YOUR_KIMI_KEY"</span>,
    <span>base_url</span><span>=</span><span>"https://api.moonshot.ai/v1"</span>,
)

<span>messages</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: <span>"The lengths of the two legs of a right triangle are 3 cm and 4 cm respectively. Find the length of the hypotenuse of this right triangle."</span>,
    },
]

<span>stream</span> <span>=</span> <span>client</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
    <span>model</span><span>=</span><span>"kimi-k1.5-preview"</span>,
    <span>messages</span><span>=</span><span>messages</span>,
    <span>temperature</span><span>=</span><span>0.3</span>,
    <span>stream</span><span>=</span><span>True</span>,
    <span>max_tokens</span><span>=</span><span>8192</span>,
)

<span>for</span> <span>chunk</span> <span>in</span> <span>stream</span>:
    <span>if</span> <span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>:
        <span>if</span> <span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>.<span>content</span>:
            <span>print</span>(<span>chunk</span>.<span>choices</span>[<span>0</span>].<span>delta</span>.<span>content</span>, <span>end</span><span>=</span><span>""</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<div data-snippet-clipboard-copy-content="@article{MoonshotAI,
  author = {Kimi Team},
  title = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  year = {2025},
}"><pre><code>@article{MoonshotAI,
  author = {Kimi Team},
  title = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  year = {2025},
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We've lost our respect for complexity (101 pts)]]></title>
            <link>https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/</link>
            <guid>42777715</guid>
            <pubDate>Tue, 21 Jan 2025 08:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/">https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/</a>, See on <a href="https://news.ycombinator.com/item?id=42777715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-amp-original-style="padding-top:var(--wp--preset--spacing--60);padding-bottom:var(--wp--preset--spacing--60)">
<p>I was talking recently to a friend about a video essayist I like, (Dan Olson of Folding Ideas) and when asked why I thought he was any good I pondered it for a moment and said “he has a lot of respect for complexity”. On reflection, I think that is one of the virtues I look for in new people I meet more generally. It’s not that we always have to be knees-deep in the details of a topic, but just being able to respect complexity, even that which you don’t understand, is something that I find admirable. Yet, over time, I feel we have lost a lot of our own respect for these people. Complexity is <em>hard</em>. Hard to work with, hard to remove if it’s unnecessary, but most of all hard to understand. We talk about complex subjects all the time. Medicine, politics, economics, sociology, morality and more. These are all deep topics that you can study your entire life, but everyone will end up talking about most of these, even quite often. So this isn’t just about academic papers and overly abstract hand-wavy blogposts like this one. I’m talking memes, news, thanksgiving dinner arguments, water cooler chats. We are constantly asking our brains to grasp at complex topics and distill down at least our own perception of them to something manageable.</p>



<p>We may be becoming worse at this. It’s not set in stone but the need to have quick and easy explanations for things, having peaked many centuries ago, has begun to rise again since the techno-optimistic days of only a few decades ago. That’s not been entirely without good reason, many things were promised then that have failed to materialize. From flying cars to world peace, some more sought than others. But the idea was that we would trust that society was heading in a good direction, and so these complex topics could be safely left to some group of people who would make it their life careers and so overall we would trust them to get the job done. Now, when many may challenge that notion of consistent progress of the world toward a brighter future, letting somebody else do it just doesn’t seem so right. Instead we now live in a time of doing your own research, of skepticism, but most of all, of the idea that understanding the full complexity of every topic that might cross your path is not only possible, but somehow, expected.</p>



<h2>How did this happen?</h2>



<p>Lots of people have spoken about the information age and what the internet has done for our perceptions of things. You can also look at geopolitical issues and point fingers to tensions or collapsing trust due to specific events. Even one can talk about how the improving lives we live can make us forget about both the value of what we have and the work it took to get there (I’m thinking of vaccines). All of these are valid contributing factors that others have covered, but I want to talk about one I love to talk about in general: Automation.</p>



<p>What does robots taking our jobs have anything to do with people’s respect for complexity? Well, it’s simple. One of the best ways of improving your understanding of something is proximity to it. Do you work in the steel industry? You probably get a better feel for how manufacturing works. Are you waitstaff? You’ll probably live the rest of your life being kind to servers. Does your friend you know work in an essential industry for the economy? You will over time develop a better idea of how much real complexity is involved in that thing. These are not useless anecdotal ideas if they allow you to give more respect for <em>other areas you do not understand but believe are equally complex.</em> Having a deeper understanding of a <em>single</em> value creating and complex system helps us put other such systems into context (at least, for most people). As we take these foundational industries like agriculture, manufacturing, engineering, construction, and automate them (or for that matter, move them overseas) we detach ourselves from real complexity and I think we lose something from that. Then, when we are trying to contextualize grocery prices, repair costs, bugs in our software, roadworks that seem to never end, we do a worse job. We likely get frustrated looking for an answer that may be many fathoms deep in the details. Now, it was never likely that your cousin who does road work might be in the car with you to explain the intricacies of asphalting, but almost as good is to simply have a respect for the complexity that is almost certainly involved. You don’t even need your cousin to tell you that.</p>



<h2>What to do?</h2>



<p>Am I implying that we should all get out our shovels and start little home gardens? Well, I don’t think that would be a <em>bad</em> idea, but notice that even people who do that may still not grasp the complexity of the global agriculture industry (in fact, people who grow their own gardens are more likely doing it because of a distrust of that industry). So, really, the gulf between subsistence farming and modern complex industries is to large to be crossed on its own.</p>



<p>Schools, then? Sadly, the education system itself suffers from the effects of this lack of respect. It does <em>seem </em>to currently be in a negative cycle, meaning less trust in teachers means less funding, which leads to less understanding kid’s and so on. However, <a href="https://en.wiktionary.org/wiki/juvenoia">juvenoia</a> is a recurring theme across history so I’m inclined to be optimistic. This may just be part of the ebb and flow of trends and ideas. Still, clear answers don’t seem ahead of us</p>



<p>What? Don’t look at me like that? I didn’t promise you any solutions at the start of this text. It’s a complex problem, and it’d be genuinely ironic if I now gave you the fix-all solution. I have more respect for the problem than to try and do that in a blogpost. Still, it’s very easy to get worried about the rhetoric and the new developments in news and elsewhere that seem to all point to disaster, and wanting some comfort. If there’s merit to this theory above then another big question of our time, how much might AI disrupt human labor, will have even more riding on its outcome. All I can do is continue looking for those people who have that respect for complexity. Some find them boring, or indecisive, or just wrong for not buying into some extreme. I think those are dumb ideas. My trust in people rises immensely these days when they have the ability to sincerely say “I don’t know”. Being all-knowing shouldn’t be the coolest thing to be since, given that it’s impossible, anyone who comes off that way is, in a sense, lying. <em>Respect for complexity</em>? Now that is cool.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[United States Digital Service Renamed to DOGE (112 pts)]]></title>
            <link>https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/</link>
            <guid>42775684</guid>
            <pubDate>Tue, 21 Jan 2025 02:22:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/">https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/</a>, See on <a href="https://news.ycombinator.com/item?id=42775684">Hacker News</a></p>
Couldn't get https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[It sure looks like Meta stole a lot of books to build its AI (139 pts)]]></title>
            <link>https://lithub.com/it-sure-looks-like-meta-stole-a-lot-of-books-to-build-its-ai/</link>
            <guid>42775545</guid>
            <pubDate>Tue, 21 Jan 2025 01:59:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/it-sure-looks-like-meta-stole-a-lot-of-books-to-build-its-ai/">https://lithub.com/it-sure-looks-like-meta-stole-a-lot-of-books-to-build-its-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=42775545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				
				
				
				<p>It’s a grim week for Meta. The company formerly known as Facebook, and before that <a href="https://en.wikipedia.org/wiki/History_of_Facebook" target="_blank">Facemash</a>, “designed to evaluate the attractiveness of female Harvard students,” now encompasses Facebook, Instagram, Threads, WhatsApp, and Meta, the failed vision for a remote workplace, fun-zone, and Zucker-verse where <a href="https://x.com/MetaHorizon/status/1579947568372404226" target="_blank">legs are always just around the corner.</a></p>
<p>CEO and founder Mark Zuckerberg announced that <a href="https://theintercept.com/2025/01/09/facebook-instagram-meta-hate-speech-content-moderation/" target="_blank">slurs are okay</a> on their platforms, added <a href="https://apnews.com/article/meta-facebook-zuckerberg-board-members-dana-white-199436c62c934ebb751b564f874ad2f6" target="_blank">a pro-Trump UFC boss to their board</a>, and made <a href="https://www.axios.com/2025/01/10/mark-zuckerberg-joe-rogan-facebook-censorship-biden" target="_blank">appearances in the aggrieved weirdo media world</a> to make some convoluted case that we need more masculine energy in business, more resentment overall, and more fealty to Don Trump. Zuckerberg has also recently switched up his personal style so that he now looks like he’s perpetually in a sitcom flashback where an older actor is unconvincingly costumed to look like their younger self.</p>
<p>And in the Northern District of California,&nbsp;<em>Wired&nbsp;</em>reports, <a href="https://www.wired.com/story/new-documents-unredacted-meta-copyright-ai-lawsuit/" target="_blank">recently unredacted court documents reveal</a> that Meta used a database of pirated books to train its AI systems<i>. </i>These documents were unsealed as part of a copyright lawsuit, one of the earliest of <a href="https://www.wired.com/story/ai-copyright-case-tracker/" target="_blank">many similar cases</a>, called <i>Kadrey et al. v. Meta Platforms.</i> The plaintiffs in this case are a number of writers and performers, including Richard Kadrey, Christopher Golden, Junot Diaz, Laura Lippman, Sarah Silverman, Ta-Nehisi Coates, and—jump scare!—Mike Huckabee.</p>
<p>The <a href="https://www.wired.com/story/new-documents-unredacted-meta-copyright-ai-lawsuit/" target="_blank">new documents quote</a> Meta employees frankly admitting to using stolen stuff from a notorious piracy site:</p>
<p>…an internal quote from a Meta employee, included in the documents, in which they speculated, “If there is media coverage suggesting we have used a dataset we know to be pirated, such as LibGen, this may undermine our negotiating position with regulators on these issues.”…</p>
<p>…These newly unredacted documents reveal exchanges between Meta employees unearthed in the discovery process, like a Meta engineer telling a colleague that they hesitated to access LibGen data because “torrenting from a [meta-owned] corporate laptop doesn’t feel right 😃”. They also allege that internal discussions about using LibGen data were escalated to Meta CEO Mark Zuckerberg (referred to as “MZ” in the memo handed over during discovery) and that Meta’s AI team was “approved to use” the pirated material.</p>
<p>Meta has claimed that they used publicly available material that was legally accessible under fair use doctrine, but that doesn’t pass the smell test to me: just because something is public on the internet, doesn’t make it legal.</p>
<p>The plaintiffs are arguing that they should be allowed to expand their case <a href="https://www.wired.com/story/new-documents-unredacted-meta-copyright-ai-lawsuit/" target="_blank">to incorporate these new findings</a>:</p>
<p>“Meta, through a corporate representative who testified on November 20, 2024, has now admitted under oath to uploading (aka ‘seeding’) pirated files containing Plaintiffs’ works on ‘torrent’ sites,” the motion alleges. (Seeding is when torrented files are then shared with other peers after they have finished downloading.)</p>
<p>“This torrenting activity turned Meta itself into a distributor of the very same pirated copyrighted material that it was also downloading for use in its commercially available AI models.”</p>
<p>Legally, Meta and their lawyers may find a way to finagle the law and get around this. But in plain terms, it doesn’t seem defensible for a major company with tons of lawyers, money, and talent to knowingly use stolen work to build something that they then turn around and sell.</p>
<p>I’m not naive enough to think that this lawsuit, or any of the many others currently winding their way through the courts, will end in this kind of software leaving the market—in America, you can’t unring a bell that’s been valued in the billions. But I do hope that the writers and artists whose work was stolen are compensated.</p>
<p>In spite of all this, tech-optimists continue to push AI in more places, and people in power continue to trumpet it as the future of everything. In the case of publishing, for example, the excellent <a href="https://www.instagram.com/xoxopublishinggg/#" target="_blank">xoxopublishinggg</a> Instagram account has been posting anonymous responses about publishing workers’ experiences with AI in the workplace—it seems like a lot of publishers are at least curious about these tools in ways that don’t bode well for an AI-less future.</p>
<p>If you’re considering using AI, or are feeling pressure at work to do so, you can add “built on piracy” to the list of concerns about this tech, alongside its environmental impact, its human toll on underpaid and marginalized workers, and the simple fact that it is incapable of making anything good.</p>
				
										
									
				

				

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ruff: Python linter and code formatter written in Rust (185 pts)]]></title>
            <link>https://github.com/astral-sh/ruff</link>
            <guid>42775029</guid>
            <pubDate>Tue, 21 Jan 2025 00:49:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/astral-sh/ruff">https://github.com/astral-sh/ruff</a>, See on <a href="https://news.ycombinator.com/item?id=42775029">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">Ruff</h2><a id="user-content-ruff" aria-label="Permalink: Ruff" href="#ruff"></a></p>
<p dir="auto"><a href="https://github.com/astral-sh/ruff"><img src="https://camo.githubusercontent.com/051a04ae958f4a1a5d6444df4cdc520305eef93d5028e6d4c7cd16efa3136cd4/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f61737472616c2d73682f727566662f6d61696e2f6173736574732f62616467652f76322e6a736f6e" alt="Ruff" data-canonical-src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json"></a>
<a href="https://pypi.python.org/pypi/ruff" rel="nofollow"><img src="https://camo.githubusercontent.com/14e1bc70770d22cc586d31fd726ffce6dbf5d248e5fbc700216542adfd6a4e07/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f727566662e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/v/ruff.svg"></a>
<a href="https://github.com/astral-sh/ruff/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/05d0bcb2b2007f0c40a1a3d3eb693e9eec4c3d85aaea9cde6d463c3c3d89629c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f727566662e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/l/ruff.svg"></a>
<a href="https://pypi.python.org/pypi/ruff" rel="nofollow"><img src="https://camo.githubusercontent.com/4756572c4e7149f6aa63e5a2c872c021eedfaa361c6a322d306bdd6b0a5c62d9/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f727566662e737667" alt="image" data-canonical-src="https://img.shields.io/pypi/pyversions/ruff.svg"></a>
<a href="https://github.com/astral-sh/ruff/actions"><img src="https://github.com/astral-sh/ruff/workflows/CI/badge.svg" alt="Actions status"></a>
<a href="https://discord.com/invite/astral-sh" rel="nofollow"><img src="https://camo.githubusercontent.com/647359c14a78a007576a41e446f1956e89ed1a91f673dfe19b848eebd94f502d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d2532333538363546322e7376673f6c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Discord" data-canonical-src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white"></a></p>
<p dir="auto"><a href="https://docs.astral.sh/ruff/" rel="nofollow"><strong>Docs</strong></a> | <a href="https://play.ruff.rs/" rel="nofollow"><strong>Playground</strong></a></p>
<p dir="auto">An extremely fast Python linter and code formatter, written in Rust.</p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/1309177/232603514-c95e9b0f-6b31-43de-9a80-9e844173fd6a.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg">
    <img alt="Shows a bar chart with benchmark results." src="https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg">
  </picture></themed-picture>
</p>
<p dir="auto">
  <i>Linting the CPython codebase from scratch.</i>
</p>
<ul dir="auto">
<li>⚡️ 10-100x faster than existing linters (like Flake8) and formatters (like Black)</li>
<li>🐍 Installable via <code>pip</code></li>
<li>🛠️ <code>pyproject.toml</code> support</li>
<li>🤝 Python 3.13 compatibility</li>
<li>⚖️ Drop-in parity with <a href="https://docs.astral.sh/ruff/faq/#how-does-ruffs-linter-compare-to-flake8" rel="nofollow">Flake8</a>, isort, and <a href="https://docs.astral.sh/ruff/faq/#how-does-ruffs-formatter-compare-to-black" rel="nofollow">Black</a></li>
<li>📦 Built-in caching, to avoid re-analyzing unchanged files</li>
<li>🔧 Fix support, for automatic error correction (e.g., automatically remove unused imports)</li>
<li>📏 Over <a href="https://docs.astral.sh/ruff/rules/" rel="nofollow">800 built-in rules</a>, with native re-implementations
of popular Flake8 plugins, like flake8-bugbear</li>
<li>⌨️ First-party <a href="https://docs.astral.sh/ruff/integrations/" rel="nofollow">editor integrations</a> for
<a href="https://github.com/astral-sh/ruff-vscode">VS Code</a> and <a href="https://docs.astral.sh/ruff/editors/setup" rel="nofollow">more</a></li>
<li>🌎 Monorepo-friendly, with <a href="https://docs.astral.sh/ruff/configuration/#config-file-discovery" rel="nofollow">hierarchical and cascading configuration</a></li>
</ul>
<p dir="auto">Ruff aims to be orders of magnitude faster than alternative tools while integrating more
functionality behind a single, common interface.</p>
<p dir="auto">Ruff can be used to replace <a href="https://pypi.org/project/flake8/" rel="nofollow">Flake8</a> (plus dozens of plugins),
<a href="https://github.com/psf/black">Black</a>, <a href="https://pypi.org/project/isort/" rel="nofollow">isort</a>,
<a href="https://pypi.org/project/pydocstyle/" rel="nofollow">pydocstyle</a>, <a href="https://pypi.org/project/pyupgrade/" rel="nofollow">pyupgrade</a>,
<a href="https://pypi.org/project/autoflake/" rel="nofollow">autoflake</a>, and more, all while executing tens or hundreds of
times faster than any individual tool.</p>
<p dir="auto">Ruff is extremely actively developed and used in major open-source projects like:</p>
<ul dir="auto">
<li><a href="https://github.com/apache/airflow">Apache Airflow</a></li>
<li><a href="https://github.com/apache/superset">Apache Superset</a></li>
<li><a href="https://github.com/tiangolo/fastapi">FastAPI</a></li>
<li><a href="https://github.com/huggingface/transformers">Hugging Face</a></li>
<li><a href="https://github.com/pandas-dev/pandas">Pandas</a></li>
<li><a href="https://github.com/scipy/scipy">SciPy</a></li>
</ul>
<p dir="auto">...and <a href="#whos-using-ruff">many more</a>.</p>
<p dir="auto">Ruff is backed by <a href="https://astral.sh/" rel="nofollow">Astral</a>. Read the <a href="https://astral.sh/blog/announcing-astral-the-company-behind-ruff" rel="nofollow">launch post</a>,
or the original <a href="https://notes.crmarsh.com/python-tooling-could-be-much-much-faster" rel="nofollow">project announcement</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testimonials</h2><a id="user-content-testimonials" aria-label="Permalink: Testimonials" href="#testimonials"></a></p>
<p dir="auto"><a href="https://twitter.com/tiangolo/status/1591912354882764802" rel="nofollow"><strong>Sebastián Ramírez</strong></a>, creator
of <a href="https://github.com/tiangolo/fastapi">FastAPI</a>:</p>
<blockquote>
<p dir="auto">Ruff is so fast that sometimes I add an intentional bug in the code just to confirm it's actually
running and checking the code.</p>
</blockquote>
<p dir="auto"><a href="https://twitter.com/schrockn/status/1612615862904827904" rel="nofollow"><strong>Nick Schrock</strong></a>, founder of <a href="https://www.elementl.com/" rel="nofollow">Elementl</a>,
co-creator of <a href="https://graphql.org/" rel="nofollow">GraphQL</a>:</p>
<blockquote>
<p dir="auto">Why is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On
our largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4
cores on my M1. Running ruff against our <em>entire</em> codebase takes .4 seconds.</p>
</blockquote>
<p dir="auto"><a href="https://github.com/bokeh/bokeh/pull/12605" data-hovercard-type="pull_request" data-hovercard-url="/bokeh/bokeh/pull/12605/hovercard"><strong>Bryan Van de Ven</strong></a>, co-creator
of <a href="https://github.com/bokeh/bokeh/">Bokeh</a>, original author
of <a href="https://docs.conda.io/en/latest/" rel="nofollow">Conda</a>:</p>
<blockquote>
<p dir="auto">Ruff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of
~20s. This is an enormous quality of life improvement for local dev. It's fast enough that I added
it as an actual commit hook, which is terrific.</p>
</blockquote>
<p dir="auto"><a href="https://twitter.com/timothycrosley/status/1606420868514877440" rel="nofollow"><strong>Timothy Crosley</strong></a>,
creator of <a href="https://github.com/PyCQA/isort">isort</a>:</p>
<blockquote>
<p dir="auto">Just switched my first project to Ruff. Only one downside so far: it's so fast I couldn't believe
it was working till I intentionally introduced some errors.</p>
</blockquote>
<p dir="auto"><a href="https://github.com/astral-sh/ruff/issues/465#issuecomment-1317400028" data-hovercard-type="issue" data-hovercard-url="/astral-sh/ruff/issues/465/hovercard"><strong>Tim Abbott</strong></a>, lead
developer of <a href="https://github.com/zulip/zulip">Zulip</a>:</p>
<blockquote>
<p dir="auto">This is just ridiculously fast... <code>ruff</code> is amazing.</p>
</blockquote>

<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<p dir="auto">For more, see the <a href="https://docs.astral.sh/ruff/" rel="nofollow">documentation</a>.</p>
<ol dir="auto">
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#rules">Rules</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#support">Support</a></li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
<li><a href="#whos-using-ruff">Who's Using Ruff?</a></li>
<li><a href="#license">License</a></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started<a id="user-content-getting-started"></a></h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">For more, see the <a href="https://docs.astral.sh/ruff/" rel="nofollow">documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Ruff is available as <a href="https://pypi.org/project/ruff/" rel="nofollow"><code>ruff</code></a> on PyPI.</p>
<p dir="auto">Invoke Ruff directly with <a href="https://docs.astral.sh/uv/" rel="nofollow"><code>uvx</code></a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="uvx ruff check   # Lint all files in the current directory.
uvx ruff format  # Format all files in the current directory."><pre>uvx ruff check   <span><span>#</span> Lint all files in the current directory.</span>
uvx ruff format  <span><span>#</span> Format all files in the current directory.</span></pre></div>
<p dir="auto">Or install Ruff with <code>uv</code> (recommended), <code>pip</code>, or <code>pipx</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# With uv.
uv tool install ruff@latest  # Install Ruff globally.
uv add --dev ruff            # Or add Ruff to your project.

# With pip.
pip install ruff

# With pipx.
pipx install ruff"><pre><span><span>#</span> With uv.</span>
uv tool install ruff@latest  <span><span>#</span> Install Ruff globally.</span>
uv add --dev ruff            <span><span>#</span> Or add Ruff to your project.</span>

<span><span>#</span> With pip.</span>
pip install ruff

<span><span>#</span> With pipx.</span>
pipx install ruff</pre></div>
<p dir="auto">Starting with version <code>0.5.0</code>, Ruff can be installed with our standalone installers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# On macOS and Linux.
curl -LsSf https://astral.sh/ruff/install.sh | sh

# On Windows.
powershell -c &quot;irm https://astral.sh/ruff/install.ps1 | iex&quot;

# For a specific version.
curl -LsSf https://astral.sh/ruff/0.9.2/install.sh | sh
powershell -c &quot;irm https://astral.sh/ruff/0.9.2/install.ps1 | iex&quot;"><pre><span><span>#</span> On macOS and Linux.</span>
curl -LsSf https://astral.sh/ruff/install.sh <span>|</span> sh

<span><span>#</span> On Windows.</span>
powershell -c <span><span>"</span>irm https://astral.sh/ruff/install.ps1 | iex<span>"</span></span>

<span><span>#</span> For a specific version.</span>
curl -LsSf https://astral.sh/ruff/0.9.2/install.sh <span>|</span> sh
powershell -c <span><span>"</span>irm https://astral.sh/ruff/0.9.2/install.ps1 | iex<span>"</span></span></pre></div>
<p dir="auto">You can also install Ruff via <a href="https://formulae.brew.sh/formula/ruff" rel="nofollow">Homebrew</a>, <a href="https://anaconda.org/conda-forge/ruff" rel="nofollow">Conda</a>,
and with <a href="https://docs.astral.sh/ruff/installation/" rel="nofollow">a variety of other package managers</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">To run Ruff as a linter, try any of the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ruff check                          # Lint all files in the current directory (and any subdirectories).
ruff check path/to/code/            # Lint all files in `/path/to/code` (and any subdirectories).
ruff check path/to/code/*.py        # Lint all `.py` files in `/path/to/code`.
ruff check path/to/code/to/file.py  # Lint `file.py`.
ruff check @arguments.txt           # Lint using an input file, treating its contents as newline-delimited command-line arguments."><pre>ruff check                          <span><span>#</span> Lint all files in the current directory (and any subdirectories).</span>
ruff check path/to/code/            <span><span>#</span> Lint all files in `/path/to/code` (and any subdirectories).</span>
ruff check path/to/code/<span>*</span>.py        <span><span>#</span> Lint all `.py` files in `/path/to/code`.</span>
ruff check path/to/code/to/file.py  <span><span>#</span> Lint `file.py`.</span>
ruff check @arguments.txt           <span><span>#</span> Lint using an input file, treating its contents as newline-delimited command-line arguments.</span></pre></div>
<p dir="auto">Or, to run Ruff as a formatter:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ruff format                          # Format all files in the current directory (and any subdirectories).
ruff format path/to/code/            # Format all files in `/path/to/code` (and any subdirectories).
ruff format path/to/code/*.py        # Format all `.py` files in `/path/to/code`.
ruff format path/to/code/to/file.py  # Format `file.py`.
ruff format @arguments.txt           # Format using an input file, treating its contents as newline-delimited command-line arguments."><pre>ruff format                          <span><span>#</span> Format all files in the current directory (and any subdirectories).</span>
ruff format path/to/code/            <span><span>#</span> Format all files in `/path/to/code` (and any subdirectories).</span>
ruff format path/to/code/<span>*</span>.py        <span><span>#</span> Format all `.py` files in `/path/to/code`.</span>
ruff format path/to/code/to/file.py  <span><span>#</span> Format `file.py`.</span>
ruff format @arguments.txt           <span><span>#</span> Format using an input file, treating its contents as newline-delimited command-line arguments.</span></pre></div>
<p dir="auto">Ruff can also be used as a <a href="https://pre-commit.com/" rel="nofollow">pre-commit</a> hook via <a href="https://github.com/astral-sh/ruff-pre-commit"><code>ruff-pre-commit</code></a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="- repo: https://github.com/astral-sh/ruff-pre-commit
  # Ruff version.
  rev: v0.9.2
  hooks:
    # Run the linter.
    - id: ruff
      args: [ --fix ]
    # Run the formatter.
    - id: ruff-format"><pre>- <span>repo</span>: <span>https://github.com/astral-sh/ruff-pre-commit</span>
  <span><span>#</span> Ruff version.</span>
  <span>rev</span>: <span>v0.9.2</span>
  <span>hooks</span>:
    <span><span>#</span> Run the linter.</span>
    - <span>id</span>: <span>ruff</span>
      <span>args</span>: <span>[ --fix ]</span>
    <span><span>#</span> Run the formatter.</span>
    - <span>id</span>: <span>ruff-format</span></pre></div>
<p dir="auto">Ruff can also be used as a <a href="https://github.com/astral-sh/ruff-vscode">VS Code extension</a> or with <a href="https://docs.astral.sh/ruff/editors/setup" rel="nofollow">various other editors</a>.</p>
<p dir="auto">Ruff can also be used as a <a href="https://github.com/features/actions">GitHub Action</a> via
<a href="https://github.com/astral-sh/ruff-action"><code>ruff-action</code></a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="name: Ruff
on: [ push, pull_request ]
jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/ruff-action@v3"><pre><span>name</span>: <span>Ruff</span>
<span>on</span>: <span>[ push, pull_request ]</span>
<span>jobs</span>:
  <span>ruff</span>:
    <span>runs-on</span>: <span>ubuntu-latest</span>
    <span>steps</span>:
      - <span>uses</span>: <span>actions/checkout@v4</span>
      - <span>uses</span>: <span>astral-sh/ruff-action@v3</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration<a id="user-content-configuration"></a></h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Ruff can be configured through a <code>pyproject.toml</code>, <code>ruff.toml</code>, or <code>.ruff.toml</code> file (see:
<a href="https://docs.astral.sh/ruff/configuration/" rel="nofollow"><em>Configuration</em></a>, or <a href="https://docs.astral.sh/ruff/settings/" rel="nofollow"><em>Settings</em></a>
for a complete list of all configuration options).</p>
<p dir="auto">If left unspecified, Ruff's default configuration is equivalent to the following <code>ruff.toml</code> file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Exclude a variety of commonly ignored directories.
exclude = [
    &quot;.bzr&quot;,
    &quot;.direnv&quot;,
    &quot;.eggs&quot;,
    &quot;.git&quot;,
    &quot;.git-rewrite&quot;,
    &quot;.hg&quot;,
    &quot;.ipynb_checkpoints&quot;,
    &quot;.mypy_cache&quot;,
    &quot;.nox&quot;,
    &quot;.pants.d&quot;,
    &quot;.pyenv&quot;,
    &quot;.pytest_cache&quot;,
    &quot;.pytype&quot;,
    &quot;.ruff_cache&quot;,
    &quot;.svn&quot;,
    &quot;.tox&quot;,
    &quot;.venv&quot;,
    &quot;.vscode&quot;,
    &quot;__pypackages__&quot;,
    &quot;_build&quot;,
    &quot;buck-out&quot;,
    &quot;build&quot;,
    &quot;dist&quot;,
    &quot;node_modules&quot;,
    &quot;site-packages&quot;,
    &quot;venv&quot;,
]

# Same as Black.
line-length = 88
indent-width = 4

# Assume Python 3.9
target-version = &quot;py39&quot;

[lint]
# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`)  codes by default.
select = [&quot;E4&quot;, &quot;E7&quot;, &quot;E9&quot;, &quot;F&quot;]
ignore = []

# Allow fix for all enabled rules (when `--fix`) is provided.
fixable = [&quot;ALL&quot;]
unfixable = []

# Allow unused variables when underscore-prefixed.
dummy-variable-rgx = &quot;^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$&quot;

[format]
# Like Black, use double quotes for strings.
quote-style = &quot;double&quot;

# Like Black, indent with spaces, rather than tabs.
indent-style = &quot;space&quot;

# Like Black, respect magic trailing commas.
skip-magic-trailing-comma = false

# Like Black, automatically detect the appropriate line ending.
line-ending = &quot;auto&quot;"><pre><span><span>#</span> Exclude a variety of commonly ignored directories.</span>
<span>exclude</span> = [
    <span><span>"</span>.bzr<span>"</span></span>,
    <span><span>"</span>.direnv<span>"</span></span>,
    <span><span>"</span>.eggs<span>"</span></span>,
    <span><span>"</span>.git<span>"</span></span>,
    <span><span>"</span>.git-rewrite<span>"</span></span>,
    <span><span>"</span>.hg<span>"</span></span>,
    <span><span>"</span>.ipynb_checkpoints<span>"</span></span>,
    <span><span>"</span>.mypy_cache<span>"</span></span>,
    <span><span>"</span>.nox<span>"</span></span>,
    <span><span>"</span>.pants.d<span>"</span></span>,
    <span><span>"</span>.pyenv<span>"</span></span>,
    <span><span>"</span>.pytest_cache<span>"</span></span>,
    <span><span>"</span>.pytype<span>"</span></span>,
    <span><span>"</span>.ruff_cache<span>"</span></span>,
    <span><span>"</span>.svn<span>"</span></span>,
    <span><span>"</span>.tox<span>"</span></span>,
    <span><span>"</span>.venv<span>"</span></span>,
    <span><span>"</span>.vscode<span>"</span></span>,
    <span><span>"</span>__pypackages__<span>"</span></span>,
    <span><span>"</span>_build<span>"</span></span>,
    <span><span>"</span>buck-out<span>"</span></span>,
    <span><span>"</span>build<span>"</span></span>,
    <span><span>"</span>dist<span>"</span></span>,
    <span><span>"</span>node_modules<span>"</span></span>,
    <span><span>"</span>site-packages<span>"</span></span>,
    <span><span>"</span>venv<span>"</span></span>,
]

<span><span>#</span> Same as Black.</span>
<span>line-length</span> = <span>88</span>
<span>indent-width</span> = <span>4</span>

<span><span>#</span> Assume Python 3.9</span>
<span>target-version</span> = <span><span>"</span>py39<span>"</span></span>

[<span>lint</span>]
<span><span>#</span> Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`)  codes by default.</span>
<span>select</span> = [<span><span>"</span>E4<span>"</span></span>, <span><span>"</span>E7<span>"</span></span>, <span><span>"</span>E9<span>"</span></span>, <span><span>"</span>F<span>"</span></span>]
<span>ignore</span> = []

<span><span>#</span> Allow fix for all enabled rules (when `--fix`) is provided.</span>
<span>fixable</span> = [<span><span>"</span>ALL<span>"</span></span>]
<span>unfixable</span> = []

<span><span>#</span> Allow unused variables when underscore-prefixed.</span>
<span>dummy-variable-rgx</span> = <span><span>"</span>^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$<span>"</span></span>

[<span>format</span>]
<span><span>#</span> Like Black, use double quotes for strings.</span>
<span>quote-style</span> = <span><span>"</span>double<span>"</span></span>

<span><span>#</span> Like Black, indent with spaces, rather than tabs.</span>
<span>indent-style</span> = <span><span>"</span>space<span>"</span></span>

<span><span>#</span> Like Black, respect magic trailing commas.</span>
<span>skip-magic-trailing-comma</span> = <span>false</span>

<span><span>#</span> Like Black, automatically detect the appropriate line ending.</span>
<span>line-ending</span> = <span><span>"</span>auto<span>"</span></span></pre></div>
<p dir="auto">Note that, in a <code>pyproject.toml</code>, each section header should be prefixed with <code>tool.ruff</code>. For
example, <code>[lint]</code> should be replaced with <code>[tool.ruff.lint]</code>.</p>
<p dir="auto">Some configuration options can be provided via dedicated command-line arguments, such as those
related to rule enablement and disablement, file discovery, and logging level:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ruff check --select F401 --select F403 --quiet"><pre>ruff check --select F401 --select F403 --quiet</pre></div>
<p dir="auto">The remaining configuration options can be provided through a catch-all <code>--config</code> argument:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ruff check --config &quot;lint.per-file-ignores = {'some_file.py' = ['F841']}&quot;"><pre>ruff check --config <span><span>"</span>lint.per-file-ignores = {'some_file.py' = ['F841']}<span>"</span></span></pre></div>
<p dir="auto">To opt in to the latest lint rules, formatter style changes, interface updates, and more, enable
<a href="https://docs.astral.sh/ruff/rules/" rel="nofollow">preview mode</a> by setting <code>preview = true</code> in your configuration
file or passing <code>--preview</code> on the command line. Preview mode enables a collection of unstable
features that may change prior to stabilization.</p>
<p dir="auto">See <code>ruff help</code> for more on Ruff's top-level commands, or <code>ruff help check</code> and <code>ruff help format</code>
for more on the linting and formatting commands, respectively.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rules<a id="user-content-rules"></a></h2><a id="user-content-rules" aria-label="Permalink: Rules" href="#rules"></a></p>

<p dir="auto"><strong>Ruff supports over 800 lint rules</strong>, many of which are inspired by popular tools like Flake8,
isort, pyupgrade, and others. Regardless of the rule's origin, Ruff re-implements every rule in
Rust as a first-party feature.</p>
<p dir="auto">By default, Ruff enables Flake8's <code>F</code> rules, along with a subset of the <code>E</code> rules, omitting any
stylistic rules that overlap with the use of a formatter, like <code>ruff format</code> or
<a href="https://github.com/psf/black">Black</a>.</p>
<p dir="auto">If you're just getting started with Ruff, <strong>the default rule set is a great place to start</strong>: it
catches a wide variety of common errors (like unused imports) with zero configuration.</p>

<p dir="auto">Beyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code
quality tools, including:</p>
<ul dir="auto">
<li><a href="https://pypi.org/project/autoflake/" rel="nofollow">autoflake</a></li>
<li><a href="https://pypi.org/project/eradicate/" rel="nofollow">eradicate</a></li>
<li><a href="https://pypi.org/project/flake8-2020/" rel="nofollow">flake8-2020</a></li>
<li><a href="https://pypi.org/project/flake8-annotations/" rel="nofollow">flake8-annotations</a></li>
<li><a href="https://pypi.org/project/flake8-async" rel="nofollow">flake8-async</a></li>
<li><a href="https://pypi.org/project/flake8-bandit/" rel="nofollow">flake8-bandit</a> (<a href="https://github.com/astral-sh/ruff/issues/1646" data-hovercard-type="issue" data-hovercard-url="/astral-sh/ruff/issues/1646/hovercard">#1646</a>)</li>
<li><a href="https://pypi.org/project/flake8-blind-except/" rel="nofollow">flake8-blind-except</a></li>
<li><a href="https://pypi.org/project/flake8-boolean-trap/" rel="nofollow">flake8-boolean-trap</a></li>
<li><a href="https://pypi.org/project/flake8-bugbear/" rel="nofollow">flake8-bugbear</a></li>
<li><a href="https://pypi.org/project/flake8-builtins/" rel="nofollow">flake8-builtins</a></li>
<li><a href="https://pypi.org/project/flake8-commas/" rel="nofollow">flake8-commas</a></li>
<li><a href="https://pypi.org/project/flake8-comprehensions/" rel="nofollow">flake8-comprehensions</a></li>
<li><a href="https://pypi.org/project/flake8-copyright/" rel="nofollow">flake8-copyright</a></li>
<li><a href="https://pypi.org/project/flake8-datetimez/" rel="nofollow">flake8-datetimez</a></li>
<li><a href="https://pypi.org/project/flake8-debugger/" rel="nofollow">flake8-debugger</a></li>
<li><a href="https://pypi.org/project/flake8-django/" rel="nofollow">flake8-django</a></li>
<li><a href="https://pypi.org/project/flake8-docstrings/" rel="nofollow">flake8-docstrings</a></li>
<li><a href="https://pypi.org/project/flake8-eradicate/" rel="nofollow">flake8-eradicate</a></li>
<li><a href="https://pypi.org/project/flake8-errmsg/" rel="nofollow">flake8-errmsg</a></li>
<li><a href="https://pypi.org/project/flake8-executable/" rel="nofollow">flake8-executable</a></li>
<li><a href="https://pypi.org/project/flake8-future-annotations/" rel="nofollow">flake8-future-annotations</a></li>
<li><a href="https://pypi.org/project/flake8-gettext/" rel="nofollow">flake8-gettext</a></li>
<li><a href="https://pypi.org/project/flake8-implicit-str-concat/" rel="nofollow">flake8-implicit-str-concat</a></li>
<li><a href="https://github.com/joaopalmeiro/flake8-import-conventions">flake8-import-conventions</a></li>
<li><a href="https://pypi.org/project/flake8-logging/" rel="nofollow">flake8-logging</a></li>
<li><a href="https://pypi.org/project/flake8-logging-format/" rel="nofollow">flake8-logging-format</a></li>
<li><a href="https://pypi.org/project/flake8-no-pep420" rel="nofollow">flake8-no-pep420</a></li>
<li><a href="https://pypi.org/project/flake8-pie/" rel="nofollow">flake8-pie</a></li>
<li><a href="https://pypi.org/project/flake8-print/" rel="nofollow">flake8-print</a></li>
<li><a href="https://pypi.org/project/flake8-pyi/" rel="nofollow">flake8-pyi</a></li>
<li><a href="https://pypi.org/project/flake8-pytest-style/" rel="nofollow">flake8-pytest-style</a></li>
<li><a href="https://pypi.org/project/flake8-quotes/" rel="nofollow">flake8-quotes</a></li>
<li><a href="https://pypi.org/project/flake8-raise/" rel="nofollow">flake8-raise</a></li>
<li><a href="https://pypi.org/project/flake8-return/" rel="nofollow">flake8-return</a></li>
<li><a href="https://pypi.org/project/flake8-self/" rel="nofollow">flake8-self</a></li>
<li><a href="https://pypi.org/project/flake8-simplify/" rel="nofollow">flake8-simplify</a></li>
<li><a href="https://pypi.org/project/flake8-slots/" rel="nofollow">flake8-slots</a></li>
<li><a href="https://pypi.org/project/flake8-super/" rel="nofollow">flake8-super</a></li>
<li><a href="https://pypi.org/project/flake8-tidy-imports/" rel="nofollow">flake8-tidy-imports</a></li>
<li><a href="https://pypi.org/project/flake8-todos/" rel="nofollow">flake8-todos</a></li>
<li><a href="https://pypi.org/project/flake8-type-checking/" rel="nofollow">flake8-type-checking</a></li>
<li><a href="https://pypi.org/project/flake8-use-pathlib/" rel="nofollow">flake8-use-pathlib</a></li>
<li><a href="https://pypi.org/project/flynt/" rel="nofollow">flynt</a> (<a href="https://github.com/astral-sh/ruff/issues/2102" data-hovercard-type="issue" data-hovercard-url="/astral-sh/ruff/issues/2102/hovercard">#2102</a>)</li>
<li><a href="https://pypi.org/project/isort/" rel="nofollow">isort</a></li>
<li><a href="https://pypi.org/project/mccabe/" rel="nofollow">mccabe</a></li>
<li><a href="https://pypi.org/project/pandas-vet/" rel="nofollow">pandas-vet</a></li>
<li><a href="https://pypi.org/project/pep8-naming/" rel="nofollow">pep8-naming</a></li>
<li><a href="https://pypi.org/project/pydocstyle/" rel="nofollow">pydocstyle</a></li>
<li><a href="https://github.com/pre-commit/pygrep-hooks">pygrep-hooks</a></li>
<li><a href="https://pypi.org/project/pylint-airflow/" rel="nofollow">pylint-airflow</a></li>
<li><a href="https://pypi.org/project/pyupgrade/" rel="nofollow">pyupgrade</a></li>
<li><a href="https://pypi.org/project/tryceratops/" rel="nofollow">tryceratops</a></li>
<li><a href="https://pypi.org/project/yesqa/" rel="nofollow">yesqa</a></li>
</ul>
<p dir="auto">For a complete enumeration of the supported rules, see <a href="https://docs.astral.sh/ruff/rules/" rel="nofollow"><em>Rules</em></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing<a id="user-content-contributing"></a></h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome and highly appreciated. To get started, check out the
<a href="https://docs.astral.sh/ruff/contributing/" rel="nofollow"><strong>contributing guidelines</strong></a>.</p>
<p dir="auto">You can also join us on <a href="https://discord.com/invite/astral-sh" rel="nofollow"><strong>Discord</strong></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support<a id="user-content-support"></a></h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">Having trouble? Check out the existing issues on <a href="https://github.com/astral-sh/ruff/issues"><strong>GitHub</strong></a>,
or feel free to <a href="https://github.com/astral-sh/ruff/issues/new"><strong>open a new one</strong></a>.</p>
<p dir="auto">You can also ask for help on <a href="https://discord.com/invite/astral-sh" rel="nofollow"><strong>Discord</strong></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements<a id="user-content-acknowledgements"></a></h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">Ruff's linter draws on both the APIs and implementation details of many other
tools in the Python ecosystem, especially <a href="https://github.com/PyCQA/flake8">Flake8</a>, <a href="https://github.com/PyCQA/pyflakes">Pyflakes</a>,
<a href="https://github.com/PyCQA/pycodestyle">pycodestyle</a>, <a href="https://github.com/PyCQA/pydocstyle">pydocstyle</a>,
<a href="https://github.com/asottile/pyupgrade">pyupgrade</a>, and <a href="https://github.com/PyCQA/isort">isort</a>.</p>
<p dir="auto">In some cases, Ruff includes a "direct" Rust port of the corresponding tool.
We're grateful to the maintainers of these tools for their work, and for all
the value they've provided to the Python community.</p>
<p dir="auto">Ruff's formatter is built on a fork of Rome's <a href="https://github.com/rome/tools/tree/main/crates/rome_formatter"><code>rome_formatter</code></a>,
and again draws on both API and implementation details from <a href="https://github.com/rome/tools">Rome</a>,
<a href="https://github.com/prettier/prettier">Prettier</a>, and <a href="https://github.com/psf/black">Black</a>.</p>
<p dir="auto">Ruff's import resolver is based on the import resolution algorithm from <a href="https://github.com/microsoft/pyright">Pyright</a>.</p>
<p dir="auto">Ruff is also influenced by a number of tools outside the Python ecosystem, like
<a href="https://github.com/rust-lang/rust-clippy">Clippy</a> and <a href="https://github.com/eslint/eslint">ESLint</a>.</p>
<p dir="auto">Ruff is the beneficiary of a large number of <a href="https://github.com/astral-sh/ruff/graphs/contributors">contributors</a>.</p>
<p dir="auto">Ruff is released under the MIT license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Who's Using Ruff?<a id="user-content-whos-using-ruff"></a></h2><a id="user-content-whos-using-ruff" aria-label="Permalink: Who's Using Ruff?" href="#whos-using-ruff"></a></p>
<p dir="auto">Ruff is used by a number of major open-source projects and companies, including:</p>
<ul dir="auto">
<li><a href="https://github.com/albumentations-team/albumentations">Albumentations</a></li>
<li>Amazon (<a href="https://github.com/aws/serverless-application-model">AWS SAM</a>)</li>
<li>Anthropic (<a href="https://github.com/anthropics/anthropic-sdk-python">Python SDK</a>)</li>
<li><a href="https://github.com/apache/airflow">Apache Airflow</a></li>
<li>AstraZeneca (<a href="https://github.com/AstraZeneca/magnus-core">Magnus</a>)</li>
<li><a href="https://github.com/python-babel/babel">Babel</a></li>
<li>Benchling (<a href="https://github.com/benchling/refac">Refac</a>)</li>
<li><a href="https://github.com/bokeh/bokeh">Bokeh</a></li>
<li>CrowdCent (<a href="https://github.com/crowdcent/numerblox">NumerBlox</a>) </li>
<li><a href="https://github.com/pyca/cryptography">Cryptography (PyCA)</a></li>
<li>CERN (<a href="https://getindico.io/" rel="nofollow">Indico</a>)</li>
<li><a href="https://github.com/iterative/dvc">DVC</a></li>
<li><a href="https://github.com/dagger/dagger">Dagger</a></li>
<li><a href="https://github.com/dagster-io/dagster">Dagster</a></li>
<li>Databricks (<a href="https://github.com/mlflow/mlflow">MLflow</a>)</li>
<li><a href="https://github.com/langgenius/dify">Dify</a></li>
<li><a href="https://github.com/tiangolo/fastapi">FastAPI</a></li>
<li><a href="https://github.com/godotengine/godot">Godot</a></li>
<li><a href="https://github.com/gradio-app/gradio">Gradio</a></li>
<li><a href="https://github.com/great-expectations/great_expectations">Great Expectations</a></li>
<li><a href="https://github.com/encode/httpx">HTTPX</a></li>
<li><a href="https://github.com/pypa/hatch">Hatch</a></li>
<li><a href="https://github.com/home-assistant/core">Home Assistant</a></li>
<li>Hugging Face (<a href="https://github.com/huggingface/transformers">Transformers</a>,
<a href="https://github.com/huggingface/datasets">Datasets</a>,
<a href="https://github.com/huggingface/diffusers">Diffusers</a>)</li>
<li>IBM (<a href="https://github.com/Qiskit/qiskit">Qiskit</a>)</li>
<li>ING Bank (<a href="https://github.com/ing-bank/popmon">popmon</a>, <a href="https://github.com/ing-bank/probatus">probatus</a>)</li>
<li><a href="https://github.com/ibis-project/ibis">Ibis</a></li>
<li><a href="https://github.com/unifyai/ivy">ivy</a></li>
<li><a href="https://github.com/jupyter-server/jupyter_server">Jupyter</a></li>
<li><a href="https://kraken.tech/" rel="nofollow">Kraken Tech</a></li>
<li><a href="https://github.com/hwchase17/langchain">LangChain</a></li>
<li><a href="https://litestar.dev/" rel="nofollow">Litestar</a></li>
<li><a href="https://github.com/jerryjliu/llama_index">LlamaIndex</a></li>
<li>Matrix (<a href="https://github.com/matrix-org/synapse">Synapse</a>)</li>
<li><a href="https://github.com/oxsecurity/megalinter">MegaLinter</a></li>
<li>Meltano (<a href="https://github.com/meltano/meltano">Meltano CLI</a>, <a href="https://github.com/meltano/sdk">Singer SDK</a>)</li>
<li>Microsoft (<a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel</a>,
<a href="https://github.com/microsoft/onnxruntime">ONNX Runtime</a>,
<a href="https://github.com/microsoft/LightGBM">LightGBM</a>)</li>
<li>Modern Treasury (<a href="https://github.com/Modern-Treasury/modern-treasury-python">Python SDK</a>)</li>
<li>Mozilla (<a href="https://github.com/mozilla/gecko-dev">Firefox</a>)</li>
<li><a href="https://github.com/python/mypy">Mypy</a></li>
<li><a href="https://github.com/nautobot/nautobot">Nautobot</a></li>
<li>Netflix (<a href="https://github.com/Netflix/dispatch">Dispatch</a>)</li>
<li><a href="https://github.com/neondatabase/neon">Neon</a></li>
<li><a href="https://nokia.com/" rel="nofollow">Nokia</a></li>
<li><a href="https://github.com/nonebot/nonebot2">NoneBot</a></li>
<li><a href="https://github.com/pyro-ppl/numpyro">NumPyro</a></li>
<li><a href="https://github.com/onnx/onnx">ONNX</a></li>
<li><a href="https://github.com/OpenBB-finance/OpenBBTerminal">OpenBB</a></li>
<li><a href="https://github.com/Open-Wine-Components/umu-launcher">Open Wine Components</a></li>
<li><a href="https://github.com/pdm-project/pdm">PDM</a></li>
<li><a href="https://github.com/PaddlePaddle/Paddle">PaddlePaddle</a></li>
<li><a href="https://github.com/pandas-dev/pandas">Pandas</a></li>
<li><a href="https://github.com/python-pillow/Pillow">Pillow</a></li>
<li><a href="https://github.com/python-poetry/poetry">Poetry</a></li>
<li><a href="https://github.com/pola-rs/polars">Polars</a></li>
<li><a href="https://github.com/PostHog/posthog">PostHog</a></li>
<li>Prefect (<a href="https://github.com/PrefectHQ/prefect">Python SDK</a>, <a href="https://github.com/PrefectHQ/marvin">Marvin</a>)</li>
<li><a href="https://github.com/pyinstaller/pyinstaller">PyInstaller</a></li>
<li><a href="https://github.com/pymc-devs/pymc/">PyMC</a></li>
<li><a href="https://github.com/pymc-labs/pymc-marketing">PyMC-Marketing</a></li>
<li><a href="https://github.com/pytest-dev/pytest">pytest</a></li>
<li><a href="https://github.com/pytorch/pytorch">PyTorch</a></li>
<li><a href="https://github.com/pydantic/pydantic">Pydantic</a></li>
<li><a href="https://github.com/PyCQA/pylint">Pylint</a></li>
<li><a href="https://github.com/pyvista/pyvista">PyVista</a></li>
<li><a href="https://github.com/reflex-dev/reflex">Reflex</a></li>
<li><a href="https://github.com/online-ml/river">River</a></li>
<li><a href="https://rippling.com/" rel="nofollow">Rippling</a></li>
<li><a href="https://github.com/sansyrox/robyn">Robyn</a></li>
<li><a href="https://github.com/saleor/saleor">Saleor</a></li>
<li>Scale AI (<a href="https://github.com/scaleapi/launch-python-client">Launch SDK</a>)</li>
<li><a href="https://github.com/scipy/scipy">SciPy</a></li>
<li>Snowflake (<a href="https://github.com/Snowflake-Labs/snowcli">SnowCLI</a>)</li>
<li><a href="https://github.com/sphinx-doc/sphinx">Sphinx</a></li>
<li><a href="https://github.com/DLR-RM/stable-baselines3">Stable Baselines3</a></li>
<li><a href="https://github.com/encode/starlette">Starlette</a></li>
<li><a href="https://github.com/streamlit/streamlit">Streamlit</a></li>
<li><a href="https://github.com/TheAlgorithms/Python">The Algorithms</a></li>
<li><a href="https://github.com/altair-viz/altair">Vega-Altair</a></li>
<li>WordPress (<a href="https://github.com/WordPress/openverse">Openverse</a>)</li>
<li><a href="https://github.com/zenml-io/zenml">ZenML</a></li>
<li><a href="https://github.com/zulip/zulip">Zulip</a></li>
<li><a href="https://github.com/pypa/build">build (PyPA)</a></li>
<li><a href="https://github.com/pypa/cibuildwheel">cibuildwheel (PyPA)</a></li>
<li><a href="https://github.com/delta-io/delta-rs">delta-rs</a></li>
<li><a href="https://github.com/alteryx/featuretools">featuretools</a></li>
<li><a href="https://github.com/mesonbuild/meson-python">meson-python</a></li>
<li><a href="https://github.com/wntrblm/nox">nox</a></li>
<li><a href="https://github.com/pypa/pip">pip</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Show Your Support</h3><a id="user-content-show-your-support" aria-label="Permalink: Show Your Support" href="#show-your-support"></a></p>
<p dir="auto">If you're using Ruff, consider adding the Ruff badge to your project's <code>README.md</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)"><pre><span>[</span><span>![</span>Ruff<span>]</span><span>(</span><span>https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json</span><span>)]</span><span>(</span><span>https://github.com/astral-sh/ruff</span><span>)</span></pre></div>
<p dir="auto">...or <code>README.rst</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content=".. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json
    :target: https://github.com/astral-sh/ruff
    :alt: Ruff"><pre>.. <span>image</span>:: <span>https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json</span>
    <span>:target:</span> <span>https://github.com/astral-sh/ruff</span>
    <span>:alt:</span> <span>Ruff</span></pre></div>
<p dir="auto">...or, as HTML:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<a href=&quot;https://github.com/astral-sh/ruff&quot;><img src=&quot;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json&quot; alt=&quot;Ruff&quot; style=&quot;max-width:100%;&quot;></a>"><pre><span>&lt;</span><span>a</span> <span>href</span>="<span>https://github.com/astral-sh/ruff</span>"<span>&gt;</span><span>&lt;</span><span>img</span> <span>src</span>="<span>https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json</span>" <span>alt</span>="<span>Ruff</span>" <span>style</span>="<span>max-width:100%;</span>"<span>&gt;</span><span>&lt;/</span><span>a</span><span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License<a id="user-content-license"></a></h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This repository is licensed under the <a href="https://github.com/astral-sh/ruff/blob/main/LICENSE">MIT License</a></p>
<p><a href="https://astral.sh/" rel="nofollow">
    <img src="https://raw.githubusercontent.com/astral-sh/ruff/main/assets/svg/Astral.svg" alt="Made by Astral">
  </a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elon Gives Nazi Salute During Inauguration Speech (139 pts)]]></title>
            <link>https://www.youtube.com/watch?v=e2bbb-6Clhs</link>
            <guid>42774621</guid>
            <pubDate>Mon, 20 Jan 2025 23:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=e2bbb-6Clhs">https://www.youtube.com/watch?v=e2bbb-6Clhs</a>, See on <a href="https://news.ycombinator.com/item?id=42774621">Hacker News</a></p>
Couldn't get https://www.youtube.com/watch?v=e2bbb-6Clhs: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse engineering Call of Duty anti-cheat (444 pts)]]></title>
            <link>https://ssno.cc/posts/reversing-tac-1-4-2025/</link>
            <guid>42774221</guid>
            <pubDate>Mon, 20 Jan 2025 23:07:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssno.cc/posts/reversing-tac-1-4-2025/">https://ssno.cc/posts/reversing-tac-1-4-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42774221">Hacker News</a></p>
Couldn't get https://ssno.cc/posts/reversing-tac-1-4-2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Elon Musk appears to make back-to-back fascist salutes at inauguration rally (240 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute</link>
            <guid>42773778</guid>
            <pubDate>Mon, 20 Jan 2025 22:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute">https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute</a>, See on <a href="https://news.ycombinator.com/item?id=42773778">Hacker News</a></p>
Couldn't get https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Matt Mullenweg, Automattic's CEO, Seems Bound and Determined to Wreck WordPress (112 pts)]]></title>
            <link>https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/</link>
            <guid>42773311</guid>
            <pubDate>Mon, 20 Jan 2025 21:32:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/">https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/</a>, See on <a href="https://news.ycombinator.com/item?id=42773311">Hacker News</a></p>
Couldn't get https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Did Elon Musk Appear to Sieg Heil at Trump Inauguration? (285 pts)]]></title>
            <link>https://www.jpost.com/international/article-838444</link>
            <guid>42772995</guid>
            <pubDate>Mon, 20 Jan 2025 21:02:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpost.com/international/article-838444">https://www.jpost.com/international/article-838444</a>, See on <a href="https://news.ycombinator.com/item?id=42772995">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            
<section>
	<section>
		


    <section>
        <h2>Musk was seen making the gesture a total of three times on live television.</h2>
    </section>

<section>
            <section>
                <section>
                    <time datetime="2025-01-20T22:29:54+02:00">
                        JANUARY 20, 2025 22:29
                    </time>
                </section>
                    <section><b>Updated:</b> JANUARY 20, 2025 23:30</section>
            </section>
            <section data-share-url="https://www.jpost.com/international/article-838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                    <nav>
                        <ul>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                        </ul>
                    </nav>
                </section>
        </section>


	</section>
	<section>
			<figure>
				<img src="https://images.jpost.com/image/upload/q_auto/c_fill,g_faces:center,h_537,w_822/644997" width="290" height="260" alt=" Elon Musk makes controversial gesture at Washington DC arena (photo credit: SCREENSHOT/X)" title=" Elon Musk makes controversial gesture at Washington DC arena">
				<figcaption>
					<section>
						<section> Elon Musk makes controversial gesture at Washington DC arena</section>
						<section>(photo credit: SCREENSHOT/X)</section>
					</section>
				</figcaption>
			</figure>
	</section>

</section>
<section>
			
			<section itemprop="articleBody" id="startBannerSticky">
				<p>US billionaire <a href="https://www.jpost.com/tags/elon-musk">Elon Musk</a> appeared to make a Heil Hitler salute at the Washington DC Trump parade on Monday, following Trump's inauguration.&nbsp;</p><p><a href="https://www.jpost.com/middle-east/article-837785">Musk</a> was seen making the gesture a total of three times on live television.</p><blockquote data-media-max-width="560"><p lang="en" dir="ltr">Elon Musk does what looks like a Hitler salute after talking of victory at Trump inauguration, thanking supporters for assuring "the future of civilisation" <a href="https://t.co/xp0kmJ5dFQ" rel="nofollow">pic.twitter.com/xp0kmJ5dFQ</a></p>— James Jackson (@derJamesJackson) <a href="https://twitter.com/derJamesJackson/status/1881436166144262376?ref_src=twsrc%5Etfw" rel="nofollow">January 20, 2025</a></blockquote><p>He then appeared on stage at the Capital One Area in front of 20,000 Trump supporters, where he thanked supporters before making the gesture.</p><blockquote><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/Breaking?src=hash&amp;ref_src=twsrc%5Etfw" rel="nofollow">#Breaking</a>: Senior Trump administration official Elon Musk thanks supporters with a Nazi salute. <a href="https://t.co/WzSZFUYvEG" rel="nofollow">pic.twitter.com/WzSZFUYvEG</a></p>— Noga Tarnopolsky נגה טרנופולסקי نوغا ترنوبولسكي (@NTarnopolsky) <a href="https://twitter.com/NTarnopolsky/status/1881436487558090831?ref_src=twsrc%5Etfw" rel="nofollow">January 20, 2025</a></blockquote><p>Social media users reacted with horror, with one writing, "Remember when Democrats called MAGA rallies "Nazi rallies?" President un-elect Elon Musk just did the Nazi Sieg Heil salute."</p><h3>Mars space travel</h3><p>The Tesla and Space X owner appeared excited by Trump's mention of Mars in his inaugural speech, given he has reportedly urged NASA to drop its plans to return to the moon and go straight to Mars, according to Politico.</p><p>President Donald Trump said the US would launch astronauts to plant the “stars and stripes” on Mars.</p><p>"We're gonna take DOGE to Mars!" said Musk in his speech, "Can you imagine how awesome it will be to have American astronauts plant the flag on another planet for the first time! How inspiring would that be?!"</p><section><hr><div>            <p>Stay updated with the latest news!</p>            <p>Subscribe to The Jerusalem Post Newsletter</p>        </div><hr></section><p>This comes amid a Washington Post report that Donald Trump's government <a href="https://www.jpost.com/american-politics/article-837770">advisory panel</a>, led by Elon Musk, will be sued soon after the incoming US president is sworn in on Monday.
				</p>
			</section>
		</section>



            
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Official DeepSeek R1 Now on Ollama (210 pts)]]></title>
            <link>https://ollama.com/library/deepseek-r1</link>
            <guid>42772983</guid>
            <pubDate>Mon, 20 Jan 2025 21:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ollama.com/library/deepseek-r1">https://ollama.com/library/deepseek-r1</a>, See on <a href="https://news.ycombinator.com/item?id=42772983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<div>
		
		<div>
			
<div id="summary">
	<h2 id="summary-display">
		<span id="summary-content">
		
			DeepSeek's first generation reasoning models with comparable performance to OpenAI-o1. 
		
		</span>
		
	</h2>
	
</div>

			<div>
				<p><span x-test-size="">1.5b</span>
					
						<span x-test-size="">7b</span>
					
						<span x-test-size="">8b</span>
					
						<span x-test-size="">14b</span>
					
						<span x-test-size="">32b</span>
					
						<span x-test-size="">70b</span>
					
						<span x-test-size="">671b</span>
					
				</p>
				<p>
					
					  <span>
						<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
						  <path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75V16.5M16.5 12L12 16.5m0 0L7.5 12m4.5 4.5V3"></path>
						</svg>
						<span x-test-pull-count="">40.4K</span>
						<span>&nbsp;Pulls</span>
					  </span>
					
					
						<span>
							<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
								<path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z"></path>
							</svg>
							<span>Updated&nbsp;</span>
							<span x-test-updated="">2 hours ago</span>
						</span>
					
				</p>
			</div>
		</div>
		
		
  



		
	</div>
	
  
    
  

  
  
  <div id="readme">
    <p>
      <h2>Readme</h2>

      
    </p>
    <div id="display">
        
          <p><img src="https://ollama.com/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a" width="320"></p>

<p>DeepSeek’s first-generation reasoning models, achieving performance comparable to OpenAI-o1 across math, code, and reasoning tasks.</p>

<h2>Models</h2>

<p><strong>1.5B Qwen DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:1.5b
</code></pre>

<p><strong>7B Qwen DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:7b
</code></pre>

<p><strong>8B Llama DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:8b
</code></pre>

<p><strong>14B Qwen DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:14b
</code></pre>

<p><strong>32B Qwen DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:32b
</code></pre>

<p><strong>70B Llama DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:70b
</code></pre>

<p><strong>671B DeepSeek R1</strong></p>

<pre><code>ollama run deepseek-r1:671b
</code></pre>

<p><img src="https://ollama.com/assets/library/deepseek-r1/e44d096e-fa46-4cae-b2f2-53991e8c8da0" alt="deepseek"></p>

        
      </div>
    
  </div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Authors seek Meta's torrent client logs and seeding data in AI piracy probe (150 pts)]]></title>
            <link>https://torrentfreak.com/authors-seek-metas-torrent-client-logs-and-seeding-data-in-ai-piracy-probe-250120/</link>
            <guid>42772771</guid>
            <pubDate>Mon, 20 Jan 2025 20:38:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/authors-seek-metas-torrent-client-logs-and-seeding-data-in-ai-piracy-probe-250120/">https://torrentfreak.com/authors-seek-metas-torrent-client-logs-and-seeding-data-in-ai-piracy-probe-250120/</a>, See on <a href="https://news.ycombinator.com/item?id=42772771">Hacker News</a></p>
Couldn't get https://torrentfreak.com/authors-seek-metas-torrent-client-logs-and-seeding-data-in-ai-piracy-probe-250120/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[ROCm Device Support Wishlist (190 pts)]]></title>
            <link>https://github.com/ROCm/ROCm/discussions/4276</link>
            <guid>42772170</guid>
            <pubDate>Mon, 20 Jan 2025 19:31:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ROCm/ROCm/discussions/4276">https://github.com/ROCm/ROCm/discussions/4276</a>, See on <a href="https://news.ycombinator.com/item?id=42772170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      <div data-body-version="299b9ab50a702b61e654a07387c220b1fb5c6d12f8237f4cbfff86784c2f2b0b" data-error="" id="discussioncomment-11894448" data-gid="DC_kwDOAzpr8c4AtX6w" data-url="/ROCm/ROCm/discussions/4276/comments/11894448" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894448/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Honestly, anything that has 16GB VRAM or more (or the ability to have reserved more, for eg. the iGPUs like 680/780/890M and Strix Halo iGPUs).</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-07e6d4f2-e873-4340-a7b4-cc09177208fa" for="discussion-upvote-button-DiscussionComment-11894448" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894448">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11896093,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="738f5e1a0c79912c63b83622201031e6c8db67ed112aea719ab7d413def28e9d" data-hovercard-type="user" data-hovercard-url="/users/niklassheth/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/niklassheth"><img src="https://avatars.githubusercontent.com/u/20130217?s=60&amp;v=4" width="30" height="30" alt="@niklassheth"></a></p>

        <div data-body-version="3366d9f7e19e5e556f43df8081525bcb532d9434f2a1a325fd67425a3e1fc6c8" id="discussioncomment-11896093" data-gid="DC_kwDOAzpr8c4AtYUd" data-url="/ROCm/ROCm/discussions/4276/comments/11896093" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896093/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">As evidence for this, you can look at the used price of GPUs. Even an 8 year old P40 is going for $300 on eBay because it has 24GB VRAM. If the MI60 was supported it could be a good budget option.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="9a4ede9d2f426b2cac5c97c9d588b433e455df2f2d11f82b00ab42d18dfbcc2d" data-error="" id="discussioncomment-11894747" data-gid="DC_kwDOAzpr8c4AtX_b" data-url="/ROCm/ROCm/discussions/4276/comments/11894747" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894747/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I would like support for ROCm to be restored to all the relatively recent GPUs (last 5-6 years) AMD has released and then dropped ROCm support for.  New I could not care much about. Actually supporting the AMD cards I bought in the past would be great.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-46052c64-2b58-4120-a6cf-206ce13fbac7" for="discussion-upvote-button-DiscussionComment-11894747" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="9eab11215d5ae982b020b1b9ab57bf9509331d016278ec1083667515affd030d" data-error="" id="discussioncomment-11894841" data-gid="DC_kwDOAzpr8c4AtYA5" data-url="/ROCm/ROCm/discussions/4276/comments/11894841" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894841/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I think it might be interesting to share here that Debian has built a CI at <a href="https://ci.rocm.debian.net/" rel="nofollow">ci.rocm.debian.net</a> where the ROCm stack, and any package that depends on it, is continuously tested. Our CI includes all of the architectures listed above.</p>
<p dir="auto">We would be happy to cooperate on increasing service support for Debian and derivatives.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-66903d35-f63f-4fec-8302-b6b1fe0fab74" for="discussion-upvote-button-DiscussionComment-11894841" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="baf615a896f6281ae4dce8c4e2704158995d26e3d65d562d075cbd45095fcb3f" data-error="" id="discussioncomment-11894876" data-gid="DC_kwDOAzpr8c4AtYBc" data-url="/ROCm/ROCm/discussions/4276/comments/11894876" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894876/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">This is not a "device" support wish, but a "platform" one. Stable Diffusion on native Windows with AMD GPUs is not possible until we get "Windows" support for "AI Libraries" (specifically MIOpen) here: <a href="https://rocm.docs.amd.com/projects/install-on-windows/en/develop/reference/component-support.html" rel="nofollow">https://rocm.docs.amd.com/projects/install-on-windows/en/develop/reference/component-support.html</a></p>
<p dir="auto">This is required to get PyTorch working. I've seen so many AMD users in recent times selling their AMD GPUs and buying "the competition" because WSL and ZLUDA are their only options, and those are half-baked solutions. Native Windows support should be a top priority.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-f247b436-6275-427f-8fa9-e125513f1e76" for="discussion-upvote-button-DiscussionComment-11894876" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894876">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895073,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="1e8bb9a91b6ac1e121d7c4a51111e736de21a302b5d916fa108e8f7b88b11dcd" data-hovercard-type="user" data-hovercard-url="/users/tocram1/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/tocram1"><img src="https://avatars.githubusercontent.com/u/22381620?s=60&amp;v=4" width="30" height="30" alt="@tocram1"></a></p>

        <div data-body-version="59dcaa13ac84895a8d972d45bb76f53ce6fdd795fa4f412208b6ec88f5bb79e3" id="discussioncomment-11895073" data-gid="DC_kwDOAzpr8c4AtYEh" data-url="/ROCm/ROCm/discussions/4276/comments/11895073" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895073/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Definitely agree on this one, this is a major hurdle in MY opinion.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="75fc6a10eb474b0ac38ca75b93996824dad488c2c5d63281ce5943635eb31b55" data-error="" id="discussioncomment-11894914" data-gid="DC_kwDOAzpr8c4AtYCC" data-url="/ROCm/ROCm/discussions/4276/comments/11894914" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894914/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">A bit older than the ones listed there, but I own a 5700XT, and a good few other people do too, from my extensive looking for how to get it to work online.</p>
<p dir="auto">Still holding on to the precompiled wheel for torch 1.13 ROCM 5.2 for Python 3.10 which is the last one that works (after setting HSA_OVERRIDE_GFX_VERSION). Later versions seem to either outright crash, or import correctly but then crash when a tensor is sent to the GPU.</p>
<p dir="auto">Using this older version as a workaround was doable back when torch 2.0 was new, but now as most new code has already been using 2.0+ for a while, it's effectively not functional at all anymore for any recently written code.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-3e032699-4bf6-4370-b1d3-6ddd7baaaec0" for="discussion-upvote-button-DiscussionComment-11894914" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894914">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895908,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="fb945d44ec154bf7c9a296dc4c0adfd92652dd919a443c392fae053fa4dab4bc" data-hovercard-type="user" data-hovercard-url="/users/SicLuceatLux/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SicLuceatLux"><img src="https://avatars.githubusercontent.com/u/43041463?s=60&amp;v=4" width="30" height="30" alt="@SicLuceatLux"></a></p>

        

    </div>


        
    </div>
  <div data-body-version="0c261b8b353a6a30cb9a1d99f88e3f6d4a9c1043e5f1ccd22425a35a36cedb04" data-error="" id="discussioncomment-11894998" data-gid="DC_kwDOAzpr8c4AtYDW" data-url="/ROCm/ROCm/discussions/4276/comments/11894998" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894998/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Considering my GPU( 6600 XT)  was released near the end of 2021 it would be nice to know that I don't need to buy a new GPU every year just to have support. It would also be nice to have actual proper Windows support instead of having to deal with the clusterfuck that is Zluda, or other translation layers. This kind of treatment from AMD is why I'll probably go nvidia the next time my budget allows it.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-563ac12c-b2cc-4200-86b1-8876cb9400ce" for="discussion-upvote-button-DiscussionComment-11894998" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="a4116625bd825f160374a9f736bc058290ceb23dd78775a84ba17d56344fe604" data-error="" id="discussioncomment-11895157" data-gid="DC_kwDOAzpr8c4AtYF1" data-url="/ROCm/ROCm/discussions/4276/comments/11895157" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895157/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">APU support opens the door for introducing this software to a wide audience, please consider hitting the entire APU line (3 and 3.5.) Early ROCm worked for 780m and got me in the front door of working with this software at all (that said I had to use env var hacks to get it functioning). Later versions of ROCm stopped working at all.</p>
<p dir="auto">The hobbyist crowd would greatly benefit from APU support, which hopefully has the AMD financial incentive of market share and product familiarity (hobbyist engineers who do something neat at home and then bring the concepts to work, where you then pick up the larger purchases)</p>
<p dir="auto">If I was able to feel confident in better consumer ROCm support I would have gladly dropped money for 2 AMD graphics cards for the LLM stuff I do.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-cc9cfe79-f4fb-44e8-b72e-684504465400" for="discussion-upvote-button-DiscussionComment-11895157" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    2 replies
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895157">

    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895323,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="08551d753a51e5999ddb8a5a0c88a89d7354468fcdbedea428c9cbc91efbed94" data-hovercard-type="user" data-hovercard-url="/users/randomstuff/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/randomstuff"><img src="https://avatars.githubusercontent.com/u/946727?s=60&amp;v=4" width="30" height="30" alt="@randomstuff"></a></p>

        <div data-body-version="7d32692793bbb76ac2be4d90993111340635b8e9c7da65be969ea9fcca74dc4e" id="discussioncomment-11895323" data-gid="DC_kwDOAzpr8c4AtYIb" data-url="/ROCm/ROCm/discussions/4276/comments/11895323" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895323/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I have been somewhat successfully been able to run Stable Diffusion on a <a href="https://www.gabriel.urdhr.fr/2022/08/28/trying-to-run-stable-diffusion-on-amd-ryzen-5-5600g/" rel="nofollow">AMD Ryzen 5 5600G</a> APU (with 16 Go / 32 Go of RAM).</p>
<p dir="auto">The performance speedup was not super impressive compared to the same implementation executed on CPU or the OpenVINO CPU implementation. I am not sure if we could get a nice speedup for this kind of device but it would be really interesting.</p>
<p dir="auto">The thing was highly unstable and had a tendency of crashing the whole system real quick. Anyway, it was nearly working for some programs. Si maybe there is not so many things missing to a have something stable :)</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895573,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="32cfbb4ae281dd01619117b092b54359b030ceebe3fa78fae5d7a1d00c8e3af1" data-hovercard-type="user" data-hovercard-url="/users/Abdull/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Abdull"><img src="https://avatars.githubusercontent.com/u/529862?s=60&amp;v=4" width="30" height="30" alt="@Abdull"></a></p>

        <div data-body-version="b0ed72ab4fe39ad8c54bf1ce3679bf025c35489ed37cf82d6366f4c770e98616" id="discussioncomment-11895573" data-gid="DC_kwDOAzpr8c4AtYMV" data-url="/ROCm/ROCm/discussions/4276/comments/11895573" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895573/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">important for Framework 13 AMD laptop users</p>
    </div>
    
</task-lists>

          

        </div>

    </div>

</div>


        
    </div>
  <div data-body-version="6dd366079f09ed3314a27f573c24f7694472b1e9620886d0a44809818ef06c97" data-error="" id="discussioncomment-11895185" data-gid="DC_kwDOAzpr8c4AtYGR" data-url="/ROCm/ROCm/discussions/4276/comments/11895185" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895185/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">why not just all, like the other company? ;-)</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-0cb80f69-16e9-4b33-bd3e-9e7a6375862a" for="discussion-upvote-button-DiscussionComment-11895185" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    3 replies
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895185">

    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895241,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58150230df92bc1e3b1bc985b82360100bf1bdba1f722ceda041f8f23cb00282" data-hovercard-type="user" data-hovercard-url="/users/powderluv/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/powderluv"><img src="https://avatars.githubusercontent.com/u/74956?s=60&amp;v=4" width="30" height="30" alt="@powderluv"></a></p>

        <div data-body-version="94f3e3e23b56bb956c129e2c7dc34d254852eeea837fccfffe0c3067d22f4cf4" id="discussioncomment-11895241" data-gid="DC_kwDOAzpr8c4AtYHJ" data-url="/ROCm/ROCm/discussions/4276/comments/11895241" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895241/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Eventually. But what would you prioritize? :)</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895322,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="034fd912b967c7ac7fac064c34a1ccfb3958f66bd1dacdc08fc1105d3d840e37" data-hovercard-type="user" data-hovercard-url="/users/shiltian/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/shiltian"><img src="https://avatars.githubusercontent.com/u/7587318?s=60&amp;v=4" width="30" height="30" alt="@shiltian"></a></p>

        <div data-body-version="444c854734197b911f0b04229e1509352e0fc94e5bf147f1ee9568e88a92539d" id="discussioncomment-11895322" data-gid="DC_kwDOAzpr8c4AtYIa" data-url="/ROCm/ROCm/discussions/4276/comments/11895322" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895322/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">my .02 is starting from all RDNA 2 and newer. that's gonna take time. by the time they are all supported, RDNA 1 might have fairly faded out.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11896209,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="94548708abd6a2498081a9869a81137e0e2ef62a4ed3bc113fce92c1c962dfae" data-hovercard-type="user" data-hovercard-url="/users/TKCZ/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TKCZ"><img src="https://avatars.githubusercontent.com/u/22118472?s=60&amp;v=4" width="30" height="30" alt="@TKCZ"></a></p>

        <div data-body-version="c416c01b691f7b738b438424cc3d8c9266f848bdc999a364f68ea3f3048f1f14" id="discussioncomment-11896209" data-gid="DC_kwDOAzpr8c4AtYWR" data-url="/ROCm/ROCm/discussions/4276/comments/11896209" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896209/language_detections">
      
    </inline-machine-translation>
  <div>
        <blockquote>
<p dir="auto">Eventually. But what would you prioritize? :)</p>
</blockquote>
<p dir="auto">Definitelly start with RDNA2 &amp; 3, since these series offered models with 16GB VRAM. That much memory deserves to stay around officially supported for as long as possible. Let alone the fact that cards like 6800XT still pack decent punch for local AI inference.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>

</div>


        
    </div>
  <div data-body-version="9f4dab7adc8c5e819850961f54e8c18019d30f85b4c1a707fd0cd3a15bac7c40" data-error="" id="discussioncomment-11895317" data-gid="DC_kwDOAzpr8c4AtYIV" data-url="/ROCm/ROCm/discussions/4276/comments/11895317" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895317/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">ROCm windows, All RDNA3 and newer. Don't forget integrated GPUs. Maybe next year?</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-9f39403a-251c-4a3f-ab44-50269333e5bd" for="discussion-upvote-button-DiscussionComment-11895317" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="7b94ee7e4a683ea60daf9aa12987a695462f6dfe1dc018b8560ecc2e80d02174" data-error="" id="discussioncomment-11895348" data-gid="DC_kwDOAzpr8c4AtYI0" data-url="/ROCm/ROCm/discussions/4276/comments/11895348" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895348/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I wish for AMD to look back at the RX 500  and the RX5000 series. And the reason being, the physical architectures for both lend themselves to really interesting compute because the RX 580 architecturally is very good to use as a modular scale up and scale down at 75 w. And based based on some back of the napkin maths that I've done an RX 580 8 gig with a 8 billion parameter model with a quant size of eight. Can pull about 15 to 30 tokens per second.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-6713e9db-8776-42b2-ab7a-134f822bdcb7" for="discussion-upvote-button-DiscussionComment-11895348" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>


          <div data-body-version="5456848d6531fe9f1f551b6f7229a70b9d12cac492941d4f1a0e1ed720aec788" data-error="" id="discussioncomment-11895367" data-gid="DC_kwDOAzpr8c4AtYJH" data-url="/ROCm/ROCm/discussions/4276/comments/11895367" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895367/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Hi,<br>
IMO all products going forward should be able to run all typical ML software: stable diffusion, LLMs, pytorch.<br>
Doesn't have to be crazy fast, but support it and then improve it over time.<br>
And simultaneously, but fine if at a lower pace, walk backwards and support the older products.</p>
<p dir="auto">So you should start by supporting strix halo and RDNA 4. Then RDNA 3 and prior APUs.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-c27855b0-7ef2-48ff-ba05-4cba14af7fb3" for="discussion-upvote-button-DiscussionComment-11895367" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="368d8a87f1f3eb9b8da0616cf95aca6b54ce9e0833bc0ce5dc74a2cb880d16d2" data-error="" id="discussioncomment-11895435" data-gid="DC_kwDOAzpr8c4AtYKL" data-url="/ROCm/ROCm/discussions/4276/comments/11895435" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895435/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Thank you for reaching out and at least trying to extend the device support. The limited consumer hardware support has always been one of the weakest point of ROCm, and if AMD is serious about the future of ROCm, at least any upcoming hardware should be supported. Being able to get used to a platform without spending 1000s is actually huge.<br>
Currently, even if unsupported, many actually work fine. I did and I'm still doing some PyTorch stuff on a 8700GE, which has a gfx1103 GPU in it. Works, but there are some nasty minor issues like this one here, causing the GPU driver to crash now and then, seemingly a firmware issue: <a data-error-text="Failed to load title" data-id="2474223008" data-permission-text="Title is private" data-url="https://github.com/lamikr/rocm_sdk_builder/issues/141" data-hovercard-type="issue" data-hovercard-url="/lamikr/rocm_sdk_builder/issues/141/hovercard" href="https://github.com/lamikr/rocm_sdk_builder/issues/141">lamikr/rocm_sdk_builder#141</a><br>
I think, it's a rather small step for AMD to make those 99% working devices to a 100% officially supported level.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-57cb16f5-c3d1-498c-9a2e-e5f430664f0a" for="discussion-upvote-button-DiscussionComment-11895435" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="054686a2c43c6262a1f6b4938167d23622b1aa0a11c76249c06691a6e298954a" data-error="" id="discussioncomment-11895444" data-gid="DC_kwDOAzpr8c4AtYKU" data-url="/ROCm/ROCm/discussions/4276/comments/11895444" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895444/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">At one time Kaveri was promoted as a hybrid processor, and while HSA was being implemented its support disappeared. It would be fair, given the promises of marketers, to make HSA + ROCm for APU Kaveri.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-356e5a80-3267-4c1b-acbd-0ada8783843b" for="discussion-upvote-button-DiscussionComment-11895444" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="313f54341a67795a6b3549078c47509a3bbe9a9250b1711d454fc3dfb6b44323" data-error="" id="discussioncomment-11895539" data-gid="DC_kwDOAzpr8c4AtYLz" data-url="/ROCm/ROCm/discussions/4276/comments/11895539" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895539/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Missing poll option: actually support the ✅ marked devices consistently</p>
<p dir="auto">There's not much point having a green icon in the support matrix if it doesn't mean your device is supported.<br>
aotriton supports only MI2xx, MI3xx, 7800, 7900.<br>
hipblaslt supports only MI2xx, MI3xx, 7800, 7900.<br>
Dao-AILab/flash-attention (which AMD contributed ROCm support to) doesn't support MI100. I think it's picky about consumer cards too but don't remember the models.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-37226189-31a4-4fad-bedf-c579ecabd45d" for="discussion-upvote-button-DiscussionComment-11895539" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895539">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895810,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="76750ea7a41fa5e9e9b1ea2e04c74ab5908b60b290bbeac03e20dcfe27e8f1e8" data-hovercard-type="user" data-hovercard-url="/users/IMbackK/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/IMbackK"><img src="https://avatars.githubusercontent.com/u/13803414?s=60&amp;v=4" width="30" height="30" alt="@IMbackK"></a></p>

        <div data-body-version="1b50beb7542cde7184da8ea2e0afb47d7f62bdd41426fc550e5676f7b5cc55bf" id="discussioncomment-11895810" data-gid="DC_kwDOAzpr8c4AtYQC" data-url="/ROCm/ROCm/discussions/4276/comments/11895810" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895810/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Yeah this is the big thing. Besides missing rdna1 support, the actual support matrix (not the mostly useless check mark, what the code supports) is mostly fine, except random libraries that then support only a subset of those.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="96b624a0db8669f4d32a09be017348010050de83168e06266ca1d3088deec029" data-error="" id="discussioncomment-11895566" data-gid="DC_kwDOAzpr8c4AtYMO" data-url="/ROCm/ROCm/discussions/4276/comments/11895566" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895566/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto"><strong>Chicken and egg.</strong>  I don't own any of your hardware because I can't run the software I want to run. Support Flux, Stable Diffusion, Tencent Hunyuan Video, Nvidia Cosmos, and I'll be in the market to buy your cards. As it stands, I can't leverage your offering.  I'll gladly build AMD workstations if your hardware can do the things I want.</p>
<p dir="auto"><strong>Prioritize VRAM.</strong> The next battle is local image and video models. Nobody wants to use hosted SaaS and all the film and VFX people will be running local Comfy, Hunyuan, etc. in just a few years time. These models need a tremendous amount of VRAM, so you need to build consumer/prosumer SKUs that have it.</p>
<p dir="auto">If you time this right and build high VRAM consumer cards with broad software support, the next generation of media production could ride on your platform.</p>
<p dir="auto">Let me underscore: you <em>must</em> be able to run popular image and video models.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-8d82a3f8-78d9-4455-b7b6-76c39c74bb48" for="discussion-upvote-button-DiscussionComment-11895566" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>

    



      <div data-body-version="09ee47da6431ac30b79faf5af02f101bfd50d483cfdbaa7b784b56efa45bee11" data-error="" id="discussioncomment-11895881" data-gid="DC_kwDOAzpr8c4AtYRJ" data-url="/ROCm/ROCm/discussions/4276/comments/11895881" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895881/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Long term support for APU's with a lot of ram and usable performance gets a bunch of developers to try things quickly and builds confidence in shipping to enterprise hardware in prod. Low power, high ram, usable performance and out of the box support for all the major tools with NO BUGS. Learn from Ballmer: Developers developers developers developers....</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-83513683-c4a5-4452-abc1-18d0b13407ca" for="discussion-upvote-button-DiscussionComment-11895881" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="429a8fd23a83a0f1f55e3bf56e326d8bab30e9ebc9e65a0897192fbad18c0115" data-error="" id="discussioncomment-11895947" data-gid="DC_kwDOAzpr8c4AtYSL" data-url="/ROCm/ROCm/discussions/4276/comments/11895947" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895947/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Basically, anything with more than 16GB of RAM. APUs capable of using system RAM could be a cost-effective entry-level option for running large language models (LLMs). While they might be slower, many people don’t require real-time LLM output.</p>
<p dir="auto">Everyone wants to run large models, but not everyone can afford to spend several thousand dollars on professional GPUs, multiple high-end prosumer cards, or Macs.</p>
<p dir="auto">The ROCm user base could grow rapidly if people could leverage their existing iGPUs for AI tasks. I wish my Raven Ridge APU could handle slow AI tasks, like sorting and tagging photos on my Nextcloud NAS, and similar applications.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-fe79600e-9a2d-4241-a4ab-f13eb5a7ffb9" for="discussion-upvote-button-DiscussionComment-11895947" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="60b2d147161c5e686c514dae9cdf1e582e98a78493f59d64b1479ae579d9bced" data-error="" id="discussioncomment-11895995" data-gid="DC_kwDOAzpr8c4AtYS7" data-url="/ROCm/ROCm/discussions/4276/comments/11895995" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895995/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">xbox and playstation, period.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-cc72407d-7745-4740-9da5-a4657fe9a2e1" for="discussion-upvote-button-DiscussionComment-11895995" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="db5020ede0a87cb441e4c80ee05bdc1b63cb1628b9c9cc55d6023f527156673e" data-error="" id="discussioncomment-11896000" data-gid="DC_kwDOAzpr8c4AtYTA" data-url="/ROCm/ROCm/discussions/4276/comments/11896000" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896000/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Strix Halo and Phoenix APUs could possibly be the most popular so definitely them but full support for the 7600xt and better seems proper. including the 6000 series equivalents. I feel the 7600xt's appeal over a regular 7600 is ROCm more than gaming</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-18baf3d8-268d-4841-b5a6-4d5f4b20a7ef" for="discussion-upvote-button-DiscussionComment-11896000" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="4eb0d589f42b297099933e81c73b825739045177384b8a92ac25acf48779bcd9" data-error="" id="discussioncomment-11896009" data-gid="DC_kwDOAzpr8c4AtYTJ" data-url="/ROCm/ROCm/discussions/4276/comments/11896009" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896009/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">You have a much wider reach with iGPUs than with dGPUs, so I wouldn't stop supporting RDNA and Vega which AMD still sells widely.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-b440b199-229e-4756-9ee4-082580964130" for="discussion-upvote-button-DiscussionComment-11896009" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="6389b831651f10398b1800c0693ba58bd996c1ccf901d9d557f998797699a33e" data-error="" id="discussioncomment-11896170" data-gid="DC_kwDOAzpr8c4AtYVq" data-url="/ROCm/ROCm/discussions/4276/comments/11896170" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896170/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">For Windows and WSL users, shouldn't using DirectML be an option? I may be wrong here though</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-b8760a12-1b9b-4244-80af-60d64fe749e7" for="discussion-upvote-button-DiscussionComment-11896170" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="0d511713bb5eb3f4b1179446b5e95932e1f2401f25e9c3f9e8a403a21d5d94a4" data-error="" id="discussioncomment-11896197" data-gid="DC_kwDOAzpr8c4AtYWF" data-url="/ROCm/ROCm/discussions/4276/comments/11896197" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896197/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Would like to see the the W7600 and W7700 supported - small memory, but single-slot! Very useful for compact builds, or if more PCIe cards are needed. I've combined these with Mellanox NICs and Highpoint HBAs.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-94216dac-1578-46d2-93fa-aeeb95d1e4dd" for="discussion-upvote-button-DiscussionComment-11896197" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="ad8da41e9c92f907c38045f5d6e2ef421dcf89ded01a6affa6baecf8d968ea73" data-error="" id="discussioncomment-11896210" data-gid="DC_kwDOAzpr8c4AtYWS" data-url="/ROCm/ROCm/discussions/4276/comments/11896210" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896210/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">All of them. GCN 4 and up if I had to be hard-pressed into an answer.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-38d3cb38-b7e2-4786-9aef-131a59a9de5e" for="discussion-upvote-button-DiscussionComment-11896210" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="27e881f62dfca99403d134c3956b66d37cf90170fc599f4e5ea75120bf6d47f9" data-error="" id="discussioncomment-11896220" data-gid="DC_kwDOAzpr8c4AtYWc" data-url="/ROCm/ROCm/discussions/4276/comments/11896220" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896220/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">It's important to note that "Support" means wildly different things to different people.</p>
<ul dir="auto">
<li>The compiler knows how to emit code for the GPU</li>
<li>The driver knows how to load code onto / allocate memory etc for the GPU</li>
<li>The libraries have been compiled for that GPU (so can actually run)</li>
<li>The libraries have GPU-specific optimisations implemented (i.e. are faster)</li>
<li>The ROCm release process tests / validates on that GPU</li>
<li>The various CI systems run on that GPU</li>
<li>Variations on where tickets can be raised</li>
</ul>
<p dir="auto">I believe this is where things have gone south. The ROCm release testing / validation is thorough and somewhat linear in the number of GPUs tested on so adding more hardware to that set costs lots of time. The cards behave fairly similarly to one another so it's also not especially informative. However writing "Supported: Foo" without actually putting Foo through the same internal testing as all others seems problematic.</p>
<p dir="auto">What a decent fraction of people want is for ROCm to run on their gaming card(s). Whether it actually went through the internal validation is somewhat less important than it refusing to run entirely because the libraries haven't been compiled for their hardware.</p>
<p dir="auto">I think the solution to this is really obvious. Build the userspace software for all the targets. Let "Supported" continue to mean whatever it currently does. That'll mean people can install the ROCm distribution and get something which at least attempts to run on their hardware. Optionally introduce a new term, whatever marketing like, to refer to the hardware that isn't on the supported list.</p>
<p dir="auto">I personally don't care at all whether the latest ROCm release has been carefully tested on the graphics card I'm using locally but I'm really annoyed when it wasn't compiled for it.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-d959b2b9-1153-4707-957d-95847ec7801c" for="discussion-upvote-button-DiscussionComment-11896220" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="25a357989dad020ca60381a652abe8e51a10e3de2d0adeb53075b86de7328e0d" data-error="" id="discussioncomment-11896278" data-gid="DC_kwDOAzpr8c4AtYXW" data-url="/ROCm/ROCm/discussions/4276/comments/11896278" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896278/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I'll keep it short, please don't drop gfx906.</p>
<p dir="auto">and maybe what I'm asking for is too much given that they seem to strictly include officially supported, CDNA, GPUs, but it would be lovely if you could get support for consumer GPUs eg. gfx906 and up added to prebuilt docker images like vllm-dev/-ci.<br>
thank you guys, ROCm is getting better and better.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-c02a500b-e04e-4b67-b4a2-1e470920e860" for="discussion-upvote-button-DiscussionComment-11896278" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="67d6d7105dd537c0790422c11383d05f508346f2128ab90a3c4ac5f4d21e7c56" data-error="" id="discussioncomment-11896331" data-gid="DC_kwDOAzpr8c4AtYYL" data-url="/ROCm/ROCm/discussions/4276/comments/11896331" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896331/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I would like to see full-stack generational support on Linux with both the runtime and HIP SDK for consumer cards on RDNA[1|2|3] and then extending it to GCN where possible.</p>
<p dir="auto">At the moment AMD have structured [and in my opinion artificially limited] their compatibility matrices to the upper tiers of the hardware stacks, e.g. 6800 and up on RDNA2, preventing those who own 6750XT and lower stack cards from using ROCm/HIP.</p>
<p dir="auto">I understand that a lot of the unsupported hardware "just works" in some fashion but it is not officially supported nor documented as being supported or which components/libraries work and which do not - this is just bad all around as nobody will buy GPU hardware or buy into the ROCm software ecosystem without knowing before hand that the hardware is capable, the hardware feature set is fully supported in software and it is relatively easy to get up and running as an end user, this is especially bad from a PR perspective for AMD in wanting to get more people to use their hardware when it is restricted by hardware/pricing tiers and by the AMD software itself.</p>
<p dir="auto">Nobody is going to purchase a GPU in order to dip into trying out the ROCm ecosystem if they have to purchase the highest tiers of GPU to know for sure that ROCm will fully support the hardware.</p>
<p dir="auto">Artificial limits which segregate capable hardware through a lack of support in or a lack of enablement in software is not a good practice and it harms not only end-users/customers but AMD and ROCm adoption too.</p>
<p dir="auto">I would like to see AMD's stance on this change to one of starting from full enablement from the outset where the hardware features exist to do that and remove any artificial tiering/segregation entirely, tear down those walls.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-424addef-6d6f-44a3-9bda-3280ef11dedd" for="discussion-upvote-button-DiscussionComment-11896331" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="284b2343c73f6c317db7f14871d9dd54a3c4148d693f00cd831a70cc846e288d" data-error="" id="discussioncomment-11896340" data-gid="DC_kwDOAzpr8c4AtYYU" data-url="/ROCm/ROCm/discussions/4276/comments/11896340" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896340/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">You know, the reason AMD is way behind Nvidia in market share is because Nvidia literally supports every single discrete graphics processor model with CUDA from the low end to their high end.  They realized what AMD never has, and has continuously annoyed people, especially Linux users.  Not everyone writing software for CUDA has an ultra high end GPU product <em>because they can't afford them</em>.  But they have a very robust software development community where the underlying SDKs largely just works.  Intel has effectively realized the same thing with ARC.</p>
<p dir="auto">If AMD can't at least match the Linux support matrix with the Windows support matrix going forward you're rapidly going to grow completely irrelevant with new generations of software tinkerers who are primarily writing software on Linux. Windows from a compute performance point of view is demonstrably poor in comparison, and the user experience is degrading over time as Microsoft lets their OS foundation crumble while they're off chasing unicorns.</p>
<p dir="auto">What's my vote?  Every GPU currently under active driver support including Vega. Vega still has a fairly large-ish install base.  Arbitrary decisions to drop support may make business decisions, but it annoys customers who buy hardware only to have it dropped from support not long after it was still being sold.  But if you must narrow down your support matrix everything from the RX 5000 series and newer.  Either actually compete with the CUDA hardware support experience or get out of the game.  Those are your only options because that's the market you're trying to grow and Nvidia is the dominant player.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-6646e146-c08b-4df3-8bb2-927c82b815cb" for="discussion-upvote-button-DiscussionComment-11896340" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="65e02158d0d0f60fde3be97886b2f1f80177a108e4a09a0f193315454137f75c" data-error="" id="discussioncomment-11896361" data-gid="DC_kwDOAzpr8c4AtYYp" data-url="/ROCm/ROCm/discussions/4276/comments/11896361" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896361/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I'm not sure why, but for me it seems that for example RDNA2 cards (and APUs) are not unsupported, but rather blocked. With setting <code>HSA_OVERRIDE_GFX_VERSION=10.3.0</code> ROCm (using pytorch) runs fine. Since Linux 6.10 and the APU memory fix it even works on my Ryzen 6000 notebook. Why the need for that environment variable?</p>
<p dir="auto">If you don't have the resources to run all tests on all types of consumer GPU/APU and you want to ensure that you provide a build that is fully tested: Why not an "enterprise release" that is fully tested and has only support for tested card and a "community edition" that has all GPUs enabled but is not fully tested (both build from the same source code with the same versions, only difference is the activated cards).</p>
<p dir="auto">If you're thinking supporting a lot of consumer GPUs is a waste of money: A big reason why NVIDIA is so successful in the AI market, because every student with even the smallest NVIDIA GPU was able to experiment with CUDA on her/his own machine. Years later when those students are working in the industry, with what products/APIs do they have experience? And when they make decisions, what will they buy for their company?<br>
AMD missed the first big wave, so they need to catch up, and maybe they get a second chance to really gain market share at some point (when for example NVIDIA is having issues with a new generation).</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-3db34814-8b6d-499d-8c08-1a49909c1da3" for="discussion-upvote-button-DiscussionComment-11896361" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="5adf4a21994224ef202e238c472a29caef73e0d49b91c99c4ccf15b93d227319" data-error="" id="discussioncomment-11896375" data-gid="DC_kwDOAzpr8c4AtYY3" data-url="/ROCm/ROCm/discussions/4276/comments/11896375" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896375/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">This is fundamentally misguided. It's not a question of which specific GPUs are supported now. It's a question of:</p>
<ol dir="auto">
<li>Will support consistently be added for new GPUs at the time of launch? Your competition has day 1 support for new GPUs, and doesn't arbitrarily decide that half the GPUs in a new generation will be incompatible.</li>
<li>Will support consistently be kept for GPUs that are currently supported? You competition still runs on ancient laptops out-of-the-box.</li>
<li>Do consumers trust you to keep to your word for 1 &amp; 2? You've walked back support before.</li>
</ol>
<p dir="auto">Reiterating from my prior comment <a href="https://github.com/amd/RyzenAI-SW/issues/2#issuecomment-1999684155" data-hovercard-type="issue" data-hovercard-url="/amd/RyzenAI-SW/issues/2/hovercard">here</a>:</p>
<blockquote>
<p dir="auto">Your competition has CUDA: Compute <em>Unified</em> Device Architecture - and indeed it supports practically everything from ancient laptops on up. In terms of effort versus reward, things target CUDA largely because they can port to it - using easily available hardware - <em>once</em> - and get fairly decent performance across a very large chunk of the market. (And then tune it later if necessary.)</p>
<p dir="auto"><a href="https://github.com/ROCm/ROCm/issues/1180" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1180/hovercard">Meanwhile</a>, <a href="https://github.com/ROCm/ROCm/issues/2429" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/2429/hovercard">ROCm</a> <a href="https://github.com/ROCm/ROCm/issues/1659" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1659/hovercard">support</a> <a href="https://github.com/ROCm/ROCm/issues/1714" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1714/hovercard">is</a> <a href="https://github.com/ROCm/ROCm/issues/1306" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1306/hovercard">a</a> <a href="https://github.com/ROCm/ROCm/issues/666" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/666/hovercard">minefield</a> <a href="https://github.com/ROCm/ROCm/issues/887" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/887/hovercard">at</a> <a href="https://github.com/ROCm/ROCm/issues/1880" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1880/hovercard">best</a>.</p>
</blockquote>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-f69bf508-67d7-40d3-87f3-2fa27351cb64" for="discussion-upvote-button-DiscussionComment-11896375" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="ebcd1fe4bc079c968e2da6d9e486b26e57d33c33e1091450cf4878b73a1c1bd3" data-error="" id="discussioncomment-11896406" data-gid="DC_kwDOAzpr8c4AtYZW" data-url="/ROCm/ROCm/discussions/4276/comments/11896406" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896406/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Supporting gfx1036 is a must. It's probably the most available device and would allow many people to see if something is working on ROCm at all. It's also a great option to test on RDNA2 when you have other generation dGPUs.</p>
<p dir="auto">But, as many people said already, supporting all devices is the only correct option if you want broad developer support. After you've dropped gfx906 support on Windows (after it barely started) I don't see any reason to invest development effort in current AMD hardware. And the UDNA news sound like you'll immediately drop all previous architectures upon release.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-2dbbbb07-e9a3-4bad-8b37-be85b36d4d61" for="discussion-upvote-button-DiscussionComment-11896406" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>


  
  <!-- '"` --><!-- </textarea></xmp> --></div></div>]]></description>
        </item>
    </channel>
</rss>