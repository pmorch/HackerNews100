<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 07 Jul 2024 17:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A reawakening of systems programming meetups (123 pts)]]></title>
            <link>https://notes.eatonphil.com/2024-07-07-systems-meetups.html</link>
            <guid>40897506</guid>
            <pubDate>Sun, 07 Jul 2024 13:20:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notes.eatonphil.com/2024-07-07-systems-meetups.html">https://notes.eatonphil.com/2024-07-07-systems-meetups.html</a>, See on <a href="https://news.ycombinator.com/item?id=40897506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>This year has seen a resurgence in really high quality systems
programming meetups. <a href="https://www.meetup.com/munich-database-meetup/">Munich Database
Meetup</a>, <a href="https://lu.ma/8ujc7st3?tk=DAAbmn">Berlin
Systems Group</a>, <a href="https://lu.ma/t6r4mi4v">SF Distributed
Systems Meetup</a>, <a href="https://nycsystems.xyz/">NYC
Systems</a>, <a href="https://twitter.com/BengaluruSys">Bengaluru
Systems</a>, to name a few.</p>
<p>This post summarizes a bit of disappointing recent tech meetup
history, the new trend of excellent systems programming meetups, and
ends with some encouragement and guidance for running your own systems
programming events.</p>
<p>I will be a little critical in this post but I want to preface by
saying: organizing meetups is really tough! It takes a lot of work and
I have a huge amount of respect for meetup organizers even when their
meetup style did not resonate with me.</p>
<p>Although much of this post talks about NYC Systems, the reason I think
this post is worth writing is because so many other meetups in a
similar vein popped up. I hope to encourage these other meetups and to
encourage folks in other major metros (London, for example) to start
similar meetups.</p>
<h3 id="meetups">Meetups</h3><p>I used to attend a bunch of meetups before the pandemic. But I quickly
got disillusioned. Almost every meetup was varying degrees of startups
pitching their product. The last straw for me was sitting through a talk
at a JavaScript meetup that was by a devrel employee of a startup who
literally gave a tutorial for their product.</p>
<p>There were also some pretty intelligent meetups like the New York
Haskell Users Group and the New York Emacs Meetup. But not being an
expert in either domain, and the attendees almost solely appearing to
be experts, I didn't particularly enjoy going.</p>
<p>There were a couple of meetups that felt inclusive for various
skill-levels of attendees yet still went into interesting
depth. Specifically, <a href="http://www.nylug.org/">New York Linux User
Group</a> and <a href="https://paperswelove.org/chapter/newyork/">Papers We Love
NYC</a>.</p>
<p>These meetups were exceptional because they were language- and
framework-agnostic, they would start broad to give you background, but
then go deep into a topic. Maybe you only understand 50% of what was
covered. But you get exposed to something new from an expert in a
domain.</p>
<p>Unfortunately, the pandemic happened and these two excellent meetups
basically have not come back.</p>
<h3 id="a-couple-of-students-in-munich">A couple of students in Munich</h3><p>The pandemic ended and I tried a couple of meetups I thought might be
better quality. Rust and Go. But they weren't much better than I
remembered. People would give a high level talk and brush over all the
interesting concepts.</p>
<p>I had been thinking of doing an in-person talk series since 2022.</p>
<blockquote><div lang="en" dir="ltr"><p>If I put together a systems/databases/distributed systems meetup in NYC (a physical meetup, not Zoom), who'd be interested (in attending, or presenting, or helping me organize, or donating space)?</p><p>No promises!</p></div>— Phil Eaton (@eatonphil) <a href="https://twitter.com/eatonphil/status/1574875016067710976?ref_src=twsrc%5Etfw">September 27, 2022</a></blockquote> 
<p>But I was busy with TigerBeetle until December of 2023 when I was
messaged on LinkedIn by <a href="https://x.com/georg_kreuzmayr?lang=en">Georg
Kreuzmayr</a>, a graduate student
at Technical University of Munich (TUM).</p>
<p>Georg and his friends, fellow graduate students at TUM, started a
database club: <a href="https://www.tumuchdata.club/">TUMuchData</a>. We got to
talking about opportunities for collaboration and I started feeling a
bit embarrassed that a graduate student had more guts than I had to
get
<a href="https://notes.eatonphil.com/eight-years-of-tech-meetups.html">back</a>
onto the meetup organizer wagon.</p>
<p>A week later, with assurance from <a href="https://twitter.com/justinjaffray">Justin
Jaffray</a> that at least he would
show up with me if no one else did, I started the <a href="https://eatonphil.com/nyc-systems-coffee-club.html">NYC Systems Coffee
Club</a> to bring
together folks in NYC interested in any topic of systems programming
(e.g. compilers, databases, web browser internals, distributed
systems, formal methods, etc.). To bring them together in a completely
informal setting for coffee at 9am in the morning in a public space in
midtown Manhattan.</p>
<blockquote><div lang="en" dir="ltr"><p>Trying something new! If you're a dev in NYC working <br>on (or interested in) systems programming, grab a coffee and come hang out at 1 Bryant Park (indoor space) this Thursday 9AM - 9:30AM.</p><p>See post for details and fill out the Google Form or DM me!<a href="https://t.co/A4bzcPGy6x">https://t.co/A4bzcPGy6x</a> <a href="https://t.co/n1ECMd59ev">pic.twitter.com/n1ECMd59ev</a></p></div>— Phil Eaton (@eatonphil) <a href="https://twitter.com/eatonphil/status/1734216183459512486?ref_src=twsrc%5Etfw">December 11, 2023</a></blockquote> 
<p>I set up that linked web page and started collecting subscribers to
the club via Google Form. Once a month I'd send an email out to the
list asking for RSVPs to this month's coffee club. The first 20 to
respond would get a calendar invite.</p>
<p><img src="https://notes.eatonphil.com/assets/coffee-club-invite.png" alt="/assets/coffee-club-invite.png"></p>
<p>And about the same time I started asking around on Twitter/LinkedIn if
someone would be interested in co-organizing a new systems programming
meetup in NYC. <a href="https://twitter.com/ngeloxyz">Angelo Saraceno</a>
immediately took me up on the idea and we met up.</p>
<h3 id="nyc-systems">NYC Systems</h3><p>We agreed on the premise: this would be a language- and
framework-agnostic meetup that was focused on engineering challenges,
not product pitches. It would be 100% for the sake of corporate
marketing, but corporate marketing of the <em>engineering team</em>, not the
product.</p>
<p><a href="https://nycsystems.xyz/">NYC Systems</a> was born!</p>
<p>We'd find speakers who could start broad and dive deep into some
interesting aspect of databases, programming languages, distributed
systems, and so on. Product pitches were necessary to establish a
context, but the focus of the talk would be about some interesting
recent technical challenge and how they dealt with it.</p>
<p>We'd schedule talks only every other month to ease our own burden in
organizing and finding great speakers.</p>
<p>Once Angelo and I had decided to go forward, the next two challenges
were finding speakers and finding a venue. Thanks to Twitter and
LinkedIn, finding speakers turned out to be the easy part.</p>
<p>It was harder to find a venue. It was surprisingly challenging to find
a company in NYC with a shared vision that the important thing about
being associated with a meetup like this is to be associated with the
quality of speakers and audience we can bring in by not allowing
transparent product pitches.</p>
<p>Almost every company in Manhattan with space we spoke with had a
requirement that they have their own speaker each night. That seemed
like a bad idea.</p>
<p>I think it was especially challenging to find a company willing to
relax about branding requirements like this because we were a new
meetup.</p>
<p>It was pretty frustrating not to find a sympathetic company with space
in Manhattan. And the only reason we didn't give up was because Angelo
was so adament that this kind of meetup actually happen. It's always
best to start something new with someone else for this exact
reason. You can keep each other going.</p>
<p>In the end we went with the only meetup that did not insist on their
own speaker or their own branding. A Brooklyn-based company whose CEO
immediately got in touch with me that they wanted to host us, <a href="https://trailofbits.com/">Trail
of Bits</a>.</p>
<h3 id="how-it-works">How it works</h3><p>To keep things easy, I set up a web page on my personal site with
information about the meetup. (Eventually we moved this to
<a href="https://nycsystems.xyz/">nycsystems.xyz</a>.) I set up a Google Form to
collect emails for a mailing list. And we started posting about the
group on Twitter and LinkedIn.</p>
<blockquote>— Phil Eaton (@eatonphil) <a href="https://twitter.com/eatonphil/status/1758249063550447768?ref_src=twsrc%5Etfw">February 15, 2024</a></blockquote> 
<p>We published the event calendar in advance (an HTML table on the
website) and announced each event's speakers a week in advance of the
event. I'd send another Google Form to the mailing list taking RSVPs
for the night. The first 60 people to respond got a Google Calendar
invite.</p>
<p><img src="https://notes.eatonphil.com/assets/nyc-systems.png" alt="/assets/nyc-systems.png"></p>
<p>It's a bit of work, sure, but I'd do anything to avoid Meetup.com.</p>
<p>
  It is interesting to see every new systems programming meetup also
  not pick Meetup.com. The only one that went with it, Munich Database
  Meetup, is a revival of an existing group, the Munich NoSQL Meetup
  and presumably they didn't want to give up their subscribers. Though
  most others use lu.ma.
</p><p>The mailing list is now about 400+ people. And in each event RSVP we
have a wait list of 20-30 people. Of course although 60 people say Yes
initially, by the time of the event we have typically gotten about 50
people in attendance.</p>
<p>At each event, Trail of Bits provided screens, chairs, food, and
drink. Angelo had recording equipment so he took over audio/video
capturing (and later editing and publishing).</p>
<p>After each event we'd publish talk videos to our
<a href="https://www.youtube.com/@NYCSystems">@NYCSystems</a> Youtube.</p>
<h3 id="network-effects">Network effects</h3><p>In March 2024, the TUMuchData folks joined <a href="https://x.com/ifesdjeen">Alex
Petrov</a>'s Munich NoSQL Meetup to form the
Munich Database Meetup. In May, <a href="https://twitter.com/thegeeknarrator">Kaivalya
Apte</a> and <a href="https://twitter.com/mgill25">Manish
Gill</a> started the Berlin Systems Group,
inspired by Alex and the Munich Database Meetup.</p>
<blockquote>— Kaivalya Apte - The Geek Narrator (@thegeeknarrator) <a href="https://twitter.com/thegeeknarrator/status/1790782561515372676?ref_src=twsrc%5Etfw">May 15, 2024</a></blockquote> 
<p>In May 2024, two PhD students in the San Francisco Bay Area, <a href="https://x.com/ShadajL">Shadaj
Laddad</a> and <a href="https://x.com/conor_power23">Conor
Power</a>, started the SF Distributed
Systems meetup.</p>
<blockquote><p lang="en" dir="ltr">We’re super excited to be organizing a new SF Distributed Systems meetup NEXT WEEK! Our first meetup features <a href="https://twitter.com/julianhyde?ref_src=twsrc%5Etfw">@julianhyde</a> and <a href="https://twitter.com/conor_power23?ref_src=twsrc%5Etfw">@conor_power23</a> presenting work on extending SQL and applying algebraic properties, sign up at <a href="https://t.co/d2lLDaQ5iJ">https://t.co/d2lLDaQ5iJ</a></p>— Shadaj Laddad (@ShadajL) <a href="https://twitter.com/ShadajL/status/1790767187327889456?ref_src=twsrc%5Etfw">May 15, 2024</a></blockquote> 
<p>And in July 2024, <a href="https://twitter.com/shraddhaag">Shraddha Agrawal</a>,
<a href="https://twitter.com/anirudhRowjee">Anirudh Rowjee</a> and friends kicked
off the first Bengaluru Systems Meetup.</p>
<blockquote><div lang="en" dir="ltr"><p>Are you ready, Systems Enthusiasts of Bengaluru?</p><p>Speaking at our first-ever meetup on 6th July, we have:<a href="https://twitter.com/simsimsandy?ref_src=twsrc%5Etfw">@simsimsandy</a> with "Learn about the systems that power GenAI applications" and <a href="https://twitter.com/vivekgalatage?ref_src=twsrc%5Etfw">@vivekgalatage</a> with "The Browser Backstage: Performance vs Security" <br>(talks linked below!)</p></div>— Bengaluru Systems Meetup (@BengaluruSys) <a href="https://twitter.com/BengaluruSys/status/1808949578307183060?ref_src=twsrc%5Etfw">July 4, 2024</a></blockquote> 
<h3 id="suggestions">Suggestions</h3><p>First off, don't pay for anything yourself. Find a company who will
host. At the same time, don't feel the need to give in too much to the
demands of the company. I'd be happy to help you think through how to
talk about the event with companies. It is mutually beneficial for
them to get to give a 5-minute hiring/product pitch and not need to do
extensive branding nor to give a 30-minute product tutorial.</p>
<p>Second, keep a bit of pressure on speakers to not do an overview talk
and not to do a product pitch. Suggest that they tell the story of
some interesting recent bug or interesting recent feature. What
happened? Why was it hard? What did you learn?</p>
<p>Focusing on these types of talks will help you get a really
interesting audience.</p>
<p>I have been continuously surprised and impressed at the folks who show
up for NYC Systems. It's a mix of technical founders in the systems
space, pretty experienced developers in the systems space, graduate
students, and developers of all sorts.</p>
<p>I am certain we can only get these kinds of folks to show up because
we avoid product pitch-type talks.</p>
<p>Third, finding speakers is still hard! The best approach so far has
been to individually message folks in industry and academia who hang
out on Twitter. Sending out a public call is easy but doesn't often
pan out. So keep an eye on interesting companies in the area.</p>
<p>Another avenue I've been thinking about is messaging VC connections to
ask them if they know any engineers/technical founders/CTOs in the
area who could give an interesting technical talk.</p>
<p>Fourth, speak with other organizers! I finally met Alex Petrov in
person last month and we had a <a href="https://twitter.com/ifesdjeen/status/1806677549038063901">great
time</a>
talking about the challenges and joys of organizing really high
quality meetups.</p>
<p>I'm always happy to chat, DMs are open.</p>
<blockquote><p lang="en" dir="ltr">New post telling a bit of the history behind <a href="https://t.co/NEh1tm8v3Q">https://t.co/NEh1tm8v3Q</a>; why it only exists due to folks like <a href="https://twitter.com/georg_kreuzmayr?ref_src=twsrc%5Etfw">@georg_kreuzmayr</a> and <a href="https://twitter.com/ngeloxyz?ref_src=twsrc%5Etfw">@ngeloxyz</a>; the explosion of systems meetups around the world; and encouragement and suggestions for future organizers!<a href="https://t.co/dwe4TtmXKK">https://t.co/dwe4TtmXKK</a> <a href="https://t.co/ZMLkVYdZDJ">pic.twitter.com/ZMLkVYdZDJ</a></p>— Phil Eaton (@eatonphil) <a href="https://twitter.com/eatonphil/status/1809934997442498812?ref_src=twsrc%5Etfw">July 7, 2024</a></blockquote> 

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube embeds are bananas heavy and it’s fixable (211 pts)]]></title>
            <link>https://frontendmasters.com/blog/youtube-embeds-are-bananas-heavy-and-its-fixable/</link>
            <guid>40897205</guid>
            <pubDate>Sun, 07 Jul 2024 12:37:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frontendmasters.com/blog/youtube-embeds-are-bananas-heavy-and-its-fixable/">https://frontendmasters.com/blog/youtube-embeds-are-bananas-heavy-and-its-fixable/</a>, See on <a href="https://news.ycombinator.com/item?id=40897205">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<p>TL;DR: YouTube Embeds are like 1.3MB in size with no shared resources between multiple embeds. Using a <a href="https://github.com/paulirish/lite-youtube-embed">&lt;lite-youtube&gt;</a> Web Component is more like 100k, <em>does</em> share resources, and sacrifices no functionality.  </p>



<p>You can put a YouTube video on any website. They help you do it. Under the <strong>Share </strong>menu right on youtube.com there is an option to <strong>&lt;&gt; Embed</strong> and you’ll see bit of HTML with an <code>&lt;iframe&gt;</code> in it. </p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="429" src="https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=1024%2C429&amp;ssl=1" alt="" srcset="https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=1024%2C429&amp;ssl=1 1024w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=300%2C126&amp;ssl=1 300w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=768%2C322&amp;ssl=1 768w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=1536%2C643&amp;ssl=1 1536w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/06/CleanShot-2024-06-30-at-09.12.30@2x.png?resize=2048%2C858&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>&lt;iframe&gt;s are never wonderful for performance, but they make sense for protected third-party content.</figcaption></figure>



<p>This is what I’m getting as I write:</p>


<pre aria-describedby="shcb-language-1" data-shcb-language-name="HTML, XML" data-shcb-language-slug="xml"><span><code><span>&lt;<span>iframe</span> 
  <span>width</span>=<span>"560"</span> 
  <span>height</span>=<span>"315"</span> 
  <span>src</span>=<span>"https://www.youtube.com/embed/LN1TQm942_U?si=EfW_M4bEHEO-idL3"</span>
  <span>title</span>=<span>"YouTube video player"</span>
  <span>frameborder</span>=<span>"0"</span>
  <span>allow</span>=<span>"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"</span>
  <span>referrerpolicy</span>=<span>"strict-origin-when-cross-origin"</span>
  <span>allowfullscreen</span>&gt;</span>
<span>&lt;/<span>iframe</span>&gt;</span></code></span><small id="shcb-language-1"><span>Code language:</span> <span>HTML, XML</span> <span>(</span><span>xml</span><span>)</span></small></pre>


<p>If I were Team YouTube, I’d get <code>loading="lazy"</code> on there to help with performance right away. No need for videos that aren’t even visible on the page to load right away. </p>


<pre aria-describedby="shcb-language-2" data-shcb-language-name="HTML, XML" data-shcb-language-slug="xml"><span><code><span><span><span>&lt;<span>iframe</span> </span>
</span></span><span><span><span>  <span>...</span></span>
</span></span><mark><span><span>  <span>loading</span>=<span>"lazy"</span></span>
</span></mark><span><span><span>  &gt;</span>
</span></span><span><span><span>&lt;/<span>iframe</span>&gt;</span>
</span></span></code></span><small id="shcb-language-2"><span>Code language:</span> <span>HTML, XML</span> <span>(</span><span>xml</span><span>)</span></small></pre>


<p>Plus I’d put some inline styles on there to keep the video fluid and maintain the original aspect ratio. Or you could target these and do that yourself in CSS. Here’s assuming the videos are the standard 16 / 9 aspect ratio:</p>


<pre aria-describedby="shcb-language-3" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>iframe</span><span>[src^=<span>"https://www.youtube.com/embed/"</span>]</span> {
  <span>inline-size</span>: <span>100%</span>;
  <span>block-size</span>: auto;
  <span>aspect-ratio</span>: <span>16</span> / <span>9</span>;
}</code></span><small id="shcb-language-3"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>


<p>But… let’s not keep this HTML at all. I’m sure you read this blog post title, but let’s put a point on it:</p>



<figure><img decoding="async" width="952" height="1024" src="https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/07/CleanShot-2024-07-01-at-07.04.34@2x.png?resize=952%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/07/CleanShot-2024-07-01-at-07.04.34@2x.png?resize=952%2C1024&amp;ssl=1 952w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/07/CleanShot-2024-07-01-at-07.04.34@2x.png?resize=279%2C300&amp;ssl=1 279w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/07/CleanShot-2024-07-01-at-07.04.34@2x.png?resize=768%2C826&amp;ssl=1 768w, https://i0.wp.com/frontendmasters.com/blog/wp-content/uploads/2024/07/CleanShot-2024-07-01-at-07.04.34@2x.png?w=1392&amp;ssl=1 1392w" sizes="(max-width: 952px) 100vw, 952px" data-recalc-dims="1"></figure>



<p>On a page with literally <em>nothing at all on it</em> other than a YouTube Embed, we’re looking at:</p>



<ul>
<li>32 requests</li>



<li>1.3 MB of data transfer</li>



<li>2.76s to load the page on my current WiFi connection</li>
</ul>



<p><a href="https://www.zachleat.com/web/youtube-embeds/">Zach Leatherman, equally exasperated by this</a>, noted:</p>



<blockquote>
<p>The weight also grows linearly with every embed—resources are&nbsp;<em>not</em>&nbsp;shared: two embeds weigh 2.4 MB; three embeds weigh 3.6 MB (you get the idea).</p>
</blockquote>



<p>Wow.</p>



<p>Looks like sizes are up a bit since Zach last looked as well.</p>



<h2 id="toc-1">The Appearance &amp; Functionality</h2>



<p>This is what you get from a YouTube Embed:</p>



<ul>
<li>You see a “poster” image of the video</li>



<li>You see the title of the video </li>



<li>You see a big play button — click it to play the video</li>
</ul>



<p>This is very little UI and functionality, which is fine! We can absolutely do all this without this many resources.</p>



<h2 id="toc-2">Why is it this way? 🤷‍♀️</h2>



<p>I don’t think we have any good answers here. In fact, I heard from a little birdie who ran it up the pole that they have tested lighter embeds and <em>found them to reduce engagement</em>. 😭</p>



<p>I’m just gonna straight up say I don’t believe it. It’s like when Google told us that taking up half the screen with AI generated answers led to people clicking on third-party results <em>more</em>, but then refused to show data or allow us to track those clicks ourselves.</p>



<p>And hey — sometimes there are unexpected results in testing. That’s why we test instead of guess. But because this is <em>so</em> counterintuitive and offtrack for so many other similar performance testing situations, this bears deeper scrutiny. It would benefit from an opening of the methodology and data. </p>



<p>Like if you tell me that if you hit people with a stick and they smile more, I’m gonna want you to stop until we can look at what’s going on there.</p>



<p>I <em>really</em> wish I could find a good link for this, but there is a famous story from YouTube engineers way-back-when who made a much lighter video page and put it into testing. They found, quite counterintuitively, that average page load times went <em>up.</em> But with a deeper look, they found that the lighter page was able to <em>reach more people, including people on low-power low-internet-speed devices</em> who were able to actually use YouTube for the first time, and them using it much more slowed those averages. That’s awesome! The speed of using the site was up <em>relatively</em> for everyone. The metric of the average page load speed was a red herring and ultimately not meaningful.</p>



<p>How do we know that’s not the same kind of thing happening here?</p>



<p>Remember the implications of all these resources isn’t just a little inconvenience. YouTube is so enormous we’re talking incredible amounts of wasted electricity and thus carbon output. Pulling a megabyte of data off every single YouTube Embed would be an incredible win all around. I might even say <em>not</em> improving this is environmentally negligent.</p>



<h2 id="toc-3">The Solution is to Replicate the Embed Experience Another Way. There are Open Source Web Components That Do It Well.</h2>



<p>With a little dab of irony, Google’s own performance champion Paul Irish has had a web component doing just this for years and years and years:</p>



<p><a href="https://github.com/paulirish/lite-youtube-embed">lite-youtube-embed</a></p>



<p>The pitch is solid:</p>



<blockquote>
<p>Provide videos with a supercharged focus on visual performance. This custom element renders just like the real thing but approximately 224× faster.</p>
</blockquote>



<p><strong>Two hundred and twenty four</strong> times faster. Which of course involves much less data transfer.</p>



<p>And I’d like to be very clear, also does the exact same thing as the default embed:</p>



<ul>
<li>You see a “poster” image of the video</li>



<li>You see the title of the video </li>



<li>You see a big play button — click it to play the video</li>
</ul>



<p>You lose nothing and gain tons of speed, efficiency, and default privacy.</p>



<h2 id="toc-4">Using Lite YouTube Embed</h2>



<ol>
<li>Link up the JavaScript to instantiate the Web Component</li>



<li>Use it</li>
</ol>



<p>You could install it from npm or copy and paste a copy into your own project or whatever. Or link it from a CDN:</p>


<pre aria-describedby="shcb-language-4" data-shcb-language-name="JavaScript" data-shcb-language-slug="javascript"><span><code><span>import</span> <span>"https://esm.sh/lite-youtube-embed"</span>;</code></span><small id="shcb-language-4"><span>Code language:</span> <span>JavaScript</span> <span>(</span><span>javascript</span><span>)</span></small></pre>


<p>That’s like this:</p>







<p>But the best way to use it is right in the README:</p>



<blockquote>
<p>Use this as your HTML, load the script asynchronously, and let the JS progressively enhance it.</p>
</blockquote>


<pre aria-describedby="shcb-language-5" data-shcb-language-name="HTML, XML" data-shcb-language-slug="xml"><span><code><span>&lt;<span>script</span> <span>defer</span> <span>src</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/lite-youtube-embed/0.3.2/lite-yt-embed.js"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>

<span>&lt;<span>link</span> <span>rel</span>=<span>"stylesheet"</span> <span>href</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/lite-youtube-embed/0.3.2/lite-yt-embed.css"</span> <span>integrity</span>=<span>"sha512-utq8YFW0J2abvPCECXM0zfICnIVpbEpW4lI5gl01cdJu+Ct3W6GQMszVITXMtBLJunnaTp6bbzk5pheKX2XuXQ=="</span> <span>crossorigin</span>=<span>"anonymous"</span> <span>referrerpolicy</span>=<span>"no-referrer"</span> /&gt;</span>

<span>&lt;<span>lite-youtube</span> <span>videoid</span>=<span>"ogfYd705cRs"</span> <span>style</span>=<span>"background-image: url('https://i.ytimg.com/vi/ogfYd705cRs/hqdefault.jpg');"</span>&gt;</span>
  <span>&lt;<span>a</span> <span>href</span>=<span>"https://youtube.com/watch?v=ogfYd705cRs"</span> <span>class</span>=<span>"lty-playbtn"</span> <span>title</span>=<span>"Play Video"</span>&gt;</span>
    <span>&lt;<span>span</span> <span>class</span>=<span>"lyt-visually-hidden"</span>&gt;</span>Play Video: Keynote (Google I/O '18)<span>&lt;/<span>span</span>&gt;</span>
  <span>&lt;/<span>a</span>&gt;</span>
<span>&lt;/<span>lite-youtube</span>&gt;</span></code></span><small id="shcb-language-5"><span>Code language:</span> <span>HTML, XML</span> <span>(</span><span>xml</span><span>)</span></small></pre>


<p>With async loaded JavaScript, note the <code>background-image</code> is put into the HTML so it can all look right before the JavaScript loads. </p>







<h2 id="toc-5">Alternatives</h2>



<ul>
<li><a href="https://github.com/justinribeiro/lite-youtube">Shadow DOM version</a> (more protected styling, more annoying to style)</li>



<li>Do it yourself
<ul>
<li>Raymond Camden: <a href="https://www.raymondcamden.com/2022/11/17/building-a-youtube-embed-web-component-both-vanilla-and-webc-flavored">Building a YouTube Embed Web Component (both vanilla and WebC flavored)</a></li>



<li>Adrian Roselli: <a href="https://adrianroselli.com/2024/06/youtube-and-vimeo-web-component.html">YouTube and Vimeo Web Component</a></li>
</ul>
</li>



<li>Mux: <code><a href="https://github.com/muxinc/media-elements/tree/main/packages/youtube-video-element">&lt;youtube-video&gt;</a></code> (matches <code>&lt;video&gt;</code> DOM APIs)</li>



<li><a href="https://github.com/ibrahimcesar/react-lite-youtube-embed">React Port</a> &amp; <a href="https://github.com/vercel/next.js/tree/canary/packages/third-parties#youtube-embed">Next.js Official Version</a></li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Malloc broke Serenity's JPGLoader, or: how to win the lottery (2021) (167 pts)]]></title>
            <link>https://sin-ack.github.io/posts/jpg-loader-bork/</link>
            <guid>40896102</guid>
            <pubDate>Sun, 07 Jul 2024 08:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sin-ack.github.io/posts/jpg-loader-bork/">https://sin-ack.github.io/posts/jpg-loader-bork/</a>, See on <a href="https://news.ycombinator.com/item?id=40896102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I got the chance to investigate an interesting bug in
<a href="https://serenityos.org/">SerenityOS</a> this week. It was related to the decoding
of JPG images in the operating system. For some reason, when a JPG image is
viewed, it comes out like this:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/lenna-broken.png" alt="Lenna,
showing up with incorrect colors."><figcaption>
            <p>Lenna,
showing up with incorrect colors.</p>
        </figcaption>
</figure>

<p>Weird, huh? Also seems like a simple confusion of RGB vs. BGR. And sure enough,
making the following change on <code>JPGLoader.cpp</code>:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span><span>-   const Color color { (u8)block.y[pixel_index], (u8)block.cb[pixel_index], (u8)block.cr[pixel_index] };
</span></span></span><span><span><span></span><span>+   const Color color { (u8)block.cr[pixel_index], (u8)block.cb[pixel_index], (u8)block.y[pixel_index] };
</span></span></span><span><span><span></span>    context.bitmap-&gt;set_pixel(x, y, color);
</span></span></code></pre></div><p>makes the image show up correctly. Case closed!</p>
<p>…not. Why did this even break in the first place?</p>
<p>The last non-reverted change
to <code>JPGLoader.cpp</code> is reported by Git to be over a month ago:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/commitlog.png" alt="Commit log
at the time of JPGLoader being broken."><figcaption>
            <p>Commit log
at the time of JPGLoader being broken.</p>
        </figcaption>
</figure>

<p>And I remembered very well that JPG images worked just fine about a week or two
ago, as I had set a JPG image as my background and would’ve noticed if it looked
wrong.</p>
<p>Well, time to bisect! I didn’t know when to start, so I picked the last 1000
commits (where images showed up correctly), and started bisecting.</p>
<h2 id="bisect-hell">Bisect hell</h2>
<p>Please skip to the next section if you’d like to avoid C++ whining.</p>
<p>SerenityOS, being an operating system project that focuses on doing its own
thing, also has its own standard library called AK (which stands for
<span title="Andreas Kling">Agnostic Kit</span>).
This library is analogous to
C++’s STL, but is more readable due to not having to support a myriad of
different operating systems and not having to contort oneself to conform to
<a href="https://www.gnu.org/prep/standards/">hideous coding standards</a>.</p>
<p>One of the nice things about having the standard library in the same repository
as its users is that making changes is very easy as the change propagates to
everyone who pulls from master. However, this is a double edged sword when it
comes to C++; because <em>everyone</em> includes the standard library (even if you
don’t include it, your includes will), and because C++’s template system means
that everything that’s templated has to include the definitions in the header as
well, this means that <em>anytime</em> someone touches AK in a commit, the <em>entire</em>
operating system has to be rebuilt (~3400 files at the time of writing).
<code>ccache</code>, while being useful in many situations, cannot handle this case.
Additionally, due to the breakneck pace of the SerenityOS project, someone ends
up touching AK at least once every 100 commits or so.</p>
<p>As a result, during the 1000 commits I ended up bisecting for, I had to build
SerenityOS from scratch about 4-5 times on a 2011 laptop with Sandy Bridge
Mobile. While this isn’t the fault of the project, I’m still mad.</p>
<h2 id="bisect-results">Bisect results</h2>
<p>So, after bisecting 1000 commits, rebuilding the OS from scratch several times
and pulling my hair out because I didn’t understand how bisect worked, I
<em>finally</em> found the commit that broke JPG images. Drumroll please…</p>
<pre tabindex="0"><code>f89e8fb71a4893911ee5125f34bd5bbb99327d33
Author:     Gunnar Beutner
AuthorDate: Sat May 15 10:06:41 2021 +0200

AK+LibC: Implement malloc_good_size() and use it for Vector/HashTable

This implements the macOS API malloc_good_size() which returns the
true allocation size for a given requested allocation size. This
allows us to make use of all the available memory in a malloc chunk.

For example, for a malloc request of 35 bytes our malloc would
internally use a chunk of size 64, however the remaining 29 bytes
would be unused.

Knowing the true allocation size allows us to request more usable
memory that would otherwise be wasted and make that available for
Vector, HashTable and potentially other callers in the future.
</code></pre><p>Uh, sorry, what?</p>
<p>But it was. Building the commit right before this one showed the image
correctly:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/lenna-beforebroken.png" alt="Lenna, before it was broken."><figcaption>
            <p>Lenna, before it was broken.</p>
        </figcaption>
</figure>

<p>Initial discussion with other developers made me think that either <code>JPGLoader</code>
or something else up the chain is depending on the capacity of a <code>Vector</code> and
writing directly into it when it really shouldn’t. So I began hunting down
possible causes.</p>
<h2 id="a-surprising-discovery">A surprising discovery</h2>
<p>The commit seemed to touch the two main container types: <code>HashTable</code> (which
<code>HashMap</code> depends on) and <code>Vector</code>. Both are used in the <code>JPGLoader</code> code, and
either could be the cause of the problem here.</p>
<p>I picked <code>HashTable</code> at random, removed the offending line:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span>         new_capacity = max(new_capacity, static_cast&lt;size_t&gt;(4));
</span></span><span><span><span>-        new_capacity = kmalloc_good_size(new_capacity * sizeof(Bucket)) / sizeof(Bucket);
</span></span></span><span><span><span></span>
</span></span><span><span>         auto* old_buckets = m_buckets;
</span></span></code></pre></div><p>and rebuilt the system, while joking around in chat about how this can’t
possibly be the problem.</p>
<p>…but then it fixed the issue.</p>
<p>What? How? Why does the <code>HashTable</code> capacity being different matter?! <code>HashTable</code>
isn’t even a contiguous stream of data you can write to, so you shouldn’t even
be able to assume its capacity!</p>
<p>Before I present the full story to you, I’ll have give a brief background on how
<code>JPGLoader</code> used to work.</p>
<h2 id="non-deterministic-serial-component-iteration">Non-deterministic serial component iteration</h2>
<p>That’s really the most appropriate title I can give this section.</p>
<p><code>JPGLoader</code> previously would read information about a JPG component from the
“Start of Frame” section of the JPG file into a struct called <code>Component</code>, and
then store that in a <code>HashTable</code>. Of course, the order in a JPG file for each
component should always be <code>Y</code>, <code>Cb</code> and <code>Cr</code>, so the <code>Component</code> struct would
idiosyncratically carry a <code>serial_id</code>, which was the position of the <code>Component</code>
within the file. The reason the <code>Component</code>s were in a hash table was that they
would then be checked against the component ordering in a “Start of Scan”
section to make sure all the components in the SOS section are in the expected
order. Why this code was written this way instead of just checking against the
ID by linearly iterating over the <code>Component</code>s, I have no idea.</p>
<p>Anyway, these components would then be iterated over during the different
decoding stages of <code>JPGLoader</code>, during which the component information would be
used to perform transforms on macroblocks.</p>
<h2 id="getting-close">Getting close</h2>
<p>When I added some debug prints to see how the components were read, I saw this
in the commit with the broken colors:</p>
<pre tabindex="0"><code>ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 1
...
</code></pre><p>And when I checked out the previous commit, I saw this:</p>
<pre tabindex="0"><code>ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 2
...
</code></pre><p>The final piece of the puzzle: During the discussion of this bug with
<a href="https://twitter.com/the_semicolon_">CxByte</a> at my wit’s end, we ended up
manually messing with the order of the components to see what would happen, and
got this message:</p>
<pre tabindex="0"><code>ImageDecoder(32:32): Huffman stream exhausted. This could be an error!
ImageDecoder(32:32): Failed to build Macroblock 3277
</code></pre><p>…ah. Of course. It’s a stream.</p>
<h2 id="the-bug">The bug</h2>
<p>So, here’s a quick rundown of the bug:</p>
<ul>
<li>Someone used a <code>HashTable</code> to store objects that should be ordered, then
iterated over it using the basic <code>HashTable</code> iterator</li>
<li>The hash of the component IDs in the JPG files were passed into <code>int_hash</code>
for hash table bucket selection</li>
<li>Not only did they get <em>just the right value</em> to be in order, they got
inserted into a HashTable with <em>just the right amount</em> of buckets to be in
the correct order</li>
<li>This caused the Huffman stream to be read in the correct order for each
component, thereby masking the bug</li>
<li>This bug was masked since <code>JPGLoader</code>’s inception by sheer luck until someone
messed with the size of the <code>HashTable</code></li>
</ul>
<h2 id="the-fix">The fix</h2>
<p>And finally, at the end of about 10 hours of debugging, <a href="https://github.com/SerenityOS/Serenity/commit/a10ad24c760bfe713f1493e49dff7da16d14bf39">here is the
commit</a>
that fixed this monster of a bug:</p>
<pre tabindex="0"><code>a10ad24c760bfe713f1493e49dff7da16d14bf39
Author:     sin-ack
AuthorDate: Mon May 31 15:22:04 2021 +0000
Commit:     Linus Groh
CommitDate: Mon May 31 17:26:11 2021 +0100

LibGfx: Make JPGLoader iterate components deterministically

JPGLoader used to store component information in a HashTable, indexed
by the ID assigned by the JPEG file.  This was fine for most purposes,
however after f89e8fb7 this was revealed to be a flawed implementation
which causes non-deterministic iteration over components.

This issue was previously masked by a perfect storm of int_hash being
stable for the integer values 0, 1 and 2; and AK::HashTable having just
the right amount of buckets for the components to be ordered correctly
after being hashed with int_hash. However, after f89e8fb7,
malloc_good_size was used for determining the amount of space for
allocation; this caused the ordering of the components to change, and
images started showing up with the red and blue channels reversed. The
issue was finally determined to be inconsistent ordering after randomly
changing the order of the components caused Huffman decoding to fail.

This was the result of about 10 hours of hair-pulling and repeatedly
doing full rebuilds due to bisecting between commits that touched AK.
Gunnar, I like you, but please don't make me go through this again. :^)

Credits to Andrew Kaster, bgianf, CxByte and Gunnar for the debugging
help.
</code></pre><h2 id="final-thoughts">Final thoughts</h2>
<p>Sometimes the simplest problems might point at big mistakes within. I could’ve
probably fixed this by just swapping the order of the arguments right then and
there, and it would’ve worked; until someone else came along and changed the
order again. Thankfully, now we will be able to look at tubas with correct
colors in peace.</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/tuba.png" alt="A tuba with the
correct colors. Source: music123.com"><figcaption>
            <p>A tuba with the
correct colors. Source: music123.com</p>
        </figcaption>
</figure>

<h2 id="thanks">Thanks</h2>
<p>Thanks to CxByte, Gunnar, Andrew and Brian for their help with debugging this,
and their helpful tips. Gunnar in particular was the one who uncovered this bug,
and despite my satirical jab in the commit message helped uncover this very
interesting bug, so he’s the one who made this post possible.</p>
<p>Also, thanks to the person who introduced this bug (the commit log gets a little
fuzzy, so I’m not quite sure who did) and hope he buys a lottery ticket. :^)</p>
<p>And thank you for reading. I’ll probably post sometime in the future, but work’s
been keeping me busy. But maybe I’ll find another bug to suck me into a rabbit
hole. Stay tuned!</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From the Transistor to the Web Browser, a rough outline for a 12 week course (102 pts)]]></title>
            <link>https://github.com/geohot/fromthetransistor</link>
            <guid>40895935</guid>
            <pubDate>Sun, 07 Jul 2024 07:54:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/geohot/fromthetransistor">https://github.com/geohot/fromthetransistor</a>, See on <a href="https://news.ycombinator.com/item?id=40895935">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">From the Transistor to the Web Browser</h2><a id="user-content-from-the-transistor-to-the-web-browser" aria-label="Permalink: From the Transistor to the Web Browser" href="#from-the-transistor-to-the-web-browser"></a></p>
<p dir="auto">Hiring is hard, a lot of modern CS education is really bad, and it's hard to find people who understand the modern computer stack from first principles.</p>
<p dir="auto">Now cleaned up and going to be software only. Closer to being real.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 1: Intro: Cheating our way past the transistor -- 0.5 weeks</h4><a id="user-content-section-1-intro-cheating-our-way-past-the-transistor----05-weeks" aria-label="Permalink: Section 1: Intro: Cheating our way past the transistor -- 0.5 weeks" href="#section-1-intro-cheating-our-way-past-the-transistor----05-weeks"></a></p>
<ul dir="auto">
<li>So about those transistors -- Course overview. Describe how FPGAs are buildable using transistors, and that ICs are just collections of transistors in a nice reliable package. Understand the LUTs and stuff. Talk briefly about the theory of transistors, but all projects must build on each other so we can’t build one.</li>
<li>Emulation -- Building on real hardware limits the reach of this course. Using something like Verilator will allow anyone with a computer to play.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 2: Bringup: What language is hardware coded in? -- 0.5 weeks</h4><a id="user-content-section-2-bringup-what-language-is-hardware-coded-in----05-weeks" aria-label="Permalink: Section 2: Bringup: What language is hardware coded in? -- 0.5 weeks" href="#section-2-bringup-what-language-is-hardware-coded-in----05-weeks"></a></p>
<ul dir="auto">
<li>Blinking an LED(Verilog, 10) -- Your first little program! Getting the simulator working. Learning Verilog.</li>
<li>Building a UART(Verilog, 100) -- An intro chapter to Verilog, copy a real UART, introducing the concept of MMIO, though the serial port may be semihosting. Serial test echo program and led control.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 3: Processor: What is a processor anyway? -- 3 weeks</h4><a id="user-content-section-3-processor-what-is-a-processor-anyway----3-weeks" aria-label="Permalink: Section 3: Processor: What is a processor anyway? -- 3 weeks" href="#section-3-processor-what-is-a-processor-anyway----3-weeks"></a></p>
<ul dir="auto">
<li>Coding an assembler(Python, 500) -- Straightforward and boring, write in python. Happens in parallel with the CPU building. Teaches you ARM assembly. Initially outputs just binary files, but changed when you write a linker.</li>
<li>Building a ARM7 CPU(Verilog, 1500) -- Break this into subchapters. A simple pipeline to start, decode, fetch, execute. How much BRAM do we have? We need at least 1MB, DDR would be hard I think, maybe an SRAM. Simulatable and synthesizable.</li>
<li>Coding a bootrom(Assembler, 40) -- This allows code download into RAM over the serial port, and is baked into the FPGA image. Cute test programs run on this.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 4: Compiler: A “high” level language -- 3 weeks</h4><a id="user-content-section-4-compiler-a-high-level-language----3-weeks" aria-label="Permalink: Section 4: Compiler: A “high” level language -- 3 weeks" href="#section-4-compiler-a-high-level-language----3-weeks"></a></p>
<ul dir="auto">
<li>Building a C compiler(Haskell, 2000) -- A bit more interesting, cover the basics of compiler design. Write in haskell. Write a parser. Break this into subchapters. Outputs ARM assembly.</li>
<li>Building a linker(Python, 300) -- If you are clever, this should take a day. Output elf files. Use for testing with QEMU, semihosting.</li>
<li>libc + malloc(C, 500) -- The gateway to more complicated programs. libc is only half here, things like memcpy and memset and printf, but no syscall wrappers.</li>
<li>Building an ethernet controller(Verilog, 200) -- Talk to a real PHY, consider carefully MMIO design.</li>
<li>Writing a bootloader(C, 300) -- Write ethernet program to boot kernel over UDP. First thing written in C. Maybe don’t redownload over serial each time and embed in FPGA image.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 5: Operating System: Software we take for granted -- 3 weeks</h4><a id="user-content-section-5-operating-system-software-we-take-for-granted----3-weeks" aria-label="Permalink: Section 5: Operating System: Software we take for granted -- 3 weeks" href="#section-5-operating-system-software-we-take-for-granted----3-weeks"></a></p>
<ul dir="auto">
<li>Building an MMU(Verilog, 1000) -- ARM9ish, explain TLBs and other fun things. Maybe also a memory controller, depending on how the FPGA is, then add the init code to your bootloader.</li>
<li>Building an operating system(C, 2500) -- UNIXish, only user space threads. (open, read, write, close), (fork, execve, wait, sleep, exit), (mmap, munmap, mprotect). Consider the debug interface you are using, ranging from printf to perhaps a gdbremote stub into kernel. Break into subchapters.</li>
<li>Talking to an SD card(Verilog, 150) -- The last hardware you have to do. And a driver</li>
<li>FAT(C, 300) -- A real filesystem, I think fat is the simplest</li>
<li>init, shell, download, cat, ls, rm(C, 250) -- Your first user space programs.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 6: Browser: Coming online -- 1 week</h4><a id="user-content-section-6-browser-coming-online----1-week" aria-label="Permalink: Section 6: Browser: Coming online -- 1 week" href="#section-6-browser-coming-online----1-week"></a></p>
<ul dir="auto">
<li>Building a TCP stack(C, 500) -- Probably coded in the kernel, integrate the ethernet driver into the kernel. Add support for networking syscalls to kernel. (send, recv, bind, connect)</li>
<li>telnetd, the power of being multiprocess(C, 50) --  Written in C, user can connect multiple times with telnet. Really just a bind shell.</li>
<li>Space saving dynamic linking(C, 300) -- Because we can, explain how dynamic linker is just a user space program. Changes to linker required.</li>
<li>So about that web(C, 500+) -- A “nice” text based web browser, using ANSI and terminal niceness. Dynamically linked and nice, nice as you want.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Section 7: Physical: Running on real hardware -- 1 week</h4><a id="user-content-section-7-physical-running-on-real-hardware----1-week" aria-label="Permalink: Section 7: Physical: Running on real hardware -- 1 week" href="#section-7-physical-running-on-real-hardware----1-week"></a></p>
<ul dir="auto">
<li>Talking to an FPGA(C, 200) -- A little code for the USB MCU to bitbang JTAG.</li>
<li>Building an FPGA board -- Board design, FPGA BGA reflow, FPGA flash, a 50mhz clock, a USB JTAG port and flasher(no special hardware, a little cypress usb mcu to do jtag), a few leds, a reset button, a serial port(USB-FTDI) also powering via USB, an sd card, expansion connector(ide cable?), and an ethernet port. Optional, expansion board, host USB port, NTSC TV out, an ISA port, and PS/2 connector on the board to taunt you. We provide a toaster oven and a multimeter thermometer to do reflow.</li>
<li>Bringup -- Compiling and downloading the Verilog for the board</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: BeaconDB – An Alternative to Mozilla Location Services (161 pts)]]></title>
            <link>https://beacondb.net/</link>
            <guid>40895672</guid>
            <pubDate>Sun, 07 Jul 2024 06:25:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://beacondb.net/">https://beacondb.net/</a>, See on <a href="https://news.ycombinator.com/item?id=40895672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <ul> <li><b>ethically sourced</b>: opt-in only data collection</li> <li><b>privacy friendly</b>: published information is obfuscated to protect transmitters and contributors</li> <li> <b>abuse resistant</b>: updating existing data requires information
          only available in physical range of a beacon
</li> </ul> <h2>contribute</h2> <p>
beaconDB has recently started to accept submissions. to add coverage for your area you
        can use the following apps on your phone:
</p> <ul> <li> <a href="https://github.com/mjaakko/NeoStumbler">NeoStumbler</a>:
          supports cell towers, wifi networks and bluetooth devices
<ul> <li> <a href="https://f-droid.org/packages/xyz.malkki.neostumbler.fdroid/">download on F-Droid</a> </li> <li>
in the Settings tab, set the endpoint to <code>https://beacondb.net</code> </li> </ul> </li> <li> <a href="https://github.com/zamojski/TowerCollector">Tower Collector</a>: only supports cell towers
<ul> <li> <a href="https://f-droid.org/packages/info.zamojski.soft.towercollector/">download on F-Droid</a>
or
<a href="https://play.google.com/store/apps/details?id=info.zamojski.soft.towercollector">Google Play</a> </li> <li>
in Upload Preferences, enable support for custom MLS services and
              set the address to <code>https://beacondb.net/v2/geosubmit</code> </li> </ul> </li> </ul> <p>
data you submit will be aggregated and shared under a public domain
        license. for more information on how your data is handled, see the
<a href="https://beacondb.net/privacy">privacy notice</a>.
</p> <h2>usage</h2> <p> <b>
beaconDB is experimental and should not be used by critical services
</b> </p> <p>
if you own an Android phone running the latest preview version of <a href="https://microg.org/">microG</a>, you can easily give beaconDB a spin without needing to install
        anything. in microG Settings on the Location page, pressing the three
        dots in the top right lets you set a custom service URL. you can set
        this to <code>https://beacondb.net/</code> to give beaconDB a try.
</p> <p>
as beaconDB is starting from scratch there is likely no wifi coverage
        for your area. if beaconDB can't estimate your location using wifi, it
        will fallback to an approximate cell tower location sourced from MLS'
        final data dump. note that submissions will take at least 5 minutes to
        become available in the beaconDB API.
</p> <h2>developers</h2> <p>
beaconDB hosts an endpoint at
<code>https://beacondb.net/v1/geolocate</code> which is compatible with <a href="https://ichnaea.readthedocs.io/en/latest/api/geolocate.html">Ichnaea's request format</a>. if your software has a large amount of users, please don't use this
        as a default location service. beaconDB infrastructure is not yet
        capable of handling a large amount of requests.
</p> <p>
data dumps are currently not available as I'm still researching the
        measures I need to take to protect the privacy of both contributors and
        AP owners.
</p> <hr> <ul> <li>
source code <a href="https://codeberg.org/beacondb/beacondb">on Codeberg</a> </li> <li>
chat <a href="https://matrix.to/#/#_oftc_#beacondb:matrix.org">on Matrix</a>
and <a href="irc://irc.oftc.net/#beacondb">IRC</a> </li> <li> <a href="https://codeberg.org/beacondb/beacondb/issues">bug tracker</a> </li> <li><a href="https://beacondb.net/privacy">privacy notice</a></li> <li>made by <a href="https://joel.net.au/">Joel Koen</a></li> </ul> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Out of Band" network management is not trivial (101 pts)]]></title>
            <link>https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OutOfBandManagementNotTrivial</link>
            <guid>40895167</guid>
            <pubDate>Sun, 07 Jul 2024 04:00:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OutOfBandManagementNotTrivial">https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OutOfBandManagementNotTrivial</a>, See on <a href="https://news.ycombinator.com/item?id=40895167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>"Out of band" network management is not trivial</h2>

	<p><small>July  6, 2024</small></p>
</div><div><p>One of the Canadian news items of the time interval is that <a href="https://crtc.gc.ca/eng/publications/reports/xona2024.htm">a
summary of the official report on the 2022 Rogers Internet and phone
outage has been released</a> (see
also the <a href="https://www.cbc.ca/news/politics/rogers-outage-human-error-system-deficiencies-1.7255641">CBC summary of the summary</a>,
and the <a href="https://en.wikipedia.org/wiki/2022_Rogers_Communications_outage">Wikipedia page on the outage</a>). This
was an extremely major outage that took down both Internet and phone
service for a lot of people for roughly a day and caused a series
of failures in services and systems that turned out to rely on
Rogers for (enough of) their phone and Internet connectivity. In
the wake of the report, some people are (correctly) pointing to
Rogers not having any <a href="https://en.wikipedia.org/wiki/Out-of-band_management">"Out of Band" network management</a> capability
as one of the major contributing factors. Some people have gone so
far as to suggest that out of band network management is an obvious
thing that everyone should have. As it happens I have some opinions
on this, and the capsule summary is that out of band network
management is non-trivial.</p>

<p>(While the outage 'only' cut off an estimated 12 million people,
the total population of Canada is about 40 million people, so it
directly affected more than one in four Canadians.)</p>

<p>Obviously, doing out of band network management means that you need
a dedicated set of physical hardware for your OOB network; separate
switches, routers, local network cabling, and long distance fiber
runs between locations (whether that is nearby university buildings
or different cities). If you're serious, you probably want your OOB
fiber runs to have different physical paths than your regular network
fiber, so one backhoe accident can't cut both of them. This separate
network infrastructure has to run to everything you want to manage
and also to everywhere you want to manage your network from. This
is potentially a lot of physical hardware and networking, and as
they say it can get worse.</p>

<p>(This out of band network also absolutely has to be secure, because
it's a back door to your entire network.)</p>

<p>When you set up OOB network management, you have a choice to make;
is your OOB network the only way to manage equipment, or can you
manage equipment either 'in-band' through your regular network or
through the out of band network. If your OOB network is your only
way of managing things, you not only have to build a separate
network, you have to make sure it is fully redundant, because
otherwise you've created a single point of failure for (some)
management. If your OOB network is a backup, you don't necessarily
need as much redundancy (although you may want some), but now you
need to actively monitor and verify that both access paths work.
You also have two access paths to keep secure, instead of just one.</p>

<p>Security or rather access authentication is another complication
for out of band management networks. If you need your OOB network,
you have to assume that all other networks aren't working, which
means that everything your network routers, switches, and so on
need to authenticate your access has to be accessible through the
OOB management network (possibly in addition to through your regular
networks, if you also have in-band management). This may not be
trivial to arrange, depending on what sort of authentication system
you're using. You also need to make sure that your overall
authentication flow can complete using only OOB network information
and services (so, for example, your authentication server can't
reach out to a third party provider's MFA service to send push
notifications to <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MFABasicOptionsIn2023">authentication apps</a>
on people's phones).</p>

<p>Locally, <a href="https://support.cs.toronto.edu/">we</a> have what I would
describe as a discount out of band management network. It has a
completely separate set of switches, cabling, and building to
building fiber runs, and some things have their management interfaces
on it. It doesn't have any redundancy, which is acceptable in our
particular environment. Unfortunately, because it's a completely
isolated network, it can be a bit awkward to use, especially if you
want to put a device on it that would appreciate modern conveniences
like the ability to send alert emails if something happens (or even
send syslog messages to a remote server; currently <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/CentralizeSyslog">our central
syslog server</a> isn't on this network, although
we should probably fix that).</p>

<p>In many cases I think you're better off having redundant and and
hardened in-band management, especially with smaller networks.
Running an out of band network is effectively having two separate
networks to look after instead of just one; if you have limited
resources (including time and attention), I think you're further
ahead focusing on making a single network solid and redundant rather
than splitting your efforts.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A free minimalist daily habit tracker (110 pts)]]></title>
            <link>https://rdht.vercel.app/</link>
            <guid>40893866</guid>
            <pubDate>Sat, 06 Jul 2024 22:37:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rdht.vercel.app/">https://rdht.vercel.app/</a>, See on <a href="https://news.ycombinator.com/item?id=40893866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><div><p>Offline use</p></div><p>You can use this app fully offline for as long as you want!</p></div><div><div><p>Streaks</p></div><p>Track your streaks for each habit. Along with your completions and longest streaks</p></div><div><div><p>Pausing</p></div><p>Need a break? Pause the app and come back to pick up right where you left off</p></div><div><div><p>Visualize your progress</p></div><p>View your daily completions on a simple to use visual map</p></div></div><div><div><h3>Offline use</h3><p>This app can be fully used offline for however long you want! You can sign in with your email if you want to sync your data between devices</p></div><p><img alt="map" loading="lazy" width="578" height="279" decoding="async" data-nimg="1" srcset="https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-dark.763094e9.png&amp;w=640&amp;q=75 1x, https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-dark.763094e9.png&amp;w=1200&amp;q=75 2x" src="https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-dark.763094e9.png&amp;w=1200&amp;q=75"><img alt="map" loading="lazy" width="542" height="273" decoding="async" data-nimg="1" srcset="https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-light.7a3bb00f.png&amp;w=640&amp;q=75 1x, https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-light.7a3bb00f.png&amp;w=1200&amp;q=75 2x" src="https://rdht.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Foffline-light.7a3bb00f.png&amp;w=1200&amp;q=75"></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Where are the good resources for learning audio processing? (143 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40892812</link>
            <guid>40892812</guid>
            <pubDate>Sat, 06 Jul 2024 19:59:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40892812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40893374"><td></td></tr>
                <tr id="40894238"><td></td></tr>
                <tr id="40894341"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40894341" href="https://news.ycombinator.com/vote?id=40894341&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>That doesn't look terse to me, though it does require familiarity with the subject.</p><p>"The last expression can be interpreted as the Fourier superposition of the sinusoidal harmonics of [expression], i.e., an inverse Fourier series sum. In other words, [expression] is the amplitude of the k-th harmonic in the Fourier-series expansion of the periodic signal x_m(t)."</p><p>Many of the concepts are hyperlinked for reference. With the required familiarity, I would much rather read this than something that took seven pages to get to the point - say by assuming that the reader is unfamiliar with a premise out of an abundance of caution.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40893967"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40893967" href="https://news.ycombinator.com/vote?id=40893967&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Second anything from CCRMA, the inventors of FM synthesis and still the one top programs in the country/world.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894254"><td></td></tr>
                <tr id="40894481"><td></td></tr>
                        <tr id="40894570"><td></td></tr>
            <tr id="40893962"><td></td></tr>
                  <tr id="40893889"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893889" href="https://news.ycombinator.com/vote?id=40893889&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>Hey - one of the industry standard time stretching library is "elastique" by Zynaptiq (licensed, not open source). Used  by Ableton, FL Studio etc.</p><p>If you want to peak into some source code - you can look into Rubberband library:</p><p><a href="https://breakfastquay.com/rubberband/" rel="nofollow">https://breakfastquay.com/rubberband/</a></p><p>Rubberband is one of the time stretching/pitch shifting algorithms used in Reaper.  You can download reaper trial and listen to the results with different parameters to see how you can tweak the code and if that gets any results you're happy with:</p><p><a href="https://www.reaper.fm/" rel="nofollow">https://www.reaper.fm/</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894189"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894189" href="https://news.ycombinator.com/vote?id=40894189&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>I find [1] a good reference. A con is the examples are in matlab, but it's clear enough between the text and matlab code to write your own implementation.</p><p>Also [2] is a decent book for overall dsp concepts.</p><p>[1] DAFX - Digital Audio Effects (Second Edition) Edited by Udo Zölzer
<a href="https://dafx.de/DAFX_Book_Page_2nd_edition/index.html" rel="nofollow">https://dafx.de/DAFX_Book_Page_2nd_edition/index.html</a></p><p>[2] Understanding Digital Signal Processing, Richard Lyons</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894433"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894433" href="https://news.ycombinator.com/vote?id=40894433&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>lyons is a good intro but maybe a bit handwavey at times (although my copy is an edition from the 90s).</p><p>consider maybe backing it up with one of the textbooks like oppenheim (the classic) or manolakis (one that i think i remember liking).</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894318"><td></td></tr>
                  <tr id="40893936"><td></td></tr>
                <tr id="40894272"><td></td></tr>
            <tr id="40894440"><td></td></tr>
                  <tr id="40895345"><td></td></tr>
            <tr id="40893704"><td></td></tr>
                <tr id="40893743"><td></td></tr>
                  <tr id="40894894"><td></td></tr>
            <tr id="40894639"><td></td></tr>
            <tr id="40893555"><td></td></tr>
            <tr id="40893694"><td></td></tr>
            <tr id="40894583"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894583" href="https://news.ycombinator.com/vote?id=40894583&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>The Will Pirkle books have a lot of good info and code to get you started:</p><p><a href="https://www.willpirkle.com/" rel="nofollow">https://www.willpirkle.com</a></p><p>Audio programming is a lot of fun but it's the most challenging domain I've ever worked in. You have to be very careful with what you do on the audio thread. No locks, no memory allocation etc. Messing this up can result in some really ugly audio artifacts.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40893918"><td></td></tr>
            <tr id="40893955"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893955" href="https://news.ycombinator.com/vote?id=40893955&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>Audio is half art, half science. That's why I'd try to find someone with experience.</p><p>Back in university, I heard lectures on FFT and its applications to audio signal processing. So open access university courses would be the second place I'd look. The approach I always try first is to ask people I know if they can recommend a conference/meetup. For example, the annual JUCE events appear to be chock full with VST plugin developers. There's also private schools like SAE where you (or your employer) can pay for you to have an hour with one of their lecturers to ask questions.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894978"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894978" href="https://news.ycombinator.com/vote?id=40894978&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Gnu Radio can easily handle audio I/O as well as it does IQ signals from SDR front ends. It's cross platform and you just build flow graphs, which then can be executed.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40893859"><td></td></tr>
            <tr id="40894552"><td></td></tr>
            <tr id="40894554"><td></td></tr>
            <tr id="40893476"><td></td></tr>
            <tr id="40894034"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894034" href="https://news.ycombinator.com/vote?id=40894034&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>I would pick up a microcontroller dev board that has a mic built in (Eg one of the STM32 discoveries). Also get a "codec" dev board. (Or alternatively, use the MCU's onboarod DAC). Get it to receive audio, process it using DSP, then output it, and/or save to memory. This will really force you to understand it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894221"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894221" href="https://news.ycombinator.com/vote?id=40894221&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Why not just use a regular laptop for this? There’s a ton of low level sound processing libraries for every OS.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894664"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894664" href="https://news.ycombinator.com/vote?id=40894664&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Bad advice. I have no idea how using a microcontroller would help someone understand pitchshifting algorithms.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40893834"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893834" href="https://news.ycombinator.com/vote?id=40893834&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Use LabView as a calculation engine to do experiments. The advantage is you get system-like diagrams.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40895055"><td></td></tr>
                <tr id="40895577"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40895577" href="https://news.ycombinator.com/vote?id=40895577&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Chris @ airwindows is super nice to release all his plugins and source code for free. But the code quality is really bad. That doesn't matter if you're using a plugin in the production of a song and it works well. But for learning dsp, it's a bad resource.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Against the burden of knowledge (103 pts)]]></title>
            <link>https://www.theseedsofscience.pub/p/against-the-burden-of-knowledge</link>
            <guid>40892365</guid>
            <pubDate>Sat, 06 Jul 2024 18:52:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theseedsofscience.pub/p/against-the-burden-of-knowledge">https://www.theseedsofscience.pub/p/against-the-burden-of-knowledge</a>, See on <a href="https://news.ycombinator.com/item?id=40892365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><a href="https://twitter.com/MTabarrok" rel="">Maxwell Tabarrok</a><span> is an economics researcher at Dartmouth College and the author of the </span><a href="https://maximumprogress.substack.com/" rel="">Maximum Progress</a><span> substack. Maximum Progress is a blog about the economics, history, science, philosophy, and culture surrounding a single graph: </span><a href="https://ourworldindata.org/grapher/world-gdp-over-the-last-two-millennia" rel="">World GDP Over the Last Two Millennia</a><span>, The Great Fact, The Hockey Stick, The Arc of Human History.</span></em></p><p><em><span>Please consider supporting our efforts at supporting independent research with a paid subscription or </span><a href="https://www.buymeacoffee.com/seeds_science" rel="">a one-time donation.</a><span> Help Seeds (of Science) sprout this Spring/Summer with a </span><a href="https://www.theseedsofscience.pub/spring_seeds" rel="">25% discount</a><span>.</span></em></p><p><em><span>ICYMI: </span><a href="https://www.theseedsofscience.pub/p/announcing-the-sos-research-collective" rel="">Announcing the SoS Research Collective</a><span>. The Collective is now active—check out </span><a href="https://www.theseedsofscience.pub/p/announcing-the-sos-research-collective" rel="">the home page</a><span> and our first crop (heh) of research fellows!</span></em></p><p><a href="https://maximumprogress.substack.com/p/something-is-getting-harder-but-its" rel="">Several posts back</a><span> I wrote about the 2020 paper “</span><a href="https://www.nber.org/system/files/working_papers/w23782/w23782.pdf" rel="">Are Ideas Getting Harder To Find?</a><span>” by Nicholas Bloom, Charles Jones, John Van Reenen, and Michael Webb. In the post, I explain the paper with a metaphor: Our economy is like a car. Jones et al point out that our fuel use (R&amp;D investment) has been growing fast for 100 years but our acceleration (productivity growth rate) hasn’t budged. They explain this by positing some inherent drag on idea exploration that gets more burdensome as we learn more. Something like inertia which makes it harder to double the speed of a car that’s already going fast than a car that starts slower.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png" width="1456" height="886" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:886,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:230280,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>But without knowing the underlying kinetics of science and economic growth, this inertia model is just a guess. There are lots of other explanations which are consistent with the observation of diverging fuel use and acceleration. Our car could be going up a hill, or over a rough and rocky road. Or our engine could be depreciating or using the extra fuel inefficiently. Similarly, the ideas we produce might face growing barriers before they can materialize as physical products and buildings which affect productivity. Or our institutions of science are squandering the extra resources they receive with inefficient institutional designs.</p><p><span>The title of my post was “</span><a href="https://maximumprogress.substack.com/p/something-is-getting-harder-but-its" rel="">Something Is Getting Harder But It's Not Finding Ideas</a><span>” but I really only end up proving that Something Is Getting Harder And We Aren’t Sure What. This post gets closer to fulfilling my original promise by addressing one of the most common arguments for why ideas really are getting harder to find: the burden of knowledge.</span></p><p>The burden of knowledge claims that new ideas inherently get harder to find because you have to spend more time learning more old ones before you’re ready to expand the frontier.</p><p>The argument in favor of this claim is pretty intuitive and convincing. It’s hard to imagine a model of scientific progress without accumulating knowledge. Some of this accumulated knowledge is necessary for expanding the frontier, but no one starts knowing it, so you need some process of investment in education. If the cost of education increases the more you need to learn, then we’ve already created a model with the burden of knowledge.</p><p>Outside of theory we find more support for the burden of knowledge. Knowledge does seem cumulative. Our encyclopedias are much longer. Scientists today know about more species, more fundamental particles, and more archaeological artifacts than scientists in the past. Education also seems like necessary pre-requisite for expanding the frontier of knowledge. Scientists often spend decades in training before they start making original research contributions.</p><p>But to explain the observation of diverging R&amp;D investments and productivity growth rates over the past several decades, the burden of knowledge must have increased over this time. There is empirical evidence for this too.</p><p>The average age of authors in academic journals is increasing, as is the age when Nobel laureates do their best work. This can be explained by an increasing burden of knowledge which takes more time to get through before new contributions can be made.</p><p>Relatedly, more journal articles and patents are being written in larger teams. Larger teams are a response to an increasing burden of knowledge as researchers specialize in narrower topics to get to the frontier of knowledge faster and then collaborate to combine all the necessary elements for a new expansion.</p><p>It is also becoming less common and less rewarding for researchers or inventors to contribute to multiple fields of study, again suggesting specialization in response to a greater burden of knowledge.</p><p>All of this evidence is parsimoniously explained with a burden of knowledge model. It’s still far from clear that these effects are enough to explain all or a significant portion of the divergence between R&amp;D inputs and productivity growth outputs but it does tell compelling story.</p><p>There are several problems with this story though.</p><p>The central piece of the burden of knowledge model is accumulating knowledge which simultaneously represents the fruits of progress but also an obstacle for future researchers. But the history of scientific and technological progress shows countless examples where this assumption in false.</p><p>My favorite is orbital mechanics. For thousands of years the standard model for astronomical prediction was Ptolemy’s geocentric model. Earth was at the center and all the celestial bodies rotated around us. This worked well but things got complicated because, from our perspective, lots of these celestial bodies would switch directions and orbit the opposite way at various times throughout the year.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg" width="613" height="602.8956043956044" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1432,&quot;width&quot;:1456,&quot;resizeWidth&quot;:613,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;The Planet's Orbital Paths According to Ptolemy: How Johannes Kepler Helped  Land “Curiosity” On Mars (1600×1574) | Sacred geometry, Astronomy, Geometry&quot;,&quot;title&quot;:&quot;The Planet's Orbital Paths According to Ptolemy: How Johannes Kepler Helped  Land “Curiosity” On Mars (1600×1574) | Sacred geometry, Astronomy, Geometry&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The Planet's Orbital Paths According to Ptolemy: How Johannes Kepler Helped  Land “Curiosity” On Mars (1600×1574) | Sacred geometry, Astronomy, Geometry" title="The Planet's Orbital Paths According to Ptolemy: How Johannes Kepler Helped  Land “Curiosity” On Mars (1600×1574) | Sacred geometry, Astronomy, Geometry" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Ptolemy and his astronomical ancestors explained these “retrograde” motions with the extra loops you see in the map above called “epicycles.” By the 15th century astronomers had accumulated centuries of meticulous measurements and incorporated them into complex orbital paths, matching their observations. Learning these models and taking enough measurements to improve one of them took an entire lifetime of monastic devotion to studying the stars. The burden of knowledge was immense.</p><p>But then, Copernicus came along with the heliocentric model which, in its simplest initial form, made worse prediction than the tuned-up Ptolemaic model. But the burden of knowledge was dissolved in an instant. Improving the Copernican model meant shifting orbital paths from perfect circles to ellipses. It had nothing to do with the epicycles and perihelions of the Ptolemaic model and none of that burdensome knowledge was necessary to expand the frontier anew.</p><p>We see similar patterns in the transition from Newtonian to relativistic mechanics or discursive Greek geometric algebra to symbolic Arabic equations or superstitious alchemy to physically grounded chemistry. There are thousands of other examples. It is not a general rule that all the past knowledge must be learned to create something new. Often, past knowledge is completely supplanted by a new discovery and progress can continue without increasing, and often decreasing, the necessary educational investment.</p><p>Another prediction of the burden of knowledge is that researchers will respond by specializing in a narrower field which allows them to get to the frontier faster. This is fine, but if this specialization then requires them to collaborate with larger groups and this drags on innovation, it could explain some of the divergence between R&amp;D inputs and productivity growth outputs.</p><p>It’s definitely true that specialization is a common response to an increased burden of knowledge. But the most common way for this specialization to manifest is not larger teams of academic scientists collaborating on a long and complicated paper. It is scientists and technologists specializing and trading for complex tools which they could not recreate themselves but which nonetheless help them expand the frontier of technology.</p><p>Consider a tech entrepreneur in the 2020s. If they want to expand the frontier of technology in software there is, in some sense, a massive burden of knowledge standing before them. The history of theoretical computing, computer engineering, all the science and engineering behind Moore’s law, networking, and the internet. But in fact, the entrepreneur does not need to invest any time in learning about these things to create a new technology using a computer. They can just buy a Macbook and offload all the burden of knowledge onto the people who make it.</p><p>Similarly, a modern scientist is highly specialized in that they use dozens of extremely complex tools which they could not recreate themselves, e.g electron microscopes, super-computers, and protein synthesizers. The burden of knowledge required to deeply understand all of these tools is far too great, so the scientist must specialize in their research and remain a mere user of these tools. But this doesn’t drag on their ability to advance knowledge, in fact it does the opposite.</p><p>The modern world has accumulated much more knowledge than at any time in the past. Specialization is a necessary response to this accumulation, but this is not a drag on innovation. Access to the fruits of this accumulated knowledge through specialization and trade accelerates progress and discovery.</p><p>The previous two arguments are intuitive and theoretical but they do not address the significant empirical evidence which the burden of knowledge can explain. If new fields and new tools are cutting through the burden of knowledge, why are researchers getting older, their teams getting larger, and their fields getting narrower and more permanent?</p><p>One explanation for this evidence is an increasing burden of knowledge. Idea space is just structured such that it takes more time, effort, and more narrow specialization to get to the modern frontier of knowledge.</p><p><span>Another explanation which equally explains our observations is that the institution of academia is depreciating. Inward looking networks of grant applicants and reviewers </span><a href="https://nexus.od.nih.gov/all/2015/03/25/age-of-investigator/" rel="">reward a fixed cohort of researchers that gets older every year</a><span>. Risk averse funders and reviewers that </span><a href="https://mattsclancy.substack.com/p/biases-against-risky-research" rel="">reward incremental, labor intensive research</a><span>. A </span><a href="https://en.wikipedia.org/wiki/The_Case_Against_Education" rel="">business model based on exclusivity</a><span> that requires more and more hurdles as the initial pool of applicants grows.</span></p><p>Institutional decay in the academy is obvious to anyone who looks and can explain our observations of aging, narrowing careers in academia. The burden of knowledge claims that these trends are inevitable responses to an unavoidable cost of progress. But an explanation based on on institutional decay suggests a solution: metascience. Redesign our academic institutions and we can reverse some of these trends.</p><p><span>The burden of knowledge is an intuitive explanation for ideas getting harder to find. Even extremely simple models of scientific progress have the burden of knowledge in them and there is some suggestive empirical evidence for the burden of knowledge in the real world. But new fields and new tools cut against the burden of knowledge. It is unlikely both theoretically and empirically that the burden of knowledge explains a significant portion of the divergence between R&amp;D inputs and productivity growth outputs that “</span><a href="https://www.nber.org/system/files/working_papers/w23782/w23782.pdf" rel="">Are Ideas Getting Harder To Find?</a><span>” points out.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to think in writing (315 pts)]]></title>
            <link>https://www.henrikkarlsson.xyz/p/writing-to-think</link>
            <guid>40892298</guid>
            <pubDate>Sat, 06 Jul 2024 18:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.henrikkarlsson.xyz/p/writing-to-think">https://www.henrikkarlsson.xyz/p/writing-to-think</a>, See on <a href="https://news.ycombinator.com/item?id=40892298">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png" width="750" height="587" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8bec767-3242-4428-a281-0cdc3182ff75_750x587.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:587,&quot;width&quot;:750,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><blockquote><p><em>The reason I've spent so long establishing this rather obvious point [that writing helps you refine your thinking] is that it leads to another that many people will find shocking. If writing down your ideas always makes them more precise and more complete, then no one who hasn't written about a topic has fully formed ideas about it. And someone who never writes has no fully formed ideas about anything nontrivial.</em></p><p><em>It feels to them as if they do, especially if they're not in the habit of critically examining their own thinking. Ideas can feel complete. It's only when you try to put them into words that you discover they're not. So if you never subject your ideas to that test, you'll not only never have fully formed ideas, but also never realize it.</em></p><p>—Paul Graham</p></blockquote><p>When I sit down to write, the meadow is still sunk in darkness, and above it, satellites pass by, one after the other. My thoughts are flighty and shapeless; they morph as I approach them. But when I type, it is as if I pin my thoughts to the table. I can examine them.</p><p><span>But it is hard to do it right. Not all writing helps me </span><em>think</em><span>. Most kinds of writing are rather weak, or even counterproductive, in this regard. You have to approach it in the right way.</span></p><p>Until last fall, I had not seen anyone properly articulate the mental moves that make writing a powerful tool for thought. Writing advice is usually focused on more superficial parts of the craft. Whatever I knew about thinking on the page, I had picked up through trial and error and conversations with other writers.</p><p><span>But then I read Imre Lakatos’s </span><em><a href="https://dl1.cuni.cz/pluginfile.php/730446/mod_resource/content/2/Imre%20Lakatos%3B%20Proofs%20and%20Refutations.pdf" rel="">Proofs and Refutations</a></em><span>. It is not, at first glance, a book about writing. It is a book of mathematical philosophy. By a Hungarian Stalinist, no less. But it is, if you read it sideways, a profound exploration of the act of writing. This shouldn’t be a surprise. Mathematics is, after all, a subset of writing—it is a way of crafting a language that helps you express and improve thoughts. The main difference, compared to prose writers and poets, is that mathematicians are more rigorous, precise. Because of this precision, reading Lakatos gave me a clearer and more precise understanding of what I do, or strive to do, as I sit down each morning and wrestle with my thoughts.&nbsp;</span></p><p>What follows is a series of meditations about thinking through writing provoked by, but not faithful to, Lakatos’s book. I’ve divided it into two parts. The first part covers the basic mental models that are useful to most people (if you write a diary, for example, and want to get clarity about things in your life). The next part goes into more complex patterns of thinking which I suspect is mostly useful if you do research or engage in some other kind of deep creative work.</p><p>A warning. If you aim to write and publish stuff, this essay might tie you up in knots. It is about thinking, not about crafting beauty or finishing things in a finite time.</p><blockquote><p><em><span>There is a crack, a crack in everything</span><br><span>That’s how the light gets in.</span><br><span>—</span></em><span>Leonard Cohen, “Anthem”</span></p></blockquote><p><span>In </span><a href="https://www.dwarkeshpatel.com/p/patrick-collison" rel="">a recent interview with Dwarkesh</a><span>, Patrick Collison explained the value of writing using a metaphor I enjoyed:</span></p><blockquote><p><span>Bruno Latour spoke about how he thinks the printing revolution, like Gutenberg’s, partially caused the scientific revolution by </span><em>making knowledge more rigid.</em><span> Before, if some observation didn’t match some claim, you could always shrug and be like: “Well, the person who transcribed that thing made a mistake.” So </span><em>by making things more rigid, it’s easier to break them. </em><span>[Emphasis mine.]&nbsp;</span></p></blockquote><p><span>Good thinking is about pushing past your current understanding and reaching the thought behind the thought. This often requires breaking old ideas, which is much easier to do when the ideas are as rigid as they get on the page. In a fluid medium like thought or conversation, you can always go, “Well, I didn’t mean it like </span><em>that</em><span>” or rely on the fact that your short-term memory is too limited for you to notice the contradiction between what you are saying now and what you said 12 minutes ago.</span></p><p>When I write, I get to observe the transition from this fluid mode of thinking to the rigid. As I type, I’m often in a fluid mode—writing at the speed of thought. I feel confident about what I’m saying. But as soon as I stop, the thoughts solidify, rigid on the page, and, as I read what I’ve written, I see cracks spreading through my ideas. What seemed right in my head fell to pieces on the page.</p><p><span>Seeing your ideas crumble can be a frustrating experience, but </span><em>it is the point</em><span> if you are writing to think. You want it to break. It is in the cracks the light shines in.</span></p><p>When I write, I push myself to make definite positive claims. Ambiguity allows thought to remain fluid on the page, floating into a different meaning when put under pressure. This makes it harder to push your thinking deeper. By making clear and sharp claims, I reveal my understanding so that I—or the person I’m writing to—can see the state of my knowledge and direct their feedback to the point where it will help my thinking improve.</p><p>This is valuable to do even in areas where you know way too little to “warrant” an opinion. I met a Japanese linguist in the harbor yesterday and talked about the relationship between the Chinese and the Japanese writing systems. This is a topic I had thought about for about twenty seconds before this. “So,” I said after two minutes, “this is a stupid question, but is the relationship between China and Japan like that between Ancient Greece and the Roman Empire?” This is, as it turns out, not a good analogy. But by spelling out my naive understanding, I gave the linguist a good area to work on when he laid out a richer model of the flow of cultural influence in East Asia.</p><p><span>In the terminology of mathematics, what I did here (and in my writing) was to “make a conjecture,” a qualified guess based on limited information. A hypothesis. The mathematician Alexander Grothendieck, whom Johanna and I </span><a href="https://www.henrikkarlsson.xyz/p/good-ideas" rel="">have written about elsewhere</a><span>, would always summarize his first impression of a new situation with a conjecture, proclaiming with irrepressible enthusiasm, “It must be true!” Ten seconds later, someone would come up with a counterexample that proved him wrong. But being right wasn’t the point: getting a better understanding was. And he would immediately throw out a new conjecture. (Holden Karnofsky has a blog post about using this technique to </span><a href="https://www.cold-takes.com/learning-by-writing/" rel="">learn through writing</a><span>.)</span></p><p>Forcing the diffuse ideas and impressions in your head into a definite statement is an art form. You have to grab hold of what is floating and make it rigid and sharp. It can feel almost embarrassing–revealing your ignorance with as much vulnerability as possible.</p><p><span>And it is only the first step. Once you have made your thoughts definite, clear, concrete, sharp, and rigid, you also want to </span><em>unfold </em><span>them.</span></p><p><span>By unfolding I mean “interrogating the conclusion to come up with an explanation of why it </span><em>could </em><span>be true.” What premises and reasoning chains leads to this conclusion? The explanation isn’t meant to prove that your conclusion was right. It is just a way of unpacking it.</span></p><p>By unfolding a claim into an explanation, you spread it on a “wider front” (to borrow a metaphor from Lakatos), so that the criticism has more targets.</p><p><span>I used this tactic in the food store yesterday. Maud, our six-year-old, told me we had to get a pink miniature plastic teapot. I couldn’t come up with a compassionate counterargument, so I said, “Why do you think a plastic teapot is so great?” And she said, “Because it is </span><em>so</em><span> beautiful. And I need one in plastic so it doesn’t break. I would use it all the time.” This brought a smile to my face. See—trying to prove her point, she had given me three times as many claims to attack!</span></p><p>Since the goal is to find flaws in our guesses (so that we can change our minds, refine our mental models and our language, and be more right) unfolding a claim through an explanation is progress. Even if the explanation is wrong.</p><blockquote><p><span>You are interested only in proofs which ‘prove’ what they have set out to prove. I am interested in proofs even if they do not accomplish their intended task. Columbus did not reach India but he discovered something interesting.</span><br><span>—Lakatos</span></p></blockquote><p><span>Let me take another example. Before Maud was born, Johanna and I worked as teachers in Sweden. The first conclusion we drew from that experience was that we didn’t want to submit our kids to what we had observed. This way of formulating it (“Not </span><em>that</em><span>”) is a bit vague as it only defines where not to look for the solution. It is useful to also attempt a positive formulation. If I were to reconstruct the positive version of our conclusion back then, it was something like, “We need to find (or start) a school where our daughter can pursue her interests at her pace.”</span></p><p>There are several subtle problems with this conclusion. But the point is—these problems didn’t come into view until we had unfolded and probed our original position.&nbsp;</p><p>The way we unfolded and improved our conclusion back then was more haphazard than it would have been today. We just talked about it aimlessly, read randomly, and made small notes. This cost us time and caused confusion. These days, I would instead unfold a conclusion like this as a series of bullet points where I spell out the intuition behind my claim in a series of premises. In the case of Maud’s education, this would have looked something like this (note that this is not my current understanding but a reconstruction of what I thought eight years ago):</p><ul><li><p>People have an intrinsic motivation to learn and it is important to not undermine that, which schools do&nbsp;</p></li><li><p>It is better to go deep on a few topics that you are passionate about rather than have a superficial understanding of a broad range of subjects you care little about</p></li><li><p>But you need to attend a school so you get socialized</p></li><li><p>Hence, we need to find a school that allows self-directed learning</p></li></ul><p>Once I unfold my understanding in writing, I often see holes right away. I start correcting myself and discarding ideas already while typing. I cut ideas that are obviously flawed. I rewrite what feels ambiguous to make it sharper–more precise, concrete, unhedged, and true to my understanding.</p><p>The flaws I see immediately, however, are only the more superficial flaws. The deeper patterns take a longer time to emerge—because they are further from my established thoughts and so are harder to articulate.</p><p>Often, they occur first as subtle emotional cues. As I reread a passage, I notice a slight tension across my chest or my eyes fog over. For some reason, it doesn’t feel right. There is something wrong here.&nbsp;</p><p>These subtle feelings are easy to dismiss (“Eh, words are slippery, I mean something slightly different . . . there is no reason to obsess about this”). But in my experience, it is these subtler problems that tend to open a path beyond my current understanding. I learned this from my wife, Johanna, who will often sit with a draft for several hours, not writing or editing, but simply articulating why something feels off to her. Our best essays have come out of the things she surfaced during those sessions.</p><p>For this reason, I suspect that many of my friends who write and publish rapidly are shortchanging themselves. They generate texts filled with hidden doors and move on before they’ve opened them.&nbsp;</p><p>I tend to go through my list of premises and assumptions and ask follow-up questions to myself, to further unfold my conclusion. To continue the example from above, I would take one of the premises and unfold it like this:</p><ul><li><p>But you need a school so you get socialized</p><ul><li><p><em>Curious: why?</em></p></li><li><p>Kids will get depressed and struggle to navigate workplaces, and so on, if they haven’t been exposed to society</p><ul><li><p><em>Where can I read more about this? Are there any good studies?</em></p></li></ul></li><li><p>Being in something like a school is important because humans are social animals. We pick up most of our skills and norms and so on by being immersed in a peer group</p><ul><li><p><em>And what follows from this?</em></p></li><li><p><em>If we are shaped by our peer group, what would the ideal peer group look like?</em></p></li></ul></li></ul></li></ul><p><span>The emotional tone of these questions is, in my head, lovingly curious; I’m not trying to</span><em> </em><span>put myself down. I’m trying not to kill ideas. I want to help them evolve and spill forth more insight. Often this dialogue ends with me changing my mind about several premises and coming to a different conclusion, but the original idea remains the seed—no less valuable for having been proven wrong. It takes creativity and boldness to leap out and form a conclusion, and the part that criticizes must understand how dependent it is on the part that throws ideas at the wall. It is often easier to criticize than it is to synthesize a new position.</span></p><p>The sun is above the horizon now, the satellites hid behind a thin layer of orange and pink. A hare raises on his hind legs in the middle of the meadow looking around. I tap the glass and watch his ears turn my way.</p><p>Now that I have spelled out my position and fixed the obvious flaws, I start probing myself more seriously to see if I can get the argument to break down.</p><p><span>If one of the premises I have unfolded is a factual claim, I’ll spend a few minutes skimming research in the area to see how well my position holds up. “Oh, it turns out that most homeschooled kids do </span><em>not</em><span> have any problems with socialization!” I realized when doing this in relation to Maud’s education. (Though it didn’t take me a few minutes, it took me years in this case. Partly because we were unsystematic, partly because homeschooling is illegal and taboo in Sweden and this had worked itself into my body so that I felt revulsion each time I probed that assumption.) In this case, looking at studies and statistics helped remove several needless assumptions. We changed our conclusion (we left Sweden and now homeschool Maud and her sister).</span></p><p><span>But often the type of problem I like to think about is too personal and messy and qualitative to be resolved cleanly through a statistically significant study. What I do in these situations instead is to consider </span><em>counterexamples</em><span>.</span></p><p><span>I like to visualize concrete situations when I make an argument (in the notes for this essay, for example, I continually compare what I say against past writing projects). This makes it easier for me to think clearly. I am tied back into a lived reality, which is rigid, and do not float off into theory, where I have a solid track record of fooling myself. When I have a concrete situation in mind, I can ask myself, “What is a situation where the opposite happened? Why was that?” I can list the characteristics of the situation that inform my conclusion and then systematically look for cases that have other characteristics. In “</span><a href="https://www.henrikkarlsson.xyz/p/childhoods" rel="">Childhoods of exceptional people</a><span>,” for example, I wrote about parenting from the perspective of concrete biographies. The sample was unsystematic. But once I had extracted what I thought were the common patterns, I asked myself, “So whom does this </span><em>not</em><span> apply to?” Then I added the people that came to mind to the sample and ended up with a distribution that was good enough for my purposes.</span></p><p>Counterexamples are useful in two ways. Either you find a counterexample that a) proves one of the premises wrong but b) does not change your mind about the conclusion. Lakatos calls this a local (and non-global) counterexample. This means there is something wrong with your unfolding. Perhaps you need to change that part of the explanation? Or perhaps you can simply drop it, making the mental model simpler and more general? Local counterexamples help you improve your explanation and get a better understanding.&nbsp;</p><p><span>There is a scene in the last season of </span><em>Breaking Bad</em><span> that illustrates this. The main character, whatever his name was, is a teacher that starts a meth lab. This can be thought of as his conclusion (“I should get into the meth business”) and when asked to defend this decision he unfolds the claim by saying, “I need to support my family.” This is false. There are better ways for him to do that (he has an old friend who offers him money). That is a local counterexample. In the final season, he admits to himself: “I did it because it made me feel alive.” This doesn’t change his conclusion (he does not change his mind about the meth) but it gives him a deeper and more correct understanding of himself.</span></p><p><span>Other times, the counterexample you find undermines the whole idea—a </span><em>global counterexample</em><span>. You unfold your conclusion and discover that one of the premises does not hold up, and there is no way to patch it. The fracture spreads right up to the conclusion. Now—this is what we have been longing for—there is a big hole of confusion where before there was a mental model. It is time to replace it with something more subtle and deep that incorporates the critique.</span></p><p>How to do this, and do it in the most interesting way possible, is the topic of the next part (which I have no idea when I’ll finish).</p><p><em>If you liked this, you might enjoy this one too:</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why privacy is important, and having "nothing to hide" is irrelevant (2016) (185 pts)]]></title>
            <link>https://robindoherty.com/2016/01/06/nothing-to-hide.html</link>
            <guid>40892259</guid>
            <pubDate>Sat, 06 Jul 2024 18:38:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robindoherty.com/2016/01/06/nothing-to-hide.html">https://robindoherty.com/2016/01/06/nothing-to-hide.html</a>, See on <a href="https://news.ycombinator.com/item?id=40892259">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            <p>
              The governments of
              <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html">Australia</a>,
              <a href="https://lawfareblog.com/german-bundestag-passes-new-data-retention-law">Germany</a>, the
              <a href="http://www.theguardian.com/world/2015/nov/05/mass-snooping-and-more-the-measures-in-theresa-mays-bill">UK</a>
              and the
              <a href="https://medium.com/@RonWyden/this-bill-won-t-protect-you-from-hackers-6aff1d250f67">US</a>
              are destroying your privacy. Some people don’t see the problem…
            </p>

            <h4 id="i-have-nothing-to-hide-so-why-should-i-care">
              “I have nothing to hide, so why should I care?”
            </h4>

            <p>
              It doesn’t matter if <em>you</em> have <em>“nothing to hide”</em>.
              Privacy is a right granted to individuals that underpins the
              freedoms of expression, association and assembly; all of which are
              essential for a free, democratic society.
            </p>

            <p>
              The statement from
              <a href="http://www.smh.com.au/digital-life/digital-life-news/metadata-retention-those-with-nothing-to-hide-have-nothing-to-fear-says-australian-federal-police-assistant-commissioner-tim-morris-20150222-13ljzi.html">some</a>
              <a href="https://www.youtube.com/watch?v=lWam4EWI48M">politicians</a>
              that “if you have nothing to hide then you have nothing to fear”
              purposefully misframes the whole debate.
            </p>

            <p>This affects all of us. We must care.</p>

            <blockquote>
              <p>
                Arguing that you don’t care about the right to privacy because
                you have nothing to hide is no different than saying you don’t
                care about free speech because you have nothing to say.
              </p>
            </blockquote>

            <p><em>– Edward Snowden</em></p>

            <h2 id="privacy-and-freedom">Privacy and freedom</h2>

            <p>Loss of privacy leads to loss of freedom.</p>

            <p>
              Your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_expression">freedom of expression</a>
              is threatened by the surveillance of your internet usage – thought
              patterns and intentions can be extrapolated from your website
              visits (rightly or wrongly), and the knowledge that you are being
              surveilled can make you less likely to research a particular
              topic. You lose that perspective, and your thought can be pushed
              in one direction as a result. Similarly, when the things you write
              online, or communicate privately to others, are surveilled, and
              you <a href="#self-censorship">self-censor</a> as a result, the
              rest of us lose your perspective, and the development of further
              ideas is stifled.
            </p>

            <p>
              Your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_association">freedom of association</a>
              is threatened by the surveillance of your communications online
              and by phone, and your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_assembly">freedom of assembly</a>
              is threatened by the tracking of your location by your mobile
              phone. Can we afford to risk the benefits of free association, the
              social change brought by activists and campaigners, or the right
              to protest?
            </p>

            <p>
              These freedoms are being eroded, right now. The effects will
              worsen over time, as each failure to exercise our freedom builds
              upon the last, and as more people experience the
              <a href="#personal-chilling">chilling effects</a>.
            </p>

            <h3 id="aggregation"><a name="aggregation"></a>Aggregation</h3>

            <p>
              Bits of information that you might not feel the need to hide can
              be <em>aggregated</em> into a telling profile, which might include
              things that you actually do want to conceal.
            </p>

            <p>
              In the case of data retention in Australia, we have given away our
              rights to privacy, and now share a constant stream of:
            </p>

            <ul>
              <li><strong>where</strong> we go,</li>
              <li><strong>who</strong> we contact and when,</li>
              <li>and <strong>what we do</strong> on the internet.</li>
            </ul>

            <p>
              With just a small portion of this
              <a href="http://www.abc.net.au/news/2015-08-16/metadata-retention-privacy-phone-will-ockenden/6694152">data</a>, off-the-shelf software and their own spare time, ABC News
              readers found
              <a href="http://www.abc.net.au/news/2015-08-24/metadata-what-you-found-will-ockenden/6703626">Will Ockenden’s home, workplace and parents’ home</a>.
            </p>

            <p>
              The intrusion becomes all the more spectacular when you consider
              the data across a whole population, the
              <a href="https://www.rt.com/usa/snowden-leak-black-budget-176/">massive budgets</a>
              of the
              <a href="https://www.privacyinternational.org/node/51">Five Eyes</a>
              intelligence agencies, and the constant progress of artificial
              intelligence and big data analytics.
            </p>

            <p>
              Your interactions with the world around you can reveal your
              political and religious beliefs, your desires, sympathies and
              convictions, and things about yourself that you
              <a href="http://www.businessinsider.com.au/the-incredible-story-of-how-target-exposed-a-teen-girls-pregnancy-2012-2">aren’t even aware of</a>
              (and they might be wrong too).
            </p>

            <p>
              Given enough data and time, your behaviour might even be
              <a href="http://qz.com/527008/an-algorithm-can-predict-human-behavior-better-than-humans/">predicted</a>.
            </p>

            <h3 id="personal-chilling-effects">
              <a name="personal-chilling"></a>Personal chilling effects
            </h3>

            <p>
              When you understand the fullness of the picture that mass
              surveillance paints of you, you begin to change your behaviour –
              you avoid exercising certain freedoms.
            </p>

            <p>You might think twice about:</p>

            <ul>
              <li>
                <p>
                  <strong>contacting</strong> or meeting people (exercising your
                  freedom of association) who you think might become “persons of
                  interest” to the state, or that you think the algorithms might
                  determine as such in the future, since you know that your
                  association with them is retained for <em>at least</em> two
                  years and may be analysed,
                </p>
              </li>
              <li>
                <p>
                  <strong>congregating</strong> in the same location as a group
                  of those people (exercising your freedom of assembly). Would
                  you attend a protest march calling for action on climate
                  change, knowing that you would forever be linked to what the
                  Australian government calls a
                  <a href="http://www.theguardian.com/australia-news/2015/sep/10/green-lawfare-voters-feel-coalition-is-trying-to-silence-environment-groups">“vigilantist” movement of “economic saboteurs”</a>?
                </p>
              </li>
              <li>
                <p>
                  <strong>participating</strong> in any activity that might make
                  you look bad in the data – even if you know that you are
                  innocent. This could mean avoiding writing about a particular
                  topic online, or visiting a particular website, or buying a
                  particular book – exercising your freedom of expression.
                </p>
              </li>
            </ul>

            <h3 id="societal-chilling-effects">
              <a name="societal-chilling"></a>Societal chilling effects
            </h3>

            <p>
              The combined result of these second thoughts across the population
              is a chilling effect on many of the activities that are key to a
              well-functioning democracy – activism, journalism, and political
              dissent, among others.
            </p>

            <p>
              We all benefit from progress that occurs when activists,
              journalists and society as a whole are able to freely engage in
              political discourse and dissent. Many of the positive changes of
              the last century were only possible because of these freedoms. For
              example, the
              <a href="https://en.wikipedia.org/wiki/Australian_referendum,_1967_(Aboriginals)">1967 referendum</a>
              on including indigenous Australians in the census, and allowing
              the federal government to make laws specifically benefiting
              indigenous races, was only made possible by sustained activism
              throughout the 1950s and 60s.
            </p>

            <p>
              Unfortunately, we are already <a name="self-censorship"></a><strong>self-censoring</strong>.
              <a href="https://www.pen.org/sites/default/files/Chilling%20Effects_PEN%20American.pdf">A 2013 survey of US writers</a>
              found that after the revelations of the NSA’s mass surveillance
              regime, 1 in 6 had avoided writing on a topic they thought would
              subject them to surveillance, and a further 1 in 6 had seriously
              considered doing so.
            </p>

            <blockquote>
              <p>
                Ask yourself: at every point in history, who suffers the most
                from unjustified surveillance? It is not the privileged, but the
                vulnerable. Surveillance is not about safety, it’s about power.
                It’s about control.
              </p>
            </blockquote>

            <p><em>– Edward Snowden</em></p>

            <h3 id="misuse--misappropriation">
              <a name="misappropriation"></a>Misuse &amp; misappropriation
            </h3>

            <p>
              By creating databases and systems of easy access to such a great
              volume of personally revealing information, we increase the scope
              of mass surveillance, and therefore the scope for infringements
              upon our human rights.
            </p>

            <p>
              East Germany is the most extreme example of a surveillance state
              in history. The Stasi – its infamous security agency – employed
              90,000 spies and had a network of at least 174,000 informants. The
              Stasi kept meticulous files on hundreds of thousands of innocent
              citizens and used this information to psychologically harrass,
              blackmail and discredit people who became dissenters. But that was
              before the internet. Reflecting on the NSA’s current systems of
              mass surveillance, a former Stasi lieutenant colonel
              <a href="http://www.mcclatchydc.com/news/nation-world/national/article24750439.html">said</a>:
              <strong>“for us, this would have been a dream come true”</strong>.
            </p>

            <p>
              Even aside from the risk of systematic state misbehaviour, in
              Australia we know that the
              <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html#snoopers">2500 snoopers</a>
              who have unrestricted access to your data are subject to
              <a href="http://www.watoday.com.au/wa-news/wa-policeman-charged-over-disclosing-ben-cousins-secrets-to-journalist-girlfriend-20150423-1mrjhd.html">“professional curiosity”</a>,
              <a href="http://www.couriermail.com.au/news/queensland/police-under-fire-for-probing-phone-records-of-their-own-in-8216disturbing8217-breach-of-officers8217-privacy/story-fnihsrf2-1226706966590">fallible morals</a>, and are only human, so will make mistakes and become victims of
              social engineering, blackmail or bribery.
            </p>

            <p>
              This is most dangerous for the most vulnerable people. For
              example, if you have an angry or violent ex-partner, you could be
              put in mortal danger by them getting their hands on this much
              detail about your life.
            </p>

            <h4 id="risk-taking">Risk taking</h4>

            <p>
              Our “digital lives” are an accurate reflection of our actual
              lives. Our phone records expose where we go and who we talk to,
              and our internet usage can expose almost everything about
              ourselves and what we care about.
            </p>

            <p>
              Even if we trust the motives of our current governments, and every
              person with authorised access to our data, we are taking an
              incredible risk. The systems of surveillance that we entrench now
              may be misappropriated and misused at any time by future
              governments, foreign intelligence agencies, double agents, and
              opportunistic hackers.
            </p>

            <p>The more data we have, the more devastating its potential.</p>

            <h3 id="gradual-erosion">
              <a name="gradual-erosion"></a>Gradual erosion
            </h3>

            <p>
              Each system of surveillance and intrusion that we introduce erodes
              our privacy and pushes us one step further away from a free
              society.
            </p>

            <p>
              While you may not have noticed the impact yet, your privacy has
              already been eroded. If we continue along our current path,
              building more powers into our systems of surveillance, what was
              once your private life will be whittled away to nothing, and the
              freedoms that we have taken for granted will cease to exist.
            </p>

            <p>
              As technology advances, we are presented with a choice – will it
              to continue to offer an overall benefit to society, or will we
              allow it to be used as a tool for total intrusion into our lives?
            </p>

            <blockquote>
              <p>
                Privacy is rarely lost in one fell swoop. It is usually eroded
                over time, little bits dissolving almost imperceptibly until we
                finally begin to notice how much is gone.
              </p>
            </blockquote>

            <p>
              <em>–
                <a href="https://web.archive.org/web/20151116013709/http://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/">Why Privacy Matters Even if You Have ‘Nothing to Hide’</a>, Daniel J. Solove</em>
            </p>

            <h2 id="what-next">What next?</h2>

            <p>
              The governments of Australia, New Zealand, Canada, the US and
              others are poised to take a big step in the wrong direction with
              the Trans-Pacific Partnership (TPP). The EFF
              <a href="https://www.eff.org/deeplinks/2015/12/how-tpp-will-affect-you-and-your-digital-rights">explains</a>
              why the TPP is a huge threat to your privacy and other rights.
            </p>

            <ul>
              <li>
                <p>
                  <strong>Take action</strong> – if you are a technologist, join
                  Hack for Privacy and fight back against mass surveillance –
                  <a href="https://hackforprivacy.org/">hackforprivacy.org</a>.
                </p>
              </li>
              <li>
                <p>
                  <strong>Spread the privacy mindset</strong> – we must foster
                  understanding of this issue in order to protect ourselves from
                  harmful laws and fight against future invasions of privacy.
                  Please help spread the knowledge, discuss this article with a
                  friend, tweet it, share it, etc.
                </p>
              </li>
              <li>
                <p>
                  <strong>Protect yourself</strong> – protect your own data from
                  mass surveillance. This
                  <a href="http://www.theguardian.com/commentisfree/2013/sep/05/government-betrayed-internet-nsa-spying">increases the cost</a>
                  of mass surveillance and helps others too. Read
                  <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html">my advice on protecting your data from retention in
                    Australia</a>, the EFF’s
                  <a href="https://ssd.eff.org/">Surveillance Self-Defense Guide</a>, and
                  <a href="http://www.tcij.org/node/1016">Information Security for Journalists</a>.
                </p>
              </li>
            </ul>

            <hr>

            <p>
              <em>Translations of this article are available in:
                <a href="http://www.seanhall.it/blog/2016/01/14/perche-la-privacy-e-importante-e-non-avere-nulla-da-nascondere-e-irrilevante">Italian</a>
                and
                <a href="https://robindoherty.com/de/2016/02/01/nichts-zu-verbergen.html">German</a>.</em>
            </p>

            <hr>

            
          </article></div>]]></description>
        </item>
    </channel>
</rss>