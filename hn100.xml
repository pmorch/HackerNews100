<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 17 Feb 2024 16:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[We Have to Start Over: From Atom to Zed (143 pts)]]></title>
            <link>https://zed.dev/blog/we-have-to-start-over</link>
            <guid>39408288</guid>
            <pubDate>Sat, 17 Feb 2024 10:45:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/we-have-to-start-over">https://zed.dev/blog/we-have-to-start-over</a>, See on <a href="https://news.ycombinator.com/item?id=39408288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header></header><p><em>After the <a href="https://zed.dev/blog/why-the-big-rewrite">last conversation</a> with Nathan, Max, and Antonio—Zed's three co-founders—I still had quite a few questions to ask: why did you make the technological choices you did? How important is Rust to Zed? Did you consciously set out to own the technological stack the way you do now? How do you decide what to polish and build-once-and-for-all-time and what to ship faster?</em></p>
<p><em>Lucky for me, they sat down with me again and answered my questions again.</em></p>
<p><em>What follows is an editorialized transcript of an hour long conversation we had. I tried to preserve intent and meaning as much as possible, while getting rid of the uhms, the likes, the you-knows, and the pauses and course-corrections that make up an in-depth conversation.</em></p>
<p><em>(You can <a href="https://www.youtube.com/watch?v=w894KLbapLw">watch the full conversation on our YouTube channel</a>.)</em></p>
<p><strong>Thorsten: The three of you have been working together for, what? Has it been 10 years?</strong></p>
<p><strong>Nathan</strong>: Ungefähr. [German for: "Something like that."]</p>
<p><strong>Max</strong>: Yeah, something like that.</p>
<p><strong>Antonio</strong>: I think 10 years sounds about right. 2014, yeah.</p>
<p><strong>Thorsten: <a href="https://en.wikipedia.org/wiki/Atom_(text_editor)">Atom</a> — that was 10 years ago. You worked together on Atom and then said "we're building Zed." It's pretty clear that you have a vision for what you want to build. And you also made some really distinct technological choices. You use Rust, it's GPU-accelerated, CRDTs. I'm wondering: how much are these technological choices are tied-in with the vision for Zed? How big of a role does the technology play?</strong></p>
<p><strong>Nathan</strong>: I mean, from my perspective, the vision for Zed is just a more refined and fleshed out version of the original vision for Atom, which just fell short due to the technical choices we made in my mind and the level of technical maturity that I think all of us had when we started Atom.</p>
<p>But the goal I've always had is a lightweight editor that is minimal that I love using that feels like a text editor, but has the power of an IDE when needed, without all of the slowness in the experience and kind of heaviness in the UI, but still powerful. That was very early on what I wanted. And for it to be extensible.</p>
<p>You know, I remember using Emacs and thinking it was so cool that you could extend it, but you're sort of operating at the character level. So that was part of the original vision too and now Max has achieved that with <a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a>. You know, basically scriptability. We're not scriptable yet, but we'll get there. But when we are, we'll have access to a richer representation of the text than just looping over characters or whatever I was doing in Emacs. I mean, they probably have that now as well, right? Because Max wrote tree-sitter.</p>
<p><strong>Max</strong>: They do, I hear.</p>
<p><strong>Nathan</strong>: So that's cool. But anyway, that was all part of the vision. And it just didn't pan out with Atom. I mean, when Chris hired me to work on Atom, I almost didn't join [meaning: join GitHub to work on Atom] because I was afraid of using web tech and that it wouldn't be able to get there.</p>
<p>But to be honest, I don't know that whatever I had at my disposal at the time would have gotten us any better because Rust didn't exist back then. So it would have been C, C++. I don't know, it would have been really hard to do something native at the time we created Atom. And I don't think my skills were in place on just fundamental algorithms, et cetera, that are critical to text editing. And C++ would have really slowed me down in my learning there. So I think it happened how it needed to happen.</p>
<p>We got to a certain point with Atom. It was 2017 when we'd shipped <a href="https://github.com/atom/teletype">Teletype</a> and it felt like, okay, it's no longer our own ignorance holding us back, it really is like the platform holding us back at this point. That's really how it was starting to feel.     Just the fact that in JavaScript, an array in JavaScript is... You think you have an array of objects, but you really have an array of pointers to objects. So every single time you're walking over that, you're chasing it down. You have no control over memory. There are garbage collector pauses that are just happening that you have no control over. You just look at the profile of the fricking thing.</p>
<p><strong>Thorsten: When you were working on Atom, was there a specific point at which you said "oh, I wish we would have built it with X"? Or was it an accumulation of paper cuts? Antonio was nodding right now.</strong></p>
<p><strong>Antonio</strong>: Speaking of 10 years of working on this thing: I remember one of my first projects in Atom — I don't know if you remember this, Nathan — was speeding up line layout. Basically, we were seeing line layout being very slow. And I remember trying rendering lines in an iframe. And I remember using Canvas, measured text, and all these APIs that were... I don't know, the Canvas API wasn't quite the same as the browser API, so you couldn't really measure text correctly. The iframe stuff had some other weird problem.</p>
<p>My experience in Atom always felt like bending over backwards to try to achieve something that in principle should have been simple. Lay out some lines and read
the position of the cursor at this spot in between these two characters. That seems fundamentally doable and yet it always felt like the tools were not at our disposal. They were very far away from what we wanted to do.</p>
<p><strong>Nathan</strong>: It was a nightmare. I mean, the ironic thing is that we created Electron to create Atom, but I can't imagine a worse application for Electron than a code editor, I don't know. For something simpler, it's probably fine, the memory footprint sucks, but it's fine. But for a code editor you just don't have the level of control I think you need to do these things in a straightforward way at the very least. It's always some... backflip.</p>
<p>So at some point in 2017, I remember sitting there, writing in Atom in my journal — that was the evening when I thought: we have to start over. We have to start over, this isn't working and we're never going to get this where we want it to go. VS Code has done an admirable job of getting it as far as it's gonna go. There'll be incremental improvements in the tech, I'm sure, but I just wanted more.</p>
<p>So at that point it was: okay, what should we do? And I'd been watching Rust, I'd seen some of <a href="https://raphlinus.github.io/">Raph Levien</a>'s writing about Rust. And at the time this seemed like the only viable path to kind of overcome some of these obstacles. And it started as: what if we just write the core of this thing in Rust and we keep Electron as the presentation layer?</p>
<p>So it was just inch-by-inch that we came to the technological decisions we chose. Even after building the UI framework, giving up on Electron, we were using <a href="https://github.com/servo/pathfinder">Pathfinder</a>, which is like this really cool project that could do arbitrary presentation of SVGs basically, but it was too slow. So then I thought: okay, what if we do our own shaders? And then went and learned about signed distance fields.</p>
<p>It was kind of funny. It was me not wanting to solve some more fundamental problem, but just being forced to do that by the unavailability of any other choice.</p>
<p>I shouldn't say it was only me, it wasn't only me. But this was from my perspective...</p>
<p><strong>Thorsten: It sounds like the goal was always to be as fast as possible, as lightweight as possible. You tried to get there, but you couldn't with the technology you had. But then Rust came along. And you didn't start saying "we need a GPU-accelerated editor", but you started by saying you want the fastest possible editor and then GPU acceleration was one way to do that. Is that right?</strong></p>
<p><strong>Nathan</strong>:
Yeah, it was: we have this hardware in the computer and rather than negotiating what DOM nodes are in the DOM at a given moment, or all this nonsense, we could just literally be like, what color should this pixel be? Great. Okay, if we can program that hardware to decide what color every pixel on the screen should be in parallel, or as parallel as possible —&nbsp;we should probably use that if we want to be fast.</p>
<p>But you know, we came there kind of grudgingly because I didn't know how to do any of it.</p>
<p><strong>Thorsten: Now, this is kind of a loaded question, but I've been on the side hacking with Rust for the last three years and my feelings about it are complicated. But two weeks someone on Hacker News said that find-all-matches in Zed takes a second but in Sublime Text it's really fast, closer to 200ms. So Antonio and I paired on that and he wrote code to optimize for this case of searching all the occurrences in a buffer. But the optimized code wasn't "optimized" code: it didn't use any dirty tricks, no SIMD, or something like that. It was high-level code, with the optimization being that it's assumption was different: instead of doing things in a loop, one by one, its assumption was to find all results. We made a release build of that and it went from 1s down to 4ms.</strong></p>
<p><strong>Antonio</strong>:
Hahaha</p>
<p><strong>Thorsten: And I sat there, looking at the 4ms, and... well, I thought: this is going to be a nice lunch break after this. But 4ms? With high-level code like that, that just called other internal APIs? Wow. So what I'm trying to ask is: Rust has these zero-cost abstractions —&nbsp;so you can use high levels of abstraction to build a text editor, but it still gives you this kind of performance. Do you think this is a specific thing about Rust, or do you think if you had just been a better C++ or C programmer, you could've done it in another language?</strong></p>
<p><strong>Antonio</strong>: You probably could have done it with C and C++. I don't know. I mean, tree-sitter is written in C, right, Max? So it is possible to write a complex library piece of software in C. Although I have to say anytime I look at the C code in tree sitter, I scream because it's just too much for me. I don't know.</p>
<p>Personally, yes, Rust is in a sweet spot. If it wasn't for the compile time being that slow — that's a thing that I really don't like about the language, but maybe it's our project that's too big, I don't know.</p>
<p>But yes it is pretty cool that you can build on top of these abstractions and just rely on them. I mean, I don't know about zero cost —  every abstraction has a cost, I guess.</p>
<p>But the thing with this project in general... With Atom it always felt like we didn't know where to look for performance. With this, with Zed, it's more: we could do this and we could do that and we could improve this. Just last week, Nathan and I were discussing how to improve the subtraction of the SumTree to perform batched insertion a lot faster.</p>
<p><strong>Nathan</strong>: And then you implemented it, right?</p>
<p><strong>Antonio</strong>: Yeah. But it's not shipped yet.</p>
<p><strong>Nathan</strong>: Great.</p>
<p><strong>Max</strong>: I'll say we did do a lot of C++ on Atom — we did a lot. We tried. And it worked, but it was just that there was a very meaningful distinction — obviously — where the boundary was between the JavaScript application code and the C++ library code. And people would talk about performance and say "just do this on a background thread, just don't do it on the main thread" and we'd say "okay, we can do that" but that means this whole subsystem that is involved here needs to be dropped into C++ in order to share memory. Then build JavaScript APIs around that and figure out how it's going to still look like idiomatic JavaScript code and preserve all these properties that it had from when it was written in JavaScript.</p>
<p>And only then could we actually move this one task to the background thread.</p>
<p>It was such a difference between writing JavaScript code — that was scriptable and pluggable and overridable —&nbsp;and the C++ that had the core capability to have shared memory and multi-threading.</p>
<p><strong>Nathan</strong>: And Rust is designed to be multi-threaded. I remember when I tried to learn Rust and I wanted to implement this <a href="https://en.wikipedia.org/wiki/Splay_tree">splay tree</a> because the splay tree was a structure that we used a lot in Atom. Well, for a time — it had its era at least. I mean, it was actually pretty good for our needs, but it had parent pointers, it was very much a mutable structure.</p>
<p>And I tried to build that in Rust and the language fought me. And I thought: can you even build anything real in this language? I had serious doubts, actually.</p>
<p>So I gave up for a while, then I tried again. And this time around I built a copy-on-write B-tree. And when I built it that way, it used <code>Arc</code>s and that meant it was inherently multi-threading friendly.</p>
<p>And when I followed the dictates of the language and the borrower checker and did it the way Rust wanted me to do it, it was: oh, cool.</p>
<p>Now we have this way of representing <a href="https://en.wikipedia.org/wiki/Rope_(data_structure)">ropes</a> — which is the fundamental text storage structure in Zed — in a way where we can spawn a background thread, and it's O(1), it's just bumping an <code>Arc</code> to take that to a background thread and look at a snapshot, et cetera.</p>
<p>It's not just about being native. I also think Rust brings to the table innovations. The language is designed to be used the way we're using it on multiple threads and at a low level.</p>
<p>And frankly, I was just a little too much of a script kiddie I think to do well in C++. It always just annoyed me: these freaking files, jumping over here, all these arcane rules. And could a C++ master do what we did in Rust? Probably, but like I wasn't gonna become that person.</p>
<p><strong>Thorsten: So Antonio, you just mentioned that with JavaScript, you didn't know where to look for performance. Max, you said, when you were using C++ or JavaScript, you felt these boundaries when you want to make something async. And now we heard about Rust — you can suddenly do stuff async on a background thread, you have less restrictions, you can move freely around.</strong></p>
<p><strong>That reminds me of something you can actually see in the Zed code base: you own the whole stack. From tree-sitter doing the parsing to GPUI, the GPU-accelerated UI framework — there aren't a lot of third-party dependencies in the code base. Some libraries, but not big building blocks.</strong></p>
<p><strong>How important is that for you? We own the full stack, top to bottom, we understand it top to bottom. Is that a conscious choice or did this happen by accident because Max built tree-setter and then you did this and now look at us, we rebuilt the whole thing.</strong></p>
<p><strong>Max</strong>: I don't know. I think it has trade-offs, but I so far it's been pretty nice to be able to just... decide how we want things to work. Like right now: we want to have language extensions that use WASM. Tree-sitter didn't have that but we added that to it.</p>
<p>There's a million things like that. We don't want to be beholden to some UI framework that may not render text exactly the way we want, because we're a text editor and that matters a lot. But we can now go change that.</p>
<p>It doesn't feel like anything is sort off limits.</p>
<p><strong>Nathan</strong>: One thing I'll say: this was very informed by an experience earlier in my career with jQuery. jQuery was the hot thing and I learned jQuery. I remember <a href="https://yehudakatz.com/">Yehuda</a> coming to <a href="https://en.wikipedia.org/wiki/Pivotal_Labs">Pivotal</a> and presenting on jQuery and I thought this is so cool. I was blown away by it. So early on, all the Atom code, believe it or not, was jQuery.</p>
<p>And the funny thing was though, having learned jQuery, because everybody told me, "oh, the reason you use jQuery is it abstracts over all the differences in the browser APIs", et cetera. I never really questioned that. But then I remember the day that I just sat down and read the freaking DOM APIs. And I thought: you know what, this is actually fine. Maybe there were some missing features or something — and I don't want to shit on jQuery, I think it has its role — but what I came away with was that if I don't have an abstraction that's nailing almost 100% of my needs then I might not want to have that abstraction and go to the level below, understand the level below it fully, and do what I need to do.</p>
<p>That was kind of what happened with GPUI. There were some UI frameworks in flight when we started on a GPUI, in 2019, but none of them did what I knew we would need to do. And I didn't understand them.</p>
<p>But I knew I could come to understand quite easily the fundamental primitives that we're going to be relying on — the language, the graphics framework. I knew we could learn those things and I knew we've written a lot of code. If I can build a system that I can understand and learn from, then I know that I can do what we need to do if it's fundamentally possible on the underlying system. And so really it was — at least for GPUI — a survival strategy: I need to understand this and the best way to understand it is to build it.</p>
<p><strong>Thorsten: What are the downsides of that? Max, you said there's trade-offs.</strong></p>
<p><strong>Nathan</strong>: Takes forever. It's slow.</p>
<p><strong>Antonio &amp; Max</strong>: [laughing]</p>
<p><strong>Antonio</strong>: It's also tricky to onboard people. You're not using the X framework out there that everybody knows, you have to teach this code base from scratch — you know, 300,000 lines of code. That's a downside.</p>
<p>But the cool thing is that while this is a downside, at the same time there's somebody else who has written that code and can explain it to the new person.</p>
<p>It might be slower, but again, you're retaining control.</p>
<p><strong>Nathan</strong>: I think it accumulates. The advantages accumulate, and the downsides depreciate. Someone just built <a href="https://github.com/MatthiasGrandl/loungy">another app on GPUI</a>, so now we have another stakeholder. The cost of having owned it, we're going to gradually write off over time, and the costs and the upsides of owning it are going to start to kick in.</p>
<p><strong>Thorsten: Sometimes people say: I only build it once and then I never have to touch it again. And the opposite of that might be: you can't predict the future, <a href="https://en.wikipedia.org/wiki/Worse_is_better">worse is better</a>, and so on.</strong></p>
<p><strong>And what you just said, that it's slower to build it all yourself, there's a ring of "build it once and do it right for our use case" to it: only the perfect abstraction for what we want to do. At the same time, there's this sense of urgency that you all have. I mean, I joined four weeks ago and I do feel like we're moving fast and we've got so much to do.</strong></p>
<p><strong>How do you balance that? How do you have this huge vision for what you want to build, and balance that with saying "I'm gonna write shaders, I'm gonna perfect how we render drop shadows or whatever"?</strong></p>
<p><strong>Nathan</strong>: Build what you need, only what you need, no more, no less, and build that as well as you can within reason. And then when it turns out to not be quite what you needed, be willing to revisit it after you've learned. But I think if you're laying down every brush stroke with intentionality and care,
and you're not wasting time speculating about what you might need, then... for me, that's always worked out. Sometimes it takes a little while though.</p>
<p><strong>Antonio</strong>: I would add on top of that: it's a gradient. It's not like everything needs to be built perfectly. Or at least that's how I feel about much of the code we write. If we're writing stuff in GPUI, well, the whole app depends on the GPUI, that better be perfect. Or the sum tree. It's this data structure that's used everywhere in the code base. That one we really wanna nail, because it has to be fast.</p>
<p>It has to work perfectly so that we can build on top of it, right? And that is reflected, also in the testing that we do on those things. The SumTree is randomized-tested because we want to make sure that all those edge cases work perfectly.</p>
<p>Now, as you move towards the edge— that performance improvement that you alluded to, Thorsten, we didn't spend three hours gold plating it, right? It was like: whatever gets the job done, it's pretty much at the edge. I mean, we should feel good about the code, we should always strive to write the code as best as we can, but we don't need to gold plate it.</p>
<p>It's a gradient. The more core something is, the more it deserves thought and quality.</p>
<p><strong>Nathan</strong>: And my favorite code to write is the code I've earned myself the right to write. Whoa, that's a lot of homophones.</p>
<p>With GPUI I had so much fun writing it that I almost felt like guilty about it.
But I have earned the right to write this code because I wrote the first version, I lived with it, I pushed it forward, I made the compromises when I needed to make them to make things right.</p>
<p>But now is the moment where we can make this better. And it makes sense to make this better. And I'm informed. I think a lot of times when people talk about like rewriting— if you're rewriting something someone else wrote, be doubly suspicious of yourself.</p>
<p>But if you wrote it and you've lived with it and you've put in the work... That's also something to be said: don't let perfectionism get in the way of learning.</p>
<p><strong>Thorsten: If I were to take the three of you and... I don't know what to throw at you that you couldn't build, but say you'd have to build, I don't know what — a PID controller for an airplane. Airplane software, there you go. Something like that.</strong></p>
<p><strong>Nathan</strong>: Nuclear reactor control subsystem.</p>
<p><strong>Thorsten: You don't know the domain and you don't know yet how you're going to build it and you don't yet know which parts you're going to need. Is that where you would say you'd need a different approach? Unlike in the editor, where you have a strong vision for what you want, you built a few before, so now you know which parts count. You know beforehand, GPUI is going to be important. So let's take our time with it and gold-plate it as Antonio said.</strong></p>
<p><strong>Max</strong>: I mean, I don't know if a nuclear reactor is a good example, but I do feel like if it was our first code editor, ... We <em>did</em> "worse is better". It wasn't intentionally bad, but we took the kind of quicker, dirtier approach once and then kind of identified the things that were real pain points to build on top of, in their sort of worse-is-better form.</p>
<p>But I do think, if for some reason Antonio and me and Nathan had to build a...</p>
<p><strong>Nathan</strong>: Choose something less mission critical maybe?</p>
<p><strong>Max</strong>: ... a Shopify clone or something. We would probably have a different mindset about it. We wouldn't know which pieces needed to be really highly honed.</p>
<p><strong>Nathan</strong>: But if I <em>were</em> building a nuclear reactor control system, I would use a Byzantine fault-tolerant consensus algorithm and pit three teams against one another to compromise each other's security and then make them come to consensus on all of it. But I don't know how to do that.</p>
<p><strong>Antonio</strong>: There's another example that's less mission critical than a nuclear reactor, but where we didn't know the data structure and we kind of took the time to learn it. It wasn't always that the structure powering the buffers in Atom and in Zed today was a CRDT. There was a research period where Nathan and I read... I forget how many papers. A lot of them. And the approach we're using right now with the CRDT — we still rewrote it two or three times — but the approach is more or less the same.</p>
<p>So I think there's a part of it that comes with experience. I feel like you tend to develop a sense of what you need to spend time on and what is more frivolous, less important.</p>
<p>Now, that said, we did rewrite the CRDT two or three times, but the research part, was important. I don't know.</p>
<p><strong>Nathan</strong>: The funny thing is in the Atom that shipped, the buffer was an array of lines, a JavaScript array of strings. And in Zed, it's a multi-thread-friendly snapshot-able copy-on-write B-tree that indexes everything you can imagine. Or everything we've needed. So we did worse is better.</p>
<p>But starting over, would it be an array of lines again? Probably not because look at the look at the time bounds on that. And put a little more thought into it, but that —&nbsp;again —&nbsp;I learned that by like doing worse-is-better and then having it be really slow or problematic in edge cases that ended up mattering.</p>
<p><strong>Thorsten: So what are the most gold-plated parts of Zed?</strong></p>
<p><strong>Nathan</strong>: GPUI is pretty gold-plated, I think, because we just rewrote the whole fricking thing.</p>
<p><strong>Antonio</strong>:
Good question.</p>
<p><strong>Max</strong>: I think what's in the <a href="https://github.com/zed-industries/zed/tree/main/crates/editor"><code>editor</code> crate</a>, where there's sort of the stack of different transforms that convert the raw text of the buffer into the lines that you see on screen, that expand the tabs and do the soft-wrapping and insert the block decorations and handle folds and stuff. All those layers have this uniform testing strategy where it's randomized-tested with property testing. So I think they're pretty gold-plated.</p>
<p>The multi-buffer too, where we sort of weave together the different excerpts of different buffers into one.</p>
<p><strong>Nathan</strong>: I would call them, um... I just wanted to suggest like an alternative substance for that part of the code base. I would say it was kind of plated and coated in blood.</p>
<p><strong>Antonio</strong>: Ha! Blood plated.</p>
<p><strong>Thorsten: You mean the editor and the multi-buffer?</strong></p>
<p><strong>Antonio</strong>: Yeah.</p>
<p><strong>Nathan</strong>: Yeah. It's randomized tests where we've spent literally the entire day in 2021, many days in a row, just debugging failures in these randomized tests that would find some weird edge case of this ornate— I mean, I wouldn't say it's ornate, but it's complicated — stacking of different layers of transformation required to present things on screen. And so it's just elbow grease, right? Find the edge cases and then figure out why they're happening by reducing the log, which for a long time we just did manually.</p>
<p><strong>Thorsten: How did it feel when one of these bugs popped up? Did you have moments of panic when property testing threw a bug in our face and you thought "maybe this whole thing doesn't work?" Or was it rather "well, it's just another thing to polish down and if not, we rewrite this"?</strong></p>
<p><strong>Antonio</strong>: Never panic, that's the rule of randomized testing, never panic. I have a lot of faith in our capability as engineers, I really do, and maybe it might be that we have to rewrite the whole thing and the randomized test is telling us that, but it's fine, we just learned something, back to the drawing board and redo it.</p>
<p><strong>Nathan</strong>: What was scary was: how long is this going to take? I think Lee, our seed investor, was also asking us that at certain times. But he stuck with us and was patient because it took a while.</p>
<p>But that piece was written in  Rust. If we f this up, the program is panicking. Goodbye, poof. It's not just like a stack trace gets thrown in the corner of the editor or something, no, it's done.</p>
<p>So we knew how hard it was to get those layers right. And we knew that there was no other choice, but to get them right. But yeah, I remember, Antonio, remember working on soft wraps and that problem we came up against where we realized the primitive we needed was this ability to represent a patch and then to be able to compose these patches together — that was one moment where I was sweating a bit, thinking "are we gonna freaking figure this out?" and then Antonio figured it out.</p>
<p><strong>Antonio</strong>: Yeah. But powering it all — you know, in terms of gold-plating — is again the sum tree. And even with that, there are some ideas on how to make it better, if we were to rewrite it.</p>
<p><strong>Nathan</strong>: We were talking the other night about how dope it would be. And Antonio, you applied some of the ideas we talked about: being able to construct all these layers in a more streaming friendly way. And you did one optimization, which is gonna land on preview next week.</p>
<p><strong>Antonio</strong>: Yeah, I need to open the PR for it still...</p>
<p><strong>Nathan</strong>: To enable more streaming inputs so people don't get zero feedback when they open a big file, but start actually loading things in, more efficiently — does that necessitate a rewrite? Maybe. Maybe not. I don't know.</p>
<p><strong>Thorsten: Quite interesting how often this idea of rewriting or doing it again comes up. We talked about this <a href="https://zed.dev/blog/why-the-big-rewrite">the last time</a>. Learning continuously. It's not: learning and <em>then</em> fixing something and patching something. It's more: we learned something, so now let's redo it with that learning in mind, vs. just putting a band aid on. It came up multiple times and you see it in the product.</strong></p>
<p><strong>When we talk, Antonio, you say things like: before we did it like <em>this</em> and now we do it like that. Just yesterday, we basically rewrote the part that deals with macOS' IME system, because Antonio said: we can't leave it like this, we don't want another person to fall into this rabbit hole, let's put a bridge on top of it.</strong></p>
<p><strong>Nathan</strong>: Nice. That's good to hear. I've heard about that.</p>
<p><strong>Thorsten: I don't know if it makes sense, but my last question is this... With a lot of software, say, SaaS Enterprise Whatever, or the Shopify clone, I think most users do not care what technology is used, as long as it works for them. And I wonder: do you think this is different with developer tools or editors? Does the technology that's used shine through more or do the users care more about it?</strong></p>
<p><strong>Max</strong>: I do think it affects the type of contributions we can get. A lot of our users, so many of them are people who would be prepared to contribute something to the code base to fulfill their own needs.</p>
<p>I think it's important that it's easy to contribute to Zed. If we written it all in C++, I think that there would be a lot of people who would like wanna change something about Zed, but would not be as prepared to make the change themselves.</p>
<p>Whereas just from the contributions that we've gotten so far since going open source a few weeks ago, it's a lot. I think people like that it's written in Rust. It's approachable. People can build the project easily. They don't have to go learn how to use CMake or whatever to build the project or Gyp. They can just use cargo.</p>
<p>But also the fact that the compiler has this strictness to it, allows us, as the receiving end of those contributions, to often merge with confidence. I think it's really helpful.</p>
<p><strong>Nathan</strong>: Rust is an absolutely beautiful tool. It's not perfect, but I love it. But does it matter to the people? I mean, I think people want a fast editor at the end of the day. We could write it in, what is it, brainfuck? They wouldn't care. But the contribution angle is super valid.</p>
<p><strong>Antonio</strong>: But I still would like to talk about the performance, I just think we are forced to do things a certain way because of performance. Why do we have this GPU accelerated UI framework? It's because the performance needs to be at a certain level. We want our frames to be below three milliseconds. We could rasterize everything on the CPU and we could have used something that did that, but, no.</p>
<p>To some extent, we're positioning ourselves to be a performance editor, because we want a performance editor. I want a performance editor. And so, the choice is almost... we have no choice almost.</p>
<p><strong>Nathan</strong>: But there's Zig now and I don't know a lot about Zig yet, I haven't had time, honestly, to learn about it, but people I respect are excited about it. It seems like it shares some of the same goals in terms of the output as Rust. I'm unclear what it's sacrificing in terms of safety, or how they handle those things. There may be pragmatic workarounds that are sort of not as strict as Rust, but in practice work, et cetera.</p>
<p>So I'm intrigued by that. I'm intrigued, but then there's a lot to be said for like monolingualism, if that makes sense. The server's in Rust, the frontend's in Rust, but if I could get 99% of the benefits of Rust with a 10th of the compile time or something...</p>
<p><strong>Thorsten: Well, I can tell you about Zig that a person on Discord was saying they're writing an editor in Zig, but the perfect name for a text editor in Zig is already taken: Zed.</strong></p><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It’s Official, Apple Kills Web Apps in the EU (189 pts)]]></title>
            <link>https://open-web-advocacy.org/blog/its-official-apple-kills-web-apps-in-the-eu/</link>
            <guid>39408196</guid>
            <pubDate>Sat, 17 Feb 2024 10:30:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://open-web-advocacy.org/blog/its-official-apple-kills-web-apps-in-the-eu/">https://open-web-advocacy.org/blog/its-official-apple-kills-web-apps-in-the-eu/</a>, See on <a href="https://news.ycombinator.com/item?id=39408196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>Nearly two weeks ago <a rel="noreferrer" target="_blank" href="https://open-web-advocacy.org/blog/did-apple-just-break-web-apps-in-ios17.4-beta-eu/">we discussed a bug</a> on iOS Beta 17.4 breaking Web App installation in the EU. Yesterday <a rel="noreferrer" target="_blank" href="https://open-web-advocacy.org/blog/apple-on-course-to-break-all-web-apps-in-eu-within-20-days/">we raised the alarm</a> that this appeared to be not a bug but a deliberate choice on Apple’s part. Today Apple officially confirmed our suspicions in an update to their compliance proposal.</p>
<p>In a direct attack on the open web, its users, and its developers, <a rel="noreferrer" target="_blank" href="https://developer.apple.com/support/dma-and-apps-in-the-eu#8">they have decided to kill Web Apps (PWAs) in the EU</a>:</p>
<blockquote>
<div><p>And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU.</p><p>
EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality. We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our users.”</p></div>
</blockquote>
<p>This is emphatically not required by the EU’s Digital Markets Act (DMA). It’s a circumvention of both the spirit and the letter of the Act, and if the EU allows it, then the DMA will have failed in its aim to allow fair and effective browser and web app competition.</p>
<p>It’s telling that this is the feature that Apple refused to share. And it makes sense: the idea that users could install safe and secure apps that Apple can’t tax, block or control is terrifying to them.</p>
<p>The legal obligation to allow third-party browsers onto iOS removes their ability to set a ceiling on web app functionality via their control of Safari and the WKWebView. Suddenly Web Apps would be a viable competitor. It is particularly galling for them to cite low adoption when they have had their thumb on the scale suppressing them for over a decade.</p>
<p>The DMA compels them to allow third party app stores, but Apple’s plan is to cripple them with their hardware and software API fee (Core Technology Fee) and their ludicrous “opt-in to your legal rights” at a different price alternative contract.</p>
<p>But web apps are much harder to stop. Even Apple admits WebKit’s sandbox is, <a rel="noreferrer" target="_blank" href="https://assets.publishing.service.gov.uk/media/62277271d3bf7f158779fe39/Apple_11.3.22.pdf">to quote them</a> ”orders of magnitude more stringent than the sandbox for native iOS apps”. They tried claiming to the UK regulator that Safari is more secure than other major browsers but decisively lost that argument.</p>
<p>So this is their new tactic: Kill off a competitor while saying the EU made them do it.</p>
<p>Apple has had 15 years to allow third party browsers the ability to compete in web app functionality and nearly 2 since they knew they would be legally compelled to do so.</p>
<p><a rel="noreferrer" target="_blank" href="https://developer.apple.com/support/dma-and-apps-in-the-eu#dev-qa:~:text=Why%20don%27t%20users%20in%20the%20EU%20have%20access%20to%20Home%20Screen%20web%20apps%3F">Apple also makes tenuous, bordering on laughable, claims regarding web app security.</a> In addition to unwarranted and unjustifiable attempts to project their own model onto competing browsers, Apple makes claims that ignore the history of web applications and browsers in providing strong privacy and security separation. Apple offers no evidence to back these assertions, and ignores the long track record of superior security of PWAs on other OSes.</p>
<p>Again and again, Apple has offered paper-thin fig-leaf arguments based on security to duck regulation, only to have these ploys rejected in nearly every jurisdiction where evidence is critically examined. This appears to be another instance of the same willfully misleading pattern. If security posturing is the backbone of Apple’s attempt to duck conformance with the DMA, the EU must reject the proposal and find Apple willfully non-compliant.</p>
<p>Apple also makes a self-fulfilling argument regarding the low use of iOS homescreen web apps. This is a situation of Apple’s own making and, indeed, a large part of why OWA has invested so much in reversing Apple’s history of self-preferencing towards native apps that Apple can tax through its App Store monopoly. Instead of offering equivalent affordances for websites looking to compete with App Store alternatives, Apple’s answer is to remove the capability, destroy critical features, and engender data loss for users and businesses that had invested in the web as a platform. Malicious destruction may be Apple’s attempt at an answer, but it is not a solution.</p>
<p>The next question is: Why all the secrecy? There was nothing in their compliance plan, Safari’s release notes or the beta’s release notes. Given that they are now stating they knew all along, it seems they wanted to see if they could sneak this past.</p>
<p>Clearly the backlash has caught them off guard and that’s why they had to rush out this panicked response, the only significant update they have made to their compliance proposal.</p>
<p>We always assumed that the commission would have to fine Apple billions to force them to allow the web to compete fairly and effectively with their App Store but it’s still incredibly disappointing to see Apple behave like this.</p>
<p>This is a message in a bottle to regulators world-wide: Apple will stop at nothing to protect its app distribution monopoly and the rent that comes with it, including removing critical features from its OSes without the slightest care for its users. It will not act in good faith, it must be forced.</p>
<p>We will continue to work with the EC to ensure that Web Apps can remain first-class citizens for iOS users, businesses, and competing browser vendors.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Considerations for a long-running Raspberry Pi (284 pts)]]></title>
            <link>https://www.dzombak.com/blog/2023/12/Considerations-for-a-long-running-Raspberry-Pi.html</link>
            <guid>39407631</guid>
            <pubDate>Sat, 17 Feb 2024 08:42:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dzombak.com/blog/2023/12/Considerations-for-a-long-running-Raspberry-Pi.html">https://www.dzombak.com/blog/2023/12/Considerations-for-a-long-running-Raspberry-Pi.html</a>, See on <a href="https://news.ycombinator.com/item?id=39407631">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><span> <time pubdate="" datetime="2023-12-29T14:43:07-05:00"> <span>December</span> <span>29,</span> <span>2023</span> </time> • <span>Tagged:</span> <a href="https://www.dzombak.com/blog/tag/series%3Api-reliability/">series:pi-reliability</a> <a href="https://www.dzombak.com/blog/tag/raspberry-pi/">raspberry-pi</a> </span></header><p>Part of the <a href="https://www.dzombak.com/blog/series/pi-reliability.html">Raspberry Pi Reliability</a> series.</p><p>I use Raspberry Pis around my home as everything from <a href="https://github.com/cdzombak/pi-fm-player">low-power FM transmitters</a> to <a href="https://github.com/cdzombak/nut_influx_connector">UPS energy monitors</a>.</p><p>Keeping a Raspberry Pi online and working with zero intervention for weeks, months, or years is somewhat of an art form. Several classes of things can go wrong, and you need to consider how your Pi will recover from each of them — and <a href="https://www.dzombak.com/blog/2023/12/Consider-the-risks-before-making-any-dramatic-changes-to-your-Raspberry-Pi-setup.html">weigh the risks of each solution against its benefits</a>.</p><p>This new set of posts in <a href="https://www.dzombak.com/blog/series/pi-reliability.html">my Raspberry Pi Reliability series</a> covers each class of issues I’ve run into, and what I’ve done to solve them. As a bonus, these posts also include some tips on monitoring, mainly using <a href="https://github.com/louislam/uptime-kuma">Uptime Kuma</a>.</p><p>This aims to be a more comprehensive guide than <a href="https://www.dzombak.com/blog/2021/11/Reducing-SD-Card-Wear-on-a-Raspberry-Pi-or-Armbian-Device.html">my previous post on reducing SD card wear</a>, and the posts linked here should be considered an updated replacement for that post.</p><p><em>Without further ado:</em></p><h2 id="what-can-go-wrong-and-how-do-i-prevent-it"> What can go wrong, and how do I prevent it? <a href="#what-can-go-wrong-and-how-do-i-prevent-it"></a></h2><ul><li><a href="https://www.dzombak.com/blog/2023/12/Maintaining-a-solid-WiFi-connection-on-Raspberry-Pi.html">The WiFi connection can fail</a></li><li><a href="https://www.dzombak.com/blog/2023/12/Keep-your-software-up-and-running-on-the-Raspberry-Pi.html">Your software service can stop working</a></li><li><a href="https://www.dzombak.com/blog/2023/12/Mitigating-hardware-firmware-driver-instability-on-the-Raspberry-Pi.html">Hardware/firmware/driver instability can cause a crash</a></li><li>Your SD card can wear out or completely fill up<ul><li><a href="https://www.dzombak.com/blog/2023/12/Choosing-the-right-SD-card-for-your-Pi.html">Start by choosing the right microSD card</a></li><li><a href="https://www.dzombak.com/blog/2023/12/Stop-using-the-Raspberry-Pi-s-SD-card-for-swap.html">Don’t use the SD card for swap!</a></li><li><em>Choose one of…</em><ul><li>Aggressively manage things that write to the SD card (especially logs)</li><li>Make the Pi’s root filesystem read-only</li><li><em>In the interest of getting this series of posts finished in fewer than 2 months,</em> for now I’ll point you to my 2021 post on reducing SD card wear, particularly the <a href="https://www.dzombak.com/blog/2021/11/Reducing-SD-Card-Wear-on-a-Raspberry-Pi-or-Armbian-Device.html#if-the-system-can-use-a-read-only-filesystem">read-only root filesystem section</a> or the <a href="https://www.dzombak.com/blog/2021/11/Reducing-SD-Card-Wear-on-a-Raspberry-Pi-or-Armbian-Device.html#if-the-system-cant-use-a-read-only-filesystem">non-read-only root filesystem section</a>. <em>I plan to produce two updated, easier-to-read guides here in the near future, for my own reference as much as yours; <a href="https://www.dzombak.com/blog/series/pi-reliability.atom.xml">watch this space</a>!</em></li></ul></li><li><a href="https://www.dzombak.com/blog/2023/12/Raspberry-Pi-SD-cards-fsck-them-often.html">Check the filesystem often</a> if you’re not using a read-only root filesystem</li></ul></li><li><a href="https://www.dzombak.com/blog/2023/12/Disable-or-remove-unneeded-services-and-software-to-help-keep-your-Raspberry-Pi-online.html">Disabling unneeded services helps with both software stability <em>and</em> SD card wear</a></li></ul><p><strong>Also, do these:</strong></p><ul><li><a href="https://www.dzombak.com/blog/2023/12/Consider-the-risks-before-making-any-dramatic-changes-to-your-Raspberry-Pi-setup.html">Consider risks and benefits before applying any invasive intervention</a></li><li><a href="https://www.dzombak.com/blog/2023/12/Remote-logging-for-easier-Raspberry-Pi-debugging.html">Remote logging can help you figure out what went wrong, when something <em>does</em> go wrong</a></li></ul><h2 id="caution-advice-to-avoid"> Caution: Advice to avoid <a href="#caution-advice-to-avoid"></a></h2><p><a href="https://raspberrypi.stackexchange.com/a/186">This Stack Exchange post</a> suggests disabling journaling for the Pi’s filesystem. <strong>Don’t do this.</strong> While this change might reduce SD card wear, it makes your Pi more likely to face filesystem corruption in the event of a crash or power outage. My goal is to make my Pis <em>more</em> reliable, and disabling journaling works against that goal.</p><h2 id="pi-reliability-series-updates"> Pi Reliability Series Updates <a href="#pi-reliability-series-updates"></a></h2><p>Inevitably I’ll come back to the posts linked above with corrections and additions. For the foreseeable future, when this happens, I will:</p><ul><li>Edit the post</li><li>Add a callout in the post noting the date the change was made</li><li>Write a brief post in the Pi Reliability blog series announcing the change, with a link to the edited post</li></ul></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From engineer to manager: what I love, what I hate (183 pts)]]></title>
            <link>https://thoughtspile.github.io/2024/02/16/eng-to-em/</link>
            <guid>39406804</guid>
            <pubDate>Sat, 17 Feb 2024 05:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoughtspile.github.io/2024/02/16/eng-to-em/">https://thoughtspile.github.io/2024/02/16/eng-to-em/</a>, See on <a href="https://news.ycombinator.com/item?id=39406804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><p>It's been almost 2 years since I moved to a team lead role, then to a full-time engineering management position after the expansion of our team. I've been a front-end developer for 7 years before that, and initially I took the "advanced individual contributor" career track before doing the management turnaround. How's it been? Bumpy, but fun. In this article, I'll share the things I love and hate about my current job.</p><h2>Love</h2><p>Let's start with the positive side of management positions. There's plenty to love, honestly.</p><h3>Impact</h3><p>First things first, I adore the power to improve the product we're building, and the overall team well-being that comes with a management position.</p><p>As an engineer, you'll sometimes find yourself in a tough spot with little to no power to change things. Early morning standups are a chore? Code quality sucks? The new feature makes no sense? As a manager, the power to change is yours: you get both the formal and informal authority to change things for the better, and to make yourself and your team happier.</p><p>Your words have weight. If you, an IC, say "guys, we really should write tests", everybody goes "oh, crazy old Vladimir, all grumpy again, haha, where do you see tests fit here?". If you, an EM, casually say "guys, we really should write tests", you might be surprised to find the tests unexpectedly growing in different places. Pleasant.</p><h3>Career opportunities</h3><p>Being an engineering manager is a more promising career opportunity than an engineering track. This might be controversial, but hear me out:</p><ol><li>The EM is normally higher-paid than the basic team-level engineering grades (junior / middle / senior).</li><li>There <em>are</em> higher IC grades (staff, principal, president of code, whatever) in the EM+ salary bands.</li><li>These staff+ IC jobs are concentrated in larger tech companies, because those have tougher technical challenges. Almost every software team in every company has a leadership position.</li><li>The management career ladder is "taller" than that of ICs. <em>Yes,</em> the chances of becoming a CTO are <em>slim,</em> but it's an opportunity that's just not there for a pure IC with no management experience.</li></ol><p>All in all, I believe the demand for EMs to be steadier than for staff+ engineers, and this path gives you more opportunities at the later stages of your career. On a related note...</p><h3>Transferable skills</h3><p>Management skills are more widely useful than an IC engineering role. A decent front-end engineer with React experience won't have trouble moving to another front-end framework, and can probably transition to a back-end / mobile engineering role with -1 grade (a year handicap or so). That's not bad.</p><p>What roles are available to someone with engineering management experience? First, you can easily take on a team with a wildly different focus — mobile developers, infrastructure, ML engineers. You'd need some time to get up to speed on the big-picture technical struggles of your new team, but most companies would take this shot. If you don't want to be an EM any more, you're well-positioned to move to a project or product management role.</p><p>If the entire tech market falls into decline, many management skills would still work for other industries. While I don't see a big flow of tech managers moving into construction business (tech <em>does</em> pay well), there's one alternate path to consider — entrepreneurship. Involvement with people and business decisions makes for great training before starting your own business.</p><p>So, being a manager gives you quite a bit of career flexibility, and makes you less vulnerable to future technological shifts.</p><h3>Less knowledge rot</h3><p>Suffering from <a href="https://www.smashingmagazine.com/2016/11/not-an-imposter-fighting-front-end-fatigue/" target="_blank" rel="noopener">front-end fatigue?</a> Can't keep up with the newest shiniest frameworks and tools? Management's got you covered!</p><p>The "hot new" agile / kanban / scrum methodologies are 20–30 years old. The basic meeting types (demos, dailies, 1-on-1s) have been developing for centuries. At the core, you have teamwork and human interactions, which haven't changed that much since the beginning of humanity.</p><p>My grandfather was a big railroad boss in the 70s, and we can sensibly discuss some of my work challenges. "Oh, you have this talented slacker? Give him some big important task, let's see what he's worth." When it comes to computers, he's more like "I'd like a shovel big enough to throw all your silly gadgets into stratosphere."</p><p>So, if you're tired of keeping up with the latest hot thing in tech, a management role can provide a well-deserved relief. <em>Do</em> keep an eye on what's happening on the tech side of things, but there's no urgency, and no need to get real deep.</p><h3>New challenges</h3><p>Frankly, after 4–5 years of working in a particular tech area, you can solve the vast majority of practical problems well enough. If you want some work challenge, you can:</p><ol><li>Slightly alter your stack — say, a new FE framework. But it's unlikely to keep you engaged very long.</li><li>Make a broader career shift — e.g. frontend to backend. This would probably give you another couple years of fun, but such transitions are, in my experience, either random (e.g. your BE dev quits and someone has to fill the role), or hit your salary.</li><li>Invent problems out of thin air — rewrite everything using a new library, or handle 9000 RPS "for the future". Fun, but most of the time it's more harm than good for your team and business.</li></ol><p>Of all the possible career moves a seasoned engineer can make, switching to management gives you the most new challenges (years worth of new stuff to learn) without hitting your salary.</p><h2>Hate</h2><p>As much as I like the challenges and impact of my new role, and the practical career benefits, I'll be the first one to admit it has downsides as well.</p><h3>Corporate BS</h3><p>As an engineer, I hated bloody corporate BS: individual performance reviews, useless deadlines, company-enforced restrictions on processes and tech stack. Well, congratulations, as a manager you are the sheriff of these practices, whether you believe in them or not.</p><p>As a leader of a team in an org with performance calibrations, I must nominate 1 person who hasn't been <em>working hard enough</em> every 6 months. This human chess is soul-sucking, but I can't make it go away — if I don't offer a sacrificial teammate, someone will be picked randomly further down the process. Crazy shit.</p><p>Sometimes you can negotiate a bit, or hack the process, e.g. assign "below-expected performance" on a round-robin basis, but to your team you'll sometimes be the <em>corporate monster.</em> Sigh. And I haven't even been through the real tough stuff like layoffs, closures and reorganizations.</p><h3>Awkward social situations</h3><p>I've made it to an engineering management position by being good at building stuff. I've been prepared to help with technical decisions, give career guidance, tune processes and set up automation as needed. In fact, a large portion of my job is debugging social tensions and psychological insecurities of people.</p><p>Your junior engineer comments out a few tests to deploy a feature preview. The QA person sees this, and is very pissed because your whole team apparently does not respect the QA role and the value they provide. Restore trust.</p><p>A project manager makes an unsuccessful joke that hurts your designer, who's now crying. Make the PM apologize. Am I a kindergarten teacher or something?</p><p>Boy, I'm no psychologist, and I can't say I'm exceptionally good with people. This part of my job is quite hard, trying to fake it til I make it here.</p><h3>Office hours</h3><p>Life of an engineer is relatively relaxed. If you don't have anything urgent, you can go lay on the grass for half a day, thinking about the future of your project or something. You can miss a few meetings on short notice, no questions asked.</p><p>Now, you're an EM. Try going and lying on the grass for a few hours. You come back to a messenger full of problems: your intern can't work because she forgot how to npm install; a senior manager wants to discuss some potential feature; release has derailed. Also, you can't really skip a meeting you're supposed to facilitate / organize without some up-front preparation.</p><p>This <em>might</em> improve as your team matures and builds better processes, but in general you feel office hours much more as a manager, and your work-life balance directly depends on how good you are at your job.</p><h3>Long feedback loop</h3><p>The final thing I hate about management is the long feedback loop of your actions. Most engineering tasks show the result quite fast: new features take weeks to months, and if that's too long for you — fix a bug and see happy users the next day, or refactor some code and watch complexity decrease in a few hours. Amazing!</p><p>You're a manager? Well, very few of your actions produce a visible result in under a month. Suppose your team has grown too large, and you want to split it up. You must pick a well-rounded set of engineers for the new team, talk to everybody involved to see how they feel about such a change, arrange new regular meetings, set up processes and communications, do some jira magic, maybe isolate the codebases of sub-products. If you think it can be done in a week, well, you're wrong.</p><p>Then, even the right changes can make things get worse before they get better. Say you're understaffed, and you decide to hire. In the short term, you spend hours and hours interviewing, and a new team member won't get up to speed right away, sucking out precious time for onboarding. It's sometimes hard to see the long-term goal behind the short-term inconvenience.</p><p>So, while engineering problem-solving is often fairly straightforward, management changes are more similar to large-scale refactorings. You won't see any quick improvements, which can be frustrating.</p><hr><p>To sum up, moving from an IC engineering role to a management position has been a rollercoaster ride for me, with both bright and bleak spots. Here's what I love:</p><ul><li>The wider impact on the product and team.</li><li>Management is a great long-term career track: it gives you more job opportunities than a staff+ IC, the flexibility to move between different technical areas and roles, and skills that will be relevant across various industries for years to come.</li><li>If you're bored with your field of tech expertise, moving to a management role is a great way to bring the challenge back into your job.</li></ul><p>And here's what I hate:</p><ul><li>Enforcing corporate decisions and policies can be soul-sucking.</li><li>Dealing with social tensions and psychological insecurities of people isn't something I was ready for.</li><li>It's hard to go offline even for a few hours without preparing in advance.</li><li>Your actions have long and non-linear feedback loops with <em>very</em> delayed gratification.</li></ul><p>Now, is this career move the right one for you? If you enjoy challenge and responsibility, and you get an opportunity — I'd say go for it! Yes, management is not a fit for everybody (I'm not even sure it fits me TBH), but it's a great experience that would surely expand your skill set and make you see engineering work from a new angle. If you totally hate it, you have plenty of time to go back into coding =)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Progman: X11 WM modeled after Program Manager from the Windows 3 era (157 pts)]]></title>
            <link>https://github.com/jcs/progman</link>
            <guid>39406568</guid>
            <pubDate>Sat, 17 Feb 2024 05:05:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jcs/progman">https://github.com/jcs/progman</a>, See on <a href="https://news.ycombinator.com/item?id=39406568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:jcs/progman" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="9Wswued4vc4EvziRjs1ya8bnN216099sh6XIlddL0M0X-Tpp4LKZmFeg6856cM9jJzMBkUARz9UvucjMwxHrzA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="jcs/progman" data-current-org="" data-current-owner="jcs" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=qnTfR9C4uvIkXo7OQBhTLzSnofSYTKEbu5IWfYs504bTgTpXHTFiJBY134hhrnYA8Qo%2BrO6P4f3wogpijwbZrZ5dleYJAe2tQmhURaYUId%2Fgt%2F%2FtGOoMi5iJmUGQz6XbUuQwRzWE6AOnWI02Fyu0TP%2BUClKH9jJB5x1J71eIuztUE0PE4ucctI4BfGHyOugfBASim%2BDGNAHXVRNcfcI7LmDon917smfaT4cvfhcsWaHhsqi2lSuUNUKxbF6zrqQnVxiv12n%2FNEMuW5qfRjVJisO1r06JAOvK3OrUYiv0eV4RhwKJ3nulB4pZu0L4MxXOdl2431UzUe8q%2F0KCPOQPlb9oUzUBVla7QUanxFkQWS9TmXwGnQskQt33oHOHIC0DVEORtq81nyMoS0O7RpIUXUI5N%2Fm7vGLMaaQ9hGwFSWiwQk42xIF%2FqEy8271G%2BOAHi5EVzFrqZEfYDIXLzPVzO627fXQ%2BILpDaDfCEVHMTvTSqaISCXesha36JnUGtTRKFRqZlQqj--kyTa1fZph0EHBraV--A0%2BO6nSjO4agIjdJkuwOpQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=jcs%2Fprogman" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/jcs/progman&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="6b97443fba96565013f7daa9e5dbf58c5bef43f73e666ca5b6de35e0cb774d0d" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral AI launches Mixtral-Next (104 pts)]]></title>
            <link>https://chat.lmsys.org/</link>
            <guid>39406168</guid>
            <pubDate>Sat, 17 Feb 2024 03:46:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chat.lmsys.org/">https://chat.lmsys.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39406168">Hacker News</a></p>
Couldn't get https://chat.lmsys.org/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Automated Unit Test Improvement Using Large Language Models at Meta (234 pts)]]></title>
            <link>https://arxiv.org/abs/2402.09171</link>
            <guid>39405996</guid>
            <pubDate>Sat, 17 Feb 2024 03:14:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2402.09171">https://arxiv.org/abs/2402.09171</a>, See on <a href="https://news.ycombinator.com/item?id=39405996">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2402.09171.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>This paper describes Meta's TestGen-LLM tool, which uses LLMs to automatically improve existing human-written tests. TestGen-LLM verifies that its generated test classes successfully clear a set of filters that assure measurable improvement over the original test suite, thereby eliminating problems due to LLM hallucination. We describe the deployment of TestGen-LLM at Meta test-a-thons for the Instagram and Facebook platforms. In an evaluation on Reels and Stories products for Instagram, 75% of TestGen-LLM's test cases built correctly, 57% passed reliably, and 25% increased coverage. During Meta's Instagram and Facebook test-a-thons, it improved 11.5% of all classes to which it was applied, with 73% of its recommendations being accepted for production deployment by Meta software engineers. We believe this is the first report on industrial scale deployment of LLM-generated code backed by such assurances of code improvement.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Alexandru Marginean [<a href="https://arxiv.org/show-email/af902b12/2402.09171">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 14 Feb 2024 13:43:14 UTC (1,490 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The adult consequences of being bullied in childhood (110 pts)]]></title>
            <link>https://www.sciencedirect.com/science/article/pii/S0277953624001345</link>
            <guid>39405593</guid>
            <pubDate>Sat, 17 Feb 2024 02:02:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedirect.com/science/article/pii/S0277953624001345">https://www.sciencedirect.com/science/article/pii/S0277953624001345</a>, See on <a href="https://news.ycombinator.com/item?id=39405593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mathjax-container" role="main"><div role="region" aria-label="Download options and search"><ul aria-label="PDF Options"><li><a target="_blank" aria-label="View PDF. Opens in a new window."><svg focusable="false" viewBox="0 0 32 32" height="24" width="24"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span><span>View&nbsp;<strong>PDF</strong></span></span></a></li><li></li></ul></div><div><article lang="en"><div id="publication"><p><a href="https://www.sciencedirect.com/journal/social-science-and-medicine" title="Go to Social Science &amp; Medicine on ScienceDirect"><span><img src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/27e772449f51fbce81a73e177357d1103ef60ba2/image/elsevier-non-solus.png" alt="Elsevier"></span></a></p><p><a href="https://www.sciencedirect.com/journal/social-science-and-medicine/vol/345/suppl/C"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0277953624X00039-cov150h.gif" alt="Social Science &amp; Medicine"></span></a></p></div><p id="article-identifier-links"><a href="https://doi.org/10.1016/j.socscimed.2024.116690" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span>https://doi.org/10.1016/j.socscimed.2024.116690</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0277953624001345&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span>Get rights and content</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></p><div id="abstracts"><div id="abs0015" lang="en"><h2>Highlights</h2><div id="abssec0015"><ul><li><span>•</span><span><p id="p0010">We report the effects of being bullied in school at ages 7 and 11, on adult outcomes decades later.</p></span></li><li><span>•</span><span><p id="p0015">We use data from the 1958 British birth cohort the NCDS.</p></span></li><li><span>•</span><span><p id="p0020">Being bullied as a child worsens well-being and labour market performance up to half a century later.</p></span></li><li><span>•</span><span><p id="p0025">Bullying in childhood lowers the probability of having a job throughout adulthood.</p></span></li><li><span>•</span><span><p id="p0030">Being exposed to bullying as a child raises the probability of premature death.</p></span></li></ul></div></div><div id="abs0010" lang="en"><h2>Abstract</h2><p id="abspara0010">Most studies examining the impact of bullying on wellbeing in adulthood rely on retrospective measures of bullying and concentrate primarily on psychological outcomes. Instead, we examine the effects of bullying at ages 7 and 11, collected prospectively by the child's mother, on subjective wellbeing, labour market prospects, and physical wellbeing over the life-course. We exploit 12 sweeps of interview data through to age 62 for a cohort born in a single week in Britain in 1958. Bullying negatively impacts subjective well-being between ages 16 and 62 and raises the probability of mortality before age 55. It also lowers the probability of having a job in adulthood. These effects are independent of other adverse childhood experiences.</p></div></div><ul id="issue-navigation"><li></li><li></li></ul><div id="kwrds0010"><h2>Keywords</h2><p><span>Bullying</span></p><p><span>Subjective wellbeing</span></p><p><span>Birth cohort</span></p><p><span>National child development study</span></p></div><section id="da0010"><h2 id="sectitle0030">Data availability</h2><p id="p0035">The data that has been used is confidential.</p></section><section aria-label="Cited by" id="section-cited-by"><header id="citing-articles-header"><h2>Cited by (0)</h2></header></section><p><span>© 2024 The Authors. Published by Elsevier Ltd.</span></p></article></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Pharma spends billions more on executives and stockholders than on R&D (378 pts)]]></title>
            <link>https://arstechnica.com/science/2024/02/big-pharma-spends-billions-more-on-executives-and-stockholders-than-on-rd/</link>
            <guid>39405547</guid>
            <pubDate>Sat, 17 Feb 2024 01:54:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2024/02/big-pharma-spends-billions-more-on-executives-and-stockholders-than-on-rd/">https://arstechnica.com/science/2024/02/big-pharma-spends-billions-more-on-executives-and-stockholders-than-on-rd/</a>, See on <a href="https://news.ycombinator.com/item?id=39405547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Greed    —
</h4>
            
            <h2 itemprop="description">Senate report points to greed and "patent thickets" as key reasons for high prices.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/20240208-bouchard-451-800x532.jpeg" alt="Big Pharma spends billions more on executives and stockholders than on R&amp;D">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 3:single/related:5f10b5ffc97d661cd5d30f34b2679bd5 --><!-- empty -->
<p>When big pharmaceutical companies are confronted over their exorbitant pricing of prescription drugs in the US, they often retreat to two well-worn arguments: One, that the high drug prices cover costs of researching and developing new drugs, a risky and expensive endeavor, and two, that middle managers—pharmacy benefit managers (PBMs), to be specific—are actually the ones price gouging Americans.</p>
<p>Both of these arguments faced substantial blows in <a href="https://www.help.senate.gov/hearings/why-does-the-united-states-pay-by-far-the-highest-prices-in-the-world-for-prescription-drugs">a hearing</a> Thursday held by the Senate Committee on Health, Education, Labor and Pensions, chaired by Sen. Bernie Sanders (I-Vt.). In fact, pharmaceutical companies are spending billions of dollars more on lavish executive compensation, dividends, and stock buyouts than they spend on research and development (R&amp;D) for new drugs, Sanders pointed out. "In other words, these companies are spending more to enrich their own stockholders and CEOs than they are in finding new cures and new treatments," he said.</p>
<p>And, while PBMs certainly contribute to America's uniquely astronomical drug pricing, their profiteering accounts for a small fraction of the massive drug market, Sanders and an expert panelist noted. PBMs work as shadowy middle managers between drugmakers, insurers, and pharmacies, setting drug formularies and consumer prices, and negotiating rebates and discounts behind the scenes. Though PBMs practices contribute to overall costs, they pale compared to pharmaceutical profits.</p>
<p>Rather, the heart of the problem, according to <a href="https://www.help.senate.gov/imo/media/doc/big_pharmas_business_model_report.pdf">a Senate report released earlier this week</a>, is pharmaceutical greed, patent gaming that allows drug makers to stretch out monopolies, and powerful lobbying.</p>
<p>On Thursday, the Senate committee gathered the CEOs of three behemoth pharmaceutical companies to question them on the drug pricing practices: Robert Davis of Merck, Joaquin Duato of Johnson &amp; Johnson, and Chris Boerner of Bristol Myers Squibb.</p>                                            
                                                        
<p>"We are aware of the many important lifesaving drugs that your companies have produced, and that's extraordinarily important," Sanders said before questioning the CEOs. "But, I think, as all of you know, those drugs mean nothing to anybody who cannot afford it."</p>
<h2>America’s uniquely high prices</h2>
<p>Sanders called drug pricing in the US "outrageous," noting that Americans spend by far the most for prescription drugs in the world. <a href="https://aspe.hhs.gov/sites/default/files/documents/277371265a705c356c968977e87446ae/international-price-comparisons.pdf">A report this month by the US Department of Health and Human Services</a> found that in 2022, US prices across all brand-name and generic drugs were nearly three times as high as prices in 33 other wealthy countries. That means that for every dollar paid in other countries for prescription drugs, Americans paid $2.78. And that gap is widening over time.</p>
<p>Focusing on drugs from the three companies represented at the hearing (J&amp;J, Merck, and Bristol Myers Squibb), the Senate report looked at how initial prices for new drugs entering the US market have skyrocketed over the past two decades. The analysis found that from 2004 to 2008, the median launch price of innovative prescription drugs sold by J&amp;J, Merck, and Bristol Myers Squibb was over $14,000. But, over the past five years, the median launch price was over $238,000. Those numbers account for inflation.</p>
<p>The report focused on high-profit drugs from each of the drug makers. Merck's Keytruda, a cancer drug, costs $191,000 a year in the US, but is just $91,000 in France and $44,000 in Japan. J&amp;J's HIV drug, Symtuza, is $56,000 in the US, but only $14,000 in Canada. And Bristol Myers Squibb's Eliquis, used to prevent strokes, costs $7,100 in the US, but $760 in the UK and $900 in Canada.</p>
<p>Sanders asked Bristol Myers Squibb's CEO Boerner if the company would "reduce the list price of Eliquis in the United States to the price that you charge in Canada, where you make a profit?" Boerner replied that "we can’t make that commitment primarily because the prices in these two countries have very different systems."</p>
<p>The powerful pharmaceutical trade group PhRMA, <a href="https://phrma.org/Blog/Setting-the-Record-Straight-Comparing-US-drug-prices-to-those-in-foreign-countries-hurts-patients">published a blog post before the hearing</a> saying that comparing US drug prices to prices in other countries "hurts patients." The group argued that Americans have broader, faster access to drugs than people in other countries.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/science/2024/02/big-pharma-spends-billions-more-on-executives-and-stockholders-than-on-rd/2/">2</a> <a href="https://arstechnica.com/science/2024/02/big-pharma-spends-billions-more-on-executives-and-stockholders-than-on-rd/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon and SpaceX are quietly trying to demolish national labor law (117 pts)]]></title>
            <link>https://techcrunch.com/2024/02/16/amazon-and-spacex-are-quietly-trying-to-demolish-national-labor-law/</link>
            <guid>39404637</guid>
            <pubDate>Fri, 16 Feb 2024 23:54:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/16/amazon-and-spacex-are-quietly-trying-to-demolish-national-labor-law/">https://techcrunch.com/2024/02/16/amazon-and-spacex-are-quietly-trying-to-demolish-national-labor-law/</a>, See on <a href="https://news.ycombinator.com/item?id=39404637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Amazon alleged in a <a href="https://aboutblaw.com/bcMF" target="_blank" rel="noopener">legal filing</a> published Friday morning that the National Labor Relations Board (NLRB) is unconstitutional. SpaceX and Trader Joe’s — companies that, like Amazon, have <a href="https://jacobin.com/2024/02/trader-joes-nlrb-new-deal" target="_blank" rel="noopener">repeatedly</a>&nbsp;<a href="https://techcrunch.com/2023/01/18/amazon-fined-by-regulators-for-unsafe-warehouse-work-conditions/">faced</a>&nbsp;<a href="https://www.cnbc.com/2023/12/01/amazon-broke-federal-labor-law-by-racially-disparaging-union-leaders.html" target="_blank" rel="noopener">labor</a> <a href="https://techcrunch.com/2024/01/03/spacex-wrongly-fired-eight-activist-employee-us-labor-board-alleges/">law</a> <a href="https://techcrunch.com/2023/10/05/lawsuit-alleges-discriminatory-pay-schemes-at-spacex/">violations</a> from the federal agency — have recently made <a href="https://www.law360.com/articles/1782460/spacex-says-nlrb-is-unconstitutional-in-labor-suit-s-wake" target="_blank" rel="noopener">similar</a> <a href="https://news.bloomberglaw.com/daily-labor-report/trader-joes-follows-spacex-in-arguing-nlrb-is-unconstitutional" target="_blank" rel="noopener">attacks</a>&nbsp;that threaten national worker protections.</p>
<p>This is just Amazon’s latest <a href="https://www.businessinsider.com/nlrb-amazon-union-busting-staten-island-jfk8-warehouse-2022-1" target="_blank" rel="noopener">attempt</a> to <a href="https://www.nytimes.com/2021/03/16/technology/amazon-unions-virginia.html" target="_blank" rel="noopener">block union organizing</a> in its fulfillment centers. But this time, these companies aren’t just limiting the rights of their own workers. If these threats against the NLRB keep moving forward, American workers could lose workplace protections that they’ve had for almost a century.</p>
<p>“It’s a crock of s–t,” said Seth Goldstein, the legal counsel for Trader Joe’s United and the Amazon Labor Union. “I don’t believe any of it, and I think it’s just a cover to bust unions.”</p>
<p>Amazon claims that the NLRB’s structure is unconstitutional because administrative law judges are “insulated from presidential oversight,” thus violating the separation of powers. The company also argues against the structure of NLRB itself, as well as its ability to fine a company for unfair labor practices after a hearing, rather than a full jury trial.</p>
<p>Amazon did not respond to request for comment.</p>
<p>“Judges need protections to remain independent, just like federal judges. You can’t remove federal judges,” Goldstein told TechCrunch. The complaint about a lack of jury trials for companies may seem less dubious, but Goldstein still thinks it’s a stretch. “At the end of the day, the courts do have jurisdiction over decisions by the board. So what are they complaining about?”</p>
<p>Like other federal agencies, the NLRB is largely shaped by the current president. Under President Joe Biden, who <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/09/01/fact-sheet-ahead-of-labor-day-biden-harris-administration-announces-new-actions-to-empower-workers-building-on-the-presidents-historic-support-for-workers-and-unions/" target="_blank" rel="noopener">refers to himself</a> as pro-worker, the NLRB has been <a href="https://www.reuters.com/legal/government/nlrb-paves-way-workers-unionize-without-formal-elections-2023-08-25/" target="_blank" rel="noopener">friendly</a> toward workers’ causes. But as the 2024 election looms, a Republican administration could significantly change that, making it more likely for corporations to be successful in attempts to strike down long-standing labor law.</p>
<p>“I do believe that this is a real threat to workers, especially if Donald Trump gets elected,” Goldstein said.</p>


			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Air Canada ordered to pay customer who was misled by airline's chatbot (297 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit</link>
            <guid>39404364</guid>
            <pubDate>Fri, 16 Feb 2024 23:21:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit">https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit</a>, See on <a href="https://news.ycombinator.com/item?id=39404364">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Canada’s largest airline <a href="https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html" data-link-name="in body link">has been ordered to pay compensation</a> after its chatbot gave a customer inaccurate information, misleading him into buying a full-price ticket.</p><figure id="d6ff2bcb-157d-453b-9238-50da8090ddfe" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:1,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Disabled man drags himself off plane after Air Canada fails to offer wheelchair&quot;,&quot;elementId&quot;:&quot;d6ff2bcb-157d-453b-9238-50da8090ddfe&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/world/2023/oct/30/air-canada-wheelchair-disabled-man-drag-himself-off-flight&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Air <a href="https://www.theguardian.com/world/canada" data-link-name="in body link" data-component="auto-linked-tag">Canada</a> came under further criticism for later attempting to distance itself from the error by claiming that the bot was “responsible for its own actions”.</p><p>Amid a broader push by companies to automate services, the case – the first of its kind in Canada – raises questions about the level of oversight companies have over the chat tools.</p><p>In 2022, Jake Moffatt contacted Air Canada to determine which documents were needed to qualify for a bereavement fare, and if refunds could be granted retroactively.</p><p>According to Moffat’s screenshot of a conversation with the <a href="https://www.theguardian.com/technology/chatbots" data-link-name="in body link">chatbot</a>, the British Columbia resident was told he could apply for the refund “within 90 days of the date your ticket was issued” by completing an online form.</p><p>Moffatt then booked tickets to and from Toronto to attend the funeral of a family member. But when he applied for a refund, Air Canada said bereavement rates did not apply to completed travel and pointed to the bereavement section of the company’s website.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-7">skip past newsletter promotion</a><p id="EmailSignup-skip-link-7" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><figure id="075bcfa3-66dc-4170-b64a-b09e96c0b09f" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:8,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;MP stopped from boarding Air Canada flight as ‘his name was Mohammad’&quot;,&quot;elementId&quot;:&quot;075bcfa3-66dc-4170-b64a-b09e96c0b09f&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/news/2023/oct/23/mp-stopped-from-boarding-air-canada-flight-as-his-name-was-mohammad&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Air Canada later admitted to Moffatt, when confronted with a screenshot of the chatbot’s advice months later, that the bot had used “misleading words” in its advice. The airline told Moffatt it would update the chatbot.</p><p>Moffatt then sued for the fare difference, prompting Air Canada to issue what the tribunal member Christopher Rivers called a “remarkable submission” in its defense.</p><p>Air Canada argued that despite the error, the chatbot was a “separate legal entity” and thus was responsible for its actions.</p><p>“While a chatbot has an interactive component, it is still just a part of Air Canada’s website. It should be obvious to Air Canada that it is responsible for all the information on its website,” wrote Rivers. “It makes no difference whether the information comes from a static page or a chatbot.”</p><p>While Air Canada argued correct information was available on its website, Rivers said the company did “not explain why the webpage titled ‘Bereavement Travel’ was inherently more trustworthy” than its chatbot.</p><p>“There is no reason why Mr Moffatt should know that one section of Air Canada’s webpage is accurate, and another is not,” he wrote.</p><p>Air Canada must pay Moffatt C$650.88, the equivalent of the difference between what Moffatt paid for his flight and a discounted bereavement fare – as well as C$36.14 in pre-judgment interest and C$125 in fees.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pro CCP 'spamouflage' network pivoting to focus on US election (130 pts)]]></title>
            <link>https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/</link>
            <guid>39404046</guid>
            <pubDate>Fri, 16 Feb 2024 22:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/">https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/</a>, See on <a href="https://news.ycombinator.com/item?id=39404046">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>



				


					

					

					<div>

						<p>15 February 2024</p>
<p>By: <a href="https://www.isdglobal.org/isd_team/elise-thomas/">Elise Thomas</a></p>
<hr>
<p><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>when almost half of the world’s population will be asked to go to the polls, arguably no election will be more globally consequential than the US Presidential election in November. Foreign interference in the elections of 2016 and the roiling domestic divisions of 2020 will cast a long shadow over the race in 2024.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">The long-running influence campaign suspected to be run by the CCP and often referred to as </span><span data-contrast="auto">‘</span><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-network-spamouflage-weaponizes-gaza-conflict-to-spread-anti-us-sentiment/"><span data-contrast="none">Spamouflage</span></a><span data-contrast="auto">’</span><span data-contrast="auto"> is already pivoting to focus on the expected competition between President Joe Biden and Republican forerunner Donald Trump. Spamouflage has been active since </span><a href="https://www.aspi.org.au/report/tweeting-through-great-firewall"><span data-contrast="none">at least 2017</span></a><span data-contrast="auto">. In April 2023 the US Department of Justice </span><a href="https://www.justice.gov/opa/pr/40-officers-china-s-national-police-charged-transnational-repression-schemes-targeting-us"><span data-contrast="none">charged 40 employees</span></a><span data-contrast="auto"> of the Chinese Ministry of Public Security</span><span data-contrast="auto">’</span><span data-contrast="auto">s 912 Special Projects Working Group for their involvement in an influence campaign which, based on details in the indictment, appears extremely likely to be Spamouflage. According to the indictment, the operation is coordinated from Beijing and implemented in offices around China. It is infamous among researchers both for its sprawling size and for its failure to generate any noteworthy engagement from real social media users.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">Analysing the narratives of the campaign is nonetheless useful as a method for understanding the likely broader strategy of the CCP going into the election year. It is also important to continue to keep an eye on Spamouflage’s tactics as they evolve. Some recent developments in new tactics from part of the Spamouflage network will be explored in an upcoming Dispatch.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">Even as this shift is occurring, most of the network is continuing to operate as usual. This includes using a network of accounts to share original images (which are now often AI generated, although in some cases more traditional photo editing tools like Photoshop also continue to be used) to illustrate the narrative being promoted.&nbsp;</span></p>
<div id="attachment_16672"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/sp-1/" rel="attachment wp-att-16672"><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-16672" src="https://www.isdglobal.org/wp-content/uploads/2024/02/SP-1.png" alt="" width="359" height="593" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/SP-1.png 359w, https://www.isdglobal.org/wp-content/uploads/2024/02/SP-1-182x300.png 182w, https://www.isdglobal.org/wp-content/uploads/2024/02/SP-1-100x165.png 100w" sizes="(max-width: 359px) 100vw, 359px"></a></p><p id="caption-attachment-16672">Figure 1: Example of an AI-generated ‘movie poster’ shared by a Spamouflage account on X, with the text “American partisan divisions.”</p></div>
<p><span data-contrast="auto">This Dispatch will focus on content shared by Spamouflage on X, formerly known as Twitter. Spamouflage is also active on YouTube, Facebook, TikTok, Medium and </span><a href="https://au.pcmag.com/security/101420/spamouflage-social-media-propaganda-op-linked-to-chinese-law-enforcement"><span data-contrast="none">literally dozens</span></a><span data-contrast="auto"> of other forums, websites and social media platforms. However, lax content moderation enforcement on X is now allowing the operation to proliferate significantly on the platform, in comparison to others which are continuing to push back against Spamouflage.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">As of January 2024, Spamouflage’s election-related content appears to be focused solely on Joe Biden and Donald Trump as the expected candidates in the Presidential election. ISD’s research has not identified content focusing on any of the other candidates in the Republican primary, or any potential Democratic challengers to President Biden. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">While there are narratives targeting both expected candidates, as of January 2024</span><span data-contrast="auto">,</span><span data-contrast="auto"> the majority of the attacks are targeted at President Biden. It is unclear whether this is simply because he is currently in office or if it reflects a preference for the electoral outcome. Interestingly, narratives relating to Trump are somewhat ambiguous in that – from the perspective of Trump supporters – they could be interpreted as positive. Again, it is not clear whether this is an intentional strategy.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">However, the bulk of the content appears aimed at creating a sense of dismay over the state of America without any clear partisan bent. It focuses on issues like urban decay, the fentanyl crisis, dirty drinking water, police brutality, gun violence and crumbling infrastructure. These are not election-specific narratives and have been a significant feature of Spamouflage’s content over several years. While not explicitly linked to the election, however, this content clearly also feeds into the attempt to create a sense of dissatisfaction with the state of the country among voters, as well as potentially engendering a sense of chaos in the US amongst international audiences.&nbsp; </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">Key narratives include:&nbsp;</span></p>
<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}"><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span><strong>The election will be divisive and damaging for America:</strong> </span></span><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>This </span><span>appears to be</span><span> one of the two most common election-specific narratives being promoted by Spamouflage. It portrays the election as a source of division and strife which compounds America’s existing problems. Most of the images associated with this narrative picture Trump and Biden face to face, </span><span>perhaps reflecting</span><span> the prompts which the AI model was given.</span></span> <span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>The images may be composites of AI generated and photoshopped.</span> </span></span></p>
<div id="attachment_16673"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-52-2/" rel="attachment wp-att-16673"><img decoding="async" aria-describedby="caption-attachment-16673" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942.png" alt="" width="835" height="889" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942.png 835w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942-282x300.png 282w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942-768x818.png 768w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942-100x106.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-52-e1707902452942-600x639.png 600w" sizes="(max-width: 835px) 100vw, 835px"></a></p><p id="caption-attachment-16673">Figure 2: Examples of Spamouflage graphics emphasising partisan and political division due to the election.</p></div>
<p><b><span data-contrast="auto">Negative Biden narratives: </span></b><span data-contrast="auto">Alongside painting the election as divisive, negative narratives about President Biden appear to be the other most significant focus of Spamouflage’s election-related efforts as of January 2024. As mentioned above, it is unclear whether this reflects a strategic goal of CCP-aligned networks or is simply because Biden is the current President.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">The scandals, legal cases and conspiracy theories linked to Biden’s son, Hunter, feature heavily in the attack narratives, as do implications that Biden is corrupt, a drug user and a liar.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<div id="attachment_16704"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-57/" rel="attachment wp-att-16704"><img decoding="async" aria-describedby="caption-attachment-16704" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57.png" alt="" width="924" height="979" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57.png 924w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57-283x300.png 283w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57-768x814.png 768w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57-100x106.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-57-600x636.png 600w" sizes="(max-width: 924px) 100vw, 924px"></a></p><p id="caption-attachment-16704">Figure 3: Examples of Spamouflage graphics targeting President Biden with negative narratives.</p></div>
<p><b><span data-contrast="auto">Ambiguous Trump narratives: </span></b><span data-contrast="auto">Narratives relating to Trump are noticeably less common than those relating to Biden. Interestingly many of them are also somewhat ambiguous – while the authors may intend them to be negative, Trump supporters might read many of them differently.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">The examples below, such as “Trump’s status as an anti-hero is making him unstoppable,” “Trump indicted again: America’s dark day” and “Twitter warrior” would potentially be received by Trump supporters as positive. It is unclear whether this ambiguity is intentional, or the result of a misapprehension on the part of the Chinese operators about the nature of Trump’s appeal to his supporters.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<div id="attachment_16705"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-59/" rel="attachment wp-att-16705"><img decoding="async" aria-describedby="caption-attachment-16705" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59.png" alt="" width="987" height="1085" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59.png 987w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59-273x300.png 273w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59-932x1024.png 932w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59-768x844.png 768w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59-100x110.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-59-600x660.png 600w" sizes="(max-width: 987px) 100vw, 987px"></a></p><p id="caption-attachment-16705">Figure 4: Examples of Spamouflage graphics sharing somewhat ambiguous narratives about former President Trump.</p></div>
<p><strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>Both candidates are too old, especially Biden: </span></span></strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>This narrative is </span><span>predominately targeted</span><span> at </span><span>Biden, but</span><span> has been featured as a separate narrative here because it does in some cases refer to both presumptive presidential candidates as too old.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<div id="attachment_16706"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-60/" rel="attachment wp-att-16706"><img decoding="async" aria-describedby="caption-attachment-16706" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60.png" alt="" width="873" height="485" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60.png 873w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60-300x167.png 300w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60-768x427.png 768w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60-100x56.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-60-600x333.png 600w" sizes="(max-width: 873px) 100vw, 873px"></a></p><p id="caption-attachment-16706">Figure 5: Examples of Spamouflage graphics sharing somewhat ambiguous narratives about former President Trump.</p></div>
<p><strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>Election fairness and integrity: </span></span></strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>As of January 2024, casting doubt on the integrity and fairness of the election itself does not appear to be a major focus of the campaign (yet). A </span><span> amount</span><span> of content is focused on this narrative</span><span> – for example, in </span><span>the month of January</span><span> 2024 one Spamouflage account posted 21 times, with just one post focused on this topic</span><span>. It is nonetheless a </span><span>narrative </span><span>to watch for </span><span>given the experience with the 2020 election and the array of conspiracy theories and hyper-partisan polarisation around the issue of election integrity in 2024.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<div id="attachment_16707"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-61/" rel="attachment wp-att-16707"><img decoding="async" aria-describedby="caption-attachment-16707" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-61.png" alt="" width="628" height="420" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-61.png 628w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-61-300x201.png 300w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-61-100x67.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-61-600x401.png 600w" sizes="(max-width: 628px) 100vw, 628px"></a></p><p id="caption-attachment-16707">Figure 6: Examples of Spamouflage graphics sharing narratives relating to electoral integrity.</p></div>
<p><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span><strong>Abortion:</strong> </span></span><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>As of January 2024</span><span>,</span><span> there is </span><span>relatively little</span><span> content relating to specific policy issues in the context of the election. The exception to this is the issue of abortion, which has been the subject of a small amount of content which claims that Biden is not doing enough to protect abortion rights, while Trump will </span><span>ban</span> <span>the right to an abortion on a federal basis</span><span>.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<div id="attachment_16708"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-63/" rel="attachment wp-att-16708"><img decoding="async" aria-describedby="caption-attachment-16708" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-63.png" alt="" width="533" height="480" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-63.png 533w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-63-300x270.png 300w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-63-100x90.png 100w" sizes="(max-width: 533px) 100vw, 533px"></a></p><p id="caption-attachment-16708">Figure 7: Examples of Spamouflage graphics with narratives relating to abortion policy.</p></div>
<p><strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>Civic and urban decay: </span></span></strong><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span><span lang="EN-AU" xml:lang="EN-AU" data-contrast="auto"><span>There is a lot of content portraying the state of the US as dire, with a rampant opioid crisis, mass homelessness, out</span><span>–</span><span>of</span><span>–</span><span>control gun violence and other social malaises. This content is not currently placing these issues in a partisan or electoral context, however.</span></span></span></span></p>
<div id="attachment_16709"><p><a href="https://www.isdglobal.org/digital_dispatches/pro-ccp-spamouflage-net-work-focuses-on-us-election/untitled-design-66/" rel="attachment wp-att-16709"><img decoding="async" aria-describedby="caption-attachment-16709" src="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-66.png" alt="" width="762" height="432" srcset="https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-66.png 762w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-66-300x170.png 300w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-66-100x57.png 100w, https://www.isdglobal.org/wp-content/uploads/2024/02/Untitled-design-66-600x340.png 600w" sizes="(max-width: 762px) 100vw, 762px"></a></p><p id="caption-attachment-16709">Figure 8: Examples of Spamouflage graphics containing negative representations about the state of homelessness and drug abuse in the US.</p></div>
<h4>Discussion</h4>
<p><span data-contrast="auto">There is no indication that these fairly standard election-related efforts by Spamouflage are, as a whole, having any more success at generating real engagement than their previous campaigns. Most tweets receive either no engagement and very low numbers of views, or are only engaged with by other accounts which appear to be a part of the Spamouflage network.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">Nonetheless, these narratives provide a useful window into the approach which CCP propaganda operations are taking at this early stage in the US electoral cycle: amplifying dismay and division; attacking President Biden including through personal smears and disinformation; and seemingly soft-pedalling on former President Trump. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>
<p><span data-contrast="auto">While this business-as-usual approach is generating the usual level of returns (i.e. none), a small number of Spamouflage accounts appear to be experimenting with different strategies. A future Dispatch will explore this partial shift in tactics and its implications.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:256}">&nbsp;</span></p>

					</div>


				

			</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coding in Vision Pro (306 pts)]]></title>
            <link>https://willem.com/blog/2024-02-16_vision-pro/</link>
            <guid>39403935</guid>
            <pubDate>Fri, 16 Feb 2024 22:37:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willem.com/blog/2024-02-16_vision-pro/">https://willem.com/blog/2024-02-16_vision-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=39403935">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content">
	
	<h2 itemprop="subheading">Exploring Spatial Computing</h2>
	
	<p>Currently, I am overlooking a lake at Mount Hood while writing this. I hear birds in the distance and see the lake calm, with subtle waves and some mist in the distance. Yet, it is fake, as I am sitting on our top floor, a barely furnished room full of items belonging to a family house with two young kids. I am using Apple's Vision Pro to explore what Spatial Computing can be. I am in awe; let me explain in this blog post.</p>

	<a name="continue" id="continue"></a>
	<a name="Writing this blog post at Mount Hood..." title="Writing this blog post at Mount Hood..." href="https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_3000px.png"><figure><img alt="Writing this blog post at Mount Hood..." src="https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_500px.png" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_500px.png 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_640px.png 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_720px.png 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_750px.png 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_960px.png 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1000px.png 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1080px.png 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1125px.png 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1440px.png 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1536px.png 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_1920px.png 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_00_Writing-this-blog-post-at-Mount-Hood_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Writing this blog post at Mount Hood...</figcaption></figure></a><a name="... not! Just our attic full of " family="" stuff""="" title="... not! Just our attic full of " href="https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_3000px.png"><figure><img alt="... not! Just our attic full of " family="" stuff""="" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_500px.png" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_500px.png 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_640px.png 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_720px.png 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_750px.png 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_960px.png 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1000px.png 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1080px.png 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1125px.png 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1440px.png 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1536px.png 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_1920px.png 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_01_not-Just-our-attic-full-of-family-stuff_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>... not! Just our attic full of "family stuff"</figcaption></figure></a><h3>Apple Vision Pro</h3><p>Imagine a set of great earphones for listening to music, offering you private access to high-quality audio playback. The Apple Vision Pro is like that, but for your eyes instead of your ears. You put it on like a set of goggles, and inside, you see a digital world blending with your reality. You can choose to let the real outer world in or filter it out, much like how active noise cancelling works for audio. </p><a name="Apple Vision Pro, like a good set of earphones for your eyes" title="Apple Vision Pro, like a good set of earphones for your eyes" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_3000px.jpg"><figure><img alt="Apple Vision Pro, like a good set of earphones for your eyes" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_02_Apple-Vision-Pro-like-a-good-set-of-earphones-for-your-eyes_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Apple Vision Pro, like a good set of earphones for your eyes</figcaption></figure></a><p>Using some very advanced chips, sensors, and cameras, the Apple Vision Pro headset is capable of projecting virtual objects into your real world, positioning them in a fixed place where they stay as long as you want them there. You can do things like watching a movie on a gigantic cinema display or immersing yourself in your family's photos. Or, you can use the Vision Pro for work, as I do, using a window where I type my text, right at the lakeside of Mount Hood.</p><p>Other websites and blogs have posted some very in-depth discussions on Apple Vision Pro, discussing the hardware, its advantages, and disadvantages. I recommend you check those out as I do not want to repeat what others have written or said. Some reviews worth your time:</p><ul><li><a href="https://www.youtube.com/watch?v=UvkgmyfMPks" title="Casey Neistat - The thing no one will say about Apple Vision Pro" target="_blank">Casey Neistat - The thing no one will say about Apple Vision Pro</a></li><li><a href="https://www.theverge.com/24054862/apple-vision-pro-review-vr-ar-headset-features-price" title="Nilay Patel - Apple Vision Pro review: magic, until it's not" target="_blank">Nilay Patel - Apple Vision Pro review: magic, until it's not</a></li><li><a href="https://om.co/2024/01/31/my-4-magic-moments-with-vision-pro/#more-922524" title="Om Malik - My 4 magic moments with Vision Pro" target="_blank">Om Malik - My 4 magic moments with Vision Pro</a></li></ul><a name="Hello World - a selfie of sorts" title="Hello World - a selfie of sorts" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_3000px.jpg"><figure><img alt="Hello World - a selfie of sorts" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_03_Hello-World-a-selfie-of-sorts_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Hello World - a selfie of sorts</figcaption></figure></a><h3>Spatial Computing</h3><p>More than this particular first generation of hardware, I am interested in what Apple is showing the world with its VisionOS software. It's not just a fancy wearable projector; it's interactive! Cameras on the inside track your iris position, i.e., where you're exactly looking. This information is used to enable interaction with the digital world by just looking at things. A subtle tap with your fingers is registered by another set of cameras, all seamlessly integrating an experience that enables you to "look and tap" like you would otherwise do with "point and click" or "touch and swipe".</p><p>This fundamental interaction model is very well executed; after a few minutes, it feels totally natural, and I have since been wondering why my iPhone or iPad does not respond in the same manner. It's classic Apple magic as all the heavy lifting is done without giving me much (if any) friction. It just works.</p><a name="Bluetooth keyboard and trackpad connected to Vision Pro" title="Bluetooth keyboard and trackpad connected to Vision Pro" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_3000px.jpg"><figure><img alt="Bluetooth keyboard and trackpad connected to Vision Pro" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_04_Bluetooth-keyboard-and-trackpad-connected-to-Vision-Pro_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Bluetooth keyboard and trackpad connected to Vision Pro</figcaption></figure></a><p>To get some work done, I have connected a standard bluetooth keyboard and trackpad to the Vision Pro, leveraging my ability to touch type; it all feels very natural. The Vision Pro does not require a computer; it is the computer! It features quite capable <a href="https://willem.com/blog/2020-12-15_why-apple-silicon-is-a-big-deal/" title="Apple Silicon chips" target="_blank">Apple Silicon chips</a>, and plenty of onboard storage (mine has 1 TB).</p><a name="You're looking at a fully capable computer system here - and a cup of coffee" title="You're looking at a fully capable computer system here - and a cup of coffee" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_3000px.jpg"><figure><img alt="You're looking at a fully capable computer system here - and a cup of coffee" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_05_You-re-looking-at-a-fully-capable-computer-system-here-and-a-cup-of-coffee_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>You're looking at a fully capable computer system here - and a cup of coffee</figcaption></figure></a><p>If you have been reading my blog, you know <a href="https://willem.com/blog/tablet/" title="I have a thing for tablets" target="_blank">I have a thing for tablets</a> as they are portable yet very capable. The Vision Pro might be another step forward: it is very portable, yet it offers an entire virtual world for your eyes! It's like being able to carry a massive multi-monitor setup with me; it's bonkers!</p><a name="Not that crazy: display, keyboard, trackpad (note the hovering piece of UI above the hardware keyboard)" title="Not that crazy: display, keyboard, trackpad (note the hovering piece of UI above the hardware keyboard)" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_3000px.jpg"><figure><img alt="Not that crazy: display, keyboard, trackpad (note the hovering piece of UI above the hardware keyboard)" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_06_Not-that-crazy-display-keyboard-trackpad-note-the-hovering-piece-of-UI-above-the-hardware-keyboard_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Not that crazy: display, keyboard, trackpad (note the hovering piece of UI above the hardware keyboard)</figcaption></figure></a><a name="You can easily arrange a multi-monitor work setup like this" title="You can easily arrange a multi-monitor work setup like this" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_3000px.jpg"><figure><img alt="You can easily arrange a multi-monitor work setup like this" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_07_You-can-easily-arrange-a-multi-monitor-work-setup-like-this_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>You can easily arrange a multi-monitor work setup like this</figcaption></figure></a><a name="It is hard to capture in a 2D photo, but for your eyes, there is real depth in the setup, like those two screens are really there" title="It is hard to capture in a 2D photo, but for your eyes, there is real depth in the setup, like those two screens are really there" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_3000px.jpg"><figure><img alt="It is hard to capture in a 2D photo, but for your eyes, there is real depth in the setup, like those two screens are really there" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_08_It-is-hard-to-capture-in-a-2D-photo-but-for-your-eyes-there-is-real-depth-in-the-setup-like-those-tw_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>It is hard to capture in a 2D photo, but for your eyes, there is real depth in the setup, like those two screens are really there</figcaption></figure></a><a name="You can look around them, move closer to them, or rearrange them by dragging them through your room" title="You can look around them, move closer to them, or rearrange them by dragging them through your room" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_3000px.jpg"><figure><img alt="You can look around them, move closer to them, or rearrange them by dragging them through your room" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_09_You-can-look-around-them-move-closer-to-them-or-rearrange-them-by-dragging-them-through-your-room_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>You can look around them, move closer to them, or rearrange them by dragging them through your room</figcaption></figure></a><a name="The projections appear so natural that my mind is really convinced it can touch things." title="The projections appear so natural that my mind is really convinced it can touch things." href="https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_3000px.jpg"><figure><img alt="The projections appear so natural that my mind is really convinced it can touch things." src="https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_10_The-projections-appear-so-natural-that-my-mind-is-really-convinced-it-can-touch-things_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The projections appear so natural that my mind is really convinced it can touch things.</figcaption></figure></a><p>Mixing the digital and real world is very accessible; it allows you to stay aware of things around you. I like it as it makes you feel a little less "enclosed inside the computer". It works for certain workflows, like sending some emails, looking things up, or making a call. The experience gets a little different if you decide to immerse yourself in any of the Vision Pro's virtual environments.</p><p>Some folks refer to it as <a href="https://calnewport.com/" title="" deep="" work""="" target="_blank">"deep work"</a>, the type of work you need some serious focus for. I find Vision Pro especially powerful for getting myself into the state of flow that is needed for the heavy lifting. I can immerse myself with context (images, logs, code, mockups) and filter out any visual clutter from the real world.</p><a name="These windows represent different views on a particular piece of work - they are big, the tall window in the center is approximately 3 meters high!" title="These windows represent different views on a particular piece of work - they are big, the tall window in the center is approximately 3 meters high!" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_3000px.jpg"><figure><img alt="These windows represent different views on a particular piece of work - they are big, the tall window in the center is approximately 3 meters high!" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_11_These-windows-represent-different-views-on-a-particular-piece-of-work-they-are-big-the-tall-window-i_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>These windows represent different views on a particular piece of work - they are big, the tall window in the center is approximately 3 meters high!</figcaption></figure></a><a name="The 'smallest' window from above is in fact very large; for comparison of scale, I removed the virtual moon surface so you can see the window next to my little daughter's shoes." title="The 'smallest' window from above is in fact very large; for comparison of scale, I removed the virtual moon surface so you can see the window next to my little daughter's shoes." href="https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_3000px.png"><figure><img alt="The 'smallest' window from above is in fact very large; for comparison of scale, I removed the virtual moon surface so you can see the window next to my little daughter's shoes." src="https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_500px.png" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_500px.png 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_640px.png 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_720px.png 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_750px.png 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_960px.png 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1000px.png 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1080px.png 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1125px.png 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1440px.png 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1536px.png 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_1920px.png 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_12_The-smallest-window-from-above-is-in-fact-very-large-for-comparison-of-scale-I-removed-the-virtual-m_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The 'smallest' window from above is in fact very large; for comparison of scale, I removed the virtual moon surface so you can see the window next to my little daughter's shoes.</figcaption></figure></a><p>Imagine a set of windows so big that you can literally stand between them. That is how I like my most powerful Vision Pro setups. You almost become one with your context, seriously. You can create an environment that enables you to really connect with what you're doing. I love walking around the windows, looking at some code or server output, and sort of getting a feel of it being a "big and working machine". In a way, it feels like standing in a big machine room. It is really unlike any conventional desktop experience.</p><a name="Again, it is very hard to capture in a 2D photo, but being able to walk around your digital context is simply incredible!" title="Again, it is very hard to capture in a 2D photo, but being able to walk around your digital context is simply incredible!" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_3000px.png"><figure><img alt="Again, it is very hard to capture in a 2D photo, but being able to walk around your digital context is simply incredible!" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_500px.png" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_500px.png 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_640px.png 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_720px.png 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_750px.png 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_960px.png 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1000px.png 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1080px.png 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1125px.png 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1440px.png 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1536px.png 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_1920px.png 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_13_Again-it-is-very-hard-to-capture-in-a-2D-photo-but-being-able-to-walk-around-your-digital-context-is_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Again, it is very hard to capture in a 2D photo, but being able to walk around your digital context is simply incredible!</figcaption></figure></a><a name="These windows are really big, conveying a sense of greatness like a statue of some kind" title="These windows are really big, conveying a sense of greatness like a statue of some kind" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_3000px.png"><figure><img alt="These windows are really big, conveying a sense of greatness like a statue of some kind" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_500px.png" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_500px.png 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_640px.png 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_720px.png 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_750px.png 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_960px.png 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1000px.png 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1080px.png 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1125px.png 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1440px.png 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1536px.png 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_1920px.png 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_14_These-windows-are-really-big-conveying-a-sense-of-greatness-like-a-statue-of-some-kind_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>These windows are really big, conveying a sense of greatness like a statue of some kind</figcaption></figure></a><a name="If you're in a virtual environment, the Vision Pro will warn you if you risk walking into something - which can be a real hazard if you're sharing the house with some kids, ha!" title="If you're in a virtual environment, the Vision Pro will warn you if you risk walking into something - which can be a real hazard if you're sharing the house with some kids, ha!" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_3000px.jpg"><figure><img alt="If you're in a virtual environment, the Vision Pro will warn you if you risk walking into something - which can be a real hazard if you're sharing the house with some kids, ha!" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_15_If-you-re-in-a-virtual-environment-the-Vision-Pro-will-warn-you-if-you-risk-walking-into-something-w_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>If you're in a virtual environment, the Vision Pro will warn you if you risk walking into something - which can be a real hazard if you're sharing the house with some kids, ha!</figcaption></figure></a><h3>Conclusion</h3><p>I will continue to explore, learn, and experiment with Vision Pro, but already I'm blown away by the spatial greatness of actually seeing the 3rd dimension digitally. It feels very natural in the same sense as the touchscreen on the original iPhone made me giggle whenever I swiped the "slide to unlock" slider. There is a lot to unlock here; come and join me on this next frontier!</p><a name="Talking about hazards... drinking coffee is a real challenge with Vision Pro - ha!" title="Talking about hazards... drinking coffee is a real challenge with Vision Pro - ha!" href="https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_3000px.jpg"><figure><img alt="Talking about hazards... drinking coffee is a real challenge with Vision Pro - ha!" src="https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_500px.jpg" srcset="https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_500px.jpg 500w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_640px.jpg 640w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_720px.jpg 720w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_750px.jpg 750w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_960px.jpg 960w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1000px.jpg 1000w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1080px.jpg 1080w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1125px.jpg 1125w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1440px.jpg 1440w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1536px.jpg 1536w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_1920px.jpg 1920w,
		https://willem.com/blog/2024-02-16_vision-pro/images/i_16_Talking-about-hazards-drinking-coffee-is-a-real-challenge-with-Vision-Pro-ha_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Talking about hazards... drinking coffee is a real challenge with Vision Pro - ha!</figcaption></figure></a>

	

	

<div id="support">
	<h2>Did you enjoy this post?</h2>
	<p>If you found this content useful, <br>consider showing your appreciation<br>
   		by buying me a coffee ❤️😋: </p>
	

</div> 



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plastic industry knew recycling was a farce for decades (325 pts)]]></title>
            <link>https://www.euronews.com/green/2024/02/16/plastic-industry-knew-recycling-was-a-farce-for-decades-yet-deceived-the-public-report-rev</link>
            <guid>39402917</guid>
            <pubDate>Fri, 16 Feb 2024 21:01:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.euronews.com/green/2024/02/16/plastic-industry-knew-recycling-was-a-farce-for-decades-yet-deceived-the-public-report-rev">https://www.euronews.com/green/2024/02/16/plastic-industry-knew-recycling-was-a-farce-for-decades-yet-deceived-the-public-report-rev</a>, See on <a href="https://news.ycombinator.com/item?id=39402917">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        Plastic producers should ‘pay for the damage they’ve caused’ after decades of deception, the report's authors say.
    </p><div><p>Recycling has been promoted as a solution to plastic waste management for more than 50 years.</p><p>But big oil companies and the plastics industry have known for decades that it’s not a technically or economically viable solution, a new report reveals.</p><p>Combining existing research and recently revealed internal documents, the <a href="https://link.mediaoutreach.meltwater.com/ls/click?upn=gIoWfh-2Bn5LP0cn0rygzp0Tg5H5-2BG0RVe5jOnsOcbKZr97eARXVajHCLMXu-2B-2BuNbrLyLIsgpIMflWConAtiH0Xg-3D-3DOmK5_bzPBhLuwedBm-2FZoquoPyYZKkavStAiQNZWV6QsStIQ2YQW3RyosK3A7kGcIUqi07J401ksFUB0G8XPqMYmuEFJS2pgGOkyzboJw70k3OmA4NIuYk-2B-2BGV5CZlR1f1TGZFY6Q8wqmuamrm-2BG5y8HloWzf4-2FtiVbSyiA7O8XrX1etnrWO5Hemx-2Fj-2BNiDaEIr4iXQ2-2FCGvoBeVOD10gY6g2m4mMDzbJjkmN1Yj5vjiwmzHIGHsMJXdiAK9kupIL1XiOpQaUbSEpciED5kNDJZQVmc-2BUOHLrLMZYImvaxdqczwSVur4RUZMvLjqkfW94pavUqv8H3xezrqgHuwapmm7EERiBkLqFYYIJ3xKLFNDGh5yqx6swEr4CwyYjGOdRkY1IMf86kQyqadzmjNYqMrAxODg-3D-3D"><strong>report</strong></a> by the Center for Climate Integrity Research (CCI) could form the foundation for legal action, its authors say.</p><p>“When corporations and trade groups know that their products pose grave risks to society, and then lie to the public and policymakers about it, they must be held accountable,” says CCI President Richard Wiles.</p><p>“Accountability means stopping the lying, telling the truth, and paying for the damage they’ve caused.”</p><h2>Plastic producers misled the public about recycling</h2><p>The report unveils the fraudulent marketing and public education campaigns used to promote <a href="https://www.euronews.com/green/2023/07/28/international-plastic-overshoot-day-which-countries-are-best-at-recycling-the-polluting-ma"><strong>plastic</strong></a> as recyclable, despite knowing that it is not a workable solution.</p><p>These strategies allowed the <a href="https://www.euronews.com/green/2023/01/09/a-drop-in-the-ocean-england-bans-some-single-use-plastics-but-does-it-go-far-enough"><strong>single-use plastics</strong></a> industry to expand, while avoiding regulation to effectively address waste and pollution, the report says.</p><p>“Recycling cannot be considered a permanent solid waste solution [to <a href="https://www.euronews.com/green/2023/10/02/england-bans-single-use-plastic-what-is-and-isnt-included-in-the-new-rules"><strong>plastics</strong></a>], as it merely prolongs the time until an item is disposed of,” reads a 1986 report by industry trade group the Vinyl Institute (VI).</p><p>The group’s founding director, Roy Gottesman, highlighted the issue again in 1989 at a conference, warning, “Recycling cannot go on indefinitely, and does not solve the solid waste problem.”</p><h2>Why is plastic so hard to recycle?</h2><p>With thousands of different types used in everyday products, plastic is expensive to collect and sort. It also degrades after just one or two uses, becoming more toxic each time it is repurposed.</p><p>Despite knowing this, oil and <a href="https://www.euronews.com/green/2023/10/03/how-is-europe-faring-in-the-fight-against-plastic-pollution"><strong>plastics</strong></a> companies pushed forward with campaigns promoting recycling.</p><p>Picture the triangle of ‘chasing arrows’ symbol to denote that packaging is <a href="https://www.euronews.com/green/2023/06/05/can-i-recycle-that-expert-advice-on-the-most-searched-household-items"><strong>recyclable</strong></a>, for example. This was introduced even though the VI had noted that the system was unlikely to work due to the trend towards composite containers, made up of multiple types of plastic.</p><p>“We are committed to the activities, but not committed to the results,” Exxon Chemical Vice President Irwin Levowitz said in a 1994 meeting with the American Plastics Council (APC).</p><p>The following year, internal notes from an APC staffer acknowledged the impossibility of <a href="https://www.euronews.com/green/2023/10/17/italy-belgium-latvia-which-european-countries-recycle-the-most"><strong>recycled</strong></a> plastic competing with virgin materials. “Virgin supplies will go up sharply in [the] near future [and] kick the shit out of PCR [Post-Consumer Recycled material] prices,” they wrote.</p><h2>How could companies be held legally accountable for lies about plastic recycling?</h2><p>This public deception could be a violation of laws designed to protect consumers and the public from corporate misconduct and pollution, according to the report’s authors.</p><p>“Attorneys general and other officials should carefully consider the evidence that these companies defrauded the public and take appropriate action to hold them accountable,” says Alyssa Johl, CCI’s vice president of legal and general counsel.</p><p>It adds to a growing list of complaints against plastics producers, including a 2022 California investigation into ExxonMobil’s role in the plastic pollution crisis, and New York suing Pepsi Co in 2023 over plastic pollution.</p><h2>Is it still worth recycling plastic?</h2><p>The best way to reduce plastic pollution is to <a href="https://www.euronews.com/green/2024/01/24/do-plastic-bag-bans-work-new-study-finds-they-save-6-billion-bags-a-year-in-some-us-states"><strong>avoid</strong></a> single-use plastics entirely. However, it is still better to recycle plastic at home than throw it away.</p><p>Around nine per cent of the world’s annual <a href="https://www.euronews.com/green/2023/01/11/new-solar-powered-technology-can-transform-plastic-waste-into-sustainable-fuels-and-cosmet"><strong>plastic waste</strong></a> is successfully recycled, and with many companies committing to using recycled plastic in their products, it can find a purpose.</p><p>Under the European Strategy for Plastics in the Circular Economy, the target is that 10 million tonnes of recycled <a href="https://www.euronews.com/green/2023/06/06/refill-stores-and-bottle-deposit-schemes-inside-the-un-goal-to-cut-plastic-pollution-by-80"><strong>plastics</strong></a> find their way into products in the EU by 2025. Almost 26 million tonnes of plastic waste is generated in Europe every year.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How did the settlers of the Canary Islands survive a millennium of isolation? (204 pts)]]></title>
            <link>https://www.science.org/content/article/humans-survive-alone-1000-years-desert-islands-off-africa</link>
            <guid>39402906</guid>
            <pubDate>Fri, 16 Feb 2024 21:00:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/humans-survive-alone-1000-years-desert-islands-off-africa">https://www.science.org/content/article/humans-survive-alone-1000-years-desert-islands-off-africa</a>, See on <a href="https://news.ycombinator.com/item?id=39402906">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/humans-survive-alone-1000-years-desert-islands-off-africa: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The majority of traffic from X may have been fake during the Super Bowl (245 pts)]]></title>
            <link>https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic</link>
            <guid>39402876</guid>
            <pubDate>Fri, 16 Feb 2024 20:58:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic">https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic</a>, See on <a href="https://news.ycombinator.com/item?id=39402876">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-ga-module="content_body">
<div>
<p><img src="https://helios-i.mashable.com/imagery/articles/04W7APqOwuVUT4NgKBjz1hQ/hero-image.fill.size_1248x702.v1708016894.jpg" alt="Elon Musk" width="1248" height="702" srcset="https://helios-i.mashable.com/imagery/articles/04W7APqOwuVUT4NgKBjz1hQ/hero-image.fill.size_400x225.v1708016894.jpg 400w, https://helios-i.mashable.com/imagery/articles/04W7APqOwuVUT4NgKBjz1hQ/hero-image.fill.size_800x450.v1708016894.jpg 800w, https://helios-i.mashable.com/imagery/articles/04W7APqOwuVUT4NgKBjz1hQ/hero-image.fill.size_1248x702.v1708016894.jpg 1600w" sizes="(max-width: 1280px) 100vw, 1280px"></p><p><span>New data shows that X has a bot problem unlike any other.</span>
<span>Credit: Beata Zawrzel/NurPhoto via Getty Images</span>
</p>
</div>
<article id="article" data-autopogo="">
<p>This week, Super Bowl 2024 shattered records, with the NFL championship broadcast on CBS becoming the <a href="https://www.cbssports.com/nfl/news/cbs-sports-super-bowl-lviii-broadcast-is-most-watched-telecast-in-history-123-4-million-tune-in/" target="_blank" title="(opens in a new window)"><u>most-watched</u></a> televised event in U.S. history.</p><p>Also riding high from the big game? Elon Musk's X. The company formerly known as Twitter published its own <a href="https://business.x.com/en/blog/super-bowl-lviii-smashes-records-on-x.html" target="_blank" title="(opens in a new window)"><u>press release</u></a>, lauding Super Bowl LVIII as one of the biggest events ever on the social media platform with more than <a href="https://twitter.com/XBusiness/status/1757428067482415518" target="_blank" title="(opens in a new window)"><u>10 billion impressions</u></a> and over 1 billion video views.</p><blockquote>
<a href="https://twitter.com/XBusiness/status/1757428067482415518" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<p>However, it appears that a significant portion of that traffic on X could be fake, according to data provided to Mashable by CHEQ, a leading cybersecurity firm that tracks bots and fake users.</p><p>According to CHEQ, a whopping 75.85 percent of traffic from X to its advertising clients' websites during the weekend of the Super Bowl was fake.</p>
<p>"I've never seen anything even remotely close to 50 percent, not to mention 76 percent," <a href="https://cheq.ai/" target="_blank" title="(opens in a new window)">CHEQ</a> founder and CEO Guy Tytunovich told Mashable regarding X's fake traffic data. "I'm amazed…I've never, ever, ever, ever seen anything even remotely close."</p><p>CHEQ's data for this report is based on 144,000 visits to its clients' sites that came from X during Super Bowl weekend, from Friday, Feb. 9 up until the end of Super Bowl Sunday on Feb. 11. The data was collected from across CHEQ's 15,000 total clients. It's a small portion of the relevant data, and it's not scientifically sampled, but it nonetheless suggests a dramatic trend.</p><p>CHEQ monitors bots and fake users across the internet in order to minimize online ad fraud for its clients. Tytunovich's company accomplishes this by tracking how visitors from different sources, such as X, interact with a client's page after they click one of their links. The company can also tell when a bot is passing itself off as a real user, such as when a fraudulent user is faking what type of operating system they are using to view a website. </p><p>Most X users who are regularly on the platform can attest to a noticeable uptick in seemingly inauthentic activity in recent months. When a post goes viral on X, its now commonplace to find bots filling the replies with AI-generated responses or accounts with randomly generated usernames spamming a user's mentions with unsolicited "link-in-bio" promotions. Now, there's data which backs up that user experience.</p><p>Advertisers have also noticed X's bot issues. In a recently published piece in <a href="https://www.theguardian.com/business/2024/feb/15/x-paid-post-promotion-advertising" target="_blank" title="(opens in a new window)"><em>The Guardian</em></a>, Gene Marks, a small business owner shared his ad campaign results from X. After a small $50 advertising spend, X's analytics shows that his website had received 350 clicks from approximately 29,000 views. However, according to Google Analytics, X wasn't the source of any of the actual traffic his website had received during that time period. </p><p>In our conversation with Tytunovich, he referenced an <a href="https://mashable.com/article/report-claims-half-facebook-maus-fake" target="_self"><u>often cited stat</u></a> that roughly <a href="https://securitytoday.com/articles/2023/05/17/report-47-percent-of-internet-traffic-is-from-bots.aspx" target="_blank" title="(opens in a new window)"><u>half of all internet traffic</u></a> is made up of bots, and how he's long been skeptical of that data based on what CHEQ itself sees.</p><p>"We were always the conservative ones," Tytunovich explained regarding CHEQ's approach to fake user data. "We protect a lot of our customers on Google Ads, YouTube, and even TikTok, which I'm not a fan of, and we've always said 50 percent [being fake] is a bit opportunistic."</p><p>"I almost decided not to go out [and publish the X bot data] because we've never seen anything like it," he said.</p><h2><strong>X has a bot problem unlike anything else seen on competing platforms</strong></h2><p>When X's Super Bowl traffic is compared to other social media platforms during the same time period, the bot issue on Musk's platform appears even more stark. CHEQ also provided data to Mashable pertaining to Facebook, Instagram, and TikTok. In terms of fake traffic, no other platform came close to X's nearly 76 percent.&nbsp;</p><p>Out of more than 40 million visits from TikTok, only 2.56 percent were determined to be fake. Facebook sent 8.1 million visits and 2.01 percent of the monitored visits were classified as inauthentic. And over on Instagram, only 0.73 percent of the 68,700 visits from the platform were fake.</p><p>Tytunovich tells Mashable that it's not out of the ordinary to see spikes in fake traffic on social media platforms during big events like U.S. elections. However, he has never seen anything close to X's 75.85 percent.</p><p>And, unfortunately for X, its bot problem goes beyond the big game too.</p><p>CHEQ also provided Mashable with fake traffic data from the entire month of January 2024. TikTok, Facebook, and Instagram all had very similar stats to each platform's respective Super Bowl weekend numbers. Slightly more than 2.8 percent of the 306 million visits sent from TikTok were determined to be fake. Out of the 90 million visits that came from Facebook, a bit more than 2 percent were fake. And Instagram's traffic was only 0.96 percent fake, based on 749,000 visits.</p><p>But, X once again fared the worst. Of the 759,000 visits from X, 31.82 percent of that traffic was determined to be fake.</p>
<p>Tytunovich, who has met with Musk previously and pushed the X owner to address the bot problem, stressed to Mashable that his company cannot tell how many fake users are on social media platforms themselves. The data only details how many bots came to CHEQ's clients' sites from those platforms.&nbsp;</p><p>However, as Tytunovich explained, his company has a wide range of clients, including large, Fortune 500 companies, and this fake activity coming from X was seen across the board regardless of industry or market.</p><p>Mashable reached out to X for information or a statement but received an automated message from the company reading "Busy now, please check back later."</p><h2><strong>An Elon Musk problem</strong></h2><p>X didn't always have a bot problem of this magnitude, according to CHEQ, something Tytunovich demonstrated by providing Mashable with data from last year's Super Bowl. During the comparable weekend in February 2023, fake traffic from the platform then-known as Twitter only accounted for 2.81 percent out of 159,000 visits. That's around 72 percent less than this year's game.</p><p>Last year's Super Bowl occurred just a few months after Elon Musk acquired the platform in late October of 2022. And a lot has changed on X between last February and today under Musk's leadership. The platform was still known as Twitter then. Notable users still had their <a href="https://mashable.com/article/twitter-blue-check-verified-removal-internet-reactions" target="_self"><u>legacy verified blue checkmarks</u></a>. Only around 200,000 to 300,000 users were subscribed to <a href="https://mashable.com/article/twitter-blue-subscriptions-lower" target="_self"><u>Twitter Blue</u></a>, which is now called X Premium. X's creator monetization program, where paying X Premium subscribers can make money off of ads displaying on their content, <a href="https://mashable.com/article/twitter-x-creator-fund-ad-revenue-sharing" target="_self"><u>did not yet exist</u></a>. All of these changes can factor into X's current bot problem. </p><p>In addition, since Musk's take over, <a href="https://www.forbes.com/sites/thomasbrewster/2024/01/10/elon-musk-fired-80-per-cent-of-twitter-x-engineers-working-on-trust-and-safety/?sh=78cf52a779b3" target="_blank" title="(opens in a new window)"><u>80 percent</u></a> of the company's Trust and Safety team's engineers have been laid off, along with half of the company's content moderators.&nbsp;Thousands of employees have been <a href="https://www.cnn.com/2023/04/12/tech/elon-musk-bbc-interview-twitter-intl-hnk/index.html" target="_blank" title="(opens in a new window)">laid off</a> across the company.</p><p>X has struggled with advertisers since Musk's takeover. Big brands and major companies <a href="https://mashable.com/article/elon-musk-twitter-x-advertisers-fk-yourselves" target="_self"><u>like Disney</u></a> have suspended ad campaigns on the platform due to hate speech and pro-Nazi content proliferating on X, as well as <a href="https://mashable.com/article/apple-suspends-x-twitter-advertising-elon-musk-antisemitic-conspiracy" target="_self"><u>antisemitic comments</u></a> made by Musk himself. According to a <a href="https://www.bloomberg.com/news/articles/2024-01-27/musk-s-x-pledges-100-person-office-in-texas-to-police-content" target="_blank" title="(opens in a new window)"><em><u>Bloomberg</u></em></a> report last month, X is planning to open a <a href="https://mashable.com/article/x-twitter-hiring-content-moderators-trust-and-safety-center-austin" target="_self"><u>Trust and Safety center</u></a> in Austin, Texas and is hiring 100 employees to work in that department in order to address some of advertisers' concerns.</p><p>But, X's problems clearly go well beyond the type of content being posted by real human beings. Advertisers typically pay social media companies based on impressions and/or clicks on their advertisements. And based on this traffic data, advertisers could potentially be paying Musk and company for visits from an audience consisting mostly of bots.</p>

</article>
</section><div x-data="window.newsletter()" x-init="init()" data-ga-impression="" data-ga-category="newsletters" data-ga-module="footer_nl_signup" data-ga-label="Top Stories">

<p>
This newsletter may contain advertising, deals, or affiliate links. Subscribing to a newsletter indicates your consent to our <a href="https://www.ziffdavis.com/terms-of-use" target="_blank" rel="noopener" title="(opens in a new window)">Terms of Use</a> and <a href="https://www.ziffdavis.com/ztg-privacy-policy" target="_blank" rel="noopener" title="(opens in a new window)">Privacy Policy</a>. You may unsubscribe from the newsletters at any time.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recording and visualising the 20k system calls it takes to "import seaborn" (106 pts)]]></title>
            <link>http://blog.mattstuchlik.com/2024/02/16/counting-syscalls-in-python.html</link>
            <guid>39402868</guid>
            <pubDate>Fri, 16 Feb 2024 20:57:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://blog.mattstuchlik.com/2024/02/16/counting-syscalls-in-python.html">http://blog.mattstuchlik.com/2024/02/16/counting-syscalls-in-python.html</a>, See on <a href="https://news.ycombinator.com/item?id=39402868">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Last time we <a href="http://blog.mattstuchlik.com/2024/02/08/counting-cpu-instructions-in-python.html">counted CPU
instructions</a>,
let’s look at <a href="https://en.wikipedia.org/wiki/System_call">syscalls</a> now!</p>

<p>I’ll show you a little tiny tool I added to
<a href="https://github.com/s7nfo/Cirron">Cirron</a> that lets you see exactly what
syscalls a piece of Python code is calling and how to analyze the trace more effectively.</p>

<p>Let’s start with <code>print("Hello")</code> as before:</p>
<div><pre><code><span>from</span> <span>cirron</span> <span>import</span> <span>Tracer</span>

<span>t</span> <span>=</span> <span>Tracer</span><span>()</span>

<span>t</span><span>.</span><span>start</span><span>()</span>
<span>print</span><span>(</span><span>"Hello"</span><span>)</span>
<span>trace</span> <span>=</span> <span>t</span><span>.</span><span>end</span><span>()</span>

<span>print</span><span>(</span><span>trace</span><span>)</span>
<span># write(1, "Hello\n", 6) = 6 &lt;0.000150s&gt;
</span></code></pre></div>

<p>You can see<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" rel="footnote">1</a></sup> <code>print</code> uses only a single
<a href="https://man7.org/linux/man-pages/man2/write.2.html">write</a> to write the string
<code>"Hello\n"</code> to stdout (that’s what the <code>1</code> stands for) and asks it to write at
most <code>6</code> bytes. Write then returns <code>6</code>, meaning it managed to write all the
bytes we asked it to. You can also see it took 0.00015s or 150μs (that’s just the
<code>write</code> call, not the whole <code>print</code> statement).</p>

<p>Pretty cool!</p>

<p>How does <code>Tracer</code> work? I initially wanted to use the
<a href="https://man7.org/linux/man-pages/man2/ptrace.2.html">ptrace</a> syscall to
implement it, but that turned out to be a little more complicated that what I
wanted, so in the end I just used the <code>strace</code> tool, which also uses <code>ptrace</code>
but handles all the complexity. <code>Tracer</code> simply <a href="https://github.com/s7nfo/Cirron/blob/master/cirron/tracer.py#L138">starts tracing
itself</a> with
it, redirecting output to a file, which is then parsed when it’s asked to stop.</p>

<p>Let’s trace <code>import seaborn</code> now:</p>
<div><pre><code><span>from</span> <span>cirron</span> <span>import</span> <span>Tracer</span>

<span>t</span> <span>=</span> <span>Tracer</span><span>()</span>

<span>t</span><span>.</span><span>start</span><span>()</span>
<span>import</span> <span>seaborn</span>
<span>trace</span> <span>=</span> <span>t</span><span>.</span><span>end</span><span>()</span>

<span>print</span><span>(</span><span>len</span><span>(</span><span>trace</span><span>))</span>
<span># 20462
</span></code></pre></div>

<p>Turns out importing Seaborn takes ~20k syscalls! That’s obviously too many to
just print out, so what’s a better way to analyze what it’s doing?</p>

<h2 id="visualizing-traces-with-perfetto">Visualizing traces with Perfetto</h2>

<p><a href="https://ui.perfetto.dev/">Perfetto Trace Viewer</a> let’s you visualize all kinds
of traces. It can’t ingest <code>strace</code> output directly, but I’ve included a
function that converts Tracer output to <a href="https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/preview">Trace Event
Format</a>,
something Perfetto can load:</p>

<div><pre><code><span>from</span> <span>cirron</span> <span>import</span> <span>to_tef</span>

<span>(...)</span>

<span>open</span><span>(</span><span>"/tmp/trace"</span><span>,</span> <span>"w"</span><span>).</span><span>write</span><span>(</span><span>to_tef</span><span>(</span><span>trace</span><span>))</span>
</code></pre></div>



<p>This gets you a file you can open with Perfetto. I’m not going to describe all it can do; I uploaded a trace of <code>import seaborn</code> <a href="https://gist.github.com/s7nfo/4cda90818a07d851fea79c8c17e8eab8">here</a>, go <a href="https://ui.perfetto.dev/">play with it</a>!</p>



<p><img src="http://blog.mattstuchlik.com/assets/perfetto.png" alt="Perfetto"></p>



<p>I was surprised to find it uses 4 threads, which mostly spend time looking up files and reading them, but one of the threads seems to be very curious about your CPU details!</p>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Driftmania – an open source PICO-8 racing game (256 pts)]]></title>
            <link>https://frenchie14.itch.io/driftmania</link>
            <guid>39402142</guid>
            <pubDate>Fri, 16 Feb 2024 19:55:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frenchie14.itch.io/driftmania">https://frenchie14.itch.io/driftmania</a>, See on <a href="https://news.ycombinator.com/item?id=39402142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Tiny Tracks. Fast Laps</h2>

<p>Driftmania is an arcade time trial racing game. Your goal is to get the fastest possible time on each of the 15 challenging tracks</p>
<p><strong>Controls (Racing)</strong></p>
<ul><li><strong>Up Arrow or Z</strong>: Accelerate</li><li><strong>Down Arrow:&nbsp;</strong>Brake&nbsp;+ Reverse</li><li><strong>Left Arrow:</strong>&nbsp;Turn left</li><li><strong>Right Arrow:</strong> Turn right</li><li><strong>X:&nbsp;</strong>D-Brake</li><li><strong>R:</strong>&nbsp;Restart level</li><li><strong>P:</strong> Pause game + Options menu</li></ul><p><strong>Controls (Menu)</strong></p><ul><li><strong>Arrow keys</strong>:&nbsp;navigate selection</li><li><strong>Z or X</strong>:&nbsp;Select</li></ul>
<p><strong>Tips</strong></p>
<ul><li>You turn faster when holding the D-Brake</li><li>Take a good look at the minimap before starting a track. You need to anticipate the turns to get the best times</li><li>Grass does not slow you down. It reduces traction, which you can use to your advantage for drifting!<br>
</li><li>Driving over yellow tiles will activate boost. Boost works with whatever direction you're facing - it doesn't matter where the arrow on the ground is pointing</li><li>Garage customizations do not change car handling. Make your car look however you want it to!</li><li>An optional ghost can be enabled in the pause menu. <strong>Replays are lost when exiting a track</strong><br>
</li></ul>
<p><strong>Credits</strong><br></p>
<ul><li>Created by <a href="https://twitter.com/MaxBize" referrerpolicy="origin" rel="nofollow noopener">Max Bize</a></li><li>Music by <a href="https://twitter.com/VAVMUSICMAGIC" referrerpolicy="origin" rel="nofollow noopener">Vav</a></li><li>Cars (based on) art by <a href="https://twitter.com/PixelArtM" referrerpolicy="origin" rel="nofollow noopener">PixelArtM</a></li><li>Cover art by <a href="https://twitter.com/TerracotaScarf" target="_blank" referrerpolicy="origin" rel="nofollow noopener">TerracotaScarf</a></li></ul>
<p><strong>I'm running a $150 speedrun tournament now until March 3rd. Want to compete? </strong><a href="https://discord.gg/bNTC82Jb" target="_blank" referrerpolicy="origin" rel="nofollow noopener">Join the Discord</a></p>
<p>You can follow more of my game development <a href="https://twitter.com/MaxBize" target="_blank" referrerpolicy="origin" rel="nofollow noopener">on Twitter</a><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paying people to work on open source is good (315 pts)]]></title>
            <link>https://jacobian.org/2024/feb/16/paying-maintainers-is-good/</link>
            <guid>39402101</guid>
            <pubDate>Fri, 16 Feb 2024 19:52:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobian.org/2024/feb/16/paying-maintainers-is-good/">https://jacobian.org/2024/feb/16/paying-maintainers-is-good/</a>, See on <a href="https://news.ycombinator.com/item?id=39402101">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><em>Warning: rant ahead. I’m writing from a place of frustration and not particularly interested in trying to moderate my tone. If you don’t want to hear me yell about open source for a while, please skip this one.</em></p><hr><p>Earlier this week, in a moment of frustration. I <a href="https://social.jacobian.org/@jacob/111914179201102152">wrote on Mastodon</a>:</p><blockquote><p>“We believe that open source should be sustainable and open source maintainers should get paid!”</p><p>Maintainer: *introduces commercial features*
“Not like that”</p><p>Maintainer: *works for a large tech co*
“Not like that”</p><p>Maintainer: *takes investment*
“Not like that”</p></blockquote><p>This went mildly viral, and I got a ton of arguments and pushback. (Also a lot of “right on"s, which was nice.) I think some of that pushback was bad-faith and uncharitable reads, but some was coming from well-intentioned misunderstandings or misreadings of my snarky toot. That’s my fault for talking around what I mean instead of coming out and saying it. So that’s this post: upgrading my shitpost to a slightly-more-considered rant.</p><p>My fundamental position is that <strong>paying people to work on open source is good</strong>, full stop, no exceptions. <strong>We need to stop criticizing maintainers getting paid, and start celebrating.</strong> Yes, all of the mechanisms are flawed in some way, but that’s because <em>the world</em> is flawed, and it’s not the fault of the people taking money. Yelling at maintainers who’ve found a way to make a living is wrong.</p><h2 id="why-this-matters">Why this matters</h2><p>This is of course a personal issue: I’ve been involved in open source communities for over twenty years now and have many colleagues and friends from those communities who would love nothing more than to make open source their jobs. Most can’t, and that sucks. Those who can end up getting nastygrams criticizing their financial choices and questioning their morality.</p><p>But it’s deeper that that. Open source is <em>good for humanity</em>. It’s only slightly hyperbolic to say that open source is one of the most notable collective successes of humankind as a species! It’s one of the few places where essentially all of humanity works together on something that benefits everyone. A world without open source would be substantially worse than the world we live in.</p><p>So, I want people who want to work on open source to be able to do so, and should be able to live comfortable lives, with their basic needs met. They’re contributing to something that is good for humanity; they shouldn’t have to sacrifice to do so!</p><h2 id="definitions">Definitions</h2><p>Part of the problem with The Discourse is a lack of shared agreement on what the core terms mean. Because I used the term “open source” in my original toot, one of the themes in the replies are people misinterpreting what I mean by “open source” (or, even more exhausting, relitigating the “open source vs free software” debate).</p><p>So if I’m going to have half a chance of explaining what I really mean I need to start by defining what these terms mean to me:</p><h3 id="open-source--free-software">“open source” / “free software”</h3><p>Note the deliberate use of lower case. I’m <em>not</em> referring to Open Source™ as defined by OSI, nor to Free Software™ as defined by the FSF<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. I mean these terms in the broadest, most inclusive sense: “software with source code that I can read and modify and release variants of, perhaps under some conditions.” So I’m including OSI and FSF licenses, but also the <a href="https://polyformproject.org/licenses/">Polyform licenses</a> and the <a href="https://www.json.org/license.html">JSON license</a> and, yes <a href="https://mariadb.com/bsl-faq-mariadb/">BSL</a> in my version of “open source”.</p><p>This is perhaps a side point, but the “minimalist” definition of Open Source meaning “only OSI-approved licenses” – or, worse, “the GPL is the only ’true’ Free Software license” – is part of the problem here. I want to see more experimentation and variety in licensing options, and if that means introducing some additional restrictions beyond “anyone can use this for any purpose” I’m pretty okay with that. In my book, a broad spectrum of licenses from <a href="https://blueoakcouncil.org/license/1.0.0">Blue Oak</a> to <a href="https://mariadb.com/bsl-faq-mariadb/">BSL</a> (and even more restrictive) “count” as open source.</p><p>So, in this piece, I’m going to use “open source” to mean anything on this spectrum from “totally unencumbered” to “unencumbered with some restrictions”, and I’m not going to articulate how much “some” would be too much for something to still be considered free. I’ll even use the terms “open source” and “free software” interchangeably just to hammer home how, in this context, the precise definitions of these terms don’t matter to me.</p><p>This stance probably really annoys some folks, and that’s to some degree intentional. Not in the sense that I want to deliberately piss anyone off, but … I’ll put it this way: if my sloppy use of these terms bothers you <em>in the context of talking about how people make their living</em>, it implies that you care more about terminology and definitions than about the people, and I’d like you to sit in that discomfort for a while.</p><h3 id="sustainability">“sustainability”</h3><p>Next, what do I mean when I talk about “sustainability” in open source? People use this term to mean lots of things – good governance, healthy communities, funding, and more.</p><p>When I talk about “sustainability”, though, I mean something very specific: “can maintainers live a decent-to-comfortable lifestyle writing free software?” If open source was “sustainable”, to me, it would mean that people could chose to make writing open source their job, and be assured that they have <em>at a minimum</em> their basic needs met – housing, food, healthcare, etc. Ideally, more than that; I’d love it if writing open source afforded people a comfortable or downright luxurious lifestyle.</p><h2 id="open-source-is-not-sustainable">Open source is not sustainable</h2><p>Almost nobody makes a living writing free software. As a percentage of all software engineers, it’s so few we can basically round down to zero.</p><p>Sure, there are a few companies that employ people to work on open source: Canonical, Red Hat, Hashicorp, and Mozilla come to mind; I’m sure you could name more. But, (a) these companies employ vanishingly few engineers when compared to the millions of engineers out there writing proprietary software and (b) it’s not like every engineer at each of these organizations actually writes only open source; almost all these organizations have business models dependent on some piece of the product being proprietary. So even the biggest open source success stories represent a fraction of a fraction.</p><p>Closer to home, let’s look at Django. By my estimate hundreds of thousands of engineers use Django daily. How many get paid to work on Django itself? <strong>One and a half</strong> – the DSF employs one full-time and one part-time Fellow. That’s the entire population of people who get paid just to work on Django. The numbers are similar to Python itself: millions of people use Python daily, but fewer than a dozen are paid to do so<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>“Sustainability” would mean that something like a dozen people were being paid to work full-time on Django – and being paid something approaching the industry median. It would mean <em>several</em> dozen people working full-time on Python. Heck, just <a href="https://pypi.org/">PyPI</a> by itself ought to have a team of 10-15, <em>minimum</em>, given its scope, scale, and importance.</p><p>Even more importantly, “sustainability” in open source would mean that the <a href="https://xkcd.com/2347/">“random person in Nebraska”</a> maintaining a critical dependency would be living handsomely, and would have several colleagues so they could get a vacation from time to time.</p><p>We don’t live in a world that even remotely approaches this.</p><h2 id="the-dream-fully-automated-luxury-gay-space-communism">The dream: fully automated luxury gay space communism</h2><p>This is usually the point where someone snarkily points out, “you don’t really hate open source, you hate capitalism”. This is one of those statements that is true, but not helpful.</p><p>Yes, the fact that people have to choose between writing open source software and affording decent healthcare is a problem deeply rooted in our current implementation of zero-sum capitalism, and not at all a problem that can be laid at the feet of the free software movement. The dream is that society and governments will recognize free software as the public good that it most certainly is and fund it appropriately. And also fix healthcare, and housing access, and public transportation, and the social safety net, and and and …</p><p>I am absolutely one million percent on board with this vision, but this shit ain’t gonna happen overnight. Indeed, I doubt it’ll happen in our lifetimes if at all.</p><p>We have to accept the world as it is – even if it’s not the world we want. This means we have to be okay with the idea that maintainers need to be paid. Far too often I see arguments like: “maintainers shouldn’t be paid by private companies because the government should be supporting them.” Sure, this sounds great – but <em>governments aren’t doing this!</em> So this argument reduces to “open source maintainers shouldn’t be paid”. I can’t get on board with that.</p><h2 id="any-time-someone-gets-paid-to-write-open-source-its-a-win">Any time someone gets paid to write open source it’s a win</h2><p>Right now, here in the real world, <strong>sustainability in open source means paying maintainer — and we should be celebrating every time that happens!</strong> Every time a maintainer finds a way to get paid, it’s a win.</p><p>Employed by Microsoft to work on Python? <strong>Win.</strong></p><p>Funded by a grant? <strong>Win.</strong></p><p>Reached a sustainable funding level on Patreon? <strong>Win.</strong></p><p>Raises VC funding to develop free software? <strong>Win.</strong></p><p>Builds a sustainable business on an Open Core model? <strong>Win.</strong></p><p>Hashicorp? <strong>Win.</strong></p><p>Supports an open project with paid hosting options? <strong>Win.</strong></p><p>Successfully uses a non-OSI-approved license to avoid being Amazon’d? <strong>Win.</strong></p><p><strong>Until we have fully automated luxury gay space communism every. single. person. who figures out a mechanism to write free software and still pay rent represents a win and we should celebrate accordingly.</strong></p><h2 id="instead-criticism">Instead, criticism</h2><p>But that’s not what happens. Instead, every time a maintainer finds a way to get paid, people show up to criticize and complain. Non-OSI licenses “don’t count” as open source. Someone employed by Microsoft is “beholden to corporate interests” and not to be trusted. Patreon is “asking for handouts”. Raising money through GitHub sponsors is “supporting Microsoft’s rent-seeking”. VC funding means we’re being set up for a “rug pull” or “enshitification”. Open Core is “bait and switch”.</p><p>None of this is hypothetical; each of these examples are actual things I’ve seen said about maintainers who take money for their work. One maintainer even told me he got criticized for selling t-shirts!</p><p>Look. There are absolutely problems with every tactic we have to support maintainers. It’s true that VC investment comes with strings attached that often lead to problems down the line. It sucks that Patreon or GitHub (and Stripe) take a cut of sponsor money. The additional restrictions imposed by PolyForm or the BSL really do go against the <a href="https://en.wikipedia.org/wiki/The_Free_Software_Definition">Freedom 0</a> ideal. I myself am often frustrated by discovering that some key feature I want out of an open core tool is only available to paid licensees.</p><p><strong>But you can criticize these systems while still supporting and celebrating the maintainers!</strong> Yell at A16Z all you like, I don’t care. (Neither do they.) But yelling at a maintainer because they took money from a VC is directing that anger in the wrong direction. The structural and societal problems that make all these different funding models problematic aren’t the fault of the people trying to make a living doing open source.</p><p>It’s like yelling at someone for shopping at Dollar General when it’s the only store they have access to. Dollar General’s predatory business model absolutely sucks, as do the governmental policies that lead to food deserts, but none of that is on the shoulders of the person who needs milk and doesn’t have alternatives.</p><h2 id="purity-only-serves-to-limit-open-sources-value-to-society">Purity only serves to limit open source’s value to society</h2><p><strong>Many, many more people should be getting paid to write free software, but for that to happen we’re going to have to be okay accepting impure or imperfect mechanisms.</strong> Criticize those mechanisms if you like. Work to change the underlying societal inequities – please!</p><p>But when a maintainer finds a way to get paid, celebrate them. It’s a win for all of us.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hyrum's Law (132 pts)]]></title>
            <link>https://www.hyrumslaw.com</link>
            <guid>39401973</guid>
            <pubDate>Fri, 16 Feb 2024 19:42:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hyrumslaw.com">https://www.hyrumslaw.com</a>, See on <a href="https://news.ycombinator.com/item?id=39401973">Hacker News</a></p>
<div id="readability-page-1" class="page">

<em>An observation on Software Engineering</em>

<p>Put succinctly, the observation is this:</p>
<blockquote>With a sufficient number of users of an API,<br>
it does not matter what you promise in the contract:<br>
all observable behaviors of your system<br>
will be depended on by somebody.</blockquote>

<p>Over the past couple years of doing low-level infrastructure migrations in one of the most complex software systems on the planet, I’ve made some observations about the differences between an interface and its implementations.  We typically think of the interface as an abstraction for interacting with a system (like the steering wheel and pedals in a car), and the implementation as the way the system does its work (wheels and an engine).  This is useful for a number of reasons, foremost among them that most useful systems rapidly become too complex for a single individual or group to completely understand, and abstractions are essential to managing that complexity.</p>

<p>Defining the correct level of abstraction is a completely separate discussion (see Mythical Man-Month), but we like to think that once an abstraction is defined, it is concrete.  In other words, an interface should theoretically provide a clear separation between consumers of a system and its implementers.  In practice, this theory breaks down as the use of a system grows and its users start to rely upon implementation details intentionally exposed through the interface, or which they divine through regular use.  Spolsky’s “Law of Leaky Abstractions” embodies consumers’ reliance upon internal implementation details.</p>

<p>Taken to its logical extreme, this leads to the following observation, colloquially referred to as “The Law of Implicit Interfaces”: Given enough use, there is no such thing as a private implementation.  That is, if an interface has enough consumers, they will collectively depend on every aspect of the implementation, intentionally or not.  This effect serves to constrain changes to the implementation, which must now conform to both the explicitly documented interface, as well as the implicit interface captured by usage.  We often refer to this phenomenon as "bug-for-bug compatibility."</p>

<p>The creation of the implicit interface usually happens gradually, and interface consumers generally aren’t aware as it’s happening.  For example, an interface may make no guarantees about performance, yet consumers often come to expect a certain level of performance from its implementation.  Those expectations become part of the implicit interface to a system, and changes to the system must maintain these performance characteristics to continue functioning for its consumers.</p>

<p>Not all consumers depend upon the same implicit interface, but given enough consumers, the implicit interface will eventually exactly match the implementation.  At this point, the interface has evaporated: the implementation has become the interface, and any changes to it will violate consumer expectations.  With a bit of luck, widespread, comprehensive, and automated testing can detect these new expectations but not ameliorate them.</p>

<p>Implicit interfaces result from the organic growth of large systems, and while we may wish the problem did not exist, designers and engineers would be wise to consider it when building and maintaining complex systems.  So be aware of how the implicit interface constrains your system design and evolution, and know that for any reasonably popular system, the interface reaches much deeper than you think.</p>

<h3>Who's Hyrum?</h3>
<p>I'm a Software Engineer at Google, working on large-scale code change tooling and infrastructure.  Prior to that, I spent five years improving Google's core C++ libraries.  The above observation grew out of experiences when even the simplest library change caused failures in some far off system.</p>

<p>While I may have made the observation, credit goes to Titus Winters for actually naming it as "Hyrum's Law" and popularizing the concept more broadly.</p>

<a href="https://twitter.com/hyrumwright?ref_src=twsrc%5Etfw" data-show-count="false">Follow @hyrumwright</a>

<h3>History</h3>
<p>Obligatory XKCD: <a href="https://xkcd.com/1172/">https://xkcd.com/1172/</a></p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[If you're just going to sit there doing nothing, at least do nothing correctly (388 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20240216-00/?p=109409</link>
            <guid>39401598</guid>
            <pubDate>Fri, 16 Feb 2024 19:11:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20240216-00/?p=109409">https://devblogs.microsoft.com/oldnewthing/20240216-00/?p=109409</a>, See on <a href="https://news.ycombinator.com/item?id=39401598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="featured">
                         <p>
            February 16th, 2024</p><!-- .entry-meta -->
        <p>There may be times where you need to make an API do nothing. It’s important to have it do nothing in the correct way.</p>
<p>For example, Windows has an extensive printing infrastructure. But that infrastructure does not exist on Xbox. What should happen if an app tries to print on an Xbox?</p>
<p>Well, the wrong thing to do is to have the printing functions throw a <code>Not­Supported­Exception</code>. The app that the user installed on the Xbox was probably tested primarily, if not exclusively, on a PC, where printing is always available. When run on an Xbox, the exception will probably go unhandled, and the app will crash. Even if the app tried to catch the exception, it would probably display a message like “Oops. That went badly. Call support and provide this incident code.”</p>
<p>A better design for “supporting” printing on Xbox is to have the printing functions succeed, but report that there are no printers installed. With this behavior, when the app tries to print, it will ask the user to select a printer, and show an empty list. The user realizes, “Oh, there are no printers,” and cancels the printing request.</p>
<p>To deal with apps that get fancy and say “Oh, you have no printers installed, let me help you install one,” the function for installing a printer can return immediately with a result code that means “The user cancelled the operation.”</p>
<p>The idea here is to have the printing functions all behave in a manner perfectly consistent with printing being fully supported, yet mysteriously there is never a printer to print to.</p>
<p>Now, you probably also want to add a function to check whether printing even works at all. Apps can use this function to hide the Print button from their UI if they are running on a system that doesn’t support printing at all. But naïve apps that assume that printing works will still behave in a reasonable manner: You’re just on a system that doesn’t have any printers and all attempts to install a printer are ineffective.</p>
<p>The name we use to describe this “do nothing” behavior is “inert”.</p>
<p>The API surface still exists and functions according to its specification, but it also does nothing. The important thing is that it does nothing in a way that is consistent with its documentation and is least likely to create problems with existing code.</p>
<p>Another example is the retirement of an API that has a variety of functions for creating widget handles, other functions that accept widget handles, and a function for closing widget handles. The team that was doing the retirement originally proposed making the API inert as follows:</p>
<pre>HRESULT CreateWidget(_Out_ HWIDGET* widget)
{
    *widget = nullptr;
    return S_OK;
}

// Every widget is documented to have at least one alias,
// so we have to produce one dummy alias (empty string).
HRESULT GetWidgetAliases(
    _Out_writes_to_(capacity, *actual) PWSTR* aliases,
    UINT capacity,
    _Out_ UINT* actual)
{
    *actual = 0;

    RETURN_HR_IF(
        HRESULT_FROM_WIN32(ERROR_MORE_DATA),
        capacity &lt; 1);

    aliases[0] = make_cotaskmem_string_nothrow(L"").release();
    RETURN_IF_NULL_ALLOC(aliases[0]);

    *actual = 1;
    return S_OK;
}

// Inert widgets cannot be enabled or disabled.
HRESULT EnableWidget(HWIDGET widget, BOOL value)
{
    return E_HANDLE;
}

HRESULT Close(HWIDGET widget)
{
    RETURN_HR_IF(E_INVALIDARG, widget != nullptr);
    return S_OK;
}
</pre>
<p>I pointed out that having <code>Create­Widget</code> succeed but return a null pointer is going to confuse apps. “The call succeeded, but I didn’t get a valid handle back?” I even found some of their own test code that checked whether the handle was null to determine whether the call succeeded, rather than checking the return value.</p>
<p>I also pointed out that having <code>Enable­Widget</code> return “invalid handle” is also going to create confusion. An app calls <code>Create­Widget</code>, and it succeeds, and it takes that handle (which is presumably valid) and tries to use it to enable a widget, and it’s told “That handle isn’t valid.” How can that be? “I asked for a widget, and you gave me one, and then when I showed it to you, you said, ‘That’s not a widget.’ This API is <a href="https://en.wikipedia.org/wiki/Gaslighting"> gaslighting</a> me!”</p>
<p>I looked through the existing documentation for their API and found that a documented return value is <code>ERROR_<wbr>CANCELLED</code> to mean that the user cancelled the creation of the widget. Therefore, apps are already dealing with the possibility of widgets not being created due to conditions outside their control, so we can take advantage of that: Any time the app tries to create a widget, just say “Nope, the, uh, user cancelled, yeah, that’s what happened.”</p>
<pre>HRESULT CreateWidget(_Out_ HWIDGET* widget)
{
    *widget = nullptr;
    return HRESULT_FROM_WIN32(ERROR_CANCELLED);
}

HRESULT GetWidgetAliases(
    _Out_writes_to_(capacity, *actual) PWSTR* aliases,
    UINT capacity,
    _Out_ UINT* actual)
{
    *actual = 0;
    return E_HANDLE;
}

HRESULT EnableWidget(HWIDGET widget, BOOL value)
{
    return E_HANDLE;
}

HRESULT Close(HWIDGET widget)
{
    return E_HANDLE;
}
</pre>
<p>Now we have a proper inert API surface.</p>
<p>If you try to create a widget, we tell you that we couldn’t because the user cancelled. Since all attempts to create a widget fail, there is no such thing as a valid widget handle, and any time you try to use one, we tell you that the handle is invalid.</p>
<p>This also avoids the problem of having to produce dummy aliases for widgets. Since there <i>are no widgets</i>, there is no legitimate case where an app could ask a widget for its aliases.</p>
<p><b>Bonus chatter</b>: To clear up some confusion: The idea here is that the printing API has always existed on desktop, where printing is supported, and the “get me the list of printers” function is documented not to throw an exception. If you want to port the printing API to Xbox, how do you do it in a way that allows existing desktop apps to continue to run on Xbox? The inert behavior is completely truthful: There are no printers on an Xbox. Nobody expects the answer to the question, “How many printers are there?” to be “How dare you ask me such a thing!”</p>
<p>Another scenario where you need to create an inert API surface is if you want to retire an existing API. How do you make the behavior of the API consistent with its contract while still doing nothing useful?</p>

        

        
		
        
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The seventh most popular easily understood unsolved problem on MathOverflow (168 pts)]]></title>
            <link>https://mathstodon.xyz/@johncarlosbaez/111942324712561452</link>
            <guid>39401487</guid>
            <pubDate>Fri, 16 Feb 2024 19:01:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathstodon.xyz/@johncarlosbaez/111942324712561452">https://mathstodon.xyz/@johncarlosbaez/111942324712561452</a>, See on <a href="https://news.ycombinator.com/item?id=39401487">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Universal Basic Income Has Been Tried over and over Again. It Works Every Time (117 pts)]]></title>
            <link>https://gizmodo.com/universal-basic-income-has-been-tried-over-and-over-aga-1851255547</link>
            <guid>39401071</guid>
            <pubDate>Fri, 16 Feb 2024 18:31:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/universal-basic-income-has-been-tried-over-and-over-aga-1851255547">https://gizmodo.com/universal-basic-income-has-been-tried-over-and-over-aga-1851255547</a>, See on <a href="https://news.ycombinator.com/item?id=39401071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><figure id="" data-id="70562640429882fc5f1c54e4485369f7" data-recommend-id="image://70562640429882fc5f1c54e4485369f7" data-format="jpg" data-width="4999" data-height="2812" data-lightbox="false" data-recommended="true" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/70562640429882fc5f1c54e4485369f7.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/70562640429882fc5f1c54e4485369f7.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/70562640429882fc5f1c54e4485369f7.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="70562640429882fc5f1c54e4485369f7" data-format="jpg" data-height="2812" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/70562640429882fc5f1c54e4485369f7.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Anita Pouchard Serra/Bloomberg<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="70562640429882fc5f1c54e4485369f7" data-recommend-id="image://70562640429882fc5f1c54e4485369f7" data-format="jpg" data-width="4999" data-height="2812" data-lightbox="false" data-recommended="true" data-hide="false"></span></figure><div><p> As AI becomes a bigger and bigger part of our lives, the threat of job automation becomes an increasing possibility for many people. Lately, there’s been a lot of talk about <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/we-might-finally-get-a-basic-income-1843342132&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/we-might-finally-get-a-basic-income-1843342132">universal basic income</a></span>, the experimental form of welfare distribution that gives unconditional cash payments to people so that they can meet their  basic needs. Tech billionaires like Sam Altman say they’re <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/sam-altmans-worldcoin-wants-to-give-you-crypto-in-excha-1847192579&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/sam-altmans-worldcoin-wants-to-give-you-crypto-in-excha-1847192579">big fans of UBI</a></span> and claim that it could solve the problem of mass job displacement when robots and software take over much of our economy. </p><p>Let’s put aside Sam’s visions of a dystopian future; UBI might just be a great idea for our country to try, anyway. There have been many, many UBI pilot programs over the past few decades, and every time they’re conducted, they make the people who receive payments happier and healthier. UBI is an idea with a long history, stretching back decades. Let’s take a quick look back at some of the experiments that have been run and the impact that they’ve had. </p></div></div><div><figure id="" data-id="b4641b0c0a51e86eede2447c7a48df15" data-recommend-id="image://b4641b0c0a51e86eede2447c7a48df15" data-format="jpg" data-width="4427" data-height="2491" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/b4641b0c0a51e86eede2447c7a48df15.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/b4641b0c0a51e86eede2447c7a48df15.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/b4641b0c0a51e86eede2447c7a48df15.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="b4641b0c0a51e86eede2447c7a48df15" data-format="jpg" data-height="2491" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/b4641b0c0a51e86eede2447c7a48df15.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Bettmann<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="b4641b0c0a51e86eede2447c7a48df15" data-recommend-id="image://b4641b0c0a51e86eede2447c7a48df15" data-format="jpg" data-width="4427" data-height="2491" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><div><p>Richard Nixon launched <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://jacobin.com/2016/05/richard-nixon-ubi-basic-income-welfare/&quot;,{&quot;metric25&quot;:1}]]" href="https://jacobin.com/2016/05/richard-nixon-ubi-basic-income-welfare/" target="_blank" rel="noopener noreferrer">a UBI program</a></span> in 1969 that was tested on a small number of communities. The program was designed to deliver an ongoing, unconditional payment to working families to assist them with their basic needs. Hilariously, one of the people put in charge of these pilots <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/931291/dick-cheney-and-donald-rumsfeld-ran-a-universal-basic-income-experiment-for-president-richard-nixon&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/931291/dick-cheney-and-donald-rumsfeld-ran-a-universal-basic-income-experiment-for-president-richard-nixon" target="_blank" rel="noopener noreferrer">was Donald Rumsfeld</a></span>, who was working in Nixon’s Office of Economic Opportunity at the time. Rumsfeld also brought on Dick Cheney to help him with the program (later, of course, the duo <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://www.theonion.com/what-i-got-right-about-the-iraq-war-1850249194&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theonion.com/what-i-got-right-about-the-iraq-war-1850249194">would go on to disastrously run</a></span> Bush II’s White House foreign policy team and embroil America in pointless wars). </p><p>Fears that the experiment would engender laziness in participants <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://thecorrespondent.com/4503/the-bizarre-tale-of-president-nixon-and-his-basic-income-bill/173117835-c34d6145&quot;,{&quot;metric25&quot;:1}]]" href="https://thecorrespondent.com/4503/the-bizarre-tale-of-president-nixon-and-his-basic-income-bill/173117835-c34d6145" target="_blank" rel="noopener noreferrer">were not borne out in the project’s findings</a></span>: “The ‘laziness’ contention is just not supported by our findings,” the chief data analyst of one of the experiments said. “There is not anywhere near the mass defection the prophets of doom predicted.” </p><p>Due to their success, Nixon’s experiments evolved into broader plans to institute a national UBI that would have delivered <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://jacobin.com/2016/05/richard-nixon-ubi-basic-income-welfare/&quot;,{&quot;metric25&quot;:1}]]" href="https://jacobin.com/2016/05/richard-nixon-ubi-basic-income-welfare/" target="_blank" rel="noopener noreferrer">as much as $1600 a year</a></span> to families of four (adjusted for inflation, that’s around $10,000 per family). This was known as the Family Assistance Plan, or FAP, which would’ve used something called a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://mitsloan.mit.edu/ideas-made-to-matter/negative-income-tax-explained&quot;,{&quot;metric25&quot;:1}]]" href="https://mitsloan.mit.edu/ideas-made-to-matter/negative-income-tax-explained" target="_blank" rel="noopener noreferrer">negative income tax</a></span> to fund the massive new welfare program. Nixon actually introduced comprehensive legislation to institute the program but it was thwarted by political headwinds. The program was eventually canceled. Nixon’s advisors, including, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theguardian.com/society/2018/feb/27/how-nixon-was-dissuaded-from-introducing-a-universal-basic-income&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theguardian.com/society/2018/feb/27/how-nixon-was-dissuaded-from-introducing-a-universal-basic-income" target="_blank" rel="noopener noreferrer">allegedly, Milton Friedman</a></span>, convinced him not to do it.</p></div></div><div><figure id="" data-id="0dfa0ec9bfae61298dbafac00fefd2fc" data-recommend-id="image://0dfa0ec9bfae61298dbafac00fefd2fc" data-format="jpg" data-width="5397" data-height="3037" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/0dfa0ec9bfae61298dbafac00fefd2fc.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/0dfa0ec9bfae61298dbafac00fefd2fc.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/0dfa0ec9bfae61298dbafac00fefd2fc.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="0dfa0ec9bfae61298dbafac00fefd2fc" data-format="jpg" data-height="3037" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/0dfa0ec9bfae61298dbafac00fefd2fc.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Bonnie Jo Mount/The Washington Post<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="0dfa0ec9bfae61298dbafac00fefd2fc" data-recommend-id="image://0dfa0ec9bfae61298dbafac00fefd2fc" data-format="jpg" data-width="5397" data-height="3037" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>The state of Alaska has one of the longest-running and <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://apnews.com/article/alaska-oil-wealth-fund-dividend-c512839da89902b06f39e87866733cf8&quot;,{&quot;metric25&quot;:1}]]" href="https://apnews.com/article/alaska-oil-wealth-fund-dividend-c512839da89902b06f39e87866733cf8" target="_blank" rel="noopener noreferrer">most successful basic income programs</a></span> in the world. The Alaska Permanent Fund delivers around $1,600 a year to every resident in the state and has done so for the past forty years. It does this by divvying up a certain percentage of the proceeds from surplus revenue derived from one of Alaska’s most vital resources: its oil and gas reserves. This dividend, as it’s called, is then sent unconditionally to state residents on an annual basis.  UBI proponents contend that this model—in which a valuable resource is treated as a shared economic asset—is <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.ucl.ac.uk/bartlett/public-purpose/sites/bartlett_public_purpose/files/berry_c_2023._the_case_for_a_universal_basic_dividend.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://www.ucl.ac.uk/bartlett/public-purpose/sites/bartlett_public_purpose/files/berry_c_2023._the_case_for_a_universal_basic_dividend.pdf" target="_blank" rel="noopener noreferrer">one of the more promising methods</a></span> by which basic income  could be scaled up to provide for a much larger, national system.</p></div><div><figure id="" data-id="11c584802400f6a6f37debc4fa381297" data-recommend-id="image://11c584802400f6a6f37debc4fa381297" data-format="jpg" data-width="6464" data-height="3636" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/11c584802400f6a6f37debc4fa381297.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/11c584802400f6a6f37debc4fa381297.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/11c584802400f6a6f37debc4fa381297.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="11c584802400f6a6f37debc4fa381297" data-format="jpg" data-height="3636" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/11c584802400f6a6f37debc4fa381297.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Fatih Aktas/Anadolu Agency<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="11c584802400f6a6f37debc4fa381297" data-recommend-id="image://11c584802400f6a6f37debc4fa381297" data-format="jpg" data-width="6464" data-height="3636" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>During the peak of the covid-19 pandemic, as many as <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.bloomberg.com/news/articles/2022-09-28/for-more-than-20-guaranteed-income-projects-the-data-is-in&quot;,{&quot;metric25&quot;:1}]]" href="https://www.bloomberg.com/news/articles/2022-09-28/for-more-than-20-guaranteed-income-projects-the-data-is-in" target="_blank" rel="noopener noreferrer">20 different U.S. cities</a></span> launched basic income pilots to bolster incomes during a time when job loss and economic downturns were rampant. The programs delivered as much as $1,000 a month to recipients, typically for as long as a full year. Data about the projects was collected by the Stanford Basic Income Lab, which compiled <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://guaranteedincome.us/&quot;,{&quot;metric25&quot;:1}]]" href="https://guaranteedincome.us/" target="_blank" rel="noopener noreferrer">a report</a></span> that showed the pilots had helped low to middle-income families meet their essential needs. Retail purchases comprised about 36 percent of the spending. Meanwhile, 31 percent of the proceeds went to food and groceries, while housing and transport received 9 percent. The other spending was distributed between things like healthcare, education, and travel. <br></p></div><div><figure id="" data-id="c3f49203470149348698f0611ac881b0" data-recommend-id="image://c3f49203470149348698f0611ac881b0" data-format="jpg" data-width="5641" data-height="3173" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/c3f49203470149348698f0611ac881b0.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/c3f49203470149348698f0611ac881b0.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/c3f49203470149348698f0611ac881b0.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="c3f49203470149348698f0611ac881b0" data-format="jpg" data-height="3173" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/c3f49203470149348698f0611ac881b0.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Al Drago/Bloomberg<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="c3f49203470149348698f0611ac881b0" data-recommend-id="image://c3f49203470149348698f0611ac881b0" data-format="jpg" data-width="5641" data-height="3173" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><div><p> The Baltimore Young Families Success Fund was <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://guaranteedincome.us/baltimore&quot;,{&quot;metric25&quot;:1}]]" href="https://guaranteedincome.us/baltimore" target="_blank" rel="noopener noreferrer">launched in 2022</a></span> by the city’s mayor with funding from the city, as well as the non-profit CASH Campaign of Maryland. The program, which was designed to cushion the blow from covid-related economic turmoil, has consistently delivered $1,000 a month to 200 participants and, as a result, has invested nearly $5 million in the community. Survey results <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.businessinsider.com/guaranteed-universal-basic-income-ubi-baltimore-young-families-success-fund-2023-11&quot;,{&quot;metric25&quot;:1}]]" href="https://www.businessinsider.com/guaranteed-universal-basic-income-ubi-baltimore-young-families-success-fund-2023-11" target="_blank" rel="noopener noreferrer">suggest that</a></span> participants spend the money on regular essentials, including groceries, car payments, and bills. </p><p>While not specifically organized around race, the experiment targeted mostly young, low-paid, African American residents, whose income <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://guaranteedincome.us/baltimore&quot;,{&quot;metric25&quot;:1}]]" href="https://guaranteedincome.us/baltimore" target="_blank" rel="noopener noreferrer">hovered around $15,000 a year</a></span>. One 21-year-old mother of two, for instance, said that she was <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://guaranteedincome.us/stories/baltimore-jewels&quot;,{&quot;metric25&quot;:1}]]" href="https://guaranteedincome.us/stories/baltimore-jewels" target="_blank" rel="noopener noreferrer">able to afford rent</a></span> as a result of the cash payment, whereas she had previously struggled to make ends meet. <br></p></div></div><div><figure id="" data-id="3eb63635da3b5f603c9502929eea044a" data-recommend-id="image://3eb63635da3b5f603c9502929eea044a" data-format="jpg" data-width="5303" data-height="2977" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/3eb63635da3b5f603c9502929eea044a.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/3eb63635da3b5f603c9502929eea044a.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/3eb63635da3b5f603c9502929eea044a.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="3eb63635da3b5f603c9502929eea044a" data-format="jpg" data-height="2977" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/3eb63635da3b5f603c9502929eea044a.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->NICK OTTO/AFP<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="3eb63635da3b5f603c9502929eea044a" data-recommend-id="image://3eb63635da3b5f603c9502929eea044a" data-format="jpg" data-width="5303" data-height="2977" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><div><p>The city of Stockton, California, began <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.stocktondemonstration.org/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.stocktondemonstration.org/" target="_blank" rel="noopener noreferrer">a UBI experiment</a></span> in 2019 that, by all available metrics, has been a big success. The SEED program, as it’s called, doled out monthly unconditional sums of $500 to 125 low-income participants for two years. </p><p>An analysis of the program <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.latimes.com/business/story/2021-03-06/stockton-study-universal-basic-income&quot;,{&quot;metric25&quot;:1}]]" href="https://www.latimes.com/business/story/2021-03-06/stockton-study-universal-basic-income" target="_blank" rel="noopener noreferrer">showed that</a></span> it helped improve the life experience of the people involved, who felt “healthier, showing less depression and anxiety and enhanced well-being” than people who had not received the funds. The <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://static1.squarespace.com/static/6039d612b17d055cac14070f/t/603ef1194c474b329f33c329/1614737690661/SEED_Preliminary+Analysis-SEEDs+First+Year_Final+Report_Individual+Pages+-2.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://static1.squarespace.com/static/6039d612b17d055cac14070f/t/603ef1194c474b329f33c329/1614737690661/SEED_Preliminary+Analysis-SEEDs+First+Year_Final+Report_Individual+Pages+-2.pdf" target="_blank" rel="noopener noreferrer">analysis</a></span> also showed that the extra cash was primarily used to pay for basic needs. Recipients spent the money mostly on food (such purchases comprised between 34-40 percent of the money spent), as well as retail merchandise, car care, utilities, insurance and medical expenses, as well as a very small amount of self-care. Stockton’s program is <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://calmatters.org/california-divide/2023/04/california-guaranteed-income/&quot;,{&quot;metric25&quot;:1}]]" href="https://calmatters.org/california-divide/2023/04/california-guaranteed-income/" target="_blank" rel="noopener noreferrer">credited with</a></span> having inspired other, similar pilot programs in other cities—particularly in California.</p></div></div><div><figure id="" data-id="1c9e9ed022b2bae69d004e663a000982" data-recommend-id="image://1c9e9ed022b2bae69d004e663a000982" data-format="jpg" data-width="3999" data-height="2249" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/1c9e9ed022b2bae69d004e663a000982.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/1c9e9ed022b2bae69d004e663a000982.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/1c9e9ed022b2bae69d004e663a000982.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="1c9e9ed022b2bae69d004e663a000982" data-format="jpg" data-height="2249" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/1c9e9ed022b2bae69d004e663a000982.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Ville Mannikko/Bloomberg<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="1c9e9ed022b2bae69d004e663a000982" data-recommend-id="image://1c9e9ed022b2bae69d004e663a000982" data-format="jpg" data-width="3999" data-height="2249" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><div><p>In 2017, Finland <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.dw.com/en/does-finland-show-the-way-to-universal-basic-income/a-53595886&quot;,{&quot;metric25&quot;:1}]]" href="https://www.dw.com/en/does-finland-show-the-way-to-universal-basic-income/a-53595886" target="_blank" rel="noopener noreferrer">launched a program</a></span> to give €560 ($616) a month to 2,000 unemployed citizens. The program, which lasted two years, was designed to replace traditional welfare systems in Finland that  put employment-related conditions on cash dispersals. Part of the program’s design was to see whether an unconditional basic income could net better rates of employment in participants than those in a traditional welfare program. </p><p>While the program’s results showed that it had a positive emotional impact on participants,  <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theguardian.com/world/2019/feb/08/finland-free-cash-experiment-fails-to-boost-employment&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theguardian.com/world/2019/feb/08/finland-free-cash-experiment-fails-to-boost-employment" target="_blank" rel="noopener noreferrer">it did not markedly improve employment rates for them</a></span>. As a result, some referred to the experiment as a “failure.” However, the experiment’s results also showed that a “no-strings-attached” basic income did not <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.aeaweb.org/articles?id=10.1257/pol.20200143&quot;,{&quot;metric25&quot;:1}]]" href="https://www.aeaweb.org/articles?id=10.1257/pol.20200143" target="_blank" rel="noopener noreferrer">markedly dissuade recipients from job-seeking or employment behavior</a></span>. Instead, it stayed roughly the same. <br></p></div></div><div><figure id="" data-id="950f14de5b2519a6eca40292f29c1497" data-recommend-id="image://950f14de5b2519a6eca40292f29c1497" data-format="jpg" data-width="3496" data-height="1966" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/950f14de5b2519a6eca40292f29c1497.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/950f14de5b2519a6eca40292f29c1497.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/950f14de5b2519a6eca40292f29c1497.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="950f14de5b2519a6eca40292f29c1497" data-format="jpg" data-height="1966" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/950f14de5b2519a6eca40292f29c1497.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->David McNew<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="950f14de5b2519a6eca40292f29c1497" data-recommend-id="image://950f14de5b2519a6eca40292f29c1497" data-format="jpg" data-width="3496" data-height="1966" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>The Compton Pledge was a UBI experiment that, as <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://time.com/6097523/compton-universal-basic-income/&quot;,{&quot;metric25&quot;:1}]]" href="https://time.com/6097523/compton-universal-basic-income/" target="_blank" rel="noopener noreferrer">Time puts it</a></span>, sought to test whether it could transcend its “status as a small research project in progressive Los Angeles and someday work as a nationwide program funded by taxpayers”. The Pledge <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://comptonpledge.org/about/&quot;,{&quot;metric25&quot;:1}]]" href="https://comptonpledge.org/about/" target="_blank" rel="noopener noreferrer">calls itself</a></span> the largest UBI experiment in the U.S. and says it releases “recurring cash relief to low-income residents for 2 years.” Participants interviewed about their experience with the program have noted their ability to pay for a variety of things that would have been out of reach without the program. Others even started businesses or non-profit organizations with the financial assistance that was provided.<strong>&nbsp;</strong>The program’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://f4gi.org/app/uploads/2022/10/VOCP.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://f4gi.org/app/uploads/2022/10/VOCP.pdf" target="_blank" rel="noopener noreferrer">final report</a></span> notes: “Residents used the additional funds to cover costs in times of sickness, start business ventures, and provide stable conditions for their families and communities.” The program was funded partially through private donations.</p></div><div><figure id="" data-id="86c1222936fc626693e06c57f76d006c" data-recommend-id="image://86c1222936fc626693e06c57f76d006c" data-format="jpg" data-width="8256" data-height="4644" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/86c1222936fc626693e06c57f76d006c.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/86c1222936fc626693e06c57f76d006c.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/86c1222936fc626693e06c57f76d006c.jpg"><img alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-chomp-id="86c1222936fc626693e06c57f76d006c" data-format="jpg" data-height="4644" data-alt="Image for article titled Universal Basic Income Has Been Tried Over and Over Again. It Works Every Time." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/86c1222936fc626693e06c57f76d006c.jpg"></picture></div><p><figcaption>Photo<!-- -->: <!-- -->Gerald Anderson/Anadolu<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="86c1222936fc626693e06c57f76d006c" data-recommend-id="image://86c1222936fc626693e06c57f76d006c" data-format="jpg" data-width="8256" data-height="4644" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><div><p>The world’s largest and longest-running UBI experiment was launched in Kenya in 2016 by the non-profit <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.givedirectly.org/?gad_source=1&amp;gclid=Cj0KCQiA5rGuBhCnARIsAN11vgRZWliBI7Kt9TOQiTg8q1_ifd64rBA8pp5TTtanxM2MOlKk24MoiCIaAqoJEALw_wcB&quot;,{&quot;metric25&quot;:1}]]" href="https://www.givedirectly.org/?gad_source=1&amp;gclid=Cj0KCQiA5rGuBhCnARIsAN11vgRZWliBI7Kt9TOQiTg8q1_ifd64rBA8pp5TTtanxM2MOlKk24MoiCIaAqoJEALw_wcB" target="_blank" rel="noopener noreferrer">GiveDirectly</a></span>. The organization, which doles out unconditional cash transfers to families living in extreme poverty, has committed as much as $30 million to thousands of people throughout Africa. The cash transfers <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.npr.org/sections/goatsandsoda/2023/12/07/1217478771/its-one-of-the-biggest-experiments-in-fighting-global-poverty-now-the-results-ar&quot;,{&quot;metric25&quot;:1}]]" href="https://www.npr.org/sections/goatsandsoda/2023/12/07/1217478771/its-one-of-the-biggest-experiments-in-fighting-global-poverty-now-the-results-ar" target="_blank" rel="noopener noreferrer">amount to a lump sum of $50 a month</a></span> for recipients—an amount that can go quite a long way to providing for basic needs. The program plans to continue sending money to recipients for as long as twelve years, making it the longest UBI experiment in existence. A recently <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://conference.nber.org/conf_papers/f192616.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://conference.nber.org/conf_papers/f192616.pdf" target="_blank" rel="noopener noreferrer">published report</a></span> on GiveDirectly’s efforts has shown that this style of welfare distribution can be much more effective than more traditional forms of distribution in alleviating poverty. Indeed, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.givedirectly.org/2023-ubi-results/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.givedirectly.org/2023-ubi-results/" target="_blank" rel="noopener noreferrer">initial results found</a></span> that the unconditional cash dispersal did not “disincentivize work” but, instead, made participants more economically resilient and entrepreneurial.  The <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://conference.nber.org/conf_papers/f192616.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://conference.nber.org/conf_papers/f192616.pdf" target="_blank" rel="noopener noreferrer">full report</a></span> on the experiment’s initial findings concludes: </p><blockquote data-type="BlockQuote"><p>Communities receiving UBI experienced substantial economic expansion—more enterprises, higher revenues, costs, and net revenues—and structural shifts, with the expansion concentrated in the non-agricultural sector. Labor supply did not change overall, but shifted out of wage employment and towards self-employment.</p></blockquote></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ledger: Stripe's system for tracking and validating money movement (120 pts)]]></title>
            <link>https://stripe.com/blog/ledger-stripe-system-for-tracking-and-validating-money-movement</link>
            <guid>39400581</guid>
            <pubDate>Fri, 16 Feb 2024 17:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stripe.com/blog/ledger-stripe-system-for-tracking-and-validating-money-movement">https://stripe.com/blog/ledger-stripe-system-for-tracking-and-validating-money-movement</a>, See on <a href="https://news.ycombinator.com/item?id=39400581">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>Last Black Friday to Cyber Monday, Stripe processed 300 million transactions with a total payment volume of $18.6B—and the Stripe API maintained greater than 99.999% availability. Underlying these metrics is our Global Payments and Treasury Network (GPTN) that manages the complexity of accepting payments, money storage, and money movement. Today, Stripe supports more than 135 currencies and payment methods through partnerships with local banks and financial networks in 185 countries. These entities provide different interfaces, data models, and behaviors, and Stripe continually manages this complexity so developers can quickly integrate the GPTN into their businesses.</p><p>Internally, Stripe needs to guarantee that what we expect to happen during payment processing actually happens for internal customers and external auditors of our data. We built Ledger, an immutable and auditable log, as a trustworthy system of record for all of our financial data. Ledger standardizes our representation of money movement, and it serves as the scalable foundation for our automated Data Quality (DQ) Platform—guaranteeing Stripe faithfully manages money for users.</p><p>Many existing systems provide primitives for accurate accounting, but the real world is imperfect, incomplete, and constantly changing. We witness basic and obvious failures like malformed reports or propagated errors from banking or network partners, and also broad macroeconomic changes such as currencies ceasing to exist or large banks collapsing overnight. While we aspire to an orderly ideal, at Stripe scale, that’s impossible—instead we built a system that keeps these imperfections manageable and bounded.</p><p>Ledger models internal data-producing systems with common patterns, and it relies on proactive alerting to surface issues and proposed solutions. Each day, Ledger sees five billion events and 99.99% of our dollar volume is fully ingested and verified within four days. Of that activity, 99.999% is monitored, categorized, and triaged through rich investigative tooling—while the remaining long-tail is reliably handled through manual analysis. Together, Ledger and the DQ Platform ensure over 99.9999% explainability of money movement, even as Stripe’s data volume has grown 10x.</p><p>In this blog post, we’ll share technical details on how we built this state-of-the-art money movement tracking system, and describe how teams at Stripe interact with the data quality metrics that underlie our global payments network.</p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/7KleMeqCSaOK4wSXgJ1jMP/5f3c489d33418c0b9129d4c29c01ffba/Ledger_Blog_Image_1.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > 5 billion events per day" src="https://images.ctfassets.net/fzn2n1nzq965/7KleMeqCSaOK4wSXgJ1jMP/5f3c489d33418c0b9129d4c29c01ffba/Ledger_Blog_Image_1.png?w=1620&amp;q=80" width="1800" height="520" loading="lazy">
    </picture>
</div>
  
</figure><h2>How Stripe processes payments</h2><p>The GPTN in part is a payment processing network consisting of customer business calls to Stripe’s API and Stripe’s interactions with a variety of banks and payment methods. There is complexity in tracking the requests Stripe makes to partners, the physical money movement between financial partners, and the reporting Stripe receives back. We make this multifaceted problem tractable by segmenting the Stripe platform into discrete services, databases, and APIs/gRPC interfaces, which lets us solve individual problems without getting overwhelmed by the broader system.&nbsp;</p><p>The challenge with this approach is that there is no intrinsic mechanism forcing these systems to represent or deliver data in the same way. Some might operate in real time, while others may operate on a monthly cadence with vastly different data volumes; some producers generate billions of events per day, while others may only generate a few hundred. Moreover, each system might have its own definitions of correctness or reliability. We require a mechanism that can deal with these variations and prove that these individual systems are collectively modeling our financials correctly. </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/3jDklujyDkjVvtB5cnrFkm/744488ffaa266695cc33d9d71b52e858/Ledger_Blog_Image_2.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Stripe's interactions with external entities" src="https://images.ctfassets.net/fzn2n1nzq965/3jDklujyDkjVvtB5cnrFkm/744488ffaa266695cc33d9d71b52e858/Ledger_Blog_Image_2.png?w=1620&amp;q=80" width="1800" height="826" loading="lazy">
    </picture>
</div>
  
    <figcaption><p>A simplified summary view of Stripe’s interactions with external entities</p></figcaption>
  
</figure><h2>How we designed Ledger</h2><p>The Stripe services mentioned above have independent responsibilities, but they collaborate to solve a large federated problem. An ideal solution provides a mental model for correctness—supported by trustworthy statistics—that easily generalizes to new use cases. Further, we want to represent all activity on the Stripe platform in a common data structure that can be analyzed by a single system.</p><p>This is the way we approach it:&nbsp;</p><ul>
  
    <li>Ledger encodes a state machine representation of producer systems, and models its behavior as a logical fund flow—the movement of balances (events) between accounts (states).&nbsp;</li>
  
    <li>Ledger computes all account balances to evaluate the health of the system, grouped by various subdivisions to generate comprehensive statistics.</li>
  
</ul><p>This approach abstracts individual differences between underlying systems and provides mathematical evidence that they are functioning correctly. </p><h3>Ledger as a semantic data store</h3><p>Ledger is a faithful representation of the underlying state of all payment processes on the Stripe platform. Instead of computing a derived dataset based on incoming data pipelines, Ledger models the actual work of producer systems, recording each operation as a transaction. Ledger modeling may diverge from upstream data, but we guard against these cases explicitly with data completeness checks.&nbsp;</p><p>Combined with our other data quality metrics, we can safely rely on Ledger’s data representation to monitor external systems. If we instrument Ledger, we indirectly instrument the data-producing pipelines. And, if we identify a problem, we alert our internal users to which part of their data pipeline is broken—and exactly how they can fix it.</p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/5QKsfxNc9Mgu1Z6IYvuPVt/49a290ebe632d11e6647d98dab21822f/Ledger_Blog_Image_3.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Processing a charge" src="https://images.ctfassets.net/fzn2n1nzq965/5QKsfxNc9Mgu1Z6IYvuPVt/49a290ebe632d11e6647d98dab21822f/Ledger_Blog_Image_3.png?w=1620&amp;q=80" width="1800" height="500" loading="lazy">
    </picture>
</div>
  
    <figcaption><p>Processing a charge with a creation event for a pending charge, and a release event for completion</p></figcaption>
  
</figure><p>Inside of Ledger, we represent this activity as a movement of balances between two discrete states (creation and release), turning the above process into an observable state machine.  </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/XTAV4qRmjqxZVOAXcJanS/d4b03662f78836c042ef359e5b8e7ebe/Ledger_Blog_Image_4.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Processing a charge in Ledger" src="https://images.ctfassets.net/fzn2n1nzq965/XTAV4qRmjqxZVOAXcJanS/d4b03662f78836c042ef359e5b8e7ebe/Ledger_Blog_Image_4.png?w=1620&amp;q=80" width="1800" height="414" loading="lazy">
    </picture>
</div>
  
    <figcaption><p>Processing a charge in Ledger, represented by a creation event for a pending charge and a release event for completion</p></figcaption>
  
</figure><h3>System abstraction</h3><p>Ledger also abstracts producer systems. Instead of separately monitoring handoffs between data pipelines, we model systems as connected fund flows moving money between accounts. Because Ledger is a transaction-level system of record, we can prove that even complex multisystem pipelines with multiple stages of handoff are working correctly. We also model data consistency between otherwise disconnected systems, and we track individual transactions through their entire lifecycle. We call this tracing, and, at our scale, this totals to billions of daily transactions.</p><h3>Unifying separate systems with fund flows</h3><p>Consider an abstract end-to-end fund flow: for example, a business adding funds to its balance. This requires moving funds between banks, reconciling money movement with third-party reporting, and matching regulatory reporting with financial reporting. The fund flow spans multiple internal team boundaries, with discrete events published to different systems at different times. If we model this fund flow with logical constructs, Ledger can unify this data across separate systems and monitor its correctness. 
</p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/2xkUjkxLNSfiQjSXKKpf9t/05f76ee13097c3b8ba66e25bcf120f8e/Ledger_Blog_Image_5.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Funds flows" src="https://images.ctfassets.net/fzn2n1nzq965/2xkUjkxLNSfiQjSXKKpf9t/05f76ee13097c3b8ba66e25bcf120f8e/Ledger_Blog_Image_5.png?w=1620&amp;q=80" width="1800" height="914" loading="lazy">
    </picture>
</div>
  
</figure><h3>Immutability</h3><p>At its core, Ledger is an immutable log of events. Transactions previously published into Ledger cannot be deleted or modified, and we can always reconstruct past state by processing all events up to that point. All constructs—balances, fund flows, data quality controls, and so on—are transformations of the static underlying structure. Ledger’s immutability ensures we can audit and reproduce any data point at any time. Immutability justifies our data quality measures by guaranteeing that we can explain and analyze the exact problematic data.</p><h2>How we designed the Data Quality (DQ) Platform</h2><p>Ledger is the foundation for our Data Quality (DQ) Platform, which unifies detection of money movement issues and response tooling. Empirically, the DQ Platform ensures reliable and timely reporting across Stripe’s key lines of business: we maintained a 99.999% readiness target, even as data volume grew 10x.</p><p>Transaction-level fund flows give us powerful tools to reason about complex interconnected subcomponents. We analyze these abstractions with a set of trustworthy DQ metrics that measure the health of a fund flow. These metrics are based on a common set of questions across all fund flows. For a specific cross-section of data, evaluated at time X, we look at:</p><ul>
  
    <li><strong>Clearing: </strong>Did the fund flow complete correctly?</li>
  
    <li><strong>Timeliness: </strong>Did the data arrive on time?</li>
  
    <li><strong>Completeness: </strong>Do we have a complete representation of the underlying data system?</li>
  
</ul><p>We then compose DQ metrics on individual fund flows to provide scoring and targeted guidance for technical experts. These measurements roll up to create a unified DQ score—a system with a 99.99% data quality score is extremely unlikely to hide major problems—turning a complex distributed analysis problem into a straightforward tabulation exercise. Technical users can likewise trust that improving DQ scores reflect true improvement in underlying system behavior and accuracy.</p><h3>Clearing</h3><p>Ledger is based on double-entry bookkeeping, a standard method for guaranteeing that all money in a system is fully accounted for by balancing credits and debits. Grounding our analysis in this construct gives us a mathematical proof of correctness. If you’ve never encountered this term before, a helpful explainer is <a href="https://anvil.works/blog/double-entry-accounting-for-engineers" data-js-controller="AnalyticsButton" data-analytics-category="Links" data-analytics-action="Clicked" data-analytics-label="">“An Engineer’s Guide to Double-Entry Bookkeeping.”</a></p><p>Using double-entry bookkeeping to validate money movement is similar to analyzing a flow of water through a network of pipes (processes) ending in reservoirs (balance sheets). At steady state, terminal (nonclearing) reservoirs are full, and intermediate (clearing) pipes are empty. If there is water stuck in the pipes, then you have a problem—in other words, unresolved balances on the balance sheet.</p><p>Traditionally, bookkeeping is purely an accounting construct, but we apply these ideas in a novel way. Rather than just tabulating cash flow in and out, we’re simultaneously modeling internal data system behaviors that may have nothing to do with physical movement of money—for example, currency conversion, report parsing, estimation, or billing analysis. We can use the same bookkeeping concepts to reason about those systems and evaluate their correctness in a much more general way.&nbsp; </p><h3>Detecting problems</h3><p>Clearing measures the fraction of Ledger that is appropriately zeroed out at steady state. Consider an example that models two steps of a flow: <code>charge creation</code> (potential money movement) and <code>release</code> (funds becoming available). As you follow the flow, keep in mind these definitions:</p><ul>
  
    <li><strong>Accounts</strong> are buckets of money distinguished by their type (e.g., <code>charge_unsubmitted</code>) and properties (e.g.,<em> </em><code>id</code>, <code>business</code>).</li>
  
    <li><strong>Events</strong> move money between accounts (e.g., <code>charge.creation</code> and <code>charge.release</code>). </li>
  
</ul><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/4fxb4PbKEzwR89xJmQDQsI/a0a0d32241a26f2531134c0fe80b0968/Engineering_Blog_Chart_9_900px_wide__2x.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > T0 and T1" src="https://images.ctfassets.net/fzn2n1nzq965/4fxb4PbKEzwR89xJmQDQsI/a0a0d32241a26f2531134c0fe80b0968/Engineering_Blog_Chart_9_900px_wide__2x.png?w=1620&amp;q=80" width="1800" height="582" loading="lazy">
    </picture>
</div>
  
</figure><p>At time <code>T0</code>, the <code>charge.creation</code> event sets up a balance in the undisbursed account; then&nbsp;at <code>T1</code>, <code>charge.release</code> completes the flow and moves the funds to the <code>business_balance</code> account.&nbsp;</p><p>It is important to note that the <code>creation</code> and <code>release</code> events are completely independent. Even if they arrive out of order, or are created by different sources, Ledger maintains accurate fund flows through the identifier for <code>business</code> and <code>id</code>. But, if the <code>release</code> event is never published or has the wrong <code>id</code>, Ledger would not clear the balance in the associated <code>charge_undisbursed</code> account, and it would instead hold the balance in a different instance of <code>charge_undisbursed</code>.</p><h3>Example clearing issue</h3><p>Consider next how a wrong value (<code>business: B</code> vs. <code>business: A</code>) results in two clearing accounts with nonzero balance. Instead of having one reservoir of money for <code>business: A</code>, we wind up with two—one for <code>business: A</code> and one for <code>business: B</code>.</p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/7lckBVyFNFtC5vdhemABCP/96a2644a0cf8b1e4ef30d749c61ffd38/Ledger_Blog_Image_7.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > T1 missing event" src="https://images.ctfassets.net/fzn2n1nzq965/7lckBVyFNFtC5vdhemABCP/96a2644a0cf8b1e4ef30d749c61ffd38/Ledger_Blog_Image_7.png?w=1620&amp;q=80" width="1800" height="572" loading="lazy">
    </picture>
</div>
  
</figure><p>Generalizing from this example, we repeat this process for every fund flow, account type, and property-based subdivision inside of Ledger. Even when we have billions of transactions, a single missing, late, or incorrect transaction immediately creates a detectable accuracy issue with a simple query—for example, “<em>Find the clearing Accounts with nonzero balance.”</em> </p><h3>Timeliness</h3><p>Clearing prevents persistent problems, but we also need to guarantee data arrives on time for time-sensitive functions such as monthly report generation. Producers create time stamps when integrating with Ledger, and we measure the delta between when data first enters the Stripe platform and when it reaches Ledger. We set a hard threshold on the data delivery window, and we create headroom for subsequent reporting, analysis, and manipulations to guarantee 99.999% timeliness.</p><h3>Completeness</h3><p>We guarantee data completeness and guard against missing data from upstream systems with explicit cross-system checks alongside automated anomaly detection. For example, we ensure that every ID in a producer database has a matching Ledger event. We also run statistical modeling on data availability. We have models for every account type that use historical trends to calculate expected data arrival time and, if events do not appear, we interpret this as potentially missing data.</p><h2>How teams at Stripe explore DQ metrics</h2><p>On top of the DQ Platform, we built hierarchical automated alerting and rich tooling. We combine interactive metric displays with analysis and guidance. The experience for internal leaders and team members focuses on proactive feedback, simple manipulation of data, and meaningful metrics. We also provide use-case-specific context that depends on which part of the business is using it. For example, consider how we show team-level DQ metrics for our periodic financial reporting, which we call Accounting Close. Note: some details are blocked out for privacy. </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/6Aotu34VZGTIKiymogYmcR/f00f7298f87a92dbc66da06e7d7c2d29/Ledger_Blog_Image_8.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Accounting Close" src="https://images.ctfassets.net/fzn2n1nzq965/6Aotu34VZGTIKiymogYmcR/f00f7298f87a92dbc66da06e7d7c2d29/Ledger_Blog_Image_8.png?w=1620&amp;q=80" width="1800" height="657" loading="lazy">
    </picture>
</div>
  
</figure><p>The topline view is generally in a good state, but there are areas for improvement at the team level within the Payment Engineering group. For example, the 50% score for Aging Balances means that some clearing issues have persisted over time:</p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/1eqOSiIS4I3S7DCdLWhZcM/db29859dcd1491556ed911b9cc4904d9/Ledger_Blog_Image_9.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Data quality metrics" src="https://images.ctfassets.net/fzn2n1nzq965/1eqOSiIS4I3S7DCdLWhZcM/db29859dcd1491556ed911b9cc4904d9/Ledger_Blog_Image_9.png?w=1620&amp;q=80" width="1800" height="1106" loading="lazy">
    </picture>
</div>
  
    <figcaption><p>A single team-level view of data quality metrics</p></figcaption>
  
</figure><p>This team-level view shows DQ metrics alongside a call to action including auto-generated tickets, relevant resources, and tool links—everything required for self-service. For leaders, this view provides the exact dollar impact of DQ issues.</p><h3>Tactical views</h3><p>DQ scores drop when a problem is observed in Ledger. Although Ledger is a projection of underlying systems, Ledger problems are not usually problems of transcription or data modeling in Ledger. They primarily reveal real problems with system implementations, integrations, or physical money movement. In these cases, we provide tactical views to trace issues back to their root cause inside Stripe platforms or external systems.</p><p>Consider an uncleared balance of a specific account type—a processing fee that must be invoiced and paid. At steady state, the invoice should be paid and the balance is zero, but over time we observe a nonclearing balance. </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/4bLJz9dNAaRCieH1Jt65dv/eeecf7750d37a0591d0064e9be800259/Ledger_Blog_Image_10.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Breakdown" src="https://images.ctfassets.net/fzn2n1nzq965/4bLJz9dNAaRCieH1Jt65dv/eeecf7750d37a0591d0064e9be800259/Ledger_Blog_Image_10.png?w=1620&amp;q=80" width="1800" height="964" loading="lazy">
    </picture>
</div>
  
</figure><h3>Investigation and attribution</h3><p>Clicking on a point in the graph generates SQL queries in Presto (our ad-hoc SQL query engine) and surfaces relevant data: reference keys, metadata, ownership, and tips. If a Ledger user is unable to debug and publish a correction—perhaps because the root cause is related to an infrastructure or third-party incident outside their control—they can reassign ownership to the right internal stakeholders and exclude it from alerting.</p><p>When issues are attributed to a known incident, we can retroactively analyze the impact to DQ metrics across teams to fully understand how Stripe was affected: </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/6pi29gH4pwDkMaZWM44rik/f278108e7e665f5d7774d2890bd7057c/Ledger_Blog_Image_11.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Live Clearing" src="https://images.ctfassets.net/fzn2n1nzq965/6pi29gH4pwDkMaZWM44rik/f278108e7e665f5d7774d2890bd7057c/Ledger_Blog_Image_11.png?w=1620&amp;q=80" width="1800" height="400" loading="lazy">
    </picture>
</div>
  
</figure><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/4uXeePTp0kQgX2ok0gwccF/d19d94f4f56401469fb1a3899c252955/Ledger_Blog_Image_12.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Data Quality Artifacts" src="https://images.ctfassets.net/fzn2n1nzq965/4uXeePTp0kQgX2ok0gwccF/d19d94f4f56401469fb1a3899c252955/Ledger_Blog_Image_12.png?w=1620&amp;q=80" width="1800" height="744" loading="lazy">
    </picture>
</div>
  
</figure><p>Combined, we have the ability to measure and analyze data quality, identify root-cause problems, and flexibly interact with the underlying data constructs to manage our problem load over time. In this case, fixing problems in Ledger may involve republishing data from source systems. </p><h3>Data correction</h3><p>Ledger is our system of record and must remain an evergreen representation of truth. Persistent problems reduce visibility into new problems and may result in incorrect reporting or derived datasets. Because Ledger is an immutable log of events, we can’t run simple queries to mutate the state; instead, we have to revert and reprocess prior operations. If an incident occurs, we need a tool for correcting data at scale.</p><p>We built a supporting utility to create and safely execute migrations, protected by a data quality tool that generates out-of-band reports on the production impact of proposed changes. Together, these tools approximate a CI pipeline for ad-hoc data repair operations. All operations must go through a two-phase review and commit of the data—and its associated DQ impact. </p><figure data-asset-count="1">
  <div>
  <picture>
      
        <source srcset="https://images.ctfassets.net/fzn2n1nzq965/1ZB9yRXjNpenEiZsghE0sr/acda5175b3e18ab2a7a04783a715e478/Ledger_Blog_Image_13.png?w=1620&amp;q=80&amp;fm=webp" type="image/webp">
      

      

      <img alt="Blog > Ledger > Data Pipeline Health Summary" src="https://images.ctfassets.net/fzn2n1nzq965/1ZB9yRXjNpenEiZsghE0sr/acda5175b3e18ab2a7a04783a715e478/Ledger_Blog_Image_13.png?w=1620&amp;q=80" width="1800" height="586" loading="lazy">
    </picture>
</div>
  
</figure><h2>Fewer data problems, more reliable reporting&nbsp;</h2><p>Our systems need to operate within a messy reality, but the innovations described in this blog post drive us towards a trustworthy and explainable operational model. Likewise, as businesses and mechanisms for money movement inevitably evolve, Stripe is empowered to keep pace with that change.</p><p>The DQ Platform ensures reliable and timely reporting across all Stripe business lines. The combination of clearing, timeliness, and completeness metrics ensures that internal stakeholders can make sound judgments about the correctness of underlying data systems without worrying about maintaining complex specialized knowledge.</p><p>The digital economy will continue to accelerate, and our focus is on building robust and scalable systems to power it. In the future, we want to improve timeliness to minute-level analysis and response—offering lower latency processing, which will strengthen fraud detection and increase available response time to address possible financial problems.&nbsp;</p><p>We are also investing in advanced enrichment capabilities that allow us to declaratively compose new datasets and reporting interfaces while guaranteeing that they meet our data quality bar. This work safely evolves the complexity of our internal systems alongside Stripe’s growth.</p><p>We’re excited to continue to solve hard, important problems. If you are too, consider joining our <a href="https://stripe.com/jobs/search?query=engineer" data-js-controller="AnalyticsButton" data-analytics-category="Links" data-analytics-action="Clicked" data-analytics-label="">engineering team</a>.</p>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPU synchronization in Godot 4.3 is getting a major upgrade (148 pts)]]></title>
            <link>https://godotengine.org/article/rendering-acyclic-graph/</link>
            <guid>39400572</guid>
            <pubDate>Fri, 16 Feb 2024 17:58:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://godotengine.org/article/rendering-acyclic-graph/">https://godotengine.org/article/rendering-acyclic-graph/</a>, See on <a href="https://news.ycombinator.com/item?id=39400572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><em>Darío, the author of this article, is a new face around this blog who was hired by <strong>W4 Games</strong> last summer to start contributing to the project. His work was kindly sponsored and donated to the Godot Engine project by <strong>W4 Games</strong>. You can find more of his contributions to the engine in his <a href="https://github.com/DarioSamo">GitHub profile</a>.</em></p>

<p>Since the introduction of Godot 4, <a href="https://docs.godotengine.org/en/stable/classes/class_renderingdevice.html">RenderingDevice</a> has been the backbone of the Forward+ and Mobile renderers. Making APIs that are both easy to use and flexible enough to cover all the features users want in a game engine is a very difficult task. The high level of detail expected by APIs like Vulkan or Direct3D 12 compared to their predecessors is worthy of a few blog posts of its own. This article will try to keep the topic as brief as possible to focus on the problems solved within Godot instead.</p>

<p>With the goal of reducing the difficulty of the development of the new renderers and allowing the GPU to parallelize work more effectively, the automatic construction of a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graph (DAG)</a> during rendering has been introduced at the lowest levels of the engine. <a href="https://github.com/godotengine/godot/pull/84976">This change is already merged</a> in the <code>main</code> development branch of Godot and should be part of the <strong>4.3 release</strong>. The introduction of the graph will bring both performance improvements and various bug fixes for issues that were very difficult to investigate. For example, after the graph was merged it was discovered that MSAA with SSAO will no longer cause artifacts in AMD Polaris (<a href="https://github.com/godotengine/godot/issues/61415">#61415</a>), despite no effort being spent towards developing a specific fix for the problem.</p>

<p>No changes are expected from users whatsoever. If you’re one of the few people who have written code that uses RenderingDevice, there’s no need to worry either: while the API has changed slightly, all of the methods just require less information than before. What level of performance improvement you see will very much depend on the contents of your project. For example, GPU particle systems will get massive improvements, while more standard scenes that use post-processing will see some frametime reduction in the ballpark of around 5% to 15%. On top of that, the Godot developers will have a much easier time improving the performance of the renderers in the near future.</p>

<p>If you’re interested in the details of how this was achieved, keep on reading.</p>

<h2 id="background">Background</h2>

<p>Understanding the problem space is crucial to do a deep dive into the technical decisions that were made. Dealing with an existing codebase for a general engine that had thousands of lines written on top of an existing API imposes many restrictions on what sort of changes are allowed. Flaws introduced in the early stages of design can have long-term effects on the development of a big project. This was very much the case with some of the key decisions taken for the RenderingDevice abstraction, its coupling to Vulkan and the negative results on the rest of the codebase. The good news is it’s never too late to go back to the drawing board. <a href="https://github.com/reduz">reduz</a> laid out the plans for this <a href="https://gist.github.com/reduz/980b9b2547d57e6a915b2bb7e1e76e08">redesign</a> during the end of 2023 and the team got to work on how to make it a reality.</p>

<h3 id="vulkan">Vulkan</h3>

<p>There’s a few Vulkan concepts that must be understood before digging into why RenderingDevice was designed the way it was for Godot 4 and the difficulties it encountered along the way.</p>

<h4 id="command-buffers">Command buffers</h4>

<p>Recording work for the GPU and submitting it for execution is a very explicit operation in Vulkan. <a href="https://docs.vulkan.org/spec/latest/chapters/cmdbuffers.html">Command buffers</a> (or command lists in D3D12) are the objects where all the recorded work is stored that that will executed at a later point on the GPU. These buffers can grow as much as the user desires and they won’t be run until they’re submitted for execution to a command queue. This implies it’s essentially possible to record from multiple sources, even multiple threads, and submit the work to the GPU once it’s ready with proper synchronization.</p>

<h4 id="render-passes">Render passes</h4>

<p>Drawing something with Vulkan requires a lot of information upfront in the form of a “render pass”: an object that contains references to the textures that the GPU will use as targets, their initial and final states (texture memory layouts) and much more. This is a stark contrast from older APIs like OpenGL or even D3D12, where the render target can be changed during command recording and does not require the creation of an object ahead of time. While a render pass is active, there are also various restrictions on what operations can be recorded on the command buffer. The render pass must end before being allowed to use all types of operations again.</p>

<h4 id="barriers">Barriers</h4>

<p>The biggest change compared to previous APIs is that synchronization between commands is no longer automatically deduced by the driver and instead must be manually implemented by the programmers using Vulkan. If you want to read more about this topic in detail, I highly recommend Hans-Kristian’s <a href="https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/">blog post about Vulkan Synchronization</a> and reading the <a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/vkCmdPipelineBarrier.html">official Vulkan documentation</a>. To keep the article short, a very basic explanation is provided below.</p>

<p>The order of execution of the recorded commands inside a command buffer <strong>is NOT guaranteed to complete in the order they were submitted</strong>: the GPU can reorder these commands in whatever order it thinks is best to complete the job as quickly as possible. To compensate for this, the programmer must manually insert <strong><a href="https://gpuopen.com/learn/vulkan-barriers-explained/">synchronization barriers</a></strong> in the command buffer that allow specifying in detail which commands should be completed or started by specifying the scope <strong>before</strong> and <strong>after</strong>. The scope includes multiple concepts such as the execution stage (e.g. drawing, compute, transfer), the type of access (e.g. read or write) and the affected memory regions (globally, buffers or textures). On top of that, barriers are capable of transitioning textures from one memory layout to another, which is a requirement to be able to use textures in different commands optimally.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/barriers.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>A barrier can establish a dependency between commands by specifying a synchronization scope.</em></td>
    </tr>
  </tbody>
</table>

<p>Beginners will have a hard time understanding this mechanism, but even experts or hardware vendors are not safe from making mistakes. A run of the <a href="https://github.com/KhronosGroup/Vulkan-ValidationLayers">Vulkan Validation Layers</a> in <em>synchronization</em> mode will reveal multiple issues on most Godot projects or even commercial games available in the market. These are among the most frustrating issues to understand as they won’t even appear consistently depending on hardware vendor or hardware speed. Since eliminating these problems was one of the main goals behind the introduction of the acyclic graph, extensive use was made of these validation tools to ensure that no synchronization errors remained.</p>

<h3 id="renderingdevice">RenderingDevice</h3>

<p><a href="https://docs.godotengine.org/en/stable/classes/class_renderingdevice.html">RenderingDevice is the abstraction</a> on which the <em>Forward+</em> and <em>Mobile</em> renderers in Godot were built. It exposes an interface that provides a reasonable level of control over the GPU in a way that is not as fine-grained as Vulkan or D3D12 but is also not as “stateful” as OpenGL. More of the rendering state needs to be defined in advance, and the chances of causing an error by leaking state from one previous command to the next are significantly reduced.</p>

<p>The commands exposed by this class are what you usually expect out of a rendering API: creating resources, copying, clearing, drawing, dispatching compute work, etc. However, the point of interest is how both rendering geometry and compute passes are organized. Godot already has the concept of “draw lists” and “compute lists”: essentially batches of commands describing what to do inside a render pass or a compute pass. The one-to-one correlation between lists and passes is very important, as it significantly reduced the number of nodes an automatic graph would have to create.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/draw-compute-lists.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Draw lists and compute lists are considered a single unit of work in the rendering pipeline.</em></td>
    </tr>
  </tbody>
</table>

<p>While Rendering Device attempted to hide many of the difficulties that Vulkan introduced, there are a few that slipped through that made writing rendering code for Godot 4 more difficult than anticipated.</p>

<h4 id="draw-list-actions">Draw list actions</h4>

<p>Just as draw lists were naturally mapped to render passes, so too was the fact that the start and end action had to be specified for the textures associated with them. These actions cover operations such as loading the contents of a texture, discarding it or clearing it with a specific color. There’s plenty of performance to be gained by choosing the optimal option in each render pass. However, due to some internal design decisions, the introduction of a <code>CONTINUE</code> action was made that doesn’t actually exist in Vulkan. This action essentially meant “the previous draw list is compatible and the texture should not be transitioned to a different state”. For an engine like Godot, which must provide a lot of <strong>optional</strong> post-processing effects and drawing layers, this proved to be a <em>maintenance nightmare</em>, ending in a ton of branching in the code that was not very easy to follow and prone to mistakes.</p>

<h4 id="draw-list-storage-textures">Draw list storage textures</h4>

<p>Since the device doesn’t know if the result of a draw list will be used in a compute pass later, it was necessary to specify which textures needed to transition to the “storage” memory layout at the end of the render pass. <em>Storage</em> is the layout required for modifying textures directly from compute passes. From the point of view of an outsider to Godot, there was no clear reason why this had to be part of the API, but when analyzing the implementation it was evident it was introduced to deal with the barrier transitions required by Vulkan. In turn, this delegated the responsibility to the programmer to keep track of whether the textures would be used later in the compute passes in order to handle them efficiently.</p>

<h4 id="draw-and-compute-list-overlap">Draw and compute list overlap</h4>

<p>Draw lists and compute lists were allowed to specify whether they can “overlap” during execution. This is a very vague argument that depends on whether the programmer correctly understands whether the render and compute work aren’t dependent on each other and could realistically run in parallel. With no real way to validate this, this flag essentially meant “turn it on and hope for the best” as it simply skipped some synchronization steps that the default behavior enforced. Once again, making use of this feature introduced some issues in the codebase where it would require tracking whether parallel work was being submitted or not: components like GI could make use of this optimization, but whether the feature is used or not depends on what that the user has enabled in the scene.</p>

<h4 id="barrier-mask">Barrier mask</h4>

<p>While RenderingDevice does not provide explicit access to barriers, a lot of methods would allow specifying a bit mask to define which stages of the pipeline the command must synchronize with. However, this was probably one of the most misused masks in the existing rendering code as its implementation wasn’t even consistent in most methods. In one instance, a variable that wasn’t a bitmask at all was accidentally casted as one and passed to a rendering method.</p>

<p>By default, most commands will just specify that all work that comes afterwards must be executed after the current command has finished. As expected, this results in Godot issuing an extreme amount of barriers “just in case” as it has no knowledge of what might be requested afterwards. Godot’s strategy essentially boils down to issuing barriers to make sure no future work executes before the current command finishes, unless the programmer using RenderingDevice specifies the barrier mask. Again, that means the developer must have exact knowledge of everything that comes next, and in turn, caused another round of maintenance issues. Therefore, this feature is rarely used and the default behavior is preferred, resulting in lower performance.</p>

<h3 id="hindsight-is-2020">Hindsight is 20/20</h3>

<p>The problems raised here may not have sounded so bad in the planning stages of Godot 4, but they clearly became increasingly difficult to solve as more rendering code was written on top of it. Being tasked with writing driver-level work in addition to refactoring the entire engine in many areas is a very difficult task, especially when new APIs have a much steeper learning curve. Many frameworks and engines have iterated on their solutions to deal with the new amount of work expected by Vulkan, and it was time for Godot to try to address this problem again.</p>

<h2 id="solution">Solution</h2>

<h3 id="preparation">Preparation</h3>

<p>Solving the problems identified above does not actually require the introduction of an acyclic graph: inserting synchronization barriers and performing dependency tracking is entirely possible without applying this technique. This was actually debated internally for a while, but it was determined that if the engine was able to reorder commands, it’d allow for grouping them more effectively between the mandatory synchronization points and would result in better performance.</p>

<p>However, being able to reorder commands meant that an intermediate step had to be introduced where commands were recorded into an auxiliary structure that could be reordered and then converted to the corresponding native API commands. One possibility was encoding the Vulkan command arguments into the auxiliary buffer, but that approach meant the entire graph structure and logic would need to be implemented for every other backend as well. Therefore, it was deemed it’d be necessary for Pedro to work on his <a href="https://github.com/godotengine/godot/pull/83452">pull request</a> that introduces an abstract interface for all the supported graphic APIs, including Vulkan, D3D12 and Metal in the near future. Thanks to this change, it was possible to use a single abstract API to encode commands into the auxiliary buffer.</p>

<p>The initial redesign was laid out in <em>reduz</em>’s <a href="https://gist.github.com/reduz/980b9b2547d57e6a915b2bb7e1e76e08">draft</a>, which was largely inspired by <a href="https://levelup.gitconnected.com/organizing-gpu-work-with-directed-acyclic-graphs-f3fd5f2c2af3">Pavlo Muratov’s “Organizing GPU Work with Directed Acyclic Graphs”</a> and showed the possibility of how the concept could be applied to Godot’s existing design. Not everything stated in the document made it into the final version: in fact, the changes to RenderingDevice were much less severe than initially indicated and the interface remained largely compatible. While the article that was used as inspiration includes a very detailed algorithm in how to implement multi-queue submission by using the graph, the team made the decision to cut this idea short and stick to a single command queue to begin with, as the difficulty of the task would come from building the graph automatically and would already take a significant amount of development time.</p>

<h3 id="acyclic-graph">Acyclic graph</h3>

<p>The unique aspect of the implemented graph is that its construction is completely invisible to the programmer using RenderingDevice. Commands requested from the class are logged internally and each command maintains an adjacency list that is updated as new dependencies are detected. Since these adjacencies only work one way and older commands cannot depend on future commands, it is virtually impossible for cyclic dependencies to form (hence the “acyclic” part of the graph). While a graph can be constructed in many ways, a list of vertices and an adjacency list are sufficient. Render commands play the role of vertices, and commands store the indices of their adjacent commands.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/command-graph.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The rendering operations of a frame and their dependencies represented as a graph.</em></td>
    </tr>
  </tbody>
</table>

<p>An important decision that was made to allow this structure to scale more effectively is that each instance of a draw list or a compute list are considered as <strong>one node in the graph</strong>. There is no benefit to allowing reordering within these structures and Godot already has a clear concept of what these lists are used for. Games often draw a lot of geometry, but they don’t create tons of render passes per frame, as that doesn’t result in efficient use of the GPU. To put it in numbers, one of the benchmark scenes used during testing could easily reach hundreds of thousands of nodes if each individual command was recorded into the graph. Making the distinction to correlate render passes to individual nodes brought this number down to about <strong>300 nodes per frame</strong>. Operating with a graph of this scale was a very good sign that the performance overhead would be very small.</p>

<p>Once all commands for the frame have been recorded, a <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological sort</a> is performed on the graph to get an ordered list of commands. During this step the “levels” of the commands are detected to determine how they can be grouped and where synchronization points (barriers) should be introduced. All commands belonging to a particular level in the graph can be executed in parallel as no dependencies have been detected between them, meaning that no barriers are required until the next level is reached. This sorting step is where the magic behind the performance gains happens.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/command-graph-levels.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>After sorting, all commands that belong to the same level can be executed in any order, resulting in multiple possible command sequences.</em></td>
    </tr>
  </tbody>
</table>

<p>One important detail that resulted in frametime reductions during this step was to take into account the type of command as a sorting factor: grouping together operations based on whether they were related to copying data, drawing or compute dispatches provided some noticeable increases in performance. While the exact reason behind this has not been determined, it seems likely that GPUs prefer to change the type of pipeline they need to use within a command buffer as little as possible.</p>

<p>While the concept of using a structure like a graph and using sorting algorithms might sound like the most daunting part of the task due to the level of abstraction involved, it is the dependency tracking and adjacency list detection during command recording where most problems arise. The relationships shown in the diagrams above were not specified by the programmer using RenderingDevice: they must be detected automatically based on how the resources were used in the frame, and this turned out to be no small task due to some particular details of how Godot works.</p>

<h3 id="resource-tracking">Resource tracking</h3>

<p>The resources used by RenderingDevice in Godot are buffers or textures. While these are separate objects at the lower level depending on the API being used, the graph considers them both as one to share much of the logic during implementation. However, a distinction will be made later when texture slices are introduced, which is something Godot uses quite a bit in various parts of its rendering code. Textures also have the additional requirement that they need to make layout transitions to be ready for use in different commands, while buffers don’t need to do this at all.</p>

<p>Whenever a resource is created, a new “tracker” structure is introduced to store the information relevant to the graph construction during command recording. The tracker holds references to which commands are writing or reading from the resource and modifies these lists accordingly as more commands are recorded. It also stores a “usage” variable that indicates what the current use of the resource is at the time of recording. Usages are both classified as “read” or “read-write” operations, and which one is used has strong implications for how dependencies between commands will be detected. For example, a command that reads from Resource A can be executed in parallel with another command that reads from Resource A, but that will not be valid if the other command can write to Resource A. In this case, a dependency is inserted between the two commands to ensure that the first command can finish reading the resource correctly before the next command modifies it.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/resource-tracking.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The tracker holds the current usage of a resource and determines whether it is necessary to perform a transition based on the type of command that references it.</em></td>
    </tr>
  </tbody>
</table>

<p>Textures also have a particular requirement: changing the usage implies a memory layout transition even if it’s just for read-only operations. For example, there’s different layouts for a texture being used as the source of a copy operation and for a texture being used for sampling in a shader. While this distinction might not necessarily be true at the hardware level, it is actually possible to witness texture corruption if these transitions are not performed correctly depending on the GPU’s architecture (AMD is really good for testing these out!). Therefore, any change in usage when textures are involved is usually considered a write operation as most of them require a particular layout. This introduces some dependencies between commands that might not be very obvious but are completely required for the operations to work correctly: continuing with the previous example, it’s not possible to use the optimal memory layout for copying a texture and sampling it in a shader in parallel, even if both are read-only operations.</p>

<h3 id="dependency-tracking">Dependency tracking</h3>

<p>Since the graph construction is automatic and there’s no input from the programmer in how the adjacency lists of the graph must be built, it’s up to RenderingDevice to use the resource trackers to figure out the dependencies between commands. While the final implementation is a bit more complex due to the introduction of texture “slices” (which is covered in another chapter), the main idea behind the algorithm is pretty straightforward.</p>

<ul>
  <li>When a command uses a resource as read-only, a reference to the command is stored in a list in the resource tracker. A reference to the command is placed on the adjacency list of the last operation that wrote to the resource.</li>
  <li>When a command uses a resource as read-write, a reference to the command is stored the resource tracker, replacing the previous one and clearing the list of commands that were reading from the resource. A reference to the command is placed on the adjacency list of all operations that were either reading or writing to the resource.</li>
  <li>An exception is made for textures: if an operation must change the type of usage, the operation is considered as if it’s writing to the resource because a memory layout transition is required. <strong>It does not matter if both operations are read-only</strong>: a write dependency will be established regardless. This is worth keeping in mind as the graph considers the operations to be dependent if the texture’s usage changes often.</li>
</ul>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/dependency-tracking-animated.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Animated example of how dependency tracking is used to build the graph. Blue and red represent how the command modifies the lists inside the trackers and green indicates which values it reads from to build the adjacency list.</em></td>
    </tr>
  </tbody>
</table>

<p>Older operations are discarded from the tracker’s lists to avoid increasing them endlessly and causing performance bottlenecks in the process. As write operations can’t be done in parallel and no information is known about the range of data that is modified (a potential future improvement), then it’s only necessary to store a reference to one command at all times. This system requires more detailed tracking once texture slices are later introduced, but the strategy remains largely the same.</p>

<p>One interesting thing to note here is that Godot can leverage the information provided by <a href="https://github.com/KhronosGroup/SPIRV-Reflect">SPIRV-reflect</a> to identify the usage of some resources as read-only even if their layout allows write operations. For example, the storage memory layout is required to be able to write to a texture directly so it is considered as a write usage by default. However, if the GLSL shader uses the <code>readonly</code> qualifier on the binding, then the graph will consider it as a read operation.</p>

<h3 id="immutable-resources">Immutable resources</h3>

<p>Resource tracking can quickly become a performance bottleneck as the solution does not scale effectively to games with large amounts of resources. If every single buffer or texture used in a frame must be tracked and checked for dependencies during recording, that can quickly balloon out of proportion. But there is a simple first step to reduce this problem: not everything needs to be tracked as most resources in a game are usually static (e.g. terrain or buildings). An internal benchmark scene from W4 Games showed this to be true pretty quickly, as the amount of trackers went down from over 20 thousand to less than a thousand after ignoring all static resources.</p>

<p>But Godot doesn’t currently know what resources are static. Users can modify these resources freely at any time, even from GDScript! Resources are not considered to be immutable or marked as such during the import process. Other engines typically mark nodes as static for additional optimizations, but Godot avoids this concept to keep the engine easy to use and not overwhelm beginners with settings whose purpose they may not yet understand. This turned out to be a big problem that was debated internally for a while, as introducing a new “immutable” attribute was the most attractive option with the downside that it would mean a lot of extra work for end users.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/complex-scene.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Complex game scenes often contain a lot of static geometry. Tracking these resources generates a lot of overhead without any real benefit.</em></td>
    </tr>
  </tbody>
</table>

<p>Fortunately, a quick solution was found that allowed trackers to be greatly reduced without the need for user intervention: during resource creation, a couple of flags are checked to see if a tracker should be created or not. If the resource is created with some initial data and no explicit flags are set for modification, then it is considered to be read-only and no tracker is created for it. If at some point an operation attempts to modify the resource, a full synchronization is introduced in the graph and the tracker is created. Synchronization is required because it’s not possible to know which commands in the frame were reading from the resource beforehand. Full synchronization implies all previous commands must be adjacent to the command that created the resource tracker, so the graph degrades to the behavior of the previous version of Godot on that particular command for one frame. This was considered to be an acceptable and very minor performance degradation that bypassed the need to introduce the “immutable” flag to the engine.</p>

<h3 id="texture-slices">Texture slices</h3>

<p>No good tale is complete without its villain. This was the most painful omission from the initial design and it proved to be the hardest part of dependency tracking and texture layout transitioning that required to be solved. As a matter of fact, it might not even be solved completely yet as new edge cases that had to be fixed popped up even after the graph was merged!</p>

<p>While textures are most commonly associated with containing two dimensions, it is possible to create two extra dimensions that further complicate their use: mipmap levels and array layers. Mipmaps are commonly used to create a chain of smaller versions of the texture that the filtering process can use to improve the image quality (see <a href="https://en.wikipedia.org/wiki/Anisotropic_filtering">Anisotropic filtering</a>). A general use case for array layers is to simply create a texture with the same dimensions multiple times and then reference a particular layer within a shader. Godot makes plenty of use out of these extra dimensions, even combining the use of both at the same time for some effects.</p>

<p>This usually doesn’t pose any additional trouble if the engine sticks to using a texture during commands in only one particular way, but the problem does not stop there: Godot can and will use different parts of the same texture for completely different purposes, even within the same command. This is possible because <a href="https://docs.godotengine.org/en/stable/classes/class_renderingdevice.html#class-renderingdevice-method-texture-create-shared-from-slice">RenderingDevice can create “shared” textures from slices</a>. While the original texture may only have one resource tracker, all shared slices are considered different textures with their own resource trackers that can be referenced independently in commands. A common use case is mipmap creation: a lower level mipmap of the texture can be set as the render target, while a higher resolution level is used for sampling, effectively creating the chain of mipmaps from the texture’s highest quality level.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/texture-slices.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The anatomy of a cubemap texture that uses both mipmaps and array layers. Godot can create slices of a texture that reference only a range of its subresources.</em></td>
    </tr>
  </tbody>
</table>

<p>Tracking texture slices effectively required the implementation of a set of strict rules to verify that the programmer using the RenderingDevice does not perform operations with undefined behavior.</p>

<ul>
  <li>The tracker for the “parent” texture holds a “dirty list” of slices that have a different memory layout from the one used by the parent.</li>
  <li>It is never possible for slices on the dirty list to overlap. In fact, these ranges are represented as 2D rectangles, which is pretty fun way to represent the problem visuallly!</li>
  <li>The tracker for a texture slice holds a reference to its parent and a flag to identify whether it is present on the dirty list or not.</li>
  <li>It is not possible for one command to use slices of the same texture that overlap, as this can lead to undefined behavior. This restriction is applied even if their usage is the same.</li>
  <li>If the parent texture is used in a command directly, all slices in the dirty list will be reverted to the usage of the parent by “normalizing” the texture to one memory layout. It is not possible to use slices with a different usage during this step.</li>
  <li>Slices present in the dirty list can also be normalized and removed individually if a new command wants to use a slice that would overlap with their dirty region. Since it’s not possible for slices to overlap in the same command, this operation can always be performed safely if the slice being normalized was used in an older command.</li>
  <li>Dependency tracking is performed strictly with the tracker associated to the parent texture of a slice and not the slice’s tracker, as this usually leads to the safest behavior.</li>
</ul>

<p>While these rules do not guarantee an optimal solution, it is not common for Godot to perform these operations on every frame, and the potential linearization of the commands is an acceptable performance hit to keep tracking as simple as possible. One point in particular that was discussed a lot was whether to resort to tracking usage individually per mipmap level and array layer, but such a decision would result in a system that wouldn’t scale at all in the long run if large texture arrays with multiple mipmaps are used.</p>

<h2 id="results">Results</h2>

<p>While this is something that is <em>not</em> usually measured, it’s worth remembering one of the main reasons behind the graph was to simplify the maintenance of the rendering code for the team. The problems identified at the start clearly meant there was a lot of code that would get deleted from the rendering pipeline. While the PR might not have ended up in the net negative due to a lot of code being isolated in the graph’s class along with debugging utilities, around ~2,500 lines of code were removed from the implementation of RenderingDevice, the Forward+ renderer and the Mobile renderer.</p>

<p>The other major benefit is that a lot of hard to identify bugs that were caused due to synchronization bugs are now potentially fixed. As pointed out before, the <a href="https://github.com/godotengine/godot/issues/61415">MSAA with SSAO issue</a> was resolved as a side effect. Problems like this one proved to be extremely hard to fix as Godot developers would require the particular set of hardware and the right scenarios for the defects to trigger. With the graph sufficiently complete and unable to cause these synchronization problems, the possibility of introducing errors of this kind disappears.</p>

<h3 id="gpu-performance">GPU performance</h3>

<p>The results are generally positive. No performance regressions have been identified in any scene as far as GPU performance is concerned, and in virtually most scenarios an improvement can be expected depending on their contents.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/benchmark-projects.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Results gathered from running various projects with an NVIDIA GeForce RTX 3090 Ti at 1920x1080. Higher is better.</em></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Legend of the Nuku Warriors: Internal demo scene by W4 Games.</li>
  <li><a href="https://github.com/RPicster/godot4-demo-desert-light">Desert Light Demo</a> by <a href="https://github.com/RPicster">RPicster</a>.</li>
  <li><a href="https://github.com/Calinou/godot-reflection">Reflection for Godot 4.0</a> ported by <a href="https://github.com/Calinou">Calinou</a>.</li>
  <li><a href="https://github.com/perfoon/Abandoned-Spaceship-Godot-Demo">Abandoned Spaceship Demo</a> by <a href="https://github.com/perfoon">Perfoon</a>.</li>
</ul>

<p>The biggest gains by far could be identified in projects with multiple GPU particle systems, where the execution can now take place in parallel wherever it’s possible. A dedicated particles benchmark makes this difference much more obvious.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/benchmark-particles.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Results gathered from running the benchmark with NVIDIA GeForce RTX 3090 Ti. Higher is better.</em></td>
    </tr>
  </tbody>
</table>

<ul>
  <li><a href="https://github.com/Geometror/godot-tests-and-benchmarks/tree/main/benchmark_particles">Particles benchmark</a> by <a href="https://github.com/Geometror">Geometror</a>.</li>
</ul>

<h3 id="cpu-performance">CPU performance</h3>

<p>The introduction of the acyclic graph to Godot does not come free. As the need to serialize commands into an intermediate buffer is introduced along with graph construction, dependency tracking, and sorting, the CPU must bear the brunt of the work. However, the results are not what most developers would expect. From profiling where the CPU spent most of its time during a frame in the benchmark scene, the following was discovered:</p>
<ul>
  <li>Graph construction and topological sorting don’t even account for more than 1% of the CPU time of the frame. The node count is usually too low to have a significant effect.</li>
  <li>Nearly 30% of the CPU time was consumed entirely by Vulkan API calls (~20%) and serialization of the commands into the draw list (~10%). This corresponds to the fact this scene has a massive amount of objects being drawn with a large amount of omni lights that can cast shadows.</li>
</ul>

<p>For now, the conclusion would seem to be that the graph itself cannot impact the scene significantly as far as CPU overhead is concerned, but the requirement to serialize large draw lists seems to simply exacerbate an existing problem: Godot needs better mechanisms to merge draw calls and avoid binding an excessive number of index buffers and unique vertices for everything in the scene. The good news is that this regression can potentially be mitigated or even improved in the short term with secondary command buffers (or a suitable replacement).</p>

<h3 id="secondary-command-buffers">Secondary command buffers</h3>

<p>As mentioned before, the new APIs enable the possibility of recording to command buffers from multiple threads. Secondary command buffers are an interesting subset of command buffers that aren’t capable of recording all types of commands and are intended to be inserted inside a render pass issued in a primary command buffer. This is actually an ideal application for draw lists, since their contents do not need to be reordered, but their location in the primary command buffer is determined during the topological sorting step of the graph. Therefore, they enable the possibility of recording in parallel and ahead of time the largest draw lists of the frame. And they actually get good results! In the benchmark scene, the CPU time spent in the frame is actually reduced compared to 4.2 thanks to overlapping most of the cost from calling the Vulkan API and delegating it to background worker threads. The graph finally gives Godot the keys to using multithreading for rendering!</p>

<p>So why is this not enabled in <code>master</code> yet? It seems that secondary command buffers can run into some strange issues on different hardware and are not as widely supported as they should be. During testing an issue was found in NVIDIA GPUs where the editor window would just go completely blank if secondary buffers were used under certain conditions. Apparently it wouldn’t be the smartest decision to rely on this feature and expect it to work correctly on most platforms. However, if you want to experiment with it yourself <a href="https://github.com/godotengine/godot/blob/d3352813ea44447bfbf135efdec23acc4d1d3f89/servers/rendering/rendering_device.cpp#L59">the code is currently present behind a compilation macro</a>. The code will automatically enable multithreaded recording when the draw lists are determined to be large enough to be suitable and will result in a real reduction in CPU times in demanding scenes, provided the user has enough CPU cores to handle it.</p>

<p>An alternative being evaluated is to record multiple primary command buffers instead and chain them together when the frame ends. However, submitting a command buffer for execution has a fixed cost that isn’t insignificant according to hardware vendors, so some consideration must be given to creating different command buffers only when the benefit outweighs the cost.</p>

<h2 id="future-work">Future work</h2>

<p>With the introduction of the directed acyclic graph and with a <a href="https://github.com/godotengine/godot/pull/87340">few more abstraction rewrites coming down the line</a>, the engine will now have access to even more optimizations that can be implemented in the future.</p>

<h3 id="multiple-queues">Multiple queues</h3>

<p>Pavlo Muratov’s <a href="https://levelup.gitconnected.com/organizing-gpu-work-with-directed-acyclic-graphs-f3fd5f2c2af3">article</a> that was used as the main inspiration behind this change contains a very interesting proposal in how to submit and synchronize GPU work across the multiple queues exposed by the hardware. Godot could potentially leverage these extra queues (e.g. dedicated compute queues), to be more explicit about what work should be executed in parallel. Finding paths that could be executed in parallel in the graph would require some elaborate detection of the dependencies between the commands, the possible paths that are independent and where the synchronization points need to be placed.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/multi-queue.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>A heavily simplified example of a potential multiqueue submission scheme that could be detected by the graph. Many portions of the compute work in Godot could be processed while other parts of the rendering pipeline are busy.</em></td>
    </tr>
  </tbody>
</table>

<p>As pointed out before when talking about using primary command buffers as an alternative to secondary command buffers, command queue submissions are not free: there must be a good balance between partitioning work to be executed in parallel when compared to just submitting everything into a single command queue.</p>

<h3 id="msaa-resolves">MSAA resolves</h3>

<p>Multisample anti-aliasing (MSAA) is a feature that requires explicit commands to “resolve” the result of the anti-aliasing into a texture that can be used by other steps in the rendering pipeline. The anti-aliased result is not actually computed during the time of drawing but either when a <a href="https://docs.vulkan.org/samples/latest/samples/performance/msaa/README.html">resolve command is issued or a render pass defines a resolve operation in a subpass</a>.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/msaa-resolve-manual.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>It’s not possible for Godot to know if something will draw again to the target, so it must resolve the result manually when it needs to sample the resource.</em></td>
    </tr>
  </tbody>
</table>

<p>With how flexible of an engine Godot is, determining where this step should go can be very tricky: the operation should be placed only when it’s absolutely necessary or as part of the last render pass that draws to the MSAA texture. This is an area that the graph could aim to resolve automatically by simplifying the implementation of MSAA in the renderers and lead to further performance improvements. Reducing the amount of resolve operations to the minimum and the bandwidth required for MSAA could be very beneficial for the Mobile renderer in particular.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/msaa-resolve-solution.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Since the graph can detect if the render pass is the last one in the frame, it can automatically insert a resolve in the render pass, saving lots of bandwidth in the process.</em></td>
    </tr>
  </tbody>
</table>

<h3 id="graph-visualization">Graph visualization</h3>

<p>While this wouldn’t provide a direct benefit to end users, building a visualizer for the graph could help the Godot developers have a clear overview of the rendering pipeline of a given frame and identify bottlenecks more easily. During development, a few compute passes were identified that weren’t being parallelized correctly due to implementation errors. For example, GPU particle systems were binding an unused buffer for write operations even if they never wrote to it, which led to the commands being identified as being dependent of each other due to having to synchronize with the potential “write” performed by the previous system.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/particle-error.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Due to an implementation error, even after implementing the graph, the execution of the particle systems was mostly linear, as they all reused the same temporary buffer for reading and writing.</em></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th><img src="https://godotengine.org/storage/blog/acyclic-graph/particle-error-fix.webp" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>After fixing the error by assigning each system their own buffers, the graph automatically reordered and executed the particle systems in parallel, leading to huge gains in performance.</em></td>
    </tr>
  </tbody>
</table>

<p>While a more obvious case like this one was identified since it did not meet expectations at first, there could be more subtle instances of this behavior yet to be found in the codebase that could be easily exposed by building better debugging tools.</p>

<h2 id="conclusions">Conclusions</h2>

<p>While the use of a directed acyclic graph for rendering is not a brand new technique, the approach used by Godot is quite novel in many ways. The simplicity of the API exposed by RenderingDevice no longer comes at the cost of rendering performance: the developer is guaranteed they’ll get efficient use of the GPU and it can only get better from here. As the engine aims to be as general purpose as possible and maintain its ease of use, a lot of alternatives had to be discarded until the right approach was found. This is a long-term technical investment that will pay off by reducing the cost of maintenance and unlocking new strategies for optimization in the long run.</p>

<p>An automatic approach ensures that despite the project being open source and modified by many different people, they no longer need complete awareness of how the entire rendering pipeline works to modify it. This will also be very beneficial when PRs like <a href="https://github.com/godotengine/godot/pull/80214">rendering effects</a> are merged, which introduce the ability to add post-processing steps where the Godot renderer will be completely unaware of all dependencies the hook may require. The extra validation introduced by recording commands to the graph has also exposed existing implementation errors, resulting in either bug fixes or even performance improvements.</p>

<p>Debugging is the weak point of this approach: when dealing with native Vulkan or D3D12 code, it can be very tough to produce a usable backtrace as the context that generated the commands is long gone by the time they’re translated from the auxiliary buffer to the native API calls. It is advised to build very good debugging tools that register as much information as possible to aid in the process. This is one area where the existing implementaton must be improved upon.</p>

<p>Considering how little abstraction the graph requires, it is entirely possible to apply this approach to other projects that don’t use Godot at all. The implementation of the technique has been kept as isolated and general purpose as possible, affecting very little of the rest of the Godot codebase except for removing code that is no longer required. Following this approach turned out to be very important, as being able to change the implementation of the graph itself or disable it completely was vital to debugging any problems introduced by implementation errors. While there are no plans to make this a general-purpose library, it could be a very interesting idea to integrate this mechanism into a generic rendering framework.</p>

<p>Look forward to testing this feature out in the 4.3-dev snapshots and future releases! Please <a href="https://forum.godotengine.org/t/progress-update-gpu-synchronization/47859">let us know</a> if you have any issues so they can be fixed in time for the first stable release.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Air Canada must honor refund policy invented by airline's chatbot (116 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/</link>
            <guid>39400374</guid>
            <pubDate>Fri, 16 Feb 2024 17:45:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/">https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/</a>, See on <a href="https://news.ycombinator.com/item?id=39400374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Blame game    —
</h4>
            
            <h2 itemprop="description">Air Canada appears to have quietly killed its costly chatbot support.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GettyImages-1453660913-800x533.jpg" alt="Air Canada must honor refund policy invented by airline’s chatbot">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 23:single/related:3be96e65dcfb5c467dc970978b485c40 --><!-- empty -->
<p>After months of resisting, Air Canada was <a href="https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html">forced</a> to give a partial refund to a grieving passenger who was misled by an airline chatbot inaccurately explaining the airline's bereavement travel policy.</p>
<p>On the day Jake Moffatt's grandmother died, Moffat immediately visited Air Canada's website to book a flight from Vancouver to Toronto. Unsure of how Air Canada's bereavement rates worked, Moffatt asked Air Canada's chatbot to explain.</p>
<p>The chatbot provided inaccurate information, encouraging Moffatt to book a flight immediately and then request a refund within 90 days. In reality, Air Canada's policy explicitly stated that the airline will not provide refunds for bereavement travel after the flight is booked. Moffatt dutifully attempted to follow the chatbot's advice and request a refund but was shocked that the request was rejected.</p>
<p>Moffatt tried for months to convince Air Canada that a refund was owed, sharing a screenshot from the chatbot that clearly claimed:</p>
<blockquote><p>If you need to travel immediately or have already travelled and would like to submit your ticket for a reduced bereavement rate, kindly do so within 90 days of the date your ticket was issued by completing our Ticket Refund Application form.</p></blockquote>
<p>Air Canada argued that because the chatbot response elsewhere linked to a page with the actual bereavement travel policy, Moffatt should have known bereavement rates could not be requested retroactively. Instead of a refund, the best Air Canada would do was to promise to update the chatbot and offer Moffatt a $200 coupon to use on a future flight.</p>                                            
                                                        
<p>Unhappy with this resolution, Moffatt refused the coupon and filed a small claims complaint in Canada's Civil Resolution Tribunal.</p>
<p>According to Air Canada, Moffatt never should have trusted the chatbot and the airline should not be liable for the chatbot's misleading information because Air Canada essentially argued that "the chatbot is a separate legal entity that is responsible for its own actions," a <a href="https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html">court order</a> said.</p>
<p>Experts <a href="https://vancouversun.com/news/local-news/air-canada-told-it-is-responsible-for-errors-by-its-website-chatbot">told the Vancouver Sun</a> that Moffatt's case appeared to be the first time a Canadian company tried to argue that it wasn't liable for information provided by its chatbot.</p>
<p>Tribunal member Christopher Rivers, who decided the case in favor of Moffatt, called Air Canada's defense "remarkable."</p>
<p>"Air Canada argues it cannot be held liable for information provided by one of its agents, servants, or representatives—including a chatbot," Rivers wrote. "It does not explain why it believes that is the case" or "why the webpage titled 'Bereavement travel' was inherently more trustworthy than its chatbot."</p>
<p>Further, Rivers found that Moffatt had "no reason" to believe that one part of Air Canada's website would be accurate and another would not.</p>
<p>Air Canada "does not explain why customers should have to double-check information found in one part of its website on another part of its website," Rivers wrote.</p>
<p>In the end, Rivers ruled that Moffatt was entitled to a partial refund of $650.88 in Canadian dollars (CAD) off the original fare (about $482 USD), which was $1,640.36 CAD (about $1,216 USD), as well as additional damages to cover interest on the airfare and Moffatt's tribunal fees.</p>
<p>Air Canada told Ars it will comply with the ruling and considers the matter closed.</p>
<h2>Air Canada’s chatbot appears to be disabled</h2>
<p>When Ars visited Air Canada's website on Friday, there appeared to be no chatbot support available, suggesting that Air Canada has disabled the chatbot.</p>                                            
                                                        
<p>Air Canada did not respond to Ars' request to confirm whether the chatbot is still part of the airline's online support offerings.</p>
<p>Last March, Air Canada's chief information officer Mel Crocker <a href="https://www.theglobhttps//www.theglobeandmail.com/business/article-ai-call-centres/">told the Globe and Mail</a> that the airline had launched the chatbot as an AI "experiment."</p>
<p>Initially, the chatbot was used to lighten the load on Air Canada's call center when flights experienced unexpected delays or cancellations.</p>
<p>“So in the case of a snowstorm, if you have not been issued your new boarding pass yet and you just want to confirm if you have a seat available on another flight, that’s the sort of thing we can easily handle with AI,” Crocker told the Globe and Mail.</p>
<p>Over time, Crocker said, Air Canada hoped the chatbot would "gain the ability to resolve even more complex customer service issues," with the airline's ultimate goal to automate every service that did not require a "human touch."</p>
<p>If Air Canada can use "technology to solve something that can be automated, we will do that,” Crocker said.</p>
<p>Air Canada was seemingly so invested in experimenting with AI that Crocker told the Globe and Mail that "Air Canada’s initial investment in customer service AI technology was much higher than the cost of continuing to pay workers to handle simple queries." It was worth it, Crocker said, because "the airline believes investing in automation and machine learning technology will lower its expenses" and "fundamentally" create "a better customer experience."</p>
<p>It's now clear that for at least one person, the chatbot created a more frustrating customer experience.</p>
<p>Experts told the Vancouver Sun that Air Canada may have succeeded in avoiding liability in Moffatt's case if its chatbot had warned customers that the information that the chatbot provided may not be accurate.</p>
<p>Because Air Canada seemingly failed to take that step, Rivers ruled that "Air Canada did not take reasonable care to ensure its chatbot was accurate."</p>
<p>"It should be obvious to Air Canada that it is responsible for all the information on its website," Rivers wrote. "It makes no difference whether the information comes from a static page or a chatbot."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Popular Git config options (352 pts)]]></title>
            <link>https://jvns.ca/blog/2024/02/16/popular-git-config-options/</link>
            <guid>39400352</guid>
            <pubDate>Fri, 16 Feb 2024 17:43:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2024/02/16/popular-git-config-options/">https://jvns.ca/blog/2024/02/16/popular-git-config-options/</a>, See on <a href="https://news.ycombinator.com/item?id=39400352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! I always wish that command line tools came with data about how popular their various options are, like:</p>

<ul>
<li>“basically nobody uses this one”</li>
<li>“80% of people use this, probably take a look”</li>
<li>“this one has 6 possible values but people only really use these 2 in practice”</li>
</ul>

<p>So I <a href="https://social.jvns.ca/@b0rk/111885363143321068">asked about people’s favourite git config options on Mastodon</a>:</p>

<blockquote>
<p>what are your favourite git config options to set? Right now I only really
have <code>git config push.autosetupremote true</code> and <code>git config
init.defaultBranch main</code> set in my <code>~/.gitconfig</code>, curious about what other
people set</p>
</blockquote>

<p>As usual I got a TON of great answers and learned about a bunch of very popular
git config options that I’d never heard of.</p>

<p>I’m going to list the options, starting with (very roughly) the most popular
ones. Here’s a table of contents:</p>

<ul>
<li><a href="#pull-ff-only-or-pull-rebase-true">pull.ff only or pull.rebase true</a></li>
<li><a href="#merge-conflictstyle-zdiff3">merge.conflictstyle zdiff3</a></li>
<li><a href="#rebase-autosquash-true">rebase.autosquash true</a></li>
<li><a href="#rebase-autostash-true">rebase.autostash true</a></li>
<li><a href="#push-default-simple-push-default-current">push.default simple, push.default current</a></li>
<li><a href="#init-defaultbranch-main">init.defaultBranch main</a></li>
<li><a href="#commit-verbose-true">commit.verbose true</a></li>
<li><a href="#rerere-enabled-true">rerere.enabled true</a></li>
<li><a href="#help-autocorrect-10">help.autocorrect 10</a></li>
<li><a href="#core-pager-delta">core.pager delta</a></li>
<li><a href="#diff-algorithm-histogram">diff.algorithm histogram</a></li>
<li><a href="#core-excludesfile-a-global-gitignore">core.excludesfile ~/.gitignore</a></li>
<li><a href="#includeif-separate-git-configs-for-personal-and-work">includeIf: separate git configs for personal and work</a></li>
<li><a href="#fsckobjects-avoid-data-corruption">fsckobjects: avoid data corruption</a></li>
<li><a href="#submodule-stuff">submodule stuff</a></li>
<li><a href="#and-more">and more</a></li>
<li><a href="#how-to-set-these">how to set these</a></li>
<li><a href="#changes-i-ve-made-after-writing-this-post">changes I’ve made after writing this post</a></li>
</ul>

<p>All of the options are documented in <code>man git-config</code>, or <a href="https://git-scm.com/docs/git-config">this page</a>.</p>

<h3 id="pull-ff-only-or-pull-rebase-true"><code>pull.ff only</code> or <code>pull.rebase true</code></h3>

<p>These two were the most popular. These both have similar goals: to avoid accidentally creating a merge commit
when you run <code>git pull</code> on a branch where the upstream branch has diverged.</p>

<ul>
<li><code>pull.rebase true</code> is the equivalent of running <code>git pull --rebase</code> every time you <code>git pull</code></li>
<li><code>pull.ff only</code> is the equivalent of running <code>git pull --ff-only</code> every time you <code>git pull</code></li>
</ul>

<p>I’m pretty sure it doesn’t make sense to set both of them at once, since <code>--ff-only</code>
overrides <code>--rebase</code>.</p>

<p>Personally I don’t use either of these since I prefer to decide how to handle
that situation every time, and now git’s default behaviour when your branch has
diverged from the upstream is to just throw an error and ask you what to do
(very similar to what <code>git pull --ff-only</code> does).</p>

<h3 id="merge-conflictstyle-zdiff3"><code>merge.conflictstyle zdiff3</code></h3>

<p>Next: making merge conflicts more readable! <code>merge.conflictstyle zdiff3</code> and <code>merge.conflictstyle diff3</code> were both super popular (“totally indispensable”).</p>

<p>The main idea is
The consensus seemed to be “diff3 is great, and zdiff3 (which is newer) is even better!”.</p>

<p>So what’s the deal with <code>diff3</code>. Well, by default in git, merge conflicts look like this:</p>

<pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
def parse(input):
    return input.split("\n")
=======
def parse(text):
    return text.split("\n\n")
&gt;&gt;&gt;&gt;&gt;&gt;&gt; somebranch
</code></pre>

<p>I’m supposed to decide whether <code>input.split("\n")</code> or <code>text.split("\n\n")</code> is
better. But how? What if I don’t remember whether <code>\n</code> or <code>\n\n</code> is right? Enter diff3!</p>

<p>Here’s what teh same merge conflict look like with <code>merge.conflictstyle diff3</code> set:</p>

<pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
def parse(input):
    return input.split("\n")
||||||| b9447fc
def parse(input):
    return input.split("\n\n")
=======
def parse(text):
    return text.split("\n\n")
&gt;&gt;&gt;&gt;&gt;&gt;&gt; somebranch
</code></pre>

<p>This has <strong>extra information</strong>: now the original version of the code is in the middle! So we can see that:</p>

<ul>
<li>one side changed <code>\n\n</code> to <code>\n</code></li>
<li>the other side renamed <code>input</code> to <code>text</code></li>
</ul>

<p>So presumably the correct merge conflict resolution is <code>return
text.split("\n")</code>, since that combines the changes from both sides.</p>

<p>I haven’t used zdiff3, but a lot of people seem to think it’s better. The blog post <a href="https://ductile.systems/zdiff3/">Better Git Conflicts with zdiff3</a> talks more about it.</p>

<h3 id="rebase-autosquash-true"><code>rebase.autosquash true</code></h3>

<p>Autosquash was also a new feature to me. The goal is to make it easier to modify old commits.</p>

<p>Here’s how it works:</p>

<ul>
<li>You have a commit that you would like to be combined with some commit that’s 3 commits ago, say <code>add parsing code</code></li>
<li>You commit it with <code>git commit --fixup OLD_COMMIT_ID</code>, which gives the new commit the commit message <code>fixup! add parsing code</code></li>
<li>Now, when you run <code>git rebase --autosquash main</code>, it will automatically combine all the <code>fixup!</code> commits with their targets</li>
</ul>

<p><code>rebase.autosquash true</code> means that <code>--autosquash</code> always gets passed automatically to <code>git rebase</code>.</p>

<h3 id="rebase-autostash-true"><code>rebase.autostash true</code></h3>

<p>This automatically runs <code>git stash</code> before a git rebase and <code>git stash pop</code> after. It basically passes <code>--autostash</code> to <code>git rebase</code>.</p>

<p>Personally I’m a little scared of this since it potentially can result in merge
conflicts after the rebase, but I guess that doesn’t come up very often for
people since it seems like a really popular configuration option.</p>

<h3 id="push-default-simple-push-default-current"><code>push.default simple</code>, <code>push.default current</code></h3>

<p>These <a href="https://git-scm.com/docs/git-config#Documentation/git-config.txt-pushdefault"><code>push.default</code></a> options tell <code>git push</code> to automatically push the current branch to a remote branch with the same name.</p>

<ul>
<li><code>push.default simple</code> is the default in Git. It only works if your branch is already tracking a remote branch</li>
<li><code>push.default current</code> is similar, but it’ll always push the local branch to a remote branch with the same name.</li>
<li><code>push.autoSetupRemote</code> and <code>push.default simple</code> together seem to do basically the same thing as <code>push.default current</code></li>
</ul>

<p><code>current</code> seems like a good setting if you’re confident that you’re never going
to accidentally make a local branch with the same name as an unrelated remote
branch. Lots of people have branch naming conventions (like <code>julia/my-change</code>)
that make this kind of conflict very unlikely, or just have few enough
collaborators that branch name conflicts probably won’t happen.</p>

<h3 id="init-defaultbranch-main"><code>init.defaultBranch main</code></h3>

<p>Create a <code>main</code> branch instead of a <code>master</code> branch when creating a new repo.</p>

<h3 id="commit-verbose-true"><code>commit.verbose true</code></h3>

<p>This adds the whole commit diff in the text editor where you’re writing your
commit message, to help you remember what you were doing.</p>

<h3 id="rerere-enabled-true"><code>rerere.enabled true</code></h3>

<p>This enables <a href="https://git-scm.com/book/en/v2/Git-Tools-Rerere">rerere</a> (”<strong>re</strong>use <strong>re</strong>covered <strong>re</strong>solution”), which remembers how you resolved merge conflicts
during a <code>git rebase</code> and automatically resolves conflicts for you when it can.</p>

<h3 id="help-autocorrect-10"><code>help.autocorrect 10</code></h3>

<p>By default git’s autocorrect try to check for typos (like <code>git ocmmit</code>), but won’t actually run the corrected command.</p>

<p>If you want it to run the suggestion automatically, you can set
<a href="https://git-scm.com/docs/git-config#Documentation/git-config.txt-helpautoCorrect"><code>help.autocorrect</code></a>
to <code>1</code> (run after 0.1 seconds), <code>10</code> (run after 1 second), <code>immediate</code> (run
immediately), or <code>prompt</code> (run after prompting)</p>



<p>The “pager” is what git uses to display the output of <code>git diff</code>, <code>git log</code>, <code>git show</code>, etc. People set it to:</p>

<ul>
<li><a href="https://github.com/dandavison/delta"><code>delta</code></a> (a fancy diff viewing tool with syntax highlighting)</li>
<li><code>less -x5,9</code> (sets tabstops, which I guess helps if you have a lot of files with tabs in them?)</li>
<li><code>less -F -X</code> (not sure about this one, <code>-F</code> seems to disable the pager if everything fits on one screen if but my git seems to do that already anyway)</li>
<li><code>cat</code> (to disable paging altogether)</li>
</ul>

<p>I used to use <code>delta</code> but turned it off because somehow I messed up the colour
scheme in my terminal and couldn’t figure out how to fix it. I think it’s a
great tool though.</p>

<p>I believe delta also suggests that you set up <code>interactive.diffFilter  delta --color-only</code> to syntax highlight code when you run <code>git add -p</code>.</p>

<h3 id="diff-algorithm-histogram"><code>diff.algorithm histogram</code></h3>

<p>Git’s default diff algorithm often handles functions being reordered badly. For example look at this diff:</p>

<pre><code>-.header {
+.footer {
     margin: 0;
 }

-.footer {
+.header {
     margin: 0;
+    color: green;
 }
</code></pre>

<p>I find it pretty confusing. But with <code>diff.algorithm histogram</code>, the diff looks like this instead, which I find much clearer:</p>

<pre><code>-.header {
-    margin: 0;
-}
-
 .footer {
     margin: 0;
 }

+.header {
+    margin: 0;
+    color: green;
+}
</code></pre>

<p>Some folks also use <code>patience</code>, but <code>histogram</code> seems to be more popular. <a href="https://luppeng.wordpress.com/2020/10/10/when-to-use-each-of-the-git-diff-algorithms/">When to Use Each of the Git Diff Algorithms</a> has more on this.</p>

<h3 id="core-excludesfile-a-global-gitignore"><code>core.excludesfile</code>: a global .gitignore</h3>

<p><code>core.excludeFiles = ~/.gitignore</code> lets you set a global gitignore file that
applies to all repositories, for things like <code>.idea</code> or <code>.DS_Store</code> that you
never want to commit to any repo. It defaults to <code>~/.config/git/ignore</code>.</p>

<h3 id="includeif-separate-git-configs-for-personal-and-work"><code>includeIf</code>: separate git configs for personal and work</h3>

<p>Lots of people said they use this to configure different email addresses for
personal and work repositories. You can set it up something like this:</p>

<pre><code>[includeIf "gitdir:~/code/&lt;work&gt;/"]
path = "~/code/&lt;work&gt;/.gitconfig"
</code></pre>

<h3 id="url-git-github-com-insteadof-https-github-com"><code>url."git@github.com:".insteadOf 'https://github.com/'</code></h3>

<p>I often accidentally clone the HTTP version of a repository instead of the
SSH version and then have to manually go into <code>~/.git/config</code> and edit the
remote URL. This seems like a nice workaround: it’ll replace
<code>https://github.com</code> in remotes with <code>git@github.com:</code>.</p>

<p>Here’s what it looks like in <code>~/.gitconfig</code> since it’s kind of a mouthful:</p>

<pre><code>[url "git@github.com:"]
	insteadOf = "https://github.com/"
</code></pre>

<p>One person said they use <code>pushInsteadOf</code> instead to only do the replacement for
<code>git push</code> because they don’t want to have to unlock their SSH key when
pulling a public repo.</p>

<p>A couple of other people mentioned setting <code>insteadOf = "gh:"</code> so they can <code>git
remote add gh:jvns/mysite</code> to add a remote with less typing.</p>

<h3 id="fsckobjects-avoid-data-corruption"><code>fsckobjects</code>: avoid data corruption</h3>

<p>A couple of people mentioned this one. Someone explained it as “detect data
corruption eagerly. Rarely matters but has saved my entire team a couple
times”.</p>

<pre><code>transfer.fsckobjects = true
fetch.fsckobjects = true
receive.fsckObjects = true
</code></pre>

<h3 id="submodule-stuff">submodule stuff</h3>

<p>I’ve never understood anything about submodules but a couple of person said they like to set:</p>

<ul>
<li><code>status.submoduleSummary  true</code></li>
<li><code>diff.submodule  log</code></li>
<li><code>submodule.recurse  true</code></li>
</ul>

<p>I won’t attempt to explain those but there’s <a href="https://hachyderm.io/@unlambda/111942468084436716#.">an explanation on Mastodon by @unlambda here</a>.</p>

<h3 id="and-more">and more</h3>

<p>Here’s everything else that was suggested by at least 2 people:</p>

<ul>
<li><code>branch.sort -committerdate</code>, makes <code>git branch</code> sort by most recently used branches instead of alphabetical, to make it easier to find branches. <code>tag.sort taggerdate</code> is similar for tags.</li>
<li><code>color.ui false</code>: to turn off colour</li>
<li><code>commit.cleanup scissors</code>: so that you can write <code>#include</code> in a commit message without the <code>#</code> being treated as a comment and removed</li>
<li><code>core.autocrlf false</code>: on Windows, to work well with folks using Unix</li>
<li><code>core.editor emacs</code>: to use emacs (or another editor) to edit commit messages</li>
<li><code>credential.helper osxkeychain</code>: use the Mac keychain for managing</li>
<li><code>diff.tool difftastic</code>: use <a href="https://difftastic.wilfred.me.uk/">difftastic</a> (or <code>meld</code> or <code>nvimdiffs</code>) to display diffs</li>
<li><code>diff.colorMoved default</code>: uses different colours to highlight lines in diffs that have been “moved”</li>
<li><code>diff.colorMovedWS allow-indentation-change</code>: with <code>diff.colorMoved</code> set, also ignores indentation changes</li>
<li><code>diff.context 10</code>: include more context in diffs</li>
<li><code>fetch.prune true</code> and <code>fetch.prunetags</code> - automatically delete remote tracking branches that have been deleted</li>
<li><code>gpg.format ssh</code>: allow you to sign commits with SSH keys</li>
<li><code>log.date iso</code>: display dates as <code>2023-05-25 13:54:51</code> instead of <code>Thu May 25 13:54:51 2023</code></li>
<li><code>merge.keepbackup false</code>, to get rid of the <code>.orig</code> files git creates during a merge conflict</li>
<li><code>merge.tool meld</code> (or <code>nvim</code>, or <code>nvimdiff</code>) so that you can use <code>git mergetool</code> to help resolve merge conflicts</li>
<li><code>push.followtags true</code>: push new tags along with commits being pushed</li>
<li><code>rebase.missingCommitsCheck error</code>: don’t allow deleting commits during a rebase</li>
<li><code>rebase.updateRefs true</code>: makes it much easier to rebase multiple stacked branches at a time. <a href="https://andrewlock.net/working-with-stacked-branches-in-git-is-easier-with-update-refs/">Here’s a blog post about it</a>.</li>
</ul>

<h3 id="how-to-set-these">how to set these</h3>

<p>I generally set git config options with <code>git config --global NAME VALUE</code>, for
example <code>git config --global diff.algorithm histogram</code>. I usually set all of my
options globally because it stresses me out to have different git behaviour in
different repositories.</p>

<p>If I want to delete an option I’ll edit <code>~/.gitconfig</code> manually, where they look like this:</p>

<pre><code>[diff]
	algorithm = histogram
</code></pre>

<h3 id="config-changes-i-ve-made-after-writing-this-post">config changes I’ve made after writing this post</h3>

<p>My git config is pretty minimal, I already had:</p>

<ul>
<li><code>init.defaultBranch main</code></li>
<li><code>push.autoSetupRemote true</code></li>
<li><code>merge.tool meld</code></li>
<li><code>diff.colorMoved default</code> (which actually doesn’t even work for me for some reason but I haven’t found the time to debug)</li>
</ul>

<p>and I added these 3 after writing this blog post:</p>

<ul>
<li><code>diff.algorithm histogram</code></li>
<li><code>branch.sort -committerdate</code></li>
<li><code>merge.conflictstyle zdiff3</code></li>
</ul>

<p>I’d probably also set <code>rebase.autosquash</code> if making carefully crafted pull
requests with multiple commits were a bigger part of my life right now.</p>

<p>I’ve learned to be cautious about setting new config options – it takes me a
long time to get used to the new behaviour and if I change too many things at
once I just get confused. <code>branch.sort -committerdate</code> is something I was
already using anyway (through an alias), and I’m pretty sold that <code>diff.algorithm
histogram</code> will make my diffs easier to read when I reorder functions.</p>

<h3 id="that-s-all">that’s all!</h3>

<p>I’m always amazed by how useful to just ask a lot of people what stuff they like and
then list the most commonly mentioned ones, like with this <a href="https://jvns.ca/blog/2022/04/12/a-list-of-new-ish--command-line-tools/">list of new-ish command line tools</a>
I put together a couple of years ago. Having a list of 20 or 30 options to consider feels so much more efficient than combing through a list of <a href="https://jvns.ca/data/all-git-options.txt">all 600 or so git config options</a></p>

<p>It was a little confusing to summarize these because git’s default
options have actually changed a lot of the years, so people occasionally have
options set that were important 8 years ago but today are the default. Also a
couple of the experimental options people were using have been removed and
replaced with a different version.</p>

<p>I did my best to explain things accurately as of how git works right now in
2024 but I’ve definitely made mistakes in here somewhere, especially because I
don’t use most of these options myself. Let me know on Mastodon if you see a
mistake and I’ll try to fix it.</p>

<p>I might also ask people about aliases later, there were a bunch of great ones
that I left out because this was already getting long.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dear writers: Delete your Findaway Voices account NOW (183 pts)]]></title>
            <link>https://mwl.io/archives/23448</link>
            <guid>39399826</guid>
            <pubDate>Fri, 16 Feb 2024 17:08:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mwl.io/archives/23448">https://mwl.io/archives/23448</a>, See on <a href="https://news.ycombinator.com/item?id=39399826">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-23448">
		<!-- .entry-header -->

	
	<div>
		<p>When Findaway Voices first appeared, it made it comparatively easy for independent authors to do audiobooks. Audio was still hard, mind you, but it was possible.</p>
<p>Spotify bought Findaway. They began playing with payments, refunds, and returns. And now, the <a href="https://my.findawayvoices.com/terms-of-use">licensing terms have changed</a>.</p>
<blockquote><p>Accordingly, you hereby grant Spotify a non-exclusive, transferable, sublicensable, royalty-free, fully paid, irrevocable, worldwide license to reproduce, make available, perform and display, translate, modify, create derivative works from (such as transcripts of User Content), distribute, and otherwise use any such User Content through any medium, whether alone or in combination with other Content or materials, in any manner and by any means, method or technology, whether now known or hereafter created, in connection with the Service, the promotion, advertising or marketing of the Service, and the operation of Spotify’s (and its successors’ and affiliates’) business, including for systems and products management, improvement and development, testing, training, modeling and implementation in connection with the Spotify Service. Where applicable and to the extent permitted under applicable law, you also agree to waive, and not to enforce, any “moral rights” or equivalent rights, such as your right to object to derogatory treatment of such User Content. Nothing in these Terms prohibits any use of User Content by Spotify that may be taken without a license.
</p></blockquote>
<p>Spotify may now do anything they want with your audiobook. They will–not can, <em>will</em>–feed it to their AI system and use it to rip off your work. They specifically declare you can’t complain about derogatory uses. They can mix your book with work you find abhorrent and release it as a new product. They can use a speech recognition system and create a printed version of your book.</p>
<p>I have one audiobook. I pulled it from distribution when the royalties problems started and I stopped getting paid. <a href="https://www.tiltedwindmillpress.com/product/audiosbs/">That audiobook became exclusive to my store on 17 January 2023</a>. It has fewer sales, but I’ve made more than I did in all the years before. (“But exposure,” some folks will say. People die of exposure.)</p>
<p>It’s not enough to stop distributing your work via Findaway. If you use them to store your audio files and nothing else, the new terms apply. They have no automatic option to delete titles from their site. I just sent this email to their technical support.</p>
<blockquote><p>Hello,</p>
<p>Findaway’s new terms of service are unacceptable. Please delete my<br>
book and my entire account.</p>
<p>Thank you.
</p></blockquote>
<p>No need to be rude. It’s not the tech support flunky’s fault.</p>
<p>Also, I’m super happy with how my one lone audiobook came out. If it sold more, I’d do more.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Training LLMs to generate text with citations via fine-grained rewards (160 pts)]]></title>
            <link>https://arxiv.org/abs/2402.04315</link>
            <guid>39399418</guid>
            <pubDate>Fri, 16 Feb 2024 16:42:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2402.04315">https://arxiv.org/abs/2402.04315</a>, See on <a href="https://news.ycombinator.com/item?id=39399418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2402.04315.pdf">Download PDF</a>
    <a href="https://arxiv.org/html/2402.04315v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>While recent Large Language Models (LLMs) have proven useful in answering user queries, they are prone to hallucination, and their responses often lack credibility due to missing references to reliable sources. An intuitive solution to these issues would be to include in-text citations referring to external documents as evidence. While previous works have directly prompted LLMs to generate in-text citations, their performances are far from satisfactory, especially when it comes to smaller LLMs. In this work, we propose an effective training framework using fine-grained rewards to teach LLMs to generate highly supportive and relevant citations, while ensuring the correctness of their responses. We also conduct a systematic analysis of applying these fine-grained rewards to common LLM training strategies, demonstrating its advantage over conventional practices. We conduct extensive experiments on Question Answering (QA) datasets taken from the ALCE benchmark and validate the model's generalizability using EXPERTQA. On LLaMA-2-7B, the incorporation of fine-grained rewards achieves the best performance among the baselines, even surpassing that of GPT-3.5-turbo.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Chengyu Huang [<a href="https://arxiv.org/show-email/5a4a117b/2402.04315">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 6 Feb 2024 19:00:40 UTC (7,723 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UI = f(statesⁿ) (134 pts)]]></title>
            <link>https://daverupert.com/2024/02/ui-states/</link>
            <guid>39399281</guid>
            <pubDate>Fri, 16 Feb 2024 16:35:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daverupert.com/2024/02/ui-states/">https://daverupert.com/2024/02/ui-states/</a>, See on <a href="https://news.ycombinator.com/item?id=39399281">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  

  <div>
    

    <p>“UI is a function of state” is a pretty popular saying in the front-end world. In context (<em>pun intended</em>), that’s typically referring to application or component state. I thought I’d pull that thread a little further and explore all the states that can effect the UI layer…</p>
<h2>First-party application states</h2>
<p>Every application whether it’s a to-do list or a shopping cart or some radically complex app will have some state. State isn’t uniform and typically exists at a variety of different levels. We’ll start at the top and drill down…</p>
<h3>Global state</h3>
<p>Data stores and feature gating that typically happens at the application level.</p>
<ul>
<li>Stores - different locations for storing data
<ul>
<li>Application store - Redux, Vuex, Mobx, Signals</li>
<li>Browser store - localStorage, sessionStorage, cookies, IndexedDB</li>
</ul>
</li>
<li>Data - different types of global data
<ul>
<li>Access control data - authentication tokens, paid/unpaid, geolocated, age, verified, member, etc.</li>
<li>User data - name, icon, etc</li>
<li>Collections - e.g. list of posts</li>
<li>Session data</li>
<li>… etc</li>
</ul>
</li>
</ul>
<h3>Page/Component state</h3>
<p>Vince Speelman’s wonderful <a href="https://medium.com/swlh/the-nine-states-of-design-5bfe9b3d6d85">Nine States of Design</a> do a great job summing up all the states that a page or component might exist in.</p>
<ul>
<li>Nothing - An empty element</li>
<li>Loading - A <code>fetch</code> is happening</li>
<li>None - No items returned</li>
<li>One - A single item comes back</li>
<li>Some - A few items comes back</li>
<li>Too Many - Too many items, need pagination (or similar)</li>
<li>Incorrect - An error occurred</li>
<li>Correct - A success happened</li>
<li>Done - The operation finished</li>
</ul>
<p>Vince’s list is perfect to me and keeps being relevant after all these years, I would add two items.</p>
<ul>
<li>Custom states - Any bespoke or custom states relevant to your application</li>
<li>Realtime multi-player event mesages- Picture the state and event message in a chat app or realtime stock ticker. Stored at the component level or thrown into global state.</li>
</ul>
<p>In my experience both the page and each component will contain some mixture of these states as well as being reactive to global state changes.</p>
<h3>Element state</h3>
<p>Individual elements can (and will) have their own states. At this layer, features of HTML, CSS, and ARIA start to reveal themselves.</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/cursor">Cursor</a> state
<ul>
<li><code>default, pointer, wait, text, move, grab, crosshair, zoom-in, zoom-out</code>, … etc</li>
<li>Custom cursors</li>
</ul>
</li>
<li>Stacking context
<ul>
<li><code>z-index</code></li>
<li>Layer
<ul>
<li>Root</li>
<li><code>::backdrop</code></li>
<li>Top</li>
</ul>
</li>
</ul>
</li>
<li>Attribute states - states reflected in HTML
<ul>
<li>Visibility = <code>hidden, visible</code></li>
<li>Language = <code>dir, lang</code></li>
<li>Functionaltiy = <code>contenteditable, draggable, invoketarget</code></li>
<li>Display = <code>inert, open, popover</code></li>
</ul>
</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes">Pseudo-class</a> states - states reflected in CSS
<ul>
<li>Action = <code>:hover, :active, :focus, :focus-visible, :focus-within</code></li>
<li>Input = <code>:autofill, :checked, :disabled, :valid, :invalid, :user-valid, :user-invalid, :required</code>, … etc.</li>
<li>Display = <code>:fullscreen, :modal, :picture-in-picture</code></li>
<li>Language = <code>:dir(), :lang()</code></li>
<li>Location = <code>:link, :visited, :target</code>, … etc.</li>
<li>Resource = <code>:playing, :paused</code></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/CustomStateSet">CustomStateSet</a> = custom states for web components</li>
<li>… etc</li>
</ul>
</li>
<li><a href="https://developer.mozilla.org/en-US/docs/web/Accessibility/ARIA/Attributes">ARIA states</a> - <a href="https://css-tricks.com/user-facing-state/">user-facing states</a> reflected in ARIA
<ul>
<li><code>aria-current</code></li>
<li><code>aria-expanded</code></li>
<li><code>aria-pressed</code></li>
<li><code>aria-hidden</code></li>
<li>… etc</li>
</ul>
</li>
</ul>
<h2>Second-party user (or device) states</h2>
<p>The user of the application and their device, peripherals, and browser have a lot of say in how the final application renders. This is by design and <a href="https://www.w3.org/TR/html-design-principles/#priority-of-constituencies">built into the foundations of the web</a>.</p>
<h3>Language and localization</h3>
<p>Surprise! Not all users live in US-West-2.</p>
<ul>
<li>Text direction = <code>ltr, rtl</code></li>
<li>Writing mode = <code>horizontal-tb, vertical-lr, vertical-rl</code></li>
<li>Distance to server/CDN (latency)</li>
<li>Auto-translations</li>
<li>Words are long (e.g. German)</li>
<li>Words are short (e.g. Chinese)</li>
</ul>
<h3>Device constraints</h3>
<p>A user’s device has a lot of variation and customization and may be your biggest unknown bottleneck for rendering to glass.</p>
<ul>
<li>Network connection = Fiber, cable, wi-fi, 5G, 4G, 3G, “<a href="https://web.dev/articles/performance-poor-connectivity#lie-fi">lie-fi</a>”</li>
<li>Viewport = <code>height, width, initial-scale, horizontal-viewport-segments, vertical-viewport-segments, viewport-segment-width, viewport-segment-height</code>, … etc.</li>
<li>Environment contstants = <code>safe-area-inset-*</code>, <code>titlebar-area-*</code>, <code>keyboard-inset-*</code>(e.g, <a href="https://css-tricks.com/the-notch-and-css/">iPhone Notch</a>, rounded corners, <a href="https://alistapart.com/article/breaking-out-of-the-box/">installed apps</a>)</li>
<li>Pixel density = 1x, 2x (Retina), 3x, … etc.</li>
<li>Low-power mode</li>
<li>Screen brightness</li>
<li>CPU speed</li>
<li>GPU/dGPU</li>
<li>L1/L2/L3 cache</li>
<li>CPU/GPU/Memory contention (e.g., other apps open)</li>
<li>Color-gamut support = Rec2020, P3, sRGB, …etc</li>
<li>Keyboard = Embedded, External, <a href="https://en.wikipedia.org/wiki/T9_(predictive_text)">T9</a>, Virtual On-screen, Touchbar, … etc</li>
<li>XR support = <code>inline, immersive-vr, immersive-ar</code></li>
</ul>
<h3>Modalities</h3>
<p>Users aren’t uniform in how they interact with their devices and may be using one or any combination of inputs and outputs all at once.</p>
<ul>
<li>Inputs
<ul>
<li>Mouse = one-button, two-button, mousewheel, trackball, touchpad, high/low DPI</li>
<li>Keyboard = 100%, 60%, 10-key, querty, colemak, Ergonomic, split, mechanical, … etc</li>
<li>Touch/Tap = coarse pointer, no hover</li>
<li>Stylus = fine pointer, hover, pressure sensitivity</li>
<li>Gestures = pinch-zoom, two/three/four-finger swipe</li>
<li>Motion = accelleration, shake-to-undo, bump, … etc</li>
<li>Orientation = landscape, portrait, alpha/beta/gamma (360º/180º/90º, respectively) rotation</li>
<li>Speech recognition = Dragon NaturallySpeaking, voice assistants</li>
<li>Switches = button, sip, puff</li>
<li>Eye-tracking</li>
<li>Gamepad</li>
<li>XR = 3 DOF, 6 DOF</li>
</ul>
</li>
<li>Outputs
<ul>
<li>Screen</li>
<li>Text-to-speech</li>
<li>Screen reader</li>
<li>Braille</li>
<li>Screen magnifier</li>
<li>Vibration</li>
<li>RSS?</li>
</ul>
</li>
</ul>
<h3>Browser states</h3>
<p>Finally, a user’s browser choice and preferred plugins determines a lot about how they experience (or would prefer to experience) your UI and your application can be responsive to some of those preferences.</p>
<ul>
<li>User preferences
<ul>
<li>prefers-color-scheme = light, dark, forced-colors</li>
<li>prefers-reduced-motion = reduce, no-preference</li>
<li>prefers-reduced-transparency = reduce, no-preference</li>
<li>user zoom = 100% to 400%</li>
<li>text size = small to x-large</li>
</ul>
</li>
<li>Features and functionality
<ul>
<li>Browser version = latest version, last 2 versions, older</li>
<li>Feature detection = <code>@support</code> or polyfills</li>
<li>Color-gamut support = Rec2020, P3, sRGB, …etc</li>
<li>Browser cache hit</li>
<li>Service worker hit</li>
<li>Display mode = fullscreen | standalone | minimal-ui | browser</li>
<li><code>beforeinstallprompt</code></li>
<li>Print mode</li>
<li>Reader mode</li>
<li>JavaScript disabled = yes, I actually know people who do this.</li>
<li>Sleeping tabs</li>
</ul>
</li>
<li>Permissions
<ul>
<li>Camera = true, false</li>
<li>Microphone = true, false</li>
<li>Geolocation = allowed, not allowed, only while using the app</li>
<li>Notifications = true, false</li>
<li>File access = true, false</li>
</ul>
</li>
<li>Plugins
<ul>
<li>Ad blockers - UBlock, Safari ITP, Ghostery, … etc</li>
<li>Custom plugins/Boosts</li>
</ul>
</li>
</ul>
<h3>User states</h3>
<p>Thus far we’ve talked about technology, now let’s consider the actual human being at the other end of the transaction. A user’s physical or mental state impact their cognitive or literal bandwidth to enjoy your experience.</p>
<ul>
<li><a href="https://meyerweb.com/eric/thoughts/2016/01/25/designing-for-crisis-design-for-real-life/">Having an emergency/crisis</a></li>
<li>Cognitive impairment</li>
<li>Permanently or temporarily disabled</li>
<li><a href="https://butyoudontlooksick.com/articles/written-by-christine/the-spoon-theory/">“Out of spoons”</a></li>
<li>Inside or outside</li>
<li>On a plane or train</li>
<li>In the city or in the woods</li>
</ul>
<h2>Third-party service states</h2>
<p>Third parties have an outsized impact on the user experience of a UI.</p>
<h3>Availability/Status</h3>
<p>The status/availability/uptime of other servers is the biggest surface area for failure for a UI.</p>
<ul>
<li>Server hardware status = online, offline, partial availability</li>
<li>Database status = online, offline, transaction locked</li>
<li>API status = online, offline, partial availability</li>
<li>Web font service = online, offline, partial availability</li>
<li>DNS status = may take up to 72 hours to resolve</li>
<li>Package dependencies = working, broken, malicious injection, protestware, … etc</li>
<li>Asset delivery and caching status
<ul>
<li>Cloudflare</li>
<li>S3</li>
</ul>
</li>
</ul>
<h3>Script injections</h3>
<p>Third-party script injections are the biggest contributor to performance degradation on a UI. Some services even take over the user experience of an application. This is often out of your control.</p>
<ul>
<li>Analytics/tracking services</li>
<li>User session recording services</li>
<li>A/B test injections</li>
<li>Instructional overlays</li>
<li>Accessibility overlays</li>
<li>Third-party authentication (OAuth) services</li>
<li>Captcha/verification services</li>
</ul>
<p>You haven’t truly lived life until one of these unchecked services takes down an application.</p>
<h2>There’s more to UI than just state…</h2>
<p>I’m sure I’ve forgotten whole categories of state. I haven’t even gotten into the hundreds of CSS properties and the thousands of values and their potential conflicts. I didn’t talk about the intricacies of styling form controls or building dropdowns with the required ARIA property combinations. I didn’t touch on <a href="https://cloudfour.com/thinks/responsive-images-101-definitions/">the decision matrix required to put an image on the page</a>. Nor does this get into <a href="https://github.com/joshbuchea/HEAD">setting all the proper tags in the <code>head</code></a> <a href="https://rviscomi.github.io/capo.js/">in the right order</a>. Nor does this discuss <a href="https://microformats.org/">microformats</a> for SEO or all the code you need to properly setup a UI to send analtyics data.</p>
<p>In closing, hire people who are good at UI.</p>

  </div>

  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why we stopped building cut and cover (176 pts)]]></title>
            <link>https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/</link>
            <guid>39398803</guid>
            <pubDate>Fri, 16 Feb 2024 16:04:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/">https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/</a>, See on <a href="https://news.ycombinator.com/item?id=39398803">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>We used to dig up roads to put trains underneath – cheaply. Ever-better tunnel boring machines have made the disruption this causes unnecessary.</p><article><div role="presentation"><p>Tunneling is one of the many technologies that make modern ​civilization possible. For one, a tunnel can dramatically reduce transportation costs by shortening travel times between two points. Prior to the construction of the Holland Tunnel beneath the Hudson River in New York, for instance, the only way across was via ferry, a journey that <!-- --><a href="https://www.ascemetsection.org/committees/history-and-heritage/landmarks/holland-tunnel">could take hours</a> if the ferries were backed up. Tunnels are also needed to build large-scale infrastructure projects: hydroelectric dams require tunnels to divert water around the construction site and to feed water to the ​turbines. And tunneling can create new, valuable land beneath dense urban areas. By going underground, we can create the space for horizontal ​infrastructure such as subway lines without destroying existing buildings or disrupting the urban fabric. This makes tunneling an important tech­nology for building cities that people like living in.<!-- --></p>



<!-- --><p>Historically, most subways were built using what’s known as ‘cut and cover’ excavation: digging an open trench, building the tunnel structure within it, and then covering the trench up. Cut and cover was used for the first London subway line, in 1860; it was used for the construction of New York’s first subway, in 1900; and for nearly a century it remained the preferred method of building subway tunnels. As late as the 1970s, most subway construction in the US was done using cut and cover.</p>


<!-- -->


<!-- --><p>For many types of underground construction, especially in undeveloped greenfield land, <!-- --><a href="https://www.waterproofmag.com/2012/01/cut-and-cover-tunnels/">cut and cover is still widely used</a>. And cut and cover is still the primary method of constructing underground train stations. But for urban subway tunnels, cut and cover has largely been supplanted by the use of tunnel-boring machines (TBMs), which tunnel horizontally beneath the ground without disturbing the surface. In a <!-- --><a href="https://datawrapper.dwcdn.net/MYoQk/5/">database compiled by Britain Remade of recent transit projects</a> around the world, there are 80 projects listed as using TBMs, compared to just one being built with cut and cover.<!-- --></p>



<!-- --><p>Some transit experts believe that this transition was a misstep. Cut and cover is a much more disruptive construction method (since it tears up the street while construction is taking place), but it’s often much cheaper than using a TBM. During construction of the <!-- --><a href="https://en.wikipedia.org/wiki/Canada_Line">Canada Line</a> in Vancouver, between 2005 and 2009, changing from bored tunnel to cut and cover <!-- --><a href="https://rccao.com/research/files/RCCAO-STATION-TO-STATION-REPORT-APRIL2020.pdf">saved more than $400 million</a> in construction costs, 16 percent of the cost of the entire project. Alon Levy of the <!-- --><a href="https://marroninstitute.nyu.edu/initiatives/transit-costs-project">Transit Costs Project</a> argues that ‘<!-- --><a href="https://pedestrianobservations.com/2021/02/25/cut-and-cover-is-underrated/">cut and cover is underrated</a>’, and it should merit more consideration when deciding how a transit project should be built:<!-- --></p>



<!-- --><blockquote><p>Regrettably, people don’t seem to even recognize it as a tradeoff, in which they spend more money to avoid surface disruption – some of our sources have told us that avoiding top-down cut and cover is an unalloyed good, a kind of modernity. Even more regrettably, this same thinking is common in much of the developing world, where subways tend to be bored.</p></blockquote>



<!-- --><p>But cut and cover has always been an unpopular method of construction, opposed by urban residents since the very first time it was used. Cut and cover may often be cheaper in terms of dollars, but as tolerance for the disruptive effects of construction has decreased, the <!-- --><em>political</em> costs of using cut and cover have risen. And as other tunneling technology has improved, the relative advantage of using cut and cover has decreased.&nbsp;<!-- --></p>



<!-- --><h3>A brief overview of tunneling technology</h3>



<!-- --><p>Understanding why tunnel-boring machines replaced cut and cover requires knowing a little bit about how tunnel construction works.</p>



<!-- --><p>With cut and cover construction, the basic method – digging a trench and then covering the trench up – is simple. But there are a variety of ways that this can be done, depending on the specifics of the tunnel and where it’s being built. The most straightforward method is to dig a trench with gently sloping sides that require no additional support. Once you’ve dug down deep enough, you build your structure, and cover everything back up again.</p>



<!-- --><figure><img loading="lazy" width="1024" height="609" src="https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1024x609.png" alt="" srcset="https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1024x609.png 1024w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-300x179.png 300w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-768x457.png 768w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1536x914.png 1536w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-2048x1219.png 2048w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-402x239.png 402w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-462x275.png 462w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-662x394.png 662w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-722x430.png 722w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-982x584.png 982w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1032x614.png 1032w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1402x834.png 1402w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-1702x1013.png 1702w, https://wip.gatspress.com/wp-content/uploads/2024/02/cut-and-cover-tunneling-2002x1192.png 2002w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<!-- --><p>Because the sides of the trench slope outward, this method occupies a lot of horizontal space. And the deeper the excavation, the more space is required. This can make it a challenge to use in urban areas, where that space is occupied by buildings and other infrastructure. To avoid this, cut and cover construction will instead often excavate straight downward, using support structures to prevent the walls from caving in.</p>



<!-- --><p>These supports can be built in a variety of different ways. One common method is to use piles, large posts that are driven deep into the earth. Piles are typically made from either steel or concrete, and can either be spaced close enough together that they form a continuous wall (such as with <!-- --><a href="https://www.kagaoanengineering.com/secant-and-tangent-pile-walls">secant piles</a> or <!-- --><a href="https://railsystem.net/sheet-pile-wall-construction/">sheet piles</a>), or spaced farther apart with infill structure between them, such as timber lagging (wood boards that span between piles) or shotcrete (sprayed concrete).<!-- --></p>



<!-- --><figure><img src="https://www.wsp.com/-/media/service/global/image/img-amtrak-gateway-program.jpg?h=710&amp;iar=0&amp;w=1440&amp;hash=6E86A2468F05791D74E053169A5B6A24" alt="">
          <!-- --><figcaption>
            <!-- --><div>
                <!-- --><p>Image</p>
                <!-- --><div><p>
                  Image from </p><!-- --><p><a href="https://www.wsp.com/en-us/services/cut-and-cover-tunneling">WSP</a>.
                </p><!-- --></div>
              <!-- --></div>
          <!-- --></figcaption>
        <!-- --></figure>



<!-- --><p>Another type of vertical support structure is the <!-- --><a href="https://en.wikipedia.org/wiki/Slurry_wall">slurry wall</a>, sometimes called the Milan system. With this method, a deep, narrow trench is excavated and filled with bentonite, a dense clay slurry, which prevents the sides from collapsing. The trench is then filled with concrete, which displaces the bentonite and forms a continuous wall when it solidifies. ​The Milan method was invented in the 1940s, and was notably used to <!-- --><a href="https://www.911memorial.org/connect/blog/slurry-wall-behind-engineering-feat-made-wtc-possible">create the ‘bathtub’ foundation on the original World Trade Center</a>.<!-- --></p>



<!-- --><p>As excavation proceeds downward, these vertical supports need to be braced to resist the horizontal force of the soil. This can be done with steel braces that span the width of the trench, or with soil anchors that tie the walls back into the surrounding soil.</p>



<!-- --><p>Cut and cover also uses different methods for building the tunnel structure itself. In the conventional method, known as bottom-up, the trench is fully excavated and the tunnel structure is built up starting from the bottom. With the top-down method, by contrast, the tunnel is excavated only partway down, and then the roof of the tunnel is built using the existing soil as a vertical support. Once the roof is in place, the rest of the tunnel is then excavated below it. With top-down construction, the surface can be completely restored after the roof has been built; with bottom-up, the top of the excavation will often be covered with temporary decking to allow use of the surface while tunnel construction is taking place.</p>



<!-- --><figure><img loading="lazy" width="1024" height="554" src="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1024x554.png" alt="" srcset="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1024x554.png 1024w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-300x162.png 300w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-768x416.png 768w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1536x832.png 1536w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-402x218.png 402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-462x250.png 462w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-662x358.png 662w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-722x391.png 722w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-982x532.png 982w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1032x559.png 1032w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1402x759.png 1402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34-1702x921.png 1702w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.01.34.png 1932w" sizes="(max-width: 1024px) 100vw, 1024px">
          <!-- --><figcaption>
            <!-- --><div>
              <!-- --><p>
                Cut and cover tunneling using different construction sequences: (a) bottom-up (b) top-down.
              </p>
              <!-- --><div>
                <!-- --><p>Image</p>
                <!-- -->
              <!-- --></div>
            <!-- --></div>
          <!-- --></figcaption>
        <!-- --></figure>



<!-- --><p>With a tunnel-boring machine, the basic method is different. Instead of digging downward, TBMs use large rotating cutting heads to excavate horizontally through the ground. Behind the rotating cutting head will be conveyors for carrying away excavated material (known as muck), hydraulic jacks for pushing the machine forward, and machines for installing the tunnel lining. A modern TBM is very much like a mobile factory that pushes its way through the earth and leaves a completely constructed tunnel behind it.</p>



<!-- --><p>Like with cut and cover, TBMs comprise a variety of specific excavation technologies that vary depending on the project. At a high level, TBMs are categorized by whether they’re designed to tunnel through soil and soft ground or through rock (though today there are increasingly <!-- --><a href="https://www.robbinstbm.com/products/tunnel-boring-machines/crossover-machines/">crossover machines</a> that can do both).<!-- --></p>



<!-- --><p>Soft-ground TBMs evolved from unmechanized tunnel shields, large hollow structures that supported the sides of the tunnel while it was being excavated. The tunnel shield was invented by Marc Brunel (father of ​Isambard Kingdom Brunel) in 1806 for tunneling under the Neva River in Russia, and was first used to <!-- --><a href="https://en.wikipedia.org/wiki/Thames_Tunnel">tunnel under the Thames in 1825</a>. <!-- --></p>



<!-- --><p>Brunel’s shield consisted of a 21-foot-tall grid of iron frames, divided into 12 separate frames, each one consisting of three compartments stacked on top of one another. Within each compartment, the face of the tunnel would be supported by a series of boards called poling boards. A worker would remove a single board, dig away the soil behind it to a depth of around nine inches, and then replace the board and move on to the next one. After all boards had been dug out, the frame would advance forward with large mechanical jacks, and the process would repeat. Behind the shield, brick lining would be installed around the sides of the tunnel to form its structure. With Brunel’s shield, tunneling under the Thames proceeded at about eight feet per week on average.</p>



<!-- --><figure><img loading="lazy" width="787" height="542" src="https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield.png" alt="" srcset="https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield.png 787w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-300x207.png 300w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-768x529.png 768w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-402x277.png 402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-462x318.png 462w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-662x456.png 662w, https://wip.gatspress.com/wp-content/uploads/2024/02/Thames_tunnel_shield-722x497.png 722w" sizes="(max-width: 787px) 100vw, 787px">
          <!-- --><figcaption>
            <!-- --><div>
              <!-- --><p>
                Caption: Tunneling shield used in construction of the Thames Tunnel in London.
              </p>
              <!-- --><div>
                <!-- --><p>Image</p>
                <!-- -->
              <!-- --></div>
            <!-- --></div>
          <!-- --></figcaption>
        <!-- --></figure>



<!-- --><p>Brunel’s shield was rectangular in shape, but most subsequent tunnel shields were circular. Early shields used workers with picks and shovels to do the actual excavation, but over time mechanical excavation equipment was added. In the early 1900s John Price developed a tunnel shield that had a large, rotating disc mounted to the front. Bucket-shaped cutters ​attached to the front of the disc would scrape away soil as it rotated and feed it into a conveyor for removal. Price’s mechanized shields were an ​immediate success, and over the next several decades were used to dig ​subways around the world, and are the ancestor of modern soft-​ground TBMs.</p>



<!-- --><p>The tunnel shield prevented the sides of the tunnel from collapsing while it was bored, but they still required some method to prevent the face of the tunnel from collapsing, and to prevent water from intruding when tunneling below the water table. By the late nineteenth century, the standard method was to use compressed air. By pressurizing the tunnel to several times atmospheric pressure, water would be kept out. Compressed air remained in use well into the twentieth century, and is still sometimes used today, but it has been largely supplanted by slurry machines and earth pressure balance machines, which respectively use a bentonite slurry and the excavated material itself to support the face of the tunnel. Today, earth pressure balance machines are the most common type of TBM for tunneling through soil.</p>



<!-- --><p>Rock TBMs evolved separately from soil TBMs. In soil, the task of ex­cavation was comparatively simple, and the primary challenge was finding a way to prevent the tunnel from collapsing while it was being dug. In rock, the tunnel could often support itself while it was being dug, and the primary difficulty was building a machine robust enough to carve through rock. This second task proved much more difficult, and successful rock-tunneling machines were developed much later than soil-tunneling machines.</p>



<!-- --><p>Attempts to build rock-tunneling machines date back to the 1850s, but the first successes appeared in the 1950s, when <!-- --><a href="https://www.robbinstbm.com/about/history/">James Robbins developed the disc cutter</a> for the <!-- --><a href="https://en.wikipedia.org/wiki/Oahe_Dam">Oahe Dam</a> project. Prior to this, most attempts at mechanical rock-tunneling machines used drag picks, sharp steel tools that scraped away bits of rock as the cutting head rotated. Robbins’s disc cutter, on the other hand, rolled freely over the surface of the rock like a wheel. As the tunneling machine pressed the disc cutter against the face of the rock, the rock cracked and flaked off.<!-- --></p>



<!-- --><figure><img loading="lazy" width="1024" height="350" src="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1024x350.png" alt="" srcset="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1024x350.png 1024w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-300x103.png 300w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-768x262.png 768w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1536x525.png 1536w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-402x137.png 402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-462x158.png 462w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-662x226.png 662w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-722x247.png 722w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-982x336.png 982w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1032x353.png 1032w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1402x479.png 1402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31-1702x582.png 1702w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.04.31.png 1978w" sizes="(max-width: 1024px) 100vw, 1024px">
          <!-- --><figcaption>
            <!-- --><div>
              <!-- --><p>
                How two disc cutters chip away rock.
              </p>
              <!-- --><div>
                <!-- --><p>Image</p>
                <!-- -->
              <!-- --></div>
            <!-- --></div>
          <!-- --></figcaption>
        <!-- --></figure>



<!-- --><p>Robbins’s disc cutter greatly increased how fast a rock-tunneling machine could tunnel. And disc cutters lasted much longer before needing to be replaced than drag picks, meaning the machines spent more time tunneling and less time down for maintenance. As a result, Robbins’s machine made it economical to mechanically tunnel through the rock for the first time. <!-- --><a href="https://www.robbinstbm.com/">The Robbins Company</a> remains a builder of all types of TBMs today, and the disc cutter continues to be the standard method for excavation on rock TBMs.<!-- --></p>



<!-- --><p>There are also other ways to bore a tunnel besides using a TBM. A <!-- --><a href="https://en.wikipedia.org/wiki/Roadheader">roadheader</a> uses a small, rotating cutter mounted to a boom arm that gets moved back and forth over the tunnel face (this is in contrast to a TBM, which excavates the entire face of the tunnel at once).<!-- --></p>



<!-- --><p><a href="https://en.wikipedia.org/wiki/Drilling_and_blasting">Drill and blast</a> involves drilling several holes in the face of the tunnel ​(typically using a mechanical drilling machine known as a <!-- --><a href="https://en.wikipedia.org/wiki/Drilling_jumbo">drilling jumbo</a>) and setting off explosives in them. Drill and blast was the primary method of excavating rock tunnels prior to the invention of rock TBMs, and is &nbsp;<!-- --><a href="https://nyatunnelbanan.se/en/blasting-is-now-being-performed-at-61-sites-simultaneously/">still widely used today</a>.<!-- --></p>



<!-- --><p>The <!-- --><a href="https://www.soundtransit.org/sites/default/files/project-documents/SEM_final.pdf">sequential excavation method</a> (SEM), also known as the New Austrian ​tunneling method, excavates a tunnel in small ‘bites’ using <!-- --><a href="https://en.wikipedia.org/wiki/Excavator#:~:text=Excavators%20are%20heavy%20construction%20equipment,undercarriage%20with%20tracks%20or%20wheels.">mechanical excavators</a> and other equipment, and supports the sides of the tunnel using <!-- --><a href="https://en.wikipedia.org/wiki/Shotcrete">shotcrete</a>.<!-- --></p>



<!-- --><figure><img loading="lazy" width="1024" height="628" src="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1024x628.png" alt="" srcset="https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1024x628.png 1024w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-300x184.png 300w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-768x471.png 768w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1536x942.png 1536w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-402x247.png 402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-462x283.png 462w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-662x406.png 662w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-722x443.png 722w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-982x603.png 982w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1032x633.png 1032w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1402x860.png 1402w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-1702x1044.png 1702w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1-2002x1228.png 2002w, https://wip.gatspress.com/wp-content/uploads/2024/02/Screenshot-2024-02-12-at-15.12.43-1.png 2034w" sizes="(max-width: 1024px) 100vw, 1024px">
          <!-- --><figcaption>
            <!-- --><div>
                <!-- --><p>Image</p>
                <!-- --><p>
                  Caption: Sketch of the sequential excavation method (SEM).
                </p>
              <!-- --></div>
          <!-- --></figcaption>
        <!-- --></figure>



<!-- --><h3>Changing technology, changing economics</h3>



<!-- --><p>For most of history, cut and cover was the cheapest way to build an urban tunnel, and boring was only done if cut and cover wasn’t an option. In the construction of <!-- --><a href="https://en.wikipedia.org/wiki/Early_history_of_the_IRT_subway">New York’s first subway, in 1900</a>, for instance, cut and cover was estimated to be just an eighth the cost of boring a tunnel, but it could only be used on about half the total length of the line.<!-- --><sup id="ref-1"></sup> Because the ground of New York varies in elevation substantially, keeping the tracks straight required tunnels bored through rock, which were built using drill and blast.<!-- --></p>



<!-- --><p>But as tunneling machine technology continued to advance, this calculus changed. Brunel’s non-mechanized shield tunneled under the Thames at the glacial pace of eight feet per week. By the early 1900s, Price mechanized shields were achieving excavation rates of nearly 200 feet per week. And by the 1970s, TBMs were achieving rates of 1,400 feet per week in soft ground, and 1,900 feet per week in rock.</p>


<!-- -->


<!-- --><p>As TBMs got faster, they also got cheaper, and became increasingly competitive with cut and cover. When a TBM was used to bore some of the tunnels on the Bay Area Rapid Transit (BART) project in the 1960s, its costs were just <!-- --><a href="https://archive.org/details/analysisofbartca1978davi/page/26/mode/2up?q=%22cut+and+cover%22">40 percent higher on average</a> than the cut and cover sections, a far cry from the eight-times cost difference on the New York Subway. ​A 1994 study of <!-- --><a href="https://www.researchgate.net/publication/341325652_Etude_des_couts_des_infrastructures_de_transport_ferroviaire_en_zone_urbaine_et_suburbaine">French subway construction costs</a> on over 90 miles of underground tunnel found that only in the most difficult underground conditions was tunnel boring more expensive on average than cut and cover.<!-- --></p>



<!-- --><p>Depending on the nature of the project and how disruptive surface construction would be, TBMs in some cases began to be cheaper than cut and cover. A <!-- --><a href="https://archive.org/details/finalalternative00unse_0/page/n31/mode/2up?q=%22cut+and+cover%22">1980 environmental analysis for a rapid transit system for Los Angeles</a> estimated that cut and cover construction would be more expensive than bored tunnel, due to needing to use eminent domain to buy and destroy homes along the roads. And when Seattle planned a tunnel to replace the <!-- --><a href="https://en.wikipedia.org/wiki/Alaskan_Way_Viaduct">Alaskan Way Viaduct</a> in the early 2000s, the costs of a bored tunnel were projected to be comparable to cut and cover, but the disruptions to the city caused by cut and cover were projected to cost several additional billion dollars.<!-- --><sup id="ref-2"></sup></p>



<!-- --><p>Similarly, TBMs have high fixed costs (in the form of the time, effort, and expense to buy the machine and get it set up) but low operational costs: once they are up and running, the marginal cost of additional excavation is low. TBMs are thus often particularly economical on large tunneling projects where the fixed costs of the machine can be thinly spread. ​When Madrid built 60 miles of underground tunnel when constructing its metro in the late 1990s and early 2000s, it achieved a famously low cost ​of €42 million per kilometer (about $73 million per kilometer in 2023 dollars) using TBMs. And the recent <!-- --><a href="http://www.madrid.org/media/transportes/ampliacion-linea11-metro/documento3-presupuesto.pdf">extension of the L11 line</a> in Madrid, which adds another 4.3 miles to the metro system, likewise found that excavation with TBMs would be cheaper than cut and cover.<!-- --></p>



<!-- --><p>Underground construction is high variance, and the costs of construction can vary greatly depending on the nature of the project and the conditions of the ground.<!-- --><sup id="ref-3"></sup> The best construction technology for a given project will depend on the specifics of that project. As Alon Levy notes, cut and cover is still a useful arrow to have in a tunneler’s quiver, as per the $400 million savings it achieved on the Canada Line. Given the comparative labor intensity of cut and cover (TBMs are highly automated, and can operate with a very small number of workers), it is likely especially appropriate for countries in Asia and Africa with low wages. But as TBM technology has advanced, it’s become more and more attractive for urban tunneling.<!-- --></p>



<!-- --><h3>Cut and cover gets harder</h3>



<!-- --><p>While tunnel-boring technology has gotten better and better, cut and cover has steadily gotten more difficult. The chief issue is the fact that cut and cover creates an enormous amount of disruption on the surface while excavation is taking place. The construction creates dirt, noise, and flooding, and can damage nearby properties as the ground is dug up; this has resulted in <!-- --><a href="https://archive.org/details/redlineextension01mass/page/n99/mode/2up?q=%22cut-and-cover%22">numerous lawsuits against transit authorities</a> (tunnel builders will generally include a contingency to pay for buildings damaged as a result of construction for this reason).<!-- --></p>



<!-- --><p>Most importantly, in cut and cover construction the street gets torn up and portions of it become unusable, sometimes for years. Access to businesses is blocked, retail sales fall, and people complain. Disruption of traffic has been called ‘<!-- --><a href="https://archive.org/details/cutandcovertunne00wick/page/28/mode/2up">the plague</a>’ of cut and cover construction:<!-- --></p>



<!-- --><blockquote><p>Noise and dust receive their share of complaints, but these can be controlled to some extent to minimize nuisance. It is the day-to-day rerouted obstacle course of construction equipment, barricades, flagmen, and rattling deck beams that create an impression of confusion and personal affront to the daily commuter or casual visitor.</p></blockquote>



<!-- --><p>Traffic disruption from cut and cover is especially egregious because the nature of subway construction projects means that construction is likely to take place in the most heavily congested areas of the city, making the problem worse until construction is completed.</p>



<!-- --><p>In <!-- --><em>The Great Society Subway</em>, Zachary Schrag talks about the disruptions caused by cut and cover during the construction of the Washington, DC, Metro, stating that ‘cut and cover meant pain’:<!-- --></p>



<!-- --><blockquote><p>Virginia Ali, whose Chili Bowl restaurant had served U Street since 1958, had endured riots and illicit drug markets, but subway construction was worse. With U Street itself blocked off, customers had to find their way through alleys. If construction workers hit a gas line, diners would have to evacuate, and frequently Ali found her restaurant’s floor inches deep in dirty water that ran off the wooden blanks that served as U Street’s decking. A block-long stretch of 7th Street turned into a twenty-foot deep garbage pit; residents fretted that children might climb through the shoddy fences and fall in. By the eve of completion, a neighborhood resident mourned ‘after five years of construction, the name of the game right now is survival’.</p></blockquote>



<!-- --><p>Cut and cover can also cause subsidence in the ground surrounding the excavation site, damaging surrounding buildings. TBMs will sometimes be chosen as the excavation method even when they’re more expensive purely to reduce this risk.</p>



<!-- --><p>Because of the disruptions it causes, cut and cover transit construction has been unpopular since its inception. London’s <!-- --><a href="https://archive.org/details/tunnelsplanningd0002mega/page/10/mode/2up">first two underground railways were built using cut and cover</a>, but public objections to the disruptions it caused, plus the fact that most of the remaining streets were too small to practically use, forced subsequent lines to be built using bored tunnel.<!-- --></p>



<!-- --><p>In the construction of New York’s first subway, cut and cover was described as ‘<!-- --><a href="https://archive.org/details/isbn_9780312591328/page/312/mode/2up?q=%22cut+and+cover%22">making life miserable for a few years</a>’. Boston built its first subway (and the first subway in the US) using cut and cover, but when designing an extension to the Red Line in 1977 it opted for less disruptive tunnel boring in many locations, such as the <!-- --><a href="https://archive.org/details/redlineextension01mass/page/n99/mode/2up?q=%22cut-and-cover%22">segment between Harvard Square and Porter Square</a>:<!-- --></p>



<!-- --><blockquote><p>The deep bore tunneling method was chosen over the cut and cover method because it will lessen the impact during construction on the surrounding neighborhoods. Specifically, the deep bore method negates the need to tear up Massachusetts Avenue, which runs along most of the length of this section and which, if narrowed to half its width, would cause severe traffic congestion problems. Additionally, shops along this section of Massachusetts Avenue, which number between 40 and 50, would incur substantial economic losses due to a temporary loss of customer parking spaces, advertising exposure, and customer accessibility.</p></blockquote>



<!-- --><p>The disruptions caused by cut and cover often make using it difficult, even when it’s cheaper than other methods. In their <!-- --><a href="https://archive.org/details/tunnelsplanningd0002mega/page/n7/mode/2up">1981 textbook on tunneling</a>, TM Megaw and JV Bartlett note that ‘The negotiations with those affected by a new [subway] line are likely to be far more difficult for cut and cover construction than for a deep tunnel. Objections sometimes are given disproportionate publicity; the promoters have to justify their proposals in much greater detail’.<!-- --></p>



<!-- --><p>During the construction of Atlanta’s subway, MARTA, in the 1970s, the planned use of cut and cover in the downtown area <!-- --><a href="https://www.princeton.edu/~ota/disk3/1976/7602/7602.PDF">caused a major backlash</a>, and caused the planners to <!-- --><a href="https://rosap.ntl.bts.gov/view/dot/11690">switch to bored tunnel</a>. When planning the BART extension to reach San Francisco Airport in 1995, transit ​advocates argued that BART’s preferred alternative required tunneling that would cost $135 million more than cut and cover, but if cut and cover was used the cities of South San Francisco and San Bruno would <!-- --><a href="https://books.google.com/books?id=SpofAAAAMAAJ&amp;pg=PA2096&amp;dq=bart+cut+and+cover+construction+vs+tunnels&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwi8iL7-kKOBAxVQnGoFHSZlBh44ChDoAXoECAoQAg#v=onepage&amp;q=bart%20cut%20and%20cover%20construction%20vs%20tunnels&amp;f=false">oppose the plan because of the construction impacts</a>. When a cut and cover tunnel was proposed for the Alaskan Way Viaduct replacement in Seattle, it was <!-- --><a href="https://books.google.com/books?id=7Xw2AQAAMAAJ&amp;pg=PA13&amp;dq=cut+and+cover+deep+bore+tunnel+cost&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwjxkujMn4KCAxWLLkQIHQdsBV44ChDoAXoECAgQAg#v=onepage&amp;q=cut%20and%20cover%20deep%20bore%20tunnel%20cost&amp;f=false">rejected by Seattle voters</a>.<!-- --></p>



<!-- --><p>The ability for citizens and advocacy groups to oppose disruptive cut and cover projects has likely been strengthened by environmental laws, such as the National Environmental Policy Act (NEPA), that require government agencies to investigate and disclose the environmental impacts of their projects. These laws first began to appear in the late 1960s, and provide an avenue for affected parties to oppose projects by arguing that agencies haven’t followed the proper administrative procedures. ​The previously mentioned Canada Line project, for instance, <!-- --><a href="https://archive.org/details/canadianenvironm0026unse/page/18/mode/2up?q=%22cut+and+cover%22">was sued</a> by a group of citizens who objected to the use of cut and cover under Canada’s <!-- --><a href="https://web.archive.org/web/20230321182016/https://www.canada.ca/en/impact-assessment-agency/services/policy-guidance/canadian-environmental-assessment-act-overview.html">Environmental Assessment Act</a>. They argued that the proper ​procedure had not been followed when disclosing the impacts of it. ​The appeals court noted that citizens objecting to public projects by ‘challenging not the substantive decision of government approving the project, but the process by which the government decision-makers informed the public’, had become common.<!-- --></p>



<!-- --><p>The nature of cut and cover construction means that we might expect it to get more expensive over time. A major expense of cut and cover construction is having to relocate below-ground utilities, and the more that have to be relocated, the greater the cost. As cities age, and accumulate more buried services, this will naturally make relocating them more expensive compared to simply tunneling beneath them.</p>



<!-- --><p>With so much opposition to cut and cover, and the increasingly competitive costs of tunnel boring, it’s not surprising that developed countries have largely switched to the latter in built-up areas. And in fact, adopting a technology, then abandoning it later when its downsides are deemed to be too high, even if its replacement is more expensive, is a common arc of technological progression: until the 1940s, hydroelectric dams made up nearly a third of electricity generated in the US, but hydro plants stopped being built in the US in the 1970s, due largely to their disruption of river ecosystems and other negative environmental effects; aluminum wiring is cheaper than copper (which is why its used for <!-- --><a href="https://en.wikipedia.org/wiki/Aluminium-conductor_steel-reinforced_cable">long-distance transmission lines</a>), but the risks of fire due to improper installation in homes caused it to be <!-- --><a href="https://books.google.com/books?id=c69tJz28TSQC&amp;pg=PA249&amp;dq=use+of+aluminum+wiring&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwjXuKvNkK2BAxW-mmoFHXWYCwo4FBDoAXoECAoQAg#v=onepage&amp;q=use%20of%20aluminum%20wiring&amp;f=false">phased out in the 1970s</a>; and, of course, there’s currently an enormous effort dedicated toward replacing carbon-emitting energy sources with more more environmentally friendly low-carbon ones.<!-- --></p>



<!-- --><p>In fact, the existence of subways at all is arguably a result of this sort of progression. Prior to the subway-construction era in the US in the early twentieth century, many cities had rapid transit systems based on elevated ​trains. New York built the first elevated train line in the world in 1868, and by 1890 its elevated trains gave New York the largest mass transit system in the world, ten years before it began construction on its subway. By 1900, elevated urban trains had been built in Kansas City, Sioux City, Chicago, and Boston.</p>



<!-- --><p>But, not unlike cut and cover construction, building an elevated train came at the cost of incredible disruption to the surrounding area (and unlike an elevated train, that disruption remained after construction was complete). The structures reduced sunlight to the street below, and steam-powered elevateds on steel frames were incredibly noisy for surroundings, lowering the quality of life and property values in their immediate vicinity. Urban elevated trains were thus frequently opposed by residents.</p>



<!-- --><p>When Los Angeles was <!-- --><a href="https://www.construction-physics.com/p/how-the-car-came-to-la">considering a mass transit system</a> in the 1920s, it was opposed by citizen groups such as the Taxpayers’ Anti-Elevated League, and an LA reporter who researched elevated trains in other US cities <!-- --><a href="https://archive.org/details/losangelesautom00bott/page/152/mode/2up?q=devil">came away with the conclusion that</a> ‘an elevated is a many-legged and roaring steel serpent and should be shunned by all cities for the machination of the devil that it is’. Cities began to prefer subways to elevateds, despite the fact that they were two to four times as expensive to build as elevated trains. Since 1908, the US has only built one new urban elevated railway, in <!-- --><a href="https://en.wikipedia.org/wiki/Metrorail_(Miami-Dade_County)">Miami</a>, a city where the high water table makes underground construction difficult.<!-- --></p>



<!-- --><p>The US is partly an exception: dozens of elevated railways have been built across the developing and middle-income worlds in the past few decades. A handful have been built in developed countries, including the Docklands Light Railway in London, in the late 1980s, and the Yurikamome which connects Tokyo with Odaiba artificial island, in 1995. But both of these were built into virgin terrain as part of redevelopments, and residents came along later with their impacts already ‘priced in’. Both are also automated and electric, and run on concrete supports, making them much quieter than early 1900s elevateds (though the DLR can screech when it turns sharp corners).</p>



<!-- --><p>Cut and cover will sometimes be the best choice from a basic cost-benefit perspective, as will elevated rail, and both are useful to have in the tunnel construction toolbox for that reason. But technological deployment decisions are <!-- --><a href="https://worksinprogress.co/issue/why-skyscrapers-are-so-short">rarely governed purely by economics</a>. There’s always a broader calculus at work with any technology: a set of shifting norms, assumptions, culture, and institutions that governs what methods are considered acceptable for solving problems. Political costs and civic opposition will often make a technology unviable regardless of how the dollars and cents add up. Perhaps a policy will overcome this problem – if not, then cut and cover seems to be a casualty of this broader calculus, like so many technologies that have come before.<!-- --></p>
<!-- --></div></article><div><div id="reference-item-1"><p>1</p><p><span><em>722 Miles: The Building of the Subways and How They Transformed New York</em>, Clifton Hood 2004, p. 86</span></p></div><div id="reference-item-2"><p>2</p><p><span>Tracking down the costs of tunnel boring versus cut and cover for this project is difficult, but they appear to be similar. The initial, six-lane cut and cover tunnel was projected to cost </span><a href="https://web.archive.org/web/20061026053920/http://www.wsdot.wa.gov/Projects/Viaduct/Alternatives.htm"><span>$4.6 billion</span></a><span>. That was later cut down to a four-lane tunnel that would cost </span><a href="https://www.seattletimes.com/seattle-news/nickels-backing-for-4-lane-tunnel-lite-gets-cool-reception/"><span>$3.4 billion</span></a><span>. The ultimate budget of the bored tunnel, which used what at the time was the largest tunnel-boring machine in the world, was </span><a href="https://web.archive.org/web/20190629201419/https://www.wsdot.wa.gov/Projects/Viaduct/Budget"><span>$3.3 billion</span></a><span>. </span><a href="https://wsdot.wa.gov/sites/default/files/2021-05/AWV-PDF-FEIS-Summary.pdf"><span>Environmental impact documents</span></a><span> from the project also seem to show bored tunnel as having been cheaper than cut and cover, though making a direct comparison here is difficult since the projects have somewhat different scope.</span></p></div><div id="reference-item-3"><p>3</p><p><span>The previously mentioned French study found that in the most difficult ground conditions, tunneling costs per mile varied from ~250 million francs per mile to ~1,200 million francs per mile.</span></p></div></div></div>]]></description>
        </item>
    </channel>
</rss>