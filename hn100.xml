<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 03 Dec 2023 11:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Clang now makes binaries an original Pi B+ can't run (167 pts)]]></title>
            <link>https://rachelbythebay.com/w/2023/11/30/armv6/</link>
            <guid>38504134</guid>
            <pubDate>Sun, 03 Dec 2023 02:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2023/11/30/armv6/">https://rachelbythebay.com/w/2023/11/30/armv6/</a>, See on <a href="https://news.ycombinator.com/item?id=38504134">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2023/11/30/armv6/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[UniFi Express (160 pts)]]></title>
            <link>https://ui.com/cloud-gateways/express</link>
            <guid>38504027</guid>
            <pubDate>Sun, 03 Dec 2023 01:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ui.com/cloud-gateways/express">https://ui.com/cloud-gateways/express</a>, See on <a href="https://news.ycombinator.com/item?id=38504027">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not a real engineer (2019) (252 pts)]]></title>
            <link>https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html</link>
            <guid>38503486</guid>
            <pubDate>Sun, 03 Dec 2023 00:05:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html">https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html</a>, See on <a href="https://news.ycombinator.com/item?id=38503486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
            <article>
    
    <section>
        <p>You are not a real engineer.</p>
<p>You are a creature with a terrible countenance</p>
<p>the stature of a man</p>
<p>and the head of a lion</p>
<p>with sixteen wings about you</p>
<p>white as fresh snow</p>
<p>hundreds of eyes</p>
<p>that flicker like torches</p>
<p>and dart in all directions</p>
<p>the belt at your waist is a serpent</p>
<p>your breath is the gathering of stormclouds</p>
<p>your voice is the roar of the wind</p>
<p>the grass withers before your footsteps</p>
<p>and your writhing, ponderous tongue</p>
<p>black as the abyss</p>
<p>brings apocalypse upon everything it touches</p>

<p>We regret to inform you</p>
<p>we will not be offering you the role at this time –</p>
<p>we’re looking for somebody more technical</p>
    <hr>

    
    </section>
</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can't sign in with FIDO2 key on office.com (152 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=1824831</link>
            <guid>38502340</guid>
            <pubDate>Sat, 02 Dec 2023 21:45:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824831">https://bugzilla.mozilla.org/show_bug.cgi?id=1824831</a>, See on <a href="https://news.ycombinator.com/item?id=38502340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">










<div id="summary-container">


  
    <p><span id="field-value-status_summary">
      <span data-status="open">Open</span>
      <span id="field-value-bug_id">
        <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824831">Bug 1824831</a>
      </span>
      <span>
        <span>Opened <span title="2023-03-27 12:53 PDT" data-time="1679946799">8 months ago</span></span>
          <span>Updated <span title="2023-12-02 13:43 PST" data-time="1701553423">1 hour ago</span></span>
      </span>
        </span>
    </p>

  
</div>








































<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;121.0b6&quot;,&quot;FIREFOX_ESR&quot;:&quot;115.5.0esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;122.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2023-11-20&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2023-11-21&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2023-11-16&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2023-11-17&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;121.0b6&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;121.0b6&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;120.0.1&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2023-12-18&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2023-12-19&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2023-12-14&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2023-12-15&quot;}">



<div id="c0">

  <div id="ct-0" data-comment-id="16345428" data-ismarkdown="true"><p>+++ This bug was initially created as a clone of <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1820016" title="RESOLVED FIXED - Cannot assert discoverable credential on login.live.com">Bug #1820016</a> +++</p>
<p>Since #1820016 is fixed, I am able to log in on live.com using my FIDO2 security key.</p>
<p>However, on office.com I still am unable to do so (using a different business/paid account which works when using Chrome).</p>
</div><div><p>Flags: needinfo?(tim.cappalli)</p></div></div><div id="c1"><p>This is not a Firefox issue. A fix for AAD accounts on the Microsoft side is being worked on.</p><div><p>Flags: <span>needinfo?(tim.cappalli)</span></p></div></div><div id="c2"><p>Any chance to follow the progress as an outsider?</p></div><div id="c5"><div id="ct-5" data-comment-id="16370318" data-ismarkdown="true"><p>The severity field is not set for this bug.<br>
:jschanck, could you have a look please?</p>
<p>For more information, please visit <a href="https://wiki.mozilla.org/Release_Management/autonag#workflow.2Fno_severity.py" rel="nofollow">auto_nag documentation</a>.</p>
</div><div><p>Flags: needinfo?(jschanck)</p></div></div><div id="c6" data-comment-id="16443788" data-ismarkdown="true"><p>With Firefox 114.0 on Linux, I am able to log into by business account using a YubiKey on office.com. However, only when in private browsing mode of my day-to-day-profile. Using regular mode or a totally fresh profile (private or regular browsing mode), it does not work either ("We had a problem authenticating you. Please try again.").</p>
<p>Any chance to get an update here? It feels like this is really close to be usable.</p>
</div><div id="c7"><p>My understanding is that office.com is a weird exception because it can use the live.com personal account login flow for business accounts too. office.com works for me too, but I wouldn't say that's an indication of usability. I believe the AAD login flow fix by MSFT is still needed.</p></div><div id="a6993396_689878"><p>Severity: -- → S3</p><p>Flags: <span>needinfo?(jschanck)</span></p><p>Priority: -- → P5</p></div><div id="c9"><p>Is this still an issue, Rahul?</p><div><p>Flags: needinfo?(sergeantsagara)</p></div></div><div id="c10">

  <div id="ct-10" data-comment-id="16691323" data-ismarkdown="true"><p>Hi John,</p>
<p>Unfortunately, it is. Sharing a screenshot to demonstrate. Our company is working internally to push Microsoft to resolve this (it's not an issue with Firefox's implementation. This can be demonstrated by spoofing the useragent as a Chromium-based browser and attempting the same login flow or just using webauthn.io for validation testing). We unfortunately are not having much luck on our end with our support requests. If possible though, I would like to leave this issue open here for both Firefox users and Microsoft's reference.</p>
<p>Thanks,</p>
<p>Rahul Rameshbabu</p>
</div><div><p>Flags: <span>needinfo?(sergeantsagara)</span></p></div></div><div id="c11"><p>I can confirm, still an issue. M$ at its best. :/</p></div>



</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Retinal cells that help stabilize our world view (101 pts)]]></title>
            <link>https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/</link>
            <guid>38501878</guid>
            <pubDate>Sat, 02 Dec 2023 20:44:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/">https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/</a>, See on <a href="https://news.ycombinator.com/item?id=38501878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
  <div>
      <figure>
        <img width="1010" height="540" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery.png" alt="Human Retina" decoding="async" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery.png 1010w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-300x160.png 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-768x411.png 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-290x155.png 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-400x214.png 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-684x366.png 684w" sizes="(max-width: 1010px) 100vw, 1010px">                </figure>
    </div>
 
  
<p>The discovery will enable researchers to better understand eye movement disorders that cause significant visual impairment.</p>

<p><em>Article by <a href="https://vision.berkeley.edu/people/emily-ward/">Emily L Ward</a></em></p>

<p><span>H</span>erbert Wertheim School of Optometry &amp; Vision Science researchers have discovered rare neurons in the eye that are crucial for  our visual system to maintain a sharp, steady image of the world. These findings will impact our understanding of the human retina and likely provide insights into the pathology of eye movement disorders.</p>
<p>The study, recently published in <em>Nature</em>, was led by Teresa Puthussery, OD, PhD, an assistant professor at the Herbert Wertheim School of Optometry &amp; Vision Science and the <a href="https://neuroscience.berkeley.edu/">Helen Wills Neuroscience Institute</a>. First author, Anna Yao Mei Wang, PhD, is a postdoctoral scholar in <a href="https://www.retinalab.berkeley.edu/">The Puthussery Lab</a>. </p>

<h2>Gaze Stabilization in a Moving World</h2>
<p>The neurons identified are involved in a fundamental feature of everyday vision. As one walks down a busy street or looks out the window of a train, the gaze stabilization system operates below our conscious awareness causing the eyes to reflexively follow the direction in which the visual scene is moving. This visual mechanism works in concert with the vestibular system to maintain a sharp image of a moving world. Clinical conditions that interfere with gaze stabilization can therefore lead to significant visual impairment.</p>
<p>The new findings demonstrate for the first time that retinal neurons underlying gaze stabilization in other mammals are also present in primates, including humans. Neurons that send visual signals from the eye to the brain are called retinal ganglion cells. In humans, there are around 20 different retinal ganglion cell types, each of which responds to specific features of the visual scene, such as form, color, and motion (1–3).</p>
<p><img decoding="async" fetchpriority="high" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-300x300.jpg" alt="Teresa Puthussery" width="400" height="400" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-300x300.jpg 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1024x1024.jpg 1024w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-150x150.jpg 150w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-768x768.jpg 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1536x1536.jpg 1536w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-2048x2048.jpg 2048w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1300x1300.jpg 1300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-290x290.jpg 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-400x400.jpg 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-684x684.jpg 684w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>The researchers discovered a highly-specialized retinal ganglion cell type known as direction-selective ganglion cells (DSGCs). They respond to motion in the visual field by increasing their activity when movement occurs in their “preferred” direction, while showing little activity to motion in the opposite direction. Collectively, responses from these neurons tell the gaze stabilization system which way the visual scene is moving.</p>
<p>“This cell type in particular—the direction-selective ganglion cell—had not been discovered previously in primate despite concerted effort, leading the field to conclude it must not be there,” said Marla Feller, PhD, a distinguished professor at UC Berkeley and an elected member of the National Academy of Sciences. Dr. Feller is an expert in retinal circuit development and function. </p>

<h2>Finding the Needle in the Haystack</h2>
<p>DSGCs were discovered in the rabbit retina in 1964 by another Berkeley Optometry faculty member, <a href="https://optometry.berkeley.edu/alumni/hall-of-fame/horace-b-barlow/">Horace Barlow</a>, and his colleagues (4). However, in the decades since, the lack of evidence for DSGCs in higher species led scientists to speculate that primate direction selectivity was computed in the brain. But when new evidence emerged suggesting that some human gaze stabilization disorders could be linked to abnormal activity of DSGCs (5), Puthussery’s lab renewed their efforts to find them. “That was a tipping point. We thought DSGCs had to be there, but that they made up a very low percentage of retinal ganglion cells. Our challenge was to work out how to find the needle in the haystack,” said Dr. Puthussery.</p>
<p>The researchers used a multi-pronged approach to overcome this problem. First, they leveraged data from state-of-the-art genetic tools (2) to track down retinal neurons with molecular features resembling DSGCs in other animals. The researchers then labeled these neurons with fluorescent markers to show that they had the expected anatomical features. Finally, the team built a customized imaging system to track the activity of hundreds of retinal ganglion cells and show that the fluorescently tagged cells responded selectively to images moving in specific directions. This combination of molecular, anatomical, and functional evidence provided unequivocal identification of the long sought-after DSGCs.</p>
<p>“The Puthussery Lab was successful where others failed because of their novel approach,” said Dr. Marla Feller. She continued, “I also cannot overstate the high quality of the data, which is critical for such a breakthrough finding.”</p>

<h2>New Insights into Common Visual Disorders</h2>
<p><img decoding="async" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-300x300.jpg" alt="Anna Wang" width="400" height="400" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-300x300.jpg 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1024x1024.jpg 1024w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-150x150.jpg 150w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-768x768.jpg 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1536x1536.jpg 1536w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-2048x2048.jpg 2048w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1300x1300.jpg 1300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-290x290.jpg 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-400x400.jpg 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-684x684.jpg 684w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>These findings will enable researchers to better understand how retinal mechanisms contribute to gaze stabilization in the normal visual system and in disorders that cause unstable gaze. For example, nystagmus is a repetitive, uncontrolled movement of the eyes that can lead to unsteady and blurry vision. Nystagmus can occur in isolation or can accompany other eye problems such as albinism and certain inherited retinal diseases. While many forms of nystagmus are caused by problems in the brain or inner ear, the results of this study suggest that some forms of nystagmus could originate from abnormal activity of DSGCs in the retina (5).</p>

<h2>Looking Forward: Testing for Blinding Diseases</h2>
<p>Overall, these results provide a vivid demonstration that a rare retinal ganglion cell type may nonetheless have a profound impact on our overall visual experience. The approach used in this study can now be applied to determine the roles of other human ganglion cell types whose functions are unknown. This will be an important step toward designing more sensitive tests for the detection of blinding diseases that cause ganglion cell degeneration such as glaucoma, which afflicts 80 million people worldwide and is the leading cause of irreversible blindness (7,8). For example, if direction-selective ganglion cells are damaged early in glaucoma, changes in eye movements might serve as an objective biomarker for early damage.</p>
<p>Remarkably, half of all individuals with glaucoma are unaware that they have it (7,8). Ultimately, detecting early changes in ganglion cell activity is vital to diagnosing disease and preventing vision loss in our aging population.</p>

<h2>About the Study</h2>
<p>The research was supported by the National Eye Institute (EY024265), Glaucoma Research Foundation (Shaffer Grant) and the Hellman Fellows Fund.</p>
<p>Wang, A.Y.M., Kulkarni, M.M., McLaughlin, A.J., Gayet J, Smith BE, Hauptschein M, McHugh CF, Yao YY, Puthussery T. An ON-type direction-selective ganglion cell in primate retina. Nature (2023).</p>
<p> <a href="https://doi.org/10.1038/s41586-023-06659-4">Read in Nature </a></p>
<h2>Related Information</h2>
<p> <a href="https://www.retinalab.berkeley.edu/">The Puthussery Lab </a></p>
<p><a href="https://vision.berkeley.edu/people/emily-ward/">Emily L Ward</a>, who wrote this web article, is a PhD student at UC Berkeley’s Herbert Wertheim School of Optometry &amp; Vision Science.</p>

  <div>
          <h2>About the Photos</h2>
        <p><strong>Top:</strong> A human retina labeled with a marker for all retinal ganglion cells in magenta. The sparse subset of retinal ganglion cells involved in gaze stabilization are labeled with a selective marker in green. <strong>Center:</strong> Teresa Puthussery, OD, PhD, heads the research group, which studies how retinal neurons process visual information before sending signals to the brain. <strong>Bottom:</strong> Anna Yao Mei Wang, PhD, is a postdoctoral scholar working in the Puthussery lab, and is first author of the study, which was published in <em>Nature</em>. Center and bottom photos by Elena Zhukova    </p>
  </div>
  

      <div id="accordion656c5fb7649ce" aria-labelledby="headingaccordion656c5fb7649e3"><p>
              1. Yan W, Peng YR, van Zyl T, et al. Cell Atlas of The Human Fovea and Peripheral Retina. Scientific Reports. 2020;10(1):9802. </p>
<p>2. Peng YR, Shekhar K, Yan W, et al. Molecular Classification and Comparative Taxonomics of Foveal and Peripheral Cells in Primate Retina. Cell. 2019;176(5):1222-1237.e22.</p>
<p>3. Wensel TG. Chapter 51 - Molecular Biology of Vision. Editor(s): Brady ST, Siegel GJ, Albers RW, Price DL. Basic Neurochemistry (Eighth Edition). Academic Press. 2012:889–903.</p>
<p>4. Barlow, HB, Hill, RM, Levick, WR. Retinal ganglion cells responding selectively to direction and speed of image motion in the rabbit. The Journal of Physiology. 1964;173.</p>
<p>5. Kamermans M, Winkelman BHJ, Hölzel MB, Howlett MHC, Kamermans W, Simonsz HJ, de Zeeuw CI. A retinal origin of nystagmus—a perspective. Frontiers in Ophthalmology. 2023;3.</p>
<p>6. Yonehara K, Fiscella M, Drinnenberg A, Esposti F, Trenholm S, Krol J, et al. Congenital Nystagmus Gene FRMD7 Is Necessary for Establishing a Neuronal Circuit Asymmetry for Direction Selectivity. Neuron. 2016;89:177–193.</p>
<p>7. Heijl A, Bengtsson B, Oskarsdottir SE. Prevalence and severity of undetected manifest glaucoma: results from the early manifest glaucoma trial screening. Ophthalmology. 2013;120(8):1541–1545. </p>
<p>8. “Glaucoma Worldwide: A Growing Concern.” Glaucoma.Org. https://glaucoma.org/glaucoma-worldwide-a-growing-concern/. Accessed October 25, 2023. Reviewed March 23, 2022.            </p></div>
  
  

<h2>Contacts</h2>
<p>Eric Craypo, Chief Communications Officer<br>
<a href="mailto:ecraypo@berkeley.edu"> ecraypo@berkeley.edu</a>
</p><p>Teresa Puthussery, Assistant Professor<br>
<a href="mailto:tputhussery@berkeley.edu"> tputhussery@berkeley.edu </a>
      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Meta patches Linux at hyperscale (115 pts)]]></title>
            <link>https://thenewstack.io/how-meta-patches-linux-at-hyperscale/</link>
            <guid>38501779</guid>
            <pubDate>Sat, 02 Dec 2023 20:32:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/how-meta-patches-linux-at-hyperscale/">https://thenewstack.io/how-meta-patches-linux-at-hyperscale/</a>, See on <a href="https://news.ycombinator.com/item?id=38501779">Hacker News</a></p>
Couldn't get https://thenewstack.io/how-meta-patches-linux-at-hyperscale/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Singing to babies is vital to help them learn language, say scientists (203 pts)]]></title>
            <link>https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists</link>
            <guid>38500906</guid>
            <pubDate>Sat, 02 Dec 2023 18:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists">https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists</a>, See on <a href="https://news.ycombinator.com/item?id=38500906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P … How many would read this to <em>that</em> tune?</p><p>According to scientists from the University of Cambridge, there’s more to the earworm than infuriating parents across the English-speaking world – they have found that singsong speech is crucial to helping babies learn language.</p><p>The study concluded that infants learn languages from rhythmic information – the rise and fall of tone – as seen in nursery rhymes or songs, such as the ubiquitous alphabet song.</p><p>The team at Cambridge also discovered that babies do not begin to process phonetic information – the smallest sounds of speech – until they are about seven months old.</p><p>The researchers said that the findings, which have been <a href="https://www.nature.com/articles/s41467-023-43490-x" data-link-name="in body link">published in the journal Nature Communications</a>, challenge the view that phonetic information – typically represented by the alphabet – is the key to language learning.</p><p>They said it also suggests that dyslexia and developmental language disorder may be associated with rhythm perception rather than difficulties with processing phonetic information.</p><p>Prof Usha Goswami, a neuroscientist at the University of Cambridge who is the study’s author, said: “Our research shows that the individual sounds of speech are not processed reliably until around seven months, even though most infants can recognise familiar words like ‘bottle’ by this point.</p><p>“From then individual speech sounds are still added in very slowly – too slowly to form the basis of language. We believe that speech rhythm information is the hidden glue underpinning the development of a well-functioning language system.</p><p>“Parents should talk and sing to their babies as much as possible or use infant-directed speech like nursery rhymes because it will make a difference to language outcome.”</p><p>It has previously been thought that infants learn small sound elements and add them together to make words.</p><p>To understand whether that was the case, the researchers recorded the brain activity of 50 infants at four, seven and 11 months old as they watched a video of a primary school teacher singing 18 nursery rhymes.</p><p>The team used special algorithms to interpret how the infants were encoding this information in the brain.</p><p>The scientists found that phonetic encoding in babies emerged gradually over the first year of life, beginning with dental sounds (produced by the upper front teeth) – such as “d” for “daddy” – and nasal sounds (produced when airflow is directed through the nose) – such as “m” for “mummy”.</p><p>Goswami said: “Infants can use rhythmic information like a scaffold or skeleton to add phonetic information on to. For example, they might learn that the rhythm pattern of English words is typically strong-weak, as in ‘daddy’ or ‘mummy’, with the stress on the first syllable.</p><p>“They can use this rhythm pattern to guess where one word ends and another begins when listening to natural speech.”</p><p>She said rhythm is a universal aspect of every language where all babies “are exposed to … a strong beat structure with a strong syllable twice a second”, adding: “We’re biologically programmed to emphasise this when speaking to babies.”</p><p>The study forms part of the BabyRhythm project led by Goswami, which is investigating how language is related to dyslexia and developmental language disorder.</p><p>She said there was a long history of trying to explain these in terms of phonetic problems but the evidence does not add up, and individual differences in children’s language learning skills may originate with rhythm.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Galactic algorithm (108 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Galactic_algorithm</link>
            <guid>38500782</guid>
            <pubDate>Sat, 02 Dec 2023 18:34:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">https://en.wikipedia.org/wiki/Galactic_algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=38500782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">
<p>A <b>galactic algorithm</b> is one with world-beating theoretical (asymptotic) performance, but which is never used in practice. Typical reasons are that the performance gains only appear for problems that are so large they never occur, or the algorithm's complexity outweighs a relatively small gain in performance.  Galactic algorithms were so named by <a href="https://en.wikipedia.org/wiki/Richard_Lipton" title="Richard Lipton">Richard Lipton</a> and Ken Regan,<sup id="cite_ref-seminal_1-0"><a href="#cite_note-seminal-1">[1]</a></sup> because they will never be used on any data sets on Earth.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Possible_use_cases">Possible use cases</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=1" title="Edit section: Possible use cases"><span>edit</span></a><span>]</span></span></h2>
<p>Even if they are never used in practice, galactic algorithms may still contribute to computer science:
</p>
<ul><li>An algorithm, even if impractical, may show new techniques that may eventually be used to create practical algorithms.</li>
<li>Available computational power may catch up to the crossover point, so that a previously impractical algorithm becomes practical.</li>
<li>An impractical algorithm can still demonstrate that conjectured bounds can be achieved, or that proposed bounds are wrong, and hence advance the theory of algorithms. As Lipton states:<sup id="cite_ref-seminal_1-1"><a href="#cite_note-seminal-1">[1]</a></sup><blockquote><p>This alone could be important and often is a great reason for finding such algorithms. For example, if tomorrow there were a discovery that showed there is a factoring algorithm with a huge but provably polynomial time bound, that would change our beliefs about factoring. The algorithm might never be used, but would certainly shape the future research into factoring.</p></blockquote>  Similarly, a hypothetical large but polynomial <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ee39ed087ed9b6a627b1d8e473ce859c1eced56c" aria-hidden="true" alt="{\displaystyle O{\bigl (}n^{2^{100}}{\bigr )}}"></span> algorithm for the <a href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem" title="Boolean satisfiability problem">Boolean satisfiability problem</a>, although unusable in practice, would settle the <a href="https://en.wikipedia.org/wiki/P_versus_NP_problem" title="P versus NP problem">P versus NP problem</a>, considered the most important open problem in computer science and one of the <a href="https://en.wikipedia.org/wiki/Millennium_Prize_Problems" title="Millennium Prize Problems">Millennium Prize Problems</a>.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li></ul>
<h2><span id="Examples">Examples</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=2" title="Edit section: Examples"><span>edit</span></a><span>]</span></span></h2>
<h3><span id="Integer_multiplication">Integer multiplication</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=3" title="Edit section: Integer multiplication"><span>edit</span></a><span>]</span></span></h3>
<p>An example of a galactic algorithm is the fastest known way to <a href="https://en.wikipedia.org/wiki/Multiplication_algorithm" title="Multiplication algorithm">multiply two numbers</a>,<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> which is based on a 1729-dimensional <a href="https://en.wikipedia.org/wiki/Fourier_transform" title="Fourier transform">Fourier transform</a>.<sup id="cite_ref-quick_4-0"><a href="#cite_note-quick-4">[4]</a></sup> It needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d2320768fb54880ca4356e61f60eb02a3f9d9f1" aria-hidden="true" alt="O(n\log n)"></span> bit operations, but as the constants hidden by the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">big O notation</a> are large, it is never used in practice. However, it also shows why galactic algorithms may still be useful. The authors state: "we are hopeful that with further refinements, the algorithm might become practical for numbers with merely billions or trillions of digits."<sup id="cite_ref-quick_4-1"><a href="#cite_note-quick-4">[4]</a></sup>
</p>
<h3><span id="Matrix_multiplication">Matrix multiplication</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=4" title="Edit section: Matrix multiplication"><span>edit</span></a><span>]</span></span></h3>
<p>The first improvement over brute-force matrix multiplication (which needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b04f5c5cfea38f43406d9442387ad28555e2609" aria-hidden="true" alt="O(n^{3})"></span> multiplications) was the <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" title="Strassen algorithm">Strassen algorithm</a>: a recursive algorithm that needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5efdd8558feb6363dbd3fe296b5f757df910e88a" aria-hidden="true" alt="{\displaystyle O(n^{2.807})}"></span>multiplications. This algorithm is not galactic and is used in practice. Further extensions of this, using sophisticated group theory, are the <a href="https://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm" title="Coppersmith–Winograd algorithm">Coppersmith–Winograd algorithm</a> and its slightly better successors, needing <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b7e9678394c2c1edfe2bbe326ea0c90343eb68b" aria-hidden="true" alt="{\displaystyle O(n^{2.373})}"></span> multiplications. These are galactic – "We nevertheless stress that such improvements are only of theoretical interest, since the huge constants involved in the complexity of fast matrix multiplication usually make these algorithms impractical."<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p>
<h3><span id="Communication_channel_capacity">Communication channel capacity</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=5" title="Edit section: Communication channel capacity"><span>edit</span></a><span>]</span></span></h3>
<p><a href="https://en.wikipedia.org/wiki/Claude_Shannon" title="Claude Shannon">Claude Shannon</a> showed a simple but impractical <a href="https://en.wikipedia.org/wiki/Code" title="Code">code</a> that could reach the capacity of a <a href="https://en.wikipedia.org/wiki/Communication_channel" title="Communication channel">communication channel</a>.  It requires assigning a random code word to every possible <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span>-bit message, then decoding by finding the closest code word.  If <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is chosen large enough, this beats any existing code and can get arbitrarily close to the capacity of the channel.  Unfortunately, any <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> big enough to beat existing codes is also completely impractical.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> These codes, though never used, inspired decades of research into more practical algorithms that today can achieve rates arbitrarily close to channel capacity.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>
</p>
<h3><span id="Sub-graphs">Sub-graphs</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=6" title="Edit section: Sub-graphs"><span>edit</span></a><span>]</span></span></h3>
<p>The problem of <a href="https://en.wikipedia.org/wiki/Decision_problem" title="Decision problem">deciding</a> whether a graph <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> contains <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> as a <a href="https://en.wikipedia.org/wiki/Graph_minor" title="Graph minor">minor</a> is <a href="https://en.wikipedia.org/wiki/NP-complete" title="NP-complete">NP-complete</a> in general, but where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> is fixed, it can be solved in polynomial time.  The running time for testing whether <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> is a minor of <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> in this case is <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6cd9594a16cb898b8f2a2dff9227a385ec183392" aria-hidden="true" alt="O(n^{2})"></span>,<sup id="cite_ref-kkr12_8-0"><a href="#cite_note-kkr12-8">[8]</a></sup> where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is the number of vertices in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> and the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">big O notation</a> hides a constant that depends superexponentially on <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span>.  The constant is greater than <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/360009b1d76b85fe5141886793eb89e9ad50e825" aria-hidden="true" alt="{\displaystyle 2\uparrow \uparrow (2\uparrow \uparrow (2\uparrow \uparrow (h/2)))}"></span> in <a href="https://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation" title="Knuth's up-arrow notation">Knuth's up-arrow notation</a>, where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" alt="h"></span> is the number of vertices in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span>.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> Even the case of <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9b3ec3aec2fcc1177dad3a297dfc9060ec07e5a3" aria-hidden="true" alt="{\displaystyle h=4}"></span> cannot be reasonably computed as the constant is greater than <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0d6b4d85f1c6a1949b61be9f5e1bf5504cd03bd5" aria-hidden="true" alt="{\displaystyle {\  \atop {\ }}{{\underbrace {2^{2^{\cdot ^{\cdot ^{2}}}}} } \atop n}}"></span> with <i>n</i> = 65536.
</p>
<h3><span id="Cryptographic_breaks">Cryptographic breaks</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=7" title="Edit section: Cryptographic breaks"><span>edit</span></a><span>]</span></span></h3>
<p>For cryptographers, a cryptographic "break" is anything faster than a brute-force attack – i.e., performing one trial decryption for each possible key. In many cases, even though they are the best known methods,  they are still infeasible with current technology. One example is the best attack known against 128-bit <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" title="Advanced Encryption Standard">AES</a>, which takes only <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/03ba78eeaf0f84e190d7aa90548b82ead88a37c5" aria-hidden="true" alt="2^{126}"></span> operations.<sup id="cite_ref-:0_10-0"><a href="#cite_note-:0-10">[10]</a></sup>  Despite being impractical, theoretical breaks can sometimes provide insight into vulnerability patterns.
</p>
<h3><span id="Traveling_salesman_problem">Traveling salesman problem</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=8" title="Edit section: Traveling salesman problem"><span>edit</span></a><span>]</span></span></h3>
<p>For several decades, the best known approximation to the <a href="https://en.wikipedia.org/wiki/Traveling_salesman_problem" title="Traveling salesman problem">traveling salesman problem</a> in a <a href="https://en.wikipedia.org/wiki/Metric_space" title="Metric space">metric space</a> was the very simple <a href="https://en.wikipedia.org/wiki/Christofides_algorithm" title="Christofides algorithm">Christofides algorithm</a> which produced a path at most 50% longer than the optimum. (Many other algorithms could <i>usually</i> do much better, but could not provably do so.)  In 2020, a newer and much more complex algorithm was discovered that can beat this by <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9cf2b5bceb62956a12c9ce5a253e838aa25c9f11" aria-hidden="true" alt="{\displaystyle 10^{-34}}"></span> percent.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> Although no one will ever switch to this algorithm for its very slight worst-case improvement, it is still considered important because "this minuscule improvement breaks through both a theoretical logjam and a psychological one".<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup>
</p>
<h3><span id="Hutter_search">Hutter search</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=9" title="Edit section: Hutter search"><span>edit</span></a><span>]</span></span></h3>
<p>A single algorithm, "Hutter search", can solve any well-defined problem in an asymptotically optimal time, barring some caveats. It works by searching through all possible algorithms (by runtime), while simultaneously searching through all possible proofs (by length of proof), looking for a proof of correctness for each algorithm.  Since the proof of correctness is of finite size, it "only" adds a constant and does not affect the asymptotic runtime. However, this constant is so big that the algorithm is entirely impractical.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup><sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>  For example, if the shortest proof of correctness of a given algorithm is 1000 bits long, the search will examine at least 2<sup>999</sup> other potential proofs first.
</p><p>Hutter search is related <a href="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference" title="Solomonoff's theory of inductive inference">Solomonoff induction</a>, which is a formalization of Bayesian inference.  All <a href="https://en.wikipedia.org/wiki/Computable" title="Computable">computable</a> theories (as implemented by programs) which perfectly describe previous observations are used to calculate the probability of the next observation, with more weight put on the shorter computable theories.  Again, the search over all possible explanations makes this procedure Galactic.
</p>
<h3><span id="Optimization">Optimization</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=10" title="Edit section: Optimization"><span>edit</span></a><span>]</span></span></h3>
<p><a href="https://en.wikipedia.org/wiki/Simulated_annealing" title="Simulated annealing">Simulated annealing</a>, when used with a logarithmic cooling schedule, has been proven to find the global optimum of any optimization problem.  However, such a cooling schedule results in entirely impractical runtimes, and is never used.<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup>  However, knowing this ideal algorithm exists has led to practical variants that are able to find very good (though not provably optimal) solutions to complex optimization problems.<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>
</p>
<h3><span id="Minimum_Spanning_Trees">Minimum Spanning Trees</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=11" title="Edit section: Minimum Spanning Trees"><span>edit</span></a><span>]</span></span></h3>
<p>The <a href="https://en.wikipedia.org/wiki/Expected_linear_time_MST_algorithm" title="Expected linear time MST algorithm">expected linear time MST algorithm</a> is able to discover the <a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree" title="Minimum spanning tree">minimum spanning tree</a> of a graph in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0922aa919079469e54e4c3affe9b7ab456f1a124" aria-hidden="true" alt="O(m + n)"></span>, where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" alt="m"></span> is the number of edges and <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is the number of nodes of the graph.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> However, the constant factor that is hidden by the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">Big O notation</a> is huge enough to make the algorithm impractical. An implementation is publicly available<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> and given the experimentally estimated implementation constants, it would only be faster than <a href="https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm" title="Borůvka's algorithm">Borůvka's algorithm</a> for graphs in which <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bc74100999273f6c2d96369163dbb6e20152e8dd" aria-hidden="true" alt="{\displaystyle m+n>9\cdot 10^{151}}"></span>.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup>
</p>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=12" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-seminal-1"><span>^ <a href="#cite_ref-seminal_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-seminal_1-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFLiptonRegan2013"><a href="https://en.wikipedia.org/wiki/Richard_Lipton" title="Richard Lipton">Lipton, Richard J.</a>; Regan, Kenneth W. (2013). <a rel="nofollow" href="https://books.google.com/books?id=eLC9BAAAQBAJ&amp;pg=PA109">"David Johnson: Galactic Algorithms"</a>. <i>People, Problems, and Proofs: Essays from Gödel's Lost Letter: 2010</i>. Heidelberg: Springer Berlin. pp.&nbsp;109–112. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9783642414220" title="Special:BookSources/9783642414220"><bdi>9783642414220</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=David+Johnson%3A+Galactic+Algorithms&amp;rft.btitle=People%2C+Problems%2C+and+Proofs%3A+Essays+from+G%C3%B6del%27s+Lost+Letter%3A+2010&amp;rft.place=Heidelberg&amp;rft.pages=109-112&amp;rft.pub=Springer+Berlin&amp;rft.date=2013&amp;rft.isbn=9783642414220&amp;rft.aulast=Lipton&amp;rft.aufirst=Richard+J.&amp;rft.au=Regan%2C+Kenneth+W.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DeLC9BAAAQBAJ%26pg%3DPA109&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFFortnow,_L.2009">Fortnow, L. (2009). <a rel="nofollow" href="http://people.cs.uchicago.edu/~fortnow/papers/pnp-cacm.pdf">"The status of the P versus NP problem"</a> <span>(PDF)</span>. <i>Communications of the ACM</i>. <b>52</b> (9): 78–86. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1145%2F1562164.1562186">10.1145/1562164.1562186</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:5969255">5969255</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=The+status+of+the+P+versus+NP+problem&amp;rft.volume=52&amp;rft.issue=9&amp;rft.pages=78-86&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1145%2F1562164.1562186&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A5969255%23id-name%3DS2CID&amp;rft.au=Fortnow%2C+L.&amp;rft_id=http%3A%2F%2Fpeople.cs.uchicago.edu%2F~fortnow%2Fpapers%2Fpnp-cacm.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFDavidHoeven2019">David, Harvey; Hoeven, Joris van der (March 2019). <a rel="nofollow" href="https://hal.archives-ouvertes.fr/hal-02070778/document">"Integer multiplication in time O(n log n)"</a>. <i>HAL</i>. hal-02070778.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=HAL&amp;rft.atitle=Integer+multiplication+in+time+O%28n+log+n%29&amp;rft.volume=hal-02070778&amp;rft.date=2019-03&amp;rft.aulast=David&amp;rft.aufirst=Harvey&amp;rft.au=Hoeven%2C+Joris+van+der&amp;rft_id=https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-02070778%2Fdocument&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-quick-4"><span>^ <a href="#cite_ref-quick_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-quick_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFHarvey2019">Harvey, David (9 April 2019). <a rel="nofollow" href="https://theconversation.com/weve-found-a-quicker-way-to-multiply-really-big-numbers-114923">"We've found a quicker way to multiply really big numbers"</a>. <i>The Conversation</i><span>. Retrieved <span>9 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Conversation&amp;rft.atitle=We%27ve+found+a+quicker+way+to+multiply+really+big+numbers&amp;rft.date=2019-04-09&amp;rft.aulast=Harvey&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Ftheconversation.com%2Fweve-found-a-quicker-way-to-multiply-really-big-numbers-114923&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite id="CITEREFLe_Gall2012">Le Gall, F. (2012), "Faster algorithms for rectangular matrix multiplication", <i>Proceedings of the 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS 2012)</i>, pp.&nbsp;514–523, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/1204.1111">1204.1111</a></span>, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FFOCS.2012.80">10.1109/FOCS.2012.80</a>, <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:2410545">2410545</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Faster+algorithms+for+rectangular+matrix+multiplication&amp;rft.btitle=Proceedings+of+the+53rd+Annual+IEEE+Symposium+on+Foundations+of+Computer+Science+%28FOCS+2012%29&amp;rft.pages=514-523&amp;rft.date=2012&amp;rft_id=info%3Aarxiv%2F1204.1111&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2410545%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FFOCS.2012.80&amp;rft.aulast=Le+Gall&amp;rft.aufirst=F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFLarry_Hardesty2010">Larry Hardesty (January 19, 2010). <a rel="nofollow" href="https://news.mit.edu/2010/explained-shannon-0115">"Explained: The Shannon limit"</a>. MIT News Office.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Explained%3A+The+Shannon+limit&amp;rft.pub=MIT+News+Office&amp;rft.date=2010-01-19&amp;rft.au=Larry+Hardesty&amp;rft_id=https%3A%2F%2Fnews.mit.edu%2F2010%2Fexplained-shannon-0115&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="https://ocw.mit.edu/courses/6-451-principles-of-digital-communication-ii-spring-2005/1a3ad00d83d1d042da3328a8edd9edc2_chap13.pdf">"Capacity-approaching codes (Chapter 13 of <i>Principles Of Digital Communication II</i>)"</a> <span>(PDF)</span>. <a href="https://en.wikipedia.org/wiki/MIT_OpenCourseWare" title="MIT OpenCourseWare">MIT OpenCourseWare</a>. 2005.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Capacity-approaching+codes+%28Chapter+13+of+Principles+Of+Digital+Communication+II%29&amp;rft.pub=MIT+OpenCourseWare&amp;rft.date=2005&amp;rft_id=https%3A%2F%2Focw.mit.edu%2Fcourses%2F6-451-principles-of-digital-communication-ii-spring-2005%2F1a3ad00d83d1d042da3328a8edd9edc2_chap13.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-kkr12-8"><span><b><a href="#cite_ref-kkr12_8-0">^</a></b></span> <span><cite id="CITEREFKawarabayashiKobayashiReed2012">Kawarabayashi, Ken-ichi; Kobayashi, Yusuke; <a href="https://en.wikipedia.org/wiki/Bruce_Reed_(mathematician)" title="Bruce Reed (mathematician)">Reed, Bruce</a> (2012). <a rel="nofollow" href="https://doi.org/10.1016%2Fj.jctb.2011.07.004">"The disjoint paths problem in quadratic time"</a>. <i><a href="https://en.wikipedia.org/wiki/Journal_of_Combinatorial_Theory" title="Journal of Combinatorial Theory">Journal of Combinatorial Theory</a></i>. Series B. <b>102</b> (2): 424–435. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2Fj.jctb.2011.07.004">10.1016/j.jctb.2011.07.004</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Combinatorial+Theory&amp;rft.atitle=The+disjoint+paths+problem+in+quadratic+time&amp;rft.volume=102&amp;rft.issue=2&amp;rft.pages=424-435&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jctb.2011.07.004&amp;rft.aulast=Kawarabayashi&amp;rft.aufirst=Ken-ichi&amp;rft.au=Kobayashi%2C+Yusuke&amp;rft.au=Reed%2C+Bruce&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.jctb.2011.07.004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFJohnson,_David_S.1987">Johnson, David S. (1987). "The NP-completeness column: An ongoing guide (edition 19)". <i>Journal of Algorithms</i>. <b>8</b> (2): 285–303. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.3864">10.1.1.114.3864</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2F0196-6774%2887%2990043-5">10.1016/0196-6774(87)90043-5</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Algorithms&amp;rft.atitle=The+NP-completeness+column%3A+An+ongoing+guide+%28edition+19%29&amp;rft.volume=8&amp;rft.issue=2&amp;rft.pages=285-303&amp;rft.date=1987&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.114.3864%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1016%2F0196-6774%2887%2990043-5&amp;rft.au=Johnson%2C+David+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-:0-10"><span><b><a href="#cite_ref-:0_10-0">^</a></b></span> <span><cite id="CITEREFBiaoshuai_TaoHongjun_Wu2015">Biaoshuai Tao &amp; Hongjun Wu (2015). <i>Information Security and Privacy</i>. Lecture Notes in Computer Science. Vol.&nbsp;9144. pp.&nbsp;39–56. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1007%2F978-3-319-19962-7_3">10.1007/978-3-319-19962-7_3</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-19961-0" title="Special:BookSources/978-3-319-19961-0"><bdi>978-3-319-19961-0</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Information+Security+and+Privacy&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=39-56&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-19962-7_3&amp;rft.isbn=978-3-319-19961-0&amp;rft.au=Biaoshuai+Tao&amp;rft.au=Hongjun+Wu&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFAnna_R._KarlinNathan_KleinShayan_Oveis_Gharan2020">Anna R. Karlin; Nathan Klein; Shayan Oveis Gharan (September 1, 2020). "A (Slightly) Improved Approximation Algorithm for Metric TSP". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/2007.01409">2007.01409</a></span> [<a rel="nofollow" href="https://arxiv.org/archive/cs.DS">cs.DS</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+%28Slightly%29+Improved+Approximation+Algorithm+for+Metric+TSP&amp;rft.date=2020-09-01&amp;rft_id=info%3Aarxiv%2F2007.01409&amp;rft.au=Anna+R.+Karlin&amp;rft.au=Nathan+Klein&amp;rft.au=Shayan+Oveis+Gharan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFKlarreich2020">Klarreich, Erica (8 October 2020). <a rel="nofollow" href="https://www.quantamagazine.org/computer-scientists-break-traveling-salesperson-record-20201008/">"Computer Scientists Break Traveling Salesperson Record"</a>. <i>Quanta Magazine</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quanta+Magazine&amp;rft.atitle=Computer+Scientists+Break+Traveling+Salesperson+Record&amp;rft.date=2020-10-08&amp;rft.aulast=Klarreich&amp;rft.aufirst=Erica&amp;rft_id=https%3A%2F%2Fwww.quantamagazine.org%2Fcomputer-scientists-break-traveling-salesperson-record-20201008%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFHutter2002">Hutter, Marcus (2002-06-14). "The Fastest and Shortest Algorithm for All Well-Defined Problems". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/cs/0206022">cs/0206022</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Fastest+and+Shortest+Algorithm+for+All+Well-Defined+Problems&amp;rft.date=2002-06-14&amp;rft_id=info%3Aarxiv%2Fcs%2F0206022&amp;rft.aulast=Hutter&amp;rft.aufirst=Marcus&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite id="CITEREFGagliolo2007">Gagliolo, Matteo (2007-11-20). <a rel="nofollow" href="https://doi.org/10.4249%2Fscholarpedia.2575">"Universal search"</a>. <i>Scholarpedia</i>. <b>2</b> (11): 2575. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" href="https://ui.adsabs.harvard.edu/abs/2007SchpJ...2.2575G">2007SchpJ...2.2575G</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.4249%2Fscholarpedia.2575">10.4249/scholarpedia.2575</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1941-6016">1941-6016</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scholarpedia&amp;rft.atitle=Universal+search&amp;rft.volume=2&amp;rft.issue=11&amp;rft.pages=2575&amp;rft.date=2007-11-20&amp;rft.issn=1941-6016&amp;rft_id=info%3Adoi%2F10.4249%2Fscholarpedia.2575&amp;rft_id=info%3Abibcode%2F2007SchpJ...2.2575G&amp;rft.aulast=Gagliolo&amp;rft.aufirst=Matteo&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.4249%252Fscholarpedia.2575&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFLiangChengLin2014">Liang, Faming; Cheng, Yichen; Lin, Guang (2014). "Simulated stochastic approximation annealing for global optimization with a square-root cooling schedule". <i>Journal of the American Statistical Association</i>. <b>109</b> (506): 847–863. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1080%2F01621459.2013.872993">10.1080/01621459.2013.872993</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:123410795">123410795</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Simulated+stochastic+approximation+annealing+for+global+optimization+with+a+square-root+cooling+schedule&amp;rft.volume=109&amp;rft.issue=506&amp;rft.pages=847-863&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.2013.872993&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A123410795%23id-name%3DS2CID&amp;rft.aulast=Liang&amp;rft.aufirst=Faming&amp;rft.au=Cheng%2C+Yichen&amp;rft.au=Lin%2C+Guang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFIngber,_Lester1993">Ingber, Lester (1993). <a rel="nofollow" href="https://doi.org/10.1016%2F0895-7177%2893%2990204-C">"Simulated annealing: Practice versus theory"</a>. <i>Mathematical and Computer Modelling</i>. <b>18</b> (11): 29–57. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2F0895-7177%2893%2990204-C">10.1016/0895-7177(93)90204-C</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Mathematical+and+Computer+Modelling&amp;rft.atitle=Simulated+annealing%3A+Practice+versus+theory&amp;rft.volume=18&amp;rft.issue=11&amp;rft.pages=29-57&amp;rft.date=1993&amp;rft_id=info%3Adoi%2F10.1016%2F0895-7177%2893%2990204-C&amp;rft.au=Ingber%2C+Lester&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252F0895-7177%252893%252990204-C&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFKargerKleinTarjan1995">Karger, David R.; Klein, Philip N.; Tarjan, Robert E. (1995-03-01). <a rel="nofollow" href="https://doi.org/10.1145%2F201019.201022">"A randomized linear-time algorithm to find minimum spanning trees"</a>. <i>Journal of the ACM</i>. <b>42</b> (2): 321–328. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1145%2F201019.201022">10.1145/201019.201022</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/0004-5411">0004-5411</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+ACM&amp;rft.atitle=A+randomized+linear-time+algorithm+to+find+minimum+spanning+trees&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=321-328&amp;rft.date=1995-03-01&amp;rft_id=info%3Adoi%2F10.1145%2F201019.201022&amp;rft.issn=0004-5411&amp;rft.aulast=Karger&amp;rft.aufirst=David+R.&amp;rft.au=Klein%2C+Philip+N.&amp;rft.au=Tarjan%2C+Robert+E.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%252F201019.201022&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFThiesen">Thiesen, Francisco. <a rel="nofollow" href="https://github.com/FranciscoThiesen/karger-klein-tarjan">"A C++ implementation for an Expected Linear-Time Minimum Spanning Tree Algorithm(Karger-Klein-Tarjan + Hagerup Minimum Spanning Tree Verification as a sub-routine)"</a>. <i><a href="https://en.wikipedia.org/wiki/GitHub" title="GitHub">GitHub</a></i><span>. Retrieved <span>2022-11-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=A+C%2B%2B+implementation+for+an+Expected+Linear-Time+Minimum+Spanning+Tree+Algorithm%28Karger-Klein-Tarjan+%2B+Hagerup+Minimum+Spanning+Tree+Verification+as+a+sub-routine%29&amp;rft.aulast=Thiesen&amp;rft.aufirst=Francisco&amp;rft_id=https%3A%2F%2Fgithub.com%2FFranciscoThiesen%2Fkarger-klein-tarjan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFGeiman_Thiesen">Geiman Thiesen, Francisco. <a rel="nofollow" href="https://franciscothiesen.github.io/Linear-Time-MST/">"Expected Linear-Time Minimum Spanning Trees"</a>. <i>franciscothiesen.github.io</i><span>. Retrieved <span>2022-11-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=franciscothiesen.github.io&amp;rft.atitle=Expected+Linear-Time+Minimum+Spanning+Trees&amp;rft.aulast=Geiman+Thiesen&amp;rft.aufirst=Francisco&amp;rft_id=https%3A%2F%2Ffranciscothiesen.github.io%2FLinear-Time-MST%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐8689768cf9‐xbkwc
Cached time: 20231202221053
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.230 seconds
Real time usage: 0.317 seconds
Preprocessor visited node count: 1332/1000000
Post‐expand include size: 39307/2097152 bytes
Template argument size: 1055/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 0/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 58198/5000000 bytes
Lua time usage: 0.122/10.000 seconds
Lua memory usage: 5630519/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  226.073      1 -total
 70.40%  159.151      1 Template:Reflist
 30.30%   68.493      2 Template:Cite_book
 21.25%   48.035      1 Template:Short_description
 13.86%   31.330      8 Template:Cite_journal
 11.41%   25.787      2 Template:Pagetype
  9.93%   22.450      6 Template:Cite_web
  5.62%   12.714      4 Template:Main_other
  4.80%   10.856      1 Template:SDcat
  4.11%    9.281      2 Template:Cite_arXiv
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:60819045-0!canonical and timestamp 20231202221052 and revision id 1188021149. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mundane emotions: Losing yourself in boredom, time and technology (2022) (129 pts)]]></title>
            <link>https://journals.sagepub.com/doi/10.1177/14705931221138617</link>
            <guid>38500681</guid>
            <pubDate>Sat, 02 Dec 2023 18:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journals.sagepub.com/doi/10.1177/14705931221138617">https://journals.sagepub.com/doi/10.1177/14705931221138617</a>, See on <a href="https://news.ycombinator.com/item?id=38500681">Hacker News</a></p>
Couldn't get https://journals.sagepub.com/doi/10.1177/14705931221138617: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cicadas are so loud, fiber optic cables can ‘hear’ them (163 pts)]]></title>
            <link>https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/</link>
            <guid>38500065</guid>
            <pubDate>Sat, 02 Dec 2023 17:11:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/">https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/</a>, See on <a href="https://news.ycombinator.com/item?id=38500065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>One of the world’s most peculiar test beds stretches above Princeton, New Jersey. It’s a fiber optic cable strung between three utility poles that then runs underground before feeding into an “interrogator.” This device fires a laser through the cable and analyzes the light that bounces back. It can pick up tiny perturbations in that light caused by seismic activity or even loud sounds, like from a passing ambulance. It’s a newfangled technique known as distributed acoustic sensing, or DAS.</p><figure data-testid="IframeEmbed"></figure><p>Because DAS can track seismicity, other scientists are <a href="https://www.wired.com/story/how-fiber-optic-cables-could-warn-you-of-an-earthquake/">increasingly using it to monitor earthquakes</a> and <a href="https://www.wired.com/story/scientists-spy-on-mount-etna-with-fiber-optic-cables/">volcanic activity</a>. (A buried system is so sensitive, in fact, that it can <a href="https://www.wired.com/story/how-underground-fiber-optics-spy-on-humans-moving-above/">detect people walking and driving above</a>.) But the scientists in Princeton just stumbled upon a rather … noisier use of the technology. In the spring of 2021, Sarper Ozharar—a physicist at NEC Laboratories, which operates the Princeton test bed—noticed <a href="https://academic.oup.com/jinsectscience/article/23/6/3/7425398">a strange signal in the DAS data</a>. “We realized there were some weird things happening,” says Ozharar. “Something that shouldn’t be there. There was a distinct frequency buzzing everywhere.”</p><p>The team suspected the “something” wasn’t a rumbling volcano—not in <em>New Jersey</em>—but the cacophony of the giant swarm of cicadas that had just emerged from underground, a population <a href="https://www.wired.com/story/eating-cicadas-brood-x/">known as Brood X</a>. A colleague suggested reaching out to Jessica Ware, an entomologist and cicada expert at the American Museum of Natural History, to confirm it. “I had been observing the cicadas and had gone around Princeton because we were collecting them for biological samples,” says Ware. “So when Sarper and the team showed that you could actually <em>hear</em> the volume of the cicadas, and it kind of matched their patterns, I was really excited.”</p><p>Add insects to the quickly growing list of things DAS can spy on. Thanks to some specialized anatomy, cicadas are the loudest insects on the planet, but all sorts of other six-legged species make a lot of noise, like crickets and grasshoppers. With fiber optic cables, entomologists might have stumbled upon a powerful new way to cheaply and constantly listen in on species—from afar. “Part of the challenge that we face in a time when there’s insect decline is that we still need to collect data about what population sizes are, and what insects are where,” says Ware. “Once we are able to familiarize ourselves with what’s possible with this type of remote sensing, I think we can be really creative.”</p><p>DAS is all about vibrations, whether they be the sounds of a singing brood of cicadas or the shifting of a geologic fault. Fiber optic cables transmit information, like high-speed internet, by firing pulses of light. Scientists can use an interrogator device to shine a laser down a cable and then analyze the tiny amounts of light that bounce back to the source. Because the speed of light is a known constant, they can pinpoint where along the cable a given disturbance happens: If something jostles the cable 100 feet down, the light will take slightly longer to return to the interrogator than something that happens at 50 feet. “Every 1 meter of fiber, more or less, we can turn it into a kind of microphone,” says Ozharar.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span>Courtesy of Journal of Insect Science/Entomological Society of America</span></p></figure><p>Ozharar’s team focused on a loop of the cable atop one of the utility poles, which you can see in the photo above. (The loop is highlighted in red.) “If the fiber is in a linear shape, a sound interacts with the fiber just once and then keeps traveling,” says Ozharar. “But if you have a coil, the same signal travels multiple times through the fiber.” That makes the system much more sensitive, like recording a concert with multiple microphones, instead of one fan in the crowd bootlegging it with their smartphone.</p><p>When Brood X emerged in the spring of 2021, Ozharar’s DAS system was accidentally listening in. This kind of “periodical cicada” develops underground and emerges every 13 or 17 years to mate, depending on the species. “Because of perhaps climate change—although we’re not exactly sure the reason—there have been stragglers, so populations that have come out early and populations that have come out later than what they’re metabolically timed to do,” says Ware. “Having a way to over time monitor those can be really helpful.”</p><p>Male cicadas have an organ, called the tymbal, that vibrates like a drum to produce that unmistakable song. Each species has its own variation on the song, allowing the right males and females to find each other. There’s extra information embedded in that sound, too: Males tend to call during the hottest time of day, which is energetically expensive. That allows females to assess the quality of their mates—they want to choose the fittest males so they can pass primo genes to their offspring.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Hence all the noise. DAS can listen from the very beginning of the emergence through the peak and into the decline as the mass mating ritual wanes. The volume of noise is a solid indicator of the number of cicadas, so entomologists can work out the population size of the brood. They can even see the effect of temperature: When it’s hotter, it’s more difficult for the male cicadas to sing. “You can see that as you go across the five days from which we have monitoring data, that when it’s slightly colder temperatures they have slightly different frequencies in hertz of the calling,” says Ware.</p><figure><p><span><p>Dead and dying cicadas from Brood X in Columbia, Maryland.</p>
</span><span>Photograph: Chip Somodevilla/Getty Images</span></p></figure><p>Fiber optic cables are already all over the place, just waiting for scientists to tap into them. They are abundant in cities, of course, but they also run between them, which would be handy for entomologists who want to monitor insects in more rural areas. “We use them just to transmit the data—zeros and ones—but we can do much more,” says Ozharar. “That’s why fiber sensing will become more and more important, and more widely used, in the near future.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Not that anyone’s suggesting DAS will replace other ways of monitoring insects—fiber optics are widespread, but they’re not <em>everywhere</em>. Instead, DAS could complement other techniques. A field called <a href="https://www.wired.com/story/why-scientists-are-bugging-the-rainforest/">bioacoustics</a> already uses microphones to listen for species in remote areas, sometimes assisted by AI to parse the data. This method could help confirm the data coming from the fiber optics. Scientists are also experimenting with “environmental DNA,” or <a href="https://www.wired.com/story/scientists-capture-airborne-animal-dna-for-the-first-time/">eDNA</a>, for instance using air quality stations to <a href="https://www.wired.com/story/a-secret-key-to-saving-species-is-blowing-in-the-wind/">gather the biological material</a> floating in a given area. And entomologists like Ware still need to collect specimens from the field to physically examine the health of individual animals.</p><p>“What seems really cool about this new technology is that you have this single cable that can cover potentially many kilometers, and all of the information is getting recorded by a single device,” says Elliott Smeds, an entomologist and research associate at the California Academy of Sciences, who wasn’t involved in the research. “Especially now that insects are declining, we’re realizing that we don’t even know what the baseline is for a lot of these species, to keep track of how they’re doing. The biggest obstacle is having enough boots on the ground to be collecting this kind of data.”</p><p>The trick will be adapting DAS to monitor species that <em>aren’t</em> the loudest insects on Earth. “In this case, it was very clear these were cicadas, because there were—without exaggeration—millions of them that suddenly descended,” says Ware. “But in most cases, the populations are much smaller for each species. Knowing whether or not we can actually distinguish among insects will be an interesting question.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI is killing our sense of awe (107 pts)]]></title>
            <link>https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe</link>
            <guid>38499843</guid>
            <pubDate>Sat, 02 Dec 2023 16:43:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe">https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe</a>, See on <a href="https://news.ycombinator.com/item?id=38499843">Hacker News</a></p>
Couldn't get https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Dark patterns in UX design and how to avoid them (124 pts)]]></title>
            <link>https://dodonut.com/blog/10-dark-patterns-in-ux-design/</link>
            <guid>38499824</guid>
            <pubDate>Sat, 02 Dec 2023 16:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dodonut.com/blog/10-dark-patterns-in-ux-design/">https://dodonut.com/blog/10-dark-patterns-in-ux-design/</a>, See on <a href="https://news.ycombinator.com/item?id=38499824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content"><p>A dark pattern is a term created by designer Harry Brignull. These patterns urge or persuade the user to perform actions or accept conditions they did not intend to. Companies use them to trick users into doing things that can bring them profits.</p><p>For example, some dark patterns trick users or pressure them to buy additional items, subscribe to newsletters, or spend more time on an app. Designer Sally Woellner, as part of her <a href="https://www.ted.com/talks/sally_woellner_dark_patterns_how_design_seeks_to_control_us/transcript" target="_blank" rel="nofollow noopener noreferrer">TED talk about Dark Patterns</a>, calls them “worryingly effective,” and this is because they are. They focus on human psychology and marketing to hit the user’s most primitive emotional and neurological response.</p><p>Dark patterns are not present in user experiences by mistake. They are carefully crafted to appear during a certain moment of the user interaction process. Sometimes, there are design errors, and, by mistake, the interface or user flow happens to benefit the company and confuse or mislead the user. But when companies realize this creates a benefit for them and then intentionally keep it that way, it becomes a dark pattern.</p>
<h3><strong>Why do people fall for dark patterns?</strong></h3><p>Users often fall for dark patterns because of emotional or contextual ‘triggers,’ such as:</p><ul><li>Fear of missing out (your friend tagged you in this post; open the app to check it out!),</li><li>Sunk-cost fallacy (having to accept terms and conditions or subscribing to newsletters to finish a signing-up process)</li><li>Frustration (desisting from actions that are hidden or unnecessarily complicated).</li><li>Confusion (ambiguous or hidden content or results from actions).</li><li>Guilt ("Are you sure you want to leave? Your friends will miss you!").
</li></ul><figure>
<img alt="The newsletter subscription with three vague options: opt in, don't opt out, don't opt in." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/b0ca5759cebe934d0b8a64532e893dd211ecdcb3-775x435.png?w=1200&amp;fit=max&amp;auto=format" height="435" width="775">
<figcaption>This newsletter subscription is extremely ambiguous and poorly written on purpose.</figcaption>
</figure>
<h3>If dark patterns are bad, why do companies use them?</h3><p>At this point, it’s common to think: Why would companies use them in the first place? And you won’t be surprised to learn that the answer is money.</p><p>Industries generate more profit by creating a user experience that manipulates users to buy more, stay longer, or invite their friends to use their platforms. This usually only works in the short term, often at the expense of creating a frustrating experience. People remember bad experiences and negative emotions rather than positive ones.</p><blockquote><div><p>— Howard Lax, Bad is Stronger than Good: Lessons for Customer Experience and Employee Engagement (and Life) LinkedIn (2018)</p>
</div>
</blockquote><p>Let’s discuss some of the most common dark patterns in UX and what to do instead.</p><p>This is one of the most common dark patterns. Confirmshaming means appealing to emotional blackmail to persuade people to confirm or stop actions from taking place. It’s okay to ask users if they are aware of and wish to proceed with their decisions. However, the wording and the way that it is presented can quickly turn into a dark pattern.</p><p>For example, the platform Duolingo sends you an email with their signature pet (an owl) crying. This is one of the most universal -yet effective- communication methods: showing sadness or vulnerability. We know an owl can’t feel sad because we’re leaving a service. Most importantly, we know the owl is not even real! However, there is something that goes beyond logic and goes straight to our emotional core.</p><p>According to <a href="https://www.theverge.com/2018/12/13/18137843/duolingo-owl-redesign-language-learning-app" target="_blank" rel="nofollow noopener noreferrer">The Verge</a>, they have even redesigned Duolingo’s signature pet over the years to widen their (apparent) facial expressions and cause an emotional reaction.</p><figure>
<img alt="The screen of Duolingo app with sad owl and text: We haven't seen you in a while." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/0e75ff43b83988ed1413577a3f2eb646b4acee25-1042x1999.png?w=1200&amp;fit=max&amp;auto=format" height="1999" width="1042">
<figcaption>You made our digital drawing resembling a bird sad.</figcaption>
</figure><p>Similarly, creating fake urgency is another typical dark pattern in UX.</p><p>Dark patterns focus solely on the interest’s company while disregarding the user’s interest. However, they use wording and emotional manipulation to present this urgent notification as something valuable to the user. Most social media platforms nowadays create this fear of missing out (FOMO) by hinting that something is happening within the app but without explaining in detail what that means.</p><p>A good example is a notification along the lines of “Your friends miss you” or “You have been invited to an event” to encourage you and find out what this is. Once you click or tap on the notification, you are inside the app, and it can show you endless content and make you stay for hours.</p><p>We all know and understand that companies want their customers to spend as much time as possible on their apps. But this gets out of scale often, and in reality, it invades the user’s lives while providing very little value.</p><figure>
<img alt="Screenshot with Facebook notifications" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/9a7fae70daffccbd050fc625a805ba851e9936db-1284x758.jpg?w=1200&amp;fit=max&amp;auto=format" height="758" width="1284">
<figcaption>Facebook lets you know many things are happening right now, they just won’t tell you what those are. Source: Reddit </figcaption>
</figure><p>Nagging is, in other words, not accepting a ‘No’ for an answer.</p><p>The most obvious example is suggesting premium subscriptions or newsletters but without allowing the user to refuse permanently. Replacing the “No” option with a “Not now,” “Not yet,” or “Maybe later” removes the choice from the user to benefit the company. The user, eventually, may accept those conditions because they give up in a way after the platform has nagged them once a day, for example.</p><figure>
<img alt="The window with user avatar, description 'You're all set!&quot; and button: Next: Invite friends" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/e9936164e7d1fec050812cb1d1d36b35812fdec4-1999x1243.png?w=1200&amp;fit=max&amp;auto=format" height="1243" width="1999">
<figcaption>This example shows nagging and contact theft. Source: Chris Oliver / Medium</figcaption>
</figure><p>Also called obstruction, sneaking is the act of including a secondary action in the middle of (usually towards the end of) a primary action. The user wants to complete the primary action but is not entirely aware of or is manipulated into accepting the secondary action.</p><p>In the past, companies, mostly from e-commerce, have already used sneaking to include additional cheap products (such as mugs) or hidden costs in the final step of the action. Because the additional amount is so small, most users won't complain or ask for a refund.</p><p>The <a href="https://www.deceptive.design/types/sneaking" target="_blank" rel="nofollow noopener noreferrer">Deceptive Patterns page</a> has talked about this in the past with the Sports Direct case.</p><p>Companies can (and should) suggest items that may be valuable to the user, either by common sense or by data (e.g., items that users buy in tandem). But it becomes a dark UX pattern when they outright place products or services that the user does not care for, and would have never thought of getting them otherwise.</p><figure>
<img alt="The white mug with big letters standing on the desk. " loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/346bbca723a1504729f6152a0a4e2e12d77f6899-1920x1920.png?w=1200&amp;fit=max&amp;auto=format" height="1920" width="1920">
<figcaption>Sports Direct used to put an extra £1 mug on their customer’s online baskets. That is now illegal.</figcaption>
</figure><p>Social media sites disguise ads very easily nowadays because they present the content, as cards or “blocks” with infinite scrolling.</p><p>This allows them to “sneak” an ad seamlessly and present it as another post. They disclose the fact that they are including ads, but in a very discreet way that goes unnoticed. The user ends up confusing ads with the “real” content they want to see. This often causes the user to end up on a different website than intended.</p><p>Other times, they just end up viewing content they are not interested in, or that provides no value.</p><figure>
<img alt="The website view with disguised ads. " loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/2528e32566b34d0d2affadf5bb8fd5c4db5ef7c9-1999x1040.png?w=1200&amp;fit=max&amp;auto=format" height="1040" width="1999">
<figcaption>Disguised ads cause confusion because the user doesn’t know which one is the ‘real’ download button. </figcaption>
</figure><p>Intentional misdirection is the use of visual or text content that creates an outcome that is ambiguous, vague or, even worse, the opposite of the desired or expected outcome.</p><p>Let’s think of an example: a user wants to cancel a subscription to a newsletter. When asking to confirm this action, a button with the word ‘Cancel’ may have two meanings: either ‘confirm’ the cancellation or ‘cancel’ the cancellation. This can happen by unintentional or poor wording or visual indicators (color, shape).</p><figure>
<img alt="Nextdoor unsubscribe panel with switch button described Marketing Updates." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/7393e5e8053ee0276442ad3513a9d172af1c9a00-1139x369.png?w=1200&amp;fit=max&amp;auto=format" height="369" width="1139">
<figcaption>Nextdoor’s unsubscribe panel has an ambiguous switch button.</figcaption>
</figure><p>We see the roach motel pattern when actions that benefit the company are sometimes intuitive, enticing, and even pushy. Conversely, actions that benefit the user and not the company are complex, ambiguous, and tedious.</p><p>Companies often use this pattern to ‘lure’ the user into taking an action by confusing or manipulating them. They make this process extremely smooth and direct; once they perform those actions, it’s hard to cancel or undo them.</p><p>In most companies, subscribing to a newsletter is easy, straightforward, and pointed out with a big CTA. However, unsubscribing is done via email, and users need to find the word Unsubscribe with a small, gray font that goes easily unnoticed. Even after users try to unsubscribe, they are asked to confirm several times and fill out surveys that discourage them from continuing this process. Sometimes, they even need to make a phone call or even go to a physical office.</p><p>Amazon’s users have had issues when canceling their Amazon Prime subscription, and with deleting their accounts as well.</p><p>In fact, the company recently <a href="https://techcrunch.com/2022/07/01/amazon-ends-prime-cancellation-dark-patterns-europe/?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAJByGnNzjsO3wkFeXRDPeTGc4b4PfUGu-EMHthPxZAKzG_T0z7NLr-9LcOtl9z7OeTkdoZbbP58vImtJ3sm9E2PsaHpIFOBrV96ZlBC79Pcfu_9BMgLKOm08bWLnrskps-6B6XDcyoHCyAGRt8nrvrHc_zUr0QG6wHrD5UukGR_P&amp;_guc_consent_skip=1696250550" target="_blank" rel="nofollow noopener noreferrer">had to simplify the process</a> required for canceling their Prime membership, to meet EU regulations.</p><figure>
<img alt="The screenshot from cancelling Amazon Prime" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/97de8b4aa09e0138722fce6a38ce419242174e2e-749x662.png?w=1200&amp;fit=max&amp;auto=format" height="662" width="749">
<figcaption>Amazon Prime puts endless barriers to canceling a membership. Source: Martyn Reding / Twitter </figcaption>
</figure><p>We see this dark pattern often in conjunction with the roach motel pattern. With preselection, users aren’t even enticed or manipulated into taking actions: the platform already ‘pre-selected’ these actions for them. Again, this pattern applies to actions that benefit the company and that users wouldn’t usually choose by themselves.</p><p>With preselection, users end up subscribing to newsletters or getting premium travel insurance without noticing, for example. When the company creates actions that only benefit them and not the user, it should be completely up to them to agree to that action after being informed of the possible benefits and conditions.</p><figure>
<img alt="Right and wrong examples of newsletter sign-up checkboxes where the wrong force users to sign up to the newsletter to get the PDF." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/6867c83b06bf6b56111e4538ddc0d86f3a9b9356-1047x697.png?w=1200&amp;fit=max&amp;auto=format" height="697" width="1047">
<figcaption>Pre-selected newsletter sign-up checkboxes are illegal in the EU.</figcaption>
</figure><p>Companies use friend spam to manipulate users into giving them social media permissions and access to their contacts.</p><p>They often disguise this action as ‘inviting your friends’ or similar actions that seem to offer a positive outcome to the user. IIn 2013, <a href="https://time.com/4062519/linkedn-spam-settlement/" target="_blank" rel="nofollow noopener noreferrer">LinkedIn received a lawsuit</a> for harvesting some of their user’s contacts, going as far as sending an email on the user’s behalf to all the people in their email contact list. This could go anywhere from their boss to a friend from high school.</p><figure>
<img alt="The view of mail from LinkedIn where the user get information that somebody wants to connect them on LinkedIn." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/bca6442e2b31950557efbfb729d89bbfcbf37cef-1092x728.png?w=1200&amp;fit=max&amp;auto=format" height="728" width="1092">
<figcaption>LinkedIn’s infamous friend spam. </figcaption>
</figure><p>Jonathan Shariat speaks about this experience in his book:</p><blockquote><div><p>— Jonathan Shariat and Cynthia Savard Saucier, “Tragic Design”, O’Reilly Media 2017</p>
</div>
</blockquote><p>With this another dark pattern, companies manipulate the user into giving their billing data or information, sometimes even promising a free trial or a discount in exchange for a product or service.</p><p>With time, they start charging a recurring billing or subscription with no chance to opt-out. They use wording and manipulation to assure the user they won’t be charged anything right now. They start charging money after a month or two when the user forgets the subscription.</p><p>In UX, it’s important to give the user control and freedom to the actions taking place on the platform. If these actions involve billing, it’s even more critical. This can be fixed easily by emailing the user to let them know they will start charging money 3-5 days before the end of the free trial.</p><figure>
<img alt="The view of purchase summary informing both about paying nothing at the moment with additional information below about automatic renewal." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/ca95cd5c01515cee2c9ba24cbc1f05d20ada86b2-975x620.png?w=1200&amp;fit=max&amp;auto=format" height="620" width="975">
<figcaption>This is a (potentially) dark pattern. Warning the user they are going to be billed a few days beforehand would be a significant improvement to the user experience.</figcaption>
</figure><p>If we want to avoid dark patterns and deceptive design, we need a good combination of research and common sense.</p>
<h3>Following research data to avoid Dark Patterns</h3><ul><li><strong>Competitive Analysis:</strong> For research, it's essential to be aware of the competition. What are some good examples of UX from similar platforms? Do their users complain about UX dark patterns? How do they convince users to subscribe to newsletters or buy their products or services?</li><li><a href="https://dodonut.com/design/guerrilla-testing/" target="_blank" rel="noopener"><strong>User Testing</strong></a> is a great way to detect design errors that can potentially become dark patterns and also to see how users react to the wording, interface, and user flow (e.g., suggesting a premium subscription is too pushy or the wording makes them feel manipulated).</li></ul>
<h3>Following common sense to avoid Dark Patterns</h3><p>As designers and users of digital products, it’s safe to say we have increased our attunement and common sense over time. Platforms usually have similar dark patterns because they share similar goals: sell a product, offer a service, or increase outreach (e.g., newsletters, followers).</p><p>Here are some common sense tips to avoid dark patterns in UX:</p><ul><li>Be transparent with the user to earn their trust and give them control and freedom to make an informed decision before taking an action.</li><li>Test and iterate your product until there’s a balance between the user’s and the company’s best interests.</li><li>Follow the best design principles and usability heuristics to keep the design user-centered and avoid common mistakes.</li><li>Create design patterns that benefit the user, even if it harms the company. At some point, the user wants to feel valued and heard and that they control the platform, not the other way around.</li></ul><p>There are many ways to make the user feel valued and heard, even if it doesn’t directly benefit the company.</p><p>YouTube included two reminders to take a break and close the app every X minutes and also a bedtime reminder to stop using the app between 11 p.m. and 8 a.m., for example.</p><figure>
<img alt="Screenshot from YouTube app" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/4392409f725d60758941d42e915ceda55702027e-1999x1690.png?w=1200&amp;fit=max&amp;auto=format" height="1690" width="1999">
<figcaption>The YouTube app encourages users to take breaks from the app to balance their experience and avoid burnout.</figcaption>
</figure><p>The YouTube mobile app includes tools to manage time spent on the app. Even though the platform encourages the user to spend more time, these reminders help balance the user’s experience and avoid burnout.</p><p>Ryanair has a dark pattern history, hiding their “Don’t insure me” option inside an unrelated dropdown menu. This was heavily criticized in the past and is now illegal in the UK and the European Union. Since then, they have changed it for a much more friendly user interface.</p><p>With these strategies, users will leave a genuine, positive impression. This leads to satisfaction, positive reviews, and profit in the long term. Also, it helps to create more&nbsp;<a href="https://dodonut.com/blog/digital-sustainability-how-to-go-green-with-digital-products/" target="_blank" rel="noopener">sustainable websites</a>&nbsp;because it reduces content on a website, emails, newsletters, and unnecessary information in general.</p><p>We all know that companies want to make money by offering products and services, and there’s nothing wrong with that!</p><p>But there’s a difference between inviting the user to interact with the platform in a certain way while still giving them a positive experience and pressuring the user to do things that do not benefit them or punishing them for acting in a way that does not benefit the company.</p><p>Companies can find several reasons to avoid dark patterns. By following best design practices, they can build a positive brand image, maintain customer trust, and adhere to legal and ethical standards. In a long-distance it promotes transparency and a long-term focus on customer satisfaction and loyalty, ultimately benefiting the company's growth and sustainability.</p><p>As UX designers, it’s not easy to balance out company profit and positive user experiences. Sometimes, we don’t even notice the design process we create causes frustration and even makes people lose money. But by learning more about dark patterns, we can understand further how to avoid them and enhance the user experience. After all, we can always strive to be more transparent and ethical to our target audience and, why not, to ourselves as well.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open-source drawing tool – Excalidraw (141 pts)]]></title>
            <link>https://github.com/excalidraw/excalidraw</link>
            <guid>38499375</guid>
            <pubDate>Sat, 02 Dec 2023 15:45:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/excalidraw/excalidraw">https://github.com/excalidraw/excalidraw</a>, See on <a href="https://news.ycombinator.com/item?id=38499375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><a href="https://excalidraw.com/" rel="nofollow">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" alt="Excalidraw" srcset="https://camo.githubusercontent.com/e76d762748baa56a56fc215f5c57681fc6c727d3f97c3ff2c1837884e1724dbc/68747470733a2f2f657863616c69647261772e6e7963332e63646e2e6469676974616c6f6365616e7370616365732e636f6d2f6769746875622f657863616c69647261775f6769746875625f636f7665725f325f6461726b2e706e67" data-canonical-src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/github/excalidraw_github_cover_2_dark.png">
    <img alt="Excalidraw" src="https://camo.githubusercontent.com/28c5cf889764ed06d14e2fffc54d553c8814077dd2659b25f6ba51f88d147086/68747470733a2f2f657863616c69647261772e6e7963332e63646e2e6469676974616c6f6365616e7370616365732e636f6d2f6769746875622f657863616c69647261775f6769746875625f636f7665725f322e706e67" data-canonical-src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/github/excalidraw_github_cover_2.png">
  </picture></themed-picture>
</a>
<h4 tabindex="-1" dir="auto">
  <a href="https://excalidraw.com/" rel="nofollow">Excalidraw Editor</a> |
  <a href="https://blog.excalidraw.com/" rel="nofollow">Blog</a> |
  <a href="https://docs.excalidraw.com/" rel="nofollow">Documentation</a> |
  <a href="https://plus.excalidraw.com/" rel="nofollow">Excalidraw+</a>
</h4>
<div dir="auto">
  <h2 tabindex="-1" dir="auto">
    An open source virtual hand-drawn style whiteboard. <br>
    Collaborative and end-to-end encrypted. </h2>
</div>

<p dir="auto">
  <a href="https://github.com/excalidraw/excalidraw/blob/master/LICENSE">
    <img alt="Excalidraw is released under the MIT license." src="https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg">
  </a>
  <a href="https://www.npmjs.com/package/@excalidraw/excalidraw" rel="nofollow">
    <img alt="npm downloads/month" src="https://camo.githubusercontent.com/39633863ab48e98f299f15cb00ffeadf27414b9eb04d01030587d82f52380c42/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f40657863616c69647261772f657863616c6964726177" data-canonical-src="https://img.shields.io/npm/dm/@excalidraw/excalidraw">
  </a>
  <a href="https://docs.excalidraw.com/docs/introduction/contributing" rel="nofollow">
    <img alt="PRs welcome!" src="https://camo.githubusercontent.com/58e45dedeb7342e0487c805f92b20dd215e093f18137b3abd5fe37de7c49088e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c6174" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat">
  </a>
  <a href="https://discord.gg/UexuTaE" rel="nofollow">
    <img alt="Chat on Discord" src="https://camo.githubusercontent.com/00dd1c359a182be67df0e0292e2da6824a150d80c544df487012afa218bf8905/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3732333637323433303734343137343638323f636f6c6f723d373338616436266c6162656c3d436861742532306f6e253230446973636f7264266c6f676f3d646973636f7264266c6f676f436f6c6f723d6666666666662677696467653d66616c7365" data-canonical-src="https://img.shields.io/discord/723672430744174682?color=738ad6&amp;label=Chat%20on%20Discord&amp;logo=discord&amp;logoColor=ffffff&amp;widge=false">
  </a>
  <a href="https://twitter.com/excalidraw" rel="nofollow">
    <img alt="Follow Excalidraw on Twitter" src="https://camo.githubusercontent.com/7c52554ad8b5433d04ace05ceac807e1fa6740a5cfe852410425b8de96c6a3a0/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f657863616c69647261772e7376673f6c6162656c3d666f6c6c6f772b40657863616c6964726177267374796c653d736f6369616c266c6f676f3d74776974746572" data-canonical-src="https://img.shields.io/twitter/follow/excalidraw.svg?label=follow+@excalidraw&amp;style=social&amp;logo=twitter">
  </a>
</p>
<div dir="auto">
  
    <p><a href="https://excalidraw.com/" rel="nofollow">
      <img src="https://camo.githubusercontent.com/600260352d4cd183ef318980816010d08cd29b9891a23e7bb1a5b61e595312eb/68747470733a2f2f657863616c69647261772e6e7963332e63646e2e6469676974616c6f6365616e7370616365732e636f6d2f67697468756225324670726f647563745f73686f77636173652e706e67" alt="Product showcase" data-canonical-src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/github%2Fproduct_showcase.png">
    </a></p><p dir="auto">
        Create beautiful hand-drawn like diagrams, wireframes, or whatever you like.
      </p>
    
  
</div>
<h2 tabindex="-1" dir="auto">Features</h2>
<p dir="auto">The Excalidraw editor (npm package) supports:</p>
<ul dir="auto">
<li>💯&nbsp;Free &amp; open-source.</li>
<li>🎨&nbsp;Infinite, canvas-based whiteboard.</li>
<li>✍️&nbsp;Hand-drawn like style.</li>
<li>🌓&nbsp;Dark mode.</li>
<li>🏗️&nbsp;Customizable.</li>
<li>📷&nbsp;Image support.</li>
<li>😀&nbsp;Shape libraries support.</li>
<li>👅&nbsp;Localization (i18n) support.</li>
<li>🖼️&nbsp;Export to PNG, SVG &amp; clipboard.</li>
<li>💾&nbsp;Open format - export drawings as an <code>.excalidraw</code> json file.</li>
<li>⚒️&nbsp;Wide range of tools - rectangle, circle, diamond, arrow, line, free-draw, eraser...</li>
<li>➡️&nbsp;Arrow-binding &amp; labeled arrows.</li>
<li>🔙&nbsp;Undo / Redo.</li>
<li>🔍&nbsp;Zoom and panning support.</li>
</ul>
<h2 tabindex="-1" dir="auto">Excalidraw.com</h2>
<p dir="auto">The app hosted at <a href="https://excalidraw.com/" rel="nofollow">excalidraw.com</a> is a minimal showcase of what you can build with Excalidraw. Its <a href="https://github.com/excalidraw/excalidraw/tree/master/excalidraw-app">source code</a> is part of this repository as well, and the app features:</p>
<ul dir="auto">
<li>📡&nbsp;PWA support (works offline).</li>
<li>🤼&nbsp;Real-time collaboration.</li>
<li>🔒&nbsp;End-to-end encryption.</li>
<li>💾&nbsp;Local-first support (autosaves to the browser).</li>
<li>🔗&nbsp;Shareable links (export to a readonly link you can share with others).</li>
</ul>
<p dir="auto">We'll be adding these features as drop-in plugins for the npm package in the future.</p>
<h2 tabindex="-1" dir="auto">Quick start</h2>
<p dir="auto">Install the <a href="https://www.npmjs.com/package/@excalidraw/excalidraw" rel="nofollow">Excalidraw npm package</a>:</p>
<div data-snippet-clipboard-copy-content="npm install react react-dom @excalidraw/excalidraw"><pre><code>npm install react react-dom @excalidraw/excalidraw
</code></pre></div>
<p dir="auto">or via yarn</p>
<div data-snippet-clipboard-copy-content="yarn add react react-dom @excalidraw/excalidraw"><pre><code>yarn add react react-dom @excalidraw/excalidraw
</code></pre></div>
<p dir="auto">Don't forget to check out our <a href="https://docs.excalidraw.com/" rel="nofollow">Documentation</a>!</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<ul dir="auto">
<li>Missing something or found a bug? <a href="https://github.com/excalidraw/excalidraw/issues">Report here</a>.</li>
<li>Want to contribute? Check out our <a href="https://docs.excalidraw.com/docs/introduction/contributing" rel="nofollow">contribution guide</a> or let us know on <a href="https://discord.gg/UexuTaE" rel="nofollow">Discord</a>.</li>
<li>Want to help with translations? See the <a href="https://docs.excalidraw.com/docs/introduction/contributing#translating" rel="nofollow">translation guide</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">Integrations</h2>
<ul dir="auto">
<li><a href="https://marketplace.visualstudio.com/items?itemName=pomdtr.excalidraw-editor" rel="nofollow">VScode extension</a></li>
<li><a href="https://www.npmjs.com/package/@excalidraw/excalidraw" rel="nofollow">npm package</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Who's integrating Excalidraw</h2>
<p dir="auto"><a href="https://googlecloudcheatsheet.withgoogle.com/architecture" rel="nofollow">Google Cloud</a> • <a href="https://meta.com/" rel="nofollow">Meta</a> • <a href="https://codesandbox.io/" rel="nofollow">CodeSandbox</a> • <a href="https://github.com/zsviczian/obsidian-excalidraw-plugin">Obsidian Excalidraw</a> • <a href="https://replit.com/" rel="nofollow">Replit</a> • <a href="https://slite.com/" rel="nofollow">Slite</a> • <a href="https://notion.so/" rel="nofollow">Notion</a> • <a href="https://www.hackerrank.com/" rel="nofollow">HackerRank</a> • and many others</p>
<h2 tabindex="-1" dir="auto">Sponsors &amp; support</h2>
<p dir="auto">If you like the project, you can become a sponsor at <a href="https://opencollective.com/excalidraw" rel="nofollow">Open Collective</a> or use <a href="https://plus.excalidraw.com/" rel="nofollow">Excalidraw+</a>.</p>
<h2 tabindex="-1" dir="auto">Thank you for supporting Excalidraw</h2>
<p dir="auto"><a href="https://opencollective.com/excalidraw/tiers/sponsors/0/website" rel="nofollow"><img src="https://camo.githubusercontent.com/9af8b217dbcbf34d3746d4bf9c055fdc0b16ff50f3d6a73f731d48bae5380c64/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f302f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/0/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/1/website" rel="nofollow"><img src="https://camo.githubusercontent.com/928c612e33fe267dbe3bcd465385e5fe66c317c255a5f97f5066d02c3a3dde26/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f312f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/1/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/2/website" rel="nofollow"><img src="https://camo.githubusercontent.com/0467c2c521d4707122de7a2ddad978c8479e31a2db8f84fec20554d228b2983c/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f322f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/2/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/3/website" rel="nofollow"><img src="https://camo.githubusercontent.com/0b7840912def4188fafe6e9b9d8e038c0863c775028b5382ce326ba39c29f4b4/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f332f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/3/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/4/website" rel="nofollow"><img src="https://camo.githubusercontent.com/d3244aefd3a13f80d051a574605827ecbcd9b8ede868480f22ac8d47f638b4de/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f342f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/4/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/5/website" rel="nofollow"><img src="https://camo.githubusercontent.com/97c3b387aad1481867826b0421dfc564c06841223f204f73ac778a12862ddcc5/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f352f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/5/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/6/website" rel="nofollow"><img src="https://camo.githubusercontent.com/bfdc8f61fbb5ec0b10fcc225c19b7fb780657a28123d4e93ce907dfbb1df879e/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f362f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/6/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/7/website" rel="nofollow"><img src="https://camo.githubusercontent.com/40bdcaff7bd0555574d5b762690095e37b0081f5d767ce1218b330607612e4a8/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f372f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/7/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/8/website" rel="nofollow"><img src="https://camo.githubusercontent.com/1bed83c896394d840840501301923f26c357d8f5f17e3b342d34a278f617599d/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f382f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/8/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/9/website" rel="nofollow"><img src="https://camo.githubusercontent.com/d987ce86c84900ac5869c4af040c2b83fb6ba007f5dc0c97f3e6dc41cfab1efc/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f392f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/9/avatar.svg?avatarHeight=120"></a> <a href="https://opencollective.com/excalidraw/tiers/sponsors/10/website" rel="nofollow"><img src="https://camo.githubusercontent.com/1b36c7e2a6f7b276fa052d19a2306e52ab63b41f3e04fe8f673efc993adb1af5/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f73706f6e736f72732f31302f6176617461722e7376673f6176617461724865696768743d313230" data-canonical-src="https://opencollective.com/excalidraw/tiers/sponsors/10/avatar.svg?avatarHeight=120"></a></p>
<p dir="auto"><a href="https://opencollective.com/excalidraw#category-CONTRIBUTE" rel="nofollow"><img src="https://camo.githubusercontent.com/93b25ca71ce9095662478c2de8816ddff8f58f012b7d5bb31f1fe1d9d5150013/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f657863616c69647261772f74696572732f6261636b6572732e7376673f6176617461724865696768743d3332" data-canonical-src="https://opencollective.com/excalidraw/tiers/backers.svg?avatarHeight=32"></a></p>
<p dir="auto">Last but not least, we're thankful to these companies for offering their services for free:</p>
<p dir="auto"><a href="https://vercel.com/" rel="nofollow"><img src="https://github.com/excalidraw/excalidraw/raw/master/.github/assets/vercel.svg" alt="Vercel"></a> <a href="https://sentry.io/" rel="nofollow"><img src="https://github.com/excalidraw/excalidraw/raw/master/.github/assets/sentry.svg" alt="Sentry"></a> <a href="https://crowdin.com/" rel="nofollow"><img src="https://github.com/excalidraw/excalidraw/raw/master/.github/assets/crowdin.svg" alt="Crowdin"></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf Live Now (109 pts)]]></title>
            <link>https://emacsconf.org</link>
            <guid>38499197</guid>
            <pubDate>Sat, 02 Dec 2023 15:26:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://emacsconf.org">https://emacsconf.org</a>, See on <a href="https://news.ycombinator.com/item?id=38499197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pagebody" role="main">
<p><a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a></p>




<p>EmacsConf is the conference about the joy of
<a href="https://www.gnu.org/software/emacs/">Emacs</a> and
Emacs Lisp.</p>


<h2>Current Conference</h2>

<ul>
<li><strong><a href="https://emacsconf.org/2023/">EmacsConf 2023</a></strong></li>
</ul>


<h2>Past Conferences</h2>

<ul>
<li><a href="https://emacsconf.org/2022/">EmacsConf 2022</a></li>
<li><a href="https://emacsconf.org/2021/">EmacsConf 2021</a></li>
<li><a href="https://emacsconf.org/2020/">EmacsConf 2020</a></li>
<li><a href="https://emacsconf.org/2019/">EmacsConf 2019</a></li>
<li><a href="https://emacsconf.org/2015/">EmacsConf 2015</a></li>
<li><a href="https://emacsconf.org/2013/">EmacsConf 2013</a></li>
</ul>


<h2>Updates</h2>

<div>

<p><a type="application/rss+xml" rel="alternate" title="EmacsConf (RSS feed)" href="https://emacsconf.org/index.rss">RSS</a>


<a type="application/atom+xml" rel="alternate" title="EmacsConf (Atom feed)" href="https://emacsconf.org/index.atom">Atom</a>

</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2023-09-25-draft-schedule/">EmacsConf 2023 progress report: 44 talks accepted, schedule being drafted</a><br>

<span>
Posted <span>Tuesday 26 September 2023 at  1:06 (UTC)</span>

</span>
</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2023-08-14-cfp-progress/">EmacsConf 2023 CFP progress report (8 talks accepted so far, 1 to review, 6 todo)</a><br>

<span>
Posted <span>Tuesday 15 August 2023 at  0:50 (UTC)</span>

</span>
</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2022-11-07/">Captions, dry run, workflow improvements</a><br>

<span>
Posted <span>Monday  7 November 2022 at 12:57 (UTC)</span>

</span>
</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2022-10-30/">Captions, tech checks, intros, OBS</a><br>

<span>
Posted <span>Sunday 30 October 2022 at 23:44 (UTC)</span>

</span>
</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2022-10-16/">Speakers confirmed, Etherpad, watch pages, shifts</a><br>

<span>
Posted <span>Wednesday 26 October 2022 at 16:18 (UTC)</span>

</span>
</p></div>
<div>

<p><a href="https://emacsconf.org/blog/2022-10-23/">Backstage, captions, streaming, and more</a><br>

<span>
Posted <span>Sunday 23 October 2022 at 18:07 (UTC)</span>

</span>
</p></div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are some unpopular technologies you wish people knew more about? (242 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38499134</link>
            <guid>38499134</guid>
            <pubDate>Sat, 02 Dec 2023 15:16:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38499134">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38502395"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38502395" href="https://news.ycombinator.com/vote?id=38502395&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Black and white film processing.  It used to be taught in schools.  Many schools still have their darkrooms and no longer use them.  It is a practical application of physics, chemistry, and art.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38499453"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499453" href="https://news.ycombinator.com/vote?id=38499453&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Most people know about MediaWiki even if they don't realize they do, because it powers Wikipedia, but I wish more people used it for documentation.<p>You can create highly specialized templates in Lua, and there's a RDBMS extension called Cargo that gives you some limited SQL ability too. With these tools you can build basically an entirely custom CMS on top of the base MW software, while retaining everything that's great about MW (easy page history, anyone can start editing including with a WYSIWYG editor, really fine-grained permissions control across user groups, a fantastic API for automated edits).</p><p>It doesn't have the range of plugins to external services the way something like Confluence has, but you can host it yourself and have a great platform for documentation.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500045"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38500045" href="https://news.ycombinator.com/vote?id=38500045&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Like any documentation system, its success depends on its audience.<p>As an administrator, I wish MediaWiki had a built-in updater (bonus points if it could be automated).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500611"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38500611" href="https://news.ycombinator.com/vote?id=38500611&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>&gt; As an administrator, I wish MediaWiki had a built-in updater (bonus points if it could be automated).<p>I get that by using the container distributions. I just mount My LocalSettings.php and storage volumes in the appropriate places and I get a new version.</p><p>And since I run on ZFS and i take a snapshot before updating if something goes wrong I can rollback the snapshot, and go back to when stuff just worked (and retry later).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38499523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499523" href="https://news.ycombinator.com/vote?id=38499523&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Nix package manager's `nix-shell` is something I wish more people knew about. Nix is gaining some popularity, but people often think of using it has to be a really big commitment, like changing your Linux distro to NixOS or replacing your dotfiles with a Nix-based one (using the Nix package manager).<p>What I wish more people knew was that you don't need to do those things to get value from Nix. Create project specific dev shells that install the packages (at the correct versions) to work with that project can almost replace 90% of the docs for getting setup to work on a project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501930"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38501930" href="https://news.ycombinator.com/vote?id=38501930&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Have you tried compiling software with a nix shell? It gets linked to the Nix store. Needless to say it was a frustrating revelation.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38499826"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499826" href="https://news.ycombinator.com/vote?id=38499826&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>It's good for a c or c++ project where libraries are very environment specific. But most modern languages have their own package/environment managers which makes Nix redundant.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38502321"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38502321" href="https://news.ycombinator.com/vote?id=38502321&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I had to use it for a c++ project and it was one of the biggest waste of time and frustrating moments of my computing career, there were constant breakages due to glibc mismatches, Nvidia drivers and whatnot, and getting an host IDE to have semantic understanding of the paths , etc... necessary for normal completions and stuff was nigh impossible.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38500159"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38500159" href="https://news.ycombinator.com/vote?id=38500159&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Not really. I introduced it to our Python projects at work and it's been great. Partially because of poetry2nix, and partially because it makes it easy to include other stuff like a specific version of Redis for testing purposes. Everybody gets the exact same dev environment, reducing a ton of "works on my machine".</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38500437"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38500437" href="https://news.ycombinator.com/vote?id=38500437&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Presumably it also can fill the role of conda/mamba i.e. also managing C/C++ libraries in the same way in the nix environment, isolated from the system libraries?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38500835"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38500835" href="https://news.ycombinator.com/vote?id=38500835&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Yep, it can lock down exact versions of those libraries as well, which is great for not mucking about with lib versions between even different Ubuntu versions, not to mention distros or macOS.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38500406"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38500406" href="https://news.ycombinator.com/vote?id=38500406&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>virtualenv is the python way. For things like redis and other external web stuff, docker is the standard.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38500812"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38500812" href="https://news.ycombinator.com/vote?id=38500812&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Sure, that works. Or I can have it all in a single shell.nix file that covers everything and is super simple to use. It's great for handing off to coworkers that don't usually use Python.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38501453"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_38501453" href="https://news.ycombinator.com/vote?id=38501453&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>It's not simple. The nix programming language is like untyped ML. Most people aren't used to it and even if you are familiar with it it gets hella hard to read. Learning curve is huge.<p>One docker file and a poetry file works just as well. And is simpler. It's literally the same thing but using os primitives to manage the environment rather then shell tricks. Makes more sense to me to use a dedicated os primitive for the task it was designed to be used for.</p><p>Additionally docker-compose allows you to manage a constellation of environments simultaneously. This is nowhere near as straightforward with nix.</p><p>I love nix but being honest here. It's not definitively the best.</p><p>The biggest reason right now to avoid it is adoption. Most people won't know what to do with a shell.nix
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501569"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_38501569" href="https://news.ycombinator.com/vote?id=38501569&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>&gt;It's not simple.<p>Neither is using virtualenvs for Python packages with native extensions.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38502097"><td></td></tr>
                                                      <tr id="38499782"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499782" href="https://news.ycombinator.com/vote?id=38499782&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>In case you don't fancy visiting all the links:<p>- Tarantool is some sort of in-memory DB with optional persistence</p><p>- Red is a programming language that has made the odd syntax decision to use {} for strings and [] to define scopes</p><p>- U++ is one of those all-encompasing C++ frameworks like QT</p><p>- Lazarus is a Pascal(?) IDE</p><p>- And FASM is a toolkit for building assemblers</p><p>I'm struggling to find the common thread across these links, apart from the OP probably being an enthusiast of obscure programming languages
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500842"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38500842" href="https://news.ycombinator.com/vote?id=38500842&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Thank you for summing it up. The common is things from developer's perspective I feel they should be checked out (not just programming languages)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38501327"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501327" href="https://news.ycombinator.com/vote?id=38501327&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I guess I'm looking for a hint as to why this selection of items is particularly interesting to <i>you</i>. These cover a pretty wide spread of topics, and for folks who aren't well versed in each topic, they might be better served by evaluating the standard option in that field (Redis, Qt, etc) before they dive into the weird alternatives</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38499216"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499216" href="https://news.ycombinator.com/vote?id=38499216&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Not sure if you're looking for things as "trifling" as programming languages, but I do wish more people knew about Nim. It's fast, statically typed, reads more or less like Python, has a great effect system, etc. It's a joy to use. I've been working through writing an interpreter in it: 
<a href="https://youtu.be/48CsjEFzyXQ" rel="nofollow noreferrer">https://youtu.be/48CsjEFzyXQ</a></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38499237"><td></td></tr>
                <tr id="38499256"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38499256" href="https://news.ycombinator.com/vote?id=38499256&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Thanks! I plan to record many more videos. Had some unplanned construction going on in my house so my recording setup is unavailable for a bit. As soon as it's done in a few weeks, I'll put out more videos.<p>Your book looks great, will check it out.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499263"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499263" href="https://news.ycombinator.com/vote?id=38499263&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Just so you know, the call for speakers for the 2024 Carolina Code Conference (polyglot) will open January 1.<p>A Nim talk would be a great fit for the event.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499476"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499476" href="https://news.ycombinator.com/vote?id=38499476&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I was using Nim for some of last years Advent of Code problems. I was mostly liking the syntax. Was a bit bother by the standard library have a snake case and camel case reference for each function (if I'm remember that correctly).<p>At the time nimble also required me to have NPM to install the the Nim package manager, Nimble. This was not ideal, but looking at [the nimble project install docs](<a href="https://github.com/nim-lang/nimble#installation">https://github.com/nim-lang/nimble#installation</a>) it seems like it is now package with the language.</p><p>Might try dusting it off for some AoC puzzles this year :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501721"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501721" href="https://news.ycombinator.com/vote?id=38501721&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I believe the whole language is "style insensitive" for variable names. So it's not just a feature of the stdlib.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38501080"><td></td></tr>
                        <tr id="38499370"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499370" href="https://news.ycombinator.com/vote?id=38499370&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>GnuPG/PGP and the web of trust[0]. A lot of things I see blockchain being used for today (e.g. NFTs) seems like it would be better solved using standard OpenPGP signatures with no backing chain.<p>Additionally, as machine-generated content proliferates, I think having services use something like the web of trust concept for membership would be super powerful. The problem is, of course, the terrible UX of cryptographic signatures. But I think there's a lot of opportunity for the group that makes it easy to use.</p><p>[0]: <a href="https://en.wikipedia.org/wiki/Web_of_trust" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Web_of_trust</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499912"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499912" href="https://news.ycombinator.com/vote?id=38499912&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>GPG is great. It also makes it really easy to encrypt environment dotfiles that safely reside in your source code repository. This is my favorite way of storing sensitive app configs. You don't even need a PGP private key in your keychain to do it. You can use a passphrase.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38500525"><td></td></tr>
                  <tr id="38499672"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499672" href="https://news.ycombinator.com/vote?id=38499672&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>There's a problem though: either you have to ban transferring NFTs (or other tokens), which makes those a lot less useful, or you need something to prevent double spend attacks (something that blockchain solves).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38499565"><td></td></tr>
            <tr id="38499497"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499497" href="https://news.ycombinator.com/vote?id=38499497&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>&gt; seems like it would be better solved using standard OpenPGP signatures with no backing chain.<p>Programmability though
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499581"><td></td></tr>
                <tr id="38500167"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38500167" href="https://news.ycombinator.com/vote?id=38500167&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>There would be no automated consensus over results of execution of programs that power the applications</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38502374"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38502374" href="https://news.ycombinator.com/vote?id=38502374&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Just curious, which would be most reliable? One entity confirms it who confirmed 1000 previous results, 2 who confirmed 500, 10 who confirmed 100 or 1000 who confirmed 1 previously?</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="38499295"><td></td></tr>
            <tr id="38499229"><td></td></tr>
                <tr id="38501650"><td></td></tr>
            <tr id="38499249"><td></td></tr>
                  <tr id="38499253"><td></td></tr>
                <tr id="38499297"><td></td></tr>
                <tr id="38499498"><td></td></tr>
                <tr id="38500226"><td></td></tr>
                <tr id="38501465"><td></td></tr>
                                    <tr id="38499435"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499435" href="https://news.ycombinator.com/vote?id=38499435&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>RDF and semantic web used to be my goto's for this, as I believe many of the core ideas are still valid and often overlooked and sometimes even poorly re-implemented. Which says something.<p>However, lately I've come to like llama.cpp and friends, yes it's not ChatGTP miracle whatever but how often do you /actually/ need that? Despite its tremendous popularity, it still seems like something more people should know about. For me, I've had great fun with running LLMs locally and experiencing their different "flavors" from a more "phenomenological" (what is it like to use them) perspective rather than a technological one.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499339"><td></td></tr>
            <tr id="38499274"><td></td></tr>
                <tr id="38499307"><td></td></tr>
                <tr id="38501443"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501443" href="https://news.ycombinator.com/vote?id=38501443&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I know, not reddit, but I simply can't resist:<p>&gt; Pick was originally implemented as the Generalized Information Retrieval Language System (GIRLS) on an IBM System/360 in 1965 by Don Nelson and Dick Pick [...]
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499509"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499509" href="https://news.ycombinator.com/vote?id=38499509&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>My first job involved working on a Pick system.  The system started life on a Prime mainframe and was migrated to UniVerse on Solaris.<p>I seriously miss it.</p><p>Every once in a while I try to get back into it.  Usually it takes the form of trying (and failing) to get a demo/personal version of UniVerse, but lately I've been poking at ScarletDME a little bit.  I'd even pay money (not much since this is just hobby stuff, but some) for UniVerse, but even the cost of it seems to be a closely guarded secret.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499567"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38499567" href="https://news.ycombinator.com/vote?id=38499567&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Thanks, Mister_Snuggles, for reminding me I'm not the only one left.<p>I HAVE to code in PICK.</p><p>"Unless it comes out of your soul like a rocket, unless being still would drive you to madness or suicide or murder, don’t do it." - Charles Burkowski</p><p>(Funny, they named the current support company "Rocket".)</p><p>Here's the link to the current Universe trial version (free and good until 04/2025. Get it, install it, and make something with it. Please don't let that part of you die.</p><p><a href="https://www.rocketsoftware.com/products/rocket-multivalue-application-development-platform/rocket-u2-trials" rel="nofollow noreferrer">https://www.rocketsoftware.com/products/rocket-multivalue-ap...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499884"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38499884" href="https://news.ycombinator.com/vote?id=38499884&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Yup, this is exactly where I get to when I try and fail to get UniVerse.<p>What's the trick to making that form work?  It won't accept my @gmail.com address, and I don't really want to use my work email address and potentially mis-represent things.  Especially since my work used to use one of Rocket's products.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501010"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38501010" href="https://news.ycombinator.com/vote?id=38501010&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I used my work email and then forwarded it to my g mail.<p>If you have concerns about doing that, you can just download it from my website at</p><p><a href="http://eddiots.com/UVTE_WINDOWS_11.4.1.zip" rel="nofollow noreferrer">http://eddiots.com/UVTE_WINDOWS_11.4.1.zip</a> (You may have to cut and paste this link into a new tab. HN doesn't seem to like this.)</p><p>If you have any problems or need the UNIX version, just reply here or contact me. email on my profile. Let me know how it goes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38501761"><td></td></tr>
                <tr id="38501809"><td></td></tr>
                              <tr id="38499732"><td></td></tr>
            <tr id="38500855"><td></td></tr>
                <tr id="38501026"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501026" href="https://news.ycombinator.com/vote?id=38501026&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Thanks, aredirect!<p>My next phase is to put the PICK-generated svg into codepen and provide links to show how to draw the art with code.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38499545"><td></td></tr>
                <tr id="38500748"><td></td></tr>
                <tr id="38502370"><td></td></tr>
                  <tr id="38499960"><td></td></tr>
                <tr id="38500100"><td></td></tr>
                <tr id="38500604"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38500604" href="https://news.ycombinator.com/vote?id=38500604&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>But beware row-level security. It's great, but the query planning is a huge mess, and you can end up with serious performance issues real fast if you're not careful.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38501489"><td></td></tr>
                  <tr id="38499490"><td></td></tr>
            <tr id="38499385"><td></td></tr>
                <tr id="38501137"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38501137" href="https://news.ycombinator.com/vote?id=38501137&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I still use Bottle for all my starter projects. It’s just unmatched in terms of bang for the buck.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499402"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499402" href="https://news.ycombinator.com/vote?id=38499402&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Vopono (<a href="https://github.com/jamesmcm/vopono">https://github.com/jamesmcm/vopono</a>):<p>"vopono is a tool to run applications through VPN tunnels via temporary network namespaces. This allows you to run only a handful of applications through different VPNs simultaneously, whilst keeping your main connection as normal.</p><p>vopono includes built-in killswitches for both Wireguard and OpenVPN."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38501816"><td></td></tr>
            <tr id="38499776"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499776" href="https://news.ycombinator.com/vote?id=38499776&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Growing in popularity, but still not as famous as it should be: EdgeDB (<a href="https://edgedb.com/" rel="nofollow noreferrer">https://EdgeDB.com</a>)<p>* Graph-relational database</p><p>* Queries return objects linked to other objects through properties, not rows</p><p>* ... But it's still Postgres under the hood</p><p>* Open source
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499948"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499948" href="https://news.ycombinator.com/vote?id=38499948&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I’ve really enjoyed working with EdgeDB. I totally agree. I’m on a project now that’s using firebase/firestore and edge seems dramatically better suited, but it would be a hard sell.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38501540"><td></td></tr>
            <tr id="38499616"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499616" href="https://news.ycombinator.com/vote?id=38499616&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Sphinx [1] gets my vote. It's the docs system that powers most sites in the Python ecosystem so it probably looks familiar to you.<p>I call it a docs system rather than static site generator because the web is just one of many output targets it supports.</p><p>To tap into its full power you need to author in a markup that predates Markdown called reStructuredText (reST). It's very similar to Markdown (MD) so it's never bothered me, but I know some people get very annoyed at the "uncanny valley" between reST and MD. reST has some very powerful yet simple features; it perplexes me that these aren't adopted in other docs systems. For example, to cross-link you just do :ref:`target` where `target` is an ID for a section. At "compile-time" the ref is replaced with the section title text. If you remove that ID then the build fails. Always accurate internal links, in other words.</p><p>The extension system really works and there is quite a large ecosystem of extensions on PyPI for common tasks, such as generating a sitemap.</p><p>The documentation for Sphinx is ironically not great; not terrible but not great either. I eventually accomplish whatever I need to do but the sub-optimal docs make the research take a bit longer than it probably has to.</p><p>I have been a technical writer for 11 years and have used many SSGs over the years. There's no perfect SSG but Sphinx strikes the best balance between the common tradeoffs.</p><p>[1] <a href="https://www.sphinx-doc.org/en/master/index.html" rel="nofollow noreferrer">https://www.sphinx-doc.org/en/master/index.html</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500981"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38500981" href="https://news.ycombinator.com/vote?id=38500981&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I have always found sphinx challenging, in usability or syntax :( 
It could be probably much more advanced, but I went for pdoc3 for api docs and mdbook for documentation in general.<p>What I really hope that exists, is a system where I can reuse the documentation (sections) in other pages, ergonomically</p><p>I built that system multiple times to do preprocessing with things like including parts or special linking or referencing images from anyhwere</p><p><a href="https://github.com/xmonader/publishingtools/tree/development/src/tfwebserver">https://github.com/xmonader/publishingtools/tree/development...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499713"><td></td></tr>
                <tr id="38499867"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38499867" href="https://news.ycombinator.com/vote?id=38499867&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>edit: my understanding of feature parity in reST/Markdown seems outdated - comment below might be incorrect<p>The value prop of Sphinx goes down a lot if you're not using reST because you can't use the extensive catalog of directives, such as the ref directive that I mentioned in my first comment. If you must use Markdown then there's not much difference between Sphinx and all the other Markdown-powered SSGs out there. In other words there's not a compelling reason to use Sphinx if you've got to use Markdown.</p><p>From Sphinx's Getting Started page:</p><p>&gt; Much of Sphinx’s power comes from the richness of its default plain-text markup format, reStructuredText, along with its significant extensibility capabilities.</p><p><a href="https://www.sphinx-doc.org/en/master/usage/quickstart.html#getting-started" rel="nofollow noreferrer">https://www.sphinx-doc.org/en/master/usage/quickstart.html#g...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499940"><td></td></tr>
                <tr id="38500098"><td></td></tr>
                              <tr id="38499938"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499938" href="https://news.ycombinator.com/vote?id=38499938&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I've used Sphinx quite a bit, the syntax is a bit fugly.  For markdown's<pre><code>   [text](url)
</code></pre>
one uses<pre><code>   `text &lt;url&gt;`_
</code></pre>
...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38500132"><td></td></tr>
                        <tr id="38499398"><td></td></tr>
            <tr id="38499623"><td></td></tr>
            <tr id="38500852"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38500852" href="https://news.ycombinator.com/vote?id=38500852&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Asciidoc lightweight markup can be used in place of <i>ANY</i> complex XML-based CCS (component content system), i.e. DocBook, DITA, S1000D, 40-50-something MIL-STD "specifications". Asciidoc can do anything they can, and can do it cheaper, faster, and better. With standard tooling that's everywhere you have a computer.<p>I'm not sure I can type out, with trembling fingers, how many dollars have been flushed down the toilet of CCSs by businesses that either had no business experimenting with componentized content, or businesses that didn't have resources for training up staff, or vendors who literally evaporated like morning dew after they'd gotten their initialization fees. So just one single story: one prime aerospace vendor I worked with had started their road to S1000D publishing in 2009. Today - at the end of 2023, and more than twenty million dollars later, with a garbage truck full of sweat and blood - that system has not released a single publication to the end user. Not <i>one</i>.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499835"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499835" href="https://news.ycombinator.com/vote?id=38499835&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>WinCompose¹, or more generally, use of a Compose key² to type all sorts of Unicode symbols or really any character (sequence) you like. People are used to thinking that they mostly can’t type what they don’t see on their keyboards, but a Compose key provides a universal method to type a large repertoire of characters through use of mnemonics.<p>¹) <a href="http://wincompose.info/" rel="nofollow noreferrer">http://wincompose.info/</a></p><p>²) <a href="https://en.wikipedia.org/wiki/Compose_key" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Compose_key</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38501802"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38501802" href="https://news.ycombinator.com/vote?id=38501802&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>My picks would be Zulip for messaging, and Adguard Home instead of pihole. And self host your email - if only to keep that skill alive.<p>The openSUSE build system is also great for building packages for a lot distros. It's not just for openSUSE.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501927"><td></td></tr>
                  <tr id="38501924"><td></td></tr>
            <tr id="38499944"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499944" href="https://news.ycombinator.com/vote?id=38499944&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Gomplate is a super easy templating tool that wraps golang's template library with some useful built in functions. It's not as extensive as starlark but it is dead simple to get going with.<p>Also, my company (VMware) has a really powerful YAML templating engine called ytt. I originally hated it and dunked on it constantly but have grown to love it. It makes creating composable and modular YAML really easy, which is extremely unfortunate that this is a real thing, but when you need it, you need it.</p><p>Lastly, Cucumber isn't _unknown_ unknown, but I wish it was more widely used. Behavior testing is really useful even if the program has great test coverage underneath. Being able to express tests in pure English that do stuff is powerful and can be a bargaining chip for crucial conversations with product sometimes if done correctly. I mean, yes, we have GPTs that can write tests from prompts written in your language of choice and GPT Vision can manipulate a browser, but Cucumber is an easy stand-in IMO that is cheap and free!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499695"><td></td></tr>
            <tr id="38500698"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38500698" href="https://news.ycombinator.com/vote?id=38500698&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>RethinkDb: a “dead” project that is still maintained part time to keep the bit rot away, but actually just mature. Similar to memcached or beanstalkd.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38499704"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499704" href="https://news.ycombinator.com/vote?id=38499704&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>When I was at school (a long time ago), they tried to explain computers to us by making an adder using beads and matchboxes. We didn't have classroom computers back then. I'd like to know how that worked.<p>I've always wanted to build a digital clock entirely running on fluids. It would use fluid gates, and present a digital display by pushing blobs of coloured immiscible liquids back and forth through glass tubes (perhaps arranged as a seven-segment display). The counter itself would be made using fluid gates (which I don't know how to make). It would be slow; but for a wallclock with minute precision, you hardly need nanosecond gates.</p><p>So I wish "fluidonics" were popular.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38502228"><td></td></tr>
            <tr id="38499745"><td></td></tr>
                  <tr id="38499478"><td></td></tr>
                <tr id="38499683"><td></td></tr>
                  <tr id="38499677"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499677" href="https://news.ycombinator.com/vote?id=38499677&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Unpopular, at least compared to cars: e-bikes.<p>- costs next to nothing to charge</p><p>- fast and fun to get around</p><p>- never pay for parking</p><p>- cheap maintenance</p><p>- hauls groceries easily</p><p>- good exercise
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499953"><td></td></tr>
                <tr id="38502127"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38502127" href="https://news.ycombinator.com/vote?id=38502127&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Sorry, but many localities make it illegal for bicycle on the sidewalk (where they should be doing it). That's why many folks do it.<p>Laws making that illegal are extra stupid since it's relatively hard to kill a pedestrian with a bicycle but downright easy to kill a cyclist with a car.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38501272"><td></td></tr>
                <tr id="38501423"><td></td></tr>
            <tr id="38501444"><td></td></tr>
                              <tr id="38502287"><td></td></tr>
            <tr id="38499271"><td></td></tr>
            <tr id="38499349"><td></td></tr>
                <tr id="38499384"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499384" href="https://news.ycombinator.com/vote?id=38499384&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Dumb question but I thought tauri was the lightweight alternative to electron. Did I remember that incorrectly?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38499553"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38499553" href="https://news.ycombinator.com/vote?id=38499553&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Lightweight often just translates to less features. Unless you're rewriting a truly bad piece of software, you're "lightweight" alternative will be just as heavyweight when you're done reimplementing everything</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38501642"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38501642" href="https://news.ycombinator.com/vote?id=38501642&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Yes, WebUI uses the real installed web browser, so no rewriting is needed like WebView. The lib is 200 Kb !!!</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38500751"><td></td></tr>
            <tr id="38499276"><td></td></tr>
                <tr id="38499362"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499362" href="https://news.ycombinator.com/vote?id=38499362&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Shout out for ProcMon from the Sysinternals tools. It grants you diagnostic superpowers. "File Not Found" error w/ no filename shown-- no problem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499491"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499491" href="https://news.ycombinator.com/vote?id=38499491&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Chinese Text Analyzer <a href="https://www.chinesetextanalyser.com/" rel="nofollow noreferrer">https://www.chinesetextanalyser.com/</a><p>Tokenizes chinese text into "words" for learning purposes and then renders the text in a GUI where you can click on a word to get the definition. It's not perfect, but a LLM fine tuned for it will eventually result in much better "tokenization".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499592"><td></td></tr>
            <tr id="38499252"><td></td></tr>
            <tr id="38499789"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499789" href="https://news.ycombinator.com/vote?id=38499789&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I wish Lua Server Pages (LSP) were more widely adopted. It's similar to PHP, but utilizes Lua instead.<p>I dream of a CMS akin to WordPress, but developed in LSP.</p><p>Lua is lean, with minimal syntactic sugar, and it feels like a 'complete' language. Therefore, we don't anticipate any additional bloat in the future.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38499900"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499900" href="https://news.ycombinator.com/vote?id=38499900&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Lua in OpenResty is one of my favorite ways to ingest events. I publish them into Redis and then have some Python workers subscribed to process them.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38501009"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501009" href="https://news.ycombinator.com/vote?id=38501009&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I had experience with OpenResty, I was so proud to kill it in one of the projects, I didn't know Lua/MoonScript good enough, tooling and debugging wasn't that great. While the idea is nice, everything around it was too much for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38499355"><td></td></tr>
                <tr id="38499474"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499474" href="https://news.ycombinator.com/vote?id=38499474&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>There's a whole category of utopian developer environments and languages with far bigger aspirations than they were able to achieve but that still influenced others. Smalltalk being another example.<p>One of my favorite things about the old C2 Wards Wiki is that it's like an archaeological site where time is frozen in this period and you can browse through preserved arguments about how Smalltalk and Extreme Programming will take over the world.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499387"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499387" href="https://news.ycombinator.com/vote?id=38499387&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I keep hearing about it and its influence, but I can't really figure out if it's active or dead or even If I can use it on a virtual machine or so. 9p.io doesn't seem to even load on my machine</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38499466"><td></td></tr>
            <tr id="38500396"><td></td></tr>
                        <tr id="38499406"><td></td></tr>
                <tr id="38499885"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499885" href="https://news.ycombinator.com/vote?id=38499885&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>The bootstrapping and getting it to work from scratch was rather complicated. A lot of the docs are outdated. That's why.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38501571"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501571" href="https://news.ycombinator.com/vote?id=38501571&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>Which platform? On Windows there is a straightforward installer, and afterwards `haxelib` command installs e.g. HaxeFlixel, HaxeUI with all of the dependencies without any hiccups.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38499459"><td></td></tr>
            <tr id="38501844"><td></td></tr>
            <tr id="38502099"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38502099" href="https://news.ycombinator.com/vote?id=38502099&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>For some reason, the best note-taking tool ever made (Verbatim) was built rather quietly by a member of the American Competitive Debate Community. I literally made people in college jealous and upset when they saw how easy it was for me to take well structured notes using Verbatim: <a href="https://paperlessdebate.com/verbatim/" rel="nofollow noreferrer">https://paperlessdebate.com/verbatim/</a> (but then I showed them how to install it and they were happy)<p>A whole lot of innovation from the competitive debate community has quietly existed for decades now. Hopefully one day SV discovers all the cool shit debaters have been building for themselves.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499304"><td></td></tr>
            <tr id="38499519"><td></td></tr>
            <tr id="38499706"><td></td></tr>
            <tr id="38499455"><td></td></tr>
            <tr id="38499536"><td></td></tr>
            <tr id="38499794"><td></td></tr>
                <tr id="38499907"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499907" href="https://news.ycombinator.com/vote?id=38499907&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>I struggle to find a use case for Camunda, especially after they somehow discontinued embedding in Spring. And I really tried.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499467"><td></td></tr>
            <tr id="38499727"><td></td></tr>
            <tr id="38499686"><td></td></tr>
            <tr id="38499489"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499489" href="https://news.ycombinator.com/vote?id=38499489&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>i tried to use u++ way back when, and bounced off really hard (and i've used lots of different frameworks and environments). perhaps things have got better documented since?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38499803"><td></td></tr>
            <tr id="38500509"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38500509" href="https://news.ycombinator.com/vote?id=38500509&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Popular is a bit relative...<p>- I'd like Emacs/org-mode knowledge common at least starting from universities because we need the classic desktop model and Emacs is the still developed piece of software implementing it alongside with Pharo, but Pharo is usable only to play and develop while Emacs is ready to end-users usage with a gazillion of ready-made packages;</p><p>- feeds, in the broad sense, meaning XML automation on the net/web so I can get my bills just from a feedreader, all transactions digitally signed, so both party have a proof (ah, of course a national PKI is mandatory), news, anything in the same way making my information mine in my hands instead of wasting time in gazillion of crappy services;</p><p>- IPv6 with a global per host, so we can finally profit of our modern fiber-optics connections instead of being tied to someone else computer, i.e. "the cloud";</p><p>- last but just aside: R instead of spreadsheets for the business guys, so they do not produce and share anymore crappy stuff, LaTeX for similar reasons to produce nice looking pdfs...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499913"><td></td></tr>
            <tr id="38499846"><td></td></tr>
            <tr id="38499959"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499959" href="https://news.ycombinator.com/vote?id=38499959&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Relational modeling. 40+ years old, effective, simple, backed by math. No one wants to learn it anymore though.<p>(I only <i>wish</i> I was being sarcastic.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500772"><td></td></tr>
                  <tr id="38500239"><td></td></tr>
            <tr id="38499421"><td></td></tr>
                <tr id="38499473"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499473" href="https://news.ycombinator.com/vote?id=38499473&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Related to this, Revo Uninstaller. Sometimes programs don't clean up after themselves properly or the uninstaller is broken. Revo doesn't care, it tries to uninstall nicely first then resorts to scanning the drive for any remaining files, then scans the registry for remaining keys.<p>Not many people seem to know about it and everyone I show it to loves it!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499511"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38499511" href="https://news.ycombinator.com/vote?id=38499511&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>While this sounds very sarcastic, but I actually want to give windows a try, didn't use it for ~ 20 years, I don't even have no idea how it looks like now, but I keep hearing good things</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38499358"><td></td></tr>
                <tr id="38500757"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38500757" href="https://news.ycombinator.com/vote?id=38500757&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>First time to see that (now it went to my forever open tabs :) )<p>How is your experience with that?do you have it self-hosted or use their offering?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38501220"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38501220" href="https://news.ycombinator.com/vote?id=38501220&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><br><div>
                  <p><span>My opinion is temporal is a step function change in building workflow software. It allows for very complicated processes done simply</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38500148"><td></td></tr>
                <tr id="38500675"><td></td></tr>
            <tr id="38500763"><td></td></tr>
                <tr id="38501824"><td></td></tr>
                              <tr id="38499278"><td></td></tr>
            <tr id="38500707"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38500707" href="https://news.ycombinator.com/vote?id=38500707&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>A company I used to work for used to use the Versant OODBMS (object-oriented dbms).<p>It was truly interesting. Long story short, you stored your objects in the database, along with other objects. No object-relational mismatch.</p><p>Queries meant taking a subset of a graph (of objects). It was fast and performant, and fairly solid.</p><p>It's essentially the result of asking "what if database development had taken a different turn at some point?".</p><p>Of the owning company would release it under some kind of open source license (maybe open core, BSL or one of those new revenue-friendly licenses) it could probably get very very popular.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38499525"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38499525" href="https://news.ycombinator.com/vote?id=38499525&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>I'm thinking unpopular could mean the tech is polarizing or frequently dismissed/overlooked.<pre><code>  * APL -- I haven't dedicated the time to learning in part because there's little support where I normally work. I'd love for APL to have be adapted like a domain specific language a la perl compatible regular expressions for various languages (april in common lisp, APL.jl in julia).
  * regular expressions. https://xkcd.com/1171/
  * bugs/issue tracking embedded in git https://github.com/MichaelMure/git-bug/
</code></pre>
But I'm more excited for things that fall into the niche/lesser-known side of of unpopular. I love finding the little gems that change how I organize or work with the system.<pre><code>  * "type efficiently by saying syllables and literal words" https://sr.ht/~geb/numen/
  * I use fasd[0] 'z' alias for jumping to previous directories in shell every day.
  * Alt+. in shell (readline, bash) to get the previous commands last argument is another ergonomic time saver that I think is relatively obscure. I have a bash wrapper to combine that with fzf for quick any-previous-command-argument  fuzzy search and insert [1]
  * zimwiki [2] (and/or a less capable emacs mode[3]) for note taking has served me well for a decade+
  * DokuWiki's XML RPC [4] enables local editor edits to a web wiki. I wish it was picked up by more editor plugin developers. (cf. emacs-dokiwki [5]) 
 * xterm isn't unpopular per say, but I don't see sixel support and title setting escape codes talked about often. I depend on a bash debug trap to update the prompt with escape codes that set the terminal title [6]</code></pre>
* are clipboard managers popular? I get a lot out of using <a href="https://github.com/erebe/greenclip">https://github.com/erebe/greenclip</a><p>[0] <a href="https://github.com/clvv/fasd">https://github.com/clvv/fasd</a>
[1] <a href="https://github.com/WillForan/fuzzy_arg">https://github.com/WillForan/fuzzy_arg</a>
[2] <a href="https://zim-wiki.org/" rel="nofollow noreferrer">https://zim-wiki.org/</a>
[3] <a href="https://github.com/WillForan/zim-wiki-mode">https://github.com/WillForan/zim-wiki-mode</a>
[4] <a href="https://www.dokuwiki.org/xmlrpc" rel="nofollow noreferrer">https://www.dokuwiki.org/xmlrpc</a>
[5] <a href="https://github.com/flexibeast/emacs-dokuwiki">https://github.com/flexibeast/emacs-dokuwiki</a>
[6] <a href="https://github.com/WillForan/dotconf/blob/master/bash/PS1.bash#L48">https://github.com/WillForan/dotconf/blob/master/bash/PS1.ba...</a> -- bash debug trap to update prompt with escape codes that set the title to previous run command -- to eg. search windows for the terminal playing music from 'mpv'
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38500421"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38500421" href="https://news.ycombinator.com/vote?id=38500421&amp;how=up&amp;goto=item%3Fid%3D38499134"></a></center>    </td><td><p><span>Greenclip is exactly what I've been looking for! Thanks!<p>Also how do you use zimwiki? I've been trying it for a month and I don't find it that great compared to something like Obsidian or QOwnNotes or even TiddlyWiki. Do you have a specific workflow?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38500208"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Ada safer than Rust? (159 pts)]]></title>
            <link>https://old.reddit.com/r/rust/comments/17miqiu/is_ada_safer_than_rust/</link>
            <guid>38498775</guid>
            <pubDate>Sat, 02 Dec 2023 14:22:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/rust/comments/17miqiu/is_ada_safer_than_rust/">https://old.reddit.com/r/rust/comments/17miqiu/is_ada_safer_than_rust/</a>, See on <a href="https://news.ycombinator.com/item?id=38498775">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I saw a <a href="https://www.reddit.com/r/ada/comments/17hlebv/an_interesting_thing_happened_to_me_yesterday/k6tbn4f/?context=3">comment</a> by <a href="https://old.reddit.com/u/Kevlar-700">u/Kevlar-700</a> that said:</p>

<blockquote>
<p>Ada without Spark is actually safer than Rust due to it's richer type system without the pain of borrowing by using the stack, which is also faster than the heap. I never use the heap and the stack is memory safe for all general purposes in Ada. Pools in full Ada such as on Linux are used for safe heap use. Spark has some basic borrowing support which may be where the confusion is coming from.</p>
</blockquote>

<p>(SPARK is basically a theorem prover that you can use with Ada, but it's very tedious, as I understand it. And "memory pools" are what Ada calls arenas)</p>

<p>I'm not interested in language advocacy. I would just like to get to the bottom of this question: Is Ada (without SPARK) safer than Rust, while also being faster and easier to use?</p>

<p>Edit: There is a fairly small number of people who have used both Rust and Ada extensively. I was hoping that they'd see this post and share their insights, but I guess it was not to be -- downvoted.</p>

<p>Edit2: I also crossposted this in <a href="https://old.reddit.com/r/ada">r/ada</a>, in case anyone's interested in their take on this. </p>

<p>​</p>

<p>​</p>

<p><a href="https://preview.redd.it/ptmvooymq8yb1.jpg?width=725&amp;format=pjpg&amp;auto=webp&amp;s=534bb658fddfbe42f75e33370c77ad5ad26e3937">safety</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GQL – Git Query Language (193 pts)]]></title>
            <link>https://github.com/AmrDeveloper/GQL</link>
            <guid>38498688</guid>
            <pubDate>Sat, 02 Dec 2023 14:06:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AmrDeveloper/GQL">https://github.com/AmrDeveloper/GQL</a>, See on <a href="https://news.ycombinator.com/item?id=38498688">Hacker News</a></p>
<div id="readability-page-1" class="page"><p dir="auto">
GQL is a query language with a syntax very similar to SQL with a tiny engine to perform queries on .git files instance of database files, the engine executes the query on the fly without the need to create database files or convert .git files into any other format, note that all Keywords in GQL are case-insensitive similar to SQL.
</p><div dir="auto" data-snippet-clipboard-copy-content="SELECT 1
SELECT 1 + 2
SELECT LEN(&quot;Git Query Language&quot;)
SELECT &quot;One&quot; IN (&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;)
SELECT &quot;Git Query Language&quot; LIKE &quot;%Query%&quot;

SELECT DISTINCT title AS tt message FROM commits
SELECT name, COUNT(name) AS commit_num FROM commits GROUP BY name ORDER BY commit_num DESC LIMIT 10
SELECT commit_count FROM branches WHERE commit_count BETWEEN 0 .. 10

SELECT * FROM refs WHERE type = &quot;branch&quot;
SELECT * FROM refs ORDER BY type

SELECT * FROM commits
SELECT name, email FROM commits
SELECT name, email FROM commits ORDER BY name DESC, email ASC
SELECT name, email FROM commits WHERE name LIKE &quot;%gmail%&quot; ORDER BY name
SELECT * FROM commits WHERE LOWER(name) = &quot;amrdeveloper&quot;
SELECT name FROM commits GROUP By name
SELECT name FROM commits GROUP By name having name = &quot;AmrDeveloper&quot;

SELECT * FROM branches
SELECT * FROM branches WHERE is_head = true
SELECT name, LEN(name) FROM branches

SELECT * FROM tags
SELECT * FROM tags OFFSET 1 LIMIT 1"><pre><span>SELECT</span> <span>1</span>
<span>SELECT</span> <span>1</span> <span>+</span> <span>2</span>
<span>SELECT</span> LEN(<span><span>"</span>Git Query Language<span>"</span></span>)
<span>SELECT</span> <span><span>"</span>One<span>"</span></span> <span>IN</span> (<span><span>"</span>One<span>"</span></span>, <span><span>"</span>Two<span>"</span></span>, <span><span>"</span>Three<span>"</span></span>)
<span>SELECT</span> <span><span>"</span>Git Query Language<span>"</span></span> <span>LIKE</span> <span><span>"</span>%Query%<span>"</span></span>

<span>SELECT DISTINCT</span> title <span>AS</span> tt message <span>FROM</span> commits
<span>SELECT</span> name, <span>COUNT</span>(name) <span>AS</span> commit_num <span>FROM</span> commits <span>GROUP BY</span> name <span>ORDER BY</span> commit_num <span>DESC</span> <span>LIMIT</span> <span>10</span>
<span>SELECT</span> commit_count <span>FROM</span> branches <span>WHERE</span> commit_count BETWEEN <span>0</span> .. <span>10</span>

<span>SELECT</span> <span>*</span> <span>FROM</span> refs <span>WHERE</span> type <span>=</span> <span><span>"</span>branch<span>"</span></span>
<span>SELECT</span> <span>*</span> <span>FROM</span> refs <span>ORDER BY</span> type

<span>SELECT</span> <span>*</span> <span>FROM</span> commits
<span>SELECT</span> name, email <span>FROM</span> commits
<span>SELECT</span> name, email <span>FROM</span> commits <span>ORDER BY</span> name <span>DESC</span>, email <span>ASC</span>
<span>SELECT</span> name, email <span>FROM</span> commits <span>WHERE</span> name <span>LIKE</span> <span><span>"</span>%gmail%<span>"</span></span> <span>ORDER BY</span> name
<span>SELECT</span> <span>*</span> <span>FROM</span> commits <span>WHERE</span> <span>LOWER</span>(name) <span>=</span> <span><span>"</span>amrdeveloper<span>"</span></span>
<span>SELECT</span> name <span>FROM</span> commits <span>GROUP By</span> name
<span>SELECT</span> name <span>FROM</span> commits <span>GROUP By</span> name <span>having</span> name <span>=</span> <span><span>"</span>AmrDeveloper<span>"</span></span>

<span>SELECT</span> <span>*</span> <span>FROM</span> branches
<span>SELECT</span> <span>*</span> <span>FROM</span> branches <span>WHERE</span> is_head <span>=</span> true
<span>SELECT</span> name, LEN(name) <span>FROM</span> branches

<span>SELECT</span> <span>*</span> <span>FROM</span> tags
<span>SELECT</span> <span>*</span> <span>FROM</span> tags OFFSET <span>1</span> <span>LIMIT</span> <span>1</span></pre></div><div data-snippet-clipboard-copy-content="MIT License

Copyright (c) 2023 Amr Hesham

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE."><pre><code>MIT License

Copyright (c) 2023 Amr Hesham

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny Volumetric Display (1244 pts)]]></title>
            <link>https://mitxela.com/projects/candle</link>
            <guid>38498109</guid>
            <pubDate>Sat, 02 Dec 2023 12:23:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitxela.com/projects/candle">https://mitxela.com/projects/candle</a>, See on <a href="https://news.ycombinator.com/item?id=38498109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mxmain"><p><a href="https://mitxela.com/projects/hardware"><img onload="this.style.opacity=1;" src="https://mitxela.com/img/titles/mitxela_dot_com-65.png" title="Back to Hardware" alt="Back to Hardware"></a></p><p>1 Dec 2023<br><b>Progress: Completed</b></p><p>
A tiny volumetric display!</p><h3>Video Demo</h3><p>

<iframe width="704" height="396" src="https://www.youtube.com/embed/HKpBhE7QVAI" allowfullscreen=""></iframe></p><p>

Naturally you can't really feel the volumetric effect on camera. It looks a lot more 3D in real life.</p><h3>Idea</h3><p>
I was recently fortunate enough to find myself in the pub with some very creative and talented people. The discussion turned to electronic candles, and how one might create something that would look like a flickering candle from any angle. I suggested a persistence-of-vision display, but the general consensus was that those require too much in the way of supporting machinery to make them work: bearings, and probably slip rings and so on.</p><p>

Afterwards I had a think and figured that if the motor and battery were small enough, the whole thing could spin. I was ordering some other circuit boards the following day, so I quickly threw together a simple LED matrix board and combined that with the other orders. Small circuit boards from China are essentially free, fast postage is the only thing that matters.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/matrix-boards.jpg" alt="Unassembled matrix boards"></p><p>

Some time ago, I got access to a pick and place machine (a Charmhigh CHM-T36VA). I have it on semi-permanent loan. It's specifically for another project, which I will write up eventually, but my feelings on it can be summarised as follows: Robots are the Future. I've spent enough of my life manually assembling circuit boards that to have a machine that can build a board in seconds right in front of me is bliss.</p><p>

The one drawback to it is that loading the reels takes a long time. For each unique component you have to tediously load the reel, which can sometimes take the best part of 20 minutes. The circuit I borrowed the machine for has 26 unique components, so loading the reels was a full day of work.</p><p>

However. This LED matrix has precisely one component, and so loading the reels was as short as technically possible. Then we can crank out the boards at break-neck speed!</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/matrix-pnp.jpg" alt="Pick and place machine in action"></p><p>

I didn't get a proper stencil, I just laser-etched one in acetate. This project was still very much at the minimal-investment stage, where I'm just idly throwing ideas around. But a generic tiny LED matrix seemed like a worthwhile thing to have a handful of, it will almost certainly come in handy.</p><p>

I did some with 0603 and also some with 0805, as I had some of those already loaded. </p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/matrices.jpg" alt="Assembled matrix boards"></p><p>

If the circuit board design hadn't been a rush job, I'd have also made a circular PCB to support it at a right angle. The pads along the bottom were to solder directly between the boards. When I come to building the next version, that's what I'll do.</p><p>

For now I was playing with ideas. I knew that I wanted a microcontroller with a fair bit of flash memory on it, as we may want a fair bit of volumetric video data. The temptation was to go with a Pico, that's dual core 125MHz (or more) and up to 16MB flash (and importantly, it's cheap). One of the main drawbacks to the Pico is that it's a pain to use the bare RP2040 chip on its own. It has no onboard flash memory, so at the very least you need to wire up a QSPI flash chip, and almost always you'll need an external crystal and a fair amount of supporting caps. The Pico board on its own is far too large for our situation.</p><p>

However, a bunch of people have produced minimal RP2040 boards catering to exactly this sort of situation. Most of them were inappropriate, either too big or not breaking out enough of the GPIO. I found one that looks promising called the Waveshare RP2040-tiny. Here they've essentially cut the pico board in half, putting the bare minimum on the main board and having a secondary board, connected by a flat flex cable, with the USB port, reset and boot buttons.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/rp2040-tiny.jpg" alt="RP2040-tiny board"></p><p>

This seemed perfect for our prototype. It's still a little too big, and still doesn't break out all the GPIO, but we should be able to get by.</p><p>

As for the battery, I immediately grabbed a LIR2450. It's lithium-ion rechargeable, and can deliver well over 100mA. You can get smaller Li-ion batteries, but their capacity and current capability are much reduced. I also get a bit nervous having LIR2032 batteries lying around, as I feel like I'm going to accidently put one into something expecting a CR2032 (same physical dimensions) and possibly break it (LIR batteries are 4.2V fully charged). And besides, that RP2040 board is about 29mm diagonally, so going with a smaller battery isn't going to make the end result any smaller.</p><p>

I 3D-printed the most minimal holder for the battery in PETG.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/battery-holder.jpg" alt="Tiny holder for a LIR2450 battery"></p><p>

I was definitely too frugal here, printing with a wall thickness of 0.5mm. It's printed in two parts, with the top glued on. I think it would make more sense to thicken up all of the parts and print in one go at 90 degrees, which is something I played with later. This 3D printed part is definitely the weakpoint, every time I drop the prototype it breaks and I have to glue it back together.</p><p>

Anyway, we got as far as our first mockup:</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly1.jpg" alt="RP2040 board on top of the battery"></p><p>

That's a TCRT5000 IR sensor I've soldered on, with tiny surface mount resistors. The sensor is a little on the big side but it's all I had to hand. The output is analog, the detector is just a photodiode, but we can use a pullup and connect this straight to a GPIO pin. There are schmitt triggers on the inputs of the RP2040 (that can be disabled through software) so we essentially get a comparator for free.</p><p>

There's a WS2812 LED on the board, connected to GPIO16. I would much rather just have an extra GPIO pin for my matrix, so I snapped off the LED and soldered some enamel wire to it. I wasn't sure if it would be needed but now is the only chance we have to do this.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly2.jpg" alt="Wire soldered to GPIO16"></p><p>

I then started soldering our matrix. The idea with the tabs at the bottom of the matrix was to have slots in the board I connect it to, which would keep everything aligned. Instead, it seems they work well as little legs to keep the board just above the components. I soldered solid-core wire to the pads and wired it up so that everything would be very rigid at the end. It's possible to correct the angle between the boards, but it takes enough force that it won't happen by accident.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly3.jpg" alt="Matrix partly soldered into place"></p><p>

That's half the connections done, there's another ten wires to solder on the back, but before we do that I wanted to wire up the motor.</p><p>

I have a handful of motors approximately the right size. The one I opted for is labelled RF-410CA. Most of the similar motors from CD and DVD drives are all slightly different diameters and different shaft lengths. I also had a think about RPM. Most of these motors have a no-load speed of 5000 to 10000RPM, which is far too fast. We can PWM the speed down, but it also says something about their starting torque. To get to 30FPS, I'd need an RPM of 1800. It's quite hard to make decisions here, because as soon as it starts spinning there will be air-resistance and it will probably hit some equilibrium. Eh, if the motor's no good we can switch it out later.</p><p>

I deadbugged a little sot-23 mosfet and a flyback diode onto our creation.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly4.jpg" alt="Mosfet and diode soldered behind the matrix"></p><p>

The IR LED was wired straight to the power line. Ideally we'd have software control over it to save power while it isn't spinning, but for this prototype I didn't want to waste a GPIO on that. The matrix is 8x10, so 18 GPIO, plus one for the sensor input and one for the motor control, and I also wanted to keep one for monitoring the battery voltage. I think it's possible to wire up a couple more of the GPIO on the RP2040-tiny board which have been broken out as "user mode selection pads" but the current thought process was to not worry and get this to a working prototype as quick as possible.</p><p>

Notice I'm wiring the matrix directly to the GPIO pins. There's no current limiting or driver transistors. The RP2040 can source/sink about 50mA total across all its GPIO. I have learned that the risky, but oh-so-appealing way to drive LEDs from microcontrollers is to skip the current limiting resistors and drive them with PWM. The inherent on-resistance of the GPIO pin is enough to limit current – maybe not to a safe level for continuous illumination, but predictably. As long as you limit the duty cycle it's fine. Here we'll be flickering all of the matrix very quickly, with a lot of careful timing around it. I think it's unlikely we'll overdrive an LED, unless the chip crashes and the matrix freezes.</p><p>

I wired up the rest of the matrix using enamel wire, threading it underneath. We didn't need any further rigidity and it looks pretty cool this way.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly5.jpg" alt="Matrix wired up"></p><p>

There is something surprisingly appealing about the naked wires. It has a kind of cyberpunk vibe. The vibe was only enhanced when I powered up the matrix with a checkerboard test pattern for the first time.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/matrix-test.jpg" alt="Orange glow of the matrix test pattern"></p><p>

I glued our 3D printed battery holder onto the motor, and attached the rest of the prototype with squidgy 3M tape. I then had to shorten the wires to the motor and connect up the battery terminals.</p><p>

I wired the battery's positive terminal straight to VBUS of the board. The RP2040 is behind the 3.3V regulator, but with the battery connected this means that connecting the USB cable would put 5V across the battery terminals. We can worry about that later. For now I just want to know if the hacky prototype has any hope of working.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/assembly6.jpg" alt="Motor, battery and circuit all connected"></p><p>

Amusingly, once I configured it to light up the matrix in response to the IR photodiode, it would light up the matrix whenever the camera flash fired.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/prototype-without-battery.jpg" alt="Prototype with battery removed"></p><p>

With the battery removed you can see my connection to it, just some of the enamel wire stripped and tinned and threaded through a couple of small holes. At this point the battery snapped in with a positive action. It was only after it had been dropped a few times and the plastic cracked that I needed to use a rubber band to hold it in place.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/prototype-without-battery2.jpg" alt="Prototype with battery removed"></p><p>

I drilled a small hole at the back in order to be able to eject the battery, just poke it out with a pointy thing.</p><h3>Software</h3><p>
We monitor the IR sensor and use the time between triggers to set the speed of the matrix display. It's all the usual stuff for a persistence-of-vision display, except with another dimension.</p><p>

One thing I like about the RP2040 is that you can set (or input) every gpio pin in the same clock cycle. STM32 chips, despite having 32 bit processors, group the IO into 16-bit registers that suffer from bus contention if you try to change them all at once.</p><p>

Here we can pre-process everything we need to send to the GPIO and step through it at a speed proportional to the measured rotation.</p><p>

The processor is dual core ARM Cortex-M0. One thing to note is that both cores have separate SysTick hardware. Rather than do this with interrupts, we can use both cores in busy-wait loops. The first core monitors the IR sensor, and uses its systick to measure the exact number of cycles between triggers. The second core waits on the signal to illuminate, and once it gets it, steps through the volumetric buffer using its own systick timer for cycle-accuracy.</p><p>

In terms of motor control, I was reasonably confident we didn't need to do anything too complicated. It's important that the device spins at a constant speed to get a consistent framerate, but it should be fairly self-regulating. Paddle wheels were often used as regulators in old mechanical devices. I made the very simplest speed control logic possible: if the RPM is below 1200, set the motor to 90% power, else set it to 60% power.</p><p>

Later I might upgrade it to proper PID control but so far there's enough inertia and air resistance that the simple control seems totally fine.</p><p>

The first time I got this thing to spin I was giddy with excitement. Within moments I had it drawing a simple volumetric checkerboard pattern. Here's one of the very first tests:</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/first-test.jpg" alt="First illumination, on the messy desk"></p><p>

The plan was to machine a base for this device, with a little signpost that would stick up for the IR sensor to catch glimpses of. I realised it worked fine by just holding a finger near it, so never got around to that part. The motor had a very small pulley attached, which was just enough to let it spin up without falling over. I later laser-cut a disk of delrin, just a push-fit over the shaft, which was only supposed to be a stop-gap until I made something on the lathe.</p><p>

The code steps through the matrix in a columnwise fashion. Looking at the device top-down, each radial line is very slightly spiralled, but that's a lot easier to correct for (if we cared) than having the whole thing be a helix. The duty cycle on the LEDs in the centre is proportionally reduced compared to the periphery.</p><p>

I quickly got this thing displaying a static test volume. It was only a matter of time before I let it fall on the floor. The 3D print cracked along the glue line.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/cracked-open.jpg" alt="3D printed part cracked open"></p><p>

No worries, we can just keep gluing it back together. It's invincible!</p><h3>Battery Level</h3><p>
One thing that worried me is that we have no protection circuit for the battery. If it drops much below 3V it will get permanently damaged. (In practice the limit is more like 2.7V, but it depends on the cell. I've destroyed a few through this process.) Most lithium batteries have protection circuits built in, that will disconnect when it reaches a dangerously low level. Not so, with a bare cell. At the very least I wanted to monitor the battery voltage so we can alert and fail to run if we think it's too low.</p><p>

The normal way of monitoring supply voltage level is to add a potential divider to get it into a readable range of the ADC. The Pico boards I think normally have this wired to one of their GPIO, but not the RP2040-tiny. I added two 100K resistors to power and ground to our last available GPIO.</p><p>

The problem is, there's no reference voltage on the Pico. There's an external pin (not broken out on the RP2040-tiny) that can be used, but if the ADC reference is just its supply voltage, then when the supply voltage dips we won't be able to detect that. At least, not well.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/vbat2.png" alt="Schematic of VBat monitoring connection"></p><p>

The 3.3V LDO regulator has part number RT9193-33, and a dropout of 220mV at 300mA. That means when the battery voltage reaches 3.52V, our RP2040 supply voltage will start to droop as well. The ADC reading as a function of battery voltage will end up something like this:</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/vbat.png" alt="Plot of ADC reading vs battery voltage"></p><p>

Of course, the dropout voltage is a function of current load, so it isn't even as predictable as that. For this prototype, I made the device show a warning when it reaches just under 3.6V. That's the only thing we can really do here. For the next version, we'll add a reference voltage. It may even be possible to connect the ADC ref to the Pico's internal 1.8V regulator. That would be enough.</p><h3>Battery charger</h3><p>
The concept was to pop out the LIR2450 when it gets low and stick it into a standalone charger. I bought a standalone charger. It broke the very first time I used it.</p><p>

I was pretty pissed off that a brand new charger would let me down (it wasn't even the cheapest!). And this, at my most excited moment, ready to display more volumetric data! Woe is me!</p><p>

I 3D printed another battery holder, this time in the other plane. The spring tabs are technically flexing in the weakest direction, but they're generous enough and the wall thickness is all 1mm now.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/new-battery-holder.jpg" alt="New battery holder"></p><p>

I wasn't planning to use this for the display, this is just my new battery charger. I set the bench power supply to current limit of 50mA and constant voltage of 4.2V. This is enough to charge a single lithium-ion cell. The constant current is on the conservative side, I wasn't sure if this was a 120mAh battery or a 60mAh battery. It's best to charge no faster than about 1C unless the battery says otherwise. But it's generally never a problem to charge slower than 1C.</p><p>

This got me fired up again, and the volumetric journey continued. But before we resume the narrative, let me just add that removing the battery and connecting to a power supply is the least convenient way of charging the device, especially after the prototype cracked and I had to add that rubber band to stop the battery flying out.</p><p>

The RP2040-tiny USB adapter board was still being used to load code onto the chip. If we build a kind of USB-intercept board, we can lift the 5V line, and expose the pins for the battery. This sits between the USB cable from the PC to RP2040-tiny programming board.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/usb-adapter1.jpg" alt="USB intercept board"></p><p>

Now we can connect the power supply to the battery without removing it from the prototype. The data lines are still connected underneath, so we can program it with the battery in place as well.</p><p>

I realised that soldering this up was a waste of time as I could have simply put wires on the RP2040-tiny adapter board.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/rp2040-tiny-battery-adapt.jpg" alt="Power lines soldered to the RP2040-tiny adapter board"></p><p>

However in the mad frenzy induced by the working volumetric display, and the kicking of myself for only having one LIR2450 in stock, I found this still too inconvenient for rapid development. In a drawer somewhere, I had some lithium-ion charging ICs. It took me a moment to find them. These are quite nice quality ones, which cost about 90p each. The part number is BQ21040DBVR. I went back to that USB intercept board, and smashed the charging IC into the middle of it.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/usb-adapter2.jpg" alt="USB intercept with charging IC"></p><p>

With this, we can leave the programming cable connected and it will be charging the battery while we think.</p><p>

Of course, it won't ever fully charge the battery this way because the prototype never turns off. The IR LED alone is constantly drawing about 9mA. There was a very bright power LED on the RP2040-tiny adapter board, I swapped out the resistor to a 20K to stop it wasting power there. But still, I think even when the prototype isn't running it's drawing about 15mA overall. The charging IC, in the constant-voltage phase, will wait until the charging current drops to 0.1C. As our charging current is set to 54mA, that'll never happen. Also, with the voltage drop across the cable the battery probably won't get above 4.1V. None of this really matters, it's just stuff to keep in mind for the next version.</p><p>

At last we could start doing fluid simulations!</p><h3>Generating volumetric data</h3><p>
We need to create our volumetric data in 3D polar coordinates, that is, r, theta and z.</p><p>

I started with a wireframe cube, which should at least be somewhat recognisable. I deliberately rotated it to be on-end, to maximise the awkwardness of displaying it. Really I suppose we should write a vector display routine for the device, that would perform some kind of 3D polar coordinate Bresenham interpolation. There's plenty of info out there about applying Bresenham to 3D, and drawing circles, but we want to draw straight lines in polar coordinates. This sounds like a fun thing to think about but for now let's focus on exporting polar voxel data from Blender.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/blender1.jpg" alt="Wireframe cube in Blender"></p><p>

That's the default cube with a wireframe modifier. To rotate a cube to be on-end, with a corner facing directly upwards, we need to first rotate x by 45 degrees, then rotate y by <code>atan(1/sqrt(2))</code>. One of the lovely things about Blender is you can just type in formulas anywhere.</p><p>

To get slices of this wireframe cube, I added another cube, reshaped it to be somewhat slice-like, and did a boolean modifier between them. I then parented both the camera and this slice to an empty, and animated the empty's Z rotation. </p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/blender2.jpg" alt="Slice of the wireframe cube"></p><p>

I configured the camera projection to be orthographic, and its resolution to be our tiny 8x10. I set the background to black and the cube's material to emissive. In the compositor, we can use a colour ramp to threshold this. The volumetric display currently has only a bit-depth of 1, so each voxel is just on or off. Thresholding it here lets us visually pick the best cutoff.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/blender-compositor.jpg" alt="Screenshot of compositor"></p><p>

"Render animation" now generates 24 images, 24 slices of the wireframe cube. I used a quick python script to chew those up into a header file that can be included in the code.</p><p>

In Blender, not only can any input accept a formula, and not only can virtually all of them can be keyframed, you can also set up a driver. Rather than resolve the formula as you enter it, it will recalculate the result for each frame. So instead of keyframing the rotation of the camera and manually setting it to linear interpolation, I just typed in <code>(frame/24)*2*pi</code> which will loop indefinitely. For the y-rotation of the cube, I now typed in <code>floor(frame/24)*pi/24</code> so it will rotate a fraction for each full loop of the camera.</p><p>

<video src="https://mitxela.com/img/uploads/blinken/candle/cube-rotate.webm" controls="" loop="" width="960" height="540">Sorry, your browser does not support .webm videos</video></p><p>

Honestly it would have been fine for the rotation to be continuous, but I wanted each frame of data to be discrete, just in case we wanted to adjust playback speed based on motor RPM.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/spinning1.jpg" alt="Volumetric display of the rotating cube"></p><p>

You'll simply have to take my word for it that the display seems a lot more three-dimensional in real life. Looking at the pictures and watching the video it does seem just like a bunch of random dots illuminated. If only you, dear reader, had a volumetric display to experience it on!</p><h3>Fluid simulations</h3><p>
Running a fluid simulation in Blender is both easy and difficult. Easy to get started, difficult to get just right. There are an awful lot of parameters involved.</p><p>

Liquid simulation is slightly easier to port to the volumetric display as it's trivial to convert the fluid particles to a mesh. In theory, we should be able to run a fluid simulation at 1/24th speed, and use the same technique as above to extract polar volumetric data.</p><p>

Unfortunately using extreme parameters like a very slow time scale leads to instabilities. There doesn't seem to be a straightforward way to play back a simulation at a slower rate, and the very slow simulation speed looks entirely wrong when sped up. I did fiddle around with this for a while with no luck. On the plus side, we're targeting a very low spatial resolution, so the fluid simulations are all fast enough to run in real-time on my desktop machine.</p><p>

I looked into other ways to render the volumetric data. There's a feature known as Multi-view, or Stereoscopy, that's intended for rendering 3D video. This lets you add two cameras and render a scene from both perspectives simultaneously. It's possible to add any number of cameras, and output all of them based on their naming suffix. I'm not sure if there's a quick way to add 24 cameras and evenly rotate them (sadly you can't apply an array modifier to a camera, I'm not sure if anyone has ever asked for that before) but a further problem with this tactic is that we also need the boolean modifiers of our slices to be rendered at the same time.</p><p>

Instead of the boolean modifier and a slice, we could cheat a little and use the built-in clipping distances. By setting the camera to only render a 0.1 slice of the scene we get almost the right output. The problem is that only surfaces are drawn, not solid fill for the clipped objects. I thought that maybe applying volumetric material to the objects could make them at least partially filled, but after playing about for a bit I had no luck.</p><p>

Instead, let's go for a more generic (but more involved) approach: just write a python script. In the scripting tab in blender, I wrote the following:</p><pre>import bpy
import os
from math import pi
 
obj = bpy.data.objects['Empty']
output_path = bpy.context.scene.render.filepath
 
for i in range(24):
  obj.rotation_euler[2] = (i/24)*2*pi
  bpy.context.scene.render.filepath = os.path.join(output_path, f"###_{i:02}.png")
  bpy.ops.render.render(animation=True)
 
bpy.context.scene.render.filepath = output_path
</pre><p>

This way we run the fluid simulation in real time, and simply re-render the whole animation 24 times with different rotations of the Empty (parent to the camera and the slice).</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/fluid-render-slice.jpg" alt="Screenshot of a single fluid slice render"></p><p>

The concept proven, I ploughed ahead with the fire simulation. The way to render this is basically the same but with a couple more steps. We set up our fire simulation, and then bake it in OpenVDB format. Here I set a small cube on fire.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/fire-simulation.jpg" alt="Fire simulation"></p><p>

Then start over, and import the OpenVDB data back into Blender. We can then create a new mesh and apply a Volume to Mesh modifier on it, which lets us threshold the volume data. Finally, another boolean modifier with our camera slice, and re-run the script above.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/fire-sim-display.jpg" alt="Fire simulation on the display"></p><p>

Again, I feel the photograph doesn't really capture the feeling here, but you hopefully get the idea.</p><p>

It occurs to me that the LED alignment could be corrected for in software, if it were predictable. We could offset the boolean slice either closer or further away from the camera, so that it doesn't spin around the exact centre. If it matched the movement of the real display we should be golden. Similarly, instead of a stretched cube, we could make it a slightly curved shape to compensate for the matrix scanning pattern as the board rotates. At this level of resolution however, I don't think any of these improvements would be visible.</p><p>

The only thing that really matters is that illuminating an individual voxel near the perimeter should look like a single dot, not a double dot from some angles. You can see it in the image below, where the voxel nearest the camera is elongated because the two illuminations as the matrix rotates didn't quite line up:</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/display-text.jpg" alt="Display showing text"></p><p>

The letter "m" in the centre is perfectly clear, because I deliberately cheated there. To make the text readable from all directions, the text voxels are rendered differently. I made it so the text scrolls in the readable orientation regardless of if you're looking at the front or back of the display. Anyway this voxel discrepancy can only really be noticed on the periphery of the display, where both illuminations are visible at once.</p><h3>Conclusion, for now</h3><p>
There is plenty of work to do on my fire simulation, but perhaps I'll delay a little until I crank out the next prototype which might be a little better aligned and a little higher-resolution.</p><p>

If I had a tiny slide-switch in stock, I would have added it to this prototype, to disconnect the battery without removing it. I started searching my boxes for something suitable before realising I could simply insert a small piece of acetate between the battery and the contact, like they do with coin cells for IR remotes and so on. That works fine.</p><p>

On the subject of IR remotes, it would be quite nice to have a remote control for this. We already have an IR sensor, although it's not a demodulating type. As shown in the video, I simply advance to the next mode after a timeout of no activity.</p><p>

Here are some vanity shots of the device.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/final3.jpg" alt="Vanity shot of prototype"></p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/final1.jpg" alt="Vanity shot of prototype"></p><p>

The IR is of course totally invisible to the naked eye, but the digital camera picks it up as a faint purple glow.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/candle/final2.jpg" alt="Vanity shot with IR sensor facing camera"></p><nav>
<a href="https://mitxela.com/projects/random" title="random project">~</a>
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/">mitxela.com</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects">Projects</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/hardware">Hardware</a></span> »
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/candle">POV Candle</a></span>
<p>Questions? Comments? Check out the <a href="https://mitxela.com/forum">Forum</a>
</p><p><a href="https://mitxela.com/support">Support mitxela.com</a>
</p></nav></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No new boss at NSA until it answers questions on buying location, browsing data (322 pts)]]></title>
            <link>https://www.theregister.com/2023/12/02/nsa_held_hostage/</link>
            <guid>38498090</guid>
            <pubDate>Sat, 02 Dec 2023 12:18:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/12/02/nsa_held_hostage/">https://www.theregister.com/2023/12/02/nsa_held_hostage/</a>, See on <a href="https://news.ycombinator.com/item?id=38498090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Is the NSA buying up Americans' location and browsing data? Senator Ron Wyden (D-OR) is tired of asking and has now moved to block the confirmation of a new NSA director until he gets answers.</p>
<p>"The American people have a right to know whether the NSA is conducting warrantless domestic surveillance of Americans in a manner that circumvents the Fourth Amendment to the Constitution," Wyden said in a <a target="_blank" rel="nofollow" href="https://www.wyden.senate.gov/news/press-releases/wyden-nsa-must-answer-whether-it-is-buying-americans-location-data-and-web-browsing-records-before-new-director-is-confirmed">statement</a> on Thursday submitted to the congressional record.</p>
<p>"Particularly as Congress is currently debating extending Section 702 of the Foreign Intelligence Surveillance Act, Congress must be able to have an informed public debate about the scope of the NSA's warrantless surveillance of Americans."</p>

    

<p>As we've previously <a target="_blank" href="https://www.theregister.com/2023/07/21/us_police_data_broker_info/">reported</a>, plenty of personal information is available for purchase from commercial data brokers by US government agencies without a warrant. The Fourth Amendment provides Americans safeguards from unreasonable search and seizures - a protection some, including Senator Wyden, would argue the Feds (and cops to that matter) violate if or when they acquire this info without a warrant.</p>
<blockquote>

<p>Congress must be able to have an informed public debate about the scope of the NSA's warrantless surveillance of Americans</p>
</blockquote>
<p>These data brokers harvest personal data from all sorts of places, mainly apps <a target="_blank" rel="nofollow" href="https://www.eff.org/issues/location-data-brokers">reselling</a> your location and other info, and then bundle it up and peddle to interested parties.</p>
<p>Wyden said he was told by Uncle Sam's Defense Intelligence Agency that it, for one, was purchasing American citizens' location data, and he made that point public in early 2021. He said he further pressed the Pentagon for the names of other military agencies buying records of people's whereabouts, browsing histories, and other personal matters, and in March that year got the answers he wanted – but the disclosure was marked "controlled unclassified information" (<a target="_blank" rel="nofollow" href="https://www.dcsa.mil/Industrial-Security/Controlled-Unclassified-Information-CUI/">CUI</a>). The senator took that to mean he couldn't share it.</p>

        


        

<p>CUI is not classified information, as its name indicates, but it should, generally speaking, be protected with access controls and not widely disseminated. Wyden is clearly not a fan of this labeling, which he described as a "made up designation with no basis in law." CUI was created by an <a target="_blank" rel="nofollow" href="https://www.federalregister.gov/documents/2010/11/09/2010-28360/controlled-unclassified-information">executive order</a> from President Obama in 2010.</p>
<p>"The administration is abusing the CUI designation to keep this unclassified information from the American public," Wyden continued.</p>

        

<p>So now the senator has placed a hold on Lieutenant General Timothy Haugh's confirmation as NSA director until the spying nerve-center confirms or denies (presumably under an unclassified designation) that it is buying up citizens' location data and/or browser histories without a warrant. The senator wants a simple yes or no.</p>
<p>This won't guarantee answers, however. It does mean the NSA will either need to satisfy Wyden's request, or Congress will need to hold a procedural vote to push through the confirmation.</p>
<ul>

<li><a href="https://www.theregister.com/2023/11/22/wyden_hemisphere_letter/">US govt pays AT&amp;T to let cops search Americans' phone records – 'usually' without a warrant</a></li>

<li><a href="https://www.theregister.com/2023/11/08/section_702_reform_legislation/">Uncle Sam snooping on US folks? Not without a warrant, lawmakers agree</a></li>

<li><a href="https://www.theregister.com/2023/12/01/traveler_privacy_protection_act/">Senate bill aims to stop Uncle Sam using facial recognition at airports</a></li>

<li><a href="https://www.theregister.com/2023/12/01/trickbot_dev_guilty_plea/">US readies prison cell for another Russian Trickbot developer</a></li>
</ul>
<p>In his statement Wyden makes clear his objections to Haugh's promotion to the rank of general and nomination to the NSA directorship aren't personal nor related to his qualifications. The congressman simply wants Uncle Sam to open up a little.</p>
<p>Senator Wyden isn't the only one who's run into opposition trying to obtain more information on US domestic intelligence gathering efforts. The Electronic Frontier Foundation has filed freedom of information act requests and lawsuits to get this evidence.</p>
<p>Wyden's latest effort comes as Congress weighs up the future of FISA Section 702, which is due to expire at the end of this year unless it's reauthorized, and in certain circumstances allows government snoops to analyze US persons' private communications without a warrant. While lawmakers are likely to renew the controversial intelligence tool, many on both sides of the aisle would like to see additional safeguards added.</p>

        

<p>One <a target="_blank" href="https://www.theregister.com/2023/11/08/section_702_reform_legislation/">proposed</a> reauthorization bill, which has already received pushback from the White House, includes several surveillance reforms, including one requiring warrants for government purchases of private information from data brokers. A rival and much more spy-friendly bill has also <a target="_blank" href="https://www.theregister.com/2023/11/29/section_702_reauthorization_bill/">been introduced</a>. ®</p>                                
                    </div></div>]]></description>
        </item>
    </channel>
</rss>