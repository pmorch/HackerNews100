<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 10 Apr 2024 19:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Kobo announces color e-readers (164 pts)]]></title>
            <link>https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink</link>
            <guid>39991693</guid>
            <pubDate>Wed, 10 Apr 2024 15:18:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink">https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink</a>, See on <a href="https://news.ycombinator.com/item?id=39991693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Rakuten Kobo is launching its first color e-readers, the <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fus.kobobooks.com%2Fproducts%2Fkobo-libra-colour">Kobo Libra Colour</a> and the <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fus.kobobooks.com%2Fcollections%2Fereaders%2Fproducts%2Fkobo-clara-colour">Kobo Clara Colour</a>. Both use E Ink‚Äôs latest Kaledio color screen technology, which has subtle, pastel-like hues and drops from a 300ppi grayscale resolution to 150ppi when you view content in color.</p><p>I‚Äôll be testing both e-readers soon, but so far, they look like small upgrades to Kobo‚Äôs existing e-readers. That‚Äôs not a bad thing, though! The seven-inch Kobo Libra 2 is <a href="https://www.theverge.com/23769068/best-ebook-readers">my favorite e-reader</a> outside of Amazon‚Äôs ecosystem, offering the <a href="https://www.theverge.com/22745670/amazon-kindle-paperwhite-2021-review-usb-c-signature-edition-display-e-reader-books">Kindle Paperwhite‚Äôs</a> IPX8 waterproof design but with extras like physical page-turning buttons, no lockscreen ads, and more storage. </p><div><div><div role="button" aria-label="Zoom" tabindex="0"><p><span><span></span><img alt="The Kobo Libra Colour comes with physical page-turning buttons and is compatible with the Kobo Stylus 2 for taking notes." loading="lazy" decoding="async" data-nimg="responsive" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 350px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/256x256/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/376x376/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/384x384/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/415x415/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/480x480/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/540x540/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/640x640/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/750x750/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/828x828/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1080x1080/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1200x1200/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1440x1440/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1920x1920/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2048x2048/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><div><figcaption><em>The Kobo Libra Colour comes with physical page-turning buttons and is compatible with the Kobo Stylus 2 for taking notes.</em></figcaption> <p><cite>Image: Rakuten Kobo</cite></p></div></div><div><div role="button" aria-label="Zoom" tabindex="0"><p><span><span></span><img alt="The Kobo Clara Colour is just like the Clara 2E but with color, an improved processor, and more storage." loading="lazy" decoding="async" data-nimg="responsive" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 350px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/256x256/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/376x376/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/384x384/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/415x415/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/480x480/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/540x540/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/640x640/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/750x750/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/828x828/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1080x1080/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1200x1200/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1440x1440/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1920x1920/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2048x2048/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><div><figcaption><em>The Kobo Clara Colour is just like the Clara 2E but with color, an improved processor, and more storage.</em></figcaption> <p><cite>Image: Rakuten Kobo</cite></p></div></div></div><p>The $219.99 Kobo Libra Colour retains all of those features but is also now compatible with the <a href="https://help.kobo.com/hc/en-us/articles/10733885674391-About-Kobo-Stylus-2#:~:text=Note%3A%20Kobo%20Stylus%202%20only,Elipsa%2C%20and%20Kobo%20Elipsa%202E.">Kobo Stylus 2</a>, just like the <a href="https://www.theverge.com/2023/4/5/23669572/kobo-elipsa-2e-e-reader-tablet-kindle-scribe-onyx-remarkable">Kobo Elipsa 2E</a>. However, it‚Äôs $30 more expensive than the Kobo Libra 2, and you‚Äôll have to buy the stylus separately for $69.99. </p><p>The $149.99 Kobo Clara Colour is slightly more distinct from its closest sibling, the $139.99 <a href="https://www.theverge.com/23542918/kobo-clara-2e-ereader-review-amazon-kindle">Kobo Clara 2E</a>. It offers the same six-inch display and IPX8 waterproof design but now comes with 16GB of storage, as well as an improved processor. I hope so; the Kobo Clara 2E‚Äôs sluggish performance was one of my chief complaints.</p><p>Kobo also introduced an upgraded black-and-white Kobo Clara BW, with the same storage and processor upgrades, for $129.99.</p><p>All of the devices are available to preorder starting today and will ship on April 30th. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta MTIA v2 ‚Äì Meta Training and Inference Accelerator (122 pts)]]></title>
            <link>https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/</link>
            <guid>39991675</guid>
            <pubDate>Wed, 10 Apr 2024 15:16:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/">https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/</a>, See on <a href="https://news.ycombinator.com/item?id=39991675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="u_0_a_Cw"><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.8562-6/341873634_933206851214321_6656088855482877648_n.svg?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=mGUHpaVA17EAb65o-qY&amp;_nc_ht=scontent.fzrh3-1.fna&amp;oh=00_AfBv4J_M2o8wil-9g4XTkhIXsd0XdjTBo_RbqYXE-3H1aw&amp;oe=661C9BF7" height="30" width="109" alt="Featured label"></p><p>Our next-generation Meta Training and Inference Accelerator</p><p>April 10, 2024 ¬∑ 8 min read</p></div><div><div><p>The next generation of Meta‚Äôs large-scale infrastructure is <a href="https://about.fb.com/news/2023/05/metas-infrastructure-for-ai/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;blog_newsroom-reimagine&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_h_bf">being built with AI in mind</a>, including supporting new generative AI (GenAI) products and services, recommendation systems, and advanced AI research. It‚Äôs an investment <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;blog_engineering-building&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_i_sa">we expect will grow</a> in the years ahead as the compute requirements to support AI models increase alongside the models‚Äô sophistication.</p><p>Last year, we unveiled the <a href="https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_internal-link&quot;,&quot;creative_detail&quot;:&quot;blog_ai-mtiav1-intro&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_j_5/">Meta Training and Inference Accelerator (MTIA) v1</a>, our first-generation AI inference accelerator that we designed in-house with Meta‚Äôs AI workloads in mind ‚Äì specifically our deep learning recommendation models that are improving a variety of experiences across our products.</p><p>MTIA is a long-term venture to provide the most efficient architecture for Meta‚Äôs unique workloads. As AI workloads become increasingly important to our products and services, this efficiency will improve our ability to provide the best experiences for our users around the world. MTIA v1 was an important step in improving the compute efficiency of our infrastructure and better supporting our software developers as they build AI models that will facilitate new and better user experiences.</p><p>Now, we‚Äôre sharing details about the next generation of MTIA.</p></div><div><p> Next generation MTIA chip model. Drag to rotate.<br></p></div><p>This inference accelerator is part of our broader full-stack development program for custom, domain-specific silicon that addresses our unique workloads and systems. This new version of MTIA more than doubles the compute and memory bandwidth of our previous solution while maintaining our close tie-in to our workloads. It is designed to efficiently serve the ranking and recommendation models that provide high-quality recommendations to users.</p></div><div id="u_0_l_LC"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Close up photograph of a hand holding a chip" id="u_0_m_uf"></p></div><div><div><h2> Under the hood<br></h2><p>This chip‚Äôs architecture is fundamentally focused on providing the right balance of compute, memory bandwidth, and memory capacity for serving ranking and recommendation models. In inference we need to be able to provide relatively high utilization, even when our batch sizes are relatively low. By focusing on providing outsized SRAM capacity, relative to typical GPUs, we can provide high utilization in cases where batch sizes are limited and provide enough compute when we experience larger amounts of potential concurrent work.</p></div><div><p>This accelerator consists of an 8x8 grid of processing elements (PEs). These PEs provide significantly increased dense compute performance (3.5x over MTIA v1) and sparse compute performance (7x improvement). This comes partly from improvements in the architecture associated with pipelining of sparse compute. It also comes from how we feed the PE grid: We have tripled the size of the local PE storage, doubled the on-chip SRAM and increased its bandwidth by 3.5X, and doubled the capacity of LPDDR5.</p></div><div><p>Our new MTIA design also features an improved network on chip (NoC) architecture that doubles the bandwidth and allows us to coordinate between different PEs at low latency. These and other new functions in the PEs form the key technologies that are vital to our long-term roadmap to scale MTIA to a wider variety of more challenging workloads.</p></div></div><div><div><div><h2>The hardware</h2><p>Serving our workloads effectively is not simply a silicon challenge. Co-designing the hardware system and the software stack along with the silicon is essential for the success of the overall inference solution.</p></div><div><p>To support the next-generation silicon we have developed a large, rack-based system that holds up to 72 accelerators. This consists of three chassis, each containing 12 boards that house two accelerators each. We specifically designed the system so that we could clock the chip at 1.35GHz (up from 800 MHz) and run it at 90 watts compared to 25 watts for our first-generation design. Our design ensures we provide denser capabilities with higher compute, memory bandwidth, and memory capacity. This density allows us to more easily accommodate a broad range of model complexities and sizes.</p></div></div><div><div id="u_0_x_hb"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Photograph of a person placing a motherboard into a server"></p></div><div id="u_0_y_g2"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Photograph of a server rack with wires and chips"></p></div></div><div><p>Beyond this, we have upgraded the fabric between the accelerators and between the host and accelerators to PCIe Gen5 to increase the bandwidth and scalability of our system. There is also the option to add an RDMA NIC if we choose to scale out beyond the rack.</p></div></div><div><div><h2>The software stack</h2><p>Software has been one of our key areas of focus from the start of our investment in MTIA. <a href="https://ai.meta.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_internal-link&quot;,&quot;creative_detail&quot;:&quot;blog_ai-pytorch-builds&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_z_p9">As the initial developers of PyTorch</a>, we value programmability and developer efficiency. Our MTIA stack is designed to fully integrate with PyTorch 2.0 and features like TorchDynamo and TorchInductor. Frontend graph-level capturing, analysis, transformation, and extraction mechanisms (such as TorchDynamo, torch.export, etc.) are agnostic to MTIA and are being reused The lower level compiler for MTIA takes the outputs from the frontend and produces highly efficient and device-specific code. This lower level compiler itself consists of a few components that are responsible for generating executable code for models and kernels.</p></div><div id="u_0_10_xe"><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.8562-6/434734036_1552580315589962_4953415076977263638_n.jpg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=_BJ5OdmLZfIAb5B55YB&amp;_nc_ht=scontent.fzrh3-1.fna&amp;oh=00_AfAZ86-X42WMruek_42kZa0zrA2Ffc8TmgNIIxQ34Iha3w&amp;oe=661C95E6" alt=""></p></div><div><div><p>Below this sits the runtime stack responsible for interfacing with the driver/firmware. The MTIA Streaming interface abstraction provides the basic and essential operations that both inference and (in the future) training software require to manage the device memory, as well as run operators and execute compiled graphs on the device. Finally, the runtime interacts with the driver, which sits in user space ‚Äì a decision we made to enable us to iterate faster on the driver and firmware within our production stack.</p><p>In many ways this new chip system runs the software stack similarly to MTIA v1, which made it much faster for the team to deploy since we had already done much of the necessary integration and development work needed to be able to run our applications on this architecture. The new MTIA is designed to be compatible with code developed for MTIA v1. Since we had already integrated the full software stack to the silicon, we were up and running our traffic with this new chip in a matter of days. This allowed us to land this next-generation MTIA silicon rapidly, going from first silicon to production models running in 16 regions in less than nine months.</p></div><h3> Triton-MTIA<br></h3><div><p>We‚Äôve further optimized the software stack by creating the Triton-MTIA compiler backend to generate high-performance code for the MTIA hardware. <a href="https://github.com/openai/triton" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;github_triton&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_11_hC">Triton</a> is an open source language and compiler for writing highly efficient ML compute kernels. It improves developer productivity for writing GPU code and we have found that the Triton language is sufficiently hardware-agnostic to be applicable to non-GPU hardware architectures like MTIA.</p><p>The Triton-MTIA backend performs optimizations to maximize hardware utilization and support high-performance kernels. It also exposes key knobs to leverage Triton and MTIA auto-tuning infrastructures to explore the kernel configuration and optimization space.</p><p>We have implemented support for the features of the Triton language and integration into PyTorch 2, providing extensive coverage for PyTorch operators. Thanks to TorchInductor, for example, our developers can leverage Triton-MTIA in both ahead-of-time (AOT) and just-in-time (JIT) workflows.</p><p>We observed dramatically improved developer efficiency with Triton-MTIA, which allowed us to scale up compute kernel authoring and significantly expand the support of PyTorch operators.</p></div></div></div><div><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Dark Meta gradient" id="u_0_12_Q7"></p><div><h2>Performance Results</h2><p>The results so far show that this MTIA chip can handle both the low complexity (LC) and high complexity (HC) ranking and recommendation models that are components of Meta‚Äôs products. Across these models, there can be a ~10x-100x difference in model size and the amount of compute per input sample. Because we control the whole stack, we can achieve greater efficiency compared to commercially available GPUs. Realizing these gains is an ongoing effort and we continue to improve performance per watt as we build up and deploy MTIA chips in our systems.</p><div><p>Early results show that this next generation silicon has already improved performance by 3x over our first generation chip across four key models we evaluated. At the platform level, with 2x the number of devices and a powerful 2-socket CPU, we are able to achieve 6x model serving throughput and a 1.5x performance per watt improvement over the first generation MTIA system. To achieve this, we have made significant progress optimizing kernels, compiler, runtime, and host serving stack. The time to optimize models is going down as the developer ecosystem matures, yet there is more headroom to improve efficiency in the future. </p><div><p>3x</p><p>improved performance over our first gen chip</p></div></div><p>MTIA has been deployed in the data center and is now serving models in production. We are already seeing the positive results of this program as it's allowing us to dedicate and invest in more compute power for our more intensive AI workloads. It is proving to be highly complementary to commercially available GPUs in delivering the optimal mix of performance and efficiency on Meta-specific workloads.</p></div></div><div><h2>Meta‚Äôs ongoing investment in custom silicon</h2><div><p>MTIA will be an important piece of our long-term roadmap to build and scale the most powerful and efficient infrastructure possible for Meta‚Äôs unique AI workloads.</p><p>We‚Äôre designing our custom silicon to work in cooperation with our existing infrastructure as well as with new, more advanced hardware (including next-generation GPUs) that we may leverage in the future. Meeting our ambitions for our custom silicon means investing not only in compute silicon but also in memory bandwidth, networking and capacity as well as other next-generation hardware systems.</p><p>We currently have several programs underway aimed at expanding the scope of MTIA, including support for GenAI workloads.</p><p>We‚Äôre only at the beginning of this journey, and we‚Äôre inviting people who want to be a part of it to visit <a href="https://www.metacareers.com/innovation" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;careers_innovation-open-roles&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_14_H+">Meta Careers</a> to learn about our open positions.</p></div></div><div><h4>Written by:</h4><h4>Eran Tal, Nicolaas Viljoen and Joel Coburn</h4></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter's pivot to x.com is a gift to phishers (304 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/</link>
            <guid>39991173</guid>
            <pubDate>Wed, 10 Apr 2024 14:35:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/">https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/</a>, See on <a href="https://news.ycombinator.com/item?id=39991173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>On April 9, Twitter/X began automatically modifying links that mention ‚Äútwitter.com‚Äù to read ‚Äúx.com‚Äù instead. But over the past 48 hours, dozens of new domain names have been registered that demonstrate how this change could be used to craft convincing phishing links ‚Äî such as <strong>fedetwitter[.]com</strong>, which until very recently rendered as <strong>fedex.com</strong> in tweets.</p>
<div id="attachment_67139"><p><img aria-describedby="caption-attachment-67139" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2024/04/ruseriousx.png" alt="" width="652" height="698"></p><p id="caption-attachment-67139">The message displayed when one visits carfatwitter.com, which Twitter/X displayed as carfax.com in tweets and messages.</p></div>
<p>A search at <a href="https://www.domaintools.com/" target="_blank" rel="noopener">DomainTools.com</a> shows at least 60 domain names have been registered over the past two days for domains ending in ‚Äútwitter.com,‚Äù although research so far shows the majority of these domains have been registered ‚Äúdefensively‚Äù by private individuals to prevent the domains from being purchased by scammers.</p>
<p>Those include <strong>carfatwitter.com</strong>, which Twitter/X truncated to carfax.com when the domain appeared in user messages or tweets. Visiting this domain currently displays a message that begins, ‚ÄúAre you serious, X Corp?‚Äù</p>
<p><strong>Update:</strong> It appears Twitter/X has corrected its mistake, and no longer truncates any domain ending in ‚Äútwitter.com‚Äù to ‚Äúx.com.‚Äù</p>
<p><em>Original story:</em></p>
<p>The same message is on other newly registered domains, including <strong>goodrtwitter.com</strong> (goodrx.com), <strong>neobutwitter.com</strong> (neobux.com), <strong>roblotwitter.com</strong> (roblox.com), <strong>square-enitwitter.com</strong> (square-enix.com) and yandetwitter.com (yandex.com). The message left on these domains indicates they were defensively registered by <a href="https://compostintraining.club/@prplecake" target="_blank" rel="noopener">a user on Mastodon</a> whose bio says they are a systems admin/engineer. That profile has not responded to requests for comment.</p>
<p>A number of these new domains including ‚Äútwitter.com‚Äù appear to be registered defensively by Twitter/X users in Japan. The domain netflitwitter.com (netflix.com, to Twitter/X users) now displays a message saying it was ‚Äúacquired to prevent its use for malicious purposes,‚Äù along with a Twitter/X username.</p>
<p>The domain mentioned at the beginning of this story ‚Äî fedetwitter.com ‚Äî redirects users to the blog of a Japanese technology enthusiast. A user with the handle ‚Äúamplest0e‚Äù appears to have registered <strong>space-twitter.com</strong>, which Twitter/X users would see as the CEO‚Äôs ‚Äúspace-x.com.‚Äù The domain ‚Äúametwitter.com‚Äù already redirects to the real americanexpress.com.<span id="more-67137"></span></p>
<p>Some of the domains registered recently and ending in ‚Äútwitter.com‚Äù currently do not resolve and contain no useful contact information in their registration records. Those include <strong>firefotwitter[.]com</strong> (firefox.com), <strong>ngintwitter[.]com</strong> (nginx.com), and <strong>webetwitter[.]com</strong> (webex.com).</p>
<div id="attachment_67144"><p><img aria-describedby="caption-attachment-67144" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter.png" alt="" width="750" height="491" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter.png 1299w, https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter-768x503.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter-782x512.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-67144">The domain setwitter.com, which Twitter/X until very recently rendered as ‚Äúsex.com,‚Äù redirects to this blog post warning about the recent changes and their potential use for phishing.</p></div>
<p><strong>Sean McNee</strong>, vice president of research and data at DomainTools, told KrebsOnSecurity it appears Twitter/X did not properly limit its redirection efforts.</p>
<p>‚ÄúBad actors could register domains as a way to divert traffic from legitimate sites or brands given the opportunity ‚Äî many such brands in the top million domains end in x, such as webex, hbomax, xerox, xbox, and more,‚Äù McNee said. ‚ÄúIt is also notable that several other globally popular brands, such as Rolex and Linux, were also on the list of registered domains.‚Äù</p>
<p>The apparent oversight by Twitter/X was cause for amusement and amazement from many former users who have migrated to other social media platforms since the new CEO took over. <strong>Matthew Garrett</strong>, a lecturer at U.C. Berkeley‚Äôs School of Information, <a href="https://infosec.exchange/@mjg59@nondeterministic.computer/112243298637438787" target="_blank" rel="noopener">summed up</a> the Schadenfreude thusly:</p>
<p>‚ÄúTwitter just doing a ‚Äòredirect links in tweets that go to x.com to twitter.com instead but accidentally do so for all domains that end x.com like eg spacex.com going to spacetwitter.com‚Äô is not absolutely the funniest thing I could imagine but it‚Äôs high up there.‚Äù</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ADS-B visualizer (150 pts)]]></title>
            <link>https://adsb.exposed/</link>
            <guid>39990346</guid>
            <pubDate>Wed, 10 Apr 2024 13:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adsb.exposed/">https://adsb.exposed/</a>, See on <a href="https://news.ycombinator.com/item?id=39990346">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>Examples:
        <span>Altitude &amp; Velocity</span>
        <span>Boeing vs. Airbus</span>
        <span>Helicopters</span>
        <span>Hi-Performance</span>
        <span>Light</span>
        <span>Gliders</span>
        <span>Ultralight</span>
        <span>Military</span>
        <span>Vertical Speed</span>
        <span>Roll Angle</span>
        <span>Steep</span>
        <span>Year</span>
        <span>A380</span>
        <span>IL-76</span>
        <span>F-16</span>
        <span>KLM</span>
        <span>N2163J</span>
        <span>Event Time</span>
        <span>Weekends</span>
        <span>Emergency</span>
        <span>Balloons</span>
        <span>Ground Vehicles</span>
        <span>Elon Musk</span>
        <span>All Airlines</span>
    </p>
    
    
    
    <p><span id="picture-copyright">Picture from Wikipedia, ¬© the details at the corresponding page.</span></p>
    
    <p>üëÅ</p>
    <p><img src="https://adsb.exposed/pointer.svg"></p>

    <p id="provider">
        <form>
            <label>
                
                Race
            </label>
            <br>
            <label>
                
                Cloud
            </label>
            <br>
            <label>
                
                Self-hosted (Intel)
            </label>
            <br>
            <label>
                
                Self-hosted (Graviton)
            </label>
        </form>
    </p>

    
    
    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[2023 ACM Turing Prize awarded to Avi Wigderson (148 pts)]]></title>
            <link>https://awards.acm.org/about/2023-turing</link>
            <guid>39990004</guid>
            <pubDate>Wed, 10 Apr 2024 12:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://awards.acm.org/about/2023-turing">https://awards.acm.org/about/2023-turing</a>, See on <a href="https://news.ycombinator.com/item?id=39990004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>ACM has named <a href="https://awards.acm.org/award-recipients/wigderson_3844537">Avi Wigderson</a> as recipient of the 2023 ACM A.M. Turing Award for foundational contributions to the theory of computation, including reshaping our understanding of the role of randomness in computation, and for his decades of intellectual leadership in theoretical computer science.</p>
<p>Wigderson is the Herbert H. Maass Professor in the School of Mathematics at the Institute for Advanced Study in Princeton, New Jersey. He has been a leading figure in areas including computational complexity theory, algorithms and optimization, randomness and cryptography, parallel and distributed computation, combinatorics, and graph theory, as well as connections between theoretical computer science and mathematics and science.</p>
<p>The ACM A.M. Turing Award, often referred to as the ‚ÄúNobel Prize of Computing,‚Äù carries a $1 million prize with financial support provided by Google, Inc. The award is named for Alan M. Turing, the British mathematician who articulated the mathematical foundations of computing.</p>
<p><u>What is Theoretical Computer Science?</u></p>
<p>Theoretical computer science is concerned with the mathematical underpinnings of the field. It poses questions such as ‚ÄúIs this problem solvable through computation?‚Äù or ‚ÄúIf this problem is solvable through computation, how much time and other resources will be required?‚Äù</p>
<p>Theoretical computer science also explores the design of efficient algorithms. Every computing technology that touches our lives is made possible by algorithms. Understanding the principles that make for powerful and efficient algorithms deepens our understanding not only of computer science, but also the laws of nature. While theoretical computer science is known as a field that presents exciting intellectual challenges and is often not directly concerned with improving the practical applications of computing, research breakthroughs in this discipline have led to advances in almost every area of the field‚Äîfrom cryptography and computational biology to network design, machine learning, and quantum computing.</p>
<p><u>Why is Randomness Important?</u></p>
<p>Fundamentally, computers are <em>deterministic</em> systems; the set of instructions of an algorithm applied to any given input uniquely determines its computation and, in particular, its output. In other words, the deterministic algorithm is following a predictable pattern. <em> Randomness </em> , by contrast, lacks a well-defined pattern, or predictability in events or outcomes. Because the world we live in seems full of random events (weather systems, biological and quantum phenomena, etc.), computer scientists have enriched algorithms by allowing them to make random choices in the course of their computation, in the hope of improving their efficiency. And indeed, many problems for which no efficient deterministic algorithm was known have been solved efficiently by probabilistic algorithms, albeit with some small probability of error (that can be efficiently reduced). But is randomness essential, or can it be removed? And what is the quality of randomness needed for the success of probabilistic algorithms?</p>
<p>These, and many other fundamental questions lie at the heart of understanding randomness and pseudorandomness in computation. An improved understanding of the dynamics of randomness in computation can lead us to develop better algorithms as well as deepen our understanding of the nature of computation itself.</p>
<p><u>Wigderson‚Äôs Contributions</u></p>
<p>A leader in theoretical computer science research for four decades, Wigderson has made foundational contributions to the understanding of the role of randomness and pseudorandomness in computation.</p>
<p>Computer scientists have discovered a remarkable connection between randomness and computational difficulty (i.e., identifying natural problems that have no efficient algorithms). Working with colleagues, Wigderson authored a highly influential series of works on trading hardness for randomness. They proved that, under standard and widely believed computational assumptions, every probabilistic polynomial time algorithm can be efficiently derandomized (namely, made fully deterministic). In other words, randomness is not necessary for efficient computation. This sequence of works revolutionized our understanding of the role of randomness in computation, and the way we think about randomness. This series of influential papers include the following three:</p>
<ul>
<li>‚Äú<a href="https://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/NOAM/HARDNESS/final.pdf">Hardness vs. Randomness</a>‚Äù (co-authored with Noam Nisan)<br>
Among other findings, this paper introduced a new type of pseudorandom generator, and proved that efficient deterministic simulation of randomized algorithms is possible under much weaker assumptions than previously known.</li>
<li>‚Äú<a href="https://link.springer.com/article/10.1007/BF01275486">BPP Has Subexponential Time Simulations Unless EXPTIME has Publishable Proofs</a>‚Äù (co-authored with L√°szl√≥ Babai, Lance Fortnow, and Noam Nisan)<br>
This paper used `hardness amplification‚Äô to demonstrate that bounded-error probabilistic polynomial time (BPP) can be simulated in subexponential time for infinitely many input lengths under weaker assumptions.</li>
<li>‚Äú<a href="https://dl.acm.org/doi/pdf/10.1145/258533.258590">P = BPP if E Requires Exponential Circuits: Derandomizing the XOR Lemma</a>‚Äù (co-authored with Russell Impagliazzo)<br>
This paper introduces a stronger pseudo-random generator with essentially optimal hardness vs randomness trade-offs.</li>
</ul>
<p>Importantly, the impact of these three papers by Wigderson goes far beyond the areas of randomness and derandomization. Ideas from these papers were subsequently used in many areas of theoretical computer science and led to impactful papers by several leading figures in the field.</p>
<p>Still working within the broad area of randomness in computation, in <a href="https://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/CRVW01/crvw01.pdf"> papers</a>&nbsp;with Omer Reingold, Salil Vadhan, and Michael Capalbo, Wigderson gave the first efficient combinatorial constructions of expander graphs, which are sparse graphs that have strong connectivity properties. They have many important applications in both mathematics and theoretical computer science.</p>
<p>Outside of his work in randomness, Wigderson has been an intellectual leader in several other areas of theoretical computer science, including multi-prover interactive proofs, cryptography, and circuit complexity.</p>
<p><u>Mentoring</u></p>
<p>In addition to his groundbreaking technical contributions, Wigderson is recognized as an esteemed mentor and colleague who has advised countless young researchers. His vast knowledge and unrivaled technical proficiency‚Äîcoupled with his friendliness, enthusiasm, and generosity‚Äîhave attracted many of the best young minds to pursue careers in theoretical computer science.</p>
<p>‚ÄúIt‚Äôs important to point out that Avi Wigderson also received the Abel Prize, which is considered the most important honor for lifetime achievements in the field of mathematics,‚Äù explained ACM President Yannis Ioannidis. ‚ÄúBeing selected for the ACM A.M. Turing Award is a fitting follow-up‚Äîas mathematics is foundational to computer science and Wigderson‚Äôs work has connected a wide range of mathematical sub-areas to theoretical computer science. Wigderson is a towering intellectual force in theoretical computer science, an exciting discipline that attracts some of the most promising young researchers to work on the most difficult challenges. This year‚Äôs Turing Award recognizes Wigderson‚Äôs specific work on randomness, as well as the indirect but substantial impact he has had on the entire field of theoretical computer science.‚Äù</p>
<p>"Avi Wigderson‚Äôs work on randomness and other topics has set the agenda in theoretical computer science for the past three decades,‚Äù explained Jeff Dean, Senior Vice President, Google. ‚ÄúFrom the earliest days of computer science, researchers have recognized that incorporating randomness was a way to design faster algorithms for a wide range of applications. Efforts to better understand randomness continue to yield important benefits to our field, and Wigderson has opened new horizons in this area. Google also salutes Wigderson‚Äôs role as a mentor. His colleagues credit him with generating great ideas and research directions, and then motivating a new generation of smart young researchers to work on them. We congratulate Avi Wigderson on receiving the ACM A.M. Turing Award‚Äîcomputing‚Äôs highest honor.‚Äù</p>
<p><strong><a href="https://www.acm.org/media-center/2024/april/turing-award-2023">News Release</a> | <a href="https://awards.acm.org/binaries/content/assets/press-releases/2024/april/news-release_wigderson_turing-award.pdf">Printable PDF</a></strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Double-Entry Bookkeeping as a Directed Graph (377 pts)]]></title>
            <link>https://matheusportela.com/double-entry-bookkeeping-as-a-directed-graph</link>
            <guid>39988993</guid>
            <pubDate>Wed, 10 Apr 2024 10:13:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matheusportela.com/double-entry-bookkeeping-as-a-directed-graph">https://matheusportela.com/double-entry-bookkeeping-as-a-directed-graph</a>, See on <a href="https://news.ycombinator.com/item?id=39988993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p><span>08 Apr 2024</span></p><h2 id="my-journey-into-accounting">My Journey into Accounting</h2>

<p>In the past couple of years, I‚Äôve been working in billing and payments at <a href="https://www.justworks.com/">Justworks</a>. This experience introduced me to the world of bookkeeping and accounting in ways I didn‚Äôt expect: I took a <a href="https://www.udemy.com/course/accounting-fsa-a-solid-foundation-for-a-career-in-finance/">course</a> and <a href="https://link.springer.com/book/10.1007/978-1-349-20618-6">read a textbook</a> in accounting, adopted <a href="https://plaintextaccounting.org/">plain text accounting</a> for my personal finances, and worked in a double-entry ledger system.</p>

<p>Being such a fundamental part of the human experience, accounting has been around for literally millenia. It fostered mathematical and language development. In some cultures, it even predates <a href="https://en.wikipedia.org/wiki/Quipu">written language</a>. For this reason, it‚Äôs not surprising that accounting uses a very particular vocabulary and set of concepts that can be intimidating to a newcomer. Credits and debits. Assets and liabilities. Balance sheet. Ledgers and journals.</p>

<p>It took me a while to get used to these things. But once I did, I realized they aren‚Äôt <em>that</em> difficult. Maybe it is just a matter of finding the right way to explain them.</p>

<p>This series of articles is my attempt to capture some of my ‚Äúa-ha‚Äù moments while learning accounting. Hopefully, it will help someone out there grasp these ideas in a more intuitive and modern way.</p>

<p>In this first article, we‚Äôll start with the basics: bookkeeping.</p>

<p>Disclaimer: in this article, I‚Äôll simplify some concepts and use slightly different terminology than traditional accounting for didactic purposes. If you‚Äôre an accountant, please bear with me.</p>

<h2 id="bookkeeping-without-ledgers">Bookkeeping Without Ledgers</h2>

<p>At its core, accounting is about keeping track of countable things over time. Some of the oldest documents archelogists have found register quantities in old societies: food, animals, people, money. Nowadays, accounting is usually interested in tracking money whereas other areas (such as inventory management or the census bureau) count the rest. For the rest of this article, we‚Äôll focus on money.</p>

<p>Let‚Äôs start with a very simple example. Imagine you‚Äôre in a small town with two people: Alice and Bob. Alice has $100 in her pocket and Bob has $50 as of January 1st, 2024. We‚Äôll record this data in a table as follows:</p>

<div><pre><code>| Person | Amount |
| ------ | ------ |
| Alice  | $100   |
| Bob    | $50    |
</code></pre></div>

<p>If nothing changes, our job is done. We just need to go around town and ask each person how much money they have, tabulate the data, and store it in a safe place. Badabing, badaboom!</p>

<p>But money is meant to be spent. Alice is studying for her finals and needs to buy a book. She notices Bob has one copy and proposes to buy it from him for $20. Bob is happy to sell her the book he hasn‚Äôt used in a while and cash in the extra $20. Great deal!</p>

<p>Now that money has changed hands, we need to update our records. Alice spent $20 and Bob received the same amount. Let‚Äôs update our table.</p>

<div><pre><code>| Person | Amount |
| ------ | ------ |
| Alice  | $80    |
| Bob    | $70    |
</code></pre></div>

<p>Before proceeding, let‚Äôs name a few things. In our records, Alice and Bob are <strong>accounts</strong>, i.e., places where money is stored. The amount of money in each account is called a <strong>balance</strong>. Saying that Alice has $80 is the same as saying that the Alice account‚Äôs balance is $80 as of February 1st, 2024.</p>

<blockquote>
  <p><strong>Definition 1: Account</strong></p>

  <p>A place where money is stored.</p>
</blockquote>

<blockquote>
  <p><strong>Definition 2: Balance</strong></p>

  <p>The amount of money in an account at a given point in time.</p>
</blockquote>

<p>Every month, we can go around town, ask people how much money they have and write it down. We‚Äôre basically creating a snapshot of the town‚Äôs financial situation monthly. (Surely, most people will be annoyed by this breach of privacy and I would probably be arrested for stalking but let‚Äôs ignore this for now.)</p>

<p>What kinds of questions can we answer with this data? Actually, many!</p>
<ul>
  <li>How much money does each person have?</li>
  <li>How much money has each person spent or gained over time?</li>
  <li>Who has the most money?</li>
  <li>Who has the least money?</li>
  <li>How much money is there in total in the town?</li>
</ul>

<p>Our records are simple but useful.</p>

<p>Now, consider Alice comes to us one day and asks ‚ÄúHow come I have $80? I thought I had more!‚Äù Unfortunately, all we can answer is ‚ÄúThat‚Äôs what I have written down‚Äù with our current data. We can‚Äôt tell, for instance, whether Alice initially had $0 and received $80 or if she had $10,000 and spent $9,920.</p>

<p>Why is this so?</p>

<p>Well, we‚Äôre only keeping track of the <em>current</em> balance of each account. Because we erase the old balance and replace it with a new one, we don‚Äôt know exactly what happened to that balance over time. We lose the changes that happened between snapshots are lost.</p>

<p>Could we do better?</p>

<p>Of course! Accountants have dealt with this problem for centuries and they have a solution: <strong>ledgers</strong>.</p>

<h2 id="bookkeeping-with-single-entry-ledgers">Bookkeeping with Single-Entry Ledgers</h2>

<p>Let‚Äôs now think how we could keep track of the historical changes in a systematic way. One way to do this is to write down each update as it happens, not only the balance in a certain date.</p>

<p>To do this, we‚Äôll change the table a little bit. For example, we write down that on January 1st, 2024, Alice had $100.</p>

<div><pre><code>| Account | Description     | Date       | Amount | Balance |
| ------- | --------------- | ---------- | ------ | ------- |
| Alice   | Opening balance | 2024-01-01 | $100   | $100    |
</code></pre></div>

<p>We added some columns to the table:</p>
<ul>
  <li><strong>Description</strong>: A human-readable explanation of the transaction (e.g. what it is about, who got paid, a reference number, etc).</li>
  <li><strong>Date</strong>: When the transaction happened. Besides ordering transactions, this field can be used to group transactions by period (e.g. monthly reports). It can be enhanced with time information (e.g. hour, minute, second) if needed.</li>
  <li><strong>Balance</strong>: The balance of the account after the transaction. This field is redundant but it‚Äôs useful when inspecting the data.</li>
</ul>

<p>So far, so good.</p>

<p>Now, let‚Äôs take a look at how we can write down that Alice bought the book from Bob.</p>

<div><pre><code>| Account | Description     | Date       | Amount | Balance |
| ------- | --------------- | ---------- | ------ | ------- |
| Alice   | Opening balance | 2024-01-01 | $100   | $100    |
| Alice   | Bought book     | 2024-02-01 | -$20   | $80     |
</code></pre></div>

<p>This is different‚Ä¶ Instead of just updating the existing balance, we‚Äôre <em>adding a new row</em> with the transaction details. The new columns we added earlier are helpful in understanding what happened to the account. We know that Alice had $100, then spent $20 when buying the book, and now has $80.</p>

<p>Time for more definitions: each row in this table is called an <strong>entry</strong> and the whole table is called a <strong>ledger</strong>.</p>

<blockquote>
  <p><strong>Definition 3: Entry</strong></p>

  <p>A record of a transaction that happened to an account.</p>
</blockquote>

<blockquote>
  <p><strong>Definition 4: Ledger</strong></p>

  <p>A collection of entries for an account.</p>
</blockquote>

<p>So far, we‚Äôve updated only Alice‚Äôs ledger. Let‚Äôs take a look at Bob‚Äôs:</p>

<div><pre><code>| Account | Description     | Date       | Amount | Balance |
| ------- | --------------- | ---------- | ------ | ------- |
| Bob     | Opening balance | 2024-01-01 | $50    | $50     |
| Bob     | Sold book       | 2024-02-01 | $20    | $70     |
</code></pre></div>

<p>Now we have a ledger for each account. Great!</p>

<p>This system we implemented right now is called a <a href="https://en.wikipedia.org/wiki/Single-entry_bookkeeping"><strong>single-entry bookkeeping</strong></a> system. Each account has its own ledger and we write down entries that affect one account at a time. This is a simple system that works well for small businesses or personal finances.</p>

<p>Ledgers are sometimes called <strong>journal</strong> or <strong>book</strong> because, in the past, they were physical books where accountants would write down transactions. In the modern world, though, they‚Äôre usually stored in a database.</p>

<center><figure><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/handwritten-ledger.jpg" alt="Picture of a 1926 handwritten ledger"><figcaption>A 1926 handwritten ledger. Notice the accountant calculated the cash and bank balances daily. Source: <a href="https://www.business-case-analysis.com/ledger.html">Business Case Analysis</a>.</figcaption></figure></center>

<p>An important characteristic of a ledger is that the data is <em>immutable</em>. Once an entry is written, it cannot be changed at all because we want to preserve the ledger‚Äôs full history. No more erasing or scribbling over entries.</p>

<p>This raises the question: what happens if we make a mistake?</p>

<p>Here‚Äôs an example. Say the correct price for the book is $30 but we wrote down $20. If we were in a mutable system, we could just update the amount in the original entry as follows:</p>

<div><pre><code>| Account | Description     | Date       | Amount | Balance |
| ------- | --------------- | ---------- | ------ | ------- |
| Alice   | Opening balance | 2024-01-01 | $100   | $100    |
| Alice   | Bought book     | 2024-02-01 | -$30   | $70     |
</code></pre></div>

<p>There are many problems with this approach though. We lose the history of the original amount. We can‚Äôt tell that we made a mistake and corrected it. We also can‚Äôt tell if the original amount was correct and we made a mistake in the correction.</p>

<p>Could we do better?</p>

<p>Yes! Instead of updating the original entry, we can write a new entry to cancel the old one and write a new one with the correct amount. Let‚Äôs see how this looks:</p>

<div><pre><code>| Account | Description        | Date       | Amount | Balance |
| ------- | ---------------    | ---------- | ------ | ------- |
| Alice   | Opening balance    | 2024-01-01 | $100   | $100    |
| Alice   | Bought book        | 2024-02-01 | -$20   | $80     |
| Alice   | Correct book price | 2024-02-01 | $20    | $100    |
| Alice   | Bought book        | 2024-02-01 | -$30   | $70     |
</code></pre></div>

<p>The end result is the same as updating an entry in-place: the balance is $70. However, we can now see that we made a mistake and corrected it. We can also see the original amount and the reason for the correction. This gives us an <em>audit trail</em> of changes.</p>

<p>In a way, a ledger is similar to <a href="https://martinfowler.com/eaaDev/EventSourcing.html">event sourcing</a> in Computer Science. In event sourcing, we store events that happened in the system and use them to compute the current state of the system. This is in contrast to storing just the state of the system and updating it in-place. Event sourcing has many benefits, like being able to replay events or to rebuild the state of the system at any point in time.</p>

<p>If our system only cares about a single account at a time, a single-entry ledger system is enough. Think of a personal finance app that you use to keep track of your money or a gym that tracks how much their members paid for the service. However, financial systems are usually more complex than that and transactions typically involve multiple accounts at once.</p>

<p>For these complex scenarios, accountants developed a more robust system: <strong>double-entry bookkeeping</strong>.</p>

<h2 id="bookkeeping-with-double-entry-ledgers">Bookkeeping with Double-Entry Ledgers</h2>

<p>Let‚Äôs revisit the example of Alice buying the book from Bob and see the ledgers for both accounts:</p>

<div><pre><code>| Account | Description        | Date       | Amount | Balance |
| ------- | ------------------ | ---------- | ------ | ------- |
| Alice   | Opening balance    | 2024-01-01 | $100   | $100    |
| Alice   | Bought book        | 2024-02-01 | -$20   | $80     |

| Account | Description        | Date       | Amount | Balance |
| ------- | ------------------ | ---------- | ------ | ------- |
| Bob     | Opening balance    | 2024-01-01 | $50    | $50     |
| Bob     | Sold book          | 2024-02-01 | $20    | $70     |
</code></pre></div>

<p>Did you notice how the transactions are related to each other? The $20 Alice spent is the same $20 Bob received. We know that but the system doesn‚Äôt since we‚Äôre not explicitly stating this relationship in our ledgers. It could be the case the Alice bought the book from Bob and Bob received the money from Charlie. We can‚Äôt tell the difference when reading the ledgers.</p>

<p>A first step in making this relationship explicit is to group related entries into a <strong>transaction</strong>. Let‚Äôs add the <code>Transaction</code> column to our table:</p>

<div><pre><code>| Account | Transaction | Description        | Date       | Amount | Balance |
| ------- | ----------  | ------------------ | ---------- | ------ | ------- |
| Alice   | 1           | Opening balance    | 2024-01-01 | $100   | $100    |
| Alice   | 3           | Book sale          | 2024-02-01 | -$20   | $80     |

| Account | Transaction | Description        | Date       | Amount | Balance |
| ------- | ----------  | ------------------ | ---------- | ------ | ------- |
| Bob     | 2           | Opening balance    | 2024-01-01 | $50    | $50     |
| Bob     | 3           | Book sale          | 2024-02-01 | $20    | $70     |
</code></pre></div>

<p>In this example, we have the following transactions:</p>
<ul>
  <li>Transaction 1: Alice‚Äôs opening balance.</li>
  <li>Transaction 2: Bob‚Äôs opening balance.</li>
  <li>Transaction 3: Alice bought a book from Bob.</li>
</ul>

<p>Now, we explicitly state that the $20 Alice spent is the same $20 Bob received. No more ambiguity.</p>

<blockquote>
  <p><strong>Definition 5: Transaction</strong></p>

  <p>A group of related entries that affect different accounts.</p>
</blockquote>

<p>The difference between our current system and the previous one is that we‚Äôre now grouping related entries into transactions. Since each transaction affects multiple accounts, we can now see how money flows between accounts. By adding transactions to the tables, we are now working with a <a href="https://en.wikipedia.org/wiki/Double-entry_bookkeeping"><strong>double-entry bookkeeping</strong></a> system.</p>

<p>Traditionally, accountants would use two columns to represent the flow of money between accounts: <strong>credits</strong> and <strong>debits</strong>. When money leaves an account, the amounts goes in the credit column. Incoming money appears in the debit column.</p>

<blockquote>
  <p><strong>Definition 6: Credit</strong></p>

  <p>An entry that represents money leaving an account.</p>
</blockquote>

<blockquote>
  <p><strong>Definition 7: Debit</strong></p>

  <p>An entry that represents money entering an account.</p>
</blockquote>

<p>(Pro-tip: Ignore what you know about credit and debit cards for now.)</p>

<p>When Alice pays Bob $20, we say Alice‚Äôs account is credited $20 and Bob‚Äôs account is debited $20. Let‚Äôs represent this in our table:</p>

<div><pre><code>| Account | Transaction | Description        | Date       | Debit | Credit |
| ------- | ----------  | ------------------ | ---------- | ----- | ------ |
| Alice   | 1           | Opening balance    | 2024-01-01 | $100  |        |
| Alice   | 3           | Bought book        | 2024-02-01 |       | $20    |

| Account | Transaction | Description        | Date       | Debit | Credit |
| ------- | ----------  | ------------------ | ---------- | ----- | ------ |
| Bob     | 2           | Opening balance    | 2024-01-01 | $50   |        |
| Bob     | 3           | Sold book          | 2024-02-01 | $20   |        |
</code></pre></div>

<p>I wanted to make a few of points before continuing our journey.</p>

<p>First, the goal of double-entry bookkeeping is to reduce mistakes, especially the ones that are hard to notice. Remember that, for centuries, accountants were using pen and paper to keep track of insane amounts of money. Small mistakes could lead to big problems. Writing debits and credits in different columns, as we did above, reduces the chance of making mistakes. Your hand is literally moved to different places on the paper when writing debits and credits.</p>

<p>Real world accounting journals wouldn‚Äôt even put these columns side-by-side. Instead, they would be in different parts of the page. In fact, accounting journals were symmetrical: the left side was for debits and the right side, for credits. Something like this:</p>

<div><pre><code>Debit                          Alice's account                           Credit
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
| Date       | Description     | $    | | Date       | Description     | $    |
| ---------- | --------------- | ---- | | ---------- | --------------- | ---- |
| 2024-01-01 | Opening balance | $100 | |            |                 |      |
|            |                 |      | | 2024-02-01 | Bought book     | $20  |
</code></pre></div>

<p>This format is commonly referred to as a <a href="https://en.wikipedia.org/wiki/Debits_and_credits#T-accounts">T-account</a> (an analogy to the same: the top with the account name, the left side with debits, and the right side with credits). For this reason, many accountants will refer to debits as entries that go on the left side and credits as the ones that go on the right side.</p>

<center><figure><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/general-post-office-accounting-book.jpg" alt="Picture of the General Post Office T-account as instituted by Benjamin Franklin"><figcaption>General Post Office T-account as instituted by Benjamin Franklin. Source: <a href="https://postalmuseum.si.edu/object/npm_1982.0786.1">Smithsonian National Post Museum</a>.</figcaption></figure></center>

<p>Computer systems don‚Äôt need to use this format, though, as it doesn‚Äôt necessary prevent software bugs. Instead, it is common to have a single amount column and another column to indicate whether the amount is a debit or a credit. For example:</p>

<div><pre><code>| Account | Transaction | Description        | Date       | Type   | Amount |
| ------- | ----------  | ------------------ | ---------- | ------ | ------ |
| Alice   | 1           | Opening balance    | 2024-01-01 | Debit  | $100   |
| Alice   | 3           | Bought book        | 2024-02-01 | Credit | $20    |
</code></pre></div>

<p>Second, notice how we‚Äôre using a positive number even when money is leaving Alice‚Äôs account. Historically, accountants don‚Äôt like negative numbers in the books as they only became popular much later in Europe. Computer systems are very good with negative numbers, though. Instead of having two columns, we could just use a single column and adopt a convention in which credits are negative and debits are positive, or vice-versa. For example:</p>

<div><pre><code>| Account | Transaction | Description        | Date       | Amount |
| ------- | ----------  | ------------------ | ---------- | ------ |
| Alice   | 1           | Opening balance    | 2024-01-01 | $100   |
| Alice   | 3           | Bought book        | 2024-02-01 | -$20   |
</code></pre></div>

<p>If you pay close attention to this last example, this is exactly what we were doing before. The difference is that now we understand that the amount is negative because it‚Äôs a credit. (Technically, using negative numbers for credits might be a limitation if we‚Äôre trying to undo a credit entry without creating a debit entry but we don‚Äôt need to be that picky for now.)</p>

<p>Finally, I‚Äôm not a big fan of old nomenclature for tradition‚Äôs sake. We could rename credits as <em>outgoing</em> money and debits as <em>incoming</em> money without losing precision. In my opinion, this is a bit less confusing.</p>

<div><pre><code>| Account | Transaction | Description        | Date       | Incoming | Outgoing |
| ------- | ----------  | ------------------ | ---------- | -------- | -------- |
| Alice   | 1           | Opening balance    | 2024-01-01 | $100     |          |
| Alice   | 3           | Bought book        | 2024-02-01 |          | $20      |

| Account | Transaction | Description        | Date       | Incoming | Outgoing |
| ------- | ----------  | ------------------ | ---------- | -------- | -------- |
| Bob     | 2           | Opening balance    | 2024-01-01 | $50      |          |
| Bob     | 3           | Sold book          | 2024-02-01 | $20      |          |
</code></pre></div>

<p>Sweet!</p>

<p>A fundamental principle of double-entry bookkeeping is that the total amount of money in the system remains the same after each transaction. A particular account can increase or decrease its balance over time but the sum of <em>all</em> balances must remain constant. Nothing is lost, nothing is created, everything is <em>transacted</em>. It is a closed system.</p>

<blockquote>
  <p><strong>Definition 6: Double-Entry Ledger</strong></p>

  <p>A system of accounting where each transaction is recorded one or more entries. The amount of money leaving accounts is equal to the amount of money entering other accounts in every transaction.</p>
</blockquote>

<p>Ok, you might be thinking: ‚ÄúWait a minute, these opening balances go against what you just said!‚Äù and you‚Äôre right. Transactions 1 and 2 change the total amount of money in the system from $0 to $150. We should do better than stating a rule only to break it in the very next sentence.</p>

<p>Let‚Äôs assume all of the money that Alice and Bob have comes from a bank. Then, let‚Äôs create an account for this bank and use this account as the other side of the opening balance transactions.</p>

<div><pre><code>| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bank    | 1           | Alice's opening balance    | 2024-01-01 |          | $100     |
| Bank    | 2           | Bob's opening balance      | 2024-01-01 |          | $50      |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Alice   | 1           | Opening balance            | 2024-01-01 | $100     |          |
| Alice   | 3           | Bought book                | 2024-02-01 |          | $20      |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bob     | 2           | Opening balance            | 2024-01-01 | $50      |          |
| Bob     | 3           | Sold book                  | 2024-02-01 | $20      |          |
</code></pre></div>

<p>In this example, we don‚Äôt care where the opening balances come from exactly. We just need to make sure money is coming from somewhere. The bank account is a kind of phony account that is there just to help us follow the rules. In accounting terms, it is called a <a href="https://en.wikipedia.org/wiki/Debits_and_credits#Contra_account">contra account</a> to the other accounts. The important thing is that all transactions are <strong>balanced</strong>, i.e., ‚Äúcredits equal debits‚Äù.</p>

<blockquote>
  <p><strong>Definition 7: Contra Account</strong></p>

  <p>An account that is used to offset another account. It is used to keep the accounting equation in balance.</p>
</blockquote>

<p>Our system is now complete. We have a double-entry ledger system that keeps track of money flowing between accounts. We can answer many questions about the financial situation of Alice and Bob and we have a clear audit trail of all transactions that happened.</p>

<p>Let‚Äôs consider a more complex example. When Alice buys the book, she accidentally uses the wrong credit card and needs to pay $2 in foreign exchange fees. Bob, on the other hand, pays $2 in sales taxes to the government, $1 in credit card fees. How do we keep track of this?</p>

<p>The secret in double-entry bookkeeping is to use accounts for everything. As we did before, we model this flow by creating new accounts: one for the credit card company and another for the tax authority. Then, when creating the transaction, we add new entries as necessary.</p>

<div><pre><code>| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bank    | 1           | Alice's opening balance    | 2024-01-01 |          | $100     |
| Bank    | 2           | Bob's opening balance      | 2024-01-01 |          | $50      |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Alice   | 1           | Opening balance            | 2024-01-01 | $100     |          |
| Alice   | 3           | Bought book                | 2024-02-01 |          | $20      |
| Alice   | 3           | Foreign exchange fee       | 2024-02-01 |          | $2       |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bob     | 2           | Opening balance            | 2024-01-01 | $50      |          |
| Bob     | 3           | Sold book                  | 2024-02-01 | $20      |          |
| Bob     | 3           | Sales tax                  | 2024-02-01 |          | $2       |
| Bob     | 3           | Credit card fee            | 2024-02-01 |          | $1       |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| CC      | 3           | Alice's credit card fee    | 2024-02-01 | $2       |          |
| CC      | 3           | Bob's credit card fee      | 2024-02-01 | $1       |          |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Tax     | 3           | Bob's sales tax            | 2024-02-01 | $2       |          |
</code></pre></div>

<p>We modified transaction 3 as follows:</p>
<ul>
  <li>Alice pays $20 to Bob and $2 to the credit card company.</li>
  <li>Bob receives $20 from Alice, pays $2 to the tax authority, and $1 to the credit card company.</li>
  <li>The credit card company receives $2 from Alice and $1 from Bob.</li>
  <li>The tax authority receives $2 from Bob.</li>
</ul>

<p>Notice that transaction 3 has <em>more than two entries</em>. It has eight entries, to be precise. This is perfectly fine! We can have as many entries as we need to represent the flow of money between accounts as long as the transaction is balanced, i.e., credits = debits.</p>

<p>It is a common mistake to think that <em>double</em>-entry bookkeeping limits transactions to two entries at a time. The technique is called ‚Äúdouble-entry‚Äù not because there are only two entries but because each transaction has <em>two sides</em>: one side where money leaves an account and another side where money enters another account. I guess ‚Äúmany-entry bookkeeping‚Äù doesn‚Äôt sound as good.</p>

<h2 id="double-entry-bookkeeping-is-a-directed-graph">Double-Entry Bookkeeping is a Directed Graph</h2>

<p>I hope these concepts are clear so far. We have accounts, entries, transactions, incoming money, and outgoing money. With practice, you‚Äôll be able to read and write these tables with ease.</p>

<p>But I have a confession to make: I‚Äôm a visual person. I like to draw and see things when I‚Äôm learning. So I started to think: how can we visualize this data in a way that makes sense to me? After using double-entry bookkeeping for a while in my personal finances and trying to come with a visualization for my ledgers, it finally clicked: we‚Äôre modeling money flow as a <a href="https://en.wikipedia.org/wiki/Directed_graph"><em>directed graph</em></a>.</p>

<p>Think about this: An account is a <em>node</em> in the graph, a credit entry is an <em>outgoing edge</em> with an amount of money leaving this node whereas a debit is an <em>incoming edge</em> with money flowing to another node. A transaction, then, groups and enforces a condition on a set of edges: the outgoing edges must have the same sum of money as the incoming edges.</p>

<p>Let‚Äôs take a look at the example we‚Äôve been using so far. First, we start with Alice‚Äôs and Bob‚Äôs accounts and the money they stored in the bank:</p>

<p><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/Picture%201.drawio.svg" alt="Graph for the first example: Alice's and Bob's initial balances with the Bank as a source"></p>

<p>A few comments on this graph:</p>
<ul>
  <li>An account is a round node with the account name.</li>
  <li>A transaction is a square node with the transaction number.</li>
  <li>A credit entry goes from an account to a transaction.</li>
  <li>A debit entry goes from a transaction to an account.</li>
  <li>The entry‚Äôs amount of money is written on the edge.</li>
  <li>An account‚Äôs balance is the sum of the amounts of the incoming edges minus the sum of the amounts of the outgoing edges.</li>
</ul>

<p>We can see that transaction 1 moves $100 from the bank to Alice. Transaction 2 moves $50 from the bank to Bob. The total amount of money in the system is $150.</p>

<p>Then, Alice buys a book from Bob:</p>

<p><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/Picture%202.drawio.svg" alt="Graph for the second example: Alice buys a book from Bob"></p>

<p>We can see that transaction 3 moves $20 from Alice to Bob. Hence, Alice has $80 and Bob, $70.</p>

<p>We haven‚Äôt added fees and taxes yet. Let‚Äôs do this:</p>

<p><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/Picture%203.drawio.svg" alt="Graph for the third example: fees and taxes"></p>

<p>Oof, that‚Äôs a lot of edges! Transaction 3 is very complex as it conflates what Alice is paying Bob with the fees and taxes they pay to other parties. We could make this easier by splitting this transaction into two smaller ones:</p>

<div><pre><code>| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bank    | 1           | Alice's opening balance    | 2024-01-01 |          | $100     |
| Bank    | 2           | Bob's opening balance      | 2024-01-01 |          | $50      |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Alice   | 1           | Opening balance            | 2024-01-01 | $100     |          |
| Alice   | 3           | Bought book                | 2024-02-01 |          | $22      |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Bob     | 2           | Opening balance            | 2024-01-01 | $50      |          |
| Bob     | 3           | Sold book                  | 2024-02-01 | $19      |          |
| Bob     | 4           | Sales tax                  | 2024-02-01 |          | $2       |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| CC      | 3           | Transaction fee            | 2024-02-01 | $3       |          |

| Account | Transaction | Description                | Date       | Incoming | Outgoing |
| ------- | ----------  | -------------------------- | ---------- | -------- | -------- |
| Tax     | 4           | Bob's sales tax            | 2024-02-01 | $2       |          |
</code></pre></div>

<p>And as a graph:</p>

<p><img src="https://matheusportela.com/assets/images/double-entry-bookkeeping/Picture%204.drawio.svg" alt="Graph for the fourth example: simplified transactions"></p>

<p>We simplified the transactions a little bit:</p>
<ul>
  <li>Alice sees $22 leaving her account but Bob only receives $19. The remaining $3 goes to the credit card company.</li>
  <li>Bob pays sales taxes in a different transaction.</li>
</ul>

<p>Regardless of how we model the transactions, the account balances are the same. Alice has $78, Bob has $69, the tax authority has $2, and the credit card company has $3. It is the accountant‚Äôs job to decide how to group transactions and entries in a way that makes sense for the business as the bookkeeping system is flexible enough to accommodate different needs.</p>

<p>These simple examples show how we can visualize money flow in a double-entry bookkeeping system as a directed graph. The graph grows over time as new transactions are added but it‚Äôs properties remain the same. In my opinion, understanding bookkeeping as a graph is a powerful way to reason about many accounting concepts. Suddenly, things as <em>balance sheets</em>, <em>income statements</em>, and <em>cash flow statements</em> are just visualizations of this graph. Categories such as <em>assets</em>, <em>liabilities</em>, <em>equity</em>, <em>income</em>, and <em>expenses</em> are just groups of nodes in the graph and it is quite easy to understand whether credits or debits increase their balances. It‚Äôs a way to make accounting more intuitive and less intimidating to me!</p>

<p>We could go on and on with this example, adding more complexity to the transactions, creating new accounts, and visualizing the graph as it grows. But I think we did a great job today and should take a well-deserved break.</p>

<h2 id="takeaways">Takeaways</h2>

<p>In this article, we‚Äôve covered the basics of bookkeeping. We started with a simple system that only kept track of balances, evolved it into a single-entry and, later, into a double-entry ledger system that models money flow between accounts. We‚Äôve seen how to represent transactions as entries in a ledger and how to group related entries into transactions. Finally, we‚Äôve seen how to visualize a double-entry ledger as a directed graph.</p>

<p>In the next article, we‚Äôll dive deeper into basic accounting concepts and see how they relate to the graph representation we‚Äôve seen here.</p>

<h2 id="resources">Resources</h2>

<p>When studying these concepts, I found the following resources particularly helpful:</p>
<ul>
  <li><a href="https://www.udemy.com/course/accounting-fsa-a-solid-foundation-for-a-career-in-finance/">Accounting &amp; Financial Statement Analysis: Complete Training</a>: A crash course in accounting in Udemy. It was my introduction to the topic and I highly recommend it.</li>
  <li><a href="https://link.springer.com/book/10.1007/978-1-349-20618-6">Mastering Accounting by George Bright and Michael Herbert</a>: A textbook that covers accounting from the basics to more advanced topics. Another great resource to deepen my understanding of accounting.</li>
  <li><a href="https://beancount.github.io/docs/the_double_entry_counting_method.html">Beancount‚Äôs documentation</a> has a great explanation of accounting as a graph over time. It was a big inspiration for this article.</li>
  <li><a href="https://www.moderntreasury.com/journal/accounting-for-developers-part-i">Modern Treasury</a> has a great series of articles that explain accounting concepts for developers. It is another big inspiration.</li>
  <li><a href="https://news.ycombinator.com/item?id=32495724">This particular thread on Hacker News</a>. Some comments are gold!</li>
  <li><a href="https://plaintextaccounting.org/">Plain text accounting</a> is a small but engaged community that uses plain text files and command-line tools to keep track of their finances. I use <a href="https://hledger.org/">hledger</a> for my personal finances.</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. imposes first-ever national drinking water limits on PFAS (123 pts)]]></title>
            <link>https://apnews.com/article/forever-chemicals-pfas-pollution-epa-drinking-water-1c8804288413a73bb7b99fc866c8fa51</link>
            <guid>39988718</guid>
            <pubDate>Wed, 10 Apr 2024 09:31:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/forever-chemicals-pfas-pollution-epa-drinking-water-1c8804288413a73bb7b99fc866c8fa51">https://apnews.com/article/forever-chemicals-pfas-pollution-epa-drinking-water-1c8804288413a73bb7b99fc866c8fa51</a>, See on <a href="https://news.ycombinator.com/item?id=39988718">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>The Biden administration on Wednesday finalized strict limits on certain so-called ‚Äúforever chemicals‚Äù in drinking water that will require utilities to reduce them to the lowest level they can be reliably measured. Officials say this will reduce exposure for 100 million people and help prevent thousands of illnesses, including cancers.</p><p>The rule is the first national drinking water limit on toxic PFAS, or perfluoroalkyl and polyfluoroalkyl substances, which are widespread and long lasting in the environment. </p><p>Health advocates praised the Environmental Protection Agency for not backing away from <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/epa-pfas-forever-chemicals-water-contamination-regulations-560d0ce3321e7fa8ed052f792c24f16f">tough limits the agency proposed last year</a></span>. But water utilities took issue with the rule, saying treatment systems are expensive to install and that customers will end up paying more for water.</p><p>Water providers are entering a new era with significant additional health standards that the EPA says will make tap water safer for millions of consumers ‚Äî a Biden administration priority. The agency has also proposed <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/lead-epa-flint-discrimination-biden-white-house-ca10a72d628491fe03ec687432bf0b45">forcing utilities to remove dangerous lead pipes</a></span>. </p>




    

<p>Utility groups warn the rules will cost tens of billions of dollars each and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/health-business-west-virginia-dementia-6770a6191b89b064bd77227e1b18639d">fall hardest on small communities with fewer resources</a></span>. Legal challenges are sure to follow. </p><p>EPA Administrator Michael Regan says the rule is the most important action the EPA has ever taken on PFAS.</p><p>‚ÄúThe result is a comprehensive and life-changing rule, one that will improve the health and vitality of so many communities across our country,‚Äù said Regan.</p>
    
<p>PFAS chemicals are hazardous because they don‚Äôt degrade in the environment and are linked to health issues such as low birth weight and liver disease, along with certain cancers. The EPA estimates the rule will cost about $1.5 billion to implement each year, but doing so will prevent nearly 10,000 deaths over decades and significantly reduce serious illnesses.</p>
    

<p>They‚Äôve been used in everyday products including nonstick pans, firefighting foam and waterproof clothing. Although some of the most common types are phased out in the U.S., others remain. Water providers will now be forced to remove contamination put in the environment by other industries.</p><p>‚ÄúIt‚Äôs that accumulation that‚Äôs the problem,‚Äù said Scott Belcher, a North Carolina State University professor who researches PFAS toxicity. ‚ÄúEven tiny, tiny, tiny amounts each time you take a drink of water over your lifetime is going to keep adding up, leading to the health effects.‚Äù</p><p>PFAS is a broad family of chemical substances, and the new rule sets strict limits on two common types ‚Äî called PFOA and PFOS ‚Äî at 4 parts per trillion. Three other types that include GenEx Chemicals that are a major problem in North Carolina are limited to 10 parts per trillion. Water providers will have to test for these PFAS chemicals and tell the public when levels are too high. Combinations of some PFAS types will be limited, too. </p><p>Regan will announce the rule in Fayetteville, North Carolina, on Wednesday.</p><p>Environmental and health advocates praised the rule, but said PFAS manufacturers knew decades ago the substances were dangerous yet hid or downplayed the evidence. Limits should have come sooner, they argue. </p>
    

<p>‚ÄúReducing PFAS in our drinking water is the most cost effective way to reduce our exposure,‚Äù said Scott Faber, a food and water expert at Environmental Working Group. ‚ÄúIt‚Äôs much more challenging to reduce other exposures such as PFAS in food or clothing or carpets.‚Äù</p><p>Over the last year, EPA has periodically released batches of utility test results for PFAS in drinking water. Roughly 16% of utilities found at least one of the two strictly limited PFAS chemicals at or above the new limits. These utilities serve tens of millions of people. The Biden administration, however, expects about 6-10% of water systems to exceed the new limits.</p><p>Water providers will generally have three years to do testing. If those test exceed the limits, they‚Äôll have two more years to install treatment systems, according to EPA officials.</p><p>Some funds are available to help utilities. Manufacturer 3M recently agreed to <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/pfas-drinking-water-settlement-3m-fa41cadfe0d65b9723377a681df43af1">pay more than $10 billion to drinking water providers</a></span> to settle PFAS litigation. And the Bipartisan Infrastructure Law includes billions to combat the substance. But utilities say more will be needed.</p>
    

<p>For some communities, tests results were a surprise. Last June, a utility outside Philadelphia that serves nearly 9,000 people learned that one of its wells had a PFOA level of 235 parts per trillion, among the highest results in the country at the time.</p><p>‚ÄúI mean, obviously, it was a shock,‚Äù said Joseph Hastings, director of the joint public works department for the Collegeville and Trappe boroughs, whose job includes solving problems presented by new regulations.</p><p>The well was quickly yanked offline, but Hastings still doesn‚Äôt know the contamination source. Several other wells were above the EPA‚Äôs new limits, but lower than those the state of Pennsylvania set earlier. Now, Hastings says installing treatment systems could be a multi-million dollar endeavor, a major expense for a small customer base.</p>
    

<p>The new regulation is ‚Äúgoing to throw public confidence in drinking water into chaos,‚Äù said Mike McGill, president of WaterPIO, a water industry communications firm.</p><p>The American Water Works Association, an industry group, says it supports the development of PFAS limits in drinking water, but argues the EPA‚Äôs rule has big problems. </p><p>The agency underestimated its high cost, which can‚Äôt be justified for communities with low levels of PFAS, and it‚Äôll raise customer water bills, the association said. Plus, there aren‚Äôt enough experts and workers ‚Äî and supplies of filtration material are limited.</p><p>Work in some places has started. The company Veolia operates utilities serving about 2.3 million people across six eastern states and manages water systems for millions more. Veolia built PFAS treatment for small water systems that serve about 150,000 people. The company expects, however, that roughly 50 more sites will need treatment ‚Äî and it‚Äôs working to scale up efforts to reduce PFAS in larger communities it serves.</p><p>Such efforts followed <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/pfas-epa-water-regulations-d2d5052c36a5a95f4e56866f028c9c4f">dramatic shifts in EPA‚Äôs health guidance</a></span> for PFAS in recent years as more research into its health harms emerged. Less than a decade ago, EPA issued a health advisory that PFOA and PFOS levels combined shouldn‚Äôt exceed 70 parts per trillion. Now, the agency says no amount is safe.</p><p>Public alarm has increased, too. In Minnesota, for example, Amara‚Äôs Law aims to stop avoidable PFAS use. It‚Äôs been nearly a year since the law‚Äôs namesake, Amara Strande, died from a rare cancer her family blames on PFAS contamination by 3M near her high school in Oakdale, although a connection between PFAS and her cancer can‚Äôt be proven. Biden administration officials say communities shouldn‚Äôt suffer like Oakdale. 3M says it extends its deepest condolences to Amara‚Äôs friends and family.</p><p>Losing Amara pushed the family towards activism. They‚Äôve testified multiple times in favor of PFAS restrictions. </p><p>‚ÄúFour parts per trillion, we couldn‚Äôt ask for a better standard,‚Äù Amara‚Äôs sister Nora said. ‚ÄúIt‚Äôs a very ambitious goal, but anything higher than that is endangering lives.‚Äù</p><h2>___</h2><p>Associated Press data journalist Camille Fassett in San Francisco and reporter Matthew Daly in Washington D.C. contributed to this story.</p><h2>___</h2><p>The Associated Press receives support from the Walton Family Foundation for coverage of water and environmental policy. The AP is solely responsible for all content. For all of AP‚Äôs environmental coverage, visit <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/environment">https://apnews.com/hub/climate-and-environment</a></span></p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Bug (179 pts)]]></title>
            <link>https://www.marginalia.nu/log/a_104_dep_bug/</link>
            <guid>39988716</guid>
            <pubDate>Wed, 10 Apr 2024 09:30:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marginalia.nu/log/a_104_dep_bug/">https://www.marginalia.nu/log/a_104_dep_bug/</a>, See on <a href="https://news.ycombinator.com/item?id=39988716">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>The project has been haunted by a mysterious bug since sometime February. It relates to the code that constructs the index, particularly the code that merges partial indices.</p><p>In short the search engine constucts the reverse index through successive merging of smaller indices, which reduces the overall memory requirement.</p><p>You can conceptualize the revese index itself as two files, one with offset pointers into another file, which has sorted numbers. This code runs after each partition finishes crawling and processing its data, and has a run time of about 4 hours.</p><p>Suddenly the code that merges the indexes started to randomly fail.</p><p>What failed was the code that copies sorted numbers from one of the older indices to one of the newer, in the case when a keyword is present in only one of the indexes and no actual merging of sorted lists is needed.</p><p>If code suddenly starts acting up when the amount of data increases, all my intuition screams that this must be a 32 bit integer overflow. The index construction does all of its work in the bermuda triangle of 32 bit errors that is 1-32 GB file size range, so it really does seem like a very probable suspect.</p><p>I went over the code looking for such a thing, and found nothing. I added a bunch of guard clauses and assertions to get some hint about what was going on, but these didn‚Äôt turn up much other than the copy operation attempting to copy outside the file.</p><p>To my surprise, while doing this the construction process suddenly went through! The index it constructed was sane. Had I fixed it by perturbing the code somehow? I ran it again and it failed.</p><p>Some non-determinism is expected since the indexes are merged in parallel, so the order they‚Äôre merged in is a bit random even if the merging itself is completely deterministic. I felt this explained the random success: I got lucky with the ordering.</p><p>Since I had a work-around I left this be for a while. I had other work that was more pressing. The seven remaining partitions were coaxed through by just hitting the restart button until it worked, taking one or more days of hammering restarts. Annoying and time consuming, but it worked.</p><p>This week the final partition came through, and I had a moment to look deeper into this enigma.</p><p>Maybe it wasn‚Äôt an integer overflow? I checked the git log for any suspect changes between December when it worked and February when it didn‚Äôt work, and I found nothing. Again I combed over the code looking for integer overflows, and still found nothing.</p><p>I did find a function that shrinks the merged index, which is initially allocated to be the total size of the inputs. Since the merge function removes duplicates, the merged index is often smaller than the sum of its parts, but it‚Äôs impossible to know how small before actually merging.</p><p>This seemed like a plausible explanation, since if the files were truncated too hard, it would explain the files seemingly being ‚Äútoo small‚Äù. I disabled the truncation, and still got errors.</p><p>In investigating this, I stumbled on a very curious aberration. I‚Äôll sketch out the gist of it:</p><div><pre tabindex="0"><code data-lang="java"><span><span>
</span></span><span><span>val <span>=</span> read<span>-</span>only mmapped file 
</span></span><span><span>      not subject to change
</span></span><span><span>counts <span>=</span> zeroed mmap<span>:</span>ed file 
</span></span><span><span>
</span></span><span><span><span>long</span> offset <span>=</span> 0<span>;</span>
</span></span><span><span><span>for</span> <span>(</span><span>int</span> i <span>=</span> 0<span>;</span> i <span>&lt;</span> length<span>;</span> i<span>++)</span> <span>{</span>
</span></span><span><span>  counts<span>[</span>i<span>]</span> <span>=</span> val<span>[</span>i<span>];</span>
</span></span><span><span>  offset <span>+=</span> val<span>[</span>i<span>];</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>long</span> size <span>=</span> 0<span>;</span>
</span></span><span><span><span>for</span> <span>(</span><span>int</span> i <span>=</span> 0<span>;</span> i <span>&lt;</span> length<span>;</span> i<span>++)</span> <span>{</span>
</span></span><span><span>   size <span>+=</span> counts<span>[</span>i<span>];</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>// ...
</span></span></span><span><span><span></span>
</span></span><span><span><span>assert</span> <span>(</span>size <span>==</span> offset<span>);</span>
</span></span><span><span>
</span></span><span><span><span>// ...
</span></span></span><span><span><span></span>
</span></span><span><span>truncate<span>(</span>size<span>);</span>
</span></span></code></pre></div><p>All this runs in sequence on the same thread, and nothing writes to <code>counts</code> other than this code.</p><p>The assertion would fail.</p><p>Alright, so it is an integer overflow! ‚Ä¶ you might think. Nope. These are all 64 bit longs, and the values being added are small and few enough not to overflow a 32 bit integer. At this point I could reliably isolate the particular inputs that triggered the behavior with the assert, so I did just that.</p><p>There are four lights, damnit!</p><p>At this point I patched production so that if this assertion were to fail, the input files were copied over to a separate directory. This gave me a 2 GB set of test-data that had been known to trigger the error that I could exfiltrate and examine locally.</p><p>The bug of course did not re-appear when I ran this code in isolation, but that actually says something important. I‚Äôd reduced the problem down to deterministic code being non-deterministic and outputting logical contradictions. This feels like a good reason to question other things than the program logic.</p><p>It‚Äôs probably safe to assume the problem is either the JVM, the linux kernel, or the hardware, in decreasing order of likelihood.</p><p>The JVM is at the top of the suspect list since one of the things that <em>had</em> in fact changed since the bug appeared was that the project migrated over to graalvm from openjdk.</p><p>Hardware errors typically don‚Äôt target only a specific function over and over, except I guess if you have some Homer-style divine grudge going on. Having not skipped over any libations, enraged gods could probably be ruled out, and to further sow doubts about this I was able to reproduce the error on another machine, not with the exfiltrated data but through reindexing Wikipedia‚Äôs data repeatedly. This also probably rules out some sort of linux kernel bug, since the kernels were a few versions apart; one machine was SMP and the other was not, one with ECC one not, etc.</p><p>So at this point the only remaining suspect on my list was the graalvm JDK. I migrated the project to the latest graalvm version, from jdk-21 to jdk-22 through oracle‚Äôs official docker images. This did absolutely nothing to address the problem. I switched the docker build process to use a temurin (openjdk) image instead of graalvm, and‚Ä¶ the problem went away! Since then, it‚Äôs worked over and over.</p><p>At this point I‚Äôd love to file a bug report, although I‚Äôm having trouble isolating the problem enough to do so. ‚ÄúDoesn‚Äôt work‚Äù is famously not an error description. The relevant process is something like 5 KLOC, and the smallest dataset that triggers the bug somewhat reliably is about 54 GB.</p><p>I‚Äôve isolated the code that manifests the bug and run it 50,000 times on the data exfiltrated from production on a machine that‚Äôs previously been able to trigger the problem, and it‚Äôs run without a hitch, so there appears to be some sort of spooky action at a distance going on. I‚Äôve tried perturbing it in various ways, introducing page faults and so on, since that‚Äôs happening a lot in production, again to no avail.</p><p>In general I‚Äôd argue you haven‚Äôt fixed a bug unless you understand why it happened and why your fix worked, which makes this frustrating, since every indication is that the bug exists within proprietary code that is out of my reach. This feels like an impasse, not a solution, even though the error has nominally been corrected.</p><p>I can at least say make statements about what hasn‚Äôt caused the error.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Client libraries are better when they have no API (133 pts)]]></title>
            <link>https://csvbase.com/blog/7</link>
            <guid>39988580</guid>
            <pubDate>Wed, 10 Apr 2024 09:10:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://csvbase.com/blog/7">https://csvbase.com/blog/7</a>, See on <a href="https://news.ycombinator.com/item?id=39988580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>When I met a friend in a pub recently and I told him I was writing a client
library for csvbase, he did laugh a bit.  "Can't people just use curl?"</p>
<p>It's true.  On csvbase, you can just curl any table url and get a csv file.
Through the magic of HTTP, this web-page:</p>
<p><img src="https://csvbase.com/blog-static/stock-exchanges.png" alt="screenshot of csvbase table web
page"></p>
<p>becomes this csv file inside curl:</p>
<p><img src="https://csvbase.com/blog-static/curl.png" alt="screenshot of csvbase table in
curl"></p>
<p>[For details of how that trick works, see <a href="https://csvbase.com/blog/2">an older
blog post</a>]</p>
<p>That barely qualifies as an API, it's just HTTP.  So what possible use could a
client library be?</p>
<p>And of course client libraries add mental overhead of their own.  You have to
read some docs, learn some methods and then and the end you still have to add
some code to use whatever library it is.</p>
<p>Wouldn't you rather just not?</p>
<p>I would certainly rather not.  With that in mind, I've written a client library
that has no API.</p>
<h2>No API</h2>
<p>Wait, no API?:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>&gt;&gt;&gt;</span> <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"csvbase://calpaterson/onion-vox-pops"</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>df</span><span>.</span><span>quote</span><span>[</span><span>0</span><span>]</span>
<span>"""I realize passengers are concerned, but speaking as a pilot,</span>
<span>there's no better place to drop acid than 40,000 feet in the air."""</span>
</pre></div>
<p>(A man after my own heart.)</p>
<p>But yes, no API.  I resent writing data APIs anyway (that's why I wrote
csvbase - to do it once, generically).  So if you want, just pull dataframes
down from csvbase with Pandas itself.  pip install
<a href="https://pypi.org/project/csvbase-client/"><code>csvbase-client</code></a> and Pandas will
suddenly learn the <code>csvbase://</code> url scheme.</p>
<p>And what if you want to write a dataframe to csvbase?  Is there an API for
that?  Again: no.  You call the usual method: <code>DataFrame.to_csv</code>:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>string</span>  <span># from the stdlib</span>
<span>&gt;&gt;&gt;</span> <span>alphabet_df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>zip</span><span>(</span><span>range</span><span>(</span><span>1</span><span>,</span> <span>27</span><span>),</span> <span>string</span><span>.</span><span>ascii_lowercase</span><span>),</span>\
    <span>columns</span><span>=</span><span>(</span><span>"number"</span><span>,</span> <span>"letter"</span><span>))</span><span>.</span><span>set_index</span><span>(</span><span>"number"</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>alphabet_df</span><span>.</span><span>to_csv</span><span>(</span><span>"csvbase://calpaterson/alphabet"</span><span>)</span>
</pre></div>
<p>You do admittedly need to put your csvbase username and <strong>API key</strong> into
<code>~/.netrc</code> first.  Here's mine:</p>
<div><pre><span></span><span>machine csvbase.com</span><span></span>
<span>  </span><span>login calpaterson</span><span></span>
<span>  </span><span>password hunter42</span><span></span>
</pre></div>
<p>You can check up on <code>calpaterson/alphabet</code>: it's a <a href="https://csvbase.com/calpaterson/alphabet">real table on
csvbase.com</a> now.</p>
<p>But perhaps you don't like Pandas.  You prefer <a href="https://pola.rs/">Polars</a>, that
other dataframe library.  Again: I refuse to write an API.  You can just use
Polars itself:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>polars</span> <span>as</span> <span>pl</span>
<span>&gt;&gt;&gt;</span> <span>pl</span><span>.</span><span>read_csv</span><span>(</span><span>"csvbase://calpaterson/alphabet"</span><span>)</span>
<span>shape</span><span>:</span> <span>(</span><span>26</span><span>,</span> <span>3</span><span>)</span>
<span>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span>
<span>‚îÇ</span> <span>csvbase_row_id</span> <span>‚îÜ</span> <span>number</span> <span>‚îÜ</span> <span>letter</span> <span>‚îÇ</span>
<span>‚îÇ</span> <span>---</span>            <span>‚îÜ</span> <span>---</span>    <span>‚îÜ</span> <span>---</span>    <span>‚îÇ</span>
<span>‚îÇ</span> <span>i64</span>            <span>‚îÜ</span> <span>i64</span>    <span>‚îÜ</span> <span>str</span>    <span>‚îÇ</span>
<span>‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°</span>
<span>‚îÇ</span> <span>1</span>              <span>‚îÜ</span> <span>1</span>      <span>‚îÜ</span> <span>a</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>2</span>              <span>‚îÜ</span> <span>2</span>      <span>‚îÜ</span> <span>b</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>3</span>              <span>‚îÜ</span> <span>3</span>      <span>‚îÜ</span> <span>c</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>4</span>              <span>‚îÜ</span> <span>4</span>      <span>‚îÜ</span> <span>d</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>5</span>              <span>‚îÜ</span> <span>5</span>      <span>‚îÜ</span> <span>e</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>‚Ä¶</span>              <span>‚îÜ</span> <span>‚Ä¶</span>      <span>‚îÜ</span> <span>‚Ä¶</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>22</span>             <span>‚îÜ</span> <span>22</span>     <span>‚îÜ</span> <span>v</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>23</span>             <span>‚îÜ</span> <span>23</span>     <span>‚îÜ</span> <span>w</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>24</span>             <span>‚îÜ</span> <span>24</span>     <span>‚îÜ</span> <span>x</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>25</span>             <span>‚îÜ</span> <span>25</span>     <span>‚îÜ</span> <span>y</span>      <span>‚îÇ</span>
<span>‚îÇ</span> <span>26</span>             <span>‚îÜ</span> <span>26</span>     <span>‚îÜ</span> <span>z</span>      <span>‚îÇ</span>
<span>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
</pre></div>
<p>What about <a href="https://docs.dask.org/en/stable/">Dask</a>?  Same thing:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>dask.dataframe</span> <span>as</span> <span>dd</span>
<span>&gt;&gt;&gt;</span> <span>dd</span><span>.</span><span>read_csv</span><span>(</span><span>"csvbase://calpaterson/alphabet"</span><span>)</span>
<span>Dask</span> <span>DataFrame</span> <span>Structure</span><span>:</span>
              <span>csvbase_row_id</span> <span>number</span>  <span>letter</span>
<span>npartitions</span><span>=</span><span>1</span>
                       <span>int64</span>  <span>int64</span>  <span>string</span>
                         <span>...</span>    <span>...</span>     <span>...</span>
<span>Dask</span> <span>Name</span><span>:</span> <span>read_csv</span><span>,</span> <span>1</span> <span>expression</span>
<span>Expr</span><span>=</span><span>ReadCSV</span><span>(</span><span>16</span><span>ad101</span><span>)</span>
</pre></div>
<p>I imported <code>pandas as pd</code>, I imported <code>polars as pl</code> and I imported
<code>dask.dataframe as dd</code>.  But I didn't import <code>csvbase_client</code>.  Unnecessary -
there is no API.</p>
<h2>Enter fsspec</h2>
<p>How is this all working?  Have I perpetrated a kind of grand, <a href="https://www.wired.com/story/jia-tan-xz-backdoor/">Jia Tan</a>-style
jedi mind trick on the maintainers of these dataframe libraries, secretly
sneaking csvbase-specific code into their repos?</p>
<p>I haven't.  All of these dataframe libraries (and probably others I haven't
thought of) use a standard filesystem interface library, called
<a href="https://github.com/fsspec/filesystem_spec/">fsspec</a>.  csvbase-client just
implements an adaptor for fsspec:</p>
<div><pre><span></span><span>from</span> <span>fsspec.spec</span> <span>import</span> <span>AbstractFileSystem</span><span>,</span> <span>AbstractBufferedFile</span>

<span>class</span> <span>CSVBaseFileSystem</span><span>(</span><span>AbstractFileSystem</span><span>):</span>
    <span>def</span> <span>_open</span><span>(</span><span>self</span><span>,</span> <span>path</span><span>,</span> <span>mode</span><span>=</span><span>"rb"</span><span>):</span>
        <span>return</span> <span>CSVBaseFile</span><span>(</span><span>self</span><span>,</span> <span>path</span><span>,</span> <span>mode</span><span>)</span>

<span>class</span> <span>CSVBaseFile</span><span>(</span><span>AbstractBufferedFile</span><span>):</span>
    <span>def</span> <span>_fetch_range</span><span>(</span><span>self</span><span>,</span> <span>start</span><span>:</span> <span>int</span><span>,</span> <span>end</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>bytes</span><span>:</span>
        <span>...</span>
</pre></div>
<p>fsspec already comes with built-in adaptors for <a href="https://calpaterson.com/s3.html">object
stores</a>, webdav, Github, Dropbox and lots
more.  It's a pretty nice abstraction layer.  csvbase's client is just one more
adaptor.</p>
<p>For whatever reason, fsspec is not that well known.  It has less than 800 stars
<a href="https://github.com/fsspec/filesystem_spec/">on github</a>.  But it is well used:
it's downloaded <a href="https://pypistats.org/packages/fsspec">more than 8 million times a
day</a>, usually as an automatically
installed dependency of other libraries.  That actually makes it the 20th most
popular Python package - bigger in fact than Pandas.</p>
<p>At any rate, after my classes are written it just takes a short setuptools
incantation to wire my classes into place upon package install:</p>
<div><pre><span></span><span>from</span> <span>setuptools</span> <span>import</span> <span>setup</span>
<span>setup</span><span>(</span>
  <span>name</span><span>=</span><span>"csvbase-client"</span><span>,</span>
  <span>...</span><span>,</span> <span># [snip]</span>
  <span>entry_points</span><span>=</span><span>{</span>
    <span>"fsspec.specs"</span><span>:</span> <span>[</span>
      <span>"csvbase=csvbase_client.fsspec.CSVBaseFileSystem"</span><span>,</span>
    <span>],</span>
  <span>},</span>
<span>)</span>
</pre></div>
<p>Or in pyproject.toml:</p>
<div><pre><span></span><span>[project.entry-points."fsspec.specs"]</span><span></span>
<span>csvbase</span><span> </span><span>=</span><span> </span><span>"csvbase_client.fsspec.CSVBaseFileSystem"</span><span></span>
</pre></div>
<p>With all this working, the <code>csvbase://</code> url scheme becomes real and you can use
it inside anything which relies on fsspec, which is a surprisingly large number
of things.</p>
<h2>How to use fsspec in your own programs</h2>
<p>fsspec is pretty nice.  It's very useful when you want, for example, to write a
cli program that can write both to a file, and then later an S3 object.</p>
<p>Instead of calling the Python built-in <code>open</code>, you call <code>fsspec.open</code>.  It is a
mostly drop-in replacement.</p>
<div><pre><span></span><span>import</span> <span>fsspec</span>

<span>with</span> <span>fsspec</span><span>.</span><span>open</span><span>(</span><span>"csvbase://calpaterson/onion-vox-pops"</span><span>)</span> <span>as</span> <span>vox_pops_f</span><span>:</span>
   <span>print</span><span>(</span><span>vox_pops_f</span><span>.</span><span>read</span><span>(</span><span>100</span><span>))</span>
</pre></div>
<p>That's it.  It is extremely simple to integrate against.</p>
<p>There isn't just <code>open</code>, either, but <code>touch</code>, <code>rm</code>, <code>cp</code>, <code>mv</code> - the whole
gang.  <code>csvbase-client</code>'s support doesn't cover all of these yet, but that is
planned.</p>
<h2>And there's a cli tool</h2>
<p>I can't get out of writing a cli tool for csvbase.  There is no way to avoid
that - but I did make it a thin veneer over fsspec.</p>
<div><pre><span></span>$ csvbase-client table get calpaterson/alphabet
csvbase_row_id,number,letter
<span>1</span>,1,a
<span>2</span>,2,b
<span>3</span>,3,c
<span>[</span>you know the rest<span>]</span>
</pre></div>
<p>But <a href="https://csvbase.com/blog/5">other examples</a> are more fun:</p>
<div><pre><span></span>$ csvbase-client table get calpaterson/eurofxref-hist <span>|</span> <span>\</span>
grep USD <span>|</span> <span>\</span>
cut -d, -f <span>2</span>,4 <span>|</span> <span>\</span>
gnuplot -e <span>"set datafile separator ','; set term dumb; \</span>
<span>plot '-' using 1:2 with lines title 'usd'"</span>
</pre></div>
<p><img src="https://csvbase.com/blog-static/dumb-term.png" alt="a gnuplot graph in drawn in the
terminal"></p>
<h2>The bytes on the internet are free and you can take them home with you</h2>
<p>As with <a href="https://github.com/calpaterson/csvbase">csvbase proper</a>,
<a href="https://github.com/calpaterson/csvbase-client">csvbase-client</a> is open source,
so you can just <a href="https://github.com/calpaterson/csvbase-client/blob/main/csvbase_client/fsspec.py">take my
code</a>
as a starting point and write your own fsspec APIs.</p>
<p>I'm looking forward to expanding on it in future.  I'm particularly keen to use
fsspec to <a href="https://filesystem-spec.readthedocs.io/en/latest/features.html#mount-anything-with-fuse">mount csvbase.com as a
filesystem</a>
via FUSE.  That sounds fun.</p>
<p>Help me out:</p>
<ul>
<li>try <a href="https://pypi.org/project/csvbase-client/">csvbase-client</a></li>
<li>
do me a solid by <a href="https://github.com/calpaterson/csvbase-client">starring csvbase-client on
github</a><ul>
<li>star the <a href="https://github.com/calpaterson/csvbase">main
project</a> as well if you're feeling
extra generous</li>
<li>regardless, shoot <a href="https://github.com/fsspec/filesystem_spec/">fsspec</a> a
github star because they did almost the work</li>
</ul>
</li>
<li><a href="mailto:cal@calpaterson.com">email me your thoughts</a></li>
<li>or <a href="https://github.com/calpaterson/csvbase-client/issues">file bugs on github</a></li>
</ul>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft employees exposed internal passwords in security lapse (123 pts)]]></title>
            <link>https://techcrunch.com/2024/04/09/microsoft-employees-exposed-internal-passwords-security-lapse/</link>
            <guid>39988415</guid>
            <pubDate>Wed, 10 Apr 2024 08:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/04/09/microsoft-employees-exposed-internal-passwords-security-lapse/">https://techcrunch.com/2024/04/09/microsoft-employees-exposed-internal-passwords-security-lapse/</a>, See on <a href="https://news.ycombinator.com/item?id=39988415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Microsoft has resolved a security lapse that exposed internal company files and credentials to the open internet.</p>
<p>Security researchers Can Yoleri, Murat √ñzfidan and Egemen Ko√ßhisarlƒ± with SOCRadar, a cybersecurity company that helps organizations find security weaknesses, discovered an open and public storage server hosted on Microsoft‚Äôs Azure cloud service that was storing internal information relating to Microsoft‚Äôs Bing search engine.</p>
<p>The Azure storage server housed code, scripts and configuration files containing passwords, keys and credentials used by the Microsoft employees for accessing other internal databases and systems.</p>
<p>But the storage server itself was not protected with a password and could be accessed by anyone on the internet.</p>
<p>Yoleri told TechCrunch that the exposed data could potentially help malicious actors identify or access other places where Microsoft stores its internal files. Identifying those storage locations ‚Äúcould result in more significant data leaks and possibly compromise the services in use,‚Äù Yoleri said.</p>
<p>The researchers notified Microsoft of the security lapse on February 6, and Microsoft secured the spilling files on March 5.</p>
<p>It‚Äôs not known for how long the cloud server was exposed to the internet, or if anyone other than SOCRadar discovered the exposed data inside. When reached by email, a spokesperson for Microsoft did not provide comment by the time of publication. Microsoft did not say if it had reset or changed any of the exposed internal credentials.</p>
<p>This is the latest security gaffe at Microsoft as the company tries to rebuild trust with its customers after a series of cloud security incidents in recent years. In a similar security lapse last year, researchers found that <a href="https://www.vice.com/en/article/m7gb43/microsoft-employees-exposed-login-credentials-azure-github" target="_blank" rel="noopener">Microsoft employees were exposing their own corporate network logins</a> in code published to GitHub.</p>
<p>Microsoft also came under fire last year after the company admitted it did not know <a href="https://techcrunch.com/2023/09/08/microsoft-hacker-china-government-storm-0558/">how China-backed hackers stole an internal email signing key</a> that allowed the hackers broad access to Microsoft-hosted inboxes of senior U.S. government officials. An independent board of cyber experts tasked with investigating the email breach wrote in their report, published last week, that the hackers succeeded because of a ‚Äúcascade of security failures at Microsoft.‚Äù</p>
<p>In March, Microsoft said that <a href="https://techcrunch.com/2024/03/08/microsoft-ongoing-cyberattack-russia-apt-29/">it continues to counter an ongoing cyberattack</a> that allowed Russian state-backed hackers to steal portions of the company‚Äôs source code and internal emails from Microsoft corporate executives.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Verified curl (136 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2024/04/10/verified-curl/</link>
            <guid>39988269</guid>
            <pubDate>Wed, 10 Apr 2024 08:20:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2024/04/10/verified-curl/">https://daniel.haxx.se/blog/2024/04/10/verified-curl/</a>, See on <a href="https://news.ycombinator.com/item?id=39988269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Don‚Äôt trust. Verify.</p>


<div>
<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2024/04/state-sponsor-your-open-source.png"><img decoding="async" width="1979" height="2800" src="https://daniel.haxx.se/blog/wp-content/uploads/2024/04/state-sponsor-your-open-source.png" alt=""></a><figcaption><em>I could not resist making a fake book cover</em></figcaption></figure></div>


<p>Here follows a brief description on how you can detect if the curl package would ever <a href="https://en.wikipedia.org/wiki/XZ_Utils_backdoor">make an xz</a>.</p>



<p>xz (and its library liblzma) was presumably selected as a target because it is an often used component and by extension via systemd it often used by openssh in several Linux distros. libcurl is probably an even more widely used software component and if infected, could potentially serve as an effective vessel to distribute evil into the world.</p>



<p>Conceivably, the xz attackers have infiltrated more than one other Open Source project to cover their bases. Which ones?</p>



<h2>No inexplicable binary blobs</h2>



<p>First, you can verify that there are no binary blobs stored in git that could host an encrypted attack payload, planted there for the future.</p>



<p>Every file in <a href="https://github.com/curl/curl">the curl git repository</a> has a benign meaning and purpose. As part of the products, the documentation, tooling or the test suites etc.</p>



<p>Without any secret ‚Äúhide-out‚Äù in the git repository, you know that any backdoor needs to be provided either in plain code or using some crazy weird <a href="https://en.wikipedia.org/wiki/Steganography">steganography</a>. Or get inserted into the tarballs with content not present in git ‚Äì read on for how to verify that this is not happening.</p>



<h2>No disabled fuzzers</h2>



<p>The xz attack would have been detected by proper fuzzing (and valgrind use) which is why the attacker made sure to sneakily disable such automated checks of code that was present in git.</p>



<p>While somewhat hard to verify, you can make sure that no such activities have been done in curl‚Äôs fuzzing or curl‚Äôs automated and CI testing,</p>



<h2>No hidden payloads in tarballs</h2>



<p>In the curl project we <em>generate</em> several files as part of the release process and those files end up in the release tarball. This means that not all files in the tarball are found in the git repository. (Because we don‚Äôt commit generated files.)</p>



<p>The generated files are produced with a small set of tools, and these tools use the source code available in git at the release tag. Anyone can check out the same code from that same release tag, make sure to have the corresponding tools (and versions) installed and then generate a version of the tarball themselves ‚Äì to verify that this tarball indeed becomes an identical copy of the public release.</p>



<p>That process verifies that the tarballs we ship are generated only with legitimate tools and that the release contents originate only from the files present in git. No secret sauce added in the process. No malicious code can get inserted.</p>



<h2>Reproducible tarballs</h2>



<p>We have recently improved reproducibility as a direct result of the post xz-attack debate. To make sure that a repeated tarball creation actually produces the exact same results, but also to make it easier for others to verify our release tarballs. With more documentation (releases now contain documentation of exactly which tools and versions that generated the tarball) and by making it easier to run the exact same virtual machine and tool setup like the one that created the release. We aim to soon <a href="https://github.com/curl/curl/pull/13250">provide a Dockerfile</a> to make this process even smoother.</p>



<p>We also verify tarball reproducibility in a CI job: generating a release tarball with a given timestamp produces the identical binary output when done again for the same timestamp.</p>



<h2>Signed tarballs</h2>



<p>As an extra detail, everyone can also verify that the released tarballs are in fact shipped by me Daniel personally, as they are always signed with my GPG key as part of the release process. This should at least prove that new releases are made with the same keys as previous ones were, which should with a reasonable probability be me.</p>



<p>The signatures also help verify that the tarballs have not been tampered with in transition, from the point I generated them to the moment they land in your download directory. curl downloads are normally distributed via a third-party CDN which we normally trust of course, but if it would ever be breached or similar, a modified tarball would be detected when the digital signature is verified.</p>



<p>We do not provide checksums for the tarballs simply because providing checksums next to the downloads adds almost no extra verification. If someone can tamper with the tarballs, they can probably update the webpage which a fake checksum as well.</p>



<h2>Signed commits</h2>



<p>All commits done to curl done by me are signed, You can verify that I did them. Not all committers in the project do them signed, unfortunately. We hope to increase the share going forward. Over the last 365 days, 73% of the curl commits were signed.</p>



<p>These signatures only verify that the commits where done by a maintainer of the curl project (or someone who controls that account). A maintainer you may not trust and who might not be known under their real name and you do not even know in which country they live. And of course, even a trusted maintainer can suddenly go rogue.</p>



<h2>Is the content in git benign?</h2>



<p>The process above only verifies that tarballs are indeed generated (only) from contents present in git and that they are unaltered from the moment I made them.</p>



<p>How do you know that the contents in git does not contain any backdoors or other vulnerabilities?</p>



<p>Without trusting anyone else‚Äôs opinions and without just relying on the fact that you can run the test suite, fuzzers and static code analyzers without finding anything, you can review it. Or pay someone else to review it.</p>



<p>We have had <a href="https://curl.se/docs/audits.html">curl audited several times</a> by external organizations, but can you trust claimed random audits?</p>



<h2>Anonymous contributors</h2>



<p>We regularly accept contributions from anonymous and pseudonymous contributors in curl ‚Äì and we always have. Our policy says that if a contribution is good: if it passes review and all tests run green, we have no reason to deny it ‚Äì in the name of progress and improvement. That is also why we accept even single-letter typo fixes: even a very small fix is a step in the right direction.</p>



<p>A (to me) surprisingly large amount of contributions are done by people who do not state a full real name. They may chose to be anonymous for various reasons ‚Äì we do not ask. Maybe they fear retaliation if they would propose something that ends up buggy? Sometimes people want to hide their affiliation/origin so that their contribution is not associated with the organization they work at. Another reason sometimes mentioned is that women do it to avoid revealing themselves as female. etc. As  I said: we do not ask so I cannot tell for sure.</p>



<h2>Anonymous maintainers</h2>



<p>We do not have anonymous maintainers, but we don‚Äôt actually have rules against it.</p>



<p>Right now, we have 18 members in the GitHub curl organization with the <em>rights</em> to push commits. I have not met all of them. I have not even seen the faces of all of them. They have all proven themselves worthy of their administrative rights based on their track record. I cannot know if anyone of them is using a false identity and I do not ask nor keep track in which country they reside. A former top maintainer in the curl projected even landed a large amount of changes under a presumed/false name during several years.</p>



<p>If a curl maintainer suddenly goes rogue and attempts to land malicious content, our only effective remedy is review. To rely on the curl community to have eyes on the changes and to test things.</p>



<h2>Can curl be targeted?</h2>



<p>I think it would be very hard but I can of course not rule it out. Possibly I am also blind for our weaknesses because I have lived with them for so long.</p>



<p>Everyone can help the greater ecosystem by verifying a package or two. If we all tighten all screws just a little bit more, things will get better.</p>



<h2>Vulnerabilities</h2>



<p>I maintain that planting a backdoor in curl code is so infuriatingly hard to achieve that efforts and energy are probably much rather spent on  finding security vulnerabilities and ways to exploit them. After all, we have <a href="https://curl.se/docs/security.html">155 published past vulnerabilities</a> in curl so far, out of which 42 have been at severity high or critical.</p>



<p>I can be fairy sure that none of those 42 somewhat serious issues were deliberately planted, because just about every one of them were found in code that I personally authored‚Ä¶</p>



<p>People often ask. But I have <strong>never</strong> seen a backdoor attempt in curl. Maybe that is just me being naive.</p>



<h2>Credits</h2>



<p>Top Image by <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=8577615">Gerd Altmann</a> from <a href="https://pixabay.com//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=8577615">Pixabay</a>. Fake book cover by Daniel Stenberg.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three major LLM releases in 24 hours (121 pts)]]></title>
            <link>https://simonwillison.net/2024/Apr/10/weeknotes-llm-releases/</link>
            <guid>39987769</guid>
            <pubDate>Wed, 10 Apr 2024 07:01:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2024/Apr/10/weeknotes-llm-releases/">https://simonwillison.net/2024/Apr/10/weeknotes-llm-releases/</a>, See on <a href="https://news.ycombinator.com/item?id=39987769">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2024/Apr/10/weeknotes-llm-releases/">

<p>10th April 2024</p>

<p>I‚Äôm a bit behind on my <a href="https://simonwillison.net/tags/weeknotes/">weeknotes</a>, so there‚Äôs a lot to cover here. But first... a review of the last 24 hours of Large Language Model news. All times are in US Pacific.</p>
<ul>
<li>11:01am: Google Gemini Pro 1.5 hits general availability, here‚Äôs <a href="https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html">the blog post</a>‚Äîtheir 1 million token context GPT-4 class model now has no waitlist, is available to anyone in 180 countries (not including Europe or the UK as far as I can tell) and most impressively all the API has a <strong>free tier</strong> that allows up to 50 requests a day, though rate limited to 2 per minute. Beyond that you can pay $7/million input tokens and $21/million output tokens, which is slightly less than GPT-4 Turbo and a little more than Claude 3 Sonnet. Gemini Pro also now support audio inputs and system prompts.</li>
<li>11:44am: OpenAI finally released the non-preview version of <strong>GPT-4 Turbo</strong>, integrating GPT-4 Vision directly into the model (previously it was separate). Vision mode now supports both functions and JSON output, previously unavailable for image inputs. OpenAI also claim that the new model is <a href="https://twitter.com/OpenAI/status/1777772582680301665">‚ÄúMajorly improved‚Äù</a> but no-one knows what they mean by that.</li>
<li>6:20pm (3:20am in their home country of France): Mistral <a href="https://twitter.com/MistralAI/status/1777869263778291896">tweet a link</a> to a 281GB magnet BitTorrent of <strong>Mixtral 8x22B</strong>‚Äîtheir latest openly licensed model release, significantly larger than their previous best open model Mixtral 8x7B. I‚Äôve not seen anyone get this running yet but it‚Äôs likely to perform extremely well, given how good the original Mixtral was.</li>
</ul>
<p>And while it wasn‚Äôt released today (it came out <a href="https://txt.cohere.com/command-r-plus-microsoft-azure/">last week</a>), this morning Cohere‚Äôs Command R+ (an excellent openly licensed model) <a href="https://fedi.simonwillison.net/@simon/112242034813525962">reached position 6 on the LMSYS Chatbot Arena Leaderboard</a>‚Äîthe highest ever ranking for an open weights model.</p>
<p>Since I have a lot of software that builds on these models, I spent a bunch of time today publishing new releases of things.</p>

<p>I‚Äôve been working on <a href="https://datasette.io/plugins/datasette-extract">Datasette Extract</a> for a while now: it‚Äôs a plugin for Datasette that adds structured data extraction from unstructured text, powered by GPT-4 Turbo.</p>
<p>I updated it for the new model releases <a href="https://github.com/datasette/datasette-extract/releases/tag/0.1a4">this morning</a>, and decided to celebrate by making <a href="https://www.youtube.com/watch?v=g3NtJatmQR0">a video</a> showing what it can do:</p>
<iframe src="https://www.youtube.com/embed/g3NtJatmQR0?si=OcLs6MqykLTFvZb3" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen"> </iframe>
<p>I want to start publishing videos like this more often, so this felt like a great opportunity to put that into practice.</p>
<p>The Datasette Cloud blog hasn‚Äôt had an entry in a while, so I <a href="https://www.datasette.cloud/blog/2024/datasette-extract/">published screenshots and notes there</a> to accompany the video.</p>
<h4 id="gemini-pro-system-prompts">Gemini Pro 1.5 system prompts</h4>
<p>I really like system prompts‚Äîextra prompts you can pass to an LLM that give it instructions about how to process the main input. They‚Äôre sadly <a href="https://simonwillison.net/2023/Apr/14/worst-that-can-happen/#gpt4">not a guaranteed solution for prompt injection</a>‚Äîeven with instructions separated from data by a system prompt you can still over-ride them in the main prompt if you try hard enough‚Äîbut they‚Äôre still useful for non-adversarial situations.</p>
<p><strong><a href="https://github.com/simonw/llm-gemini/releases/tag/0.1a2">llm-gemini 0.1a2</a></strong> adds support for them, so now you can do things like this:</p>
<div><pre>llm -m p15 <span><span>'</span>say hi three times three different ways<span>'</span></span> \
  --system <span><span>'</span>in spanish<span>'</span></span></pre></div>
<p>And get back output like this:</p>
<blockquote>
<p>¬°Hola! üëã ¬°Buenos d√≠as! ‚òÄÔ∏è ¬°Buenas tardes! üòä</p>
</blockquote>
<p>Interestingly ‚Äúin german‚Äù doesn‚Äôt include emoji, but ‚Äúin spanish‚Äù does.</p>
<p>I had to reverse-engineer the REST format for sending a system prompt from the Python library as the REST documentation hasn‚Äôt been updated yet‚Äî<a href="https://github.com/simonw/llm-gemini/issues/6#issuecomment-2046460319">notes on that in my issue</a>.</p>
<h4 id="datasette-enrichments-turbo">datasette-enrichments-gpt using GPT-4 Turbo</h4>
<p>Another small release: the <a href="https://datasette.io/plugins/datasette-enrichments-gpt">datasette-enrichments-gpt</a> plugin can enrich data in a table by running prompts through GPT-3.5, GPT-4 Turbo or GPT-4 Vision. I released <a href="https://github.com/datasette/datasette-enrichments-gpt/releases/tag/0.4">version 0.4</a> switching to the new GPT-4 Turbo model.</p>
<h4 id="weeknotes-178-everything-else">Everything else</h4>
<p>That covers today... but my last weeknotes were nearly four weeks ago! Here‚Äôs everything else, with a few extra annotations:</p>
<h4 id="weeknotes-178-blog-entries">Blog entries</h4>
<p>All five of my most recent posts are about ways that I use LLM tools in my own work‚Äîsee also my <a href="https://simonwillison.net/series/using-llms/">How I use LLMs and ChatGPT</a> series.</p>
<ul>
<li><a href="https://simonwillison.net/2024/Apr/8/files-to-prompt/">Building files-to-prompt entirely using Claude 3 Opus</a></li>
<li><a href="https://simonwillison.net/2024/Mar/30/ocr-pdfs-images/">Running OCR against PDFs and images directly in your browser</a></li>
<li><a href="https://simonwillison.net/2024/Mar/26/llm-cmd/">llm cmd undo last git commit‚Äîa new plugin for LLM</a></li>
<li><a href="https://simonwillison.net/2024/Mar/23/building-c-extensions-for-sqlite-with-chatgpt-code-interpreter/">Building and testing C extensions for SQLite with ChatGPT Code Interpreter</a></li>
<li><a href="https://simonwillison.net/2024/Mar/22/claude-and-chatgpt-case-study/">Claude and ChatGPT for ad-hoc sidequests</a></li>
</ul>
<h4 id="weeknotes-178-releases">Releases</h4>
<p>Many of these releases relate to ongoing work on <a href="https://www.datasette.cloud/">Datasette Cloud</a>. In particular there‚Äôs a flurry of minor releases to add descriptions to the action menu items added by various plugins, best illustrated by this screenshot:</p>
<p><img src="https://static.simonwillison.net/static/2024/action-menus.png" alt="A screenshot showing the database actions, table actions and row actions menus in Datasette running on Datasette Cloud. The database menu items are: Upload CSV. Create a new table by uploading a CSV file. Execute SQL write. Run queries like insert/update/delete against this database. Query this database with Al assistance. Ask a question to build a SQL query. Create table with Al extracted data. Paste in text or an image to extract structured data. Edit database metadata. Set the description, source and license for this database. Create a table. Define a new table with specified columns. Create table with pasted data. Paste in JSON, CSV or TSV data (e.g. from Google Sheets). Export this database. Create and download a snapshot of this SQLite database (1.3 GB). The table menu items: Delete this table. Delete table and all rows within it. Enrich selected data. Run a data cleaning operation against every selected row. Query this table with Al assistance. Ask a question to build a SQL query. Extract data into this table with Al. Paste in text or an image to extract structured data. Edit table metadata. Set the description, source and license for this table. Edit table schema. Rename the table, add and remove columns.... Make table public. Allow anyone to view this table. Configure full-text search. Select columns to make searchable for this table. The row menu items: Enrich this row. Run a dat acleaning operation against this row."></p>
<ul>
<li>
<strong><a href="https://github.com/datasette/datasette-enrichments-gpt/releases/tag/0.4">datasette-enrichments-gpt 0.4</a></strong>‚Äî2024-04-10<br>Datasette enrichment for analyzing row data using OpenAI‚Äôs GPT models</li>
<li>
<strong><a href="https://github.com/simonw/llm-gemini/releases/tag/0.1a2">llm-gemini 0.1a2</a></strong>‚Äî2024-04-10<br>LLM plugin to access Google‚Äôs Gemini family of models</li>
<li>
<strong><a href="https://github.com/simonw/datasette-public/releases/tag/0.2.3">datasette-public 0.2.3</a></strong>‚Äî2024-04-09<br>Make specific Datasette tables visible to the public</li>
<li>
<strong><a href="https://github.com/datasette/datasette-enrichments/releases/tag/0.3.2">datasette-enrichments 0.3.2</a></strong>‚Äî2024-04-09<br>Tools for running enrichments against data stored in Datasette</li>
<li>
<strong><a href="https://github.com/datasette/datasette-extract/releases/tag/0.1a4">datasette-extract 0.1a4</a></strong>‚Äî2024-04-09<br>Import unstructured data (text and images) into structured tables</li>
<li>
<strong><a href="https://github.com/simonw/datasette-cors/releases/tag/1.0">datasette-cors 1.0</a></strong>‚Äî2024-04-08<br>Datasette plugin for configuring CORS headers</li>
<li>
<strong><a href="https://github.com/simonw/asgi-cors/releases/tag/1.0">asgi-cors 1.0</a></strong>‚Äî2024-04-08<br>ASGI middleware for applying CORS headers to an ASGI application</li>
<li>
<strong><a href="https://github.com/simonw/files-to-prompt/releases/tag/0.2.1">files-to-prompt 0.2.1</a></strong>‚Äî2024-04-08<br>Concatenate a directory full of files into a single prompt for use with LLMs</li>
<li>
<strong><a href="https://github.com/datasette/datasette-embeddings/releases/tag/0.1a3">datasette-embeddings 0.1a3</a></strong>‚Äî2024-04-08<br>Store and query embedding vectors in Datasette tables</li>
<li>
<strong><a href="https://github.com/datasette/datasette-studio/releases/tag/0.1a3">datasette-studio 0.1a3</a></strong>‚Äî2024-04-06<br>Datasette pre-configured with useful plugins. Experimental alpha.</li>
<li>
<strong><a href="https://github.com/datasette/datasette-paste/releases/tag/0.1a5">datasette-paste 0.1a5</a></strong>‚Äî2024-04-06<br>Paste data to create tables in Datasette</li>
<li>
<strong><a href="https://github.com/datasette/datasette-import/releases/tag/0.1a4">datasette-import 0.1a4</a></strong>‚Äî2024-04-06<br>Tools for importing data into Datasette</li>
<li>
<strong><a href="https://github.com/datasette/datasette-enrichments-quickjs/releases/tag/0.1a2">datasette-enrichments-quickjs 0.1a2</a></strong>‚Äî2024-04-05<br>Enrich data with a custom JavaScript function</li>
<li>
<strong><a href="https://github.com/simonw/s3-credentials/releases/tag/0.16.1">s3-credentials 0.16.1</a></strong>‚Äî2024-04-05<br>A tool for creating credentials for accessing S3 buckets</li>
<li>
<strong><a href="https://github.com/simonw/llm-command-r/releases/tag/0.2">llm-command-r 0.2</a></strong>‚Äî2024-04-04<br>Access the Cohere Command R family of models</li>
<li>
<strong><a href="https://github.com/simonw/llm-nomic-api-embed/releases/tag/0.1">llm-nomic-api-embed 0.1</a></strong>‚Äî2024-03-30<br>Create embeddings for LLM using the Nomic API</li>
<li>
<strong><a href="https://github.com/simonw/textract-cli/releases/tag/0.1">textract-cli 0.1</a></strong>‚Äî2024-03-29<br>CLI for running files through AWS Textract</li>
<li>
<strong><a href="https://github.com/simonw/llm-cmd/releases/tag/0.1a0">llm-cmd 0.1a0</a></strong>‚Äî2024-03-26<br>Use LLM to generate and execute commands in your shell</li>
<li>
<strong><a href="https://github.com/simonw/datasette-write/releases/tag/0.3.2">datasette-write 0.3.2</a></strong>‚Äî2024-03-18<br>Datasette plugin providing a UI for executing SQL writes against the database</li>
</ul>
<h4 id="weeknotes-178-tils">TILs</h4>
<ul>
<li>
<a href="https://til.simonwillison.net/macos/impaste">impaste: pasting images to piped commands on macOS</a>‚Äî2024-04-04</li>
<li>
<a href="https://til.simonwillison.net/go/installing-tools">Installing tools written in Go</a>‚Äî2024-03-26</li>
<li>
<a href="https://til.simonwillison.net/chrome/headless">Google Chrome --headless mode</a>‚Äî2024-03-24</li>
<li>
<a href="https://til.simonwillison.net/clickhouse/github-public-history">Reviewing your history of public GitHub repositories using ClickHouse</a>‚Äî2024-03-20</li>
<li>
<a href="https://til.simonwillison.net/npm/self-hosted-quickjs">Running self-hosted QuickJS in a browser</a>‚Äî2024-03-20</li>
<li>
<a href="https://til.simonwillison.net/python/comparing-version-numbers">Programmatically comparing Python version strings</a>‚Äî2024-03-17</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: CompressX, my FFmpeg wrapper for macOS (111 pts)]]></title>
            <link>https://compressx.app</link>
            <guid>39987579</guid>
            <pubDate>Wed, 10 Apr 2024 06:32:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://compressx.app">https://compressx.app</a>, See on <a href="https://news.ycombinator.com/item?id=39987579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><dl><p><dt>Up to 90% file size reduction.</dt> <dd>Compress your videos and images without significantly losing quality, powered by FFmpeg</dd></p><p><dt>Monitor folder for automatic compression.</dt> <dd>Automatically compress new files in monitored folders</dd></p><p><dt>Support 5 quality options.</dt> <dd>Further reduce video size to better suit your requirements.</dd></p><p><dt>Gif conversion.</dt> <dd>Just drop a video, select quality, FPS, and voil√†.</dd></p><p><dt>Compatible with transparent video.</dt> <dd>Compress video with transparent background with the most powerful Apple APIs.</dd></p><p><dt>Export to MP4 or WebM.</dt> <dd>Export the compressed video in various formats, such as MP4 and WebM.</dd></p><p><dt>Multiple files at once.</dt> <dd>Increase your productivity by compressing multiple files simultaneously.</dd></p><p><dt>Raycast extension.</dt> <dd>Speed up your workflow by sending your file to Raycast.</dd></p><p><dt>Work 100% offline.</dt> <dd>Your files never leave your computer.</dd></p></dl></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Used Monolithic Architecture to Ship Threads in Only Five Months (174 pts)]]></title>
            <link>https://www.infoq.com/news/2024/04/meta-threads-instagram-5-months/</link>
            <guid>39987466</guid>
            <pubDate>Wed, 10 Apr 2024 06:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.infoq.com/news/2024/04/meta-threads-instagram-5-months/">https://www.infoq.com/news/2024/04/meta-threads-instagram-5-months/</a>, See on <a href="https://news.ycombinator.com/item?id=39987466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<p>Zahan Malkani <a href="https://qconlondon.com/presentation/apr2024/0-1-shipping-threads-5-months">talked during QCon London 2024 about Meta's journey</a> from identifying the opportunity in the market to shipping the Threads application only five months later. The company leveraged Instagram's existing monolithic architecture and quickly iterated to create a new text-first microblogging service in record time.</p>

<p>Soon after Elon Musk acquired Twitter, Meta saw an opportunity to create a competing service but had little time to launch it to attract existing Twitter users, who were looking for alternatives. The company initially tested whether better support for text-based posts on Instagram would be sufficient to sway some Twitter users over to Meta's products, but these efforts didn‚Äôt attract enough new users.</p>

<p>Meta formed a small team to devise an approach to delivering a new service that would directly compete with Twitter in just a few months. <a href="https://www.linkedin.com/in/zahanm">Zahan Malkani</a>, a software engineer at Meta, shared how his team was able to reuse the existing Instagram backend components, data stores, and large parts of the existing infrastructure stack but customize them to offer functionality comparable to what now is X.</p>

<p><img alt="" data-src="news/2024/04/meta-threads-instagram-5-months/en/resources/1meta-instagram-arch-1712608215163.jpeg" src="https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2024/04/meta-threads-instagram-5-months/en/resources/1meta-instagram-arch-1712608215163.jpeg" rel="share"></p>

<p><em>Instagram / Threads High-Level Architecture (Source: <a href="https://www.linkedin.com/posts/danielbryantuk_qconlondon-ugcPost-7183060633251147776-a6Fx?utm_source=share&amp;utm_medium=member_desktop">Daniel Bryant‚Äôs LinkedIn post</a>)</em></p>

<p>Theads's technology stack is almost identical to Instagram's, consisting of a few monolithic application components and dedicated data stores. The main backend component is a large Python codebase using a custom version of the <a href="https://www.djangoproject.com/">Django Framework</a>, named Distillery, that integrates with an older PHP component called WWW. The data is stored in <a href="https://engineering.fb.com/2013/06/25/core-infra/tao-the-power-of-the-graph/">TAO</a>, a write-though cache that operates on a <a href="https://en.wikipedia.org/wiki/Graph_database">graph data model</a>, which in turn uses UDB, a sharded <a href="https://www.mysql.com/">MySQL</a> deployment, that stores all the data. Additionally, the <a href="https://engineering.fb.com/2021/08/06/core-infra/zippydb/">ZippyDB</a> key-value cache stores transient data, and <a href="https://engineering.fb.com/2020/08/17/production-engineering/async/">Async</a>, a serverless function compute platform, is used to execute asynchronous jobs outside of peak hours.</p>

<p>While working on Threads, the team used a <a href="https://www.apollographql.com/docs/technotes/TN0032-sdui-basics">Server-Driven UI (SDUI)</a> approach to enable a quick experimentation cycle in the early days of the project, using thousands of company employees for feedback.</p>

<p>Despite the apparent advantages of reusing Instagram's platform for Threads (much faster delivery time), Malkani admitted the company introduced a substantial amount of technical debt that must be addressed in the future. The team is working on gradually separating the data models from Instagram's as the Threads service gains new functionality so that both platforms can be separated, but the process will take some time.</p>

<p>Malkani recounted the stressful period when Threads launched in July 2023, including a few mishaps, like when users in&nbsp;Southeast Asia and other time zones were&nbsp;able to download the mobile app before the US team was ready to allow traffic in, due to the time zone confusion. Engineers also had to improve scalability of some processes to allow for importing followers from Instagram. The team has been working tirelessly to address any issues and ensure the stability of the platform, which saw unprecedented adoption. Ten million users downloaded the app on the first day, and 100 million in the first five days.</p>

<p>Since the launch, the team delivered new features like the "following" feed, trending conversations, and the limited availability of API access for reading and writing posts. Threads team is also actively working on adopting <a href="https://www.w3.org/TR/activitypub/">the ActivityPub protocol</a>, allowing users to share their posts to other social networks that support the protocol.</p>

								









  
    <div> <!-- main wrapper for authors section -->
        <h2>About the Author</h2> <!-- section title -->

        
            
                
            
            <div data-id="author-Rafal-Gancarz">
                    <h4><strong>Rafal Gancarz</strong></h4>
                    
                </div>
        
    </div>

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A science fiction obsession led me to psychological war (157 pts)]]></title>
            <link>https://buttondown.email/thehypothesis/archive/how-a-science-fiction-obsession-led-me-to/</link>
            <guid>39986593</guid>
            <pubDate>Wed, 10 Apr 2024 03:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.email/thehypothesis/archive/how-a-science-fiction-obsession-led-me-to/">https://buttondown.email/thehypothesis/archive/how-a-science-fiction-obsession-led-me-to/</a>, See on <a href="https://news.ycombinator.com/item?id=39986593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <date>
                    
                        April 9, 2024
                    </date>
                
                

                

                
                    
                        <p>I've spent the past three years researching and writing a book about the history of psychological warfare in the United States. It‚Äôs called <a href="https://wwnorton.com/books/9780393881516?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank"><em>Stories Are Weapons: Psychological Warfare and the American Mind</em></a><em>, </em>and it comes out on June 4. The subject crept up on me, and not for the reasons you might think.</p>
<p>It all started over a decade ago at a science fiction convention in San Diego. I was talking to the writer Eugene Fisher about obscure writers that we loved. He mentioned Cordwainer Smith, a mid-twentieth century author who had written about human-animal hybrids of the distant future who led a revolution against their cyborg masters. It sounded amazing and weird, and I made a mental note to pick up some of Smith‚Äôs work. It was only later that I discovered that Cordwainer Smith was the pen name of Paul Linebarger, an intelligence operative who wrote the first Army manual devoted to the practice of psychological warfare in 1948.</p>
<p>I had to know more. So I started digging, and what follows is some of what I found. I was only able to cram a few of these gems into my book, so I've got a treasure trove of stuff here that I've been dying to talk about.</p>
<p>Linebarger‚Äôs father was a judge in the Philippines who became a devoted follower of Chinese nationalist Sun Yat-Sen. As a result, the young writer spent long stretches of his childhood under the tutelage of his godfather Sun Yat-Sen in China, learning statecraft from his father‚Äôs circle and Mandarin in school. He grew up with two names: ÊûóÁôΩ‰πê (Lin Bai-lo) and Paul Linebarger. As an adult, he published science fiction as Cordwainer Smith, realist fiction under the name Felix C. Forrest, as well as a spy novel and an unpublished pop psychology book under the name Carmichael Smith. As a professional psywarrior, he worked to overthrow the Communists in China ‚Äì not for the glory of America, but to continue the nationalist project of his mentor Sun Yat-Sen.&nbsp;</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/74f2ad0d-1868-4f64-9556-6e84b9a3ca42.png?w=960&amp;fit=max"><figcaption>The 1948 edition of "Psychological Warfare," and "We the Underpeople," a collection of Cordwainer Smith's short stories and a novel.</figcaption></figure>
<p>Now declassified, Linebarger‚Äôs <em>Psychological Warfare</em> is available from a number of print-on-demand publishers. I ordered a copy online, and read it alongside a collection of Cordwainer Smith stories called <em>We the Underpeople</em>. I couldn‚Äôt believe the same person had written them. This guy who wrote about subversive cat women and robot cities and weapons made from angry psychic weasels and mind control sex between people who are literally floating naked inside a chamber of flames ‚Äì he had <em>also</em> codified the U.S. military‚Äôs approach to psyops at the dawn of the Cold War? <em>Really??</em></p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/18215c15-3639-4b96-9c48-6c93a20f8e31.jpg?w=960&amp;fit=max"><figcaption>An array of membership and ID cards that Linebarger saved, now preserved among his papers at the Hoover Institute. Note that his "mystery writers" name is Carmichael Smith, a name he used to publish a Cold War novel called "Atomsk." Under his legal name, he was part of the Cosmos Club, a private club in DC for thought leaders; and of course he was an Eisenhower man.</figcaption></figure>
<p>I‚Äôm not the first person to ask this question using italics and lots of question marks. A miniscule cottage industry of writing about Linebarger‚Äôs life explores whether he was <a href="https://elms.faculty.ucdavis.edu/wp-content/uploads/sites/98/2014/07/20021-Behind-the-Jet1.pdf?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">secretly delusional</a>, or perhaps <a href="https://reactormag.com/the-what-he-did-the-poetic-science-fiction-of-cordwainer-smith/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">dropping subversive messages</a> in his stories. Gary K. Wolfe, a literary critic who has <a href="https://www.jstor.org/stable/4239107?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">written quite a bit</a> about Linebarger‚Äôs fiction, told me that some fans thought the author had to be a time traveler because his futures felt so vivid and bizarrely detailed. There are even questions surrounding the people who study Linebarger. <a href="https://nevalalee.wordpress.com/about/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">Alec Nevala-Lee</a>, author of <em>Astounding: John W. Campbell, Isaac Asimov, Robert A. Heinlein, L. Ron Hubbard, and the Golden Age of Science Fiction</em>, said that he‚Äôs heard a lot of wild speculation about UC Davis psychology professor <a href="https://www.cordwainer-smith.com/scholarly.htm?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">Alan C. Elms</a>, who spent decades writing a biography of Linebarger, but never published it for mysterious reasons.&nbsp;</p>
<p>My point is that Paul Linebarger was a psyop specialist whose life history reads like a psyop. It makes you want to do your own research, as the conspiracy influencers say. I couldn‚Äôt stop thinking about Linebarger, but it wasn‚Äôt because I thought he was some kind of time traveling superspy. His work made me realize how much American propaganda strategies owed to science fiction.&nbsp;</p>
<p>Eventually, I followed my curiosity to the Hoover Institution Library &amp; Archive at Stanford University, where Linebarger‚Äôs papers are kept alongside his father‚Äôs.</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/7c91b14c-5ac7-4497-aecb-03eb9e28abea.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>This and the image below are from Linebarger‚Äôs personal diaries, which he kept between the ages of 10 and 16. Above is a note from October 17, 1926, when he was 13 years old. ‚ÄúI love Shanghai. Paradise!!!‚Äù he scrawls. ‚ÄúI don‚Äôt want to go away. Never! Never!! Never!!!!!!‚Äù He had just spent two years in China with his family, and was very enthusiastic about travel.</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/5b7ed81d-834a-4e6d-ac7a-1793af7fb91e.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>Two photos taken February ninth, 1929. Linebarger was 15 years old, and was in his first year at George Washington University.&nbsp;</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/51499013-2138-4d2f-9e2c-05229ba4e0a1.jpg?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>These are some slips of paper and pictures he kept tucked into the front flap of his teen journal: Chinese language practice, a picture of himself on a ship with a group of his father‚Äôs compatriots and Sun Yat-Sen followers, a picture of the Horsehead Nebula cut out from a magazine, and a list of women‚Äôs names (likely girls he‚Äôd had crushes on ‚Äì his journals are full of urgent romantic commentary). It was wild to peer into the baby mind of a psywarrior, to see how closely his childhood interests aligned with his adult profession. He approached science fiction and international policy as two strands in the same project: Both were about explaining alien civilizations to each other, with a very specific goal in mind.</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/66e01d49-e79f-4771-9c14-5995e81ae25d.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>The fragment of typewritten manuscript above is from a book called ‚ÄúConversations with Sun Yat-sen,‚Äù which he co-wrote with his father in the early 1930s. It‚Äôs from the introduction, written exclusively by the younger Linebarger, when he was both a college student and an his father‚Äôs secretary, helping with policy and intelligence analysis for the Chinese nationalist government. He wanted to sow empathy for China among Americans, especially at a time when racist immigration policies and political ignorance had distorted many people's understanding of what was happening across the Pacific.</p>
<p>He writes: ‚ÄúChina the Nation, in the mind of Sun Yat-sen, is the most difficult of all his principles to interpret to the Western understanding. Nationalism is so simple and intelligible a phenomenon when preached by Hitler and Mussolini that is seems impossible that any other doctrines should be nationalistic and yet run counter to the chauvinisms of the modern world.‚Äù</p>
<p>Linebarger goes on to describe Sun Yat-sen as something of a science fiction writer, teaching his people about alien worlds beyond China. ‚ÄúIt was the duty of Sun Yat-sen to persuade a world that it was no world, but a nation; to persuade his fellow-countrymen that their customs and traditions were not the universal laws of reason, but only the peculiarly fine development of one civilization; to teach them that their world, whence patriotic and religious wars had long been banished, had to contend with a narrowing universe which had brought forth other worlds, fantastically different, upon the same globe.‚Äù</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/bfa8b895-225c-423c-84d7-0e78655c3ea1.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>I had to know more about where this overlap between genre fiction and psychological warfare began. So I delved deeper -- reading histories, interviewing experts and practitioners -- and I found examples of U.S. psyops going back to the nation's earliest days. Two hundred years ago, propagandists were using narrative techniques borrowed from many kinds of popular storytelling: tabloid journalism, fantasy, cowboy stories, adventure tales, comedy, horror. This was a tradition that Linebarger had inherited from generations of Americans before him. In the nineteenth century, for example, popular Western dime novels inspired pundits who pushed "manifest destiny" as a policy. Newspaper accounts justifying the United States' wars on Indigenous nations often read like cowboy adventures set in an unclaimed, virgin land. Using the tropes of popular entertainment helped pro-expansionists sell settlers on the U.S. government policy of coercively relocating hundreds of thousands of people.</p>
<p>In World War II, Linebarger and many of his colleagues advised psywarriors to make their products resemble movies, pulp fiction, radio, and other forms of popular entertainment. They also studied advertising for hints about how to persuade reluctant adversaries, and imitated the language of scientists to make their lies sound trustworthy.&nbsp;</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/b66a7721-1604-4d38-8e82-da34b248cc52.jpg?w=960&amp;fit=max"><figcaption>More of Paul Linebarger's identification cards -- these reflect his positions in the military and overseas.</figcaption></figure>
<p>I think psyops specialists are often cast as secret agents who suppress dissent, cover up the truth, and push mindless conformity. But most of Linebarger's work focused on fomenting revolutionary movements. He wanted his work to inspire ordinary people who feared their struggles against Nazis and dictators were doomed. In 1950, he wrote an unpublished monograph about how to encourage "passive resistance," which he described as "obstruction to authority" that doesn't involve an organized military force. People in such a movement don't plant bombs, he wrote, but "their hostility to authority outweighs their fear of authority." He credited this form of resistance movement with challenging tyranny in Ukraine, China, Japan, and India.</p>
<p>He also compared it to art. "Passive resistance in its more quiet and secret forms is essentially an artistic rather than a scientific undertaking," he wrote.</p>
<figure><img alt="Passive resistance in its more quiet and secret forms is essentially an artistic rather than a scientific undertaking.  It is no use trying to organize such a movement on a disciplined and controlled basis, even though particular elements within it may be subject to real instruction and to real indoctrination. Passive resistance as a whole must be sought in terms of a succession of spontaneous activities, some of which are incited by outside propaganda and some of which arise from the conditions prevailing under the hated regime." contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/e6228e6e-719f-4fa5-80db-195a7b41de88.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>He was right. Psyops are an unsung speculative art. Some are brilliant, and others are duds. But they are all attempts to create compelling, emotional stories that offer audiences a new perspective ‚Äì and inspire them to take action.</p>
<p>Psyops are also, fundamentally, lies -- often with violent overtones. Still, the original 1948 version of <em>Psychological Warfare</em> concludes with a section about "psychological disarmament," where Linebarger imagined a world of psychological truths and peace. Border controls would be abolished, and the government would fund education and public parks, while also guaranteeing a free press.<br></p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/3383e857-05b1-4bf1-80d2-9c480b372d1b.png?w=960&amp;fit=max"><figcaption>Linebarger saved several ration cards from World War II, including this one for tobacco.</figcaption></figure>
<p>As the Cold War escalated, however, he abandoned this serene vision. In <a href="https://www.gutenberg.org/files/48612/48612-h/48612-h.htm?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">the 1954 edition of <em>Psychological Warfare</em></a>, he explained that he had replaced the disarmament chapters with a section on the future of psyops. His implication was that psychological warfare would be permanent, with no ceasefire or peaceful resolution. And, as propaganda production grew more sophisticated, he predicted that more authors would join the cause. "The artistic and cultural aspect of writing is readily converted to propaganda usage," Linebarger wrote in the book's new conclusion.</p>
<p>Throughout his life, Linebarger kept journals of his travels. Often, he would jot down a sentence or two, describing the sounds of aircraft carriers or the way light glinted on the Nile at sunset. And sometimes, those notes showed Linebarger realizing that the United States had its own set of oppressive systems that ought to be resisted.</p>
<figure><img contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/3317848e-35e1-466f-8ed5-f395550a129e.png?w=960&amp;fit=max"><figcaption></figcaption></figure>
<p>In an undated note from the 1950s, Linebarger noted: "The women assistants in Washington (Pentagon) astonish me more and more. One whom I have met has more brains than any of the officers around here."</p>
<p>Unlike most men in his profession at the time, Linebarger frequently acknowledged the contributions of women. Many of his major fictional characters are women, too -- including the heroes C'mel and D'joan, who lead resistance movements against the dictatorial Instrumentality, an interstellar government that looms over much of his work. <a href="https://www.jstor.org/stable/4239639?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">According to his biographer Alan C. Elms</a>, Linebarger had hoped to use the pseudonym Lucy Estes on his first two books, but his publisher convinced him to use a man's name.</p>
<p>I spoke to Linebarger's daughter Rosana Hart, who maintains <a href="http://www.cordwainer-smith.com/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">a website devoted to her father's work</a>. "I think he thought that women were superior to men," she told me. I wondered whether this feeling -- so out-of-step with dominant ideas about women in the 1950s -- might have fueled his urge to generate new identities for himself through writing. Maybe he was searching for a way to express an identity that was more fluid than the one the world allowed him.</p>
<figure><img alt="For your present purposes it does not matter whence, historically, your troubles came. Nor does it matter whether what you think about the origins of your troubles is factually true or not. What does matter is that you swing a searchlight from the vantage point of your watched mind across part of the vast terrain of your unwatched mind and that you find, here or there, the character of the trouble which is interfering in your reasonableness and your happiness. This can be illustrated with an example: You have something between your legs. If you are a man it is a small complicated bag of flesh. If you are a woman it is an inconspicuous but deep wrinkle. Whichever set of genitals it may be, the organ itself is actually surprisingly strong ..." contenteditable="false" draggable="false" src="https://assets.buttondown.email/images/e3332011-ee08-4105-8dde-93830f9e7e79.png?w=960&amp;fit=max"><figcaption>An excerpt from an unpublished manuscript from the mid-1950s, written under the name Carmichael Smith (Linebarger's "crime writer" pseudonym), devoted to what he called "ethical dianetics," or "mutual emotional aid." He points out that one source of "trouble" for human psychology is the fact of our genitals, which cannot be talked about openly.</figcaption></figure>
<p>After I talked to Hart, I kept thinking about Linebarger's fiction as a wrathful exercise in frustrated self-fashioning. There is an undeniable streak of cruelty in Linebarger‚Äôs sci-fi stories ‚Äì he revels in describing intense mental and physical torture, and many of his characters die in gruesome ways. Hart told me that her father believed people should see the ugly side of humanity, in order to understand the truth about the world. When she was a little girl, he made a point of telling her about the horrific things people had done to each other in the wars he‚Äôd studied and experienced firsthand. ‚ÄúHe would go into more detail about suffering than a child should have had to listen to,‚Äù she said.</p>
<p>No matter what Linebarger did, he was always trapped in a cold, liminal space between the worlds of China and the United States, propaganda and art. If he couldn't inhabit the world as it was, perhaps he could use his words to bash a better one into being.</p>
<p>With his book <em>Psychological Warfare</em>, he codified a form of creativity whose purpose is to persuade, but also to intimidate, demoralize, and mislead. He described psyops as an opportunity to aid the oppressed, but also a way to hurt adversaries.</p>
<p>This is the paradox at the heart of all propaganda. Unlike wild storytelling, psyops have a specific purpose: to become a weapon. Perhaps it is forged with the intention of bringing justice to the oppressed. And perhaps its emotional ammunition is aimed at the minds of the vulnerable. Either way, it is a weapon whose power cannot be contained. Like a gun or a tank, it can be transferred from the military into civilian life, exploding our domestic policies, school board meetings, healthcare access, and employment opportunities. And that is what <em>Stories Are Weapons</em> is about: how psyops designed for use against national adversaries became weapons in a culture war between people who live in the United States.</p>
<h2>Pre-order <em>Stories Are Weapons</em> now!</h2>
<p>You can <a href="https://wwnorton.com/books/9780393881516?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">pre-order <em>Stories Are Weapons</em> now</a> from your local indie bookstore! If you'd like a personalized and/or signed copy, you can order it from <a href="https://www.greenapplebooks.com/signed-annalee-newitz?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">Green Apple Bookstore</a> (just write in the "info" field how you would like it personalized).</p>
<p>Pre-orders help tremendously, by sending a signal to stores and my publisher that people are interested in the book -- and that can lead to more exposure for <em>Stories Are Weapons</em>.</p>
<h2>See me on my west coast book tour!</h2>
<p>Mark your calendars and get your tickets now! Here's the schedule (more dates may be added later):</p>
<p>6/4: Powell's Books in Portland (w/Dave Miller, host of OPB's "Think Out Loud")</p>
<p>6/6: Seattle Town Hall (w/Lindy West) -- ticketed event (link coming soon!)</p>
<p>6/13: Mechanics Institute in San Francisco (w/Alexis Madrigal)</p>
<p>6/18: <a href="https://app.gopassage.com/events/stories-are-weapons/event_times/1490223?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">Berkeley Arts &amp; Letters at the Hillside Club in Berkeley</a> (w/Ed Yong) -- ticketed event</p>
<h2>What I've been working on lately</h2>
<p>I reviewed two fascinating books about surveillance <a href="https://www.nytimes.com/2024/02/28/books/review/means-of-control-byron-tau-the-sentinel-state-minxin-pei.html?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">for the <em>New York Times</em>:</a> "The Sentinel State," by Minxin Pei, and "Means of Control" by Byron Tau. Comparing the high tech (and low tech) ways that China and the U.S. spy on their citizens is extremely instructive.</p>
<p>I have a new short story out in the glorious <em>Uncanny Magazine</em>! It's called "<a href="https://www.uncannymagazine.com/article/the-best-ever-cosplay-of-whistle-and-midnight/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">The Best-Ever Cosplay of Whistle and Midnight</a>," and it's about what happens when the biggest worm cosplay convention on the planet Sasky loses its venue. Get ready for interspecies dramas, last-minute costume decisions, and a lucky encounter with a very silly cat who works as a bartender at THE TONGUE FORKS. This story is partly a response to the many people who read <em>The Terraformers</em> and asked me, "What happened to the worms after they were able to speak?" But it's also a standalone tale about what it's like to celebrate your body, no matter what form it takes.</p>
<p>Also, if you are feeling saddened by the rise in Comstockery in the States, just remember that <a href="https://us.macmillan.com/books/9780765392121/thefutureofanothertimeline?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">I wrote a novel about time traveling feminists fighting Comstockers</a> across the timeline to restore reproductive rights in America. Hell yeah!</p>
<p>My <em>New Scientist</em> column comes out monthly, and is now outside the paywall! Check out some recent columns on <a href="https://www.newscientist.com/article/mg26134830-200-is-the-truth-out-there-yes-but-it-doesnt-involve-aliens/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">new ways of analyzing UFO sightings</a>, why the Taylor Swift psyops stories are <a href="https://www.newscientist.com/article/mg26134793-500-the-taylor-swift-psy-op-conspiracy-theory-offers-a-troubling-lesson/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">more dangerous than you think</a>, the <a href="https://www.newscientist.com/article/mg26034712-800-the-weird-tale-of-california-forever-a-tech-billionaire-instant-city/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">unregulated Utopian city</a> that billionaires are secretly trying to build on Northern California farmland, and why <a href="https://www.newscientist.com/article/2403999-trust-and-safety-the-most-important-tech-job-youve-never-heard-of/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">trust and safety</a> is the most important tech job you've never heard of.</p>
<p>And the amazing podcast that I co-host with Charlie Jane Anders, <a href="https://ouropinionsarecorrect.libsyn.com/?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">Our Opinions Are Correct</a>, comes out fortnightly! Check out our recent episode on <a href="https://ouropinionsarecorrect.libsyn.com/queer-horror-with-dr-chuck-tingle?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">queer horror</a> with guest Chuck Tingle, and our <a href="https://ouropinionsarecorrect.libsyn.com/we-failed-the-turing-test-walex-hanna-and-emily-m-bender?utm_source=thehypothesis&amp;utm_medium=email&amp;utm_campaign=how-a-science-fiction-obsession-led-me-to" rel="noopener noreferrer nofollow" target="_blank">evisceration of the Turing Test</a> with the help of AI researchers Alex Hanna and Emily M. Bender!</p>
                    
                

                

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral AI Launches New 8x22B MOE Model (213 pts)]]></title>
            <link>https://twitter.com/MistralAI</link>
            <guid>39986095</guid>
            <pubDate>Wed, 10 Apr 2024 01:31:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/MistralAI">https://twitter.com/MistralAI</a>, See on <a href="https://news.ycombinator.com/item?id=39986095">Hacker News</a></p>
Couldn't get https://twitter.com/MistralAI: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Why does part of the Windows 98 Setup program look older than the rest? (2020) (295 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/14903/why-does-part-of-the-windows-98-setup-program-look-older-than-the-rest</link>
            <guid>39985630</guid>
            <pubDate>Wed, 10 Apr 2024 00:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/14903/why-does-part-of-the-windows-98-setup-program-look-older-than-the-rest">https://retrocomputing.stackexchange.com/questions/14903/why-does-part-of-the-windows-98-setup-program-look-older-than-the-rest</a>, See on <a href="https://news.ycombinator.com/item?id=39985630">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>Basically, because it is running under Windows 3.1 at that point.</p>
<p>Windows 98‚Äôs setup process goes through three main phases, in three different operating environments; each one installs the operating environment for the next, until the installation is complete.</p>
<ol>
<li><p>The first, which can run from the setup floppies and/or CD-ROM, uses a DOS program (<code>DOSSETUP.BIN</code>) to set up disk partitions, run various checks etc.:</p>
<p><a href="https://i.stack.imgur.com/jEOF5.png" rel="noreferrer"><img src="https://i.stack.imgur.com/jEOF5.png" alt="Screenshot of the DOS phase of Windows 98 setup"></a></p>
<p>This phases finishes by copying a minimal version of Windows 3.1 to the target installation drive, in a temporary directory (normally <code>WININST0.400</code>), containing <code>DOSX.EXE</code>, <code>USER.EXE</code>, <code>GDI.EXE</code>, <code>KRNL386.EXE</code>, <code>LZEXPAND.DLL</code> etc. (see <code>MINI.CAB</code>).</p>
</li>
<li><p>The second uses this minimal Windows 3.1 to run a Windows 3 program, <code>W98SETUP.BIN</code> (specified as the ‚Äúshell‚Äù in <code>SYSTEM.INI</code>):</p>
<p><a href="https://i.stack.imgur.com/O9Lcv.png" rel="noreferrer"><img src="https://i.stack.imgur.com/O9Lcv.png" alt="Screenshot of the Windows 3 phase of Windows 98 setup"></a></p>
<p>This starts by copying more files to support all the information-gathering during setup, and various other niceties including the 3D look shown in your screenshot (the contents of the <code>PRECOPY</code> CABs); it ends by copying most of Windows 98, setting the system up so that it will boot Windows 98 from the target drive, and rebooting.</p>
</li>
<li><p>The third runs after the first boot into Windows 98, from Windows 98:</p>
<p><a href="https://i.stack.imgur.com/MWn8z.png" rel="noreferrer"><img src="https://i.stack.imgur.com/MWn8z.png" alt="Screenshot of the Windows 98 phase"></a></p>
</li>
</ol>
<p>Many PCs with Windows 98 pre-installed were shipped in a variant of the state left at the end of the second phase above; the third phase starts with a ‚ÄúStarting Windows 98 for the first time‚Äù message, and follows that up by asking the user for their name and company name. Thus PC buyers got a system pre-installed, but ready to be personalised.</p>
<p>You can interrupt setup at any point, or inspect the image during installation in an emulator, to see what‚Äôs present on the disk and thus determine the runtime environment.</p>
<p>It is also possible to initiate the setup process from any of the above environments, which is how Windows 98 handles upgrades (from MS-DOS, or Windows 3, or Windows 95).</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 Turbo with Vision is a step backwards for coding (160 pts)]]></title>
            <link>https://aider.chat/2024/04/09/gpt-4-turbo.html</link>
            <guid>39985596</guid>
            <pubDate>Wed, 10 Apr 2024 00:03:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aider.chat/2024/04/09/gpt-4-turbo.html">https://aider.chat/2024/04/09/gpt-4-turbo.html</a>, See on <a href="https://news.ycombinator.com/item?id=39985596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
      

<p><a href="https://twitter.com/OpenAIDevs/status/1777769463258988634">OpenAI just released GPT-4 Turbo with Vision</a>
and it performs worse on aider‚Äôs coding benchmark suites than all the previous GPT-4 models.
In particular, it seems much more prone to ‚Äúlazy coding‚Äù than the
existing GPT-4 Turbo ‚Äúpreview‚Äù models.</p>

<h2 id="code-editing-skill">Code editing skill</h2>

<p><a href="https://aider.chat/assets/2024-04-09-gpt-4-turbo.svg"><img src="https://aider.chat/assets/2024-04-09-gpt-4-turbo.svg" alt="benchmark results"></a></p>

<p>Aider relies on a
<a href="https://aider.chat/docs/benchmarks.html#the-benchmark">code editing benchmark</a>
to quantitatively evaluate how well
an LLM can make changes to existing code.
The benchmark uses aider to try and complete
<a href="https://github.com/exercism/python">133 Exercism Python coding exercises</a>.</p>

<p>For each exercise, the LLM gets two tries to solve each problem:</p>

<ol>
  <li>On the first try, it gets initial stub code and the English description of the coding task. If the tests all pass, we are done.</li>
  <li>If any tests failed, aider sends the LLM the failing test output and gives it a second try to complete the task.</li>
</ol>

<p><strong>GPT-4 Turbo with Vision
scores only 62% on this benchmark,
the lowest score of any of the existing GPT-4 models.</strong>
The other models scored 63-66%, so this represents only a small
regression, and is likely statistically insignificant when compared
against <code>gpt-4-0613</code>.</p>

<h2 id="lazy-coding">Lazy coding</h2>

<p><a href="https://aider.chat/assets/2024-04-09-gpt-4-turbo-laziness.svg"><img src="https://aider.chat/assets/2024-04-09-gpt-4-turbo-laziness.svg" alt="benchmark results"></a></p>

<p>The GPT-4 Turbo ‚Äúpreview‚Äù models have been widely criticized for being ‚Äúlazy‚Äù
when coding.
They often omit needed code
and instead leave comments with homework assignments like ‚Äúimplement method here‚Äù.</p>

<div><pre><code>def some_complex_method(foo, bar):
    # ... implement method here ...
</code></pre></div>

<p>Aider uses a <a href="https://github.com/paul-gauthier/refactor-benchmark">‚Äúlaziness‚Äù benchmark suite</a>
which is designed to both provoke and quantify lazy coding.
It consists of
89 python refactoring tasks
which tend to make GPT-4 Turbo code in that lazy manner.</p>

<p><strong>The new GPT-4 Turbo with Vision model scores only 34% on aider‚Äôs
refactoring benchmark, making it the laziest coder of all the GPT-4 Turbo models
by a significant margin.</strong></p>

<h2 id="conclusions">Conclusions</h2>

<p>Aider has full support for the new GPT-4 Turbo with Vision
model, which you can access using the switch <code>--model gpt-4-turbo-2024-04-09</code>.
But aider will continue to use <code>gpt-4-1106-preview</code> by default,
as it is by far the strongest coder of the GPT-4 models.</p>



      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My deployment platform is a shell script (123 pts)]]></title>
            <link>https://j3s.sh/thought/my-deployment-platform-is-a-shell-script.html</link>
            <guid>39985249</guid>
            <pubDate>Tue, 09 Apr 2024 22:58:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://j3s.sh/thought/my-deployment-platform-is-a-shell-script.html">https://j3s.sh/thought/my-deployment-platform-is-a-shell-script.html</a>, See on <a href="https://news.ycombinator.com/item?id=39985249">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><small><a href="https://j3s.sh/thoughts.html">‚Üµreturn</a></small>
  </p><p>my deployment platform is a shell script</p>
  <p><b>
    <img height="30" src="https://j3s.sh/static/unnamed-puffy.png" alt="another pufferfish drawn by rekka">
  </b>
</p></div>
<p>my deployment platform is a shell script
2024-04-09

like many people, i fell in love with free software
because i could install it. i'd come home from work and
install a bunch of software.

what fun! tee hee! a playground and i'm the prince!

but eventually, relentlessly, it all starts to feel more
like a horror show.

proxmox needs an upgrade! *SPOOKY WIND*
how the fuck does k8s work again?? *SPOOKY CRICKETS*
promql *EXISTENTIAL SCREAM*


i'm too old now - i'm more fickle with my time. i like
things that work for years with as little interaction
from me as possible.

when it comes to my own projects, i always prioritize
maintainability.

to that end, i built a little deployment system that i
run on a single virtual machine - it's a shell script!

i run it every minute via cron.

here's the script, in its entirety:

  #!/bin/sh

  println() {
    printf "%s\n" "$1" &gt;&gt; /root/gocicd.log
  }

  die() {
    printf "%s\n" "$1" &gt;&gt; /root/gocicd.log
    exit 1
  }

  cd /root
  for project in $(ls go-cicd); do
    cd "/root/go-cicd/$project" 2&gt;&amp;1 &gt;&gt; /root/gocicd.log
    git fetch origin 2&gt;&amp;1 &gt;&gt; /root/gocicd.log
    if git status | grep -q behind; then
      println "$(date): building $project"
      git merge origin/main ||
        git merge origin/master ||
	  die "could not merge $project"
      go build ||
        die "could not build $project"
      mv "$project" "/usr/local/bin/$project"
      cat &lt;&lt;EOF &gt;/etc/init.d/$project"
      #!/sbin/openrc-run

      supervisor="supervise-daemon"
      command="/usr/local/bin/$project"
      directory="/root/go-cicd/$project"
      EOF
      service "$project" restart
    fi
  done

whenever i make an upstream change to any of my tracked
projects, it is cloned, built, and running within 60
seconds.

this gives me a lot of joy. the blog post you're reading
right now was deployed using this system (j3s.sh is a go
application).

this has worked for many years with no maintenance at
all!

my script will never:
  - go down
  - require an upgrade
  - force me to migrate
  - surprise me
  - keep me up at night

all of this makes jes very happy.


digging in a little, the contents of the go-cicd dir look like this:

  $ ls go-cicd/
  existentialcrisis.sh  jackal                nekobot
  j3s.sh                vore                  neoarkbot

these are all of my "tracked projects".

to start tracking a new project, i only need to clone a
repository:

  $ cd go-cicd
  $ git clone git.j3s.sh/newproject

now whenever a new commit is made to
git.j3s.sh/newproject, it is deployed within 60 seconds.

ez.

here's a little taste of the log file:

  $ tail -n 5 go-cicd.log
  Thu Feb  8 00:13:12 UTC 2024: building vore
  Fri Feb  9 22:08:25 UTC 2024: building vore
  Mon Apr  8 02:07:00 UTC 2024: building j3s.sh
  Mon Apr  8 02:59:00 UTC 2024: building j3s.sh
  Tue Apr  9 21:11:00 UTC 2024: building vore

cool! i wonder what happened in march.
(oh, i moved to Virginia, right)


i recognize that this script is pretty limited. it can
only deploy golang applications to my alpine system, but
that's exactly the point i'm trying to prove:

a little, specific solution might be  easier to maintain
and straight up more enjoyable than a larger, more
general system.

i spent maybe 10 minutes writing this script in December
of 2021, and i'm proud of how reliable it has been.

consider keeping your little things little.

it worked for little old me.


until next time, with love from virginia,


  lil jes

</p><p>follow me on <a href="https://merveilles.town/@j3s">mastodon!</a>
</p><p>last updated 2024-04-09T00:00:00.000Z

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building Reliable Systems Out of Unreliable Agents (270 pts)]]></title>
            <link>https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents</link>
            <guid>39984209</guid>
            <pubDate>Tue, 09 Apr 2024 21:01:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents">https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents</a>, See on <a href="https://news.ycombinator.com/item?id=39984209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you‚Äôve tried building real-world features with AI, chances are that you‚Äôve experienced reliability issues. It‚Äôs common knowledge that AI makes for great demos, but‚Ä¶&nbsp;<em>questionable</em>&nbsp;products. After getting uncannily correct answers at first, you get burned on reliability with some wild output and decide you can‚Äôt make anything useful out of that.</p><p>Well, I‚Äôm here to tell you that there‚Äôs hope. Even though AI agents are&nbsp;not&nbsp;reliable, it&nbsp;is&nbsp;possible to build reliable systems out of them.</p><p>These learnings come from a years-long process of creating&nbsp;<a href="https://www.rainforestqa.com/" target="_blank" rel="noreferrer noopener">a QA AI</a>. While building, we found a process that worked pretty well for us and we‚Äôre sharing it here. As a summary, it consists of these high-level steps:</p><ul><li>Write simple prompts to solve your problem</li><li>Use that experience to build an eval system to do prompt engineering and improve performance in a principled way</li><li>Deploy your AI system with good observability, and use that signal to keep gathering examples and improving your evals</li><li>Invest in Retrieval Augmented Generation (RAG)</li><li>Fine-tune your model using the data you gathered from earlier steps</li></ul><p>Having worked on this problem for a while, I think these are the best practices every team should adopt. But there‚Äôs an additional approach we came up with that gave us a breakthrough in reliability, and it might be a good fit for your product, too:</p><ul><li>Use complementary agents</li></ul><p>The principle behind this step is simple: it‚Äôs possible to build&nbsp;systems&nbsp;of complementary agents that work much more reliably than a single agent. More on that later.</p><p>Before we jump in, a note on who this is for: you don‚Äôt need much AI experience to follow the process we lay out here. In fact, most of our team while building our QA agent didn‚Äôt have previous AI or ML experience. A solid software engineering background, however, is super helpful ‚Äî a sentiment <a href="https://twitter.com/gdb/status/1729893902814192096" target="_blank" rel="noreferrer noopener">echoed</a> by well-known people in the industry. Particularly, thinking deeply about how to test what you‚Äôre building and constantly finding ways to optimize your workflow are really important.</p><div id="ez-toc-container"><nav><ul><li><a href="#Start_with_simple_prompts" title="Start with simple prompts">Start with simple prompts</a></li><li><a href="#Use_an_eval_system_to_do_prompt_engineering" title="Use an eval system to do prompt engineering">Use an eval system to do prompt engineering</a></li><li><a href="#Improve_with_observability" title="Improve with observability">Improve with observability</a></li><li><a href="#Invest_in_RAG" title="Invest in RAG">Invest in RAG</a></li><li><a href="#Fine-tune_your_model" title="Fine-tune your model">Fine-tune your model</a></li><li><a href="#Use_complementary_agents" title="Use complementary agents">Use complementary agents</a></li><li><a href="#Final_notes" title="Final notes">Final notes</a></li></ul></nav></div><h2><span id="Start_with_simple_prompts"></span>Start with simple prompts<span></span></h2><p>The most obvious way to start using an LLM to solve a problem is simply asking it to do the thing in your own words. This approach often works well enough at the beginning to give you hope, but starts falling down as soon as you want any reliability. The answers you get might be mostly correct, but not good enough for production. And you‚Äôll quickly notice scenarios where the answers are consistently wrong.</p><p>The best LLMs today are amazing generalists, but not very good specialists ‚Äî and generally, you want specialists to solve your business problems. They need to have enough general knowledge to not be tedious, but at the same time they need to know how exactly to handle the specifics in the gray areas of your problem space.</p><p>Let‚Äôs take a trivial example: you want to get a list of ingredients needed to prepare different things to eat. You start with the first thing that comes to mind:</p><figure><img loading="lazy" decoding="async" width="916" height="1024" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-916x1024.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-916x1024.jpg 916w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-268x300.jpg 268w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-768x858.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-1374x1536.jpg 1374w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2.jpg 1426w" sizes="(max-width: 916px) 100vw, 916px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20916%201024'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-916x1024.jpg 916w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-268x300.jpg 268w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-768x858.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-1374x1536.jpg 1374w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2.jpg 1426w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj1-2-916x1024.jpg"></figure><p>This is good ‚Äî the list of ingredients is right there. But there‚Äôs also a bunch of other stuff that you don‚Äôt need. For example, you might use the same knife for both jars and not care for being lectured about ‚Äåknife hygiene. You can fiddle with the prompt pretty easily:</p><div><figure><img loading="lazy" decoding="async" width="1024" height="638" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-1024x638.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-1024x638.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-300x187.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-768x478.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2.jpg 1362w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20638'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-1024x638.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-300x187.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-768x478.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2.jpg 1362w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj2-2-1024x638.jpg"></figure></div><p>Better, but there‚Äôs still some unnecessary commentary there. Let‚Äôs have another shot:</p><div><figure><img loading="lazy" decoding="async" width="1024" height="442" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-1024x442.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-1024x442.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-300x130.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-768x332.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2.jpg 1172w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20442'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-1024x442.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-300x130.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-768x332.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2.jpg 1172w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj3-2-1024x442.jpg"></figure></div><p>OK, I guess that‚Äôll do. Now we just need to make it JSON so we can integrate it with the rest of our product. Also, just to be safe, let‚Äôs run it a few times to make sure it‚Äôs reliable:</p><div><figure><img loading="lazy" decoding="async" width="1024" height="572" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-1024x572.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-1024x572.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-300x167.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-768x429.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2.jpg 1394w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20572'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-1024x572.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-300x167.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-768x429.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2.jpg 1394w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj4-2-1024x572.jpg"></figure></div><div><figure><img loading="lazy" decoding="async" width="1024" height="619" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-1024x619.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-1024x619.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-300x181.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-768x464.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2.jpg 1396w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20619'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-1024x619.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-300x181.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-768x464.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2.jpg 1396w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj5-2-1024x619.jpg"></figure></div><div><figure><img loading="lazy" decoding="async" width="1024" height="587" src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-1024x587.jpg" alt="" srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-1024x587.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-300x172.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-768x440.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2.jpg 1378w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20587'%3E%3C/svg%3E" data-lazy-srcset="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-1024x587.jpg 1024w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-300x172.jpg 300w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-768x440.jpg 768w, https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2.jpg 1378w" data-lazy-src="https://www.rainforestqa.com/blog/wp-content/uploads/2024/04/pbj6-2-1024x587.jpg"></figure></div><p>As you can see, we‚Äôre reliably getting JSON out, but it‚Äôs not consistent: the capitalization of the keys and what‚Äôs included in each value varies. These specific problems are easy to deal with and even this might be good enough for your use case, but we‚Äôre still far from the reliable and reproducible behavior we‚Äôre looking for.</p><h3>Minimum necessary product integration</h3><p>At this point, it‚Äôs time to integrate a minimal version of your ‚ÄúAI component‚Äù with your product, so the next step is to start using the API instead of the console. Grab your favorite LLM-provider client (or just use their API ‚Äî there are <a href="https://x.com/simonw/status/1728141822063767857?s=20" target="_blank" rel="noreferrer noopener">some good reasons to stick with HTTP</a>) and integrate it into your product in the most minimal way possible. The point is to start building out the infrastructure, knowing that the results won‚Äôt be great yet.</p><p>Some cheat codes at this point, based on my experience:</p><ul><li>If you use <code>mypy</code>, you might be tempted to use strongly-typed inputs when interacting with the client (e.g., the OpenAI client), but my advice would be: don‚Äôt. While I like having <code>mypy</code> around, it‚Äôs much easier to work with plain dictionaries to build your messages and you‚Äôre not risking a lot of bugs.</li><li>In my experience, it‚Äôs a good idea to set <code>temperature=0.0</code> in all your model calls if you care about reliability. You still won‚Äôt get perfect reproducibility, but it‚Äôs usually the best place to start your explorations.</li><li>If you‚Äôre thinking about using a wrapper like <a href="https://github.com/jxnl/instructor" target="_blank" rel="noreferrer noopener"><code>instructor</code></a> to get structured data out of the LLM: it‚Äôs <em>really</em> cool and makes some use-cases very smooth, but also makes your code a little less flexible. I‚Äôd usually start without it and then bring it in at a later point, once I‚Äôm confident in the shape of my data.</li></ul><h2><span id="Use_an_eval_system_to_do_prompt_engineering"></span>Use an eval system to do prompt engineering<span></span></h2><p>The first thing you should try after the naive ‚Äúask a simple question‚Äù approach is prompt engineering. While the phrase is common, I don‚Äôt think many people have an accurate definition of what ‚Äúprompt engineering‚Äù actually means, so let‚Äôs define it first.</p><p>When I say ‚Äúprompt engineering,‚Äù I mean something like, ‚Äúiterative improvement of a prompt based on measurable success criteria‚Äù, where ‚Äúiterative‚Äù and ‚Äúmeasurable success criteria‚Äù are the key phrases. (I like&nbsp;<a href="https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting" target="_blank" rel="noreferrer noopener">this post</a>&nbsp;from last year as an early attempt to define this.) The key is to have some way of determining whether an answer you get from an LLM is correct and then measuring correctness across examples to give you a number you can compare over time.</p><p>Create an evaluation loop so you have a way of checking any change you make, and then make that loop as fast as it can be so you can iterate effectively. For an overview of how to think about your eval systems, see&nbsp;<a href="https://hamel.dev/blog/posts/evals/" target="_blank" rel="noreferrer noopener">this excellent blog post</a>.</p><h3>Evaluating when there are multiple correct answers</h3><p>This whole procedure rhymes with ‚Äútesting‚Äù and ‚Äúcollecting a validation set,‚Äù except for any given question there might be multiple correct answers, so it‚Äôs not obvious how to do this. Here are some situations and how to deal with them:</p><ul><li>It‚Äôs possible to apply deterministic transformations on the output of the LLM before you compare it to the ‚Äúknown good‚Äù answer. An example might be the capitalization issue from earlier, or maybe you only ever want three first words as an output. Running these transformations will make it trivial to compare what you get with what you expect.</li><li>You might be able to use some heuristics to validate your output. E.g., if you‚Äôre working on summarization, you might be able to say something like ‚Äúto summarize this story accurately, the following words are absolutely necessary‚Äù and then get away with doing string matching on the response.</li><li>Maybe you need the output in a certain format. E.g., you‚Äôre getting function calls or their arguments from an LLM or you‚Äôre expecting country codes or other well-defined outputs. In these cases, you can validate what you get against a known schema and retry in case of errors. In practice, you can use something like&nbsp;<a href="https://github.com/jxnl/instructor" target="_blank" rel="noreferrer noopener">instructor</a> ‚Äî if you‚Äôre comfortable with the constraints it imposes, including around code flexibility ‚Äî and then you‚Äôre left with straightforwardly comparing structured data.</li><li>In a true Inception fashion, you might want to use a simpler, smaller, and cheaper LLM to evaluate the outputs of your big-LLM-using-component. Comparing two differently-written, but equivalent lists of ingredients is an easy task even for something like GPT 3.5 Turbo. Just keep in mind: even thought it‚Äôs pretty reliable, you‚Äôre now introducing <em>some</em> flakiness into your test suite. Trade-offs!</li><li>To evaluate an answer, you might have to ‚Äúexecute‚Äù the entire set of instructions the agent gives you and check if you‚Äôve reached the goal. This is more complex and time-consuming, but sometimes the only way. For example, we often ask an agent to achieve a goal inside a browser by outputting a series of instructions that might span multiple screens. The only way for us to check its answer is to execute the instructions inside Playwright and run some assertions on the final state.</li></ul><h3>Building your validation set</h3><p>Once you have your evaluation loop nailed down, you can build a validation set of example inputs and the corresponding outputs you‚Äôd like the agent to produce.</p><p>As you evaluate different strategies and make changes to your prompts, it‚Äôs ideal if you have a single metric to compare over time. Something like ‚Äú% prompts answered correctly‚Äù is the most obvious, but something like precision/recall might be more informative depending on your use case.</p><p>It‚Äôs also possible you won‚Äôt be able to use a single metric if you‚Äôre evaluating fuzzy properties of your answers, in which case you can at least look at what breaks after each change and make a judgment call.</p><h3>Prompt engineering tricks</h3><p>Now‚Äôs your chance to try all the prompt engineering tricks you‚Äôve heard about. Let‚Äôs cover some of them!</p><p>First of all, provide all the context you‚Äôd need to give to an intelligent human operator who‚Äôs unfamiliar with the nuances and requirements of the task. This is a necessary (but not sufficient!) condition to making your system work. E.g., if you know you absolutely always want some salted butter under your peanut butter, you need to include that information in your prompt.</p><p>If you‚Äôre not getting the correct responses, ask the agent to think step-by-step before providing the actual answer. This can be a little tricky if you‚Äôre expecting structured data out ‚Äî you‚Äôll have to somehow give the agent a way to do some reasoning&nbsp;<em>before</em> it makes any consequential decisions and locks itself in.</p><p>E.g., if you use the <a href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools" target="_blank" rel="noreferrer noopener">tool-calling API</a>, which is really nifty, you might be tempted to tell the agent to do some chain-of-thought reasoning by having a JSON schema similar to this:</p><pre><code>[
    {
        "type": "function",
        "function": {
            "name": "scoop_out",
            "description": "scoop something out",
            "parameters": {
                "type": "object",
                "properties": {
                    "chain_of_thought": {
                        "type": "string",
                        "description": "the reasoning for this action"
                    },
                    "jar": {
                        "type": "string",
                        "description": "the jar to scoop out of"
                    },
                    "amount": {
                        "type": "integer",
                        "description": "how much to scoop out"
                    }
                },
                "required": ["chain_of_thought", "jar","amount"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "spread",
            "description": "spread something on a piece of bread",
            "parameters": {
                "type": "object",
                "properties": {
                    "chain_of_thought": {
                        "type": "string",
                        "description": "the reasoning for this action"
                    },
                    "substance": {
                        "type": "string",
                        "description": "what to spread"
                    }
                },
                "required": ["chain_of_thought", "substance"]
            }
        }
    }
]</code></pre><p>Unfortunately, this will make the agent output the function name <em>before</em> it produces the chain-of-thought, locking it into the early decision and defeating the whole point. One way to get around this is to pass in the schema with the available functions, but ask the agent to output a JSON that wraps the function spec, similar to this:</p><pre><code>You are an assistant helping prepare food. Given a dish name, respond with a JSON object of the following structure:

{{
    "chain_of_thought": "Describe your reasoning for the next action",
    "function_name": "scoop_out" | "spread",
    "function_args": {{
        &lt; appropriate arguments for the function &gt;
    }}
}}</code></pre><p>This has fewer guarantees, but works well enough in practice with GPT 4 Turbo.</p><p>Generally, chain-of-thought has a speed/cost vs. accuracy trade-off, so pay attention to your latencies and token usage in addition to correctness.</p><p>Another popular trick is <em>few-shot prompting</em>. In many cases, you‚Äôll get a noticeable bump in performance if you include a few examples of questions and their corresponding answers in your prompt, though this isn‚Äôt always feasible. E.g., your actual input might be so large that including more than a single ‚Äúshot‚Äù in your prompt isn‚Äôt practical.</p><p>Finally, you can try offering the agent a bribe or telling it something bad will happen if it answers incorrectly. We didn‚Äôt find these tactics worked for us, but they might for you ‚Äî they‚Äôre worth trying, assuming you trust your eval process.</p><p>Every trick from the ones listed above will change things: some things will hopefully get better, but it‚Äôs likely you‚Äôll break something else at the same time. It‚Äôs really important you have a representative set of examples that you can work with, so commit to spending time on building it.</p><h2><span id="Improve_with_observability"></span>Improve with observability<span></span></h2><p>At this point, you‚Äôll likely have something that‚Äôs good enough to deploy as an alpha-quality product. Which you should absolutely do as soon as you can so you can get real user data and feedback.</p><p>It‚Äôs important you‚Äôre open about where your system is in terms of robustness, but it‚Äôs impossible to overstate the value of users telling you what they think. It‚Äôs tempting to get everything working correctly before opening up to users, but you‚Äôll hit a point of diminishing returns without real user feedback. This is an absolutely necessary ingredient to making your system better over time ‚Äî don‚Äôt skip it.</p><p>Before release, just make sure your observability practices are solid. From my perspective, this basically means logging all of your LLM input/output pairs so you can a) look at them and learn what your users need and b) label them manually to build up your eval set.</p><p>There a many options to go with here, from big monitoring providers you might already be using to open-source libraries that help you trace your LLM calls. Some, like <a href="https://github.com/traceloop/openllmetry" target="_blank" rel="noreferrer noopener">openllmetry</a> and <a href="https://github.com/Arize-ai/openinference" target="_blank" rel="noreferrer noopener">openinference</a> even use the OpenTelemetry under the hood, which seems like a great idea. I haven‚Äôt seen a tool focused on labeling the data you‚Äôve gathered and turning it into a validation set, however, which is why we built our own solution: store some JSON files in S3 and have a web interface to look at and label them. It doesn‚Äôt have as many bells and whistles as off-the-shelf options, but it‚Äôs enough for what we need at the moment.</p><h2><span id="Invest_in_RAG"></span>Invest in RAG<span></span></h2><p>Once you‚Äôve exhausted all your prompt-engineering tricks and you feel like you‚Äôre out of ideas and your performance is at a plateau, it might be time to invest in a RAG pipeline. Roughly, RAG is runtime prompt engineering where you build a system to dynamically add relevant things to your prompt before you ask the agent for an answer.</p><p>An example might be answering questions about very recent events. This isn‚Äôt something LLMs are good at, because they‚Äôre not usually retrained to include the latest news. However, it‚Äôs relatively straightforward to run a web search and include some of the most relevant news articles in your prompt before asking the LLM to give you the answer. If you have relevant data of your own you can leverage, it‚Äôs likely to give you another noticeable improvement.</p><p>Another example from our world: we‚Äôve got an agent interacting with the UI of an application based on plain-English prompts. We also have more than ten years worth of data from our clients writing testing prompts in English and our crowd of human testers executing those instructions. We can use this data to tell the agent something like ‚Äúit looks like most human testers executing similar tasks clicked on button X and then typed Y into field Z‚Äù to guide it.</p><p>Retrieval is great and very powerful, but it has real trade-offs, complexity being the main one. Again, there are many options: you can roll your own solution, use an external provider, or have some combination of the two (e.g., using <a href="https://platform.openai.com/docs/guides/embeddings/how-to-get-embeddings" target="_blank" rel="noreferrer noopener">OpenAI‚Äôs embeddings</a> and <a href="https://github.com/pgvector/pgvector" target="_blank" rel="noreferrer noopener">storing the vectors in your Postgres</a> instance).</p><p>A particular library that looked great (a little more on the do-it-yourself end of the spectrum) is <a href="https://github.com/bclavie/RAGatouille" target="_blank" rel="noreferrer noopener">RAGatouille</a>, but I wasn‚Äôt able to make it work and gave up after a couple of hours. In the end, we used BigQuery to get data out, OpenAI for producing embeddings, and <a href="https://pinecone.io/" target="_blank" rel="noreferrer noopener">Pinecone</a> for storage and nearest-neighbor search because that was the easiest way for us to deploy something without setting up a lot of new infrastructure. Pinecone makes it very easy to store and search through embeddings with their associated metadata to augment your prompts.</p><p>There‚Äôs more we can do here ‚Äî we didn‚Äôt evaluate any alternative embedding engines, we only find top-3 related samples, and get limited data out of those samples currently. Looking at alternative embeddings, including more samples, and getting more details information about each sample is something we plan to look at in the future.</p><p>You can spend quite a while on this level of the ladder. There‚Äôs a lot of room for exploration. If you exhaust all the possibilities and ways of building your pipeline, still aren‚Äôt getting good enough results and can‚Äôt think any more sources of useful data, it‚Äôs time to consider fine-tuning.</p><h2><span id="Fine-tune_your_model"></span>Fine-tune your model<span></span></h2><p>Now we‚Äôre getting to the edges of the known universe. If you‚Äôve done everything above: created an eval system, shipped an AI product, observed it running in production, got real user data, and even have a useful RAG pipeline, then congratulations! You‚Äôre on the bleeding edge of applied AI.</p><p>Where to go from here is unclear. Fine-tuning a model based on the data you‚Äôve gathered so far seems like the obvious choice. But beware ‚Äî I‚Äôve heard conflicting opinions in the industry about the merits of fine-tuning relative to the effort required.</p><p>It&nbsp;<em>seems</em>&nbsp;like it should work better, but there are unresolved practical matters: OpenAI <a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning">only allows you to fine-tune older models</a>, and <a href="https://docs.anthropic.com/claude/docs/glossary#fine-tuning">Anthropic is kind of promising to make it available</a> soon with a bunch of caveats.</p><p>Fine-tuning and hosting your own models is a whole different area of expertise. Which model do you choose as the base? How do you gather data for fine-tuning? How do you evaluate any improvements? And so on. In the case of self-hosted models, I‚Äôd caution against hoping to save money vs. hosted solutions ‚Äî you‚Äôre very unlikely to have the expertise and the economies of scale to get there, even if you choose smaller models.</p><p>My advice would be to wait a few months for the dust to settle a bit before investing here, unless you‚Äôve tried everything else already and still aren‚Äôt getting good-enough results. We haven‚Äôt had to do this so far because we still haven‚Äôt exhausted all the possibilities mentioned above, so we‚Äôre postponing the increase in complexity.</p><h2><span id="Use_complementary_agents"></span>Use complementary agents<span></span></h2><p>Finally, I want to share a trick that might be applicable to your problem, but is sort of independent of the whole process described above ‚Äî you can apply it at any of the stages I‚Äôve described.</p><p>It involves a bit of a computation vs. reliability trade-off: it turns out that in many situations it‚Äôs possible to throw more resources at a problem to get better results. The only question is: can you find a balance that‚Äôs both fast and cheap enough while being accurate enough?</p><p>You‚Äôll often feel like you‚Äôre playing whack-a-mole when trying to fix specific problems with your LLM prompts. For instance, I often find there‚Äôs a tension between creating the correct high-level plan of execution and the ability to‚Äå precisely execute it. This reminded me of the idea behind&nbsp;<a href="https://blog.gardeviance.org/2015/03/on-pioneers-settlers-town-planners-and.html" target="_blank" rel="noreferrer noopener">‚Äúpioneers, settlers, and city planners‚Äù</a>: different people have different skills and approaches and thrive in different situations. It‚Äôs rare for a single person to both have a good grand vision and to be able to precisely manage the vision‚Äôs execution.</p><p>Of course, LLMs aren‚Äôt people, but some of their properties make the analogy work. While it‚Äôs difficult to prompt your way to an agent that always does the right thing, it‚Äôs much easier to plan what‚Äôs needed and create a team of specialists that complement each other.</p><p>I‚Äôve seen a similar approach called an ‚Äúensemble of agents,‚Äù but I prefer ‚Äúcomplementary agents‚Äù for this approach because it highlights that the agents are meaningfully different and support each other in ways that identical agents couldn‚Äôt.</p><p>For example, to achieve a non-obvious goal, it helps to create a high-level plan first, before jumping into the details. While creating high-level plans, it‚Äôs useful to have a very broad and low-resolution view of the world without getting bogged down by details. Once you have a plan, however, executing each subsequent step is much easier with a narrow, high-resolution view of the world. Specific details can make or break your work, and at the same time, seeing irrelevant information can confuse you. How do we square this circle?</p><p>One answer is creating teams of complementary agents to give each other feedback. LLMs are pretty good at correcting themselves if you tell them what they got wrong, and it‚Äôs not too difficult to create a ‚Äúverifier‚Äù agent that checks specific aspects of a given response.</p><p>An example conversation between ‚Äúhigh level planner‚Äù and ‚Äúverifier‚Äù agents might look something like the following:</p><pre><code>Planner
OK, we need to make a PB&amp;J sandwich! To do that, we need to get some peanut
butter, some jelly and some bread, then take out a plate and a knife.

Verifier
Cool, that sounds good.

Planner
OK, now take the peanut butter and spread it on the bread.

Verifier
(noticing there's no slice of bread visible) Wait, I can't see the bread in
front of me, you can't spread anything on it because it's not there.

Planner
Ah, of course, we need to take the slice of bread out first and put it on a
plate.

Verifier
Yep, that seems reasonable, let's do it.
</code></pre><p>The two agents complement each other, and neither can work on its own. Nobody is perfect, but we can build a reliable system out of flawed pieces if we‚Äôre thoughtful about it.</p><h3>How we‚Äôre using complementary agents</h3><p>This is exactly what we did for our testing agents: there‚Äôs a planner and a verifier. The planner knows the overall goal and tries to achieve it. It‚Äôs creative and can usually find a way to get to the goal even if it isn‚Äôt immediately obvious. E.g., if you ask it to click on a product that‚Äôs not on the current page, it‚Äôll often use the search functionality to look for the product. But sometimes the planner is <em>too</em> optimistic and wants to do things that seem like they should be possible, but in fact aren‚Äôt.</p><p>For example, it might want to click on a ‚ÄúPay now‚Äù button on an e-commerce checkout page, because the button <em>should</em> be there, but it‚Äôs just below the fold and not currently visible. In such cases, the verifier (who doesn‚Äôt know the overall goal and is only looking at the immediate situation) can correct the planner and point out that the concrete task we‚Äôre trying to do right now isn‚Äôt possible.</p><h2><span id="Final_notes"></span><strong>Final notes</strong><span></span></h2><p>Putting all this together again, we now have a pretty clear process for building LLM-based products that deal with their inherent unreliability.</p><p>Making something usable in the real world still isn‚Äôt a well-explored area, and things are changing really quickly, so you can‚Äôt follow well-explored paths. It‚Äôs basically applied research, rather than pure engineering. Still, having a clear process to follow while you‚Äôre iterating will make your life easier and allow you to set the right expectations at the start.</p><p>The process I‚Äôve described should follow a step-by-step increase in complexity, starting with naive prompting and finally doing RAG and possibly fine-tuning. At each step, evaluate whether the increased complexity is worth it ‚Äî you might get good-enough results pretty early, depending on your use case. I bet getting through the first four steps will be enough to handle most of your problems.</p><p>Keep in mind that this is going to be a very iterative process ‚Äî there‚Äôs no way to design and build AI systems in a single try. You won‚Äôt be able to predict what works and how your users will bend your tool, so you absolutely need their feedback. You‚Äôll build the first, inadequate version, use it, notice flaws, improve it, release it more widely, etc. And if you‚Äôre successful and build something that gets used, your prize will be more iterations and improvements. Yay!</p><p>Also, don‚Äôt sweat having a single, optimizable success metric too much. It‚Äôs the ideal scenario, but it might take you a while to get to that point. Despite having a collection of tests and examples, we still rely ‚Äúvibe checks‚Äù when evaluating whether a new prompt version is an improvement. Just counting passing examples might not be enough if some examples are more important than others.</p><p>Finally, try the ‚Äúcomplementary agents‚Äù trick to work around weaknesses you notice. It‚Äôs often very difficult to make a single agent do the right thing reliably, but detecting the wrong thing so you can retry tends to be easier.</p><h3>What‚Äôs next for us</h3><p>There‚Äôs still a bunch of things that we‚Äôre planning to work on in the coming months, so our product won‚Äôt be static. I don‚Äôt expect, however, to deviate much from the process we described here. We‚Äôre continuously speaking with our customers and monitoring how our product is being used and finding edge cases to fix. We‚Äôre also certainly not at the global optimum when it comes to reliability, speed, and cost, so we‚Äôll continue experimenting with alternative models, providers, and ways of work.</p><p>Specifically, I‚Äôm really intrigued by the latest Anthropic models (e.g., what can we usefully do with a small model like Haiku, which still has vision capabilities?) and I‚Äôm deeply intrigued by the ideas <a href="https://github.com/stanfordnlp/dspy">DSPy</a> is promoting. I suspect there are some unrealized wins in the way we structure our prompts.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The challenges of building modern open source software on PowerPC Mac OS X (101 pts)]]></title>
            <link>http://www.netbsd.org/~nia/tigersrc/</link>
            <guid>39983915</guid>
            <pubDate>Tue, 09 Apr 2024 20:30:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.netbsd.org/~nia/tigersrc/">http://www.netbsd.org/~nia/tigersrc/</a>, See on <a href="https://news.ycombinator.com/item?id=39983915">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Unix software from pkgsrc for Mac OS X 10.4 (PowerPC Tiger)</h2>
<h2>Introduction</h2>
<p>
PowerPC Macs were produced in huge numbers, and a lot of this hardware
is still viable for use today, with professional software such as
Photoshop CS2 and Propellerheads Reason. They're still good
workstations, with lots of productivity software,
and no always-online tracking or distractions. Originally, I got mine
for running NetBSD, but found the pull of 20 year old commercial software
too tempting to resist.
</p>
<p>
Regardless, how usable is Mac OS X 10.4 for Unix professionals,
software developers, and command-line junkies? A surprising
amount of free software can still run, often with some
simple adjustments. The <a href="https://www.pkgsrc.org/">pkgsrc</a>
framework offers a platform-netural repository with powerful
frameworks that allow wide porting of software.
</p>
<p>
Pre-built PowerPC binaries for popular software are available,
including PostgreSQL, ImageMagick, Python 3, Wget, cURL, FFmpeg,
OpenSSH, OpenSSL, Apache Web Server, nginx, yt-dlp, SDL,
Midnight Commander, and many more.
</p>
<p>
Note: I make no guarantees about the security or up-to-dateness
of these packages, though I pinky promise they're better than what
Tiger includes by default.  No warranty. Your fridge may explode.
You may find you're suddenly able to connect to servers that
use modern encryption, with all the risks that entails.
</p>
<h2>How to install software</h2>
<h3>Bootstrapping</h3>
<p><a href="https://ftp.netbsd.org/pub/pkgsrc/misc/nia/tigersrc/bootstrap-tiger.tar.gz">Download the bootstrap kit</a></p>
<p>Extract the bootstrap kit on 10.4, set your <code>PATH</code>:</p>
<pre><code>
$ sudo tar -C / -xzpvf bootstrap-tiger.tar.gz
$ export PATH=/usr/pkg/sbin:/usr/pkg/bin:$PATH
$ export PKG_PATH=https://ftp.NetBSD.org/pub/pkgsrc/misc/nia/tigersrc/packages/All/
</code>
</pre>
<p>Add the last two lines to <code>~/.bash_profile</code>.
</p><h3>Installing packages</h3>
<p><a href="https://ftp.netbsd.org/pub/pkgsrc/misc/nia/tigersrc/packages/All/">Browse the repository</a></p>
<pre><code>
$ sudo pkg_add ffmpeg2
</code>
</pre>
<h2>Challenges building modern software on 10.4</h2>
<p>Part of this project is <em>just for fun</em>. Since I'm a developer
specialized in build systems, I get enjoyment out of pushing pkgsrc as far
as possible. Therefore, others should get to learn from this too.</p>
<p>Refer to the <a href="http://www.netbsd.org/~nia/tigersrc/mk.conf">mk.conf</a> used for this repository,
containing some non-upstreamed workarounds, and the
<a href="http://www.netbsd.org/~nia/tigersrc/tiger-packages.txt">allowlist of packages</a>.</p>
<ul>
<li><strong>Compiler:</strong> XCode's GCC 4.0 does not support C++11 or C11.
    Some software expects the compiler to default to C99,
    and does not explicitly specify <code>-std=c99</code> in <code>CFLAGS</code>.
    This older version of GCC supports C99 but does not default to it,
    which should be worked around by setting <code>FORCE_C_STD</code>
    in pkgsrc. Many pieces of modern software like to specify lots of unsupported
    -W and -Wno arguments to customize warnings. These can be stripped out with pkgsrc's
    <code>BUILDLINK_TRANSFORM</code>.</li>
<li><strong>Linker:</strong> The strict Mach-O linker included in Tiger is
    quite different from what modern software expects (e.g. it does not
    support <code>-shared</code>), <em>unless</em> that software uses libtool to make
    shared libraries in a portable manner.
    pkgsrc has long had a policy of "libtoolization", patching software that
    builds with plain Makefiles to use libtool.
    <code>BUILDLINK_TRANSFORM</code> can also translate many GNU ELF-style
    linker arguments to be compatible with the Darwin linker.
    I also found the <code>-m</code> option (for making multiply-defined
    symbols into a warning instead of an error) useful.</li>
<li><strong>Library:</strong> Now-ubiqitious functions are missing, including
    <code>clock_gettime</code> and <code>strnlen</code>.
    These can easily be substituted from either <code>libnbcompat</code> or
    <code>macports-legacy-support</code>.</li>
<li><strong>Atomics:</strong> Some wide atomic instructions are missing
    from 32-bit PowerPC. This isn't a PowerPC or Darwin-specific problem,
    since it affects other 32-bit instruction sets like i486.</li>
<li><strong>Rust:</strong> Even if it worked on this platform, build times
    would be completely unacceptable. We use the pre-Rust versions of
    software like py-cryptography, since pkgsrc makes this easy. Reduce CO2 emissions,
    keep writing C.</li>
<li><strong>Locales:</strong> Certain UTF-8 file names fail to extract with
    <em>bsdtar</em>, with the UTF-8 sequences
    being detected as invalid. I haven't done much research into this yet,
    but it affects very few packages, such as the Icelandic aspell
    dictionary. This is probably not a bsdtar problem, since it
    works on NetBSD with the same tar version.</li>
<li><strong>Toolchain bugs:</strong> There is a problem with
    <code>signal.h</code> that causes some software to fail to compile.
    This can be easily worked around by disabling the relevant type definitions
    by pre-defining macros in <code>CFLAGS</code>.</li>
<li><strong>Kernel bugs:</strong> Sadly, <code>kqueue</code> does not work
    properly on Tiger. kqueue support is nearly always optional in software,
    but sometimes the detection needs to be turned off for this OS version.
    GNU configure makes this easy, other build systems may vary.</li>
<li><strong>Other curiosities:</strong> The default dashboard widgets and
    screensaver in 10.4 use a surprising amount of CPU time that could be
    better spent on GCC. They're easy to disable, though.</li>
</ul>
<p>Most of these problems are <em>very general</em>, so there's a lot of
benefit to be gained from automatically making these adjustments for everything.</p>
<p>A big problem for this project is the wider ecosystem (well, mostly GNOME-adjacent
libraries) moving away from the GNU build system, which mostly solved the
problem of building shared libraries on different platforms years ago,
as well as nicely handling feature detection.  More work needs to be done before
CMake and Meson can work well on this platform, but also a way to say to them
"yes, this OS has this feature, but please ignore it" would be very useful
(also for testing!).
</p>
<p>Related to the issue of 64-bit atomics is the world moving away from 32-bit
platforms. If you're a stranger to the embedded world, this is happening
more slowly than you might think. While Mac OS X suffers from the Year 2038
Problem, NetBSD solved it years ago. 64-bit wide atomic instructions
are unavailable on many NetBSD ports, with libatomic being a hacky workaround
at best.</p>
<p>Most importantly, if you maintain a C/C++ software project, and don't specify
<code>-std=(gnu|c)XX</code> in your build sytem already, <em>please do</em>.
Keep in mind that <code>-Werror</code> will fall over the moment you try building with
a compiler version that you haven't tested personally, and distribution maintainers
will want to disable it. For pkgsrc on modern platforms, at any one time we're building
with around 4 different major versions of GCC plus Clang, so we'd disable it
even if we weren't supporting crusty old stuff.</p>
<h2>See also</h2>
<ul>
<li><a href="https://www.macports.org/">MacPorts</a> - lots of prior art</li>
<li><a href="https://github.com/mistydemeo/tigerbrew">TigerBrew</a> - lots of frozen packages to prevent them breaking, pkgsrc being more "live"</li>
<li><a href="https://www.macintoshrepository.org/">Macintosh Repository</a> - useful for obtaining XCode</li>
</ul>
<small>
<p>nia from the domain pkgsrc.org<br>
Best viewed in Links.<br>
Last updated March 2024.</p>
<p>
<a href="https://validator.w3.org/markup/check?uri=referer"><img src="https://www.w3.org/Icons/valid-html401" alt="Valid HTML 4.01 Strict" height="31" width="88"></a>
</p>
</small>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A MySQL compatible database engine written in pure Go (370 pts)]]></title>
            <link>https://github.com/dolthub/go-mysql-server</link>
            <guid>39983490</guid>
            <pubDate>Tue, 09 Apr 2024 19:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dolthub/go-mysql-server">https://github.com/dolthub/go-mysql-server</a>, See on <a href="https://news.ycombinator.com/item?id=39983490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/dolthub/go-mysql-server/blob/main/mascot.png"><img height="240" src="https://github.com/dolthub/go-mysql-server/raw/main/mascot.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A MySQL compatible database engine written in pure Go</h2><a id="user-content-a-mysql-compatible-database-engine-written-in-pure-go" aria-label="Permalink: A MySQL compatible database engine written in pure Go" href="#a-mysql-compatible-database-engine-written-in-pure-go"></a></p>
<p dir="auto"><strong>go-mysql-server</strong> is a data-source agnostic SQL engine and server
which runs queries on data sources you provide, using the MySQL
dialect and wire protocol. A simple in-memory database implementation
is included, and you can query any data source you want by
implementing your own backend.</p>
<p dir="auto"><a href="https://www.doltdb.com/" rel="nofollow">Dolt</a>, a SQL database with Git-style
versioning, is the main production database implementation of this
package.  <a href="https://docs.dolthub.com/introduction/what-is-dolt" rel="nofollow">Check
out</a> that project
for reference a implementation. Or, hop into the Dolt discord
<a href="https://discord.com/invite/RFwfYpu" rel="nofollow">here</a> if you want to talk to the
<a href="https://www.dolthub.com/team" rel="nofollow">core developers</a> behind
<strong>go-mysql-server</strong> and Dolt.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatibility</h2><a id="user-content-compatibility" aria-label="Permalink: Compatibility" href="#compatibility"></a></p>
<p dir="auto">With the exception of specific limitations (see below),
<strong>go-mysql-server</strong> is a drop-in replacement for MySQL. Any client
library, tool, query, SQL syntax, SQL function, etc. that works with
MySQL should also work with <strong>go-mysql-server</strong>. If you find a gap in
functionality, please file an issue.</p>
<p dir="auto">For full MySQL compatibility documentation, see the <a href="https://docs.dolthub.com/sql-reference/sql-support" rel="nofollow">Dolt
docs</a> on this
topic.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scope of this project</h2><a id="user-content-scope-of-this-project" aria-label="Permalink: Scope of this project" href="#scope-of-this-project"></a></p>
<ul dir="auto">
<li>SQL server and engine to query your data sources.</li>
<li>In-memory database backend implementation suitable for use in tests.</li>
<li>Interfaces you can use to implement new backends to query your own
data sources.</li>
<li>With a few caveats and using a full database implementation, a
drop-in MySQL database replacement.</li>
</ul>
<p dir="auto"><strong>go-mysql-server</strong> has two primary uses case:</p>
<ol dir="auto">
<li>
<p dir="auto">Stand-in for MySQL in a golang test environment, using the built-in
<code>memory</code> database implementation.</p>
</li>
<li>
<p dir="auto">Providing access to arbitrary data sources with SQL queries by
implementing a handful of interfaces. The most complete real-world
implementation is <a href="https://github.com/dolthub/dolt">Dolt</a>.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Add <strong>go-mysql-server</strong> as a dependency to your project. In the
directory with the <code>go.mod</code> file, run:</p>
<div data-snippet-clipboard-copy-content="go get github.com/dolthub/go-mysql-server@latest"><pre><code>go get github.com/dolthub/go-mysql-server@latest
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using the in-memory test server</h2><a id="user-content-using-the-in-memory-test-server" aria-label="Permalink: Using the in-memory test server" href="#using-the-in-memory-test-server"></a></p>
<p dir="auto">The in-memory test server can replace a real MySQL server in
tests. Start the server using the code in the <a href="https://github.com/dolthub/go-mysql-server/blob/main/_example/main.go">_example
directory</a>, also reproduced below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;time&quot;

	&quot;github.com/dolthub/vitess/go/vt/proto/query&quot;

	sqle &quot;github.com/dolthub/go-mysql-server&quot;
	&quot;github.com/dolthub/go-mysql-server/memory&quot;
	&quot;github.com/dolthub/go-mysql-server/server&quot;
	&quot;github.com/dolthub/go-mysql-server/sql&quot;
	&quot;github.com/dolthub/go-mysql-server/sql/types&quot;
)

// This is an example of how to implement a MySQL server.
// After running the example, you may connect to it using the following:
//
// > mysql --host=localhost --port=3306 --user=root mydb --execute=&quot;SELECT * FROM mytable;&quot;
// +----------+-------------------+-------------------------------+----------------------------+
// | name     | email             | phone_numbers                 | created_at                 |
// +----------+-------------------+-------------------------------+----------------------------+
// | Jane Deo | janedeo@gmail.com | [&quot;556-565-566&quot;,&quot;777-777-777&quot;] | 2022-11-01 12:00:00.000001 |
// | Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |
// | John Doe | john@doe.com      | [&quot;555-555-555&quot;]               | 2022-11-01 12:00:00.000001 |
// | John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |
// +----------+-------------------+-------------------------------+----------------------------+
//
// The included MySQL client is used in this example, however any MySQL-compatible client will work.

var (
	dbName    = &quot;mydb&quot;
	tableName = &quot;mytable&quot;
	address   = &quot;localhost&quot;
	port      = 3306
)

func main() {
	pro := createTestDatabase()
	engine := sqle.NewDefault(pro)

	session := memory.NewSession(sql.NewBaseSession(), pro)
	ctx := sql.NewContext(context.Background(), sql.WithSession(session))
	ctx.SetCurrentDatabase(&quot;test&quot;)

	// This variable may be found in the &quot;users_example.go&quot; file. Please refer to that file for a walkthrough on how to
	// set up the &quot;mysql&quot; database to allow user creation and user checking when establishing connections. This is set
	// to false for this example, but feel free to play around with it and see how it works.
	if enableUsers {
		if err := enableUserAccounts(ctx, engine); err != nil {
			panic(err)
		}
	}

	config := server.Config{
		Protocol: &quot;tcp&quot;,
		Address:  fmt.Sprintf(&quot;%s:%d&quot;, address, port),
	}
	s, err := server.NewServer(config, engine, memory.NewSessionBuilder(pro), nil)
	if err != nil {
		panic(err)
	}
	if err = s.Start(); err != nil {
		panic(err)
	}
}

func createTestDatabase() *memory.DbProvider {
	db := memory.NewDatabase(dbName)
	db.BaseDatabase.EnablePrimaryKeyIndexes()

	pro := memory.NewDBProvider(db)
	session := memory.NewSession(sql.NewBaseSession(), pro)
	ctx := sql.NewContext(context.Background(), sql.WithSession(session))

	table := memory.NewTable(db, tableName, sql.NewPrimaryKeySchema(sql.Schema{
		{Name: &quot;name&quot;, Type: types.Text, Nullable: false, Source: tableName, PrimaryKey: true},
		{Name: &quot;email&quot;, Type: types.Text, Nullable: false, Source: tableName, PrimaryKey: true},
		{Name: &quot;phone_numbers&quot;, Type: types.JSON, Nullable: false, Source: tableName},
		{Name: &quot;created_at&quot;, Type: types.MustCreateDatetimeType(query.Type_DATETIME, 6), Nullable: false, Source: tableName},
	}), db.GetForeignKeyCollection())
	db.AddTable(tableName, table)

	creationTime := time.Unix(0, 1667304000000001000).UTC()
	_ = table.Insert(ctx, sql.NewRow(&quot;Jane Deo&quot;, &quot;janedeo@gmail.com&quot;, types.MustJSON(`[&quot;556-565-566&quot;, &quot;777-777-777&quot;]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;Jane Doe&quot;, &quot;jane@doe.com&quot;, types.MustJSON(`[]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;John Doe&quot;, &quot;john@doe.com&quot;, types.MustJSON(`[&quot;555-555-555&quot;]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;John Doe&quot;, &quot;johnalt@doe.com&quot;, types.MustJSON(`[]`), creationTime))

	return pro
}"><pre><span>package</span> main

<span>import</span> (
	<span>"context"</span>
	<span>"fmt"</span>
	<span>"time"</span>

	<span>"github.com/dolthub/vitess/go/vt/proto/query"</span>

	sqle <span>"github.com/dolthub/go-mysql-server"</span>
	<span>"github.com/dolthub/go-mysql-server/memory"</span>
	<span>"github.com/dolthub/go-mysql-server/server"</span>
	<span>"github.com/dolthub/go-mysql-server/sql"</span>
	<span>"github.com/dolthub/go-mysql-server/sql/types"</span>
)

<span>// This is an example of how to implement a MySQL server.</span>
<span>// After running the example, you may connect to it using the following:</span>
<span>//</span>
<span>// &gt; mysql --host=localhost --port=3306 --user=root mydb --execute="SELECT * FROM mytable;"</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>// | name     | email             | phone_numbers                 | created_at                 |</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>// | Jane Deo | janedeo@gmail.com | ["556-565-566","777-777-777"] | 2022-11-01 12:00:00.000001 |</span>
<span>// | Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |</span>
<span>// | John Doe | john@doe.com      | ["555-555-555"]               | 2022-11-01 12:00:00.000001 |</span>
<span>// | John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>//</span>
<span>// The included MySQL client is used in this example, however any MySQL-compatible client will work.</span>

<span>var</span> (
	<span>dbName</span>    <span>=</span> <span>"mydb"</span>
	<span>tableName</span> <span>=</span> <span>"mytable"</span>
	<span>address</span>   <span>=</span> <span>"localhost"</span>
	<span>port</span>      <span>=</span> <span>3306</span>
)

<span>func</span> <span>main</span>() {
	<span>pro</span> <span>:=</span> <span>createTestDatabase</span>()
	<span>engine</span> <span>:=</span> <span>sqle</span>.<span>NewDefault</span>(<span>pro</span>)

	<span>session</span> <span>:=</span> <span>memory</span>.<span>NewSession</span>(<span>sql</span>.<span>NewBaseSession</span>(), <span>pro</span>)
	<span>ctx</span> <span>:=</span> <span>sql</span>.<span>NewContext</span>(<span>context</span>.<span>Background</span>(), <span>sql</span>.<span>WithSession</span>(<span>session</span>))
	<span>ctx</span>.<span>SetCurrentDatabase</span>(<span>"test"</span>)

	<span>// This variable may be found in the "users_example.go" file. Please refer to that file for a walkthrough on how to</span>
	<span>// set up the "mysql" database to allow user creation and user checking when establishing connections. This is set</span>
	<span>// to false for this example, but feel free to play around with it and see how it works.</span>
	<span>if</span> <span>enableUsers</span> {
		<span>if</span> <span>err</span> <span>:=</span> <span>enableUserAccounts</span>(<span>ctx</span>, <span>engine</span>); <span>err</span> <span>!=</span> <span>nil</span> {
			<span>panic</span>(<span>err</span>)
		}
	}

	<span>config</span> <span>:=</span> server.<span>Config</span>{
		<span>Protocol</span>: <span>"tcp"</span>,
		<span>Address</span>:  <span>fmt</span>.<span>Sprintf</span>(<span>"%s:%d"</span>, <span>address</span>, <span>port</span>),
	}
	<span>s</span>, <span>err</span> <span>:=</span> <span>server</span>.<span>NewServer</span>(<span>config</span>, <span>engine</span>, <span>memory</span>.<span>NewSessionBuilder</span>(<span>pro</span>), <span>nil</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>panic</span>(<span>err</span>)
	}
	<span>if</span> <span>err</span> <span>=</span> <span>s</span>.<span>Start</span>(); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>panic</span>(<span>err</span>)
	}
}

<span>func</span> <span>createTestDatabase</span>() <span>*</span>memory.<span>DbProvider</span> {
	<span>db</span> <span>:=</span> <span>memory</span>.<span>NewDatabase</span>(<span>dbName</span>)
	<span>db</span>.<span>BaseDatabase</span>.<span>EnablePrimaryKeyIndexes</span>()

	<span>pro</span> <span>:=</span> <span>memory</span>.<span>NewDBProvider</span>(<span>db</span>)
	<span>session</span> <span>:=</span> <span>memory</span>.<span>NewSession</span>(<span>sql</span>.<span>NewBaseSession</span>(), <span>pro</span>)
	<span>ctx</span> <span>:=</span> <span>sql</span>.<span>NewContext</span>(<span>context</span>.<span>Background</span>(), <span>sql</span>.<span>WithSession</span>(<span>session</span>))

	<span>table</span> <span>:=</span> <span>memory</span>.<span>NewTable</span>(<span>db</span>, <span>tableName</span>, <span>sql</span>.<span>NewPrimaryKeySchema</span>(sql.<span>Schema</span>{
		{<span>Name</span>: <span>"name"</span>, <span>Type</span>: <span>types</span>.<span>Text</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>, <span>PrimaryKey</span>: <span>true</span>},
		{<span>Name</span>: <span>"email"</span>, <span>Type</span>: <span>types</span>.<span>Text</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>, <span>PrimaryKey</span>: <span>true</span>},
		{<span>Name</span>: <span>"phone_numbers"</span>, <span>Type</span>: <span>types</span>.<span>JSON</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>},
		{<span>Name</span>: <span>"created_at"</span>, <span>Type</span>: <span>types</span>.<span>MustCreateDatetimeType</span>(<span>query</span>.<span>Type_DATETIME</span>, <span>6</span>), <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>},
	}), <span>db</span>.<span>GetForeignKeyCollection</span>())
	<span>db</span>.<span>AddTable</span>(<span>tableName</span>, <span>table</span>)

	<span>creationTime</span> <span>:=</span> <span>time</span>.<span>Unix</span>(<span>0</span>, <span>1667304000000001000</span>).<span>UTC</span>()
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"Jane Deo"</span>, <span>"janedeo@gmail.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`["556-565-566", "777-777-777"]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"Jane Doe"</span>, <span>"jane@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`[]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"John Doe"</span>, <span>"john@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`["555-555-555"]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"John Doe"</span>, <span>"johnalt@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`[]`</span>), <span>creationTime</span>))

	<span>return</span> <span>pro</span>
}</pre></div>
<p dir="auto">This example populates the database by creating <code>memory.Database</code> and
<code>memory.Table</code> objects via golang code, but you can also populate it
by issuing <code>CREATE DATABASE</code>, <code>CREATE TABLE</code>, etc. statements to the
server once it's running.</p>
<p dir="auto">Once the server is running, connect with any MySQL client, including
the golang MySQL connector and the <code>mysql</code> shell.</p>
<div dir="auto" data-snippet-clipboard-copy-content="> mysql --host=localhost --port=3306 --user=root mydb --execute=&quot;SELECT * FROM mytable;&quot;
+----------+-------------------+-------------------------------+----------------------------+
| name     | email             | phone_numbers                 | created_at                 |
+----------+-------------------+-------------------------------+----------------------------+
| Jane Deo | janedeo@gmail.com | [&quot;556-565-566&quot;,&quot;777-777-777&quot;] | 2022-11-01 12:00:00.000001 |
| Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |
| John Doe | john@doe.com      | [&quot;555-555-555&quot;]               | 2022-11-01 12:00:00.000001 |
| John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |
+----------+-------------------+-------------------------------+----------------------------+"><pre><span>&gt;</span> mysql --host=localhost --port=3306 --user=root mydb --execute=<span><span>"</span>SELECT * FROM mytable;<span>"</span></span>
+----------+-------------------+-------------------------------+----------------------------+
<span>|</span> name     <span>|</span> email             <span>|</span> phone_numbers                 <span>|</span> created_at                 <span>|</span>
+----------+-------------------+-------------------------------+----------------------------+
<span>|</span> Jane Deo <span>|</span> janedeo@gmail.com <span>|</span> [<span><span>"</span>556-565-566<span>"</span></span>,<span><span>"</span>777-777-777<span>"</span></span>] <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> Jane Doe <span>|</span> jane@doe.com      <span>|</span> []                            <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> John Doe <span>|</span> john@doe.com      <span>|</span> [<span><span>"</span>555-555-555<span>"</span></span>]               <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> John Doe <span>|</span> johnalt@doe.com   <span>|</span> []                            <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
+----------+-------------------+-------------------------------+----------------------------+</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations of the in-memory database implementation</h2><a id="user-content-limitations-of-the-in-memory-database-implementation" aria-label="Permalink: Limitations of the in-memory database implementation" href="#limitations-of-the-in-memory-database-implementation"></a></p>
<p dir="auto">The in-memory database implementation included with this package is
intended for use in tests. It has specific limitations that we know
of:</p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1306" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1306/hovercard">Not
threadsafe</a>. To
avoid concurrency issues, limit DDL and DML statements (<code>CREATE TABLE</code>, <code>INSERT</code>, etc.) to a single goroutine.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1506" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1506/hovercard">No transaction
support</a>. Statements
like <code>START TRANSACTION</code>, <code>ROLLBACK</code>, and <code>COMMIT</code> are no-ops.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1347" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1347/hovercard">Non-performant index
implementation</a>. Indexed
lookups and joins perform full table scans on the underlying tables.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Custom backend implementations</h2><a id="user-content-custom-backend-implementations" aria-label="Permalink: Custom backend implementations" href="#custom-backend-implementations"></a></p>
<p dir="auto">You can create your own backend to query your own data sources by
implementing some interfaces. For detailed instructions, see the
<a href="https://github.com/dolthub/go-mysql-server/blob/main/BACKEND.md">backend guide</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical documentation for contributors and backend developers</h2><a id="user-content-technical-documentation-for-contributors-and-backend-developers" aria-label="Permalink: Technical documentation for contributors and backend developers" href="#technical-documentation-for-contributors-and-backend-developers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/go-mysql-server/blob/main/ARCHITECTURE.md">Architecture</a> is an overview of the various
packages of the project and how they fit together.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/blob/main/CONTRIBUTING.md">Contribution guide</a> for new contributors,
including instructions for how to get your PR merged.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Powered by go-mysql-server</h2><a id="user-content-powered-by-go-mysql-server" aria-label="Permalink: Powered by go-mysql-server" href="#powered-by-go-mysql-server"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/dolt">dolt</a></li>
<li><a href="https://github.com/src-d/gitbase">gitbase</a> (defunct)</li>
</ul>
<p dir="auto">Are you building a database backend using <strong>go-mysql-server</strong>? We
would like to hear from you and include you in this list.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security Policy</h2><a id="user-content-security-policy" aria-label="Permalink: Security Policy" href="#security-policy"></a></p>
<p dir="auto"><a href="https://github.com/dolthub/go-mysql-server/blob/main/SECURITY.md">go-mysql-server's security
policy</a> is
maintained in this repository. Please follow the disclosure instructions there.
Please do not initially report security issues in this repository's public
GitHub issues.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto"><strong>go-mysql-server</strong> was originally developed by the <code>{source-d}</code>
organzation, and this repository was originally forked from
<a href="https://github.com/src-d/go-mysql-server">src-d</a>. We want to thank
the entire <code>{source-d}</code> development team for their work on this
project, especially Miguel Molina (@erizocosmico) and Juanjo √Ålvarez
Martinez (@juanjux).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache License 2.0, see <a href="https://github.com/dolthub/go-mysql-server/blob/main/LICENSE">LICENSE</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yes, social media is a cause of the epidemic of teenage mental illness (924 pts)]]></title>
            <link>https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic</link>
            <guid>39983233</guid>
            <pubDate>Tue, 09 Apr 2024 19:29:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic">https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic</a>, See on <a href="https://news.ycombinator.com/item?id=39983233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>For centuries, adults have worried about whatever ‚Äúkids these days‚Äù are doing. From novels in the 18th century to the bicycle in the 19th and through comic books, rock and roll, marijuana, and violent video games in the 20th century, there are always those who ring alarms, and there are always </span><a href="https://parents.simonandschuster.com/9781982159597" rel="">those who are skeptics of those alarms</a><span>. So far, the skeptics have been right more often than not, and when they are right, they earn the right to call the alarm ringers ‚Äúalarmists‚Äù who have fomented a groundless moral panic, usually through sensational but rare (or non-existent) horror stories trumpeted by irresponsible media.&nbsp;</span></p><p><span>But the skeptics are not always right. I think it is a very good thing that alarms were rung about teen smoking, teen pregnancy, drunk driving, and the exposure of children to sex and violence on TV. The lesson of </span><em>The Boy Who Cried Wolf</em><span> is not that after two false alarms we should disconnect the alarm system. In that story, the wolf does eventually come.&nbsp;</span></p><p><span>The question before us now, on the topic of teens and social media, is this: Are the skeptics correct that we are going through just one more groundless moral panic over teens and tech in which adults are freaking out while, in fact, </span><em>the harms are so minimal</em><span> that they shouldn‚Äôt be a cause for worry? Or did the wolf really arrive around 2012, and has been mauling young people ever since via their smartphones and social media accounts? (Of course, there are </span><a href="https://technosapiens.substack.com/" rel="">researchers</a><span> who reside in the space between these two perspectives.)</span></p><p>Psychologist Candice Odgers has taken the skeptical side for many years now (along with researchers including Amy Orben, Andrew Przybylski, Jeff Hancock, Chris Ferguson, and Aaron Brown), while Jean Twenge and I have been writing as alarm ringers. It has been a normal and productive academic debate. Engagement with each other‚Äôs arguments is how science makes progress. Even if we never convince each other, the broader scientific and policy communities tune in to the debate, and eventually, they‚Äôll move one way or the other.</p><p><span>Odgers recently stated the skeptics' case in an essay in </span><em>Nature</em><span> titled </span><em><a href="https://www.nature.com/articles/d41586-024-00902-2" rel="">The Great Rewiring: Is Social Media Really Behind an Epidemic of Teenage Mental Illness</a><span>?</span></em><span> The essay offered a critique of my recent book, </span><em>The Anxious Generation</em><span>. Odgers‚Äô primary criticism is that I have mistaken correlation for causation and that ‚Äúthere is no evidence that using these platforms is rewiring children‚Äôs brains or driving an epidemic of mental illness.‚Äù&nbsp; She also warns that my ringing of a false alarm ‚Äúmight distract us from effectively responding to the real causes of the current mental-health crisis in young people,‚Äù which, she suggests, are social ills such as racism, economic hardship, and the lingering impact of the 2008 Global Financial Crisis and its disparate impact on children in low SES families.&nbsp;</span></p><p>In this response essay, I‚Äôll present the two main problems I see with the skeptics' approach, as exemplified in Odgers‚Äô review:&nbsp;</p><ol><li><p>Odgers is wrong to say that I have no evidence of causation</p></li><li><p>Odgers‚Äô alternative explanation does not fit the available facts.</p></li></ol><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>Odgers‚Äô central claim is that I have mistaken correlation for causation and that I have ‚Äúno evidence‚Äù that social media is a cause, rather than a mere correlate, of the current epidemic of adolescent mental illness. Odgers says that I am just ‚Äúmaking up stories by simply looking at trend lines.‚Äù</p><p><span>In 2018, when I entered this debate as a co-author of </span><em>The Coddling of the American Mind</em><span>, it was true that the great majority of published studies on ‚Äúdigital media‚Äù and mental health were correlational, and every social scientist knows that correlational studies often suggest to our intuitive minds a causal pathway that vanishes when experiments using random assignment are published. (Think of the changing guidance on the health effects of fat, carbs, and red wine). But even in 2018 there were a few </span><a href="https://doi.org/10.1080/15213269.2016.1257392" rel="">experimental</a><span> </span><a href="https://psycnet.apa.org/record/2014-19176-040" rel="">studies</a><span> on social media and mental health. For example, college students</span><a href="https://guilfordjournals.com/doi/abs/10.1521/jscp.2018.37.10.751" rel=""> who were asked</a><span> to reduce their social media use for three weeks generally experienced mental health benefits compared to the control group. Zach Rausch, Jean Twenge, and I began to collect all the studies we could find in 2019, and we organized them by type: correlational, longitudinal, and experimental. We put all of our work online in Google Docs that are open to other researchers for comment and critique. You can find all of our ‚Äúcollaborative review‚Äù documents at </span><a href="http://anxiousgeneration.com/reviews" rel="">AnxiousGeneration.com/reviews</a></p><p><span>The main document that collects studies on social media is here:</span><br><a href="https://docs.google.com/document/d/1w-HOfseF2wF9YIpXwUUtP65-olnkPyWcgF5BiAtBEy0/edit" rel="">Social Media and Mental Health: A Collaborative Review</a></p><p><span>In that document, we list dozens of correlational and longitudinal studies. These large datasets provide us with correlation coefficients that tell us how variables in the dataset are related to each other, and they tell us when and for whom those relationships are stronger. Those studies reveal a fairly consistent relationship in which heavy users of social media are at much higher risk of mental illness or poor mental health than everyone else. A </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6537508/" rel="">widely cited 2018 study</a><span> of 14-year-olds found that girls who spend five hours or more on social media per day are </span><em>three times as likely to be depressed</em><span> as girls who use social media only a little or not at all. For boys, the ratio is lower, closer to two-to-one. A </span><a href="https://pubmed.ncbi.nlm.nih.gov/35564559/#:~:text=The%20risk%20of%20depression%20increased,of%20adolescent%20social%20media%20use." rel="">meta-analysis of 26 such studies</a><span> found that the risk of depression increased by 13% for each hour increase on social media for adolescents (and that increase was even higher for girls).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-143412349" href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic#footnote-1-143412349" target="_self" rel="">1</a></span><span>&nbsp;</span></p><p>In that document, we also list 22 experimental studies, 16 of which found significant evidence of harm (or of benefits from getting off of social media for long enough to get past withdrawal symptoms). To give just a few examples:&nbsp;</p><ol><li><p><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.20190658" rel="">Alcott and colleagues (2020)</a><span> randomly assigned 2743 adults to either deactivate their Facebook accounts for one month or not. This study also found that deactivation significantly improved subjective well-being and that ‚Äú80% of the treatment group agreed that deactivation was good for them.‚Äù The treatment group was also more likely to report using Facebook less and having uninstalled the app from their phones post-experiment.</span></p></li><li><p><a href="https://doi.org/10.1007/s10389-022-01751-x" rel="">Brailovskaia and colleagues (2022)</a><span> have done one of the only studies I have seen that incorporate both social media reduction and physical activity increases. They randomly assigned 642 participants to (1) reduce social media use to 30 minutes a day for two weeks, (2) increase physical activity by 30 minutes a day for two weeks, (3) follow both instructions, or (4) do nothing. The researchers found the strongest effects within the combined condition (#3). This group reported the largest decreases in depressive symptoms and increases in life satisfaction and subjective happiness compared to other groups.&nbsp;</span></p></li><li><p><span>There are also a </span><a href="https://psycnet.apa.org/doi/10.1037/ppm0000182" rel="">number</a><span> of </span><a href="https://www.sciencedirect.com/science/article/pii/S174014452030406X" rel="">experiments</a><span> that have looked at Instagram's unique negative impacts on women, including the finding that it is </span><a href="https://www.sciencedirect.com/science/article/abs/pii/S1740144519303754?via%3Dihub" rel="">more harmful to women</a><span> than is Facebook.</span></p></li></ol><p><span>In that document, we also list nine quasi-experiments or natural experiments (as when high-speed internet arrives in different parts of a country at different times), eight of which found evidence of harm to mental health, especially for girls and women. (Odgers cited only the </span><a href="https://journals.sagepub.com/doi/10.1177/21677026231207791" rel=""><span>9</span><sup>th</sup><span> one</span></a><span>, which relies on a dataset that is made up of unreliable estimates that do not detect known rises in mental illness, as </span><a href="https://www.afterbabel.com/p/international-mental-health-gbd" rel="">Zach showed here</a><span>.) To give just one example: </span><a href="https://www.iza.org/publications/dp/15728/high-speed-internet-and-the-widening-gender-gap-in-adolescent-mental-health-evidence-from-hospital-records" rel="">Arenas-Arroyo and colleagues (2022) </a><span>looked at the links between the staggered rollout of broadband internet in Spain between 2007-2019 and hospital discharge diagnoses of behavioral and mental health cases of adolescents. They found a significant effect of the arrival of high-speed internet,</span><em> but only among adolescent girls.</em></p><p><span>There are also a number of studies showing </span><a href="https://openaccess.nhh.no/nhh-xmlui/handle/11250/3119200" rel="">mental health improvements</a><span>, </span><a href="https://doi.org/10.3390/ijerph18041907" rel="">increases in physical activity</a><span>, and </span><a href="https://doi.org/10.1108/AEA-05-2021-0112" rel="">reductions in bullying</a><span> when schools go phone-free‚Äîone of the few natural experiments that specifically targets both adolescents </span><em>and</em><span> group-level effects. (These group-level effects are illustrated brilliantly </span><a href="https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/" rel="">here</a><span>).&nbsp;</span></p><p>I am not saying that academic debates are settled by counting up the number of studies on each side, but bringing so many studies together in one place gives us an overview of the available evidence, and that overview supports three points about problems with the skeptics‚Äô arguments.</p><p><span>First, if the skeptics were right and the null hypothesis were true (i.e., social media does </span><em>not</em><span> cause harm to teen mental health), then the published studies would just reflect random noise</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-143412349" href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic#footnote-2-143412349" target="_self" rel="">2</a></span><span> and Type I errors (believing something that is false). In that case, we‚Äôd see experimental studies producing a wide range of findings, including many that showed </span><em>benefits</em><span> to mental health from using social media (or that showed harm to those who go off of social media for a few weeks). Yet there are hardly any such experimental findings. Most experiments find evidence of negative effects; some find no evidence of such effects, and very few show benefits. Also, if the null hypothesis were true, then we‚Äôd find some studies where the effects were larger for boys and some that found larger effects for girls. Yet that‚Äôs not what we find. When a sex difference is reported, it almost always shows more harm to girls and women. There is a clear and consistent signal running through the experimental studies (as well as the correlational studies), a signal that is not consistent with the null hypothesis.</span></p><p><span>Second, and most germane to Odgers‚Äô review: She and the other skeptics are free to critique the hundreds of studies Zach and I cite in our essays at </span><em>After Babel</em><span> and in chapters 1, 5, 6, and 7 of </span><em>The Anxious Generatio</em><span>n. They can certainly say that they are not persuaded and that they will not be persuaded until the perfect experiment is done. But they cannot say that I am drawing </span><em>only</em><span> on correlational studies, or that I have ‚Äúno evidence‚Äù of causation, or that I do not understand the difference between correlation and causation. I laid out the evidence for causality (not just correlation) between social media use and mental health outcomes for girls and walked the reader through the Google Doc and multiple kinds of evidence in this post in early 2023:</span></p><p><strong><a href="https://www.afterbabel.com/p/social-media-mental-illness-epidemic" rel="">Social Media is a Major Cause of the Mental Illness Epidemic in Teen Girls. Here‚Äôs the Evidence</a><span>.</span></strong></p><p><span>I presented several conceptual problems with the skeptics‚Äô claims about causality and evidence in this essay: </span><strong><a href="https://www.afterbabel.com/p/why-some-researchers-think-im-wrong" rel="">Why Some Researchers Think I‚Äôm Wrong About Social Media and Mental Illness</a><span>.</span></strong><span> For example, I noted that the skeptics focus on testing one narrow model of causality that treats social media consumption as if it were an individual act, like consuming sugar, and then looks for the size of the dose-response relationship in individuals. But much of my book is about the </span><em>collective action traps</em><span> that entire communities of adolescents fall into when they move their social lives onto these platforms, such that it becomes costly to abstain. It is at that point that collective mental health declines most sharply, and the individuals who try to quit find that they are socially isolated. The skeptics do not consider the ways that these network or group-level effects may obscure individual-level effects, and may be much larger than the individual-level effects.</span></p><p><span>Third, even beyond the published experiments, there is ample evidence of causation that should be relevant to parents, lawyers, and legislators: eyewitness testimony. When you ask members of Gen Z what </span><em>they</em><span> think is causing their high rates of mental illness, they often point to </span><a href="https://headspace.org.au/assets/headspace-National-Youth-Mental-Health-Survey-2018.pdf" rel="">social media</a><span> and </span><a href="https://www.rsph.org.uk/about-us/news/instagram-ranked-worst-for-young-people-s-mental-health.html" rel="">particularly Instagram</a><span> as a major cause.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-143412349" href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic#footnote-3-143412349" target="_self" rel="">3</a></span><span> (See </span><a href="https://docs.google.com/document/d/1w-HOfseF2wF9YIpXwUUtP65-olnkPyWcgF5BiAtBEy0/edit#heading=h.uj5mgiudhp60" rel="">section 4 of our main collaborative review doc</a><span>.)&nbsp; I have been searching for essays by members of Gen Z that defend social media and the phone-based childhood as being good for mental health. I can‚Äôt find them, but I find </span><a href="https://www.afterbabel.com/t/voices-of-gen-z" rel="">plenty of members of Gen Z</a><span> who say that social media damaged them or their generation. Also relevant: many members of </span><a href="https://www.halfthestoryproject.com/" rel="">Gen Z are</a><span> </span><a href="https://www.logoffmovement.org/" rel="">starting</a><span> </span><a href="https://www.rethinkwords.com/" rel="">organizations</a><span> </span><a href="https://designitforus.org/" rel="">to fight</a><span> </span><a href="https://www.nosonovember.org/" rel="">back</a><span>.</span></p><p><span>Meta collected some eyewitness testimony accidentally. In that famous internal study </span><a href="https://www.wsj.com/articles/the-facebook-files-11631713039?mod=bigtop-breadcrumb" rel="">brought out by whistleblower Frances Haugen</a><span>, the researchers found that Instagram is particularly bad for girls. They wrote: ‚ÄúTeens blame Instagram for increases in the rate of anxiety and depression. . . . This reaction was unprompted and consistent across all groups.‚Äù Quantitative researchers such as Odgers are free to place less weight on qualitative studies, but they </span><em>are </em><span>a kind of evidence in social science research. They are relevant when we try to sort out multiple theories about causation, especially when the platforms will not share data with scientists so the experts with the deepest insights into what social media is doing to teens are the teens themselves. They see it happening. Do they count as ‚Äúno evidence‚Äù since their claims are not peer-reviewed?</span></p><p>The second major problem with Odgers‚Äô review is that she proposes an alternative to my ‚Äúgreat rewiring‚Äù theory that does not fit the known facts. Odgers claims that the ‚Äúreal causes‚Äù of the crisis, from which my book ‚Äúmight distract us from effectively responding,‚Äù are longstanding social ills such as ‚Äústructural discrimination and racism, sexism and sexual abuse, the opioid epidemic, economic hardship and social isolation.‚Äù She proposes that the specific timing of the epidemic, beginning around 2012, might be linked to the 2008 Global Financial Crisis, which had lasting effects on ‚Äúfamilies in the bottom 20% of the income distribution,‚Äù who were ‚Äúalso growing up at the time of an opioid crisis, school shootings, and increasing unrest because of racial and sexual discrimination and violence.‚Äù</p><p>I agree that those things are all bad for human development, but Odgers‚Äô theory cannot explain why rates of anxiety and depression were generally flat in the 2000s and then suddenly shot upward roughly four years after the start of the Global Financial Crisis. Did life in America suddenly get that much worse during President Obama‚Äôs second term, as the economy was steadily improving?&nbsp;</p><p>Her theory also cannot explain why adolescent mental health collapsed in similar ways around the same time in Canada, the UK, Australia, and New Zealand, as Zach and I showed in this post:</p><p><strong><a href="https://www.afterbabel.com/p/international-mental-illness-part-one" rel="">The Teen Mental Illness Epidemic is International, Part 1: The Anglosphere</a></strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png" width="1456" height="687" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:687,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50b837d0-ae20-48c8-b9f8-fee6dd6da67f_1600x755.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 1.</strong><span> Since 2010, rates of self-harm episodes have increased for adolescents in the Anglosphere countries, especially for girls. For data on all sources and larger versions of the graphs, see </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">Rausch and Haidt (2023).</a><span> (Data for Canada is limited to Ontario province, which contains nearly 40% of the population of Canada.)</span></em></p><p>Nor can she explain why it also happened at roughly the same time in the Nordic countries, which lack most of the social pathologies on Odgers‚Äô list, as Zach and I showed in this post:</p><p><strong><a href="https://www.afterbabel.com/p/international-mental-illness-part-two" rel="">The Teen Mental Illness Epidemic is International, Part 2: The Nordic Nations</a></strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png" width="473" height="396.4564315352697" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:808,&quot;width&quot;:964,&quot;resizeWidth&quot;:473,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d11a32a-850f-4850-89e5-6a29ba5fa1ac_964x808.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 2.</strong><span> Percent of Nordic Teens with High Psychological Distress. Data from the </span><a href="https://hbsc.org/" rel="">Health Behavior in School-Age Children Survey (2002-2018)</a><span>. Graphs and data were organized, analyzed, and created by Thomas Potrebny and Zach Rausch. See 1.1.1 of </span><a href="https://docs.google.com/document/d/1w5DUx-7wTfFXvwuSRbM1Mi8VCqbpdUey4BgzPi9LvtA/edit#" rel="">Nordic Adolescent Mood Disorders since 2010</a><span>.</span></em></p><p>Nor can she explain why it also happened in much, though not all, of Western Europe:</p><p><strong><a href="https://www.afterbabel.com/p/international-crisis-europe" rel="">The Youth Mental Health Crisis is International Part 4: Europe</a></strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png" width="597" height="366.8313253012048" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:510,&quot;width&quot;:830,&quot;resizeWidth&quot;:597,&quot;bytes&quot;:218844,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F026ae4ff-6ff6-4a52-bb2e-8022c93827d2_830x510.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 3. </strong><span>Changes in psychological distress by high vs. low individualism of each country, split by sex. Source: </span><a href="https://hbsc.org/data/" rel="">Health Behavior in School-Age Children Survey, 2002-2018</a><span> (See Zach‚Äôs </span><a href="https://docs.google.com/spreadsheets/d/1czZiySSxNHOn6_K6zmXv-t_NheygAaBfHM3zmH1nPDo/edit#gid=204943004" rel="">spreadsheet</a><span> for data points) and </span><a href="https://www.hofstede-insights.com/country-comparison-tool" rel="">Hofstede Insights.</a></em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-143412349" href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic#footnote-4-143412349" target="_self" rel="">4</a></span><span> </span></p><p>Nor can she explain why suicide rates for Gen Z girls (but not always boys) are at record levels across the Anglosphere, as we showed in this post:</p><p><strong><a href="https://www.afterbabel.com/p/anglo-teen-suicide" rel="">Suicide Rates Are Up for Gen Z Across the Anglosphere, Especially for Girls</a></strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png" width="996" height="512" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:512,&quot;width&quot;:996,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138694,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f5d67d-b793-4ea5-91f6-ed9ad8f548b3_996x512.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 4. </strong><span>All datasets and figures can be </span><a href="https://www.afterbabel.com/p/anglo-teen-suicide" rel="">found in the post</a><span>.&nbsp;</span></em></p><p>If Odgers was correct that the ‚Äúreal causes‚Äù of the epidemic are America‚Äôs social ills, then we would not find these patterns in so many countries. I just can‚Äôt see a causal path by which America‚Äôs school shootings, lockdown drills, poverty, or racism caused girls in Australia to suddenly start self-harming or dying by suicide at the same time as so many American girls.</p><p>An equally large problem for Odgers‚Äô explanation is that it commits her to the prediction that the increases in mental illness were largest for teens in low SES families. After all, her explanation for why there was a four-year delay between the onset of the GFC and the onset of the mental health crisis was because the effects lasted longer for those ‚Äúin the bottom 20% of the income distribution,‚Äù who ‚Äúcontinue to experience harm.‚Äù&nbsp;</p><p><a href="https://www.afterbabel.com/p/financial-crisis" rel="">Jean Twenge tested Odgers‚Äô explanation</a><span> by looking to see whether rates of major depressive episodes increased faster for teens in families below the poverty line (shown in red in Figure 5 below) versus those whose families‚Äô incomes were at least double the poverty line (shown in blue). As you can see, there was no difference between the two groups up through 2012 (which is contrary to Odgers‚Äô thesis about the differential impacts of the GFC on mental health), and then a difference opened up after 2012, but in the </span><em>opposite</em><span> direction of Odgers‚Äô prediction.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png" width="591" height="518.8923444976076" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:734,&quot;width&quot;:836,&quot;resizeWidth&quot;:591,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bc59bda-d344-4ff6-8477-cda3a19be24d_836x734.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 5.</strong><span> Percent of U.S. 12- to 17-year-olds experiencing major depressive episodes in the last 12 months, by family income level. Source: Data from the nationally representative </span><a href="https://www.samhsa.gov/data/data-we-collect/nsduh-national-survey-drug-use-and-health" rel="">National Survey of Drug Use and Health</a><span>; analysis by Jean M. Twenge for the Generation Tech Substack.</span></em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-143412349" href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic#footnote-5-143412349" target="_self" rel="">5</a></span><em>&nbsp;</em></p><p><span>Twenge has also addressed </span><a href="https://www.afterbabel.com/p/13-explanations-mental-health-crisis" rel="">13 </a><em><a href="https://www.afterbabel.com/p/13-explanations-mental-health-crisis" rel="">other</a></em><a href="https://www.afterbabel.com/p/13-explanations-mental-health-crisis" rel=""> possible explanations</a><span> for the mental health crisis and shows why they don‚Äôt fit the data.</span></p><p>In short: Odgers has pointed to an alternative causal explanation that A) does not fit the timing in the U.S., B) does not fit the social class data in the U.S., and C) does not fit the international scope of the crisis.&nbsp;</p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/phone-based-childhood-cause-epidemic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>Parents, teachers, and legislators cannot wait any longer; they want to do something about the ever-rising levels of anxiety, distraction, and suffering. Whose policy prescriptions should they follow, given the current state of the evidence and the relative risks and costs associated with each path?&nbsp;</p><p>If leaders and change-makers were to embrace Odgers‚Äô causal theory about the ‚Äúreal causes‚Äù rather than being ‚Äúdistracted‚Äù by mine, then the way forward is to first solve society‚Äôs biggest social problems, most of which we have been working on for decades. Perhaps this time we‚Äôll make more progress, and in ten or twenty years, rates of teen mental illness will begin to decline.&nbsp;</p><p>And if Odger‚Äôs causal theory turns out to be wrong? We‚Äôll have spent another decade or two locked in the usual culture war battles over spending on social programs that may or may not be effective, and we will have lost another generation to mental illness.&nbsp;</p><p>In contrast, if leaders and change makers were to embrace my account of the ‚Äúgreat rewiring of childhood,‚Äù in which the phone-based childhood replaced the play-based childhood, what policy implications follow? That we should roll back the phone-based childhood, especially in elementary school and middle school because of the vital importance of protecting kids during early puberty. More specifically, we‚Äôd try to implement these four norms as widely as possible:&nbsp;</p><ol><li><p><em>No smartphones before high school</em><span> (as a norm, not a law; </span><a href="https://www.anxiousgeneration.com/pdfs/for-parents.pdf" rel="">parents can just give younger kids</a><span> flip phones, basic phones, or phone watches).</span></p></li><li><p><em>No social media before 16</em><span> (as a norm, but one that would be much more effective if supported by laws such as the proposed </span><a href="https://www.commonsensemedia.org/sites/default/files/featured-content/files/coppa-2.0-one-pager-2024.pdf" rel="">update to COPPA</a><span>, the </span><a href="https://www.commonsensemedia.org/sites/default/files/featured-content/files/kosa-one-pager-2024_1.pdf" rel="">Kids Online Safety Act</a><span>, state-level </span><a href="https://californiaaadc.com/" rel="">age-appropriate design codes</a><span>, and new social media bills like the bipartisan </span><a href="https://www.washingtonpost.com/opinions/2023/05/11/social-media-cotton-schatz-murphy-britt/" rel="">Protecting Kids on Social Media Act</a><span>, or like the state level bills passed </span><a href="https://socialmedia.utah.gov/" rel="">in Utah</a><span> last year and in </span><a href="https://www.reuters.com/world/us/floridas-desantis-signs-law-restricting-social-media-people-under-16-2024-03-25/" rel="">Florida</a><span> last month).</span></p></li><li><p><em><a href="https://www.anxiousgeneration.com/pdfs/for-educators.pdf" rel="">Phone-free schools</a></em><span> (use phone lockers or Yondr pouches for the whole school day, so that students can </span><a href="https://www.theatlantic.com/ideas/archive/2023/06/ban-smartphones-phone-free-schools-social-media/674304/" rel="">pay attention to their teachers and to each other</a><span>)</span></p></li><li><p><span>More </span><a href="https://letgrow.org/program/parents-and-families/" rel="">independence, free play, and responsibility</a><span> in the real world.</span></p></li></ol><p>Note that these four reforms, taken together, cost almost nothing, have strong bipartisan support, and can be implemented all right now, this year, if we agree to act collectively.</p><p><span>And what if it turns out that I am wrong? What if, in reality, the multinational collapse of adolescent mental health in the early 2010s was not </span><em>caused</em><span> by the arrival of phone-based childhood; it was just a big coincidence. Will kids be damaged by these four norms? I don‚Äôt think so. What irreversible harm will be done to children who spend more time listening to their teachers during class, more time playing and exploring together outdoors, and less time sitting alone hunched over a device?</span></p><p><span>We are now 12 years into a public health emergency that began around 2012. In </span><em><a href="https://www.anxiousgeneration.com/" rel="">The Anxious Generation</a><span>,</span></em><span> I offer a detailed explanation of what caused it (drawing on many academic fields) and a detailed path by which we can reverse it. I know of no plausible alternative explanation, nor have I found anyone offering a realistic alternative pathway out.</span></p><p>We certainly need skeptics to challenge alarm-ringers, who sometimes do ring false alarms. God bless the skeptics. But at a certain point, we need to take action based on the most plausible theory, even if we can‚Äôt be 100% certain that we have the correct causal theory. I think that point is now.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stalwart mail server (self-hosted all-in-one mail server) now as an admin webui (185 pts)]]></title>
            <link>https://stalw.art/blog/stalwart-webadmin/</link>
            <guid>39983018</guid>
            <pubDate>Tue, 09 Apr 2024 19:08:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stalw.art/blog/stalwart-webadmin/">https://stalw.art/blog/stalwart-webadmin/</a>, See on <a href="https://news.ycombinator.com/item?id=39983018">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>We're thrilled to announce the release of <a href="https://github.com/stalwartlabs/mail-server" target="_blank" rel="noopener noreferrer">Stalwart Mail Server</a> version <code>0.7.0</code>, a significant update that brings a wealth of features and improvements to enhance the performance and manageability of your email services. This release marks a pivotal moment in our journey to provide an email server solution that combines ease of use with robust performance, ensuring that your email infrastructure is both secure and efficient.</p><h3 id="introducing-web-based-administration">Introducing Web-Based Administration<a href="#introducing-web-based-administration" aria-label="Direct link to Introducing Web-Based Administration" title="Direct link to Introducing Web-Based Administration">‚Äã</a></h3><p><img loading="lazy" alt="Setup screencast" src="https://stalw.art/assets/images/screencast-setup-780bc42a88c6e41ad8925d242c2bf469.gif" width="921" height="532"></p><p>At the heart of version <code>0.7.0</code> is the introduction of a new, web-based administration tool. Developed in Rust, this single-page application (SPA) represents a monumental shift in how you interact with Stalwart Mail Server. Gone are the days of relying on SSH connections or command-line interfaces for routine administration tasks. Now, every aspect of your mail server can be managed from the convenience of a web browser.</p><p>The new web administration tool is designed to streamline and simplify the management of your mail server, offering a wide array of features:</p><ul><li><strong>Complete Control Over Accounts and Domains</strong>: Easily manage user accounts, domains, groups, and mailing lists, all from a user-friendly interface.</li><li><strong>Advanced Queue Management</strong>: Monitor and manage your SMTP queues with ease, including messages and outbound DMARC and TLS reports, ensuring timely delivery and compliance.</li><li><strong>Insightful Report Visualization</strong>: Gain valuable insights into your email security with a dedicated interface for visualizing received DMARC, TLS-RPT, and Failure (ARF) reports.</li><li><strong>Full Configuration Flexibility</strong>: Adjust and fine-tune every aspect of your mail server settings directly from the webadmin, tailored to meet your specific requirements.</li><li><strong>Enhanced Log Viewing and Searching</strong>: Navigate through logs effortlessly with advanced search and filtering capabilities, making it easier to pinpoint issues or monitor activity.</li><li><strong>Self-Service Portal for Users</strong>: Empower your users with a self-service portal for password resets and managing encryption-at-rest keys, enhancing security and convenience.</li></ul><p>This transformative approach to mail server management not only elevates the administration experience but also significantly reduces the complexity and time required to manage your email infrastructure.</p><h3 id="enhanced-performance-and-efficiency">Enhanced Performance and Efficiency<a href="#enhanced-performance-and-efficiency" aria-label="Direct link to Enhanced Performance and Efficiency" title="Direct link to Enhanced Performance and Efficiency">‚Äã</a></h3><p>Beyond management improvements, Stalwart Mail Server <code>0.7.0</code> introduces significant performance enhancements to ensure swift and efficient email delivery. A major focus has been placed on optimizing mailbox retrieval speeds to accommodate IMAP clients, particularly those without client-side caching, ensuring that large mailboxes are displayed promptly. This version also integrates automatic compression for messages and binaries stored in the blob store using LZ4, a move that conservatively manages storage space while improving access and transfer speeds. These enhancements collectively ensure that Stalwart Mail Server <code>0.7.0</code> delivers unparalleled performance, making it faster and more efficient than ever before.</p><h3 id="embracing-the-future">Embracing the Future<a href="#embracing-the-future" aria-label="Direct link to Embracing the Future" title="Direct link to Embracing the Future">‚Äã</a></h3><p>With the release of version <code>0.7.0</code>, Stalwart Mail Server sets a new standard for email server solutions. The introduction of a web-based administration tool and significant performance improvements underscore our commitment to innovation and excellence. We invite you to experience the future of email server management and performance with Stalwart Mail Server <code>0.7.0</code>.</p></div></div>]]></description>
        </item>
    </channel>
</rss>