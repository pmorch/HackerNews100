<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 21 Oct 2024 13:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AWS and Azure Are at Least 4x–10x More Expensive Than Hetzner (110 pts)]]></title>
            <link>https://learn.umh.app/course/aws-and-azure-are-at-least-4x-10x-more-expensive-than-hetzner/</link>
            <guid>41902103</guid>
            <pubDate>Mon, 21 Oct 2024 09:07:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://learn.umh.app/course/aws-and-azure-are-at-least-4x-10x-more-expensive-than-hetzner/">https://learn.umh.app/course/aws-and-azure-are-at-least-4x-10x-more-expensive-than-hetzner/</a>, See on <a href="https://news.ycombinator.com/item?id=41902103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
    <div data-post-hero="">

    <div data-post-hero-content="">
          

      

        <p>Why We Recommend Hetzner to Try Out the UMH: it is at least 4x–10x less expensive than AWS and Azure for similar VM instances.</p>

        <ul data-post-hero-authors="">
            <li>
              <a href="https://learn.umh.app/instructor/jeremy/">
                  <picture>
  <source srcset="https://learn.umh.app/content/images/size/w30/format/webp/2023/02/Jeremy_huc484169f1c4136c603a7df27dcdff14f_371473_1200x0_resize_q75_box.jpg 30w, https://learn.umh.app/content/images/size/w100/format/webp/2023/02/Jeremy_huc484169f1c4136c603a7df27dcdff14f_371473_1200x0_resize_q75_box.jpg 100w" sizes="32px" type="image/webp">
  <img onload="this.classList.remove('blur')" loading="lazy" srcset="https://learn.umh.app/content/images/size/w30/format/webp/2023/02/Jeremy_huc484169f1c4136c603a7df27dcdff14f_371473_1200x0_resize_q75_box.jpg 30w, https://learn.umh.app/content/images/size/w100/format/webp/2023/02/Jeremy_huc484169f1c4136c603a7df27dcdff14f_371473_1200x0_resize_q75_box.jpg 100w" sizes="32px" src="https://learn.umh.app/content/images/size/w30/2023/02/Jeremy_huc484169f1c4136c603a7df27dcdff14f_371473_1200x0_resize_q75_box.jpg" alt="">
</picture>
                <span>Jeremy Theocharis</span>
              </a>
            </li>
        </ul>
      

        <p>Why We Recommend Hetzner to Try Out the UMH: it is at least 4x–10x less expensive than AWS and Azure for similar VM instances.</p>
    </div>

      <figure>
        <picture>
  <source srcset="https://learn.umh.app/content/images/size/w320/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 320w, https://learn.umh.app/content/images/size/w640/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 600w, https://learn.umh.app/content/images/size/w960/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 960w, https://learn.umh.app/content/images/size/w1280/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 1200w" sizes="(max-width: 600px) 480px, 720px" type="image/webp">
  <img loading="eager" srcset="https://learn.umh.app/content/images/size/w320/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 320w, https://learn.umh.app/content/images/size/w640/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 600w, https://learn.umh.app/content/images/size/w960/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 960w, https://learn.umh.app/content/images/size/w1280/format/webp/2024/10/YT_Thumbnail_3_Approach-13.png 1200w" sizes="(max-width: 600px) 480px, 720px" src="https://learn.umh.app/content/images/size/w30/2024/10/YT_Thumbnail_3_Approach-13.png" alt="AWS and Azure are At Least 4x–10x More Expensive Than Hetzner">
</picture>
        
      </figure>

  </div>
    <section data-post-content="">
      
      <article data-no-overflow="">
        <p><strong>No, you don’t have to use AWS or Azure. </strong>While AWS and Azure are industry leaders, their advantages often only materialize at massive scales. In many cases, they lead to escalating costs and vendor lock-in without delivering proportional benefits.</p><p>If your organization hasn’t yet  committed to a cloud provider or negotiated fixed contracts, it’s worth exploring alternatives like <a href="https://www.hetzner.com/cloud/?ref=learn.umh.app">Hetzner</a>.</p><p>In this article, we provide a technical comparison between Hetzner, AWS, and Azure, focusing on three key aspects:</p><ol><li>Cost Efficiency</li><li>Adequate Performance and Reliability</li><li>Industry Trends</li></ol><h2 id="cost-efficiency-hetzner-vs-aws-and-azure">Cost Efficiency: Hetzner vs. AWS and Azure</h2><p>Below is a direct comparison of equivalent instances from Hetzner, AWS, and Azure as of <em>2024-10-16</em>.</p><h3 id="base-numbers">Base Numbers</h3><table>
<thead>
<tr>
<th>Cloud Provider</th>
<th>Type</th>
<th>vCPUs</th>
<th>RAM</th>
<th>Monthly Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hetzner Cloud</td>
<td>CPX41</td>
<td>8</td>
<td>16 GB</td>
<td>$32.70 <br> (billed hourly)</td>
</tr>
<tr>
<td>AWS EC2 <br>(1-Year)</td>
<td>c6g.2xlarge</td>
<td>8</td>
<td>16 GiB</td>
<td>$180.60</td>
</tr>
<tr>
<td>AWS EC2 <br>(On-Demand)</td>
<td>c6g.2xlarge</td>
<td>8</td>
<td>16 GiB</td>
<td>$226.59</td>
</tr>
<tr>
<td>Azure VM</td>
<td>F8</td>
<td>8</td>
<td>16 GiB</td>
<td>$331.42 <br> (billed hourly)</td>
</tr>
</tbody>
</table>
<p><strong>Cost Comparison:</strong></p><ul><li>AWS On-Demand vs. Hetzner: $226.59 / $32.70 ≈ <strong>6.93 times</strong> more expensive</li><li>AWS 1-Year Reserved vs. Hetzner: $180.60 / $32.70 ≈ <strong>5.52 times</strong> more expensive</li><li>Azure vs. Hetzner: $331.42 / $32.70 ≈ <strong>10.14 times</strong> more expensive</li></ul><p>This is not an isolated case. Let’s examine more powerful instances:</p><table>
<thead>
<tr>
<th>Instance Type</th>
<th>vCPUs/CPUs</th>
<th>RAM</th>
<th>Monthly Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hetzner CPX51</td>
<td>16 vCPUs</td>
<td>32 GB</td>
<td>$71.23</td>
</tr>
<tr>
<td>Hetzner AX102 <br>(Dedicated CPU, 1-month commitment)</td>
<td>16 CPUs (Dedicated)</td>
<td>128 GB</td>
<td>$134.94</td>
</tr>
<tr>
<td>AWS c6g.4xlarge <br>(1-Year)</td>
<td>16 vCPUs</td>
<td>32 GiB</td>
<td>$361.28</td>
</tr>
<tr>
<td>AWS c6g.4xlarge <br>(On-Demand)</td>
<td>16 vCPUs</td>
<td>32 GiB</td>
<td>$457.72</td>
</tr>
<tr>
<td>AWS r6g.4xlarge</td>
<td>16 vCPUs</td>
<td>128 GiB</td>
<td>$453.18</td>
</tr>
</tbody>
</table>
<p>Not all CPUs are created equal, and performance can vary significantly between different architectures and configurations. AWS’s c6g instances use ARM-based Graviton2 processors, which offer excellent performance per dollar for certain workloads but may present compatibility issues with software not optimized for ARM architecture. When selecting an x86-based instance like AWS’s m7a.2xlarge (8 vCPUs, 32 GB RAM), which utilizes AMD EPYC processors, the cost increases to <strong>$405.47</strong> per month—making it over <strong>5 times more expensive</strong> than Hetzner’s CPX51. </p><h3 id="hidden-costs-in-aws-and-azure">Hidden Costs in AWS and Azure</h3><p>Beyond the base pricing, AWS and Azure often introduce additional expenses that can impact the total cost of ownership:</p><ul><li>Storage Costs: EBS volumes (AWS) and Managed Disks (Azure) are billed separately.</li><li>Data Transfer Fees: Charges apply for data movement between services and outbound internet traffic, which can accumulate based on usage patterns.</li><li>Complex Pricing Models: Layered pricing structures and a multitude of service offerings can make cost estimation and budgeting more challenging.</li></ul><p>In contrast, Hetzner offers straightforward, nearly all-inclusive pricing, simplifying budget management and reducing the risk of unexpected charges. Yes, there are disadvantages about managing your own infrastructure, and we will cover them in the following chapters.</p><h2 id="adequate-performance-and-reliability">Adequate Performance and Reliability</h2><p>For many manufacturing companies and system integrators, the primary requirement is reliable application hosting without the need for massive scaling or global distribution. Most workloads in the manufacturing sector continue to operate on <a href="https://learn.umh.app/lesson/introduction-into-it-ot-system-administration/">virtual machines</a>, often running on-premises Windows servers. In such contexts, the advanced features and managed services offered by AWS and Azure may be excessive and unnecessarily complex.</p><p>Many organizations have small IT teams—sometimes as few as one person—responsible for managing Industrial IoT applications and infrastructure. These teams need straightforward, cost-effective solutions that align with their existing skill sets. Starting with a couple of VMs on Hetzner allows companies to begin their journey into modern IT infrastructure without incurring high costs or requiring specialized personnel.</p><p>In contrast, adopting AWS or Azure from the outset can require a steep learning curve and may necessitate hiring additional staff with specialized expertise. We experienced this firsthand: we spent several weeks trying to perform simple administrative tasks on AWS, such as adding a billing administrator, and found the process unnecessarily complicated.</p><p><strong>Do you really need the advanced features of AWS and Azure right now? Or would a simple virtual machine at a reasonable price be sufficient?</strong> That’s the main question here.</p><p>As the creator of Ruby on Rails puts it:</p><blockquote>I’d rather make some nice software than pay 100 times more for my compute.</blockquote><p>Let's look into what the industry is saying!</p><h2 id="industry-trends">Industry Trends</h2><p>There’s a growing movement among tech companies and startups to opt for more cost-effective hosting solutions like Hetzner. The high costs associated with AWS and Azure are leading many to reconsider their choices.</p><h3 id="ahrefs">Ahrefs</h3><figure><img src="https://learn.umh.app/content/images/2024/10/image-8.png" alt="" loading="lazy" width="721" height="1089" srcset="https://learn.umh.app/content/images/size/w600/2024/10/image-8.png 600w, https://learn.umh.app/content/images/2024/10/image-8.png 721w" sizes="(min-width: 720px) 720px"></figure><p><strong>Ahrefs</strong>, a prominent SEO tool provider, detailed their experience in the article <a href="https://tech.ahrefs.com/how-ahrefs-saved-us-400m-in-3-years-by-not-going-to-the-cloud-8939dd930af8?ref=learn.umh.app">“How Ahrefs Saved US$400M in 3 Years by NOT Going to the Cloud”</a>. Their main points are:</p><p><strong>Vendor Lock-In Concerns:</strong> They emphasized the difficulty of exiting a cloud provider due to convenience and potential vendor lock-in.</p><blockquote>“It is complicated to leave a cloud once you are there… Also, abandoning a cloud infrastructure due to higher costs may not be what the engineering team wants.”</blockquote><p><strong>Performance Advantages</strong>: Owning their hardware allowed for faster and more comprehensive results, enhancing their product.</p><blockquote>“Having faster and better results means that our servers are much faster than what a cloud can provide… Our reports are also generated faster and are more comprehensive.”</blockquote><p><strong>Revenue Implications:</strong> Their total revenue over that period was around $257 million, meaning AWS costs would have exceeded their entire revenue.</p><blockquote>The company revenue wouldn’t even be close to covering the 2½-year AWS usage costs.”</blockquote><p><strong>Massive Cost Savings:</strong> Ahrefs calculated that using AWS would have cost them an additional ~$400 million over 2.5 years compared to their own infrastructure.</p><blockquote>“Ahrefs has saved ~USD 400 million by ensuring its infrastructure is NOT 100% in the IaaS cloud during the last 2½ years.”</blockquote><h3 id="insights-from-industry-leaders">Insights from Industry Leaders</h3><figure><img src="https://learn.umh.app/content/images/2024/10/Screenshot-2024-10-17-at-13.30.48.png" alt="" loading="lazy" width="1278" height="659" srcset="https://learn.umh.app/content/images/size/w600/2024/10/Screenshot-2024-10-17-at-13.30.48.png 600w, https://learn.umh.app/content/images/size/w1000/2024/10/Screenshot-2024-10-17-at-13.30.48.png 1000w, https://learn.umh.app/content/images/2024/10/Screenshot-2024-10-17-at-13.30.48.png 1278w" sizes="(min-width: 720px) 720px"><figcaption><span>David Heinemeier Hansson on the Rails World Conference 2024</span></figcaption></figure><p>David Heinemeier Hansson, the creator of Ruby on Rails, <a href="https://youtu.be/-cEn_83zRFw?t=1652&amp;ref=learn.umh.app">discussed at the Rails World Conference</a> how startups can save costs and gain more powerful machines by choosing providers like Hetzner over AWS or Azure. Key points from his keynote include:</p><p><strong>Critique of Cloud Dependency: </strong>He criticized the industry trend of making developers feel incapable of managing servers, leading to over-reliance on expensive cloud services.</p><blockquote>We’ve sort of all turned into pink elephants tied with a tiny rope of learned helplessness when it comes to deployment… The problem is that the entire industry has cultivated a fear of touching a server.”</blockquote><p><strong>Value of Self-Hosting:</strong> He pointed out that you can get substantially more computing power for less money by managing your own servers.</p><blockquote>You can buy… 40 cores, 96 threads, 256 GB of RAM for $220 a month [from Hetzner]… I’d rather make some nice software than pay 100 times more for my compute.”</blockquote><p><strong>Questioning Cloud Economics:</strong> He highlighted the significant markup on cloud services compared to the actual cost of hardware.</p><blockquote>“AWS has a 40% margin… Dell, someone who actually makes the computers, have a 5% margin. That is a failed market.”</blockquote><p>These perspectives reflect a larger industry movement: companies are reevaluating the cost-benefit equation of major cloud providers, especially when high expenses don’t translate into proportional advantages.</p><h2 id="conclusion-what-has-this-to-do-with-umh">Conclusion: What has this to do with UMH?</h2><p>To get started with the <a href="https://www.umh.app/?ref=learn.umh.app" rel="noreferrer">UMH</a>, you need to install it via the <a href="https://management.umh.app/?ref=learn.umh.app" rel="noreferrer">Management Console</a>, either locally using the experimental Docker container or in a virtual machine.</p><p>If you don’t have an on-premises VM, you don’t need to use AWS or Azure either! By choosing Hetzner, you can deploy a UMH cloud instance for approximately <strong>$32 per month</strong>, compared to several hundred dollars on AWS or Azure. This makes it a much easier sell to conservative manufacturing companies, as <strong>the initial proof of concept (PoC) with the free community edition of UMH and a Hetzner cloud instance costs just a $32 per month of software and infrastructure costs</strong>.</p><p>In conclusion, if you’re just getting started and are not yet locked into AWS or Azure, Hetzner offers a cost-effective, reliable, and straightforward alternative. It allows you to deploy applications like UMH without incurring excessive costs or dealing with unnecessary complexity.</p>
      </article>
    </section>

    

        

      <div data-related="posts">
          <h2>Read next</h2>

          
        </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Drive Blackout in Italy After Another Major Anti-Piracy Blunder (121 pts)]]></title>
            <link>https://torrentfreak.com/google-drive-blackout-in-italy-after-another-major-anti-piracy-blunder-241020/</link>
            <guid>41901168</guid>
            <pubDate>Mon, 21 Oct 2024 06:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/google-drive-blackout-in-italy-after-another-major-anti-piracy-blunder-241020/">https://torrentfreak.com/google-drive-blackout-in-italy-after-another-major-anti-piracy-blunder-241020/</a>, See on <a href="https://news.ycombinator.com/item?id=41901168">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://torrentfreak.com/images/piracy-shield-planet-s.png"><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/piracy-shield-planet-s.png.webp 450w, https://torrentfreak.com/images/piracy-shield-planet-s-300x186.png.webp 300w" sizes="(max-width: 300px) 100vw, 300px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/piracy-shield-planet-s.png" alt="piracy-shield-planet-s" width="300" height="186" srcset="https://torrentfreak.com/images/piracy-shield-planet-s.png 450w, https://torrentfreak.com/images/piracy-shield-planet-s-300x186.png 300w, https://torrentfreak.com/images/piracy-shield-planet-s-150x93.png 150w" sizes="(max-width: 300px) 100vw, 300px">
</picture>
</a>Italy has an administrative blocking mechanism and a technical blocking platform, Piracy Shield, operated by rightsholders in the private sector. </p>
<p>Up until now, AGCOM, Italy’s independent telecoms regulator, has been Piracy Shield’s greatest supporter, at least of those not already benefiting financially from the activities of football league Serie A, currently the only beneficiary of Piracy Shield blocking. </p>
<p>To the extent there’s much of a ‘public’ component to Piracy Shield’s activities in Italy, the ‘private’ absolutely dominates. There’s almost zero transparency and any information of any use is routinely withheld from the public, even when that information relates directly to the public. People who demand access to information are routinely ignored, even punished. The only people never punished are those operating Piracy Shield, no matter how big the blunder or how many people are affected.</p>
<p>After blocking Cloudflare a few months ago, on Saturday night another vital online service was rendered inaccessible. The nature and circumstances of this event should be a signal for the Italian government to remove rightsholders’ ability to meddle in internet infrastructure before it’s too late. The details make for very uncomfortable reading.</p>
<h2>Warnings Pile Up, All Ignored, Again and Again</h2>
<p>When reporting on the <a href="https://torrentfreak.com/piracy-shield-cloudflare-disaster-blocks-countless-sites-fires-up-opposition-240226/">Cloudflare debacle</a> in February, we included commentary from Giorgio Bonfiglio, Principal Technical Account Manager at Amazon Web Services. </p>
<p>Bonfiglio’s expert advice was ignored before, during, and after last year’s introduction of new law to support blocking, despite predicting the Cloudflare problem before it actually became one. As far as we can determine, Bonfiglio was first to link Google Drive’s outage on Saturday evening with Piracy Shield blocking.</p>
<p>“Piracy Shield blocked a Google Drive domain,” Bonfiglio <a href="https://x.com/g_bonfiglio/status/1847728976933904453">revealed</a> on X, along with the AGCOM notice displayed on the blocked domain.</p>
<center><a href="https://torrentfreak.com/images/X-block-1.png"><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/X-block-1.png.webp 663w, https://torrentfreak.com/images/X-block-1-300x181.png.webp 300w" sizes="(max-width: 663px) 100vw, 663px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/X-block-1.png" alt="X-block-1" width="663" height="399" srcset="https://torrentfreak.com/images/X-block-1.png 663w, https://torrentfreak.com/images/X-block-1-300x181.png 300w, https://torrentfreak.com/images/X-block-1-600x361.png 600w, https://torrentfreak.com/images/X-block-1-150x90.png 150w" sizes="(max-width: 663px) 100vw, 663px">
</picture>
</a></center>
<p>The domain/subdomain blocked in the image above is <em>drive.usercontent.google.com</em>; not only does this URL clearly identify Google as its owner, the Google product it serves is on full display too. With no prompting a 10-year-old could identify google.com as important on the internet. So, three broad explanations for how it ended up on the system (ticket below) before causing chaos.</p>
<p><em>1. Domain was accidentally entered into the system, then evaded all subsequent checks<br>
2. Domain was knowingly entered into the system, then evaded all subsequent checks<br>
3. Domain was knowingly entered into the system, and then passed, regardless of risk</em></p>
<center><em>The losing ticket….</em><a href="https://torrentfreak.com/images/shield-ticket1.png"><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/shield-ticket1.png.webp 900w, https://torrentfreak.com/images/shield-ticket1-300x186.png.webp 300w" sizes="(max-width: 670px) 100vw, 670px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/shield-ticket1.png" alt="shield-ticket1" width="670" height="415" srcset="https://torrentfreak.com/images/shield-ticket1.png 900w, https://torrentfreak.com/images/shield-ticket1-300x186.png 300w, https://torrentfreak.com/images/shield-ticket1-600x371.png 600w, https://torrentfreak.com/images/shield-ticket1-150x93.png 150w" sizes="(max-width: 670px) 100vw, 670px">
</picture>
</a></center>
<p>For good measure, the relevant Google IP address [142.250.180.129] was also entered into Piracy Shield to be blocked by local ISPs; <a href="https://x.com/g_bonfiglio/status/1847729915858211314/photo/2">this image</a> shows how access to that IP degraded unlike an adjacent one.</p>
<p>Those hoping to access Google Drive were subject to domain hijacking instead, with requests diverted to a blocking page hosted at different IP addresses depending on the ISP involved; 195.162.95.240 [Sky] and 34.110.214.49 [TIM], for example.</p>
<h2>Blocking in 30 Minutes, Unblocking…whenever</h2>
<p>The domain/IP address block began to take effect a little time after 6pm and as the image below shows, three smaller ‘downtime peaks’ were followed by an almost total degradation of service around 9pm. This seems to show that blunders take at least three hours to fix, even a massive one like this. More tellingly, the constant claim of blocking internet resources within 30 mins is at best, very optimistic indeed.</p>
<p>We took a look at Google Trends data for Italy during the same period. The top five queries in Italy all relate to Google Drive (right) and on the left, the topic ‘Google Drive’ dominates by a very wide margin. Nevertheless, the results are sensitive enough to identify AGCOM and piracy as connected to the trending searches. </p>
<center><a href="https://torrentfreak.com/images/piracy-shield-trends.png"><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/piracy-shield-trends.png.webp 1214w, https://torrentfreak.com/images/piracy-shield-trends-300x129.png.webp 300w" sizes="(max-width: 670px) 100vw, 670px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/piracy-shield-trends.png" alt="piracy-shield-trends" width="670" height="289" srcset="https://torrentfreak.com/images/piracy-shield-trends.png 1214w, https://torrentfreak.com/images/piracy-shield-trends-300x129.png 300w, https://torrentfreak.com/images/piracy-shield-trends-600x259.png 600w, https://torrentfreak.com/images/piracy-shield-trends-150x65.png 150w" sizes="(max-width: 670px) 100vw, 670px">
</picture>
</a></center>
<p>More data is needed to draw firm conclusions but under both columns, Google Drive competitor ‘One Drive’ gets a mention. It wouldn’t be unreasonable to conclude that faced with no access to their files on Google Drive, searching for a replacement would be a logical step. The hidden costs of overblocking are perhaps not quite so hidden here.</p>
<h2>Full Unblocking Doesn’t Take 30 mins</h2>
<p>A full twelve hours after the block was put in place, around 20% of the Italian population still had no access to their Google Drives due to the lingering IP address block that underpinned the domain-based blocking.</p>
<center><a href="https://torrentfreak.com/images/block-delay.png"><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/block-delay.png.webp 733w, https://torrentfreak.com/images/block-delay-300x268.png.webp 300w" sizes="(max-width: 670px) 100vw, 670px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/block-delay.png" alt="block-delay" width="670" height="599" srcset="https://torrentfreak.com/images/block-delay.png 733w, https://torrentfreak.com/images/block-delay-300x268.png 300w, https://torrentfreak.com/images/block-delay-600x536.png 600w, https://torrentfreak.com/images/block-delay-150x134.png 150w" sizes="(max-width: 670px) 100vw, 670px">
</picture>
</a></center>
<p>Had this disaster happened on a weekday, who knows the damage it could’ve caused. Luckily it didn’t, and everyone can be grateful for that, but the word ‘luck’ in a sentence to describe an event that should not have happened, period, understates the seriousness of the situation.</p>
<p>Whether there will be explanation of any kind on Monday is currently unknown, but there is no explaining this one away. Explanations for the Cloudflare block began with denial, slowly moved towards claims it was only a tiny, tiny block that didn’t last long, before Cloudflare was blamed for having a customer allegedly pirating football matches.</p>
<h2>Drastic Action Required Immediately</h2>
<p>Incompetence doesn’t qualify as an excuse, not when a Google domain is part of the equation. So if not incompetence, surely it must’ve been deliberate? Whatever the reason or excuse, the conclusion is the same; this cannot be allowed to continue, and the government must step in before the unthinkable happens. </p>
<p>Since users are about to be fined for piracy, an alternative would be to introduce heavy fines, directly linked to the potential damage to companies, infrastructure or government, plus compensation paid to citizens, for those who overblock.</p>
<p>Let’s say, a population of 59 million in Italy, a conservative 30 million Google users, one euro compensation each, leading to a 30 million euro fine. It won’t stop incompetence, but it should focus the mind during the 30-day ban on any additional blocking or until the fine is paid in full, whichever comes last.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Software engineer titles have almost lost all their meaning (129 pts)]]></title>
            <link>https://www.trevorlasn.com/blog/software-engineer-titles-have-almost-lost-all-their-meaning</link>
            <guid>41900456</guid>
            <pubDate>Mon, 21 Oct 2024 03:33:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trevorlasn.com/blog/software-engineer-titles-have-almost-lost-all-their-meaning">https://www.trevorlasn.com/blog/software-engineer-titles-have-almost-lost-all-their-meaning</a>, See on <a href="https://news.ycombinator.com/item?id=41900456">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p>Remember when being a “Senior Software Engineer” actually meant something? I do, and I can’t help but feel nostalgic for that clarity. In recent years, our industry has witnessed rampant title inflation, turning what used to be a clear-cut junior-mid-senior progression into a confusing parade of inflated roles.</p>
<p>The “senior” title, once a badge of substantial experience and expertise, has been particularly devalued. Today, developers are being crowned “senior” faster than ever, often with just three to four years under their belts. It’s as if the path to seniority, once a marathon of skill-building and diverse experiences, has turned into a sprinter’s dash.</p>
<p>This explosion of grandiose titles isn’t just confusing—it’s eroding the meaning of career milestones in tech. Each new title tries to outdo the last in impressiveness, while paradoxically meaning less and less. For everyone involved—from job seekers to hiring managers—this inflation has muddied the waters of professional progression and recognition.</p>
<h3 id="what-is-a-senior-engineer-anyway">What is a “Senior” Engineer Anyway?</h3>
<p>Being a senior engineer meant far more than just logging years on the job. It was a title earned through a diverse set of experiences and challenges that shaped not just their technical skills, but their entire approach to software development.</p>
<p>A true senior engineer is a battle-tested problem solver. They’ve faced and conquered complex technical challenges across multiple projects, dealing with more than just tricky bugs. These are the architects who’ve untangled system-wide issues that require deep understanding and creative solutions. They’re the ones who can navigate and refactor sprawling legacy codebases with confidence, understanding the delicate balance between maintaining existing systems and building new ones.</p>
<p>Senior engineers have been through the crucible of major production outages. They’ve felt the heat of a system melting down in real-time and learned to stay calm under pressure. These experiences have taught them to diagnose issues rapidly and lead a team through a crisis, making critical decisions when every second counts.</p>
<p>But technical skills alone don’t make a senior engineer. They’re also architectural visionaries who can see beyond immediate tasks to design scalable, maintainable systems. Their decisions positively impact projects years down the line, showcasing a level of foresight that only comes with extensive experience. They’ve developed the soft skills to be effective mentors and leaders, guiding junior developers not just in coding, but in navigating the complex landscape of software development.</p>
<p>Perhaps most importantly, senior engineers remain humble and curious despite their experience. They’re continuous learners, adapting to new technologies and methodologies, always expanding their toolkit. They’ve developed a strong sense of professional ethics, understanding the broader implications of their work and advocating for responsible development practices.</p>
<p>This depth of experience isn’t typically gained in just a few years. It’s forged through diverse projects, multiple tech stacks, and yes, a fair share of failures and lessons learned along the way.</p>
<h3 id="the-root-cause-of-title-inflation">The Root Cause Of Title Inflation</h3>
<p>The fierce competition for talent has led companies, especially startups, to use titles as a retention tactic. Unable to always match the salaries offered by tech giants, these companies resort to inflating titles as a form of non-monetary compensation. While this might seem like a clever short-term solution, it’s creating long-term problems for the industry by diluting the meaning of these titles.</p>
<p>The rise of professional networking platforms like LinkedIn has exacerbated this issue. These platforms have turned titles into personal branding tools, creating immense pressure for individuals to sport impressive-sounding roles. This “LinkedIn Effect” has everyone, from fresh graduates to seasoned professionals, yearning for titles that look good on their profiles, often prioritizing appearance over substance.</p>
<p>HR departments, grappling with the increasing complexity of tech roles, have contributed to this problem as well. In an attempt to accurately categorize the myriad of specialized positions in our rapidly evolving field, they’ve created a proliferation of niche titles. While these titles might be descriptive, they’ve made it increasingly difficult to compare roles across companies, further muddying the waters of career progression.</p>
<p>Lastly, many companies have begun using title promotions as a retention strategy. The intent is to recognize and retain valuable employees, but this approach often backfires. When titles are handed out like participation trophies, they cease to align with actual growth in responsibilities or skills. This misalignment not only devalues the titles themselves but also sets unrealistic expectations for the newly promoted employees.</p>
<p>In essence, what we’re seeing is a perfect storm of market pressures, personal branding needs, organizational challenges, and short-sighted retention strategies. Together, these factors have inflated titles to the point where they risk losing their meaning entirely.</p>
<h3 id="why-do-we-need-to-address-title-inflation">Why Do We Need to Address Title Inflation?</h3>
<p>Title inflation isn’t just about words on a business card or a LinkedIn profile. It’s a problem that strikes at the heart of our industry’s integrity and functionality. When we inflate titles, we’re essentially lying to ourselves and each other about our capabilities and experience.</p>
<p>This deception has real consequences. It creates a mismatch between expectations and reality, leading to situations where people are placed in roles they’re not prepared for. Imagine a “senior” engineer with three years of experience trying to architect a complex system or mentor junior developers. The potential for failure is high, and the stress on that individual is immense.</p>
<h3 id="what-can-we-do-about-title-inflation">What Can We Do About Title Inflation?</h3>
<p>For those in leadership positions, it’s paramount to resist the temptation of using inflated titles as a quick fix for retention or recruitment challenges. Instead, focus on creating meaningful career progression frameworks that tie advancements to concrete skills and responsibilities. Consider implementing a system similar to those used by larger tech companies, where levels (like L3, L4, L5) provide a more nuanced view of seniority without resorting to title inflation.</p>
<p>Companies can take a stand by standardizing their title structures and being transparent about what each level means. This could involve creating detailed job descriptions that clearly outline the expectations and responsibilities for each role. By doing so, you not only provide clarity for your employees but also contribute to a more standardized industry-wide understanding of titles.</p>
<p>HR departments have a critical role to play. They can work on developing more sophisticated ways to categorize and compare roles across the industry. This might involve collaborating with tech leads to create standardized skill matrices that can be used to evaluate candidates and employees more objectively.</p>
<p>Companies that resist title inflation gain a significant competitive edge. By maintaining meaningful titles, they attract and retain top talent who value authentic growth over inflated roles. This leads to more accurate hiring, improved team dynamics, and enhanced productivity. Realistic titles also foster trust, both internally and with clients, positioning the company as a beacon of integrity in the industry. Ultimately, companies with well-defined, honest title structures build stronger, more capable teams and a reputation for excellence that sets them apart in the market.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A step toward fully 3D-printed active electronics (132 pts)]]></title>
            <link>https://news.mit.edu/2024/mit-team-takes-major-step-toward-fully-3d-printed-active-electronics-1015</link>
            <guid>41899873</guid>
            <pubDate>Mon, 21 Oct 2024 01:17:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.mit.edu/2024/mit-team-takes-major-step-toward-fully-3d-printed-active-electronics-1015">https://news.mit.edu/2024/mit-team-takes-major-step-toward-fully-3d-printed-active-electronics-1015</a>, See on <a href="https://news.ycombinator.com/item?id=41899873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

            <p>Active electronics — components that can control electrical signals — usually contain semiconductor devices that receive, store, and process information. These components, which must be made in a clean room, require advanced fabrication technology that is not widely available outside a few specialized manufacturing centers.</p><p>During the Covid-19 pandemic, the lack of widespread semiconductor fabrication facilities was one cause of a worldwide electronics shortage, which drove up costs for consumers and had implications in everything from&nbsp;<a href="https://news.mit.edu/2022/us-leadership-microelectronics-semiconductors-0119" target="_blank">economic growth to national defense</a>. The ability to 3D print an entire, active electronic device without the need for semiconductors could bring electronics fabrication to businesses, labs, and homes across the globe.</p><p>While this idea is still far off, MIT researchers have taken an important step in that direction by demonstrating fully 3D-printed resettable fuses, which are key components of active electronics that usually require semiconductors.</p><p>The researchers’ semiconductor-free devices, which they produced using standard 3D printing hardware and an inexpensive, biodegradable material, can perform the same switching functions as the semiconductor-based transistors used for processing operations in active electronics.</p><p>Although still far from achieving the performance of semiconductor transistors, the 3D-printed devices could be used for basic control operations like regulating the speed of an electric motor.</p><p>“This technology has real legs. While we cannot compete with silicon as a semiconductor, our idea is not to necessarily replace what is existing, but to push 3D printing technology into uncharted territory. In a nutshell, this is really about democratizing technology. This could allow anyone to create smart hardware far from traditional manufacturing centers,” says Luis Fernando Velásquez-García, a principal research scientist in MIT’s Microsystems Technology Laboratories (MTL) and senior author of a <a href="https://www.tandfonline.com/doi/full/10.1080/17452759.2024.2404157" target="_blank">paper describing the devices</a>, which appears in <em>Virtual and Physical Prototyping.</em></p><p>He is joined on the paper by lead author Jorge Cañada, an electrical engineering and computer science graduate student.</p><p><strong>An unexpected project</strong></p><p>Semiconductors, including silicon, are materials with electrical properties that can be tailored by adding certain impurities. A silicon device can have conductive and insulating regions, depending on how it is engineered. These properties make silicon ideal for producing transistors, which are a basic building block of modern electronics.</p><p>However, the researchers didn’t set out to 3D-print semiconductor-free devices that could behave like silicon-based transistors.</p><p>This project grew out of another in which they were fabricating magnetic coils using extrusion printing, a process where the printer melts filament and squirts material through a nozzle, fabricating an object layer-by-layer.</p><p>They saw an interesting phenomenon in the material they were using, a polymer filament doped with copper nanoparticles.</p><p>If they passed a large amount of electric current into the material, it would exhibit a huge spike in resistance but would return to its original level shortly after the current flow stopped.</p><p>This property enables engineers to make transistors that can operate as switches, something that is typically only associated with silicon and other semiconductors. Transistors, which switch on and off to process binary data, are used to form logic gates which perform computation.</p><p>“We saw that this was something that could help take 3D printing hardware to the next level. It offers a clear way to provide some degree of ‘smart’ to an electronic device,” Velásquez-García says.</p><p>The researchers tried to replicate the same phenomenon with other 3D printing filaments, testing polymers doped with carbon, carbon nanotubes, and graphene. In the end, they could not find another printable material that could function as a resettable fuse.</p><p>They hypothesize that the copper particles in the material spread out when it is heated by the electric current, which causes a spike in resistance that comes back down when the material cools and the copper particles move closer together. They also think the polymer base of the material changes from crystalline to amorphous when heated, then returns to crystalline when cooled down — a phenomenon known as the polymeric positive temperature coefficient.</p><p>“For now, that is our best explanation, but that is not the full answer because that doesn’t explain why it only happened in this combination of materials. We need to do more research, but there is no doubt that this phenomenon is real,” he says.</p><p><strong>3D-printing active electronics</strong></p><p>The team leveraged the phenomenon to print switches in a single step that could be used to form semiconductor-free logic gates.</p><p>The devices are made from thin, 3D-printed traces of the copper-doped polymer. They contain intersecting conductive regions that enable the researchers to regulate the resistance by controlling the voltage fed into the switch.</p><p>While the devices did not perform as well as silicon-based transistors, they could be used for simpler control and processing functions, such as turning a motor on and off. Their experiments showed that, even after 4,000 cycles of switching, the devices showed no signs of deterioration.</p><p>But there are limits to how small the researchers can make the switches, based on the physics of extrusion printing and the properties of the material. They could print devices that were a few hundred microns, but transistors in state-of-the-art electronics are only few nanometers in diameter.</p><p>“The reality is that there are many engineering situations that don’t require the best chips. At the end of the day, all you care about is whether your device can do the task. This technology is able to satisfy a constraint like that,” he says.</p><p>However, unlike semiconductor fabrication, their technique uses a biodegradable material and the process uses less energy and produces less waste. The polymer filament could also be doped with other materials, like magnetic microparticles that could enable additional functionalities.</p><p>In the future, the researchers want to use this technology to print fully functional electronics. They are striving to fabricate a working magnetic motor using only extrusion 3D printing. They also want to finetune the process so they could build more complex circuits and see how far they can push the performance of these devices.</p><p>“This paper demonstrates that active electronic devices can be made using extruded polymeric conductive materials. This technology enables electronics to be built into 3D printed structures. An intriguing application is on-demand 3D printing of mechatronics on board spacecraft,” says Roger Howe, the William E. Ayer Professor of Engineering, Emeritus, at Stanford University, who was not involved with this work.</p><p>This work is funded, in part, by Empiriko Corporation.</p>        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Today is Ubuntu's 20th Anniversary (224 pts)]]></title>
            <link>https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html</link>
            <guid>41898736</guid>
            <pubDate>Sun, 20 Oct 2024 21:44:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html">https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000003.html</a>, See on <a href="https://news.ycombinator.com/item?id=41898736">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Mark Shuttleworth</b> 
    <a href="mailto:ubuntu-announce%40lists.ubuntu.com?Subject=Announcing%20Ubuntu%204.10%20%22The%20Warty%20Warthog%20Release%22&amp;In-Reply-To=" title="Announcing Ubuntu 4.10 &quot;The Warty Warthog Release&quot;">mark at hbd.com
       </a><br>
    <i>Wed Oct 20 11:06:23 CDT 2004</i>
    <ul>
        <li>Previous message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000002.html">Announcing Ubuntu 4.10 (Release Candidate)
</a></li>
        <li>Next message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000004.html">Warty Live CD Released
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/date.html#3">[ date ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/thread.html#3">[ thread ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/subject.html#3">[ subject ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/author.html#3">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>=== Announcing Ubuntu 4.10 "The Warty Warthog Release" ===

The warm-hearted Warthogs of the Warty Team are proud to present the
very first release of Ubuntu!

Ubuntu is a new Linux distribution that brings together the extraordinary
breadth of Debian with a fast and easy install, regular releases (every
six months), a tight selection of excellent packages installed by default
and a commitment to security updates with 18 months of security and
technical support for every release.

You get a distribution that is:

  * absolutely committed to free software,  every end-user application 
on the
    CD is free software

  * 100% free of charge, and the Ubuntu team is committed to keeping
    Ubuntu free of charge

  * security updates for the distribution at no charge for 18 months
    for any release

  * updated to the latest desktop and kernel and infrastructure every
    six months with a new release

  * supports x86, amd64 and ppc processors, with additional ports under
    way

If you've heard all about Ubuntu and just want to get the install CD or
test the Release Candidate Live CD, you can download it here immediately:

  <a href="http://www.ubuntulinux.org/download/">http://www.ubuntulinux.org/download/</a>

If you want a shrinkwrapped CD we will gladly ship it to you at no cost.
To receive a complimentary copy of the Warty Warthog CD -- or a handful
to give to your friends, your school or LUG, register online at:

  <a href="http://shipit.ubuntulinux.org/">http://shipit.ubuntulinux.org/</a>

For more information, you can turn to any of the following resources:

Ubuntu Website: <a href="http://www.ubuntulinux.org/">http://www.ubuntulinux.org</a>

  The website contains some basic background on Ubuntu, an
  overview of the project, information on how to get it, and
  some documentation for the software.

Ubuntu Wiki: <a href="http://wiki.ubuntulinux.org/">http://wiki.ubuntulinux.org</a>

  The wiki is a shared web space used by the Ubuntu community to
  develop new ideas for Ubuntu. Anybody is welcome to edit and
  add to the wiki.

Ubuntu IRC Channel: #ubuntu and on irc.freenode.net

  The Ubuntu IRC channel is your best place to start for help and
  discussion about Ubuntu and the Warty Warthog release. We aim
  to keep the signal-to-noise ratio as high as possible on that
  channel, and on all community forums.

Ubuntu Mailing Lists:

  Ubuntu mailing lists are the heart of our community. In addition to the
  announcement list, and lists for users and developers of Ubuntu,
  there are now Ubuntu mailing lists in German, French, Spanish as well
  as lists devoted to Ubuntu security, news, translators, and the
  inevitable lighthearted chitchat list ("the Sounder"). To get more
  information or subscribe, visit:

    <a href="http://lists.ubuntu.com/">http://lists.ubuntu.com</a>


Warty Warthog Features

 * Simple and fast Installation

   Ubuntu comes on one single CD, with thousands of extra packages
   available online. The install is optimised for speed and
   simplicity. Ubuntu has excellent support for laptops (both
   x86 based and Powerbook / iBook PPC based), and can also be
   setup in a minimalist server configuration.

 * GNOME 2.8

   Ubuntu was the first distribution to ship Gnome 2.8, on the day
   of the 2.8 release. Ubuntu is a great way to try out Gnome 2.8 if
   you have not already experienced its speed and simplicity.

 * Firefox 0.9 (with security patches)

 * First class productivity software

   Evolution 2.0 and OpenOffice.org 1.1.2

 * XFree86 4.3 with improved hardware support

   We also worked hard to detect as much hardware as possible,
   simplifying the X install considerably.

Warty can be installed in a minimalist mode for servers, or in full
desktop mode. It works well on laptops and desktops. Warty is secure
by design - a key goal was to ensure that Warty was as safe from attack
over the internet as possible after a default install.

Thanks to the team of professional and volunteer maintainers who have
worked so hard to bring the Warthog to life, and also to our rapidly
growing community, who have provided excellent testing and ideas for
the future of Ubuntu!

"Ubuntu" is an ancient African word for "humanity towards others", and
we think it's a perfect name for an open source community project. In
that spirit we invite you to join, to contribute and to share Ubuntu
with your own community. Our next release, the Hoary Hedgehog, is due
in six months time. You can help to shape it by joining the team
and contributing your own expertise. See you at #ubuntu on
irc.freenode.net.


</pre>


<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000002.html">Announcing Ubuntu 4.10 (Release Candidate)
</a></li>
	<li>Next message: <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/000004.html">Warty Live CD Released
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/date.html#3">[ date ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/thread.html#3">[ thread ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/subject.html#3">[ subject ]</a>
              <a href="https://lists.ubuntu.com/archives/ubuntu-announce/2004-October/author.html#3">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="http://lists.ubuntu.com/mailman/listinfo/ubuntu-announce">More information about the ubuntu-announce
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft said it lost weeks of security logs for its customers' cloud products (200 pts)]]></title>
            <link>https://techcrunch.com/2024/10/17/microsoft-said-it-lost-weeks-of-security-logs-for-its-customers-cloud-products/</link>
            <guid>41898723</guid>
            <pubDate>Sun, 20 Oct 2024 21:42:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/10/17/microsoft-said-it-lost-weeks-of-security-logs-for-its-customers-cloud-products/">https://techcrunch.com/2024/10/17/microsoft-said-it-lost-weeks-of-security-logs-for-its-customers-cloud-products/</a>, See on <a href="https://news.ycombinator.com/item?id=41898723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Microsoft has notified customers that it’s missing more than two weeks of security logs for some of its cloud products, leaving network defenders without critical data for detecting possible intrusions.</p>

<p>According to a notification sent to affected customers, Microsoft said that “a bug in one of Microsoft’s internal monitoring agents resulted in a malfunction in some of the agents when uploading log data to our internal logging platform” between September 2 and September 19.&nbsp;</p>







<p>The notification said that the logging outage was not caused by a security incident, and “only affected the collection of log events.”&nbsp;</p>

<p>Business Insider <a href="https://www.businessinsider.com/microsoft-tells-customers-it-lost-log-data-key-security-products-2024-10" target="_blank" rel="noreferrer noopener nofollow">first reported</a> the loss of log data earlier in October. Details of the notification have not been widely reported. As noted by <a href="https://cyberplace.social/@GossiTheDog/113313392062371141" target="_blank" rel="noreferrer noopener nofollow">security researcher Kevin Beaumont</a>, the notifications that Microsoft sent to affected companies are likely accessible only to a handful of users with tenant admin rights.</p>

<p>Logging helps to keep track of events within a product, such as information about users signing in and failed attempts, which can help network defenders identify suspected intrusions. Missing logs could make it more difficult to identify unauthorized access to the customers’ networks during that two-week window.&nbsp;</p>

<p>The affected products include Microsoft Entra, Sentinel, Defender for Cloud, and Purview, according to the Business Insider report. Affected customers “may have experienced potential gaps in security related logs or events, possibly affecting customers’ ability to analyze data, detect threats, or generate security alerts,” the notification said.</p>

<p>Microsoft would not answer specific questions about the logging outage, but a Microsoft executive confirmed to TechCrunch that the incident was caused by an “operational bug within our internal monitoring agent.”</p>


<p>“We have mitigated the issue by rolling back a service change. We have communicated to all impacted customers and will provide support as needed,” said John Sheehan, a Microsoft corporate vice president.</p>

<p>The logging outage comes a year after Microsoft <a href="https://techcrunch.com/2023/07/17/microsoft-lost-keys-government-hacked/">came under fire from federal investigators</a> for withholding security logs from certain U.S. federal government departments that host their emails on the company’s hardened, government-only cloud; investigators said having access to those logs could have identified a series of China-backed intrusions far sooner.</p>

<p>The China-backed intruders, referred to as Storm-0558, broke into Microsoft’s network and stole a digital skeleton key that allowed the hackers unfettered access to U.S. government emails stored in Microsoft’s cloud. According to a <a href="https://techcrunch.com/2023/08/11/cyber-security-review-board-microsoft-hack-government-emails/">government-issued postmortem of the cyberattack</a>, the State Department identified the intrusions because it paid for a higher-tier Microsoft license that granted access to security logs for its cloud products, which many other hacked U.S. government agencies did not have.</p>







<p>Following the China-backed hacks, Microsoft said <a href="https://www.wsj.com/articles/microsoft-to-offer-some-cybersecurity-tools-free-after-suspected-china-hack-6db94221" target="_blank" rel="noreferrer noopener nofollow">it would start providing logs</a> to its lower-paid cloud accounts from September 2023.</p>

<p><em>Carly Page contributed reporting.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Skeptical of rewriting JavaScript tools in "faster" languages (113 pts)]]></title>
            <link>https://nolanlawson.com/2024/10/20/why-im-skeptical-of-rewriting-javascript-tools-in-faster-languages/</link>
            <guid>41898603</guid>
            <pubDate>Sun, 20 Oct 2024 21:25:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2024/10/20/why-im-skeptical-of-rewriting-javascript-tools-in-faster-languages/">https://nolanlawson.com/2024/10/20/why-im-skeptical-of-rewriting-javascript-tools-in-faster-languages/</a>, See on <a href="https://news.ycombinator.com/item?id=41898603">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>I’ve written a lot of JavaScript. I <em>like</em> JavaScript. And more importantly, I’ve built up a set of skills in understanding, optimizing, and debugging JavaScript that I’m reluctant to give up on.</p>
<p>So maybe it’s natural that I get a worried pit in my stomach over the current mania to rewrite every Node.js tool in a “faster” language like Rust, Zig, Go, etc. Don’t get me wrong – these languages are cool! (I’ve got a copy of the Rust book on my desk right now, and I even contributed <a href="https://github.com/servo/servo/commits?author=nolanlawson">a bit</a> to Servo for fun.) But ultimately, I’ve invested a ton of my career in learning the ins and outs of JavaScript, and it’s by far the language I’m most comfortable with.</p>
<p>So I acknowledge my bias (and perhaps over-investment in one skill set). But the more I think about it, the more I feel that my skepticism is also justified by some real objective concerns, which I’d like to cover in this post.</p>
<h2>Performance</h2>
<p>One reason for my skepticism is that I just don’t think we’ve exhausted all the possibilities of making JavaScript tools faster. Marvin Hagemeister has done <a href="https://marvinh.dev/blog/speeding-up-javascript-ecosystem/">an excellent job</a> of demonstrating this, by showing how much low-hanging fruit there is in ESLint, Tailwind, etc.</p>
<p>In the browser world, JavaScript has proven itself to be “fast enough” for most workloads. Sure, WebAssembly exists, but I think it’s fair to say that it’s mostly used for niche, CPU-intensive tasks rather than for building a whole website. So why are JavaScript-based CLI tools rushing to throw JavaScript away?</p>
<h3>The big rewrite</h3>
<p>I think the perf gap comes from a few different things. First, there’s the aforementioned low-hanging fruit – for a long time, the JavaScript tooling ecosystem has been focused on building something that <em>works</em>, not something fast. Now we’ve reached a saturation point where the API surface is mostly settled, and everyone just wants “the same thing, but faster.” Hence the explosion of new tools that are nearly drop-in replacements for existing ones: <a href="https://rolldown.rs/">Rolldown</a> for <a href="https://rollupjs.org/">Rollup</a>, <a href="https://oxc.rs/docs/guide/usage/linter">Oxlint</a> for <a href="https://eslint.org/">ESLint</a>, <a href="https://biomejs.dev/formatter/">Biome</a> for <a href="https://prettier.io/">Prettier</a>, etc.</p>
<p>However, these tools aren’t necessarily faster because they’re using a faster language. They could just be faster because 1) they’re being written with performance in mind, and 2) the API surface is already settled, so the authors don’t have to spend development time tinkering with the overall design. Heck, you don’t even need to write tests! Just use the existing test suite from the previous tool.</p>
<p>In my career, I’ve often seen a rewrite from A to B resulting in a speed boost, followed by the triumphant claim that B is faster than A. However, <a href="https://www.youtube.com/live/0F9t_WeJ5p4?t=4234s">as Ryan Carniato points out</a>, a rewrite is often faster just because it’s a rewrite – you know more the second time around, you’re paying more attention to perf, etc.</p>
<h3>Bytecode and JIT</h3>
<p>The second class of performance gaps comes from the things browsers give us for free, and that we rarely think about: the <a href="https://v8.dev/blog/code-caching-for-devs">bytecode cache</a> and <a href="https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/">JIT</a> (Just-In-Time compiler).</p>
<p>When you load a website for the second or third time, if the JavaScript is cached correctly, then the browser doesn’t need to parse and compile the source code into bytecode anymore. It just loads the bytecode directly off disk. This is the bytecode cache in action.</p>
<p>Furthermore, if a function is “hot” (frequently executed), it will be further optimized into machine code. This is the JIT in action.</p>
<p>In the world of Node.js scripts, we don’t get the benefits of the bytecode cache at all. Every time you run a Node script, the entire script has to be parsed and compiled from scratch. This is a big reason for the reported perf wins between JavaScript and non-JavaScript tooling.</p>
<p>Thanks to the inimitable <a href="https://joyeecheung.github.io/blog/about/">Joyee Cheung</a>, though, Node is now getting a <a href="https://github.com/nodejs/node/pull/52535">compile cache</a>. You can set an environment variable and immediately get faster Node.js script loads:</p>
<pre title="">export NODE_COMPILE_CACHE=~/.cache/nodejs-compile-cache
</pre>
<p>I’ve set this in my <code>~/.bashrc</code> on all my dev machines. I hope it makes it into the default Node settings someday.</p>
<p>As for JIT, this is another thing that (sadly) most Node scripts can’t really benefit from. You have to run a function before it becomes “hot,” so on the server side, it’s more likely to kick in for long-running servers than for one-off scripts.</p>
<p>And the JIT can make a big difference! In Pinafore, I considered replacing the JavaScript-based <a href="https://blurha.sh/">blurhash</a> library with a Rust (Wasm) version, before <a href="https://github.com/nolanlawson/pinafore/pull/1781#issuecomment-630562314">realizing</a> that the performance difference was erased by the time we got to the fifth iteration. That’s the power of the JIT.</p>
<p>Maybe eventually a tool like <a href="https://github.com/CanadaHonk/porffor">Porffor</a> could be used to do an AOT (Ahead-Of-Time) compilation of Node scripts. In the meantime, though, JIT is still a case where native languages have an edge on JavaScript.</p>
<p>I should also acknowledge: there is a perf hit from using Wasm versus pure-native tools. So this could be another reason native tools are taking the CLI world by storm, but not necessarily the browser frontend.</p>
<h2>Contributions and debuggability</h2>
<p>I hinted at it earlier, but this is the main source of my skepticism toward the “rewrite it all in native” movement.</p>
<p>JavaScript is, in my opinion, a working-class language. It’s very forgiving of types (this is one reason I’m not a huge TypeScript fan), it’s easy to pick up (compared to something like Rust), and since it’s supported by browsers, there is a huge pool of people who are conversant with it.</p>
<p>For years, we’ve had both library authors and library consumers in the JavaScript ecosystem largely using JavaScript. I think we take for granted what this enables.</p>
<p>For one: the path to contribution is much smoother. To quote <a href="https://fosstodon.org/@mcollina/112723450963851116">Matteo Collina</a>:</p>
<blockquote><p>
  Most developers ignore the fact that they have the skills to debug/fix/modify their dependencies. They are not maintained by unknown demigods but by fellow developers.
</p></blockquote>
<p>This breaks down if JavaScript library authors are using languages that are different (and more difficult!) than JavaScript. They may as well be demigods!</p>
<p>For another thing: it’s straightforward to modify JavaScript dependencies locally. I’ve often tweaked something in my local <code>node_modules</code> folder when I’m trying to track down a bug or work on a feature in a library I depend on. Whereas if it’s written in a native language, I’d need to check out the source code and compile it myself – a big barrier to entry.</p>
<p>(To be fair, this has already gotten a bit tricky thanks to the widespread use of TypeScript. But TypeScript is not <em>too</em> far from the source JavaScript, so you’d be amazed how far you can get by clicking “pretty print” in the DevTools. Thankfully most Node libraries are also not minified.)</p>
<p>Of course, this also leads us back to debuggability. If I want to debug a JavaScript library, I can simply use the browser’s DevTools or a Node.js debugger that I’m already familiar with. I can set breakpoints, inspect variables, and reason about the code as I would for my own code. This <a href="https://developer.chrome.com/blog/wasm-debugging-2020">isn’t impossible with Wasm</a>, but it requires a different skill set.</p>
<h2>Conclusion</h2>
<p>I think it’s great that there’s a new generation of tooling for the JavaScript ecosystem. I’m excited to see where projects like <a href="https://oxc.rs/">Oxc</a> and <a href="https://voidzero.dev/posts/announcing-voidzero-inc">VoidZero</a> end up. The existing incumbents are indeed exceedingly slow and would probably benefit from the competition. (I get especially peeved by the typical <code>eslint</code> + <code>prettier</code> + <code>tsc</code> + <code>rollup</code> lint+build cycle.)</p>
<p>That said, I don’t think that JavaScript is inherently slow, or that we’ve exhausted all the possibilities for improving it. Sometimes I look at truly perf-focused JavaScript, such as the <a href="https://learn.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/whats-new/2024/08/devtools-128#heap-snapshot-improvements">recent improvements</a> to the Chromium DevTools using mind-blowing techniques like <a href="https://github.com/ChromeDevTools/devtools-frontend/commit/b73fc5a44552e81019b614594ba7c375f74fc446">using <code>Uint8Array</code>s as bit vectors</a>, and I feel that we’ve barely scratched the surface. (If you really want an inferiority complex, see <a href="https://github.com/ChromeDevTools/devtools-frontend/commits?author=sethbrenith">other commits from Seth Brenith</a>. They are wild.)</p>
<p>I also think that, as a community, we have not really grappled with what the world would look like if we relegate JavaScript tooling to an elite priesthood of Rust and Zig developers. I can imagine the average JavaScript developer feeling completely hopeless every time there’s a bug in one of their build tools. Rather than empowering the next generation of web developers to achieve more, we might be training them for a career of learned helplessness. Imagine what it will feel like for the average junior developer to face a <a href="https://en.wikipedia.org/wiki/Segmentation_fault">segfault</a> rather than a familiar JavaScript <code>Error</code>.</p>
<p>At this point, I’m a senior in my career, so of course I have little excuse to cling to my JavaScript security-blanket. It’s part of my job to dig down a few layers deeper and understand how every part of the stack works.</p>
<p>However, I can’t help but feel like we are embarking down an unknown path with unintended consequences, when there is another path that is less fraught and could get us nearly the same results. The current freight train shows no signs of slowing down, though, so I guess we’ll find out when we get there.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Create mind maps to learn new things using AI (164 pts)]]></title>
            <link>https://github.com/aotakeda/learn-thing</link>
            <guid>41898076</guid>
            <pubDate>Sun, 20 Oct 2024 20:01:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/aotakeda/learn-thing">https://github.com/aotakeda/learn-thing</a>, See on <a href="https://news.ycombinator.com/item?id=41898076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Mind Map Visualization Project</h2><a id="user-content-mind-map-visualization-project" aria-label="Permalink: Mind Map Visualization Project" href="#mind-map-visualization-project"></a></p>
<p dir="auto">This is a simple <a href="https://nextjs.org/" rel="nofollow">Next.js</a> project that implements a mind map visualization tool using <a href="https://reactflow.dev/" rel="nofollow">React Flow</a>.</p>
<p dir="auto">Watch a demo of it in action <a href="https://www.youtube.com/watch?v=Y-9He-tG3aM" rel="nofollow">here</a> or check out the gif below.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/aotakeda/learn-thing/blob/main/public/demo.gif"><img src="https://github.com/aotakeda/learn-thing/raw/main/public/demo.gif" alt="Demo gif" data-animated-image=""></a></p>
<p dir="auto">The UI is built using <a href="https://ui.shadcn.com/" rel="nofollow">shadcn</a> and some components from <a href="https://magicui.design/" rel="nofollow">Magic UI</a>.</p>
<p dir="auto">It allows users to view and interact with mind maps, and download the mind map data as a markdown file.</p>
<p dir="auto">The mind map data is generated using either local models from <a href="https://ollama.com/" rel="nofollow">Ollama</a> or external models like <a href="https://openai.com/" rel="nofollow">OpenAI</a> and leveraging <a href="https://sdk.vercel.ai/docs/introduction" rel="nofollow">AI SDK</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Interactive mind map visualization</li>
<li>Node details view in a side sheet</li>
<li>Markdown export functionality</li>
<li>Save mind map data to a local JSON file</li>
<li>Switch between local and external models</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Install all dependencies:</p>

<p dir="auto">Copy the <code>.env.template</code> file to <code>.env.local</code> and specify which model (local or external) you want to use by setting the <code>NEXT_PUBLIC_USE_LOCAL_MODELS</code> environment variable to <code>true</code> or <code>false</code>.</p>
<p dir="auto">When running an OpenAI model, you must specify your OpenAI API key in the <code>.env.local</code> file.</p>
<p dir="auto">Inside the <code>route.ts</code> file, you must specify the model you are running using Ollama, by default it will use the <code>llama3.1</code> model for local models and for external models it will use the <code>gpt-3.5-turbo</code> model.</p>
<p dir="auto">Bear in mind that external models tend to be much faster serving than local models.</p>
<p dir="auto">If you want to learn how to run a model locally, check out the <a href="https://github.com/ollama/ollama/blob/main/README.md#quickstart">Ollama documentation</a>.</p>
<p dir="auto">Now you're ready to run the development server:</p>

<p dir="auto">Open <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> with your browser and then start creating your own learning mind maps.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prompts</h2><a id="user-content-prompts" aria-label="Permalink: Prompts" href="#prompts"></a></p>
<p dir="auto">The prompts used to generate the mind map data is defined in the <code>defaultLocalPrompt</code> and <code>defaultExternalPrompt</code> variables in the <code>prompts.ts</code> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebGPU-Based WiFi Simulator (276 pts)]]></title>
            <link>https://wifi-solver.com</link>
            <guid>41897214</guid>
            <pubDate>Sun, 20 Oct 2024 18:01:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wifi-solver.com">https://wifi-solver.com</a>, See on <a href="https://news.ycombinator.com/item?id=41897214">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Do AI detectors work? Students face false cheating accusations (213 pts)]]></title>
            <link>https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations</link>
            <guid>41896973</guid>
            <pubDate>Sun, 20 Oct 2024 17:26:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations">https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations</a>, See on <a href="https://news.ycombinator.com/item?id=41896973">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kurt Vonnegut's lost board game published (264 pts)]]></title>
            <link>https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview</link>
            <guid>41896636</guid>
            <pubDate>Sun, 20 Oct 2024 16:44:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview">https://www.polygon.com/board-games/467103/kurt-vonnegut-ghq-lost-board-game-publisher-interview</a>, See on <a href="https://news.ycombinator.com/item?id=41896636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Fans of literature most likely know Kurt Vonnegut for the novel <em><a rel="sponsored" href="https://www.amazon.com/Slaughterhouse-Five-Kurt-Vonnegut-audiobook/dp/B015EKZX2U/?tag=polygon05-20">Slaughterhouse-Five</a></em>. The staunchly anti-war book first resonated with readers during the Vietnam War era, later becoming a staple in high school curricula the world over. When Vonnegut died in 2007 at the age of 84, he was widely recognized as one of the greatest American novelists of all time. But would you believe that he was also an accomplished game designer?</p><p>In 1956, following the lukewarm reception of his first novel, <em>Player Piano</em>, Vonnegut was one of the 16 million other World War II veterans struggling to put food on the table. His moneymaking solution at the time was a board game called <em>GHQ</em>, which leveraged his understanding of modern combined arms warfare and distilled it into a simple game played on an eight-by-eight grid. Vonnegut pitched the game relentlessly to publishers all year long according to game designer and NYU faculty member <a href="https://gamecenter.nyu.edu/faculty/geoff-engelstein/">Geoff Engelstein</a>, who recently found those letters sitting in the archives at <a href="https://libraries.indiana.edu/lilly-library/kurt-vonnegut">Indiana University</a>. But the real treasure was an original set of typewritten rules, complete with Vonnegut’s own notes in the margins. </p><p>With the permission of the Vonnegut estate, Engelstein tells Polygon that he cleaned the original rules up just a little bit, buffed out the dents in <em>GHQ</em>’s endgame, and spun up some decent art and graphic design. Now you can purchase the final product, titled <em>Kurt Vonnegut’s GHQ: The Lost Board Game</em>, at your local Barnes &amp; Noble — nearly 70 years after it was created.</p><div><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="445" data-pswp-width="600" target="_blank" rel="noreferrer"><img alt="A render of GHQ set up on a table for play. The markers are large and colorful, shaped like arrows and blocks. " data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_laid_out.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><cite>Image: Mars International</cite></p></div><p>In a recent interview with Polygon, Engelstein still seemed stunned to have stumbled over the game in the first place through his research. But what’s truly fascinating to him is how diametrically opposed to Vonnegut’s later work <em>GHQ </em>truly is.</p><p>“<em>Sirens of Titan</em> was written at the same time as he was working on this game,” Engelstein told Polygon. “In <em>Sirens of Titan</em>, there’s this army of Mars which is really a joke. No one in the army, [not] even the officers, are really in charge of what’s going on. They’re all mind controlled. Nobody has any real free will. They’re just set up as a pawn to be sacrificed, to make Earth come together, kind of <em>Watchmen</em>-style.” </p><div id=":R3irarr6:"><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_1.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_compilation_2.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div></div><p>While <em><a rel="sponsored" href="https://www.amazon.com/The-Sirens-of-Titan-Kurt-Vonnegut-audiobook/dp/B001D1ILCO/?tag=polygon05-20">The Sirens of Titan</a></em> was a deeply cynical view of war, <em>GHQ </em>is deeply <em>un</em>cynical. In fact, his own pitch letters note that Vonnegut thought <em>GHQ</em> would be an excellent training aid for future military leaders, including cadets at West Point. How are modern audiences to reconcile those words from the same man who wrote <em><a rel="sponsored" href="https://www.amazon.com/Cats-Cradle-Kurt-Vonnegut-audiobook/dp/B000Z7FH9M/?tag=polygon05-20">Cat’s Cradle</a></em>?</p><p>“There’s no definitive answers [to those questions],” Engelstein said. “He didn’t write about it. Nobody asked him about it while he was alive, so we will never know.”</p><p>For fans of board gaming, the questions go in a slightly different direction: What if Vonnegut’s pitches from the 1950s had been successful? </p><p>Engelstein reasons that if Vonnegut was pitching the game in ’56, then it would have taken at least a few years for the game to be produced and finally published. That 1958-1959 window would have placed <em>GHQ</em> in rare company — 1958 was the year <em>Tactics 2</em> was published, a game that would go on to inspire the <a href="https://www.polygon.com/features/2013/1/29/3916154/turn-by-turn-battlefront-combat-mission">Squad Leader</a> series of map-and-token tactical wargames and, ultimately, video game genres like turn-based and real-time strategy. Just a year later and the industry would see the release of <em>Risk</em> and <em>Diplomacy</em>, the precursors of the modern 4X genre and, in and of themselves, two successful franchises that are popular to this day. </p><div><p><a href="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="2000" data-pswp-width="3000" target="_blank" rel="noreferrer"><img alt="A letter pitching GHQ to the Sallfield Publishing Company in Ohio. Also a rejection letter from the same organization." data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq_rejection_5a4312.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p>“Three games that had tremendous influence, all war-related, coming out in that one-year, two-year period,” Engelstein mused. “So if <em>GHQ</em> also came out at the time period? There’s something in the air at that point, obviously.”</p><p>Of course, we’ll never know how those counterfactuals would have played out, but at least <em>GHQ</em> is finally available to the public. That’s great news for one of its original playtesters, Kurt Vonnegut’s son, Mark Vonnegut, who’s now 77. Engelstein said his input was invaluable in bringing the game to life.</p><p>“The success of <em>Slaughterhouse-Five</em> and the other novels is nice enough,” Vonnegut’s son recently wrote Engelstein in an email, “but I truly believe he’s watching somehow, someway, from somewhere and that the success of <em>GHQ</em> will be a greater and purely unadulterated pleasure. [...] He was discouraged about his writing at the time, but had unshakable faith that <em>GHQ</em> would succeed.”</p><p>You can find <em>Kurt Vonnegut’s GHQ: The Lost Board Game</em>, along with a special forward by <a href="https://www.polygon.com/24164196/expanse-james-s-a-corey-new-book-mercy-gods">author James S.A. Corey</a>, exclusively at Barnes &amp; Noble.</p><div data-product-filter=""><p><a href="https://go.skimresources.com/?id=1025X1701642&amp;xs=1&amp;url=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fkurt-vonneguts-ghq-the-lost-board-game-mars-international%2F1146300521" rel="nofollow noopener noreferrer" target="_blank"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 768px) 100vw, 300px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=16.700150678051%2C0%2C66.599698643898%2C100&amp;w=2400"></a><a href="https://go.skimresources.com/?id=1025X1701642&amp;xs=1&amp;url=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fkurt-vonneguts-ghq-the-lost-board-game-mars-international%2F1146300521" rel="nofollow noopener noreferrer" target="_blank"><img alt="" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 768px) 100vw, 600px" srcset="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=376 376w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=384 384w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=415 415w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=480 480w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=540 540w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=640 640w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=750 750w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=828 828w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1080 1080w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1200 1200w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1440 1440w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=1920 1920w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2048 2048w, https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2400 2400w" src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/10/ghq.jpg?quality=90&amp;strip=all&amp;crop=0.050226017076845%2C0%2C99.899547965846%2C100&amp;w=2400"></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drasi: Microsoft's open source data processing platform for event-driven systems (278 pts)]]></title>
            <link>https://github.com/drasi-project/drasi-platform</link>
            <guid>41896297</guid>
            <pubDate>Sun, 20 Oct 2024 16:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/drasi-project/drasi-platform">https://github.com/drasi-project/drasi-platform</a>, See on <a href="https://news.ycombinator.com/item?id=41896297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Drasi</h2><a id="user-content-drasi" aria-label="Permalink: Drasi" href="#drasi"></a></p>
<p dir="auto">Drasi is a data processing platform that simplifies detecting changes in data and taking immediate action. It is a comprehensive solution that provides built-in capabilities to track system logs and change feeds for specific events, evaluate them for relevance, and automatically initiate appropriate reactions. Visit our documentation site at <a href="https://drasi.io/" rel="nofollow">https://drasi.io</a> for detailed information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Drasi provides real-time actionable insights without the overhead of traditional data processing methods. It tracks system changes and events without the need to copy data to a central data lake or repeatedly query data sources. Drasi uses queries to continuously evaluate incoming data changes. When the changes match the criteria and conditions specified in these queries the result sets of these queries are updated. These updates then trigger context-aware reactions defined tuned to your specific requirements.</p>
<p dir="auto">Drasi operates through three components:</p>
<ul dir="auto">
<li><strong>Sources</strong> connect to data repositories within software systems to monitor logs and feeds to track changing data.</li>
<li><strong>Continuous Queries</strong> interpret monitored changes by applying criteria and conditions to identify significant changes. In Drasi, these Continuous Queries are written using the Cypher Query Language.</li>
<li><strong>Reactions</strong> trigger meaningful responses based on updates to the result sets of the Continuous Queries.<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/drasi-project/community/blob/main/images/drasi_components.png"><img src="https://github.com/drasi-project/community/raw/main/images/drasi_components.png" alt="Alt text" width="800" height="300"></a></p>
<p dir="auto"><br>To illustrate how Drasi interprets events and triggers appropriate responses, consider a delivery system for an online ordering service. Orders are processed through an order management system, and delivery drivers need real-time notifications when orders are ready for pickup. Drasi automates this process by:<br></p>
<ul dir="auto">
<li>Configuring a Source to monitor the order management system for changes in order statuses and a second Source to detect when a driver becomes available for a delivery run.</li>
<li>Creating a Continuous Query that combines data from both Sources to match orders ready for pickup with available drivers.</li>
<li>Defining a Reaction to send alerts to drivers, notifying them to proceed to the pickup area.
This streamlined setup ensures drivers are promptly informed, optimizing the delivery process through real-time data integration and automated responses.<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/drasi-project/community/blob/main/images/curbside_pickup_drasi.png"><img src="https://github.com/drasi-project/community/raw/main/images/curbside_pickup_drasi.png" alt="Alt text" width="800" height="300"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Follow the <a href="https://drasi.io/getting-started/" rel="nofollow">Getting Started tutorial</a> and try out Drasi. The tutorial will lead you through:</p>
<ol dir="auto">
<li>Applying a Source representing the data source whose changes you want to observe.</li>
<li>Creating Continuous Queries to define the data to observe, conditions to assess changes, and the structure of the output.</li>
<li>Applying a Debug Reaction to view the output generated by one or more Continuous Queries.</li>
</ol>
<p dir="auto">Head over to our <a href="https://drasi.io/" rel="nofollow">documentation site</a> and visit the <a href="https://drasi.io/tutorials/" rel="nofollow">Tutorial</a> and <a href="https://drasi.io/how-to-guides/" rel="nofollow">How To</a> guides to learn more about Drasi.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Release Status</h2><a id="user-content-release-status" aria-label="Permalink: Release Status" href="#release-status"></a></p>
<p dir="auto">This is an early release of Drasi for the community learn about the platform and experiment with in Proofs Of Concept. Please share your thoughts on Drasi and create GitHub issues for any bugs you may find or if you have feature requests that will help improve Drasi.</p>
<p dir="auto">This repo contains everything you require to build a Drasi-based solution with Sources, Reactions, and tooling for development and testing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">We hope you will join us and contribute to Drasi! Some of the ways to get started with contributing are participating in Issue discussions or joining us on our <a href="https://aka.ms/drasidiscord" rel="nofollow">Discord server</a>. Check out our <a href="https://github.com/drasi-project/community">Community repo</a> for more information on the community, and guidance on contributing and development.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing To Drasi</h2><a id="user-content-contributing-to-drasi" aria-label="Permalink: Contributing To Drasi" href="#contributing-to-drasi"></a></p>
<p dir="auto">Please see the <a href="https://github.com/drasi-project/drasi-platform/blob/main/CONTRIBUTING.md">Contribution guide</a> for information on contributing to Drasi.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Please refer to our guide on <a href="https://github.com/drasi-project/drasi-platform/blob/main/SECURITY.md#reporting-security-issues">reporting security vulnerabilities</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code of Conduct</h2><a id="user-content-code-of-conduct" aria-label="Permalink: Code of Conduct" href="#code-of-conduct"></a></p>
<p dir="auto">Please refer to Drasi's <a href="https://github.com/drasi-project/community/blob/main/CODE_OF_CONDUCT.md">Code of Conduct</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <strong>Apache 2.0 license</strong>. Please see the <a href="https://github.com/drasi-project/community/blob/main/LICENSE">LICENSE</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact the Drasi Authors</h2><a id="user-content-contact-the-drasi-authors" aria-label="Permalink: Contact the Drasi Authors" href="#contact-the-drasi-authors"></a></p>
<p dir="auto">Please join us on Discord to contact us and we will get back to you as soon as possible. You can also email us at <a href="mailto:info@drasi.io">info@drasi.io</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Part of PostgreSQL We Hate the Most (2023) (301 pts)]]></title>
            <link>https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html</link>
            <guid>41895951</guid>
            <pubDate>Sun, 20 Oct 2024 15:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html">https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html</a>, See on <a href="https://news.ycombinator.com/item?id=41895951">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>There are a lot of choices in databases (<a onclick="javascript:pageTracker._trackPageview('/outgoing/dbdb.io');" href="https://dbdb.io/" target="_blank">897</a> as of April 2023). With so many systems, it’s hard to know what to pick! But there is an interesting phenomenon where the Internet collectively decides on the default choice for new applications. In the 2000s, the conventional wisdom selected MySQL because rising tech stars like Google and Facebook were using it. Then in the 2010s, it was MongoDB because <a onclick="javascript:pageTracker._trackPageview('/outgoing/stackoverflow.com');" href="https://stackoverflow.com/a/3737121" target="_blank">non-durable writes</a> made it “<a onclick="javascript:pageTracker._trackPageview('/outgoing/youtu.be');" href="https://youtu.be/b2F-DItXtZs" target="_blank">webscale</a>“. In the last five years, PostgreSQL has become the Internet’s darling DBMS. And for good reasons! It’s dependable, feature-rich, extensible, and well-suited for most operational workloads.</p>
<p>But as much as we <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://twitter.com/andy_pavlo/status/1534225032179814403" target="_blank">love PostgreSQL at OtterTune</a>, certain aspects of it are not great. So instead of writing yet another blog article like everyone else touting the awesomeness of everyone’s favorite elephant-themed DBMS, we want to discuss the one major thing that sucks: how PostgreSQL implements <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control" target="_blank">multi-version concurrency control</a> (MVCC). Our <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://db.cs.cmu.edu/papers/2017/p781-wu.pdf" target="_blank">research</a> at Carnegie Mellon University and experience optimizing PostgreSQL database instances on Amazon RDS have shown that its MVCC implementation is the <u><b>worst</b></u> among the other widely used relational DBMSs, including MySQL, Oracle, and Microsoft SQL Server. And yes, Amazon’s PostgreSQL Aurora still has these problems.</p>
<p>In this article, we’ll dive into MVCC: what it is, how PostgreSQL does it, and why it is terrible. Our goal at OtterTune is to give you <i>fewer</i> things to worry about with your databases, so we’ve thought a lot about dealing with this problem. We’ll cover OtterTune’s solution for managing PostgreSQL’s MVCC issues automatically for RDS and Aurora databases in a follow-up article next week.</p>
<h2 id="what-is-mvcc">What is Multi-Version Concurrency Control?</h2>
<p>The goal of MVCC in a DBMS is to allow multiple queries to read and write to the database simultaneously without interfering with each other when possible. The basic idea of MVCC is that the DBMS never overwrites existing rows. Instead, for each (logical) row, the DBMS maintains multiple (physical) versions. When the application executes a query, the DBMS determines which version to retrieve to satisfy the request according to some version ordering (e.g., creation timestamp). The benefit of this approach is that multiple queries can read older versions of rows without getting blocked by another query updating it. Queries observe a snapshot of the database as it existed when the DBMS started that query’s transaction (snapshot isolation). This approach eliminates the need for explicit <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/explicit-locking.html" target="_blank">record locks</a> that block readers from accessing data while writers modify the same item.</p>
<p>David Reed’s 1978 MIT Ph.D. dissertation, “<a onclick="javascript:pageTracker._trackPageview('/outgoing/dspace.mit.edu');" href="https://dspace.mit.edu/handle/1721.1/16279" target="_blank">Concurrency Control in Distributed Database Systems</a>,” was, we believe, the first publication to describe MVCC. The first commercial DBMS implementation of MVCC was <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/InterBase#History" target="_blank">InterBase</a> in the 1980s. Since then, nearly every new DBMS created in the last two decades that supports transactions implements MVCC.</p>
<p>A systems engineer has to make several design decisions when building a DBMS that supports MVCC. At a high level, it comes down to the following:</p>
<ol>
  <li aria-level="1">How to store updates to existing rows.</li>
  <li aria-level="1">How to find the correct version of a row for a query at runtime.</li>
  <li aria-level="1">How to remove expired versions that are no longer visible.</li>
</ol>

<p>These decisions are not mutually exclusive. In the case of PostgreSQL, it’s how they decided to handle the first question in the 1980s that caused problems with the other two that we still have to deal with today.</p>
<p>For our discussion, we will use the following example of a table containing movie information. Each row in the table includes the movie name, release year, director, and a unique ID serving as the primary key, with secondary indexes on the movie name and director. Here is the DDL command to create this table:</p>
<pre><code>CREATE TABLE movies (
  id INTEGER PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
  name VARCHAR(256) NOT NULL,
  year SMALLINT NOT NULL,
  director VARCHAR(128)
);
CREATE INDEX idx_name ON movies (name);
CREATE INDEX idx_director ON movies (director);</code></pre>

<p>The table contains a primary index (<code>movies_pkey</code>) and two secondary B+Tree indexes (<code>idx_name</code>, <code>idx_director</code>).</p>
<h2 id="postgresql-mvcc">PostgreSQL’s Multi-Version Concurrency Control</h2>

<p>As discussed in Stonebraker’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/apps.dtic.mil');" href="https://apps.dtic.mil/sti/citations/ADA187244" target="_blank">system design document from 1987</a>, PostgreSQL was designed from the beginning to support multi-versioning. The core idea of PostgreSQL’s MVCC scheme is seemingly straightforward: when a query updates an existing row in a table, the DBMS makes a copy of that row and applies the changes to this new version instead of overwriting the original row. We refer to this approach as the <b>append-only</b> version storage scheme. But as we now describe, this approach has several non-trivial implications in the rest of the system.</p>
<h3>Multi-Versioned Storage</h3>
<p>PostgreSQL stores all row versions in a table in the same storage space. To update an existing tuple, the DBMS first acquires an empty slot from the table for the new row version. It then copies the row content of the current version to the new version, and applies the modifications to the row in the newly allocated version slot. You can see this process in the example below when an application executes an update query on the movies database to change the release year of “<a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Shaolin_and_Wu_Tang" target="_blank">Shaolin and Wu Tang</a>” from 1985 to 1983:</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example1.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example1.svg"></a>
  <figcaption>When an UPDATE query changes a tuple in the table, PostgreSQL copies the original version of the tuple and then applies the change to the new version. In this example, there is no more space in Table Page #1, so PostgreSQL creates the new version in Table Page #2.</figcaption>
</figure>

<p>Now with two physical versions representing the same logical row, the DBMS needs to record the lineage of these versions so that it knows how to find them in the future. MVCC DBMSs achieve this by creating a <b>version chain</b> via a singly linked-list. The version chain only goes in one direction to reduce storage and maintenance overhead. This means that the DBMS has to decide what order to use: <i>newest-to-oldest</i> (N2O) order or <i>oldest-to-newest</i> (O2N). For the N2O order, each tuple version points to its previous version and the version chain’s head is always the latest version. For the O2N order, each tuple version points to its new version, and the head is the oldest tuple version. The O2N approach avoids the need for the DBMS to update indexes to point to a newer version of the tuple each time it’s modified. However, it may take longer for the DBMS to find the latest version during query processing, potentially traversing a long version chain. Most DBMSs, including Oracle and MySQL, implement N2O. But PostgreSQL stands alone in using O2N (except for Microsoft’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/learn.microsoft.com');" href="https://learn.microsoft.com/en-us/sql/relational-databases/in-memory-oltp/introduction-to-memory-optimized-tables?view=sql-server-ver16" target="_blank">In-Memory OLTP engine</a> for SQL Server).</p>
<p>The next issue is how PostgreSQL determines what to record for these version pointers. The header for each row in PostgreSQL contains a tuple id field ( <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/storage-page-layout.html#STORAGE-TUPLE-LAYOUT" target="_blank">t_tcid</a>) of the next version (or its own tuple id if it is the latest version). Thus, as shown in this next example, when a query requests the latest version of a row, the DBMS traverses the index, lands on the oldest version, and then follows the pointer until it finds a version that it needs.</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example3.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example3.svg"> </a>
  <figcaption>The SELECT query traverses the index to find tuple with requested movie name. The index entry points to the oldest version of the tuple, which means PostgreSQL follows the version chain embedded in the original version to find the new version.</figcaption>
</figure>

<p>PostgreSQL developers realized early on that there are two problems with its MVCC scheme. First, making a new copy of an entire tuple every time it is updated is expensive. And second, traversing the entire version chain just to find the latest version (which is what most queries want) is wasteful. Of course there is also the problem of cleaning up old versions, but we’ll cover that below.</p>
<p>To avoid traversing the entire version chain, PostgreSQL adds an entry to a table’s indexes for each physical version of a row. That means if there are five physical versions of a logical row, there will be (at most) five entries for that tuple in the index! In the example below, we see that the <code>idx_name</code> index contains entries for each of the “Shaolin and Wu Tang” rows that are on separate pages. This enables direct access to the latest version of the tuple, without the need to traverse the long version chain.</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example4.svg">
    <img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example4.svg">
    </a>
    <figcaption>In this example, the index contains multiple entries for the “Shaolin and Wu Tang” tuple (one for each version). Now PostgreSQL uses the index to find the latest version and then immediately retrieves it from Table Page #2 without having to traverse the version chain starting at Table Page #1.</figcaption>
</figure>

<p>PostgreSQL tries to avoid having to install multiple index entries and storing related versions over multiple pages by creating a new copy in the same disk page (block) as the old version to reduce disk I/O. This optimization is known as <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/storage-hot.html" target="_blank">heap-only tuple (HOT)</a> updates. The DBMS uses the HOT approach if an update does not modify any columns referenced by a table’s indexes and the new version is stored on the same data page as the old version (if there is space in that page). Now in our example, after the update the index still points to the old version and queries retrieve the latest version by traversing the version chain. During normal operation, PostgreSQL further optimizes this process by removing old versions to prune the version chain.</p>
<h3>Version Vacuum</h3>
<p>We’ve established that PostgreSQL makes a copy of rows whenever an application updates them. The next question is how the system removes older versions (called “dead tuples”). The original version of PostgreSQL from the 1980s did not remove dead tuples. The idea was that keeping all the older versions allowed applications to execute “time-travel” queries to examine the database at a particular point in time (e.g., run a <code>SELECT</code> query on the state of the database as it existed at the end of last week). But never removing dead tuples means tables never shrink in size if the application deletes tuples. It also means long version chains for frequently updated tuples, which would slow down queries, except that PostgreSQL adds index entries that allow queries to quickly jump to the correct version instead of traversing the chain. But now, this means the indexes are larger, making them slower and adding additional memory pressure. Hopefully, you can understand now why all these issues are interconnected.</p>
<p>To overcome these problems, PostgreSQL uses a vacuum procedure to clean up dead tuples from tables. The vacuum performs a sequential scan on table pages modified since its last run and find expired versions. The DBMS considers a version “<b>expired</b>” if it is not visible to any active transaction. This means no current transaction is accessing that version, and future transactions will use the latest “<b>live</b>” version instead. Thus, removing the expired version and reclaiming the space for reuse is safe.</p>
<p>PostgreSQL automatically executes this vacuum procedure (autovacuum) at regular intervals based on its configuration settings. In addition to the global settings that affect the vacuum frequency for all tables, PostgreSQL provides the flexibility to configure autovacuum at the table level to fine-tune the process for specific tables. Users can also trigger the vacuum manually to optimize database performance via the <code>VACUUM</code> SQL command.</p>
<h2 id="why-postgresqls-mvcc-is-the-worst">Why PostgreSQL’s MVCC is the Worst</h2>
<p>We will be blunt: if someone is going to build a new MVCC DBMS today, they should <u> <b>not</b> </u> do it the way PostgreSQL does (e.g., append-only storage with autovacuum). In our <a onclick="javascript:pageTracker._trackPageview('/downloads/papers/2017/p781-wu.pdf');" href="https://db.cs.cmu.edu/papers/2017/p781-wu.pdf" target="_blank">2018 VLDB paper</a> (aka “ <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/andy_pavlo/status/902863242774634496" target="_blank">the best paper ever on MVCC</a>“), we did not find another DBMS doing MVCC the way PostgreSQL does it. Its design is a relic of the 1980s and before the proliferation of <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Log-structured_merge-tree" target="_blank">log-structured</a> system patterns from the 1990s.</p>
<p>Let’s talk about four problems that arise with PostgreSQL’s MVCC. We will also talk about why other MVCC DBMSs like Oracle and MySQL avoid these problems.</p>
<h3>Problem #1: Version Copying</h3>
<p>With the append-only storage scheme in MVCC, if a query updates a tuple, the DBMS copies all its columns into the new version. This copying occurs no matter if the query updates a single or all of its columns. As you can imagine, append-only MVCC results in massive data duplication and increased storage requirements. This approach means that PostgreSQL requires more memory and disk storage to store a database than other DBMS, which means slower queries and higher cloud costs. Instead of copying an entire tuple for a new version, MySQL and Oracle store a compact delta between the new and current versions (think of it like a git diff). Using deltas means that if a query only updates a single column in a tuple for a table with 1000 columns, then the DBMS only stores a delta record with the change to that one column. On the other hand, PostgreSQL creates a new version with the one column that the query changed and the 999 other untouched columns. We will ignore TOAST attributes because PostgreSQL <a onclick="javascript:pageTracker._trackPageview('/outgoing/dba.stackexchange.com');" href="https://dba.stackexchange.com/a/308779" target="_blank">handles them differently</a>.</p>
<p>There was an attempt to modernize PostgreSQL’s version storage implementation. EnterpriseDB started the <a onclick="javascript:pageTracker._trackPageview('/outgoing/wiki.postgresql.org');" href="https://wiki.postgresql.org/wiki/Zheap" target="_blank">zheap project</a> in 2013 to replace the append-only storage engine to use delta versions. Unfortunately the <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.cybertec-postgresql.com');" href="https://www.cybertec-postgresql.com/en/postgresql-zheap-current-status/" target="_blank">last official update was in 2021</a>, and to the best of our knowledge the effort has fizzled out.</p>
<h3>Problem #2: Table Bloat</h3>
<p>Expired versions in PostgreSQL (i.e., dead tuples) also occupy more space than delta versions. Although PostgreSQL’s autovacuum will eventually remove these dead tuples, write-heavy workloads can cause them to accumulate faster than the vacuum can catch up, resulting in continuous database growth. The DBMS has to load dead tuples into memory during query execution since the system intermingles dead tuples with live tuples in pages. Unfettered bloat slows query performance by causing the DBMS to incur more IOPS and consume more memory than necessary during table scans. Additionally, inaccurate optimizer statistics caused by dead tuples can lead to poor query plans.</p>
<p>Suppose our movies table has 10 million live and 40 million dead tuples, making 80% of the table obsolete data. Assume also that the table also has many more columns than what we are showing and that the average size of each tuple is 1KB. With this scenario, the live tuples occupy 10GB of storage space while the dead tuples occupy ~40GB of storage; the total size of the table is 50GB. When a query performs a full table scan on this table, PostgreSQL has to retrieve all 50GB from the disk and store it in memory, even if most of it is obsolete. Although Postgres has a <a onclick="javascript:pageTracker._trackPageview('/outgoing/madusudanan.com');" href="https://madusudanan.com/blog/understanding-postgres-caching-in-depth/#SeqScans" target="_blank">protection mechanism</a> to avoid polluting its buffer pool cache from sequential scans, it does not help prevent IO costs.</p>
<p>Even if you make sure that PostgreSQL’s autovacuum is running at regular intervals and able to keep up with your workload (which is not always easy to do, see below), the autovacuum cannot reclaim storage space. The autovacuum only removes dead tuples and relocates live tuples within each page, but it does not reclaim empty pages from the disk.</p>
<p>When the DBMS truncates the last page due to the absence of any tuple, other pages remain on disk. In our example above, even if PostgreSQL removed the 40GB of dead tuples from the movies table, it still retains the 50GB of allocated storage space from the operating system (or, in the case of RDS, from Amazon). To reclaim and return such unused space, one must use <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/current/sql-vacuum.html#:~:text=VACUUM%20FULL%20rewrites%20the%20entire,while%20it%20is%20being%20processed." target="_blank"><code>VACUUM FULL</code></a> or the <a onclick="javascript:pageTracker._trackPageview('/outgoing/reorg.github.io');" href="https://reorg.github.io/pg_repack/" target="_blank">pg_repack</a> extension to rewrite the entire table to a new space with no wasted storage. Running either of these operations is not an easy endeavor that one should take without considering the performance implications for production databases; they are resource-intensive and time-consuming operations that will crush query performance. The following figure shows how <code>VACUUM</code> and <code>VACUUM FULL</code> work.</p>
<figure>
    <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-vacuum.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-vacuum.svg"> </a>
    <figcaption>With PostgreSQL’s regular VACUUM operation, the DBMS only removes dead tuples from each table page and reorganizes it to put all the live tuples at the end of the page. With VACUUM FULL, PostgreSQL removes the dead tuples from each page, coalesces and compacts the remaining live tuples to a new page (Table Page #3), and then deletes the unneeded pages (Table Pages #1 / #2).</figcaption>
</figure>

<h3>Problem #3: Secondary Index Maintenance</h3>
<p>A single update to a tuple requires PostgreSQL to update all the indexes for that table. Updating all the indexes is necessary because PostgreSQL uses the exact physical locations of a version in both primary and secondary indexes. Unless the DBMS stores the new version in the same page as the previous version (HOT update), the system does this for every update.</p>
<p>Returning to our <code>UPDATE</code> query example, PostgreSQL creates a new version by copying the original version into a new page just like before. But it also inserts entries pointing to the new version in table’s primary key index ( <code>movies_pkey</code>) and the two secondary indexes ( <code>idx_director</code>, <code>idx_name</code>).</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example5.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-example5.svg"> </a>
  <figcaption>Example of PostgreSQL index maintenance operations with a non-HOT update. The DBMS creates the new version of the tuple in Table Page #2, and then inserts new entries that point to that version in all the table’s indexes.</figcaption>
</figure>

<p>The need for PostgreSQL to modify all of a table’s indexes for each update has several performance implications. Obviously, this makes update queries slower because the system has to do more work. The DBMS incurs additional I/O to traverse each index and insert the new entries. Accessing an index introduces lock/latch contention in both the index and the DBMS’s internal data structures (e.g., buffer pool’s page table). Again, PostgreSQL does this maintenance work for all a table’s indexes, even if queries are never going to use them (by the way, OtterTune <a onclick="javascript:pageTracker._trackPageview('/outgoing/docs.ottertune.com');" href="https://docs.ottertune.com/documentation/database-instance-dashboard-and-recommendations/recommendations/index-recommendations">automatically finds unused indexes in your database</a>). These extra reads and writes are problematic in DBMSs that charge users based on IOPS, like Amazon Aurora.</p>
<p>As described above, PostgreSQL avoids updating indexes each time if it can perform a HOT write where the new version is on the same page as the current version. Our analysis of OtterTune customers’ PostgreSQL databases shows that roughly 46% of updates use the HOT optimization on average. Although that’s an impressive number, it still means more than 50% of the updates are paying this penalty.</p>
<p>There are many examples of users struggling with this aspect of PostgreSQL’s MVCC implementation. The most famous testament of this is Uber’s 2016 blog article about why they <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.uber.com');" href="https://www.uber.com/blog/postgres-to-mysql-migration/" target="_blank">switched from Postgres to MySQL</a>. Their write-heavy workload was experiencing significant performance problems on tables with many secondary indexes.</p>
<p>Oracle and MySQL do not have this problem in their MVCC implementation because their secondary indexes do not store the physical addresses of new versions. Instead, they store a logical identifier (e.g., tuple id, primary key) that the DBMS then uses to look up the current version’s physical address. Now this may make secondary index reads slower since the DBMS has to resolve a logical identifier, but these DBMS have other advantages in their MVCC implementation to reduce overhead.</p>


<h3>Problem #4: Vacuum Management</h3>
<p>PostgreSQL’s performance relies heavily on the effectiveness of the autovacuum to remove obsolete data and reclaim space (this is why OtterTune immediately checks the health status of the autovacuum when you first connect your database). It does not matter if you are running RDS, Aurora, or Aurora Serverless; all variants of PostgreSQL have the same autovacuum issues. But making sure that PostgreSQL’s autovacuum is running as best as possible is difficult due to its complexity. PostgreSQL’s default settings for tuning the autovacuum are not ideal for all tables, particularly for large ones. For example, the default setting for the configuration knob that controls what percentage of a table PostgreSQL has to update before the autovacuum kicks in (<a onclick="javascript:pageTracker._trackPageview('/outgoing/www.postgresql.org');" href="https://www.postgresql.org/docs/15/runtime-config-autovacuum.html#GUC-AUTOVACUUM-VACUUM-SCALE-FACTOR" target="_blank">autovacuum_vacuum_scale_factor</a>) is 20%. This threshold means that if a table has 100 million tuples, the DBMS does not trigger the autovacuum until queries update at least 20 million tuples. As such, PostgreSQL may unnecessarily keep around a lot of dead tuples in a table (thereby incurring IO and memory costs) for a long time.</p>
<p>Another problem with the autovacuum in PostgreSQL is that it may get blocked by long-running transactions, which can result in the accumulation of more dead tuples and stale statistics. Failing to clean expired versions in a timely manner leads to numerous performance problems, causing more long-running transactions that block the autovacuum process. It becomes a vicious cycle, requiring humans to intervene manually by killing long-running transactions. Consider the graph below that shows the number of dead tuples in an OtterTune customer’s database over two weeks:</p>
<figure>
  <a href="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-deadtuples.svg"><img decoding="async" src="https://www.cs.cmu.edu/~pavlo/images/blog/020/ottertune-mvcc-deadtuples.svg"></a>
  <figcaption>The number of dead tuples over time in a PostgreSQL Amazon RDS database.</figcaption>
</figure>

<p>The sawtooth pattern in the chart shows that the autovacuum performs a major clean-up about once every day. For example, on February 14th, the DBMS cleaned up 3.2 million dead tuples. This graph is actually an example of an unhealthy PostgreSQL database. The chart clearly shows an upward trend in the number of dead tuples because the autovacuum cannot keep up.</p>
<p>At OtterTune, we see this problem often in our customers’ databases. One PostgreSQL RDS instance had a long-running query caused by stale statistics after bulk insertions. This query blocked the autovacuum from updating the statistics, resulting in more long-running queries. OtterTune’s automated health checks identified the problem, but the administrator still had to kill the query manually and run <a onclick="javascript:pageTracker._trackPageview('/outgoing/ottertune.com');" href="https://ottertune.com/blog/run-postgresql-analyze-to-fix-a-slowdow-in-db/">ANALYZE after bulk insertions</a>. The good news is that the long query’s execution time went from 52 minutes to just 34 seconds.</p>

<p>There are always hard design decisions one has to make when building a DBMS. And these decisions will cause any DBMS to perform differently on varying workloads. For Uber’s specific write-intensive workload, PostgreSQL’s index write amplification due to MVCC is why they switched to MySQL. But please don’t misunderstand our diatribe to mean that we don’t think you should ever use PostgreSQL. Although its MVCC implementation is the wrong way to do it, PostgreSQL is still our favorite DBMS. To love something is to be willing to work with its flaws (see Dan Savage’s <a onclick="javascript:pageTracker._trackPageview('/outgoing/youtu.be');" href="https://youtu.be/r1tCAXVsClw" target="_blank">“The Price of Admission”</a>).</p>
<p>So how does one work around PostgreSQL’s quirks? Well, you can spend an enormous amount of time and effort tuning it yourself. <a onclick="javascript:pageTracker._trackPageview('/outgoing/philbooth.me');" href="https://philbooth.me/blog/nine-ways-to-shoot-yourself-in-the-foot-with-postgresql" target="_blank">Good luck with that</a>.</p>
<p>We’ll cover more about what we can do in our next article.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive breached again through stolen access tokens (441 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/</link>
            <guid>41895764</guid>
            <pubDate>Sun, 20 Oct 2024 15:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/">https://www.bleepingcomputer.com/news/security/internet-archive-breached-again-through-stolen-access-tokens/</a>, See on <a href="https://news.ycombinator.com/item?id=41895764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="The Internet Archive" height="900" src="https://www.bleepstatic.com/content/hl-images/2024/10/09/internet-archive.jpg" width="1600"></p>
<p>The Internet Archive was breached again, this time on their Zendesk email support platform after repeated warnings that threat actors stole exposed GitLab authentication tokens.</p>
<p>Since last night, BleepingComputer has received numerous messages from people who received replies to their old Internet Archive removal requests, warning that the organization has been breached as they did not correctly rotate their stolen authentication tokens.</p>
<p>"It's dispiriting to see that even after being made aware of the breach weeks ago, IA has still not done the due diligence of rotating many of the API keys that were exposed in their gitlab secrets," reads an email from the threat actor.</p>
<p>"As demonstrated by this message, this includes a Zendesk token with perms to access 800K+ support tickets sent to info@archive.org since 2018."</p>
<p>"Whether you were trying to ask a general question, or requesting the removal of your site from the Wayback Machine your data is now in the hands of some random guy. If not me, it'd be someone else."</p>
<div>
<figure><img alt="Internet Archive Zendesk emails sent by the threat actor" height="600" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/zendesk-emails.jpg" width="937"><figcaption><strong>Internet Archive Zendesk emails sent by the threat actor</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The email headers in these emails also pass all DKIM, DMARC, and SPF authentication checks, proving they were sent by an authorized Zendesk server at&nbsp;192.161.151.10.</p>
<div>
<figure><img alt="Internet Archive Zendesk email headers" height="200" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/mail-headers.jpg" width="909"><figcaption><strong>Internet Archive Zendesk email headers</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>After publishing this story, BleepingComputer was told by a recipient of these emails that they had to upload personal identification when requesting a removal of a page from the Wayback Machine.</p>
<p>The threat actor may now also have access to these attachments depending on the API access they had to Zendesk and if they used it to <a href="https://developer.zendesk.com/api-reference/ticketing/tickets/ticket-attachments/#show-attachment" target="_blank" rel="nofollow noopener">download support tickets</a>.</p>
<p>These emails come after BleepingComputer repeatedly tried to warn the Internet Archive that their source code was stolen through a&nbsp;GitLab authentication token that was exposed online for almost two years.</p>
<h2>Exposed GitLab authentication tokens</h2>
<p>On October 9th, BleepingComputer reported that Internet&nbsp;Archive was <a href="https://www.bleepingcomputer.com/news/security/internet-archive-hacked-data-breach-impacts-31-million-users/" target="_blank">hit by two different attacks at once last week</a>—a data breach where the site's user data for 33 million users was stolen and a DDoS attack by a pro-Palestinian group named SN_BlackMeta.</p>
<p>While both attacks occurred over the same period, they were conducted by different threat actors. However, many outlets incorrectly reported that SN_BlackMeta was behind the breach rather than just the DDoS attacks.</p>
<div>
<figure><img alt="JavaScript alert on Internet Archive warning about the breach" height="300" width="665" data-src="https://www.bleepstatic.com/images/news/security/d/data-breaches/w/wayback-machine/js-alert.jpg" src="https://www.bleepstatic.com/images/news/security/d/data-breaches/w/wayback-machine/js-alert.jpg"><figcaption><strong>JavaScript alert on Internet Archive warning about the breach</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>This misreporting frustrated the threat actor behind the actual data breach, who contacted BleepingComputer through an intermediary to claim credit for the attack and explain how they breached the Internet Archive.</p>
<p>The threat actor told BleepingComputer that the initial breach of Internet Archive started with them finding an exposed GitLab configuration file on one of the organization's development servers, <em>services-hls.dev.archive.org</em>.</p>
<p>BleepingComputer was able to confirm that this token has been exposed since at least December 2022, with it rotating multiple times since then.</p>
<div>
<figure><img alt="Exposed Internet Archive GitLab authentication token" height="600" width="860" data-src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/gitlab-token.jpg" src="https://www.bleepstatic.com/images/news/security/attacks/i/internet-archive/gitlab-tokens/gitlab-token.jpg"><figcaption><strong>Exposed Internet Archive GitLab authentication token</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The threat actor says this GitLab configuration file contained an authentication token allowing them to download the Internet Archive source code.</p>
<p>The hacker say that this source code contained additional credentials and authentication tokens, including the credentials to Internet Archive's database management system. This allowed the threat actor to download the organization's user database, further source code, and modify the site.</p>
<p>The threat actor claimed to have stolen 7TB of data from the Internet Archive but would not share any samples as proof.</p>
<p>However, now we know that the stolen data also included the API access tokens for Internet Archive's Zendesk support system.</p>
<p>BleepingComputer attempted contact the Internet Archive numerous times, as recently as on Friday, offering to share what we knew about how the breach occurred and why it was done, but we never received a response.</p>
<h2>Breached for cyber street cred</h2>
<p>After the Internet Archive was breached, conspiracy theories abounded about why they were attacked.</p>
<p>Some said&nbsp;Israel did it,&nbsp;the United States government, or corporations in their ongoing battle with the Internet Archive over copyright infringement.</p>
<p>However, the Internet Archive was not breached for political or monetary reasons but simply because the threat actor could.</p>
<p>There is a large community of people who traffic in stolen data, whether they do it for money by extorting the victim, selling it to other threat actors, or simply because they are collectors of data breaches.</p>
<p>This data is often released for free to gain <em>cyber street cred</em><strong>,&nbsp;</strong>increasing their reputation among other threat actors in this community&nbsp;as they all compete for who has the most significant and most publicized attacks.</p>
<p>In the case of the Internet Archive, there was no money to be made by trying to extort the organization. However, as a well-known and extremely popular website, it definitely boosted a person's reputation amongst this community.</p>
<p>While no one has publicly claimed this breach, BleepingComputer was told it was done&nbsp;while the threat actor was in a group chat with others, with many receiving some of the stolen data.</p>
<p>This database is now likely being traded amongst other people in the data breach community, and we will likely see it leaked for free in the future on hacking forums like Breached.</p>
<p><em>Update 10/20/24: Added information about how some people had to upload personal IDs when requesting removal from Internet Archive.</em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The AI Investment Boom (227 pts)]]></title>
            <link>https://www.apricitas.io/p/the-ai-investment-boom</link>
            <guid>41895746</guid>
            <pubDate>Sun, 20 Oct 2024 14:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apricitas.io/p/the-ai-investment-boom">https://www.apricitas.io/p/the-ai-investment-boom</a>, See on <a href="https://news.ycombinator.com/item?id=41895746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><strong>Thanks for reading! If you haven’t subscribed, please click the button below:</strong></p><p><strong>By subscribing you’ll join over 45,000 people who read Apricitas!</strong></p><p><span>Last month, Microsoft made a high-profile announcement that it is paying to </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=63304" rel="">reopen reactor one at the Three Mile Island nuclear plant to meet the company’s growing data center power demand, joining Amazon</a><span> as the second major US tech company to turn to legacy nuclear facilities for their increasing energy needs. Microsoft is the primary investor and computing provider for OpenAI, who kicked off a revolution in AI development with its release of ChatGPT less than two years ago—and the Three Mile Island reopening underscored the frenzied growth in physical investment currently going on to meet the demands of these new AI systems.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:215863,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5612c0b3-6bf4-44ba-b573-95ac968f3d4b_2886x1843.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Today, AI products are used ubiquitously to generate code, text, and images, analyze data, automate tasks, enhance online platforms, and much, much, much more—with usage expected only to increase going forward. Yet these cutting-edge models require enormous computing resources for their training and inference, that computing requires massive arrays of advanced hardware housed at industrial-scale facilities, and those facilities require access to vast quantities of power, water, broadband, and other infrastructure for their operations.</p><p><span>Thus, the downstream result of the AI boom has been a rapid increase in US fixed investment to meet the growth in computing demand, with hundreds of billions of dollars going to high-end computers, data center facilities, power plants, and more. Right now, US data center construction is at a record-high rate of $28.6B a year, up 57% from last year and 114% from only two years ago. For context, that’s roughly as much as America spends on </span><a href="https://www.census.gov/construction/c30/historical_data.html" rel="">restaurant, bar, and retail store construction combined.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:353767,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c4ba116-ab33-45e6-a439-45e0af48c1cb_2886x1843.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>However, that construction figure is only for the physical buildings themselves—it excludes the massive racks of high-powered computers that form the brains of data centers plus the vast quantities of cables, fans, and other parts necessary to make that brain work. In August, net US imports of large computers (like those used for AI training) rose to a new record high, and net imports of computer parts, accessories, and other components had set a record high just the month before—in total, the US has brought in more than $65B across the two categories over the last year </span><a href="https://fred.stlouisfed.org/series/A34SVS" rel="">on top of rising domestic production.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:257436,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F034e4193-7897-4616-ba76-15e4c88b0cea_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The majority of these new data centers, computers, and equipment are being bought by companies in the information technology space—that includes computing infrastructure providers like Amazon, web search firms like Google, and software publishers like Microsoft. Those companies have increased their net holdings of property, plant, and equipment by more than $95B over the last year, a record high, as they each compete to rapidly scale up and deploy their AI systems.</p><p><span>It’s a stark change from a little over a decade ago, when Facebook bought up Instagram for only $1.2B, following it up by paying $15B for WhatsApp two years later. At the time, these acquisitions were some of the largest in tech history and marked the beginning of an era where lightweight software publishers were considered the industry’s future—in total, Instagram had only 13 employees at the time it was purchased, Whatsapp had only 55, and neither company had much of a physical presence beyond some office space and programmers’ workstations. Today, </span><a href="https://s21.q4cdn.com/399680738/files/doc_financials/2024/q2/META-Q2-2024-Earnings-Call-Transcript.pdf" rel="">Facebook (now Meta) has spent $15.2B on capital expenditures in the first half of 2024 alone</a><span>, much of it on massive arrays of computing infrastructure to support the company’s Llama brand of AI models. So far, the AI boom has been more hardware-intensive than any tech boom in history, and that is rapidly boosting construction and investment within the United States.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/be130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:212869,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe130439-788c-4884-91e1-7d9bd42f2c0a_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>American businesses’ investment in computers and related equipment has skyrocketed to a new record high amidst the AI boom, </span><a href="https://fred.stlouisfed.org/graph/?g=1wxmt" rel="">jumping 16.6% over the last year even after adjusting for inflation.</a><span> That’s in stark contrast to the nearly-decade-long relative stagnation in investment seen throughout the 2010s, which was only really shattered by the digital demands of the pandemic-era remote work boom. Computer investment retracted a bit in 2022 as work-from-home levels and internet usage stabilized, but it then came roaring back with the AI boom starting in late 2023.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:249266,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8734e08-9b80-4c97-8197-e7661004686a_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Yet not all computers are created equal—total computer investment may be at record levels, but the growth in the highest-end computer systems has been even faster. Taiwan’s TSMC is the world’s leading manufacturer of cutting-edge semiconductors, and the ravenous demand for AI compute is visible in the growing amount of chips, computers, and related components that the US now imports from Taiwan. Those imports have totaled more than $38B over the last year, rising more than 140% over the previous year, with little sign of stopping. All three categories have seen rapid growth, but direct US imports of logic chips have seen the largest relative increase, rising from relatively minimal levels to nearly $5B a year. Computer parts and components remain the largest import item—a reminder that data centers require more than just computers for their day-to-day operation and even when operational require further supplies for their maintenance and repair.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223124,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d8a83df-0f4a-4897-a01a-b9e2dfa61610_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://apps.bea.gov/iTable/?ReqID=10&amp;step=2&amp;_gl=1*gocdd0*_ga*NzU5NjY0MDc1LjE3MTgwMDA3NzE.*_ga_J4698JNNFT*MTcyOTQyNDU4OC44NC4wLjE3Mjk0MjQ1ODguNjAuMC4w#eyJhcHBpZCI6MTAsInN0ZXBzIjpbMiwzXSwiZGF0YSI6W1siVGFibGVfTGlzdCIsIjU3Il1dfQ==" rel="">Breaking down the detailed sector-level investment data available through 2023</a><span> shows that </span><a href="https://imgur.com/ECaAd3r" rel="">although data processors and web search firms like Amazon/Google continued to have the largest investment levels in the tech space</a><span>, it was software developers who saw the fastest investment growth. Software publishers’ real investment in intellectual property—which encompasses many of the AI models themselves plus related research and development—grew by 40% since 2021, while real investment in equipment like computers grew by an astonishing 96%. The era of leading software developers being hardware-light companies has been replaced by an era where developers are racing each other to see who can build out hardware capabilities the fastest.</span></p><p><span>All of this hardware investment is not, however, evenly spread throughout the country. While data centers have to be spread out to some extent in order to serve networking needs and avoid binding infrastructure constraints, it’s often beneficial to concentrate them in large clusters to multiply their effectiveness and reduce costs/latency. That’s especially true for AI, which is why firms are pushing the limits of data center size </span><a href="https://www.semianalysis.com/p/multi-datacenter-training-openais" rel="">and networking</a><span> to throw as much computing power at model development as possible.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:455992,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0135f5cc-fc51-43be-ac6d-be4e08c995c6_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>While we do not have granular data center construction data—official construction numbers only break down data center spending at the regional level—we can still see some interesting underlying patterns. The US data center buildout has remained strongest in its historical clusters within the American South, but growth has been much faster in markets throughout the Midwest and West Coast, while the Northeast has been functionally unaffected.</p><p><span>That buildout can have large implications for local power demand—over the last few months, the Energy Information Administration has </span><a href="https://www.eia.gov/outlooks/steo/pdf/steo_full.pdf" rel="">repeatedly raised its projections for load growth based on data center demand</a><span>, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=62409" rel="">now predicting that total commercial-sector electricity consumption will rise 3% this year and another 1% next year.</a><span> While those projections still leave commercial users as </span><a href="https://www.eia.gov/outlooks/steo/data/browser/#/?v=19&amp;f=A&amp;s=0&amp;start=2024&amp;end=2025&amp;chartindexed=2&amp;map=&amp;linechart=~ELCCTWH~ELRCTWH~ELICTWH&amp;id=&amp;ctype=linechart&amp;maptype=0" rel="">a smaller driver of rising power consumption than residential electrification and industrial reshoring</a><span>, they represent the sector’s fastest demand growth in years—for context, </span><a href="https://www.eia.gov/electricity/data/browser/#/topic/5?agg=0,1&amp;geo=g&amp;endsec=vg&amp;linechart=~~ELEC.SALES.US-COM.A~&amp;columnchart=ELEC.SALES.US-ALL.A~ELEC.SALES.US-RES.A~ELEC.SALES.US-COM.A~ELEC.SALES.US-IND.A&amp;map=ELEC.SALES.US-ALL.A&amp;freq=A&amp;ctype=linechart&amp;ltype=pin&amp;rtype=s&amp;maptype=0&amp;rse=0&amp;pin=" rel="">commercial power consumption rose only 5% in total between 2007 and 2023</a><span> and the </span><a href="https://www.eia.gov/energyexplained/electricity/use-of-electricity.php" rel="">pre-AI-boom official estimates put computers &amp; office equipment at only 11.4% of total commercial power consumption.</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:318101,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F908a35b0-18da-4548-989b-36eb2d74751b_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Yet in some parts of the country, data center power consumption has been a major driver of electricity load growth—to use an illustrative example, North Dakota’s commercial power consumption has risen by more than 45% after the </span><a href="https://www.governor.nd.gov/news/burgum-one-worlds-largest-data-centers-locate-williston-area-industry-targets-growth-nd" rel="">opening of several key data centers in 2022.</a><span> However, North Dakota is a relatively tiny power and computing market, so the most significant increases in raw power demand have instead come from larger data center clusters in larger states like Virginia and Texas.</span></p><p><span>The </span><a href="https://x.com/JosephPolitano/status/1846265551611707500" rel="">byteway</a><span> in the Northern Virginia suburbs of DC is the largest cluster of computing power in the world, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=62409" rel="">and it’s caused the state to see a 30% increase in commercial energy consumption since 2019 and the largest raw increase in commercial power demand in the nation.</a><span> Texas, which has explicitly worked to attract data centers and crypto miners as part of its energy load management program, has also seen a 10% increase in commercial power consumption since 2019, </span><a href="https://www.eia.gov/todayinenergy/detail.php?id=63344" rel="">with much larger growth expected in the coming years.</a></p><p><span>That data center load growth has been a contributor to </span><a href="https://www.apricitas.io/p/the-regional-impacts-of-americas" rel="">the Lone Star State’s notable overperformance in renewable investment, where it leads the rest of the country significantly.</a><span> Indeed, ERCOT (Texas’ power grid) and PJM (which serves Virginia) are both currently </span><a href="https://www.eia.gov/outlooks/steo/data/browser/#/?v=22&amp;f=A&amp;s=0&amp;start=2023&amp;end=2025&amp;chartindexed=1&amp;map=&amp;linechart=RTEPGEN_US~RNEPGEN_TX~RNEPGEN_PJ~&amp;maptype=0&amp;ctype=linechart&amp;id=" rel="">projected to outpace the nation in renewables growth through this year and 2025.</a><span> The agglomeration benefits of data centers mean that AI firms are increasingly looking to concentrate near large power resources, hence the renewed focus on nuclear energy and the growing desire for tech companies to directly invest in power generation infrastructure as they build computing capabilities.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:428185,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ab4a7b9-6565-4d42-9036-e86ece5f2435_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Amidst the AI boom, revenue in the information technology space has rebounded from the slowdown of 2022 and 2023—software publishers, web search portals, and computing infrastructure providers have all seen their incomes rise by 12-15% over the last year. It’s a far cry from the halcyon days of 2021, but still puts revenue growth on the strong side of pre-COVID norms.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png" width="1456" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:312405,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42130026-484f-4ff4-8227-31fe24156b2b_2886x1843.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Yet despite the tech sector’s recent rebound in revenues and boom in physical investment, employment growth has remained remarkably weak. The US has added only 32k tech jobs over the last year, lower than at any point in 2021, 2022, or the 9 years preceding the pandemic. Even the software publishers and computing infrastructure industries at the forefront of this AI boom have seen functionally zero net employment growth over the last year—the dismal job market that has beleaguered recent computer science graduates simply has not improved much.</p><p><span>That’s not to say there’s been no labor market impact of the AI investment boom, but rather that they’ve been primarily outside of traditional information tech sectors. </span><a href="https://imgur.com/b4lxZ7h" rel="">Total compensation in semiconductor manufacturing increased 25% from Q1 2023 to Q1 2024</a><span> as workers in companies like NVIDIA got much more valuable stock options. Some of the </span><a href="https://data.bls.gov/dataViewer/view/timeseries/CEU2023622001" rel="">30k increase in commercial construction jobs over the last year</a><span> is certainly downstream of data center demand—</span><a href="https://www.apricitas.io/p/the-regional-impacts-of-americas" rel="">that’s in addition to the ongoing job boom in industrial construction for chip fabs and other manufacturing sectors, plus the employment gains as part of the electricity power and broader infrastructure buildout.</a><span> Yet so far, the job dynamics of the AI boom have been radically different than the past decade of tech labor markets as growth focuses more on hardware investments, manufacturing/design firms, and infrastructure builders more than traditional programmers.</span></p><p>Right now, AI developers are competing intensely and each banking that continued product improvements and greater commercialization will more than validate the historical scale of current investments. In the near term, investment is only expected to increase as more advanced models are developed and AI usage is expanded into more real-world applications (like self-driving vehicles). Policymakers also view AI as a key part of the future US economy—AI development and data center capacity are cutting-edge industries where America has built a significant lead by virtue of the dominance of Silicon Valley and large US tech conglomerates, and thus the AI boom has benefitted US investment more than perhaps any other country.</p><p><span>Yet that makes it more likely geopolitical competition will intensify around hardware capacity—the CHIPS Act that is driving so much of current US electronics industrial policy was a pre-ChatGPT creation, and some industry heads already complain that it’s showing its age in terms of priorities and scale. The significant increase in demand for high-end semiconductors has boosted US reliance on Taiwanese imports, which the CHIPS Act was supposed to help ameliorate, and there are any number of components where the US remains dependent on China to meet data-center-scale supply. Plus, the US will likely continue restricting Chinese access to the highest-end chips in hopes of holding back their AI development, while China continues to build out its chipmaking capacity in hopes of reducing import dependence. As this AI investment boom continues, </span><a href="https://www.apricitas.io/p/america-and-chinas-chip-race" rel="">expect it to only move further into the forefront of the ongoing Chip War.</a></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Syncthing Android App Discontinued (376 pts)]]></title>
            <link>https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/</link>
            <guid>41895718</guid>
            <pubDate>Sun, 20 Oct 2024 14:51:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/">https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/</a>, See on <a href="https://news.ycombinator.com/item?id=41895718">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/Syncthing/comments/1g7zpvm/syncthing_android_app_discontinued/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Energy-based model explains how chronic stress transforms into disease over time (166 pts)]]></title>
            <link>https://www.sciencedirect.com/science/article/pii/S030645302200292X</link>
            <guid>41895609</guid>
            <pubDate>Sun, 20 Oct 2024 14:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedirect.com/science/article/pii/S030645302200292X">https://www.sciencedirect.com/science/article/pii/S030645302200292X</a>, See on <a href="https://news.ycombinator.com/item?id=41895609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root" data-aa-name="root"><header id="gh-cnt"></header><div id="mathjax-container" role="main"><div role="region" aria-label="Download options and search"><ul aria-label="PDF Options"><li><a target="_blank" aria-label="View PDF. Opens in a new window."><svg focusable="false" viewBox="0 0 35 32" height="20"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span><span><span>View&nbsp;<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article lang="en"><div id="publication"><p><a href="https://www.sciencedirect.com/journal/psychoneuroendocrinology" title="Go to Psychoneuroendocrinology on ScienceDirect"><span><span><img src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/17220c80f4e09945173d394db9fa2f4c6a17b614/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></p><p><a href="https://www.sciencedirect.com/journal/psychoneuroendocrinology/vol/146/suppl/C"><span><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0306453022X00103-cov150h.gif" alt="Psychoneuroendocrinology"></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noreferrer noopener"><span><span>license</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></p><p><span></span>open access</p></div><div id="abstracts"><div id="ab0015"><h2>Highlights</h2><div id="abs0015"><ul><li><span>•</span><span><p>Allostasis and allostatic load cost energy</p></span></li><li><span>•</span><span><p>The organism’s energy consumption capacity is biologically limited</p></span></li><li><span>•</span><span><p>The transition from allostasis to allostatic load is defined by an energetic tradeoff where allostasis and stress-related energy costs compete with growth, maintenance, and repair</p></span></li><li><span>•</span><span><p>The energetic model of allostatic load (EMAL) makes testable predictions requiring further research</p></span></li></ul></div></div><div id="ab0010"><h2>Abstract</h2><div id="abs0010"><p>Chronic psychosocial stress increases disease risk and mortality, but the underlying mechanisms remain largely unclear. Here we outline an energy-based model for the transduction of chronic stress into disease over time. The energetic model of allostatic load (EMAL) emphasizes the energetic cost of allostasis and allostatic load, where the “load” is the additional energetic burden required to support allostasis and stress-induced energy needs. Living organisms have a limited capacity to consume energy. Overconsumption of energy by allostatic brain-body processes leads to <em>hypermetabolism</em>, defined as excess energy expenditure above the organism’s optimum. In turn, hypermetabolism accelerates physiological decline in cells, laboratory animals, and humans, and may drive biological aging. Therefore, we propose that the transition from adaptive allostasis to maladaptive allostatic states, allostatic load, and allostatic overload arises when the added energetic cost of stress competes with longevity-promoting growth, maintenance, and repair. Mechanistically, the energetic restriction of growth, maintenance and repair processes leads to the progressive wear-and-tear of molecular and organ systems. The proposed model makes testable predictions around the physiological, cellular, and sub-cellular energetic mechanisms that transduce chronic stress into disease risk and mortality. We also highlight new avenues to quantify allostatic load and its link to health across the lifespan, via the integration of systemic and cellular energy expenditure measurements together with classic allostatic load biomarkers.</p></div></div></div><ul id="issue-navigation"><li></li><li></li></ul><div id="keys0005"><h2>Keywords</h2><p><span>Allostatic load</span></p><p><span>Energy</span></p><p><span>Hypermetabolism</span></p><p><span>Coping resources</span></p><p><span>Energetic model of allostatic load (EMAL)</span></p><p><span>Allostasis and stress-induced energy expenditure (ASEE)</span></p><p><span>Brain</span></p><p><span>Mitochondria</span></p></div><section aria-label="Cited by" id="section-cited-by"><header id="citing-articles-header"><h2>Cited by (0)</h2></header></section><p><span>© 2022 The Author(s). Published by Elsevier Ltd.</span></p></article></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VersaTiles – a complete FLOSS map stack (145 pts)]]></title>
            <link>https://versatiles.org/</link>
            <guid>41895356</guid>
            <pubDate>Sun, 20 Oct 2024 13:51:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://versatiles.org/">https://versatiles.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41895356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div id="heroblock">
	<p><img src="https://versatiles.org/assets/logo/versatiles.svg"></p><div id="heroline">
		
		<p>
			<span>a</span>
			<span>complete</span>
			<span><abbr title="Free, Libre and Open Source Software">FLOSS</abbr></span>
			<span>map</span>
			<span>stack</span>
		</p>
	</div>
</div>
<p><hero>VersaTiles is a completely <a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" title="Free, Libre and Open Source Software">FLOSS</a> stack for generating, distributing, and using map tiles based on OpenStreetMap data, free of any commercial interests.</hero></p>
<h2>Try it out</h2>





<h2>If you want to know more</h2>
<p>we explain here:</p>
<ul>
<li><a href="https://versatiles.org/intro.html">how to use it</a>,</li>
<li><a href="https://versatiles.org/overview.html">how it works</a> and</li>
<li><a href="https://versatiles.org/contribute.html">how you can help.</a></li>
</ul>
<h2>powered by</h2>
<p><a href="https://www.miz-babelsberg.de/foerderung/foerderprojekte-alumni/details/versatiles-editorial-tools.html"><img src="https://versatiles.org/assets/logo/miz-logo.png" width="281"></a></p>
<p><small>MIZ-Babelsberg is funding the development of the "VersaTiles Editorial Tools", which are specifically designed for the use of maps in journalistic newsrooms.</small></p>
</div></div>]]></description>
        </item>
    </channel>
</rss>