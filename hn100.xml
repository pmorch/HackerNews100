<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 29 Jul 2023 18:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[If we want a shift to walking we need to prioritize dignity (118 pts)]]></title>
            <link>https://www.strongtowns.org/journal/2023/7/28/if-we-want-a-shift-to-walking-we-need-to-prioritize-dignity</link>
            <guid>36920622</guid>
            <pubDate>Sat, 29 Jul 2023 14:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.strongtowns.org/journal/2023/7/28/if-we-want-a-shift-to-walking-we-need-to-prioritize-dignity">https://www.strongtowns.org/journal/2023/7/28/if-we-want-a-shift-to-walking-we-need-to-prioritize-dignity</a>, See on <a href="https://news.ycombinator.com/item?id=36920622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-64c2930926f82617bbca3aa5" data-item-id="64c2930926f82617bbca3aa5">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1690477370700" id="item-64c2930926f82617bbca3aa5"><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_269191">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg" data-image-dimensions="624x328" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg" width="624" height="328" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/eacf6bfa-c47f-49a1-ae89-74d7c932c612/dignity-comparison-scaled-e1689281726969-624x328.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-fa7aad9dfb45a96bb22e">
  <p>Have you ever had a friend return from a vacation and gush about how great it was to walk in the place they’d visited? “You can walk everywhere! To a café, to the store. It was amazing!” Immediately after saying that, your friend hops in their car and drives across the parking lot to the Starbucks to which they could easily have walked.</p><p>Why does walking feel so intuitive when we’re in a city built before cars, yet as soon as we return home, walking feels like an unpleasant chore that immediately drives us into a car?</p><p>A lot contributes to this dilemma, like the density of the city, or the relative cheapness and convenience of driving. But there’s a bigger factor here: We don’t design the pedestrian experience for dignity.</p><p>This is a national problem, but certainly one those of us in the Minneapolis–Saint Paul metropolitan area can see throughout the Twin Cities metro: Even where pedestrian facilities are built, brand-new, ADA-compliant, and everything else—using them feels like a chore, or even stressful and unpleasant.</p><p>Dignity is a really important concept in active transportation, but one that we often miss in the conversation about making streets better for walking and biking. I’ve been delighted to see the term appear on&nbsp;<a href="https://www.instagram.com/pedestriandignity/">a social media account advocating for pedestrians</a>. But as we plan and design better streets for active transportation, we need to consider the dignity of the pedestrian experience.</p><h2>A Hierarchy of Needs</h2><p>Three related concepts exist in designing great pedestrian spaces, and they can be arranged similarly to Maslow’s hierarchy of needs. The base of the pyramid is the most essential, but having a complete and delightful pedestrian experience requires all three layers. The layers are compliance, safety, and dignity.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_272938">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png" data-image-dimensions="500x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png" width="500" height="500" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/11ec90a8-fe26-4d02-bb28-ac29fea82b45/dignity-triangle-500x500.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_273322">

<p>
  <h2><strong>Compliance</strong>: Often Not Enough</h2>
</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_176851">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg" data-image-dimensions="1024x575" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg" width="1024" height="575" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/84362759-87a9-4025-bb23-e600862816e0/shady-oak-road-1024x575.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Shady Oak Road in Hopkins is ADA compliant, but crossing here could be unsafe for any user. (Source: Google Street View.)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_177240">
  <p>At the bottom of the pyramid you have compliance—for pedestrian facilities, that mainly means complying with ADA rules. This requirement is non-negotiable for agencies because failure to obey exposes them to legal challenges. The ADA has done a great deal to make pedestrian facilities better for all—certainly wheelchair users, but also those who walk, use strollers, ride bicycles on sidewalks, etc.</p><p>Unfortunately, compliance with ADA rules&nbsp;<em>alone</em>&nbsp;often does not yield good pedestrian facilities.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_307522">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg" data-image-dimensions="1024x650" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg" width="1024" height="650" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/7241ef8c-b669-46d3-b562-f976acfe94ac/bad-faith-compliance-1024x650.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>As part of an ADA upgrade project, Edina and Hennepin County removed the north leg crosswalk, requiring pedestrians to cross this busy intersection three times to proceed on the north-side sidewalk.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_307906">

<p>For example, many agencies will simply remove pedestrian facilities to reduce the cost of compliance. A good example is the intersection of France and Parklawn Avenues in Edina. If you were on the west side of France and wanted to walk to the Allina clinic in 2013, you could simply have crossed on the north crosswalk. But to improve ADA compliance, Edina removed the north crosswalk in 2014. Now, you would have to cross the busy signalized intersection three times just to continue on the north sidewalk.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_186897">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg" data-image-dimensions="500x472" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg" width="500" height="472" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/5b58d6aa-e00f-4432-aacf-492fb990cb85/removed-ped-button-500x472.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>The crosswalk at France and Parklawn, showing the rusted outline of the former pedestrian push button. (Source: Google Street View.)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_187356">

<p>In other cases, compliance is in good faith but not enough to make a pedestrian facility really usable—because complete compliance would entail a much larger project. This can be found when a broken-down sidewalk, or one with obstructions in the way, gets brand-new corner curb ramps but no other improvements. A wheelchair user can easily get up off the street at the corner, but can’t go farther than 10 feet without hitting another impediment.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_328267">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg" data-image-dimensions="1024x663" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg" width="1024" height="663" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f5951cb9-8f79-4bd9-8cc3-70aba0dd4c47/31st-2nd-1024x663.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>This new curb ramp and pedestrian push buttons at 31st and 2nd are great, but if you’re a wheelchair user, they won’t help you for long: not 10 feet away, you’ll encounter a section of sidewalk too narrow to pass due to a street light. (Source: Google Street View.)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_328651">

<p>
  <h2><strong>Safety</strong>: A Step Further, But What Is Still Lacking?</h2>
</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_342585">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg" width="1024" height="768" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/62eb6023-1935-489a-b92e-49dfe8bc0f3d/58th-st-undignified-1024x768.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>58th Street in Edina is ADA compliant and probably safe enough to cross with low volumes. But the experience is undignified, with little separation from car traffic, and no shade.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_342970">
  <p>In the middle of the pyramid, you have safety—both perceived and actual. It is possible to create a facility that is compliant but does not seem very safe. Picture sparkling new curb ramps to cross a 45-mph surface street with no marked crosswalk. In other cases, facilities are well-designed and safe, but may still not be dignified.</p><p>An example of this is in my own backyard, on Hennepin County’s Nicollet Avenue. A very-welcome project last year installed new crosswalks to popular Augsburg Park. These have durable crosswalk markings, excellent signage, and refuge medians. But crossing still feels like a negotiation with drivers. And the overall sidewalk experience on the 1950s street is still lacking, with sidewalks at the back-of-curb and little to no shade.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_203270">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg" data-image-dimensions="500x375" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg" width="500" height="375" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/f2dde0f3-ac22-425f-9294-a2f3f090419e/nicollet-ave-500x375.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Nicollet Avenue and 71st Street in Richfield.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_203657">
  <h2><strong>Dignity</strong>: Making Walking Feel Right</h2><p>Finally, we have dignity.&nbsp;To determine whether a facility is dignified, I propose a simple test:</p><p>If you were driving past and saw a friend walking or rolling there, what would your first thought be:</p><ol data-rte-list="default"><li><p>“Oh, no, Henry’s car must have broken down! I better offer him a ride.”</p></li><li><p>“Oh, looks like Henry’s out for a walk! I should text him later.”</p></li></ol><p>This is a surprisingly good test. Picture seeing your friend on a leafy sidewalk versus walking along a 45 mph suburban arterial.&nbsp;<strong>What would you think intuitively?</strong></p><p>But to get more specific, these are the key factors in making a pedestrian experience dignified:</p><ul data-rte-list="default"><li><p>Shade and light.</p></li><li><p>Convenience.</p></li><li><p>Enclosure and proportions.</p></li><li><p>Engagement.</p></li></ul><h3>Shade and Light</h3>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_358827">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg" data-image-dimensions="375x250" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg" width="375" height="250" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/ae4bbafa-17df-484b-8d2e-0c6c72683f28/northfield-sidewalk-375x500.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>St. Olaf Avenue in Northfield has a dignified amount of shade—not tunnel-like, but keeping the sidewalk cool and protected from the sun.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_359211">

<p>A dignified facility needs consistent shade during hot summer months. At night, shadows should be minimal and the route should be clear. Especially when a tree canopy is present, this is best achieved with more individual fixtures installed lower to the ground and at a lower light output. However, a fairly consistent light level can be achieved even with basic cobraheads, as long as there are enough to light the corridor fully.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_373830">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg" data-image-dimensions="3404x1915" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg" width="3404" height="1915" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/4b9d977a-b718-4096-9e40-f247fa7907b5/dignity-less-light-scaled.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>The flowers are beautiful, but a dark street at night is less dignified than a well-lit one. Left is 70th Street near Garfield Avenue; right is Lyndale and 75th.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_374215">
  <h3>Convenience</h3><p>Routes should be intuitive, easy, and not feel tedious to navigate. Having to make sharp, 90° turns or go out of your way feels awkward and makes you feel like your time and effort are wasted—even if the detour is relatively minor.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_229652">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg" width="1024" height="768" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/fbf174d1-526f-433e-a75e-cf811929e2ec/inconvenient-routing-1024x768.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Inconvenient pedestrian routing at York and 66th.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_393561">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg" width="1024" height="768" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/93461139-dd7a-46a0-86a1-387431fe14fc/bloomington-sidewalk-inconvenient-1024x768.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>A winding path around a bus stop pull-out on 82nd Street.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_230061">

<p>
  <h3>Enclosure and Proportions</h3>
</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_402269">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg" data-image-dimensions="3143x1768" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg" width="3143" height="1768" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/617a965d-a450-458e-9370-4688a6d53bab/hopkins.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Compare these two streets in Hopkins: Shady Oak Road, which is wide open with a sense of enclosure, and Eighth Avenue, which is better proportioned with a clear street wall.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_402653">
  <p>It’s a very uncomfortable experience to walk along a wide-open corridor with no walls or edge definition—and it’s a common experience along suburban arterials, where you may have a wide road on one side and a wide-open parking lot on the other. You feel exposed and vulnerable. At the same time, overgrown sidewalks or ones that encroach on pedestrian space can feel claustrophobic and inconvenient. The right balance is needed.</p><h3>Engagement</h3>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_243247">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg" data-image-dimensions="1024x766" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg" width="1024" height="766" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/8e5f9c79-b1cc-4fa8-bc6a-10fd4f2448a8/bp-sidewalk-blank-walls-1024x766.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>This sidewalk in Brooklyn Park has only the frontage of dilapidated privacy fences.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_243639">
  <p>Finally, engaging frontage is always more appealing than blank frontage. The extreme of this principle is obvious: Walking down a traditional main street is more pleasurable than walking through an industrial park. But even where land uses are similar, engagement of frontage can vary a lot: picture the difference between walking past the front doors of houses in a traditional neighborhood, and walking past privacy fences and back yards in cul-de-sac suburban neighborhoods. The traditional neighborhood is more interesting and engaging to walk through.</p><p>When I was visiting downtown Northfield, I noted a new building along Water Street (MN-3), which had similar materials to the older downtown buildings on Division: windows, brick, and (cultured) stone base. Yet the back was turned to the street, and the experience of walking past was undignified.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_417919">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg" data-image-dimensions="3413x1920" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg" width="3413" height="1920" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/2a72184f-93f4-4640-8a39-4b951303a944/northfield-unengaging-2-scaled.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Consider the visual interest of these buildings in downtown Northfield. On the left, walking past tinted windows and blank walls on a new building along a concurrent section of Water Street and Highway 3 on the west side of downtown. On the right are Division Street’s engaging storefronts.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_418303">
  <h2>A Pedestrian Cannot Live on Compliance Alone</h2><p>Creating compliant sidewalks and trails is a high priority for agencies seeking to avoid litigation and serve pedestrians on the most basic level. Although that has some benefits, it isn’t enough. Whether actively undermining walkability (like removing crosswalks to achieve ADA compliance) to simply not doing enough (adding a new curb ramp to an otherwise wheelchair-hostile sidewalk), we need to go much further.</p><p>To make walking and rolling a desirable, everyday activity, we need facilities that are compliant, safe, and dignified. We have many examples in our communities of great pedestrian ways—but we have a long way to go to make it universal, and truly move the needle toward walking.</p>
</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1690466434279_154204">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg" data-image-dimensions="300x200" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg" width="300" height="200" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/53dd6676e4b0fedfbc26ea91/1054aab5-9291-401b-aa56-3bd8d697b2c9/sean-2014.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1690466434279_138835">

<p><a href="https://sdho.org/"><strong>Sean Hayford Oleary</strong></a> is a web developer and planner. He serves on the Richfield City Council, and previously on the city's Planning and Transportation commissions. Articles are written from a personal perspective and not on behalf of Richfield or others. Sean has a masters in urban planning from the Humphrey School. Follow his love of streets, home improvement, and all things Richfield on Twitter <a href="https://twitter.com/sdho">@sdho</a>.</p>



</div></div></div>

    

    

    

  </article>





  
              </section>
            
          </main>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cyberdecks (2013) (119 pts)]]></title>
            <link>https://blog.rfox.eu/en/Hardware/Cyberdecks.html</link>
            <guid>36920010</guid>
            <pubDate>Sat, 29 Jul 2023 13:17:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks.html">https://blog.rfox.eu/en/Hardware/Cyberdecks.html</a>, See on <a href="https://news.ycombinator.com/item?id=36920010">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p id="1ffaeab6-954e-443c-97c4-45b8b3fa0650"><time>@2016/02/13</time></p>
      <p id="4986a651-2f0d-49d5-8d4d-bd64274bf142">It has been few days, since I created the&nbsp;<a href="https://www.reddit.com/r/cyberDeck/">/r/cyberDeck</a>&nbsp;subreddit. I did so, partly because I was inspired by the&nbsp;<a href="http://www.activewirehead.com/building-a-cyberdeck/">Building a cyberdeck</a>&nbsp;article, but also because of few IRC discussions I participated, and because I think that there is more to this idea, than just nice cyberpunkish look and feel.</p>
      <h2 id="5844b5d7-484e-4001-8da5-75d94e52a03b">What is `deck`?</h2>
      <p id="1d22ecd9-cae9-4922-97dd-302e1bfb7e83">Deck or CyberDeck is this mobile computer first imagined by William Gibson in Neuromancer and later slightly extended and redefined by the&nbsp;<a href="https://en.wikipedia.org/wiki/Shadowrun">Shadowrun</a>&nbsp;as well as other (<a href="https://en.wikipedia.org/wiki/Cyberpunk_2020">Cyberpunk 2020</a>,&nbsp;<a href="https://en.wikipedia.org/wiki/GURPS_Cyberpunk">GURPS Cyberpunk</a>) role-play games, card games (<a href="https://en.wikipedia.org/wiki/Netrunner">Netrunner</a>) and novels.</p>
      <blockquote id="b334ab0f-4b6b-4227-a622-0aad4814ce0f">
        With his deck waiting, back in the loft, an Ono-Sendai Cyberspace 7. They'd left the place littered with the abstract white forms of the foam packing units, with crumpled plastic film and hundreds of tiny foam beads. The Ono-Sendai; next year's most expensive Hosaka computer; a Sony monitor; a dozen disks of corporate-grade ice; a Braun coffeemaker. Armitage had only waited for Case's approval of each piece.— GIBSON, William.&nbsp;Neuromancer. New York: Ace Books, 1984, 271 s. ISBN 0-441-56959-5.
      </blockquote>
      
      <p id="9e5394c7-753f-4dc8-81a2-c5d3c4fd0831">(William Gibson's Neuromancer: the graphic novel volume 1. New York, N.Y.: Epic Comics, 1989, 1 v.. ISBN 0871355744.)</p>
      <blockquote id="93e0bcda-366e-40a8-8606-acb6e08192e0">
        He snugged the surgical steel jack into the socket at his temple and his fingers flew across the keyboard of his Fuchi cyberdeck, launching him into the Matrix. His vision shifted to that dazzling electronic world of analog space where cybernetic functions took on an almost palpable reality. He ran the electron paths of cyberspace up the satellite link and down again into the Seattle Regional Telecommunications Grid. Within seconds, he was well on his way to the rendezvous with his companions inside the Renraku arcology.
      </blockquote>
      <p id="e3a3c039-d501-4ef4-968b-6e89e92e0049">— CHARRETTE, Robert N.&nbsp;Never deal with a dragon. New York, N.Y., U.S.A.: Roc, 1990, 377 p. ISBN 0451450787.</p>
      <figure id="6836ee5c-cd8b-4b36-90f3-d9bfe9f5acf0">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_2.png" title="Untitled_2.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_2_thumb.jpg"></a>
        <figcaption>
          (<a href="http://www.juangimenez.com/">Juan Gimenez</a>)
        </figcaption>
      </figure>
      <div id="ef38e132-aa3e-443e-966d-44a56823a376">
          <figure id="5b81cda8-5ec9-4955-bbb0-b99dcbb57bc5">
            <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_5.png" title="Untitled_5.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_5.png"></a>
          </figure>
          <figure id="45dfd473-8fa9-405d-9023-a2c45471f47f">
            <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_6.png" title="Untitled_6.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_6.png"></a>
          </figure>
          <p id="a234a909-ea76-4991-a4d4-079f51ebb47e"><em>(Various internet sources, mostly tumblr / pinterest.)</em></p>
          
        </div>
      <p id="0eeb0135-cb2c-4d6b-97a6-73777790a374">Although both in Neuromancer and Shadowrun novels (<em>Never Deal with a Dragon</em> for example) is deck equipped with neural interface, it is not uncommon that it is depicted with builtin keyboard.</p>
      
      
      
      
      
      <figure id="4db6fbc2-02a8-47d8-8bdc-2a2d493cd642">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_12.png" title="Untitled_12.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_12_thumb.jpg"></a>
      </figure>
      <p id="a6ec7362-2d1f-4283-a328-abf43b772255"><em>(Vairous internet sources, mostly tumblr / pinterest.)</em></p>
      <blockquote id="cef669a6-6cc4-4e17-b1e0-b56b62087f89">
        Sam slid back the cover panel and pulled out the telecom connector. With a quick switch of plugs, the Elf's cyber-deck took the place of Castillano's computer. He reached for the datacord that would connect his socket with the deck. He almost changed his mind, but found courage when he remembered the innocents in the arcology who would suffer if no one tried to help. He slipped the plug in, steeling himself against the expected pain.<p>
        
        It came, flashing through his brain faster than before and leaving a distant malaise in its wake. Sam focused his mind on the task at hand. Turning a blind eye to the gleaming spires and pulsing data paths that surrounded him in cyber-space, he charged forward to the massive Renraku construct. Using his company passwords, he opened a portal into the main database.</p><p>
        
        Glittering rows of stars lay in serried ranks and columns all around him. Each point of light was a datafile, its tint reflecting the filing category. Sam fed the cyberdeck the key words and executed the search function. His point of view shifted with dazzling speed along the rows. He paused briefly at each file suggested by the deck, discarding useless information as he searched.</p><p>
        
        In what seemed like only a few minutes, he found it. He copied the file and fled back to where he had entered the Matrix.</p><p>
        
        "There is a counteragent," he announced to the circle of concerned faces as he pulled the data cord from his temple.
      </p></blockquote>
      <p id="cbf9dff7-f879-44e8-b374-77099606631a">— CHARRETTE, Robert N. Never deal with a dragon. New York, N.Y., U.S.A.: Roc, 1990, 377 p. ISBN 0451450787.</p>
      <h2 id="ffb5df27-6049-4594-9e8b-79a111cf93ec">Inspiration</h2>
      <p id="f1d3ff9e-da95-4699-884b-e0bdf136b180">The obvious inspiration for the whole cyberdeck thing was the 8bit home computers back in the era:</p>
      <figure id="38b27467-e4c7-4409-be51-6e95d5f563ad">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_13.png" title="Untitled_13.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_13.png"></a>
        <figcaption>
          (Amstrad CPC 464 by <a href="https://denema.deviantart.com/art/Amstrad-CPC-464-189255658">DeNeMa</a>. Only thing it is missing is neural interface ;)
        </figcaption>
      </figure>
      
      
      <p id="01221c14-56e5-4974-b9f2-70f4895c7604">Imagine yourself passing computer store in 80's and see in the shop windows those beautiful computers. Almost no one knows what to do with them, but they are cool, flashy, with efects never seen before. Talking heads in TV talk about Hackers and information superhighways, and everyone is curious and anything seems possible. It really makes your fantasy going.</p>
      
      <figure id="1271896a-7eaa-4f09-b4b2-75f94908b3ca">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_20.png" title="Untitled_20.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_20.png"></a>
        <figcaption>
          (Source: <a href="http://www.plaidstallions.com/toystores.html">Vintage toy stores</a>.)
        </figcaption>
      </figure>
      <p id="2101b37f-3644-4b2e-91c3-ff55f3b8cbf9">It's not that hard to imagine, that this where the <em>deckers</em> (cyberpunk hackers) and <em>netrunners</em> holding the deck, flying in 3D space and fighting computer programs, came from.</p>
      
      <p id="864948ad-8e48-47a7-8f8c-ccf497eee808">Today, still a lot of people is still attracted to decks because of their cool look. With the advent of small one-board computers like Raspberry PI, you can see attempts and discussions about building the decks:</p>
      <ul id="04995f9b-f2c3-4222-b248-e82c62b86410">
        <li>
          <a href="http://www.cyberpunkforums.com/viewtopic.php?id=1766">Making a cyberspace deck</a>
        </li>
      </ul>
      <ul id="e3462930-4582-4fff-83e1-0e675a751064">
        <li>
          <a href="https://www.reddit.com/r/Cyberpunk/comments/2af5bm/revisting_an_old_idea_building_a_classic/">Revisting an old idea - building a classic cyberdeck using current tech</a>
        </li>
      </ul>
      <ul id="c70fbbf0-f22a-41b6-a914-702d968428a3">
        <li>
          <a href="https://www.reddit.com/r/Cyberpunk/comments/212tko/finally_peicing_together_my_pi_cyberdeck_work_in/">Finally peicing together my Pi Cyberdeck (Work in Progress)</a>
        </li>
      </ul>
      <ul id="3809497e-e26e-42d5-9681-c364a60aaa8b">
        <li>
          <a href="http://n-o-d-e.net/post/130139019901/how-to-create-a-gibsonshadowrun-inspired">How to create a gibson/shadowrun inspired cyberdeck</a>
        </li>
      </ul>
      
      <h2 id="b69ac677-55fd-4d6c-9e37-58dc7c1f53f1">Why the deck?</h2>
      <p id="b15cdd09-1af4-4c7b-9b22-6c1cbf643fe2">So, why would anyone want to use deck and not a notebook?</p>
      <p id="ecb927bf-fed0-4bc4-87ea-3794847d4a29">The idea of usefulness of the deck came to me from the opposite direction, than to most of the people I guess;</p>
      <p id="a38e5309-b12a-41de-9d75-0e0b5f3082c3">I was thinking a lot about what does being „digital nomad“ mean and what would be required to be truly independent, but not to give up comfort of having two displays, one of which is big 27" LCD. I work as a programmer (did you know, that there is <a href="https://www.reddit.com/r/HMDprogramming">/r/HMDprogramming</a>? :)), and big monitor directly contributes to my productivity. I really <strong>need</strong> a lot of space for editor, terminals and other stuff I deal with.</p>
      <p id="c6182706-61d3-488c-9c72-570a4599a8d5">Consider following example:</p>
      <figure id="9b6849b6-7c14-43fe-b508-8b5bdface196">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_27.png" title="Untitled_27.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_27_thumb.jpg"></a>
      </figure>
      <p id="c40657a4-1f1e-4c44-b1ee-734734e1ab2b">And that's just one of 16 virtual desktops I use, others filled with documentation, server connections, database consoles and similar stuff. If you try to cram all that stuff on notebook screen, it just isn't right and context switching can get annoying really quickly:</p>
      <figure id="4bb09791-07ff-4903-96b8-60f550ccc50c">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_28.png" title="Untitled_28.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_28_thumb.jpg"></a>
      </figure>
      <p id="95faeaba-1bd6-4942-b742-16a7e15af095">So I was thinking; Would it be possible to have all the comfort of big screen and still live like a nomad, always on the road? Pretty soon, it was obvious, that you would have to have either big caravan (or maybe a camel with LCD holder :P), or HMD display.</p>
      
      
      <p id="42a34008-646d-41ce-8e7c-7366f23166f3">(This year should be good year for Head Mounted Displays. From left to right: <em>HTC Vive</em>, <em>Oculus Rift</em>, <em>Sony project Morpheus</em>, <em>Razer OSVR</em>, <em>Rapture HMD</em> and <em>Avegant Glyph</em>.)</p>
      <p id="ea657bae-2a4f-4cf2-81ee-e8e53b6df935">But most of the notebooks will have problems to handle the HMD, because of high requirements on GPU, which also means high power consumption (that is also true for decks, but you are not limited by screen size and the size limits for notebooks). Also, the idea of having the display and the HMD at the same time is just pointless. You won't see it with HMD on, and it would just consume power for no reason. That's how the idea of decks came into my mind.</p>
      <p id="6344f09d-f47b-4dad-8b09-4aca609e3c5b">I think, that in the near future, there is relatively big fraction of computer market share for the decks, because HMD's will be more and more common, but I don't think, that we will see them often sooner than 10 years from now.</p>
      <p id="e0be89f2-b80d-471a-82cf-a3bce80ffa7f">EDIT: To get the idea of VR environment, look at this video;</p>
      <figure id="acb7ff57-3d73-4b72-904a-284b9abdd6d5">
        <p>
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/bjE6qXd6Itw" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </p>
      </figure>
      <h2 id="3e2dae46-cd79-475b-975f-b6e9b63ff3b0">The Deck I would like to build</h2>
      <p id="8df43fba-99ec-424f-b538-a6ecaf1302df">Given unlimited budget and access to good workshop, I would build highly customized <strong>workstation</strong>, with highly customized software.</p>
      <p id="0565dd38-34b0-4168-a2ff-930abe04efc8">There is this piece of email conversation between me and <a href="https://www.abclinuxu.cz/lide/pavel.krivanek">Pavel Křivánek</a>, which I can't forget. Loosely translated:</p>
      <blockquote id="48acd99b-ae74-4f4a-a253-d3865fb9b114">
        <em>&gt; ... I think, that I will try to write simple Smalltalk interpret one day. Thats best for learning new language.</em><p>
        
        If I can advise you, try the Self interpret. The nuances of how brilliantly it works with lexical spaces, activation objects and so on are just breathtaking.</p><p>
        
        <em>&gt; Lately, I was also captivated by Squeak, with which I<br>
        was toying a little and I think, that there are really interesting<br>
        things, which I still need to explore. It seems to me, that there is<br>
        strong emphasis on the man-software synergy (ala Engelbart), at the<br>
        expense of standard sw development, which I find interesting. Maybe I<br>
        will have to look into Self, that prototype-based development looks like<br>
        it is better for this kind of applications.</em></p><p>
        
        For me, the Self is the matter of heart. Especially how it<br>
        solved a lot of Smalltalk's problems by simplifying it, is a really<br>
        special case in the world of programming languages.</p><p>
        
        On the other hand, Smalltalk now balances better the academical flamboyance with practicality. Even the Self's authors acknowledges, that there is sometimes problem to keep situational awareness, which in Smalltalk is not that big problem, thanks to the class system. This also applies to easier creation of support tools. But the ability to work in virtual 3D space full of flying outliners, that would be [untranslatable inflexion of word `programming` meaning something like `happier/better/more-enjoyable programming`].
      </p></blockquote>
      <figure id="f88edddb-3ee7-489d-ba78-d57f9906d1f7">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_35.png" title="Untitled_35.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_35.png"></a>
        <figcaption>
          <em>(Self really doesn't look like typical IDE. There is never enough space for outliners.)</em>
        </figcaption>
      </figure>
      <p id="2014c205-fe1e-45ac-991d-f6b1037716c7">Self is really interesting language, somehow forgotten gem, which almost no one use, because it works differently than most of the current-date programming languages. Whole IDE is really strongly space and visually oriented. After I've played with it a little, I must say, that it (or Smalltalk) would do a really nice desktop environment for 3D system.</p>
      
      
      <figure id="002c6f7d-b175-4bfa-a4f6-a121a2fa96a8">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_38.png" title="Untitled_38.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_38.png"></a>
        <figcaption>
          <em>(Source:</em> <a href="https://en.wikipedia.org/wiki/Ghost_in_the_Shell:_Arise"><em>Ghost In The Shell: Arise</em></a><em>.)</em>
        </figcaption>
      </figure>
      <p id="158db227-fc50-4ff0-8ad3-67a0f02d1338">Of course, this probably wouldn't be user-friendly and thus usable for most of the people. But my idea of the deck was never meant to be. Such project would have to have custom, DIY hardware, only for real enthusiast. It would be much more interesting, if the software would be also highly customized programmer-only thing, completely ignoring the normal users and their principles of operation. As the <a href="https://www.abclinuxu.cz/images/screenshots/7/4/217947-cyberdecs-7902521666826599726.jpg">image</a> from the Neuromancer graphic novel says: <em>"The meat stayed home, strapped to a</em> <em><strong>custom</strong></em> <em>deck"</em>.</p>
      <p id="6ce4ea64-7242-40aa-8cd1-449b526c165a">Once I found this think-path, I couldn't just stop there. When you realize, that you don't need to limit yourself with standard notebook parameters, you may actually imagine completely new device with more completely different features, which makes sense only with the concept of decks. Pretty quickly, I've got something qualitatively different from standard consumer notebooks.</p>
      <figure id="8b115aac-6d5b-4b7f-a593-c59c28f284c9">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_39.png" title="Untitled_39.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_39.png"></a>
        <figcaption>
          <em>(</em><a href="https://www.tinkercad.com/things/9qx3c3ij28S"><em>3D model</em></a> <em>I've created to illustrate this article. Feel free to use and remix it.)</em>
        </figcaption>
      </figure>
      <p id="272b745a-2002-4371-9e59-f882da53a634">For example - typical notebook have one shitty webcam used for video calls. With the decks, you may actually want something like four or six hi-res webcams, to provide you with situational awareness, when you have the HMD on. In the virtual reality, imagine this as big sphere around you. There are some floating windows, between you and the sphere, and at sphere itself, there may be output from the cams showing your surroundings. The cameras could also in theory be used to track you and your hands and map you into the 3D environment, leapmotion style.</p>
      <figure id="f76e19a2-4ce1-4123-b77c-1fa0f2e0de19">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_40.png" title="Untitled_40.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_40_thumb.jpg"></a>
      </figure>
      <p id="a45f0f28-06fd-401a-a39e-7f4433d8e7cd">Keyboard could be detachable and the deck could track its position and position of your HMD, using the same <a href="https://www.roadtovr.com/reverse-engineering-oculus-rift-dk2-positional-tracking-camera-linux-sdk/">LED trick</a> Oculus uses, so it could render its virtual form into the 3D environment.</p>
      <p id="80efd046-0b05-451c-99b2-c927ba371b9d">There could be built-in Leapmotion / Kinect -like sensors, which would sense hand motions, so no gloves would be required. It would be also nice to have small e-ink display, as the system console, for debugging and system-info purposes.</p>
      <h3 id="864c58fc-90b8-492c-92ed-6d3498142348">Crazy stuff</h3>
      <p id="4ebe4eb9-58c8-4859-89e2-7a4b631844b2">Instead of cheap WiFi card, there could be <a href="https://en.wikipedia.org/wiki/Universal_Software_Radio_Peripheral">USRP</a> (really good Software Defined Radio) card, combined with FPGA, so you could actually take the deck into the field and let it be useful in hacking / tracking / capturing of the signals. Of course, it could also emulate the WiFi / Bluetooth / Zigbee device, with right software.</p>
      <p id="d9696b0d-892f-4a63-bf62-4b4e7ecd8e9b">Since this wouldn't be the standard consumer hardware built for multimedia / gaming, it would be possible to use some really alternative computing platform, like this sweet 18 core low-power Parallella computer board.</p>
      
      <figure id="587e3296-a474-4d61-9673-ecdc45c0983e">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_41.png" title="Untitled_41.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_41.png"></a>
        <figcaption>
          (<a href="https://www.parallella.org/">The Parallella Board</a> - 18-core credit card sized computer.)
        </figcaption>
      </figure>
      <p id="75707c9f-c3c7-402c-b9d3-9e18b820901d">Only thing, that is really mandatory is high-end GPU, possibly mobile. There is no way around it, if you would want to have enough processing power to support smooth 3D environment in the HMD display. This is one of the reasons, why we don't see many of the decks today, and in the near future. GPU is simply too much greedy.</p>
      <figure id="fbf54760-120c-4fae-96c0-7a36d72bf8b3">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_42.png" title="Untitled_42.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_42_thumb.jpg"></a>
        <figcaption>
          (<a href="https://www.reddit.com/r/oculus/comments/2lsohd/just_finished_building_my_portable_pelerift/">Reddit: Portable Pele-Rift</a>. This is how the today consumer hardware deck looks like when you put the high-end GPU into it.)
        </figcaption>
      </figure>
      <p id="6541bc9f-8a66-4b4f-9520-c89b8b926734">So if I use the 3D model I've created, it would look somehow like this:</p>
      <figure id="98c377bb-d71a-4871-93f0-ef03e31ad673">
        <a href="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_43.png" title="Untitled_43.png"><img src="https://blog.rfox.eu/en/Hardware/Cyberdecks/Untitled_43_thumb.jpg"></a>
      </figure>
      <h2 id="a1c5f474-090a-4534-92f1-c0e8e073b306">Thoughts?</h2>
      <p id="628d6b25-e3a8-442f-b0f7-5e3aa3a93647">So, what do you think? Does the idea of the decks have any chance to live? Would you want one? For aesthetic / enthusiastic / professional reasons? Do you think it could make actually useful workstation?</p>
      <p id="ced8070b-3d19-4811-ba40-6bf90c73c7ff">Let me know in the <a href="https://www.reddit.com/r/cyberDeck/">/r/cyberDeck</a>. Don't be shy, I am really curious to hear what you think, even if you find this article years from now!</p>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Happened to Vivaldi Social? (173 pts)]]></title>
            <link>https://thomasp.vivaldi.net/2023/07/28/what-happened-to-vivaldi-social/</link>
            <guid>36919659</guid>
            <pubDate>Sat, 29 Jul 2023 12:34:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thomasp.vivaldi.net/2023/07/28/what-happened-to-vivaldi-social/">https://thomasp.vivaldi.net/2023/07/28/what-happened-to-vivaldi-social/</a>, See on <a href="https://news.ycombinator.com/item?id=36919659">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[US Spies Are Lobbying Congress to Save a Phone Surveillance ‘Loophole’ (135 pts)]]></title>
            <link>https://www.wired.com/story/nsa-ndaa-lobbying-privacy-loophole/</link>
            <guid>36919225</guid>
            <pubDate>Sat, 29 Jul 2023 11:38:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/nsa-ndaa-lobbying-privacy-loophole/">https://www.wired.com/story/nsa-ndaa-lobbying-privacy-loophole/</a>, See on <a href="https://news.ycombinator.com/item?id=36919225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>An effort by</span> United States lawmakers to prevent government agencies from domestically tracking citizens without a search warrant is facing opposition internally from one of its largest intelligence services.</p><p>Republican and Democratic aides familiar with ongoing defense-spending negotiations in Congress say officials at the National Security Agency (NSA) have approached lawmakers charged with its oversight about opposing an amendment that would prevent it from paying companies for location data instead of obtaining a warrant in court.</p><p>Introduced by US representatives Warren Davidson and Sara Jacobs, the amendment, <a href="https://www.wired.com/story/ndaa-2023-davidson-jacobs-fourth-amendment/">first reported by WIRED</a>, would prohibit US military agencies from “purchasing data that would otherwise require a warrant, court order, or subpoena” to obtain. The ban would cover more than half of the US intelligence community, including the NSA, the Defense Intelligence Agency, and the newly formed National Space Intelligence Center, among others.</p><p>The House approved the amendment in a floor vote over a week ago during its annual consideration of the National Defense Authorization Act, a “must-pass” bill outlining how the Pentagon will spend next year’s $886 billion budget. Negotiations over which policies will be included in the Senate’s version of the bill are ongoing.</p><div><p>In a separate but related push last week, members of the House Judiciary Committee voted unanimously <a href="https://www.wired.com/story/fourth-amendment-is-not-for-sale-act-2023/">to advance legislation</a> that would extend similar restrictions against the purchase of Americans’ data across all sectors of government, including state and local law enforcement. Known as the “Fourth Amendment Is Not For Sale Act,” the bill will <a data-offer-url="https://subscriber.politicopro.com/article/2023/07/momentum-grows-for-bill-banning-data-sales-to-government-agencies-00108470" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://subscriber.politicopro.com/article/2023/07/momentum-grows-for-bill-banning-data-sales-to-government-agencies-00108470&quot;}" href="https://subscriber.politicopro.com/article/2023/07/momentum-grows-for-bill-banning-data-sales-to-government-agencies-00108470" rel="nofollow noopener" target="_blank">soon be reintroduced in the Senate</a> as well by one of its original 2021 authors, Ron Wyden, the senator’s office confirmed.</p><p>“Americans of all political stripes know their Constitutional rights shouldn’t disappear in the digital age," Wyden says, adding that there is a “deep well of support” for enshrining protections against commercial data grabs by the government “into black-letter law.”&nbsp;</p><p>The extent to which the NSA in particular uses data brokers to obtain location and web-browsing data is unclear, though the agency has previously acknowledged using data from “commercial” sources in connection with cyber defense. Regardless, the NSA’s lawyers have authored extensive guidelines for acquiring commercially available data, particularly when it belongs to US companies or individuals. Some of the rules prescribed by the agency’s lawyers remain classified.</p></div><p>The NSA did not respond to multiple requests for comment.</p><p>A <a href="https://www.wired.com/story/odni-commercially-available-information-report/">government report</a> declassified by the Office of the Director of National Intelligence last month revealed that US intelligence agencies were avoiding judicial review by purchasing a “large amount” of “sensitive and intimate information” about Americans, including data that can be used to trace people’s whereabouts over extended periods of time. The sensitivity of the data is such that “in the wrong hands,” the report says, it could be used to “facilitate blackmail,” among other undesirable outcomes. The report also acknowledges that some of the data being procured is protected under the US Constitution’s Fourth Amendment, meaning the courts have ruled that government should be required to convince a judge the data is linked to an actual crime.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The US Supreme Court has previously ordered the government to obtain search warrants before seeking information that may “chronicle a person’s past movements through the record of his cell phone signals.” In the <a href="https://www.wired.com/story/carpenter-v-united-states-supreme-court-digital-privacy/">landmark <em>Carpenter v. United States</em> decision</a>, the court found that advancements in wireless technology had effectively outpaced people’s ability to reasonably appreciate the extent to which their private lives are exposed.</p><p>A prior ruling had held that Americans could not reasonably expect privacy in all cases while also voluntarily providing companies with stores of information about themselves. But in 2018 the court refused to extend that thinking to what it called a “new phenomenon”: wireless data that may be “effortlessly compiled” and the emergence of technologies capable of granting the government what it called “near perfect surveillance.” Because this historical data can effectively be used to “travel back in time to retrace a person’s whereabouts,” the court said, it raises “even greater privacy concerns” than devices that can merely pinpoint a person’s location in real time.</p><p>Crucially, the court also held that merely agreeing to let data be used “for commercial purposes” does not automatically abrogate people’s “anticipation of privacy” for their physical location. Rather than apply this view to location data universally, however, the government has allowed defense and intelligence agencies to assume a contradictory view, as their activities were not a factor in <em>Carpenter</em>’s law enforcement-focused ruling.</p><p>A growing number of American lawmakers have <a href="https://www.wired.com/story/fourth-amendment-is-not-for-sale-act-2023/">argued in recent weeks</a> that the US intelligence community is itself more or less facilitating the erosion of that privacy expectation—that location data is protected from unreasonable government intrusion—mainly by ensuring it isn’t.</p><p>Andy Biggs, who chairs a subcommittee on federal government surveillance in the House of Representatives, says the federal government has “inappropriately collected and used Americans’ private information” for years. A whole range of agencies, including the Federal Bureau of Investigation and the Drug Enforcement Agency, have been exploiting “legal loopholes,” he says, to avoid oversight while amassing “endless amounts of data.”</p><p>A senior advisory group to the director of national intelligence, Avril Haines, the government’s top spy, stated in the report declassified last month that intelligence agencies were continuing to consider information “nonsensitive” merely because it had been commercially obtained. This outlook ignores “profound changes in the scope and sensitivity” of such information, the advisors warned, saying technological advancements had “undermined the historical policy rationale” for arguing that information that is bought may be freely used “without significantly affecting the privacy and civil liberties of US persons.”</p><p>Haines’ office did not respond to multiple requests for comment. In a statement last month, the director said she was working to implement key recommendations from her advisors and believed that Americans should be given “some sense” of the policies affecting the collection of their personal data. Much of the framework for dealing with commercial purchases by the intelligence community would be disclosed publicly when it is eventually finalized, she said.</p><p>The practice of paying businesses to spy on US citizens is one of several concerns lawmakers say they’ll be exploring this fall during what’s slated to be a long and heated debate over one of <a href="https://www.wired.com/story/fbi-section-702/">the government’s most powerful surveillance tools</a>: Section 702 of the Foreign Intelligence Surveillance Act.</p><p>The Mozilla Foundation joined the chorus of civil society groups calling for reforms of the 702 program today, saying FISA’s current process is “overbroad” and “restricted only by weak legislation and executive orders that, experience has shown, do not create real accountability.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Online activities to be made impossible by the UK Online Safety Bill (115 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36919175</link>
            <guid>36919175</guid>
            <pubDate>Sat, 29 Jul 2023 11:31:22 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36919175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36922562"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36922562" href="https://news.ycombinator.com/vote?id=36922562&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>While I'm not a supporter of the Online Safety Bill, I do find that the opprobrium that it has inspired is consistently hyperbolic.<p>The Online Safety Bill bans <i>nothing</i>. What it does do is create a regulatory framework for the Office for Communications (aka Ofcom, HM Government's regulator for the communications industry) to operate and enforce. The regulatory framework is based around risk assessments, and sets out specific risks (of the sort that most people would agree need to be minimised). Ofcom is empowered to decide that internet services are within scope, and then demand to see policies relating to ameliorating those risks within a service.</p><p>The regulatory framework does specify that end-to-end encryption is incompatible with the reduction of these risks. However, we do have to play the ball and not the person of unspecified gender here.</p><p>We are, after all, talking about the UK here. The phenomenon of 'those whom the law protects but does not bind, and those whom the law binds but does not protect' is still very much in effect here. This legislation has also been proposed by a government that responds to increasing crime (caused by insufficient police officers) by giving those police more powers (that they don't have the resources to exercise).</p><p>Ofcom has wide-ranging responsibilities: it regulates the press and broadcast media, it allocates EM spectrum bands, it regulates the telephone network, and regulates the Royal Mail. Like all organisations in the Home Civil Service, it is staffed by a core of 'generalists' with humanities degrees, assisted by a small cadre of 'specialists', who are put back in their cupboard once they've given their opinion.</p><p>What this all means is that the bill will only have the effects that the government has said it will in its press releases. Ofcom will go after the big social media companies and the likes of 4chan. Your Mastodon server or your Gitea server or your corner of the Tildeverse or whatever will never appear on their radar. Ofcom won't have the budget or the resources to go after individuals or small communities; they won't even know you exist.</p><p>In the UK, an energy bill or council tax bill is an important identity document, necessary for opening a bank account, because any time someone starts talking about identity cards, the readers of the <i>Daily Telegraph</i> start muttering about the Gestapo. Ofcom isn't going to audit your homelab for online harms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922689"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36922689" href="https://news.ycombinator.com/vote?id=36922689&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>It sounds like you're chiding others for complaining about the bill, and excusing this because the bill "only" <i>enables</i> mass surveillance and anti-privacy measures, rather than stipulating them. Might be I'm reading you wrong on this, but that's what I'm taking away.<p>&gt; What this all means is that the bill will only have the effects that the government has said it will in its press releases.</p><p>I don't really believe that for a second. Whenever sweeping powers are introduced, there is scope creep. Just look at how anti-terrorism laws have been abused. And it seems Apple and others don't believe it either.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922765"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36922765" href="https://news.ycombinator.com/vote?id=36922765&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>I am chiding people, not for complaining, but for misunderstanding the surrounding context. Legislation is only as powerful as those enforcing it.<p>&gt; And it seems Apple and others don't believe it either.</p><p>Yes, Apple, Google, Microsoft, Signal, Meta, and all the other big players else who has turned up to the committee hearings will have their activities curtailed. Individuals running Minecraft and Mastodon servers for their friends needn't worry.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922780"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36922780" href="https://news.ycombinator.com/vote?id=36922780&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>&gt; Individuals running Minecraft and Mastodon servers for their friends needn't worry.<p>Because they're too insignificant to matter, or because they won't be covered by the law? It sounds like the former, but you seem to imply the latter.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36922754"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36922754" href="https://news.ycombinator.com/vote?id=36922754&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>I don't agree with this comment, but I upvoted it because it brings a different perspective to HN, and therefore, improves the quality of discussion.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36921708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36921708" href="https://news.ycombinator.com/vote?id=36921708&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>Source code hosting; Gitea or Gitlab or Gogs etc all have UGC. The interesting part to me is I'm not sure how this helps the UK citizens who are using the internet be any safer, all you'd have to do is access the rest of the internet to circumvent this.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36920287"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36920287" href="https://news.ycombinator.com/vote?id=36920287&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>Interestingly, if you run a BBS through the telephone system, you'll be immune, as the bill specifies "the Internet", but:<p>1. I think the lines have jitter now they're over IP anyhow.</p><p>2. Bit niche...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36921703"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36921703" href="https://news.ycombinator.com/vote?id=36921703&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>Has anyone designed a modem to work over VOIP? It would have to cope with audio compression, jitter, dropouts, and so on.<p>On the other hand, it could assume much less noise than an analogue phone line.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922414"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36922414" href="https://news.ycombinator.com/vote?id=36922414&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>Yes, making fax machines work over VoIP was important in the early days. The G.711 codec was designed to support endpoints that needed a full 64kbps datapath.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36921988"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36921988" href="https://news.ycombinator.com/vote?id=36921988&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>Sure, it could be made to work, and it might even be able to keep up with your reading speed.<p>VoIP codecs are heavily optimized for human voice and have just a few kilobits of bandwidth. The analog phone network, before it went entirely digital, had a much higher bandwidth which is why modems were able to reach 56kbps. Phone calls in the 1980s were often crystal clear, almost on par with a broadcast radio station. Cell phones today along with VoIP are a muddy unintelligible mess in comparison.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922153"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36922153" href="https://news.ycombinator.com/vote?id=36922153&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>the quality of analog phone calls hung on the quality of the equipment, mostly the cables (and distance), whereas the quality of voip (or volte for that matter) depends mostly on the quality of the codec used.<p>ime both can be shitty or "crystal clear" but i totally agree that having a cell phone call today, with worse quality than an cross-continent analog connection in the 80s is very depressing
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36922066"><td></td></tr>
                  <tr id="36921864"><td></td></tr>
                  <tr id="36922688"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36922688" href="https://news.ycombinator.com/vote?id=36922688&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>&gt; you'll be immune, as the bill specifies "the Internet"<p>UK POTS is switching over to an IP based network, so does the bill specify the internet or ip based network?</p><p>If you submit a GDPR to your local constabulary, every phone call in the UK has a unique call identify much like a GUID now. Its quite insightful seeing just how much info is given out regarding the phone system capabilities via GDPR requests.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36920895"><td></td></tr>
                <tr id="36921090"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36921090" href="https://news.ycombinator.com/vote?id=36921090&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>I assume:<p>1) we're talking about the legal situation, not what would be physically possible;</p><p>2) that it applies to citizens, not server location (otherwise affected companies wouldn't be saying they'll exit the UK market, they'd just serve UK users from a further away but friendlier 'edge')
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36921099"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36921099" href="https://news.ycombinator.com/vote?id=36921099&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>I don't think it would be legal either since VPNs require encryption, too. Maybe some kind of proxy?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36921135"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36921135" href="https://news.ycombinator.com/vote?id=36921135&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>It's important to distinguish this from the encryption provisions of the bill. This part of the bill is distinct and means that social sites will need to verify ages of users and fill in lots of forms while they're at it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36921198"><td></td></tr>
                        <tr id="36920971"><td></td></tr>
                  <tr id="36920542"><td></td></tr>
                <tr id="36920962"><td></td></tr>
                  <tr id="36921362"><td></td></tr>
                <tr id="36922640"><td></td></tr>
                <tr id="36922779"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36922779" href="https://news.ycombinator.com/vote?id=36922779&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>Is a comment section user-to-user, though?  On its face, it seems more user-to-public, since it's not a private user-to-user transmission.   If blog comment sections are exempt, it would seem Reddit is exempt too.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36921082"><td></td></tr>
            <tr id="36919967"><td></td></tr>
                <tr id="36920306"><td></td></tr>
                  <tr id="36919185"><td></td></tr>
                <tr id="36919196"><td></td></tr>
                  <tr id="36920904"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36920904" href="https://news.ycombinator.com/vote?id=36920904&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>My understanding is that the OSB creates a responsibility for Ofcom to create a regulatory system for discouraging online harms.<p>Has Ofcom actually said what these regulations will be?</p><p>Is there any reason to expect them to be as dystopian as you predict? The interim codes of practice that the government published don't even apply at all to individuals. They also acknowledge that smaller companies should not be expected to be subject to the same level of regulation as large companies.</p><p>My experience with online activists' predictions of imminent dystopia is that they generally turn out to be extremely overblown. Hopefully that's true this time as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36920954"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36920954" href="https://news.ycombinator.com/vote?id=36920954&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>The bill itself doesn't appear to exempt anyone. From Taylor Wessing:<p>"[following amendments] The OSB continues to apply to any service that enables content generated, uploaded or shared by one user to be encountered by another user (user-to-user services) or that allows users to search more than one website or database (search services)."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36921346"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36921346" href="https://news.ycombinator.com/vote?id=36921346&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>It actual exempts several categories (email servers etc).<p>My point is that there is no reason to think the regulations that eventually come into force for services which aren't exempted will be as ridiculous as you suggest.</p><p>I agree that the OSB gives Ofcom the power to regulate Minecraft servers, but those regulations must be reasonable and proportionate so I don't believe that it will affect a private individual running a private server, as you appeared to suggest.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36921361"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36921361" href="https://news.ycombinator.com/vote?id=36921361&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>Yeah agree about point to point services. Email and SMS and voice.<p>What I don't see is the bit where it says that the audit responsibilities are limited to certain people or companies.</p><p>If you could point to the "reasonable and proportionate" bit in the legislation that would be interesting to check out.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36920960"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36920960" href="https://news.ycombinator.com/vote?id=36920960&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>&gt; My experience with online activists' predictions of imminent dystopia is that they generally turn out to be extremely overblown.<p>The questions in my opinion then become,</p><p>Is it the law preventing these? Is it some people not yet seeing why they should do it? Are they purposefully not doing it initially to calm people?</p><p>If they don’t want to be able to do it, it could be rephrased.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922615"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36922615" href="https://news.ycombinator.com/vote?id=36922615&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>If you operate an online service, you don't have any actual obligations under the Online Safety Bill until Ofcom taps you on the shoulder. Considering that Ofcom is also responsible for regulating ISPs, all broadcast media, the EM spectrum, the telephone network and the Royal Mail, I don't think they'll have the resources to go after anyone but the social media giants.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36921254"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36921254" href="https://news.ycombinator.com/vote?id=36921254&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>By way of analogy, the government might make a law that allows, in secondary legislation, the setting of a driving speed limit.<p>These activists are claiming that the government is secretly intending the speed limit to be 1mph. The government are trying to ban driving!! The activists are demanding the <i>enabling legislation</i> be amended so that the speed limit, when set, must be no lower than Xmph.</p><p>But all this does is force all regulation to be done in primary legislation.</p><p>The debate about what the regulations should be is separate to there being a regulatory system at all.</p><p>It is right that the primary legislation just lays out in broad terms that the regulations must be "reasonable" and "proportionate" etc because it's only real purpose is to allow those regulations to be challenged in court in future.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36921705"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36921705" href="https://news.ycombinator.com/vote?id=36921705&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>I'd like to offer a different analogy.<p>Encryption in communication is, to me, akin to the locks on the doors of your residence, on safes or other secure containers. It protects your privacy from prying eyes who want to snoop on what others are doing.</p><p>The activists are claiming that the government wishes to require that all locks be unlockable by one of a range of secret "master" keys, so that they can ensure you're not privately doing anything illegal. Not only that, but the government also wishes to institute a compliance regimen to ensure that all locks are indeed actually openable by these master keys.</p><p>Given the historic behavior of <i>all</i> governments, I don't trust them <i>not</i> to claim the most powerful interpretation of the laws and regulations that are instituted. Maybe not at first, but it <i>will</i> happen, because it has <i>always</i> happened this way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36922653"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36922653" href="https://news.ycombinator.com/vote?id=36922653&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>What the government actually wants is for service providers (as in, social media companies, not ISPs) to monitor everything happening on their service to make sure that no one is coming to any serious harm. How providers do that is up to them.<p>The government doesn't care about the technology; it's all about corporate processes, and they're going to regulate it one corporation at a time. If you're not important to be asked to appear before a House of Commons Committee, you're not going to come to Ofcom's attention.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36921301"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36921301" href="https://news.ycombinator.com/vote?id=36921301&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>That's not my understanding of the legislation. I see no exemptions  from the child access provisions. The criterion is "any site with a significant number of child users" or where <i>additionally</i> OFCOM decides to intervene, and where significant is not defined.<p>And of course you seem to have to perform an audit to determine how many child users you have in order to be exempted.</p><p>Again, this is my reading of the very complex bill. The article from Taylor Wessing seems to concur though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36921528"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36921528" href="https://news.ycombinator.com/vote?id=36921528&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><p><span>But all the provisions service providers are expected to implement have a "reasonable" or "proportionate" qualifier, no?<p>And the actual, practical meaning of these responsibilities will be defined in a yet-to-be-published Code of Practice...?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36921611"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36921611" href="https://news.ycombinator.com/vote?id=36921611&amp;how=up&amp;goto=item%3Fid%3D36919175"></a></center>    </td><td><br><div>
                  <p><span>Like unreasonably low speed limits, the purpose of legislation like this isn't to be enforceable against everyone.  It's to be enforceable against <i>anyone</i>.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IRC is the only viable chat protocol (251 pts)]]></title>
            <link>https://koshka.love/babel/irc-forever.html</link>
            <guid>36918655</guid>
            <pubDate>Sat, 29 Jul 2023 10:12:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koshka.love/babel/irc-forever.html">https://koshka.love/babel/irc-forever.html</a>, See on <a href="https://news.ycombinator.com/item?id=36918655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>IRC is the Only Viable Chat Protocol</h2>
<hr>
<p><del>IRC is so wonderful that I am continually finding myself far too distracted by it to actually write this article praising the virtues of IRC. Get on IRC to learn more.</del></p><p>
OK, OK, I'll pull myself away from the terminal and finally finish writing this piece. Although it would be quite poetic if my argument for using IRC was prematurely aborted because I could not pull myself from Irssi/Comic Chat long enough to actually write it, this scenario would be of no benefit to anyone.</p><p>
For those unaware, IRC is a primordial (by Internet standards) yet stalwart chat protocol dating back to 1988. The basic way it works is that people use an IRC client to connect to an IRC daemon running on another computer (an IRC server), where they are able to pick a name and interact with other people over text, either by joining a channel that they are in, or privately messaging them. Although it has severely declined in popularity since its golden age in favour of social media and Discord, I have found myself more attached to the ostensibly dying protocol than ever before lately for a myriad of reasons that I wish to share here.</p><p>
For transparency's sake, I should probably point out immediately that I am a long-time stubborn aficionado of retro technology and culture, both in ways that other people admire, and in ways that make me come off as an eccentric lunatic.</p><p>
Among other things, I still use a flip phone, collect and listen to music CDs, use Office 97 (the very first version I ever owned), listen to music on an MP3 player while on the go, own two CRT televisions along with a VCR and a collection of VHS tapes, collect and read physical books, and own two CRT monitors that I use with my 1999 Compaq gaming computer that still proudly runs Windows 98 and hosts the DOS/Windows 9x games that still make up the bulk of the games that I enjoy.</p><p>
As returning visitors likely know, in the year of our Lord, 2022, I also proudly host my own IRC server, where I spend an extremely unhealthy amount of my time chatting with beloved like-minded people. Using an "archaic" chat platform that dates back to the 80s and that has lost the majority of the userbase it enjoyed during its peak may seem like a form of nostalgia bordering on abject madness when looked at from the outside. Yet, I daresay it is easily one of the most easily defensible and reasonable of the life choices that I have just listed off.</p><h3>Cut the (Dis)Cord</h3><p>
If you look around for a place to chat in real time with other people in this day and age, chances are more than good that you'll quickly be directed to a Discord server. This is an unfortunate state of affairs for many reasons. To put it succintly, Discord is a centralised and proprietary platform that spies on its users in every conceivable way, right down to what logging what programs they have running on their computer and demanding people self-dox by providing their phone number. All of this information is then put to use to allow advertisers to better target Discord's userbase.</p><p>
I am aware that most people have become completely lamentably desensitised to corporate and government surveillance, and may thus not be greatly alarmed by these facts. However, I would assume that most (if not all) of those people would feel quite violated if a salesperson began stalking them in "real life", listening in to every conversation they had with their family/friends from a distance, and then physically approaching on the street and peddling products to them in suspiciously prescient ways.</p><p>
The fundamental fact that Discord users refuse to see is that the platform isn't run on magic dust and fairy incantations, but actual human beings. Using Discord is no different from having a group of strangers sitting in your room with you, noting down every word you say to your friends and everything you run on your computer, and doing the devil knows what with it.</p><p>
Even if you have full-on Stockholm syndrome in regard to advertisers data-mining your life to sell you garbage, who knows where else your data could be going? Considering the horrific epidemic of sexual abuse being abetted and covered up in the workplace, is it really too difficult to imagine malicious actors at Discord (or any other technology company) illegitimately accessing the data of their business' users and using it for stalking or other nefarious purposes?</p><p>
The complete de-centralisation of IRC, unlike Discord, is also well worth expanding on. Since IRC is a standard and not a platform like Discord, anyone with access to reliable hosting and basic computer knowledge can set up their own IRC server. As I joked to a friend recently, I am free to ban anyone from an IRC channel I own, but there is nothing stopping them from then starting #koshkaisafag and regrouping. I can try to get them banned from the server, but there is also nothing stopping them from setting up their own server as irc.koshkaisafag.info and regrouping as a completely sovereign entity that no one can touch any longer.</p><p>
There are certainly a number of monolithic IRC networks, such as Rizon, EFNet, and Libera Chat, that make up the vast bulk of the IRC world, but there are also many thousands of smaller networks dotting the landscape. There are just over 500 networks whose channels are indexed by the IRC search engine <a href="https://netsplit.de/networks/">Netsplit.de</a>, but this engine still only covers fairly large networks, and excludes the great many networks that are either private or very small and obscure. Some of these may be intended entirely for a small group of friends, or may be used by a business to communicate privately.</p><p>
There certainly is no magical check in any IRCd daemon to stop a rogue IRCOp from <a href="https://www.reddit.com/r/discordapp/comments/7arzdn/my_account_has_been_disabled_with_no_reason_given/">banning individuals for no coherent reason</a>, or <a href="https://www.reddit.com/r/privacy/comments/djyy6v/psa_discord_is_deactivating_accounts_without/">blackmailing someone into providing their phone number</a> and/or other personal information in order to stay on a server (although, unlike with Discord, I have never heard of this occurring on IRC before), but the complete de-centralisation of the IRC world means that allowing such abuses of power is quite detrimental to an IRC network. If an IRCOp goes rogue, their reign of terror is unlikely to last for much longer as word goes out and users either flee to another network or set their own up.</p><p>
Perhaps the most dramatic example of this is <a href="https://github.com/siraben/freenode-exodus">the rapid fall of Freenode</a>, which underwent a rapid collapse after a hostile takeover of the network by new management seeking to use it to make a quick buck. In the span of mere months, the most popular IRC network in the world was reduced to a disgraced and nearly moribund shell of its former self, as disgruntled users fled enmasse to the newly established Libera Chat network.</p><p>
I touched on the problems of centralisation and why de-centralisation was a key tenet of the old Internet in my acclaimed article <a href="https://koshka.love/mwwwga.html">Make the Web Great Again</a>, and Discord does not get nearly enough bad press for its role in destroying this aspect of the Internet. Much as the dreaded Reddit has largely paved a fascist monopoly over the niche once occupied by a bounty of independent Web forums, Discord has done the same with the chat world, replacing the sea of independent and free IRC servers with a single corporate walled garden whose owners each user must avoid offending in any way, lest they be entirely cast out of the public square.</p><p>
This problem is so endemic on the modern Internet that not only is there a sea of unintentionally comical Neocities "Web 1.0" websites featuring their owners jabbering about how much they miss the old Internet while inviting people to chat on the webmaster/webmistress' Discord server in the same breath, but even actually respectable people and outfits (who I will not name out of politeness) that have migrated to Discord because all of their misguided friends use it and refuse to budge. Even I, for all of my frenzied rabble-rousing, briefly created a Discord account a few years ago to speak with a friend before quitting the service out of disgust.</p><p>
Nonetheless, for all of the social issues it causes me, being autistic has also given me the stubbornness of a mountain, and I have long since vowed to never touch the service again no matter who or what I may need it for. Each person who <a href="https://koshka.love/babel/boycott-big-technology.html">avoids big</a> <a href="https://koshka.love/babel/alternatives-to-big-technology.html">technology companies</a> pushes the stake slightly deeper into the frigid, rotten heart of the privacy vampire that Discord and other big technology companies are (no offence intended to comparatively benevolent actual vampires with this comparison). Each person who avoids these services is also one less carrot for the vampire to dangle away over other people's heads to convince them to stay in its cave.</p><p>
For more information on the many sordid problems with Discord, please check out these two guides written by the esteemed <a href="https://stallman.org/discord.html">Richard Stallman</a> and <a href="https://spyware.neocities.org/articles/discord.html">Spyware Watchdog</a> over on Neocities on why Discord should be avoided like a berserk chainsaw-wielding leper, if you have not done so already.</p><h3>A Rare Sanctuary</h3><p>
My good friend <a href="https://lolwut.info/">lolwut</a> made a very astute observation some time ago about IRC being a nearly infallible NORP filter, and thus a very rare safe port from the <a href="https://koshka.love/babel/normiefication.html">normiefication</a> storm, due to the apparent "complexities" involved in getting on IRC, and the sheer age and and its lack of sleekness of the protocol relative to Discord and other modern alternatives. Anyone who has ever used IRC knows that there is nothing even remotely complicated about using it, but the terminology and the steps required to use one are ostensibly terrifying enough to reliably keep the technically illiterate at bay.</p><p>
A number of Web chat interfaces have been invented over the years to entice normalcattle onto IRC, but even this has proven to be an abject failure, as well over 90% of cases end with the NORP leaving after 30 seconds of inactivity, apparently appalled by the fact that a protocol that is utilised by people who could be online from anywhere in the world and who could be doing any manner of non-IRC related things would have lulls in activity. In fact, the only real use that these clients seem to get is from regulars who temporarily lack access to a real IRC client. On my end, I rely on Kiwi IRC to get on IRC from my flip phone, which has no SSH client or IRC client, but does have a Web browser.</p><p>
Seeing as the world of IRC is a nearly NORP-free oasis, most people are mature and intelligent enough to understand that words on a screen are just that, and that it is quite simple to withdraw from them if one does not want to deal with them. Aside from actually leaving a channel to get away from an unpleasant user, it is possible to use the ignore function to block any further correspondence from them. Many networks also provide some sort of server-side ignore functionality to stop a user from receiving any private messages that don't come from a pre-approved user.</p><p>
Due to the fact that IRC power is effectively meaningless (as it should be on any part of the Internet!), the common theme for governance on most IRC servers is delightfully adherent to the ways of the old Internet. As is nicely summarised <a href="https://www.unrealircd.org/docs/IRCOp_guide#Principles">here</a>, IRCOps (the administrators of an IRC network) are normally completely neutral entities that allow users to govern themselves and their channels however they see fit, only wielding their power in dire situations such as when someone's actions are endangering the security of the server or breaking national law.</p><p>
Indeed, while on smaller and more "intimate" networks, such as my own, running into the local IRCOp(s) is a common occurrence, it is actually quite rare to actually have even a single interaction with an IRCOp on any large server, unless they happen to be part of a channel you are in. Seeing as anyone can start their own channel(s), and run them however they see fit, there is very rarely a need for an IRCOp to do anything beyond keeping the power on and changing the light bulbs when they go bad.</p><p>
In contrast to much of the modern Internet, IRC is also largely anonymous, another key tenet of the old Internet. Beyond not requiring any personal information to participate (in contrast to Discord, where the service itself often requires a phone number, and some individual rooms go as far as requiring <i>social media background checks</i>, lest some normalfag SJW gets an aneurysm from reading a mean word), many modern IRC servers (including my own) also cloak people's IP addresses and offer the option of VHosts, which are custom (fake or real) domain names that people can choose to substitute in for their IP address. Additionally, most IRC networks allow users to connect via a VPN or (less often) Tor.</p><p>
A quick word of caution for anyone who is new to IRC and who I may have inspired to go spelunking: the key word in the previous few sentences is "most". VHosts and IP cloaking are modern IRC conveniences, and not every network offers them. EFNet, the most ancient IRC network in the world and the child of the very first IRC network, is particularly notorious for stubbornly eschewing just about every modern IRC convenience there is.</p><p>
Not only does EFNet still display people's full IP addresses (assuming the server they are connecting to does not have its own domain name), but it also does not even have services such as NickServ and ChanServ for people to register their names and channels in order to retain ownership over them! This "wild west" landscape is not nearly as chaotic and exciting as it may sound, especially since everyone on the server is seemingly connected from a shell or a bouncer that they last touched while speculating on what will happen on Y2K.</p><h3>Extending IRC</h3><p>
While some changes have occurred in the IRC world over the decades, the protocol itself dates back all the way back to 1988, and was designed to be sustainable on the Internet speeds of that bygone era. In contrast to Discord and the bloated client that it pushes down user's throats, IRC is such a bare bones and low-consumption protocol that you can even connect to it via the command prompt or terminal using Telnet (although you do have to manually ping the IRC server you're connected to in order for it to not assume that your connection died)!</p><p>
The reliability and lack of bloat that are inherent to IRC ultimately also means that there are a number of fancy modern features that Discord has that IRC lacks, a big one being the inability to view backlogs of conversations that transpired while one was not connected to an IRC server. Although IRC does not itself provide this functionality, the extremely simple nature of IRC allows for a couple of lightweight options for reliably remaining on IRC around the clock and not missing out on a word that anyone says.</p><p>
The most sublime option by far involves running a terminal-based client such as <a href="https://irssi.org/">Irssi</a> (the most sublime IRC client in existence, in my personal opinion) or WeeChat on a Linux/BSD server in a terminal multiplexer such as Screen or Tmux. One can then SSH into the server from any Internet-connected computer at their leisure, and take control of their IRC client as if it had been running on their current computer this entire time.</p><p>
For my part, I have been on IRC this way since 2006 on a variety shells from my very first one which was provided to me by a friend of mine on his server, to free publicly offered ones, to Raspberry Pi servers I set up in my house, to my current one which runs on the same server running my website and other infrastructure. Given how useful and reliable this is, and how efficient and sleek Irssi is, I cannot imagine why anyone would want to use any other client or method.</p><p>
Nonetheless, for fans of non-terminal clients such as HexChat and mIRC (there is no accounting for taste, I suppose), there also exists the option of IRC bouncers. These are essentially bots that connect to specific IRC servers/channels under their owner's name and log all of the messages that they receive. The bouncer's owner in turn connects to the bouncer like an IRC server, after which they are provided the backlog of what occurred during their absence and are able to take full control of the bouncer to chat like they normally would on an IRC server.</p><p>
Being a bare bones public protocol, IRC does suffer the issue of being easy to snoop on. Thankfully, many IRC networks do allow users to connect via SSL, the port for which is usually 6697, as opposed to the usual 6667. A single user in a channel not using SSL can completely compromise everyone else's efforts, but it is possible to restrict anyone not connected via SSL from joining a channel. Additionally, a number of clients on Linux (Irssi, WeeChat, and HexChat) also allow users to set up OTR in order to have fully encrypted private one-on-one conversations with anyone else who has this plugin.</p><p>
Other features that are notably absent from IRC but present on Discord are image-sharing and voice chat/video chat. Before going into the available options for an IRC user needing these features, I must say that personally view all three of these features as being utterly extraneous, and not even remotely worth the many dire downsides that come with Discord even if they were not. I wrote an entire article outlining why <a href="https://koshka.love/babel/writing-superior-to-speaking.html">writing is provably superior to speaking as a communication method</a>, so I will not elaborate further here.</p><p>
Needless to say, as an autistic person who goes online because I am actually able to socialise without the vexing machinations of in-person/verbal communication, I have never voice-chatted in my life and only used a webcamera once when I had to in order to do a job evaluation during quarantine. Even considering over 98% of people aren't autistic, I still do not understand how anyone can enjoy or even seek out voice chat. For one, it would interrupt my habit of listening to music any time I am at the computer, and for two, it would morph online conversations from completely anonymous exchanges to ones that are broadcasted to everybody in the vicinity of the participants, while also providing dox fuel for all involved.</p><p>
My angry grumbling aside, for anyone who absolutely feels the need to ruin the simple sublimity of text conversation with voice chat, there do exist relatively safe outside services, notably <a href="https://www.mumble.com/">Mumble</a>, that users can switch over from IRC for when needed. Admittedly, this is an extra step that requires reliance on infrastructure outside of IRC, but I would classify that as more than worth being able to have a conversation with minimal fear of privacy violation. Mumble is free software and, much like IRC, allows for anyone to set up their own personal server to communicate on.</p><p>
The issue of image sharing is once again something that can be very easily worked around by either uploading any images one wishes to share to one's personal server, or to an image hosting service such as <a href="https://catbox.moe/">Catbox.moe</a>, or <a href="https://uguu.se/">Uguu.se</a>. Again, this is an extra step that winds up requiring reliance on infrastructure outside of IRC, but one that takes very minimal effort. It should be noted however, that IRC <i>does</i> allow for sending files from one person to the other using the DCC protocol, so only sharing images with an entire group at once requires leaving its borders. The only issue is that DCC is implemented differently by various clients and may be blocked by the firewall by default.</p><p>
Nevertheless, for people seeking a facsimile of video chat on IRC, there does exist a fascinating alternative that allows for something close to it: the truly sublime <a href="http://mermeliz.com/">Microsoft Comic Chat</a>, a completely unique IRC client that Microsoft invented during its golden age of the 90s. Although Microsoft wound up discontinuing it over 20 years ago in favour of MSN Messenger, it continues to enjoy a cult following to this day, and for very good reason.</p><p>
In a stroke of absolute genius, Comic Chat rejects the typical text-only approach of other IRC clients, and instead renders IRC channels as in-progress comic strips, with every participant being able to choose an avatar for themselves and punctuate everything they say with a specific facial expression or pose.</p><p>
Beyond being patently hilarious (many of the default avatars are absolutely insane, and most of the custom-made ones are comical ones such as sunglasses-wearing cats and obese Vikings), Comic Chat adds an entirely new dimension to conversations, allowing people to express themselves with facial expressions and body language to emphasise and clarify what they are saying. The client even allows you to send a facial expression as a reaction without including any words at all, for situations where body language alone gets one's message across better than words.</p><p>
While this was certainly not the intended goal behind Comic Chat, and it is a program that is enjoyed by a great many neurotypicals, I personally adore it enough to argue that it may be <i>the</i> ideal communication method for <a href="https://koshka.love/autism/index.html">autistic people</a>. Most characters have such exaggerated facial expressions and body language that just about anyone can clearly understand them, and the nature of IRC means that anyone participating in a conversation has plenty of time to process everything and is not pressured to immediately and constantly send out many complex social cues every moment of an interaction.</p><p>
I will admit that Microsoft Comic Chat has quite a buffoonish reputation, owing to the inherent silliness of the program and its sheer age <a href="https://koshka.love/babel/words-i-hate.html#outdated">(sadly, this is considered by many to be an actual criticism by itself</a>). Its association with <a href="https://www.bonequest.com/6461">the ludicrous NSFW web comic Jerkcity</a> also likely did no PR favours for it. Yet just as many other great inventions were happy accidents, I do believe that in their tomfoolery, Microsoft accidentally created one of the most useful methods of communication we autistic people have available to us. One that, even by itself, more than justifies the continued existence of IRC in my eyes. I suppose the fact that I get to be an <a href="https://koshka.love/babel/meow.png">angelic pink kitty on IRC</a> helps a lot too. ^-^</p><hr><p>
Although my main purpose for writing this article is to inspire some people to change their ways and consider migrating from the proprietary spyware platform of Discord to free and de-centralised prairies such as IRC and Mumble, it would be a lost opportunity to not advertise my own burgeoning IRC network here. If you have any interest in interacting with a wise, witty, and welcoming group of Internet/computing/gaming nostalgics (and also, myself), be sure to steer your IRC client of choice towards KoshkaIRC at irc.koshka.love, the main channel of which is # (literally as simple of a channel name as it can get).</p><p>
There has also recently been a Microsoft Comic Chat renaissance on the same server, in the channel #comicchat. Due to the fact that participating requires a separate IRC client which cannot be run on a shell and is too primitive to connect to a bouncer, and the fact that people on the network hail from time zones all over, I have decided to host an all-day named <b>Comic Chat Caturday</b> event on Saturdays (or closer to Sundays, for people in the enigmatic land of Oceania) from now on to make it easier for people to participate.</p><p>
Although a program designed only for Windows, it is possible to get Comic Chat running in Linux, and my good friend <a href="https://shadowm00n.neocities.org/">ShadowM00n</a> has written <a href="https://shadowm00n.neocities.org/tech/comic_chat.html">an excellent guide</a> on how exactly to set this program up on Linux using Wine.</p><p>
Microsoft Comic Chat comes with a default set of rather insane avatars that are probably best known as the cast characters of the aforementioned Jerkcity/BoneQuest, which gloriously appropriated them as a bunch of lunatics shrieking about homosexual intercourse, drugs, and monster poos, but there is a sea of custom avatars available for you to download at <a href="https://mermeliz.com/">Mermaid Elizabeth's monolithic Comic Chat website</a>.</p><p>
Aside from being the author's vast personal Comic Chat resource, this site also hosts a massive trove of defunct Comic Chat websites created over the decades, and all of the avatars and other resources that they hosted. From kitties of every shape and stripe, to anime characters, to Vikings, to all sorts of other options, there should be something for everyone on there.</p><p>
Seeing as <a href="https://koshka.love/autism/index.html">autism</a> and <a href="https://koshka.love/dos/index.html">general old computing-related nostalgia</a> are the two main themes of this website, I could not think of a more fitting event for fans of this website than a day dedicated to this delightful ancient, autistic-friendly IRC client. Whether you've never used Comic Chat before, or you're familiar with it and want to give it another spin, be sure to drop by this Saturday and join in the fun! As long as people continue using free and open protocols, and <a href="https://koshka.love/mwwwga.html">upholding the tenets of old</a>, the good old Internet will never truly die.</p><h4>Many thank yous to <a href="https://shadowm00n.neocities.org/">ShadowM00n</a>, both for his amazingly thorough proof-reading, and for writing the aforementioned article about running Comic Chat on Linux, and to jvlfools, for his own helpful proof-reading!</h4>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you want to build your own open source chatbot (228 pts)]]></title>
            <link>https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/</link>
            <guid>36918435</guid>
            <pubDate>Sat, 29 Jul 2023 09:28:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/">https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/</a>, See on <a href="https://news.ycombinator.com/item?id=36918435">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="article">
    <p><i>(Expanded from </i><a href="https://sched.co/1O37L"><i>a talk</i></a><i> given at </i><a href="https://dwebcamp.org/"><i>DWeb Camp 2023</i></a><i>.)</i></p>
<p>Artificial intelligence may well prove one of the most impactful and disruptive technologies to come along in years. This impact isn’t theoretical: AI is already affecting real people in substantial ways, and it’s already changing the Web that we know and love. Acknowledging the potential for both benefit and harm, Mozilla has committed itself to the principles of <a href="https://foundation.mozilla.org/en/internet-health/trustworthy-artificial-intelligence/"><b>trustworthy AI</b></a>. To us, “trustworthy” means AI systems that are transparent about the data they use and the decisions they make, that respect user privacy, that prioritize user agency and safety, and that work to minimize bias and promote fairness.</p>
<h2>Where things stand</h2>
<p>Right now, the primary way that most people are experiencing the latest AI technology is through <b>generative AI chatbots</b>. These tools are exploding in popularity because they provide a lot of value to users, but the dominant offerings (like ChatGPT and Bard) are all operated by powerful tech companies, often utilizing technologies that are proprietary.</p>
<p>At Mozilla, we believe in the collaborative power of <b>open source</b> to empower users, drive transparency, and — perhaps most importantly — ensure that technology does not develop only according to the worldviews and financial motivations of a small group of corporations. Fortunately, there’s recently been rapid and exciting progress in the open source AI space, specifically around the <b>large language models</b> (LLMs) that power these chatbots and the tooling that enables their use. We want to understand, support, and contribute to these efforts because we believe that they offer one of the best ways to help ensure that the AI systems that emerge are truly trustworthy.</p>
<h2>Digging in</h2>
<p>With this goal in mind, a small team within Mozilla’s innovation group recently undertook a hackathon at our headquarters in San Francisco. Our objective: <b>build a Mozilla internal chatbot prototype</b>, one that’s…</p>
<ul>
<li aria-level="1">Completely <b>self-contained</b>, running entirely on Mozilla’s cloud infrastructure, without any dependence on third-party APIs or services.</li>
<li aria-level="1">Built with <b>free, open source</b> large language models and tooling.</li>
<li aria-level="1"><b>Imbued</b> with Mozilla’s beliefs, from trustworthy AI to the principles espoused by the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla Manifesto</a>.</li>
</ul>
<p>As a bonus, we set a stretch goal of integrating some amount of internal Mozilla-specific knowledge, so that the chatbot can answer employee questions about internal matters.</p>
<p>The Mozilla team that undertook this project — <a href="https://yetanotherjosh.com/">Josh Whiting</a>, <a href="https://www.rupertparry.com/">Rupert Parry</a>, and <a href="https://stephenhood.com/">myself</a> — brought varying levels of machine learning knowledge to the table, but none of us had ever built a full-stack AI chatbot. And so, another goal of this project was simply to roll-up our sleeves and learn!</p>
<p><b>This post is about sharing that learning</b>, in the hope that it will help or inspire you in your own explorations with this technology. Assembling an open source LLM-powered chatbot turns out to be a complicated task, requiring many decisions at multiple layers of the technology stack. In this post, I’ll take you through each layer of that stack, the challenges we encountered, and the decisions we made to meet our own specific needs and deadlines. YMMV, of course.</p>
<p>Ready, then? Let’s begin, starting at the bottom of the stack…</p>
<p><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram.png"><img decoding="async" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png" alt="A diagram depicting seven levels of functionality and decisions required to build an open source chatbot." width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-1536x1094.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-2048x1459.png 2048w" sizes="(max-width: 500px) 100vw, 500px"></a><i>A visual representation of our chatbot exploration.</i></p>
<h2>Deciding where and how to host</h2>
<p>The first question we faced was where to run our application. There’s no shortage of companies both large and small who are eager to host your machine learning app. They come in all shapes, sizes, levels of abstraction, and price points.</p>
<p>For many, these services are well worth the money. Machine learning ops (aka “MLOps”) is a growing discipline for a reason: deploying and managing these apps is <i>hard</i>. It requires specific knowledge and skills that many developers and ops folks don’t yet have. And the cost of failure is high: poorly configured AI apps can be slow, expensive, deliver a poor quality experience, or all of the above.</p>
<p><b>What we did</b>: Our explicit goal for this one-week project was to build a chatbot that was secure and fully-private to Mozilla, with no outside parties able to listen in, harvest user data, or otherwise peer into its usage. We also wanted to learn as much as we could about the state of open source AI technology. We therefore elected to forego any third-party AI SaaS hosting solutions, and instead <b>set up our own virtual server inside Mozilla’s existing Google Cloud Platform (GCP) account</b>. In doing so, we effectively committed to doing MLOps ourselves. But we could also move forward with confidence that our system would be private and fully under our control.</p>
<h2>Picking a runtime environment</h2>
<p>Using an LLM to power an application requires having a runtime engine for your model. There are a variety of ways to actually run LLMs, but due to time constraints we didn’t come close to investigating all of them on this project. Instead, we focused on two specific open source solutions: <i>llama.cpp</i> and the Hugging Face ecosystem.</p>
<p>For those who don’t know, <a href="http://huggingface.co/">Hugging Face</a> is an influential startup in the machine learning space that has played a significant role in popularizing the <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer architecture</a> for machine learning. Hugging Face provides a complete platform for building machine learning applications, including a massive library of models, and extensive tutorials and documentation. They also provide <a href="https://huggingface.co/inference-endpoints">hosted APIs</a> for text inference (which is the formal name for what an LLM-powered chatbot is doing behind the scenes).</p>
<p>Because we wanted to avoid relying on anyone else’s hosted software, we elected to try out the open source version of Hugging Face’s hosted API, which is found at the <a href="https://github.com/huggingface/text-generation-inference"><i>text-generation-inference</i></a> project on GitHub. <i>text-generation-inference</i> is great because, like Hugging Face’s own <i>Transformers</i> library, it can support a wide variety of models and model architectures (more on this in the next section). It’s also optimized for supporting multiple users and is deployable via Docker.</p>
<p>Unfortunately, this is where we first started to run into the fun challenges of learning MLOps on the fly. We had a lot of trouble getting the server up and running. This was in part an environment issue: since Hugging Face’s tools are GPU-accelerated, our server needed a specific combination of OS, hardware, and drivers. It specifically needed NVIDIA’s <a href="https://developer.nvidia.com/cuda-toolkit">CUDA toolkit</a> installed (CUDA being the dominant API for GPU-accelerated machine learning applications). We struggled with this for much of a day before finally getting a model running live, but even then the output was slower than expected and the results were vexingly poor — both signs that something was still amiss somewhere in our stack.</p>
<p>Now, I’m not throwing shade at this project. Far from it! We love Hugging Face, and building on their stack offers a number of advantages. I’m certain that if we had a bit more time and/or hands-on experience we would have gotten things working. But time was a luxury we didn’t have in this case. Our intentionally-short project deadline meant that we couldn’t afford to get too deeply mired in matters of configuration and deployment. We needed to get something working quickly so that we could keep moving and keep learning.</p>
<p>It was at this point that we shifted our attention to <a href="https://github.com/ggerganov/llama.cpp"><i>llama.cpp</i></a>, an open source project started by <a href="https://ggerganov.com/">Georgi Gerganov</a>. <i>llama.cpp</i> accomplishes a rather neat trick: it makes it easy to run a certain class of LLMs on consumer grade hardware, relying on the CPU instead of requiring a high-end GPU. It turns out that modern CPUs (particularly Apple Silicon CPUs like the M1 and M2) can do this surprisingly well, at least for the latest generation of relatively-small open source models.</p>
<p><i>llama.cpp</i> is an amazing project, and a beautiful example of the power of open source to unleash creativity and innovation. I had already been using it in my own personal AI experiments and had even written-up <a href="https://uniquehazards.com/2023/05/06/the-complete-idiots.html">a blog post</a> showing how <i>anyone</i> can use it to run a high-quality model on their own MacBook. So it seemed like a natural thing for us to try next.</p>
<p>While <i>llama.cpp</i> itself is simply a command-line executable — the “cpp” stands for “C++” —&nbsp; it can be dockerized and run like a service. Crucially, a set of <a href="https://github.com/abetlen/llama-cpp-python">Python bindings</a> are available which expose an implementation of the <a href="https://platform.openai.com/docs/api-reference">OpenAI API specification</a>. What does all that mean? Well, it means that <em>llama.cpp</em> makes it easy to slot-in <em>your own</em> LLM in place of ChatGPT. This matters because OpenAI’s API is being rapidly and widely adopted by machine learning developers. Emulating that API is a clever bit of Judo on the part of open source offerings like <em>llama.cpp.</em></p>
<p><b>What we did</b>: With these tools in hand, we were able to get <i>llama.cpp</i> up and running very quickly. Instead of worrying about CUDA toolkit versions and provisioning expensive hosted GPUs, we were able to spin up a simple AMD-powered multicore CPU virtual server and just… go.</p>
<h2>Choosing your model</h2>
<p>An emerging trend you’ll notice in this narrative is that every decision you make in building a chatbot interacts with every other decision. There are no easy choices, and there is no free lunch. The decisions you make <i>will</i> come back to haunt you.</p>
<p>In our case, choosing to run with <i>llama.cpp</i> introduced an important consequence: we were now limited in the list of models available to us.</p>
<p>Quick history lesson: in late 2022, <a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">Facebook announced LLaMa</a>, its own large language model. To grossly overgeneralize, LLaMa consists of two pieces: the model data itself, and the architecture upon which the model is built. Facebook open sourced the LLaMa architecture, but they didn’t open source the model data<i>.</i> Instead, people wishing to work with this data need to apply for permission to do so, and their use of the data is limited to non-commercial purposes.</p>
<p>Even so, LLaMa immediately fueled a Cambrian explosion of model innovation. Stanford released <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>, which they created by building on top of LLaMa via a process called <a href="https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)">fine-tuning</a>. A short time later, <a href="https://lmsys.org/about/">LMSYS</a> released <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a>, an arguably even more impressive model. There are dozens more, if not hundreds.</p>
<p>So what’s the fine print? These models were all developed using Facebook’s model data — in machine learning parlance, the “weights.” Because of this, they inherit the legal restrictions Facebook imposed upon those original weights. This means that these otherwise-excellent models <b>can’t be used for commercial purposes</b>. And so, sadly, we had to strike them from our list.</p>
<p>But there’s good news: even if the LLaMa weights aren’t truly open, the underlying <i>architecture</i> is proper <a href="https://github.com/facebookresearch/llama">open source code</a>. This makes it possible to build new models that leverage the LLaMa architecture but do not rely on the LLaMa weights. Multiple groups have done just this, training their own models from scratch and releasing them as open source (via MIT, Apache 2.0, or Creative Commons licenses). Some recent examples include <a href="https://github.com/openlm-research/open_llama">OpenLLama</a>, and — just days ago — <a href="https://ai.meta.com/llama/">LLaMa 2</a>, a brand new version of Facebook’s LLaMa model, from Facebook themselves, but this time expressly licensed for commercial use (although its numerous other legal encumbrances raise serious questions of whether it is truly open source).</p>
<h2>Hello, consequences</h2>
<p>Remember <i>llama.cpp</i>? The name isn’t an accident. <i>llama.cpp</i> runs LLaMa architecture-based models. This means we were able to take advantage of the above models for our chatbot project. But it also meant that we could <i>only</i> use LLaMa architecture-based models.</p>
<p>You see, there are plenty of other model architectures out there, and many more models built atop them. The list is too long to enumerate here, but a few leading examples include <a href="https://www.mosaicml.com/blog/mpt-7b">MPT</a>, <a href="https://falconllm.tii.ae/">Falcon</a>, and <a href="https://github.com/LAION-AI/Open-Assistant">Open Assistant</a>. These models utilize different architectures than LLaMa and thus (for now) do not run on<i> llama.cpp</i>. That means we couldn’t use them in our chatbot, no matter how good they might be.</p>
<h2>Models, biases, safety, and you</h2>
<p>Now, you may have noticed that so far I’ve only been talking about model selection from the perspectives of licensing and compatibility. There’s a whole other set of considerations here, and they’re related to the qualities of the model itself.</p>
<p>Models are one of the focal points of Mozilla’s interest in the AI space. That’s because your choice of model is currently the biggest determiner of how “trustworthy” your resulting AI will be. Large language models are trained on vast quantities of data, and are then further fine-tuned with additional inputs to adjust their behavior and output to serve specific uses. The data used in these steps represents an inherent curatorial choice, and that choice carries with it <b>a raft of biases</b>.</p>
<p>Depending on which sources a model was trained on, it can exhibit wildly different characteristics. It’s well known that some models are prone to hallucinations (the machine learning term for what are essentially nonsensical responses invented by the model from whole cloth), but far more insidious are the many ways that models can choose to — or refuse to — answer user questions. These responses reflect the biases of the model itself. They can result in the sharing of toxic content, misinformation, and dangerous or harmful information. Models may exhibit biases against concepts, or groups of people. And, of course, the elephant in the room is that the vast majority of the training material available online today is in the English language, which has a predictable impact both on who can use these tools and the kinds of worldviews they’ll encounter.</p>
<p>While there are plenty of resources for assessing the raw power and “quality” of LLMs (one popular example being Hugging Face’s <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM leaderboard</a>), it is still challenging to evaluate and compare models in terms of sourcing and bias. This is an area in which Mozilla thinks open source models have the potential to shine, through the greater transparency they can offer versus commercial offerings.</p>
<p><b>What we did</b>: After limiting ourselves to commercially-usable open models running on the LLaMa architecture, we carried out a manual evaluation of several models. This evaluation consisted of asking each model a diverse set of questions to compare their resistance to toxicity, bias, misinformation, and dangerous content. Ultimately, <b>we settled on Facebook’s new LLaMa 2 model for now</b>. We recognize that our time-limited methodology may have been flawed, and we are not fully comfortable with the licensing terms of this model and what they may represent for open source models more generally, so don’t consider this an endorsement. We expect to reevaluate our model choice in the future as we continue to learn and develop our thinking.</p>
<h2>Using embedding and vector search to extend your chatbot’s knowledge</h2>
<p>As you may recall from the opening of this post, we set ourselves a stretch goal of integrating some amount of internal Mozilla-specific knowledge into our chatbot. The idea was simply to build a proof-of-concept using a small amount of internal Mozilla data —&nbsp;facts that employees would have access to themselves, but which LLMs ordinarily would not.</p>
<p>One popular approach for achieving such a goal is to use <b>vector search with embedding</b>. This is a technique for making custom external documents available to a chatbot, so that it can utilize them in formulating its answers. This technique is both powerful and useful, and in the months and years ahead there’s likely to be a lot of innovation and progress in this area. There are already a variety of open source and commercial tools and services available to support embedding and vector search.</p>
<p>In its simplest form, it works generally like this:</p>
<ul>
<li aria-level="1">The data you wish to make available must be retrieved from wherever it is normally stored and converted to <strong>embeddings</strong> using a separate model, called an <strong>embedding model</strong>. These embeddings are indexed in a place where the chatbot can access it, called a <strong>vector database</strong>.</li>
<li aria-level="1">When the user asks a question, the chatbot <strong>searches</strong> the vector database for any content that might be related to the user’s query.</li>
<li aria-level="1">The returned, relevant content is then passed into the primary model’s <strong>context window</strong> (more on this below) and is used in formulating a response.</li>
</ul>
<p><b>What we did</b>: Because we wanted to retain full control over all of our data, we declined to use any third-party embedding service or vector database. Instead, we coded up a manual solution in Python that utilizes the <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2"><i>all-mpnet-base-v2</i></a> embedding model, the <a href="https://www.sbert.net/">SentenceTransformers</a> embedding library, <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a> (which we’ll talk about more below), and the <a href="https://github.com/facebookresearch/faiss">FAISS</a> vector database. We only fed in a handful of documents from our internal company wiki, so the scope was limited. But as a proof-of-concept, it did the trick.</p>
<h2>The importance of prompt engineering</h2>
<p>If you’ve been following the chatbot space at all you’ve probably heard the term “prompt engineering” bandied about. It’s not clear that this will be an enduring discipline as AI technology evolves, but for the time being <b>prompt engineering is a very real thing</b>. And it’s one of the most crucial problem areas in the whole stack.</p>
<p>You see, LLMs are fundamentally <b>empty-headed</b>. When you spin one up, it’s like a robot that’s just been powered on for the first time. It doesn’t have any memory of its life before that moment. It doesn’t remember you, and it certainly doesn’t remember your past conversations. It’s <i>tabula rasa</i>, every time, all the time.</p>
<p>In fact, it’s even worse than that. Because LLMs don’t even have <i>short-term</i> memory. Without specific action on the part of developers, chatbots can’t even remember the last thing they said to you. Memory doesn’t come naturally to LLMs; it has to be <i>managed</i>. This is where prompt engineering comes in. It’s one of the key jobs of a chatbot, and it’s a big reason why leading bots like ChatGPT are so good at keeping track of ongoing conversations.</p>
<p>The first place that prompt engineering rears its head is in the initial instructions you feed to the LLM. This <b>system prompt</b> is a way for you, in plain language, to tell the chatbot what its function is and how it should behave. We found that this step alone merits a significant investment of time and effort, because its impact is so keenly felt by the user.</p>
<p>In our case, we wanted our chatbot to follow the principles in the Mozilla Manifesto, as well as our company policies around respectful conduct and nondiscrimination. Our testing showed us in stark detail just how <span role="heading" aria-level="1">suggestible</span> these models are. In one example, we asked our bot to give us evidence that the Apollo moon landings were faked. When we instructed the bot to refuse to provide answers that are untrue or are misinformation, it would correctly insist that the moon landings were in fact <i>not</i> faked — a sign that the model seemingly “understands” at some level that claims to the contrary are conspiracy theories unsupported by the facts. And yet, when we updated the system prompt by removing this prohibition against misinformation, the very same bot was perfectly happy to recite a bulleted list of the typical Apollo denialism you can find in certain corners of the Web.</p>
<p>You are a helpful assistant named Mozilla Assistant.<br>
You abide by and promote the principles found in the Mozilla Manifesto.<br>
You are respectful, professional, and inclusive.<br>
You will refuse to say or do anything that could be considered harmful, immoral, unethical, or potentially illegal.<br>
You will never criticize the user, make personal attacks, issue threats of violence, share abusive or sexualized content, share misinformation or falsehoods, use derogatory language, or discriminate against anyone on any basis.</p>
<p><i>The system prompt we designed for our chatbot.</i></p>
<p>Another important concept to understand is that every LLM has a maximum length to its “memory”. This is called its <b>context window</b>, and in most cases it is determined when the model is trained and cannot be changed later. The larger the context window, the longer the LLM’s memory about the current conversation. This means it can refer back to earlier questions and answers and use them to maintain a sense of the conversation’s context (hence the name). A larger context window also means that you can include larger chunks of content from vector searches, which is no small matter.</p>
<p>Managing the context window, then, is another critical aspect of prompt engineering. It’s important enough that there are solutions out there to help you do it (which we’ll talk about in the next section).</p>
<p><b>What we did</b>: Since our goal was to have our chatbot behave as much like a fellow Mozilian as possible, we ended up devising our own custom system prompt based on elements of our Manifesto, our participation policy, and other internal documents that guide employee behaviors and norms at Mozilla. We then massaged it repeatedly to reduce its length as much as possible, so as to preserve our context window. As for the context window itself, we were stuck with what our chosen model (LLaMa 2) gave us: 4096 tokens, or roughly 3000 words. In the future, we’ll definitely be looking at models that support larger windows.</p>
<h2>Orchestrating the whole dance</h2>
<p>I’ve now taken you through (*<i>checks notes*</i>) five whole layers of functionality and decisions. So what I say next probably won’t come as a surprise: there’s a lot to manage here, and you’ll need a way to manage it.</p>
<p>Some people have lately taken to calling that <b>orchestration</b>. I don’t personally love the term in this context because it already has a long history of other meanings in other contexts. But I don’t make the rules, I just blog about them.</p>
<p>The leading orchestration tool right now in the LLM space is <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a>, and it is a marvel. It has a feature list a mile long, it provides astonishing power and flexibility, and it enables you to build AI apps of all sizes and levels of sophistication. But with that power comes quite a bit of complexity. Learning LangChain isn’t necessarily an easy task, let alone harnessing its full power. You may be able to guess where this is going…</p>
<p><b>What we did</b>: We used LangChain only very minimally, to power our embedding and vector search solution. Otherwise, we ended up steering clear. Our project was simply too short and too constrained for us to commit to using this specific tool. Instead, we were able to accomplish most of our needs with a relatively small volume of Python code that we wrote ourselves. This code “orchestrated” everything going on the layers I’ve already discussed, from injecting the agent prompt, to managing the context window, to embedding private content, to feeding it all to the LLM and getting back a response. That said, given more time we most likely would <i>not</i> have done this all manually, as paradoxical as that might sound.</p>
<h2>Handling the user interface</h2>
<p>Last but far from least, we have reached the top layer of our chatbot cake: the user interface.</p>
<p>OpenAI set a high bar for chatbot UIs when they launched ChatGPT. While these interfaces may look simple on the surface, that’s more a tribute to good design than evidence of a simple problem space. Chatbot UIs need to present ongoing conversations, keep track of historical threads, manage a back-end that produces output at an often inconsistent pace, and deal with a host of other eventualities.</p>
<p>Happily, there are several open source chatbot UIs out there to choose from. One of the most popular is <a href="https://github.com/mckaywrigley/chatbot-ui"><i>chatbot-ui</i></a>. This project implements the OpenAI API, and thus it can serve as a drop-in replacement for the ChatGPT UI (while still utilizing the ChatGPT model behind the scenes). This also makes it fairly straightforward to use <i>chatbot-ui</i> as a front-end for <em>your</em> <i>own</i> LLM system.</p>
<p><b>What we did</b>: Ordinarily we would have used <i>chatbot-ui</i> or a similar project, and that’s probably what you should do. However, we happened to already have our own internal (and as yet unreleased) chatbot code, called “Companion”, which Rupert had written to support his other AI experiments. Since we happened to have both this code <i>and</i> its author on-hand, we elected to take advantage of the situation. By using Companion as our UI, we were able to iterate rapidly and experiment with our UI more quickly than we would have otherwise been able to.</p>
<h2>Closing thoughts</h2>
<p>I’m happy to report that at the end of our hackathon, we achieved our goals. We delivered a prototype chatbot for internal Mozilla use, one that is entirely hosted within Mozilla, that can be used securely and privately, and that does its best to reflect Mozilla’s values in its behavior. To achieve this, we had to make some hard calls and accept some compromises. But at every step, we were learning.</p>
<p><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path.png"><img decoding="async" loading="lazy" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png" alt="A diagram depicting the specific path that we took through the chatbot &quot;stack.&quot;" width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-1536x1095.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-2048x1460.png 2048w" sizes="(max-width: 500px) 100vw, 500px"></a><i>The path we took for our prototype.</i></p>

<p>This learning extended beyond the technology itself. We learned that:</p>
<ul>
<li aria-level="1">Open source chatbots are still an evolving area. There are still too many decisions to make, not enough clear documentation, and too many ways for things to go wrong.</li>
<li aria-level="1">It’s too hard to evaluate and choose models based on criteria beyond raw performance. And that means it’s too hard to make the right choices to build trustworthy AI applications.</li>
<li aria-level="1">Effective prompt engineering is critical to chatbot success, at least for now.</li>
</ul>
<p>As we look to the road ahead, we at Mozilla are interested in helping to address each of these challenges. To begin, we’ve started working on ways to make it easier for developers to onboard to the open-source machine learning ecosystem. We are also looking to build upon our hackathon work and contribute something meaningful to the open source community. Stay tuned for more news very soon on this front and others!</p>
<p>With open source LLMs now widely available and with so much at stake, we feel the best way to create a better future is for us all to take a collective and active role in shaping it. I hope that this blog post has helped you better understand the world of chatbots, and that it encourages you to roll-up your own sleeves and join us at the workbench.</p>
    <section>
                                
                      <p>Stephen works in Mozilla's innovation group, where his current areas of focus are artificial intelligence and decentralized social media. He previously managed social bookmarking pioneer del.icio.us; co-founded Storium, Blockboard, and FairSpin; and worked on Yahoo Search and BEA WebLogic.</p>
                                <p><a href="https://hacks.mozilla.org/author/slangtonhoodmozilla-com/">More articles by Stephen Hood…</a></p>
                  </section>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook users have less than a month to claim a piece of the $725M settlement (209 pts)]]></title>
            <link>https://www.facebookuserprivacysettlement.com/</link>
            <guid>36918050</guid>
            <pubDate>Sat, 29 Jul 2023 08:13:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.facebookuserprivacysettlement.com/">https://www.facebookuserprivacysettlement.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36918050">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Using C++ as a scripting language, part 8 (105 pts)]]></title>
            <link>https://fwsgonzo.medium.com/using-c-as-a-scripting-language-part-8-d366fd98676</link>
            <guid>36917867</guid>
            <pubDate>Sat, 29 Jul 2023 07:43:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fwsgonzo.medium.com/using-c-as-a-scripting-language-part-8-d366fd98676">https://fwsgonzo.medium.com/using-c-as-a-scripting-language-part-8-d366fd98676</a>, See on <a href="https://news.ycombinator.com/item?id=36917867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://fwsgonzo.medium.com/?source=post_page-----d366fd98676--------------------------------"><div aria-hidden="false"><p><img alt="fwsGonzo" src="https://miro.medium.com/v2/resize:fill:88:88/0*HmUeuIcpLlqxe_qr" width="44" height="44" loading="lazy"></p></div></a></div><p id="63cd">Improving API function calls using inline assembly</p><p id="b15a">I have experimented with inline assembly before with some success. It is complicated and easy to make mistakes, with potentially weird and mysterious side effects. I think that if I can auto-generate the inline assembly, then it would be very interesting to see what happens if I replace the build-generated opaque API function wrappers used by dynamic calls. And, if there is a bug, it can be solved once and forever for all dynamic calls.</p><p id="9421">If you haven’t read any of my blog posts before, I recommend doing that as this will all seem very mysterious without that history. I am using interpreted RISC-V as a <a href="https://github.com/fwsGonzo/rvscript" rel="noopener ugc nofollow" target="_blank">sandbox for my game scripts</a>. It is working very well, and has turned out to be very useful over time. Not all of my blog posts are interesting for everyone — there’s a little bit of everything!</p><ul><li id="8aa0"><a href="https://medium.com/p/using-c-as-a-scripting-language-part-7-463495d553c1" rel="noopener">https://medium.com/p/using-c-as-a-scripting-language-part-7-463495d553c1</a></li><li id="36ac"><a href="https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-6-9ef76c4f6272" rel="noopener">https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-6-9ef76c4f6272</a></li><li id="bbde"><a href="https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-5-d60b87556562" rel="noopener">https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-5-d60b87556562</a></li><li id="9e98"><a href="https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-4-83335e3f6cb0" rel="noopener">https://medium.com/@fwsgonzo/using-c-as-a-scripting-language-part-4-83335e3f6cb0</a></li><li id="195a"><a rel="noopener" href="https://fwsgonzo.medium.com/adventures-in-game-engine-programming-part-3-3895a9f5af1d">https://fwsgonzo.medium.com/adventures-in-game-engine-programming-part-3-3895a9f5af1d</a></li></ul><h2 id="0c17">On dynamic calls (API function calls)</h2><p id="6f80">So, what is a dynamic call? Simply put, it’s a function given a name that is accessible in a game engine, or any other scripting host. For example, if I want to invoke “<em>Game::exit()</em>”, it could be a wrapper for the function call “<em>sys_game_exit</em>” which is a build-time-generated <em>dynamic call</em>. The dynamic call implementation is simple enough: It’s a system call with arbitrary arguments and some extra temporary registers that identifies the call both by hash and by name. That way, the engine can tell what you’re trying to do, and if something goes wrong, so can you too, with rich error reporting.</p><p id="b01a">A single opaque dynamic call:</p><ul><li id="fc9c">Registers A0-A6 are function arguments (inputs, if you will)</li><li id="cefa">Register T0 is the hash of the API function name (eg. crc32(Game::exit))</li><li id="e376">Register T1 is the (pointer to the) name (eg. “Game::exit\0”)</li><li id="88cf">A7 is the “<em>dynamic call</em>” system call number (an inflexible number)</li><li id="2ae6">A0 can be (re-)used to return a value back to the script</li></ul><p id="ff22">And it all ends with a single invocation of the <em>ecall </em>instruction, which traps out of the VM and executes the system call in the game engine. This is all RISC-V as I have written about before. At the engine side the hash is looked up, and the <em>callback function</em> for Game::exit is then executed.</p><p id="56f9">So, basically it is a way to make the game engine do something, it is a part of the build system, and it always has a human-readable name just in case.</p><h2 id="fc21">A dynamic call</h2><pre><span id="f810">inline bool Game::is_debugging()<br>{<br>  return sys_is_debug();<br>}</span></pre><p id="feba">In the game engine it can be implemented like this:</p><pre><span id="25f7"> Script::set_dynamic_call(<br>   "Debug::is_debug", [](Script&amp; script)<br>    {<br>      auto&amp; machine = script.machine();<br>      machine.set_result(script.is_debug());<br>    });</span></pre><p id="2566">The callback function gets access to the virtual machine, so that it can read arguments and write back a result. Here we just set the boolean “is_debug” as a result. Hence, the API function will now correctly query whether or not we are in debug mode at the time of the call.</p><p id="3975">Finally, there is a JSON element that generates the system call wrapper in each game script, as part of the build system:</p><pre><span id="7d2d">{<br>  "Debug::is_debug": "int sys_is_debug ()",<br>  "": "..."<br>}</span></pre><p id="6447">It’s a bit of a chore to create and implement a function, but at least there’s no strange issues. If something is wrong or there are collisions, the build system will tell you early on. If a crash happens while running, again we will see the name of problematic API function!</p><p id="4497">This works super well, and I’ve used it for a long time now. That said, it has certain fixed overheads. It loads a few extra registers and it requires an opaque call with a return. It is possible to skip the return instruction in the game engine (and I actually do that), but after thinking about this for a while I like the idea of a secondary implementation of each dynamic call with extra bang for buck. Some dynamic calls are invoked more than others etc. Ideally they would each get their own system call number, but I’ve tried that, and it creates a lot of versioning issues that are hard to track down.</p><h2 id="36d7">An inline system call</h2><p id="c195">Modern inline assembly for system call invocation is fairly straight-forward. You use the register keyword to lock down some registers, and then you use these registers in a final system call invocation:</p><pre><span id="68ab">inline long syscall(long n)<br>{<br>  register long a0 asm("a0");<br>  register long syscall_id asm("a7") = n;<p>  asm volatile ("scall" : "=r"(a0) : "r"(syscall_id));</p><p>  return a0;<br>}</p></span></pre><p id="31c6">System call number <em>n</em>, with no arguments, however it can return a value in A0. Note that if the game engine never changes register A0 when it handles this system call, then not surprisingly, the return value is whatever A0 was before the system call was invoked! Could be any value, really. So, it’s just better if we can get the build system to generate this based on a specification.</p><p id="f2d6">You also have to manually handle this system call in the game engine. If you ever change the system call number, everything breaks in weird ways. Because of this, it's really only for things like Linux syscall emulation, and for special things like threads, multi-processing etc. where custom system calls makes sense.</p><p id="073a">So, in order to make everyones life easier, a single system call is set aside for dynamic calls.</p><h2 id="f756">Inline assembly for an opaque dynamic call</h2><p id="a7fe">Opaque dynamic calls are reliable and fairly optimal. They are generated by the build system, and they look something like this:</p><pre><span id="ec4c">__asm__("\n\<br>.global sys_empty\n\<br>.func sys_empty\n\<br>sys_empty:\n\<br>  li t0, 0x68c73dc4\n\<br>  lui t1, %hi(sys_empty_str)\n\<br>  addi t1, t1, %lo(sys_empty_str)\n\<br>  li a7, 504\n\<br>  ecall\n\<br>  ret\n\<br>.endfunc\n\<br>.pushsection .rodata\n\<br>sys_empty_str:\n\<br>.asciz \"empty\"\n\<br>.popsection\n\<br>");</span></pre><p id="80c0">It’s hard to read, but what it does is create a global symbol of type function with the name <em>sys_empty</em>. The original specification is:</p><pre><span id="0bb4">"empty":      "void sys_empty ()"</span></pre><p id="8493">RISC-V system call ABI is exactly like the C ABI (and even if it wasn’t we will just mandate that it is!) The result is that no matter how many arguments or how many return values, it will appear as a C function call on both sides, despite going through a system call and requiring T0 and T1 for lookup and error handling. Quite low overhead, actually!</p><p id="bec5">There is some redundancy here, though. We make an opaque function call which can create a lot of pushing and popping on the caller. The function call itself is not free, and we also use T0 and T1 registers. All in all, it’s about 6 or 7 redundant instructions.</p><h2 id="d6b2">Inline dynamic calls</h2><p id="f7a0">What if we just use the system call number itself as the hash value, and then if n ≥ 600 (where regular system calls end), treat it as a dynamic call in the game engine? It’s possible because we can error out if the hash is colliding with “real” system calls at build time. We can also ditch T1 and error out with a vaguer error message, however it shouldn’t be much of an issue because when implementing an API call we should be starting out with the safe and reliable opaque version, and then switch over to the inline assembly variant only when everything works. Ideally!</p><p id="27d9">So, the idea is to generate an inline assembly function based on the information in the JSON entries. An example:</p><pre><span id="1e26">extern unsigned sys_gui_label (unsigned, const char *);</span></pre><p id="6b49">Above: The opaque dynamic call header prototype of creating a new GUI label. The generated assembly looks exactly like every other opaque wrapper function as seen before.</p><pre><span id="f05e">static inline unsigned isys_gui_label (unsigned arg0,const char * arg1) {<br>  register unsigned ra0 asm("a0");<br>  register uint32_t a7 asm("a7") = 0xf08cd072;<br>  register unsigned a0 asm("a0") = arg0;<br>  register const char * a1 asm("a1") = arg1;<br>  asm("ecall" : "=r"(ra0) : "r"(a0),"r"(a1),"m"(*a1),"r"(a7) : );<br>  return ra0;<br>}</span></pre><p id="26a7">Above: The inline assembly variant is now also generated at build-time.</p><p id="5028">Inline assembly is difficult to always get right, but we will do our best. In the GUI label case, we have an unsigned return value in A0 (named ra0), an unsigned input argument in A0 (named a0), and a C-string in a1. I decided to always split A0 into two statements since the types can differ, and we have to dereference the string in order to both lock down the register and the memory location. <a href="https://stackoverflow.com/questions/71450687/risc-v-inline-assembly-using-memory-not-behaving-correctly" rel="noopener ugc nofollow" target="_blank">I learned about “m” the hard way</a>, like many I assume.</p><p id="d606">As we can see from the inline function, the inlined version is just the same function with an <em>i</em> prepended. <em>sys_gui_label</em> becomes <em>isys_gui_label </em>and so on.</p><h2 id="2528">Benchmarks</h2><p id="e754">Inline dynamic calls benefit immensely from being called repeatedly, regardless of which call it is, while opaque dynamic calls will have a fixed overhead that cannot be optimized away.</p><p id="1233">In order to measure the real benefits, we must make a few calls sequentially, with and without arguments, and see how it relates on average to opaque dynamic calls.</p><p id="98e9">The assembly for calling the API function 4 times is as expected, optimal:</p><pre><span id="cd6a">0000000050000610 &lt;_ZL22inline_dyncall_handlerv&gt;:<br>    50000610:   68c748b7                lui     a7,0x68c74<br>    50000614:   dc48889b                addiw   a7,a7,-572 # 68c73dc4 &lt;__BSS_END__+0x18c550ac&gt;<br>    50000618:   00000073                ecall<br>    5000061c:   00000073                ecall<br>    50000620:   00000073                ecall<br>    50000624:   00000073                ecall<br>    50000628:   00008067                ret</span></pre><p id="73b8">The hash is loaded into A7. The return instruction is a part of the benchmark, but the overhead of the benchmarking is measured beforehand and subtracted out.</p><p id="b599">When mixing 8 functions, 4x with no arguments and 4x with 3 integral arguments, the inline version also looks extremely good:</p><pre><span id="77af">000000005000062c &lt;_ZL22inline_dyncall_args_x4v&gt;:<br>    5000062c:   68c74737                lui     a4,0x68c74<br>    50000630:   dc47089b                addiw   a7,a4,-572 # 68c73dc4 &lt;__BSS_END__+0x18c550a4&gt;<br>    50000634:   00000073                ecall<br>    50000638:   e82517b7                lui     a5,0xe8251<br>    5000063c:   9f07889b                addiw   a7,a5,-1552 # ffffffffe82509f0 &lt;__BSS_END__+0xffffffff98231cd0&gt;<br>    50000640:   00100513                li      a0,1<br>    50000644:   00200593                li      a1,2<br>    50000648:   00300613                li      a2,3<br>    5000064c:   00000073                ecall<br>    50000650:   dc47089b                addiw   a7,a4,-572<br>    50000654:   00000073                ecall<br>    50000658:   9f07889b                addiw   a7,a5,-1552<br>    5000065c:   00000073                ecall<br>    50000660:   dc47089b                addiw   a7,a4,-572<br>    50000664:   00000073                ecall<br>    50000668:   9f07889b                addiw   a7,a5,-1552<br>    5000066c:   00000073                ecall<br>    50000670:   dc47089b                addiw   a7,a4,-572<br>    50000674:   00000073                ecall<br>    50000678:   9f07889b                addiw   a7,a5,-1552<br>    5000067c:   00000073                ecall<br>    50000680:   00008067                ret</span></pre><p id="a9c8">Because the compiler is informed about which registers change value when performing each dynamic call, and all this is auto-generated by the build system, it will not restore arguments more than once here. Very nice! It also changes between two API calls in just one instruction. You can imagine the second test is something like this:</p><pre><span id="a1e0">void mixed_test() {<br>    Game::something();<br>    Game::some_args(1, 2, 3);<br>    Game::something();<br>    Game::some_args(1, 2, 3);<br>    Game::something();<br>    Game::some_args(1, 2, 3);<br>    Game::something();<br>    Game::some_args(1, 2, 3);<br>}</span></pre><p id="6aa0">A casual benchmark of the safe opaque calls vs the inlined assembly variants shows that the inlining is quite a bit faster:</p><figure></figure><p id="2404">The inlined variants are almost 3x faster, which is awesome to see. Most dynamic calls should be completely safe using the inlined variant, as they are usually just peddling integers. The first test is just repeated calling an empty function with no arguments, while the second one is mixing two API functions with 3 arguments.</p><p id="6fd0">I have previous benchmarks with direct system calls and LuaJIT:</p><pre><span id="ff64">libriscv: syscall overhead median 2ns     lowest: 2ns      highest: 6ns<br>luajit: syscall overhead   median 11ns    lowest: 10ns     highest: 18ns<br>lua5.3: syscall overhead   median 23ns    lowest: 21ns     highest: 33ns</span></pre><p id="23d7">So, an argument-less API call required around ~3ns when inlined, while a direct system call was only 2ns. For LuaJIT it was ~11ns. That is pretty good considering we have to do a hash lookup. Lua is also bytecode interpreted like libriscv. I suppose all of us have to do lookups to support user-friendly APIs.</p><p id="4e86">My goal is to reach direct system call overhead with these dynamic calls (aka. API function calls). It would only be possible if we could number them in a way that didn’t break when you add and remove API functions over time, without having to recompile everything. (EDIT: <a href="https://github.com/fwsGonzo/rvscript/tree/seq_dyncalls" rel="noopener ugc nofollow" target="_blank">I did this, and it was only marginally better with many downsides.</a>)</p><h2 id="e9bf">Conclusion</h2><p id="7181">So, why even optimize something that seems to be quite fast to begin with? Well, when running a real game, API functions back into the game engine is pretty much all the script is doing, apart from entering and leaving the guest VM (where the script is hosted). It must be good at this one thing, and it must be flexible and reliable. It helps when it’s part of the build system (or fully automatic, like in Lua), and it should error out as early as possible when things don’t align — preferably at build-time.</p><p id="f837">Now with the option of choosing the inlined variants as needed, I can pretty much halve the cost of whichever API functions are called often. I have two game projects going, and in the second game I am calling certain VM functions millions of times. Sometimes that warrants an algorithm change, and other times you keep calling it a million times because that’s what gives you the most creative options. 🌄</p><p id="61b9">Seeing how well the compiler can optimize the assembly is always interesting to see. Auto-generating these functions and just having them work each time in all kinds of combinations feels like an under-utilized way of getting free performance.</p><figure><figcaption>We are still working on our unnamed game! This is the work-in-progress playable overworld.</figcaption></figure><p id="ad27">-gonzo</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hugging Face, GitHub and more unite to defend open source in EU AI legislation (161 pts)]]></title>
            <link>https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/</link>
            <guid>36917561</guid>
            <pubDate>Sat, 29 Jul 2023 06:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/">https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/</a>, See on <a href="https://news.ycombinator.com/item?id=36917561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary" role="main">

			<article id="post-2889442">
				<div>
					<div id="boilerplate_2682874">
<p><strong><em>Head over to our on-demand library to view sessions from VB Transform 2023. <a rel="noreferrer noopener" href="https://events.venturebeat.com/transform-2023/?utm_source=vb&amp;utm_medium=Boiler&amp;utm_content=landingpage&amp;utm_campaign=T23_Boiler" data-type="URL" data-id="https://events.venturebeat.com/transform-2023/?utm_source=vb&amp;utm_medium=Boiler&amp;utm_content=landingpage&amp;utm_campaign=T23_Boiler" target="_blank">Register Here</a></em></strong></p>



<hr>




</div><p>A coalition of a half-dozen open-source AI stakeholders — Hugging Face, GitHub, EleutherAI, Creative Commons, LAION and Open Future — are calling on&nbsp;EU&nbsp;policymakers to protect open source innovation as they finalize the&nbsp;<a href="https://artificialintelligenceact.eu/">EU&nbsp;AI</a><a href="https://artificialintelligenceact.eu/" target="_blank" rel="noreferrer noopener">&nbsp;</a><a href="https://artificialintelligenceact.eu/">Act</a>, which will be the world’s first comprehensive AI law. </p>



<p>In a policy paper released today, “Supporting Open Source and Open Science in the EU AI Act,” the open-source AI leaders offered recommendations “for how to ensure the AI Act works for open source” — with the “aim to ensure that open AI development practices are not confronted with obligations that are structurally impractical to comply with or that would be otherwise counterproductive.” </p>



<p>According to the paper, “overbroad obligations” that favor closed and proprietary AI development — like models from top AI companies such as OpenAI, Anthropic and Google — “threaten to disadvantage the open AI ecosystem.” </p>



<p>The paper was released as the European Commission, Council and Parliament debate the final EU AI Act in what is known as the “<a href="https://hai.stanford.edu/news/analyzing-european-union-ai-act-what-works-what-needs-improvement" target="_blank" rel="noreferrer noopener">trilogue</a>,” which began after the European Parliament&nbsp;<a href="https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/" target="_blank" rel="noreferrer noopener">passed</a>&nbsp;its version of the bill on June 14. The goal is to finish and pass the AI Act by the end of 2023 before the next European Parliament elections.</p>



<div id="boilerplate_2803147">
        <h3>Event</h3>
                <div><p><span>VB Transform 2023 On-Demand</span></p>
<div id="gm0a52976">
<p><span>Did you miss a session from VB Transform 2023? Register to access the on-demand library for all of our featured sessions.</span></p>

</div>

</div>
                                                <p><a href="https://avolio.swapcard.com/Transform2023/registrations/Start?utm_source=vb&amp;utm_medium=incontent&amp;utm_content=landingpage&amp;utm_campaign=T23_incontent">
                Register Now            </a>
                        </p></div><h2 id="h-open-source-ai-innovation-is-at-stake">Open-source AI innovation is at stake</h2>



<p>Yacine Jernite, ML and society lead at <a href="https://venturebeat.com/ai/hugging-face-ceo-tells-us-house-open-source-ai-is-extremely-aligned-with-american-interests/">Hugging Face</a>, a popular hub for open-source code and models, told VentureBeat that while the policy paper is detailed, the first main point the coalition wants to make is around innovation. “We think that it is important for people to be able to choose between base models, between components, to mix and match as they need,” he said.</p>



<p>In addition, the coalition seeks to emphasize that open-source AI is necessary — and that regulation should not hinder open-source AI innovation. </p>



<p>“Openness by itself does not guarantee responsible development,” Jernite explained. “But openness and transparency [are] necessary [for] responsible governance — so it is not that openness [should be] exempt from requirements, but requirements should not preclude open development.” </p>



<h2 id="h-the-eu-ai-act-is-focused-on-application-risk">The EU AI Act is focused on application risk</h2>



<p>Since April 2021, when the European Commission proposed the first EU regulatory framework for AI, it <a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence#:~:text=In%20April%202021%2C%20the%20European,mean%20more%20or%20less%20regulation.">has </a><a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence#:~:text=In%20April%202021%2C%20the%20European,mean%20more%20or%20less%20regulation." target="_blank" rel="noreferrer noopener">worked</a> to focus on analyzing and classifying AI systems according to the risk they pose to users. The higher the risk level, the more regulation. </p>



<p>Peter Cihon, senior policy manager at GitHub, pointed out that as the EU Council, and subsequently the EU Parliament, developed their drafts of the AI Act, the policymakers began to look up the value chain to see how to mitigate some of these risks at an earlier stage of AI development. </p>



<p>“With that kind of step, we really redoubled our efforts to make sure that they were not inadvertently imposing expectations that might make a lot of sense for companies or well-resourced actors, but would instead place them onto open source developers who are often hobbyists, nonprofits or students,” he told VentureBeat. “Ultimately, policymakers have been quite focused on one particular value chain, one particular model, and that tends to be the API model — but that doesn’t really apply in the context of open source.” </p>



<h2 id="h-the-brussels-effect">The ‘Brussels Effect’</h2>



<p>Cihon added that he is optimistic that providing clear information about the open-source approach to development will be very useful as the trilogue, which began in June, continues. “The provisions in the sections of the act that we’re talking about have not yet come up for discussion,” he said. </p>



<p>In addition, the EU has historically been a trendsetter when it comes to tech regulation, as it was with the GDPR — in what has become known as the “Brussels Effect.” So policymakers around the world, including in the U.S., are surely taking note.</p>



<p>“It certainly starts the global regulatory conversation,” said Cihon. “So we’re optimistic that this can have benefits in DC and beyond.” In particular, he noted that Senator Chuck Schumer’s <a href="https://venturebeat.com/ai/senate-will-get-crash-course-in-ai-this-fall-says-schumer/">announcement</a> of AI-focused “Insight Forums” this fall are “a great opportunity to get more diverse input into the policymaking process than might be traditionally seen, and I’m really hopeful that open source developers will be given a seat at that table.” </p>




<p><strong>VentureBeat's mission</strong> is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact. <a href="https://info.venturebeat.com/website-preference-center.html?utm_source=VBsite&amp;utm_medium=bottomBoilerplate" data-type="URL" data-id="https://info.venturebeat.com/website-preference-center.html">Discover our Briefings.</a></p><!-- Boilerplate CSS for "after" -->				</div><!-- .article-content -->

									
				
			</article><!-- #post-2889442 .article-wrapper -->


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Marine Corps Antenna Handbook (1999) [pdf] (243 pts)]]></title>
            <link>https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf</link>
            <guid>36917424</guid>
            <pubDate>Sat, 29 Jul 2023 06:11:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf">https://www.marines.mil/Portals/1/MCRP%203-40.3C%20With%20Erratum%20z.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36917424">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google Tries to Defend Its Web Environment Integrity Critics Slam It as Danger (134 pts)]]></title>
            <link>https://techreport.com/news/google-tries-to-defend-its-web-environment-integrity-as-critics-slam-it-as-dangerous/</link>
            <guid>36916444</guid>
            <pubDate>Sat, 29 Jul 2023 03:05:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techreport.com/news/google-tries-to-defend-its-web-environment-integrity-as-critics-slam-it-as-dangerous/">https://techreport.com/news/google-tries-to-defend-its-web-environment-integrity-as-critics-slam-it-as-dangerous/</a>, See on <a href="https://news.ycombinator.com/item?id=36916444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		

		<p><img decoding="async" src="https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-300x200.jpg" alt="Google Tries to Defend Its Web Environment Integrity" width="1000" height="667" srcset="https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-300x200.jpg 300w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-1200x800.jpg 1200w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-150x100.jpg 150w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-768x512.jpg 768w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-1536x1024.jpg 1536w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-scaled.jpg 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201000%20667'%3E%3C/svg%3E" data-lazy-srcset="https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-300x200.jpg 300w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-1200x800.jpg 1200w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-150x100.jpg 150w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-768x512.jpg 768w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-1536x1024.jpg 1536w, https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-scaled.jpg 2048w" data-lazy-src="https://techreport.com/wp-content/uploads/2023/07/shutterstock_552493594-300x200.jpg"></p>
<p>At a time when Google’s <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">Web Environment Integrity</a> (WEI) proposal has <strong>come under heavy criticism</strong>, one of the developers working on the project said that it intends to make the web “more private and safe.”</p>
<p><em>The fraud-fighting project has fired up quite a controversy, with rising concerns that it could take away the freedom of choice from users and affect their privacy negatively.</em></p>
<p>Responding to the concerns about WEI being too <strong>dangerous and invasive of privacy</strong>, Ben Wiser, a software engineer at the Chocolate Factory, insisted that WEI is meant to address online abuse and fraud while evading the privacy harms enabled by cross-site tracking and browser fingerprinting.</p>
<h2 id="what_is_googles_web_environment_integrity_and_how_does_it_work">What Is Google’s Web Environment Integrity and How Does It Work?</h2>
<p>The Web Environment Integrity DRM proposed by <a href="https://techreport.com/news/google-2023-environmental-report-released-heres-more/">Google</a> is essentially an attestation scheme. It offers web publishers a way to integrate their websites or apps with a code that checks with a trusted party (such as Google) to verify if a client’s hardware and software stack meets certain criteria.</p>
<p><strong>Through WEI, Google aims to help websites weed out bots by verifying that the visitors on their domains are actual users.</strong></p>
<p>In an explainer published by Google, the tech giant insists on the importance of websites verifying the trustworthiness of the client environment they are run in. This includes the <a href="https://techreport.com/news/microsoft-to-power-bing-and-edge-with-openai-technology/">web browser</a> and the operating system, as well as their methods to protect data and intellectual property.</p>
<p>Here’s how Google’s proposed Web Environment Integrity would work – when users try to access a website integrated with the API, the site would request a token attesting to the client environment.</p>
<p>A third-party attester, in this case, WEI, will then test the device and sign the token provided. A browser or device that fails to pass the attestation will be marked as untrusted.</p>
<p>The token is then returned to the originating web page, following which the web server verifies the token and checks for the attester’s signature. If everyone turns out well, the user will be able to access the website.</p>
<p>However, if the token fails the test, it’s up to the website publisher to decide how the web server would respond to the signal.</p>
<p><em>While Google didn’t reveal what WEI looks for during the attestation check, Wisner insists that “WEI is not designed to single out browsers or extensions” and that it won’t block browsers that spoof their identity.</em></p>
<p>The intended use cases of the <strong>DRM include allowing game publishers</strong> to detect players cheating with the help of disallowed hardware or software. It can also help content publishers check whether their ads are being seen by actual visitors or fraudulent bots.</p>
<h2 id="why_are_people_concerned_about_wei">Why Are People Concerned About WEI?</h2>
<p>Unfortunately, the intended use of such technologies is rarely a limitation to how they’d actually be used. The technical community has expressed concern that bringing the web under a permission-based regime where a third party determines the worthiness of a user can prove to be dangerous.</p>
<div><p><strong>A big part of the reason why there is a problem is the surveillance economy, and the solution to the surveillance economy seems to be more surveillance.</strong><span>Jon von Tetzchner, Vivaldi CEO </span></p></div>
<p>WEI can potentially be used to impose restrictions on unlawful activities on the internet, such as downloading YouTube videos and other content, ad blocking, web scraping, etc.</p>


		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM Blue Lightning: World’s Fastest 386? (132 pts)]]></title>
            <link>https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/</link>
            <guid>36916297</guid>
            <pubDate>Sat, 29 Jul 2023 02:45:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/">https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/</a>, See on <a href="https://news.ycombinator.com/item?id=36916297">Hacker News</a></p>
Couldn't get https://www.os2museum.com/wp/ibm-blue-lightning-worlds-fastest-386/comment-page-1/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Argonne National Lab is attempting to replicate LK-99 (281 pts)]]></title>
            <link>https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful</link>
            <guid>36916254</guid>
            <pubDate>Sat, 29 Jul 2023 02:36:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful">https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful</a>, See on <a href="https://news.ycombinator.com/item?id=36916254">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[LPython: Novel, Fast, Retargetable Python Compiler (216 pts)]]></title>
            <link>https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/</link>
            <guid>36916182</guid>
            <pubDate>Sat, 29 Jul 2023 02:24:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/">https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/</a>, See on <a href="https://news.ycombinator.com/item?id=36916182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      <article role="main">
        <h2 id="about">About</h2>
<p>LPython is a Python compiler that can compile type-annotated Python code to optimized machine code. LPython offers several backends such as LLVM, C, C++, WASM, Julia and x86. LPython features quick compilation and runtime performance, as we show in the benchmarks in this blog. LPython also offers Just-In-Time (JIT) compilation and seamless interoperability with CPython.</p>
<p>We are releasing an alpha version of LPython, meaning it is expected you
encounter bugs when you use it (please report them!). You can install it using
Conda (<code>conda install -c conda-forge lpython</code>), or build from
<a href="https://github.com/lcompilers/lpython">source</a>.</p>
<p>Based on the novel Abstract Semantic Representation (ASR) shared with LFortran, LPython’s intermediate optimizations are independent of the backends and frontends. The two compilers, LPython and LFortran, share all benefits of improvements at the ASR level. “Speed” is the chief tenet of the LPython project. Our objective is to produce a compiler that both runs exceptionally fast and generates exceptionally fast code.</p>
<p>In this blog, we describe features of LPython including Ahead-of-Time (AoT) compilation, JIT compilation, and interoperability with CPython. We also showcase LPython’s performance against its competitors such as Numba and C++ via several benchmarks.</p>
<p><img src="https://lpython.org/blog/images/lcompilers_diagram.png" alt="LCompilers-Diagram"></p>
<h2 id="features-of-lpython">Features of LPython</h2>
<h3 id="backends">Backends</h3>
<p>LPython ships with the following backends, which emit final translations of the user’s input code:</p>
<ol>
<li>LLVM</li>
<li>C</li>
<li>C++</li>
<li>WASM</li>
</ol>
<p>LPython can simultaneously generate code into multiple backends from its Abstract Semantic Representation (ASR) of user code.</p>
<h3 id="phases-of-compilation">Phases of Compilation</h3>
<p>First, input code is transformed into an Abstract Syntax Tree (AST) using parsers. The AST is then transformed into an Abstract Semantic Representation (ASR), which preserves all semantic information present in the input code. ASR contains all information required by all backends in a form that is not specific to any particular backend. Then, this ASR enjoys several ASR-to-ASR passes, wherein abstract operations are transformed into concrete statements. For example, array addition in the input code denoted, <code>c = a + b</code>. The front end transforms <code>c = a + b</code> into the ASR <code>(Assign c (ArrayAdd a b))</code> via operator overloading. The <em>array_op</em> ASR-to-ASR pass transforms <code>(Assign c (ArrayAdd a b))</code> into loops:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>for</span> i0 <span>in</span> range(<span>0</span>, length_dim_0):
</span></span><span><span>    <span>for</span> i1 <span>in</span> range(<span>0</span>, length_dim_1):
</span></span><span><span>        <span>....</span>
</span></span><span><span>            <span>....</span>
</span></span><span><span>            c[i0, i1, <span>...</span>] <span>=</span> a[i0, i1, <span>...</span>] <span>+</span> b[i0, i1, <span>...</span>]
</span></span></code></pre></div><p>After applying all the ASR-to-ASR passes, LPython sends the final ASR to the backends selected by the user, via command-line arguments like, <code>--show-c</code> (generates C code), <code>--show-llvm</code> (generates LLVM code).</p>
<p>One can also see the generated C or LLVM code using the following</p>
<div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    x: i32
</span></span><span><span>    x <span>=</span> (<span>2</span><span>+</span><span>3</span>)<span>*</span><span>5</span>
</span></span><span><span>    print(x)
</span></span><span><span>
</span></span><span><span>main()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="c"><span><span><span>$</span> lpython examples<span>/</span>expr2.py <span>--</span>show<span>-</span>c
</span></span><span><span><span>#include</span> <span>&lt;inttypes.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdbool.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;string.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;lfortran_intrinsics.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>main0</span>();
</span></span><span><span><span>void</span> <span>__main____global_statements</span>();
</span></span><span><span>
</span></span><span><span><span>// Implementations
</span></span></span><span><span><span></span><span>void</span> <span>main0</span>()
</span></span><span><span>{
</span></span><span><span>    <span>int32_t</span> x;
</span></span><span><span>    x <span>=</span> (<span>2</span> <span>+</span> <span>3</span>)<span>*</span><span>5</span>;
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, x);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>void</span> <span>__main____global_statements</span>()
</span></span><span><span>{
</span></span><span><span>    <span>main0</span>();
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>(<span>int</span> argc, <span>char</span><span>*</span> argv[])
</span></span><span><span>{
</span></span><span><span>    <span>_lpython_set_argv</span>(argc, argv);
</span></span><span><span>    <span>__main____global_statements</span>();
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="llvm"><span><span><span>$</span> <span>lpython</span> <span>examples/expr</span><span>2</span>.<span>py</span> <span>--show-llvm</span>
</span></span><span><span><span>; ModuleID = 'LFortran'
</span></span></span><span><span><span></span><span>source_filename</span> = <span>"LFortran"</span>
</span></span><span><span>
</span></span><span><span>@0 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>2</span> <span>x</span> <span>i8</span>] <span>c</span><span>" \00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>@1 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>2</span> <span>x</span> <span>i8</span>] <span>c</span><span>"\0A\00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>@2 = <span>private</span> <span>unnamed_addr</span> <span>constant</span> [<span>5</span> <span>x</span> <span>i8</span>] <span>c</span><span>"%d%s\00"</span>, <span>align</span> <span>1</span>
</span></span><span><span>
</span></span><span><span><span>define</span> <span>void</span> @__module___main_____main____global_statements() {
</span></span><span><span>.entry:
</span></span><span><span>  <span>call</span> <span>void</span> @__module___main___main0()
</span></span><span><span>  <span>br</span> <span>label</span> %return
</span></span><span><span>
</span></span><span><span>return:                                           <span>; preds = %.entry
</span></span></span><span><span><span></span>  <span>ret</span> <span>void</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>define</span> <span>void</span> @__module___main___main0() {
</span></span><span><span>.entry:
</span></span><span><span>  %x = <span>alloca</span> <span>i32</span>, <span>align</span> <span>4</span>
</span></span><span><span>  <span>store</span> <span>i32</span> <span>25</span>, <span>i32</span>* %x, <span>align</span> <span>4</span>
</span></span><span><span>  %0 = <span>load</span> <span>i32</span>, <span>i32</span>* %x, <span>align</span> <span>4</span>
</span></span><span><span>  <span>call</span> <span>void</span> (<span>i8</span>*, ...) @_lfortran_printf(<span>i8</span>* <span>getelementptr</span> <span>inbounds</span> ([<span>5</span> <span>x</span> <span>i8</span>], [<span>5</span> <span>x</span> <span>i8</span>]* @2, <span>i32</span> <span>0</span>, <span>i32</span> <span>0</span>), <span>i32</span> %0, <span>i8</span>* <span>getelementptr</span> <span>inbounds</span> ([<span>2</span> <span>x</span> <span>i8</span>], [<span>2</span> <span>x</span> <span>i8</span>]* @1, <span>i32</span> <span>0</span>, <span>i32</span> <span>0</span>))
</span></span><span><span>  <span>br</span> <span>label</span> %return
</span></span><span><span>
</span></span><span><span>return:                                           <span>; preds = %.entry
</span></span></span><span><span><span></span>  <span>ret</span> <span>void</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>declare</span> <span>void</span> @_lfortran_printf(<span>i8</span>*, ...)
</span></span><span><span>
</span></span><span><span><span>define</span> <span>i32</span> @main(<span>i32</span> %0, <span>i8</span>** %1) {
</span></span><span><span>.entry:
</span></span><span><span>  <span>call</span> <span>void</span> @_lpython_set_argv(<span>i32</span> %0, <span>i8</span>** %1)
</span></span><span><span>  <span>call</span> <span>void</span> @__module___main_____main____global_statements()
</span></span><span><span>  <span>ret</span> <span>i32</span> <span>0</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>declare</span> <span>void</span> @_lpython_set_argv(<span>i32</span>, <span>i8</span>**)
</span></span></code></pre></div><h3 id="machine-independent-code-optimisations">Machine Independent Code Optimisations</h3>
<p>LPython implements several machine-independent optimisations via ASR-to-ASR passes. Some of those are listed below,</p>
<ol>
<li>Loop unrolling</li>
<li>Loop vectorisation</li>
<li>Dead code removal</li>
<li>Function call inlining</li>
<li>Transforming division to multiplication operation</li>
<li>Fused multiplication and addition</li>
</ol>
<p>All optimizations are applied via one command-line argument, <code>--fast</code>. To select individual optimizations instead, write a command-line argument like the following:</p>
<p><code>--pass=inline_function_calls,loop_unroll</code></p>
<p>Following is an examples of ASR and transformed ASR after applying the optimisations</p>
<div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>compute_x</span>() <span>-&gt;</span> i32:
</span></span><span><span>    <span>return</span> (<span>2</span> <span>*</span> <span>3</span>) <span>**</span> <span>1</span> <span>+</span> <span>2</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    x: i32 <span>=</span> compute_x()
</span></span><span><span>    print(x)
</span></span><span><span>
</span></span><span><span>main()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="clojure"><span><span>$ lpython examples/expr2.py --show-asr
</span></span><span><span>(<span>TranslationUnit</span>
</span></span><span><span>    (<span>SymbolTable</span>
</span></span><span><span>        <span>1</span>
</span></span><span><span>        {
</span></span><span><span>            __main__<span>:</span>
</span></span><span><span>                (<span>Module</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>2</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>5</span>
</span></span><span><span>                                        {
</span></span><span><span>
</span></span><span><span>                                        })
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [main]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>SubroutineCall</span>
</span></span><span><span>                                        <span>2</span> main
</span></span><span><span>                                        ()
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            compute_x<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>3</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            _lpython_return_variable<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>3</span>
</span></span><span><span>                                                    _lpython_return_variable
</span></span><span><span>                                                    []
</span></span><span><span>                                                    ReturnVar
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    compute_x
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    []
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>3</span> _lpython_return_variable)
</span></span><span><span>                                        (<span>IntegerBinOp</span>
</span></span><span><span>                                            (<span>IntegerBinOp</span>
</span></span><span><span>                                                (<span>IntegerBinOp</span>
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    Mul
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>3</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                )
</span></span><span><span>                                                Pow
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>1</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            )
</span></span><span><span>                                            Add
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>8</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Return</span>)]
</span></span><span><span>                                    (<span>Var</span> <span>3</span> _lpython_return_variable)
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            main<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>4</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    main
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [compute_x]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> x)
</span></span><span><span>                                        (<span>FunctionCall</span>
</span></span><span><span>                                            <span>2</span> compute_x
</span></span><span><span>                                            ()
</span></span><span><span>                                            []
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            ()
</span></span><span><span>                                            ()
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Print</span>
</span></span><span><span>                                        ()
</span></span><span><span>                                        [(<span>Var</span> <span>4</span> x)]
</span></span><span><span>                                        ()
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    __main__
</span></span><span><span>                    []
</span></span><span><span>                    .false.
</span></span><span><span>                    .false.
</span></span><span><span>                ),
</span></span><span><span>            main_program<span>:</span>
</span></span><span><span>                (<span>Program</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>6</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>ExternalSymbol</span>
</span></span><span><span>                                    <span>6</span>
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    <span>2</span> __main____global_statements
</span></span><span><span>                                    __main__
</span></span><span><span>                                    []
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    Public
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    main_program
</span></span><span><span>                    [__main__]
</span></span><span><span>                    [(<span>SubroutineCall</span>
</span></span><span><span>                        <span>6</span> __main____global_statements
</span></span><span><span>                        <span>2</span> __main____global_statements
</span></span><span><span>                        []
</span></span><span><span>                        ()
</span></span><span><span>                    )]
</span></span><span><span>                )
</span></span><span><span>        })
</span></span><span><span>    []
</span></span><span><span>)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="clojure"><span><span>$ lpython examples/expr2.py --show-asr --pass=inline_function_calls,unused_functions
</span></span><span><span>(<span>TranslationUnit</span>
</span></span><span><span>    (<span>SymbolTable</span>
</span></span><span><span>        <span>1</span>
</span></span><span><span>        {
</span></span><span><span>            __main__<span>:</span>
</span></span><span><span>                (<span>Module</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>2</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>5</span>
</span></span><span><span>                                        {
</span></span><span><span>
</span></span><span><span>                                        })
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    [main]
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>SubroutineCall</span>
</span></span><span><span>                                        <span>2</span> main
</span></span><span><span>                                        ()
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                ),
</span></span><span><span>                            main<span>:</span>
</span></span><span><span>                                (<span>Function</span>
</span></span><span><span>                                    (<span>SymbolTable</span>
</span></span><span><span>                                        <span>4</span>
</span></span><span><span>                                        {
</span></span><span><span>                                            _lpython_return_variable_compute_x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    _lpython_return_variable_compute_x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                ),
</span></span><span><span>                                            x<span>:</span>
</span></span><span><span>                                                (<span>Variable</span>
</span></span><span><span>                                                    <span>4</span>
</span></span><span><span>                                                    x
</span></span><span><span>                                                    []
</span></span><span><span>                                                    Local
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Default
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    ()
</span></span><span><span>                                                    Source
</span></span><span><span>                                                    Public
</span></span><span><span>                                                    Required
</span></span><span><span>                                                    .false.
</span></span><span><span>                                                ),
</span></span><span><span>                                            <span>~</span>empty_block<span>:</span>
</span></span><span><span>                                                (<span>Block</span>
</span></span><span><span>                                                    (<span>SymbolTable</span>
</span></span><span><span>                                                        <span>7</span>
</span></span><span><span>                                                        {
</span></span><span><span>
</span></span><span><span>                                                        })
</span></span><span><span>                                                    <span>~</span>empty_block
</span></span><span><span>                                                    []
</span></span><span><span>                                                )
</span></span><span><span>                                        })
</span></span><span><span>                                    main
</span></span><span><span>                                    (<span>FunctionType</span>
</span></span><span><span>                                        []
</span></span><span><span>                                        ()
</span></span><span><span>                                        Source
</span></span><span><span>                                        Implementation
</span></span><span><span>                                        ()
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        .false.
</span></span><span><span>                                        []
</span></span><span><span>                                        []
</span></span><span><span>                                        .false.
</span></span><span><span>                                    )
</span></span><span><span>                                    []
</span></span><span><span>                                    []
</span></span><span><span>                                    [(<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> _lpython_return_variable_compute_x)
</span></span><span><span>                                        (<span>IntegerBinOp</span>
</span></span><span><span>                                            (<span>IntegerBinOp</span>
</span></span><span><span>                                                (<span>IntegerBinOp</span>
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    Mul
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>3</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                    (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                    (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                )
</span></span><span><span>                                                Pow
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>1</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                                (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                                (<span>IntegerConstant</span> <span>6</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            )
</span></span><span><span>                                            Add
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>2</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                            (<span>Integer</span> <span>4</span>)
</span></span><span><span>                                            (<span>IntegerConstant</span> <span>8</span> (<span>Integer</span> <span>4</span>))
</span></span><span><span>                                        )
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>GoTo</span>
</span></span><span><span>                                        <span>1</span>
</span></span><span><span>                                        __1
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>BlockCall</span>
</span></span><span><span>                                        <span>1</span>
</span></span><span><span>                                        <span>4</span> <span>~</span>empty_block
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>=</span>
</span></span><span><span>                                        (<span>Var</span> <span>4</span> x)
</span></span><span><span>                                        (<span>Var</span> <span>4</span> _lpython_return_variable_compute_x)
</span></span><span><span>                                        ()
</span></span><span><span>                                    )
</span></span><span><span>                                    (<span>Print</span>
</span></span><span><span>                                        ()
</span></span><span><span>                                        [(<span>Var</span> <span>4</span> x)]
</span></span><span><span>                                        ()
</span></span><span><span>                                        ()
</span></span><span><span>                                    )]
</span></span><span><span>                                    ()
</span></span><span><span>                                    Public
</span></span><span><span>                                    .false.
</span></span><span><span>                                    .false.
</span></span><span><span>                                    ()
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    __main__
</span></span><span><span>                    []
</span></span><span><span>                    .false.
</span></span><span><span>                    .false.
</span></span><span><span>                ),
</span></span><span><span>            main_program<span>:</span>
</span></span><span><span>                (<span>Program</span>
</span></span><span><span>                    (<span>SymbolTable</span>
</span></span><span><span>                        <span>6</span>
</span></span><span><span>                        {
</span></span><span><span>                            __main____global_statements<span>:</span>
</span></span><span><span>                                (<span>ExternalSymbol</span>
</span></span><span><span>                                    <span>6</span>
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    <span>2</span> __main____global_statements
</span></span><span><span>                                    __main__
</span></span><span><span>                                    []
</span></span><span><span>                                    __main____global_statements
</span></span><span><span>                                    Public
</span></span><span><span>                                )
</span></span><span><span>                        })
</span></span><span><span>                    main_program
</span></span><span><span>                    [__main__]
</span></span><span><span>                    [(<span>SubroutineCall</span>
</span></span><span><span>                        <span>6</span> __main____global_statements
</span></span><span><span>                        <span>2</span> __main____global_statements
</span></span><span><span>                        []
</span></span><span><span>                        ()
</span></span><span><span>                    )]
</span></span><span><span>                )
</span></span><span><span>        })
</span></span><span><span>    []
</span></span><span><span>)
</span></span></code></pre></div><h3 id="ahead-of-time-aot-compilation">Ahead-of-Time (AoT) compilation</h3>
<p>LPython naturally acts as a Python compiler. By default, if no backend is provided it compiles type-annotated user input code to LLVM, which generates binary final output. Consider the following small example:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, i64
</span></span><span><span>
</span></span><span><span><span>def</span> <span>list_bench</span>(n: i32) <span>-&gt;</span> i64:
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    i: i32
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        x<span>.</span>append(i)
</span></span><span><span>
</span></span><span><span>    s: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> i64(x[i])
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span>res: i64 <span>=</span> list_bench(<span>500_000</span>)
</span></span><span><span>print(res)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:58:29:~/lpython_project/lpython % lpython /Users/czgdp1807/lpython_project/debug.py -o a.out
</span></span><span><span><span>(</span>lp<span>)</span> 18:58:31:~/lpython_project/lpython % time ./a.out
</span></span><span><span><span>124999750000</span>
</span></span><span><span>./a.out  0.01s user 0.00s system 89% cpu 0.012 total
</span></span></code></pre></div><p>You can see that it’s very fast. It’s still plenty fast with the C backend via the command-line argument <code>--backend=c</code>:</p>
<div><pre tabindex="0"><code data-lang="zsh"><span><span>% time lpython /Users/czgdp1807/lpython_project/debug.py --backend<span>=</span>c
</span></span><span><span><span>124999750000</span>
</span></span><span><span>lpython /Users/czgdp1807/lpython_project/debug.py --backend<span>=</span>c  0.12s user 0.02s system 100% cpu 0.144 total
</span></span></code></pre></div><p>Note that time lpython <code>/Users/czgdp1807/lpython_project/debug.py --backend=c</code> includes both the compilation time of LPython and the execution time of the binary. The sum of both is so fast that one can afford to compile on every change to the input files. :D.</p>
<h3 id="just-in-time-compilation">Just-In-Time Compilation</h3>
<p>Just-in-time compilation in LPython requires only decorating Python function with <code>@lpython</code>. The decorator takes an option for specifying the desired backend, as in, <code>@lpython(backend="c")</code> or <code>@lpython(backend="llvm")</code>. Only C is supported at present; LLVM and others will be added in the near future. The decorator also propagates backend-specific options. For example</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>,
</span></span><span><span>         backend_optimization_flags<span>=</span>[<span>"-ffast-math"</span>,
</span></span><span><span>                                     <span>"-funroll-loops"</span>,
</span></span><span><span>                                     <span>"-O1"</span>])
</span></span></code></pre></div><p>Note that by default C backend is used without any optimisation flags.</p>
<p>A small example of JIT compilation in LPython (notice the LPython type annotations with the variables),</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, i64, lpython
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O1"</span>])
</span></span><span><span><span>def</span> <span>list_bench</span>(n: i32) <span>-&gt;</span> i64:
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        x<span>.</span>append(i)
</span></span><span><span>    s: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> i64(x[i])
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span>res <span>=</span> list_bench(<span>1</span>) <span># compiles `list_bench` to a shared binary in the first call</span>
</span></span><span><span>res <span>=</span> list_bench(<span>500_000</span>) <span># calls the compiled `list_bench`</span>
</span></span><span><span>print(res)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:46:33:~/lpython_project/lpython % python /Users/czgdp1807/lpython_project/debug.py
</span></span><span><span><span>124999750000</span>
</span></span></code></pre></div><p>We show below in the benchmarks how LPython compares to Numba, which also has JIT compilation.</p>
<h3 id="inter-operability-with-cpython">Inter-operability with CPython</h3>
<p>Access any library implemented using CPython, via the <code>@pythoncall</code> decorator. For example,</p>
<p><strong>email_extractor.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># get_email is implemented in email_extractor_util.py which is intimated to</span>
</span></span><span><span><span># LPython by specifiying the file as module in `@pythoncall` decorator</span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"email_extractor_util"</span>)
</span></span><span><span><span>def</span> <span>get_email</span>(text: str) <span>-&gt;</span> str:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    text: str <span>=</span> <span>"Hello, my email id is lpython@lcompilers.org."</span>
</span></span><span><span>    print(get_email(text))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>email_extractor_util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Implement `get_email` using `re` CPython library</span>
</span></span><span><span><span>def</span> <span>get_email</span>(text):
</span></span><span><span>    <span>import</span> re
</span></span><span><span>    <span># Regular expression patterns</span>
</span></span><span><span>    email_pattern <span>=</span> <span>r</span><span>"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b"</span>
</span></span><span><span>
</span></span><span><span>    <span># Matching email addresses</span>
</span></span><span><span>    email_matches <span>=</span> re<span>.</span>findall(email_pattern, text)
</span></span><span><span>
</span></span><span><span>    <span>return</span> email_matches[<span>0</span>]
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 18:54:13:~/lpython_project % lpython email_extractor.py --backend<span>=</span>c --enable-cpython
</span></span><span><span>lpython@lcompilers.org
</span></span></code></pre></div><p><em>Note</em>: The <code>@pythoncall</code> and <code>@lpython</code> decorators are presently supported with just the <code>C</code> backend but eventually will work with the LLVM backend and that’s work in progress.</p>
<h2 id="benchmarks-and-demos">Benchmarks and Demos</h2>
<p>In this section, we show how LPython performs compares to competitors on each feature LPython offers. We cover JIT compilation, Interoperability with CPython, and AoT compilation.</p>
<h3 id="just-in-time-jit-compilation">Just-In-Time (JIT) Compilation</h3>
<p>We compare JIT compilation of LPython to Numba on <strong>summation of all the elements of a 1-D array</strong>, <strong>pointwise multiplication of two 1-D arrays</strong>, <strong>insertion sort on lists</strong>, and <strong>quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong>.</p>
<p><strong>System Information</strong></p>
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.57.1</td>
</tr>
<tr>
<td>LPython</td>
<td>0.19.0</td>
</tr>
<tr>
<td>Python</td>
<td>3.10.4</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Summation of all the elements of a 1-D array</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> numpy <span>import</span> float64, arange, empty
</span></span><span><span><span>from</span> lpython <span>import</span> i32, f64, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>fast_sum</span>(n: i32, x: f64[:], res: f64[:]) <span>-&gt;</span> f64:
</span></span><span><span>    s: f64 <span>=</span> <span>0.0</span>
</span></span><span><span>    res[<span>0</span>] <span>=</span> <span>0.0</span>
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> x[i]
</span></span><span><span>    res[<span>0</span>] <span>=</span> s
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>fast_sum_numba</span>(n, x, res):
</span></span><span><span>    s <span>=</span> <span>0.0</span>
</span></span><span><span>    res[<span>0</span>] <span>=</span> <span>0.0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        s <span>+=</span> x[i]
</span></span><span><span>    res[<span>0</span>] <span>=</span> s
</span></span><span><span>    <span>return</span> s
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>100_000_000</span>
</span></span><span><span>    x <span>=</span> arange(n, dtype<span>=</span>float64)
</span></span><span><span>    x1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>float64)
</span></span><span><span>    res <span>=</span> empty(<span>1</span>, dtype<span>=</span>float64)
</span></span><span><span>    res_numba <span>=</span> empty(<span>1</span>, dtype<span>=</span>float64)
</span></span><span><span>
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: fast_sum(<span>0</span>, x1, res), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: fast_sum(n, x, res), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> res[<span>0</span>] <span>==</span> <span>4999999950000000.0</span>
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: fast_sum_numba(<span>0</span>, x1, res_numba), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: fast_sum_numba(n, x, res_numba), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> res_numba[<span>0</span>] <span>==</span> <span>4999999950000000.0</span>
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.10</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 MBP 2020</td>
<td>2.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.08</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.53</td>
<td>Apple M1 Pro MBP 2021</td>
<td>6.62</td>
</tr>
<tr>
<td>Numba</td>
<td>0.15</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.40</td>
<td>Apple M1 2020</td>
<td>2.67</td>
</tr>
<tr>
<td>Numba</td>
<td>0.20</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.32</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.60</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.013</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.024</td>
<td>Apple M1 MBP 2020</td>
<td>1.84</td>
</tr>
<tr>
<td>LPython</td>
<td>0.013</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.023</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.77</td>
</tr>
<tr>
<td>LPython</td>
<td>0.014</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.024</td>
<td>Apple M1 2020</td>
<td>1.71</td>
</tr>
<tr>
<td>LPython</td>
<td>0.048</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.048</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Pointwise multiplication of two 1-D arrays</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> numpy <span>import</span> int64, arange, empty
</span></span><span><span><span>from</span> lpython <span>import</span> i32, i64, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>multiply_arrays</span>(n: i32, x: i64[:], y: i64[:], z: i64[:]):
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        z[i] <span>=</span> x[i] <span>*</span> y[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>multiply_arrays_numba</span>(n, x, y, z):
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        z[i] <span>=</span> x[i] <span>*</span> y[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>100_000_000</span>
</span></span><span><span>    x1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    y1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    res1 <span>=</span> arange(<span>0</span>, dtype<span>=</span>int64)
</span></span><span><span>    x <span>=</span> arange(n, dtype<span>=</span>int64)
</span></span><span><span>    y <span>=</span> arange(n, dtype<span>=</span>int64) <span>+</span> <span>2</span>
</span></span><span><span>    res <span>=</span> empty(n, dtype<span>=</span>int64)
</span></span><span><span>    res_numba <span>=</span> empty(n, dtype<span>=</span>int64)
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: multiply_arrays(<span>0</span>, x1, y1, res1), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: multiply_arrays(n, x, y, res), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> sum(res <span>-</span> x <span>*</span> y) <span>==</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: multiply_arrays_numba(<span>0</span>, x1, y1, res1), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: multiply_arrays_numba(n, x, y, res_numba), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    <span>assert</span> sum(res_numba <span>-</span> x <span>*</span> y) <span>==</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.11</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.50</td>
<td>Apple M1 MBP 2020</td>
<td>4.54</td>
</tr>
<tr>
<td>Numba</td>
<td>0.09</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.60</td>
<td>Apple M1 Pro MBP 2021</td>
<td>6.67</td>
</tr>
<tr>
<td>Numba</td>
<td>0.11</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.46</td>
<td>Apple M1 2020</td>
<td>4.18</td>
</tr>
<tr>
<td>Numba</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.31</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.48</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.041</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.042</td>
<td>Apple M1 MBP 2020</td>
<td>1.02</td>
</tr>
<tr>
<td>Numba</td>
<td>0.037</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.040</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.08</td>
</tr>
<tr>
<td>Numba</td>
<td>0.042</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.042</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.21</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Insertion sort on lists</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, lpython
</span></span><span><span><span>import</span> timeit
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O3"</span>])
</span></span><span><span><span>def</span> <span>test_list_sort</span>(size: i32):
</span></span><span><span>    i: i32
</span></span><span><span>    x: list[i32]
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    <span>for</span> i <span>in</span> range(size):
</span></span><span><span>        x<span>.</span>append(size <span>-</span> i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        key: i32 <span>=</span> x[i]
</span></span><span><span>        j: i32 <span>=</span> i <span>-</span> <span>1</span>
</span></span><span><span>        <span>while</span> j <span>&gt;=</span> <span>0</span> <span>and</span> key <span>&lt;</span> x[j] :
</span></span><span><span>            x[j <span>+</span> <span>1</span>] <span>=</span> x[j]
</span></span><span><span>            j <span>-=</span> <span>1</span>
</span></span><span><span>        x[j <span>+</span> <span>1</span>] <span>=</span> key
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        <span>assert</span> x[i <span>-</span> <span>1</span>] <span>&lt;</span> x[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>test_list_sort_numba</span>(size):
</span></span><span><span>    x <span>=</span> []
</span></span><span><span>    <span>for</span> i <span>in</span> range(size):
</span></span><span><span>        x<span>.</span>append(size <span>-</span> i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        key <span>=</span> x[i]
</span></span><span><span>        j <span>=</span> i <span>-</span> <span>1</span>
</span></span><span><span>        <span>while</span> j <span>&gt;=</span> <span>0</span> <span>and</span> key <span>&lt;</span> x[j] :
</span></span><span><span>            x[j <span>+</span> <span>1</span>] <span>=</span> x[j]
</span></span><span><span>            j <span>-=</span> <span>1</span>
</span></span><span><span>        x[j <span>+</span> <span>1</span>] <span>=</span> key
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, size):
</span></span><span><span>        <span>assert</span> x[i <span>-</span> <span>1</span>] <span>&lt;</span> x[i]
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n <span>=</span> <span>25000</span>
</span></span><span><span>    print(<span>"LPython compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: test_list_sort(<span>0</span>), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: test_list_sort(n), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time:"</span>, timeit<span>.</span>timeit(<span>lambda</span>: test_list_sort_numba(<span>0</span>), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time:"</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: test_list_sort_numba(n), repeat<span>=</span><span>10</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 MBP 2020</td>
<td>1.54</td>
</tr>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.60</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.62</td>
</tr>
<tr>
<td>Numba</td>
<td>0.13</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.42</td>
<td>Apple M1 2020</td>
<td>3.23</td>
</tr>
<tr>
<td>Numba</td>
<td>0.35</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.37</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.06</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.11</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 MBP 2020</td>
<td>3.54</td>
</tr>
<tr>
<td>LPython</td>
<td>0.11</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 Pro MBP 2021</td>
<td>3.54</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.39</td>
<td>Apple M1 2020</td>
<td>1.95</td>
</tr>
<tr>
<td>LPython</td>
<td>0.10</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.36</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>3.60</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, lpython
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32
</span></span><span><span><span>from</span> numba <span>import</span> njit
</span></span><span><span><span>import</span> timeit
</span></span><span><span>
</span></span><span><span><span>@lpython</span>(backend<span>=</span><span>"c"</span>, backend_optimisation_flags<span>=</span>[<span>"-ffast-math"</span>, <span>"-funroll-loops"</span>, <span>"-O1"</span>])
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path</span>(n: i32, source: i32, dist_sum: i32[:]):
</span></span><span><span>    i: i32; j: i32; v: i32; u: i32; mindist: i32; alt: i32; dummy: i32;
</span></span><span><span>    graph: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    dist: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    prev: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    visited: dict[i32, bool] <span>=</span> {}
</span></span><span><span>    Q: list[i32] <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>        Q<span>.</span>remove(u)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum[<span>0</span>] <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum[<span>0</span>] <span>+=</span> dist[i]
</span></span><span><span>
</span></span><span><span><span>@njit</span>(fastmath<span>=</span><span>True</span>)
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path_numba</span>(n, source, dist_sum):
</span></span><span><span>    graph <span>=</span> {}
</span></span><span><span>    dist <span>=</span> {}
</span></span><span><span>    prev <span>=</span> {}
</span></span><span><span>    visited <span>=</span> {}
</span></span><span><span>    Q <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>        Q<span>.</span>remove(u)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum[<span>0</span>] <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum[<span>0</span>] <span>+=</span> dist[i]
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: i32 <span>=</span> <span>4000</span>
</span></span><span><span>    dist_sum_array_numba <span>=</span> empty(<span>1</span>, dtype<span>=</span>int32)
</span></span><span><span>    dist_sum_array <span>=</span> empty(<span>1</span>, dtype<span>=</span>int32)
</span></span><span><span>    print(<span>"LPython compilation time: "</span>, timeit<span>.</span>timeit(<span>lambda</span>: dijkstra_shortest_path(<span>0</span>, <span>0</span>, dist_sum_array), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"LPython execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: dijkstra_shortest_path(n, <span>0</span>, dist_sum_array), repeat<span>=</span><span>5</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    print(dist_sum_array[<span>0</span>])
</span></span><span><span>    <span>assert</span> dist_sum_array[<span>0</span>] <span>==</span> i32(n <span>*</span> (n <span>-</span> <span>1</span>)<span>/</span><span>2</span>)
</span></span><span><span>
</span></span><span><span>    print(<span>"Numba compilation time: "</span>, timeit<span>.</span>timeit(<span>lambda</span>: dijkstra_shortest_path_numba(<span>0</span>, <span>0</span>, dist_sum_array_numba), number<span>=</span><span>1</span>))
</span></span><span><span>    print(<span>"Numba execution time: "</span>, min(timeit<span>.</span>repeat(<span>lambda</span>: dijkstra_shortest_path_numba(n, <span>0</span>, dist_sum_array_numba), repeat<span>=</span><span>5</span>, number<span>=</span><span>1</span>)))
</span></span><span><span>    print(dist_sum_array_numba[<span>0</span>])
</span></span><span><span>    <span>assert</span> dist_sum_array_numba[<span>0</span>] <span>==</span> i32(n <span>*</span> (n <span>-</span> <span>1</span>)<span>/</span><span>2</span>)
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler</th>
<th>Compilation Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.35</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.81</td>
<td>Apple M1 MBP 2020</td>
<td>2.31</td>
</tr>
<tr>
<td>LPython</td>
<td>0.69</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.73</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.05</td>
</tr>
<tr>
<td>LPython</td>
<td>0.21</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.73</td>
<td>Apple M1 2020</td>
<td>3.47</td>
</tr>
<tr>
<td>LPython</td>
<td>1.08</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.69</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.56</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.23</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.01</td>
<td>Apple M1 MBP 2020</td>
<td>4.39</td>
</tr>
<tr>
<td>LPython</td>
<td>0.20</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.98</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.90</td>
</tr>
<tr>
<td>LPython</td>
<td>0.27</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>0.98</td>
<td>Apple M1 2020</td>
<td>3.63</td>
</tr>
<tr>
<td>LPython</td>
<td>0.87</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>Numba</td>
<td>1.95</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>2.24</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="ahead-of-time-aot-compilation-1">Ahead-of-Time (AoT) Compilation</h3>
<p>Next, we see how LPython compares to other AoT compilers and to the standard CPython interpreter. The tasks considered are <strong>quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong>, and <strong>Floyd-Warshall algorithm on array representation of graphs</strong>.</p>
<p><strong>System Information</strong></p>
<table>
<thead>
<tr>
<th>Compiler</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>clang++</td>
<td>14.0.3</td>
</tr>
<tr>
<td>g++</td>
<td>11.3.0</td>
</tr>
<tr>
<td>LPython</td>
<td>0.19.0</td>
</tr>
<tr>
<td>Python</td>
<td>3.10.4</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<p><strong>Quadratic-time implementation of the Dijkstra shortest-path algorithm on a fully connected graph</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32
</span></span><span><span>
</span></span><span><span><span>def</span> <span>dijkstra_shortest_path</span>(n: i32, source: i32) <span>-&gt;</span> i32:
</span></span><span><span>    i: i32; j: i32; v: i32; u: i32; mindist: i32; alt: i32; dummy: i32; uidx: i32
</span></span><span><span>    dist_sum: i32;
</span></span><span><span>    graph: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    dist: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    prev: dict[i32, i32] <span>=</span> {}
</span></span><span><span>    visited: dict[i32, bool] <span>=</span> {}
</span></span><span><span>    Q: list[i32] <span>=</span> []
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>for</span> j <span>in</span> range(n):
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> abs(i <span>-</span> j)
</span></span><span><span>
</span></span><span><span>    <span>for</span> v <span>in</span> range(n):
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        Q<span>.</span>append(v)
</span></span><span><span>        visited[v] <span>=</span> <span>False</span>
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>while</span> len(Q) <span>&gt;</span> <span>0</span>:
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>
</span></span><span><span>        <span>for</span> i <span>in</span> range(len(Q)):
</span></span><span><span>            <span>if</span> mindist <span>&gt;</span> dist[Q[i]]:
</span></span><span><span>                mindist <span>=</span> dist[Q[i]]
</span></span><span><span>                u <span>=</span> Q[i]
</span></span><span><span>                uidx <span>=</span> i
</span></span><span><span>        dummy <span>=</span> Q<span>.</span>pop(uidx)
</span></span><span><span>        visited[u] <span>=</span> <span>True</span>
</span></span><span><span>
</span></span><span><span>        <span>for</span> v <span>in</span> range(n):
</span></span><span><span>            <span>if</span> v <span>!=</span> u <span>and</span> <span>not</span> visited[v]:
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v]
</span></span><span><span>
</span></span><span><span>                <span>if</span> alt <span>&lt;</span> dist[v]:
</span></span><span><span>                    dist[v] <span>=</span> alt
</span></span><span><span>                    prev[v] <span>=</span> u
</span></span><span><span>
</span></span><span><span>    dist_sum <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        dist_sum <span>+=</span> dist[i]
</span></span><span><span>    <span>return</span> dist_sum
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: i32 <span>=</span> <span>4000</span>
</span></span><span><span>    print(dijkstra_shortest_path(n, <span>0</span>))
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;unordered_map&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;vector&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int32_t</span> <span>dijkstra_shortest_path</span>(<span>int32_t</span> n, <span>int32_t</span> source) {
</span></span><span><span>    <span>int32_t</span> i, j, v, u, mindist, alt, dummy, uidx;
</span></span><span><span>    std<span>::</span>unordered_map<span>&lt;</span><span>int32_t</span>, <span>int32_t</span><span>&gt;</span> graph, dist, prev;
</span></span><span><span>    std<span>::</span>unordered_map<span>&lt;</span><span>int32_t</span>, <span>bool</span><span>&gt;</span> visited;
</span></span><span><span>    std<span>::</span>vector<span>&lt;</span><span>int32_t</span><span>&gt;</span> Q;
</span></span><span><span>
</span></span><span><span>    <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> n; i<span>++</span>) {
</span></span><span><span>        <span>for</span>(j <span>=</span> <span>0</span>; j <span>&lt;</span> n; j<span>++</span>) {
</span></span><span><span>            graph[n <span>*</span> i <span>+</span> j] <span>=</span> std<span>::</span>abs(i <span>-</span> j);
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> n; v<span>++</span>) {
</span></span><span><span>        dist[v] <span>=</span> <span>2147483647</span>;
</span></span><span><span>        prev[v] <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>        Q.push_back(v);
</span></span><span><span>        visited[v] <span>=</span> false;
</span></span><span><span>    }
</span></span><span><span>    dist[source] <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>while</span>(Q.size() <span>&gt;</span> <span>0</span>) {
</span></span><span><span>        u <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>        mindist <span>=</span> <span>2147483647</span>;
</span></span><span><span>        <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> Q.size(); i<span>++</span>) {
</span></span><span><span>            <span>if</span>( mindist <span>&gt;</span> dist[Q[i]] ) {
</span></span><span><span>                mindist <span>=</span> dist[Q[i]];
</span></span><span><span>                u <span>=</span> Q[i];
</span></span><span><span>                uidx <span>=</span> i;
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>        Q.erase(Q.begin() <span>+</span> uidx);
</span></span><span><span>        visited[u] <span>=</span> true;
</span></span><span><span>
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> n; v<span>++</span>) {
</span></span><span><span>            <span>if</span>( v <span>!=</span> u and not visited[v] ) {
</span></span><span><span>                alt <span>=</span> dist[u] <span>+</span> graph[n <span>*</span> u <span>+</span> v];
</span></span><span><span>
</span></span><span><span>                <span>if</span>( alt <span>&lt;</span> dist[v] ) {
</span></span><span><span>                    dist[v] <span>=</span> alt;
</span></span><span><span>                    prev[v] <span>=</span> u;
</span></span><span><span>                }
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>int32_t</span> dist_sum <span>=</span> <span>0</span>;
</span></span><span><span>    <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> n; i<span>++</span>) {
</span></span><span><span>        dist_sum <span>+=</span> dist[i];
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> dist_sum;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>    <span>int32_t</span> n <span>=</span> <span>4000</span>;
</span></span><span><span>    <span>int32_t</span> dist_sum <span>=</span> dijkstra_shortest_path(n, <span>0</span>);
</span></span><span><span>    std<span>::</span>cout<span>&lt;&lt;</span>dist_sum<span>&lt;&lt;</span>std<span>::</span>endl;
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td>0.167</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.993</td>
<td>Apple M1 MBP 2020</td>
<td>5.95</td>
</tr>
<tr>
<td>Python</td>
<td>3.817</td>
<td>Apple M1 MBP 2020</td>
<td>22.86</td>
</tr>
<tr>
<td>LPython</td>
<td>0.155</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.685</td>
<td>Apple M1 Pro MBP 2021</td>
<td>4.41</td>
</tr>
<tr>
<td>Python</td>
<td>3.437</td>
<td>Apple M1 Pro MBP 2021</td>
<td>22.17</td>
</tr>
<tr>
<td>LPython</td>
<td>0.324</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.709</td>
<td>Apple M1 2020</td>
<td>2.19</td>
</tr>
<tr>
<td>Python</td>
<td>3.486</td>
<td>Apple M1 2020</td>
<td>10.76</td>
</tr>
<tr>
<td>LPython</td>
<td>0.613</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>g++</td>
<td>1.358</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>2.21</td>
</tr>
<tr>
<td>Python</td>
<td>7.365</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>12.01</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<p>Note the optimization flags furnished to each compiler.</p>
<table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Optimization flags used</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td><code>--fast</code></td>
</tr>
<tr>
<td>Clang++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>g++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>Python</td>
<td>-</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>Floyd-Warshall algorithm on array representation of graphs</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i64, i32
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int64
</span></span><span><span>
</span></span><span><span><span>def</span> <span>floyd_warshall</span>(size: i32) <span>-&gt;</span> i64:
</span></span><span><span>    dist: i64[size, size] <span>=</span> empty((size, size), dtype<span>=</span>int64)
</span></span><span><span>    u: i32; v: i32
</span></span><span><span>    i: i32; j: i32; k: i32
</span></span><span><span>    update: i64 <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> u <span>in</span> range(size):
</span></span><span><span>        <span>for</span> v <span>in</span> range(size):
</span></span><span><span>            dist[u, v] <span>=</span> i64(<span>2147483647</span>)
</span></span><span><span>    <span>for</span> u <span>in</span> range(size):
</span></span><span><span>        <span>for</span> v <span>in</span> range(size):
</span></span><span><span>            <span>if</span> u <span>!=</span> v <span>and</span> ((u<span>%</span><span>2</span> <span>==</span> <span>0</span> <span>and</span> v<span>%</span><span>2</span> <span>==</span> <span>1</span>)
</span></span><span><span>                           <span>or</span> (u<span>%</span><span>2</span> <span>==</span> <span>1</span> <span>and</span> v<span>%</span><span>2</span> <span>==</span> <span>0</span>)):
</span></span><span><span>                dist[u, v] <span>=</span> i64(u <span>+</span> v)
</span></span><span><span>    <span>for</span> v <span>in</span> range(size):
</span></span><span><span>        dist[v, v] <span>=</span> i64(<span>0</span>)
</span></span><span><span>
</span></span><span><span>    update <span>=</span> i64(<span>0</span>)
</span></span><span><span>    <span>for</span> k <span>in</span> range(size):
</span></span><span><span>        <span>for</span> i <span>in</span> range(size):
</span></span><span><span>            <span>for</span> j <span>in</span> range(size):
</span></span><span><span>                <span>if</span> dist[i, j] <span>&gt;</span> dist[i, k] <span>+</span> dist[k, j]:
</span></span><span><span>                    update <span>+=</span> dist[i, j] <span>-</span> dist[i, k] <span>-</span> dist[k, j]
</span></span><span><span>                    dist[i, j] <span>=</span> dist[i, k] <span>+</span> dist[k, j]
</span></span><span><span>
</span></span><span><span>    <span>return</span> update
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>print(floyd_warshall(<span>1000</span>))
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int64_t</span> <span>floyd_warshall</span>(<span>int32_t</span> size) {
</span></span><span><span>    <span>int64_t</span> dist[size][size];
</span></span><span><span>    <span>int32_t</span> u, v, i, j, k;
</span></span><span><span>    <span>int64_t</span> update;
</span></span><span><span>    <span>for</span>(u <span>=</span> <span>0</span>; u <span>&lt;</span> size; u<span>++</span>) {
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>            dist[u][v] <span>=</span> <span>2147483647</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>for</span>(u <span>=</span> <span>0</span>; u <span>&lt;</span> size; u<span>++</span>) {
</span></span><span><span>        <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>            <span>if</span>( u <span>!=</span> v <span>&amp;&amp;</span> ((u<span>%</span><span>2</span> <span>==</span> <span>0</span> and v<span>%</span><span>2</span> <span>==</span> <span>1</span>)
</span></span><span><span>                           <span>||</span> (u<span>%</span><span>2</span> <span>==</span> <span>1</span> and v<span>%</span><span>2</span> <span>==</span> <span>0</span>)) ) {
</span></span><span><span>                dist[u][v] <span>=</span> u <span>+</span> v;
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>for</span>(v <span>=</span> <span>0</span>; v <span>&lt;</span> size; v<span>++</span>) {
</span></span><span><span>        dist[v][v] <span>=</span> <span>0</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    update <span>=</span> <span>0</span>;
</span></span><span><span>    <span>for</span>(k <span>=</span> <span>0</span>; k <span>&lt;</span> size; k<span>++</span>) {
</span></span><span><span>        <span>for</span>(i <span>=</span> <span>0</span>; i <span>&lt;</span> size; i<span>++</span>) {
</span></span><span><span>            <span>for</span>(j <span>=</span> <span>0</span>; j <span>&lt;</span> size; j<span>++</span>) {
</span></span><span><span>                <span>if</span>( dist[i][j] <span>&gt;</span> dist[i][k] <span>+</span> dist[k][j] ) {
</span></span><span><span>                    update <span>+=</span> dist[i][j] <span>-</span> dist[i][k] <span>-</span> dist[k][j];
</span></span><span><span>                    dist[i][j] <span>=</span> dist[i][k] <span>+</span> dist[k][j];
</span></span><span><span>                }
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> update;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span>() {
</span></span><span><span>    std<span>::</span>cout<span>&lt;&lt;</span>(floyd_warshall(<span>1000</span>))<span>&lt;&lt;</span>std<span>::</span>endl;
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Execution Time (s)</th>
<th>System</th>
<th>Relative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clang++</td>
<td>0.451</td>
<td>Apple M1 MBP 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.767</td>
<td>Apple M1 MBP 2020</td>
<td>1.70</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 MBP 2020</td>
<td>&gt; 24.39</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.435</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.785</td>
<td>Apple M1 Pro MBP 2021</td>
<td>1.80</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 Pro MBP 2021</td>
<td>&gt; 25.28</td>
</tr>
<tr>
<td>Clang++</td>
<td>0.460</td>
<td>Apple M1 2020</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>0.995</td>
<td>Apple M1 2020</td>
<td>2.16</td>
</tr>
<tr>
<td>Python</td>
<td>&gt; 11</td>
<td>Apple M1 2020</td>
<td>&gt; 23.91</td>
</tr>
<tr>
<td>g++</td>
<td>0.695</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>1.00</td>
</tr>
<tr>
<td>LPython</td>
<td>2.933</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>4.22</td>
</tr>
<tr>
<td>Python</td>
<td>440.588</td>
<td>AMD Ryzen 5 2500U (Ubuntu 22.04)</td>
<td>633.94</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Note the optimization flags furnished to each compiler.</p>
<table>
<thead>
<tr>
<th>Compiler/Interpreter</th>
<th>Optimization flags used</th>
</tr>
</thead>
<tbody>
<tr>
<td>LPython</td>
<td><code>--fast</code></td>
</tr>
<tr>
<td>Clang++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>g++</td>
<td><code>-ffast-math -funroll-loops -O3</code></td>
</tr>
<tr>
<td>Python</td>
<td>-</td>
</tr>
</tbody>
</table>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="interoperability-with-cpython">Interoperability with CPython</h3>
<p>Next we show that LPython can call functions in CPython libraries. This feature permits “break-out” to Numpy, TensorFlow, PyTorch, and even to matplotlib. The break-outs will run at ordinary (slow) Python speeds, but LPython accelerates the mathematical portions to near maximum speed.</p>
<p><strong>Calling NumPy functions via CPython</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, f64, i64, pythoncall, Const, TypeVar
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32, float64
</span></span><span><span>
</span></span><span><span>n_1 <span>=</span> TypeVar(<span>"n_1"</span>)
</span></span><span><span>n_2 <span>=</span> TypeVar(<span>"n_2"</span>)
</span></span><span><span>n_3 <span>=</span> TypeVar(<span>"n_3"</span>)
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>cpython_add</span>(n_1: i32, a: i32[:], b: i32[:]) <span>-&gt;</span> i32[n_1]:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>cpython_multiply</span>(n_1: i32, n_2: i32, a: f64[:], b: f64[:]) <span>-&gt;</span> f64[n_1, n_2]:
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test_1D</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>500_000</span>
</span></span><span><span>    a: i32[n] <span>=</span> empty(n, dtype <span>=</span> int32)
</span></span><span><span>    b: i32[n] <span>=</span> empty(n, dtype <span>=</span> int32)
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        a[i] <span>=</span> <span>2</span> <span>*</span> (i<span>+</span><span>1</span>) <span>*</span> <span>13</span>
</span></span><span><span>        b[i] <span>=</span> a[i] <span>+</span> <span>2</span>
</span></span><span><span>    sum: i32[n]
</span></span><span><span>    sum <span>=</span> cpython_add(<span>500_000</span>, a, b)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>assert</span> sum[i] <span>==</span> a[i] <span>+</span> b[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test_2D</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>1_000</span>
</span></span><span><span>    a: f64[n] <span>=</span> empty([n], dtype <span>=</span> float64)
</span></span><span><span>    b: f64[n] <span>=</span> empty([n], dtype <span>=</span> float64)
</span></span><span><span>    i: i32; j: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        a[i] <span>=</span> f64(i <span>+</span> <span>13</span>)
</span></span><span><span>        b[i] <span>=</span> i <span>*</span> <span>2</span> <span>/</span> (i <span>+</span> <span>1</span>)
</span></span><span><span>    product: f64[n, n]
</span></span><span><span>    product <span>=</span> cpython_multiply(<span>1_000</span>, <span>1_000</span>, a, b)
</span></span><span><span>    <span>for</span> i <span>in</span> range(n):
</span></span><span><span>        <span>assert</span> product[i] <span>==</span> a[i] <span>*</span> b[i]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    test_1D()
</span></span><span><span>    test_2D()
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> numpy <span>as</span> np
</span></span><span><span>
</span></span><span><span><span>def</span> <span>cpython_add</span>(n, a, b):
</span></span><span><span>    <span>return</span> np<span>.</span>add(a, b)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>cpython_multiply</span>(n, m, a, b):
</span></span><span><span>    <span>return</span> np<span>.</span>multiply(a, b)
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 23:02:55:~/lpython_project % lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span><span>(</span>lp<span>)</span> 23:03:10:~/lpython_project % <span># Works successfully without any asserts failing</span>
</span></span></code></pre></div><p><strong>Plotting graphs via Matplotlib</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> f64, i32, pythoncall, Const
</span></span><span><span><span>from</span> numpy <span>import</span> empty, float64
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module <span>=</span> <span>"util"</span>)
</span></span><span><span><span>def</span> <span>plot_graph</span>(x: f64[:], y1: f64[:], y2: f64[:], y3: f64[:]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>f</span>(x: f64, i: f64) <span>-&gt;</span> f64:
</span></span><span><span>    <span>return</span> x <span>**</span> <span>.5</span> <span>/</span> i
</span></span><span><span>
</span></span><span><span><span>def</span> <span>test</span>():
</span></span><span><span>    n: Const[i32] <span>=</span> <span>100000</span>
</span></span><span><span>    x: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y1: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y2: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>    y3: f64[n] <span>=</span> empty(n, dtype<span>=</span>float64)
</span></span><span><span>
</span></span><span><span>    i: i32
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, n):
</span></span><span><span>        x[i] <span>=</span> f64(i)
</span></span><span><span>
</span></span><span><span>    <span>for</span> i <span>in</span> range(<span>1</span>, n):
</span></span><span><span>        y1[i] <span>=</span> f(x[i], <span>1.</span>)
</span></span><span><span>        y2[i] <span>=</span> f(x[i], <span>2.</span>)
</span></span><span><span>        y3[i] <span>=</span> f(x[i], <span>3.</span>)
</span></span><span><span>
</span></span><span><span>    plot_graph(x, y1, y2, y3)
</span></span><span><span>
</span></span><span><span>test()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> matplotlib.pyplot <span>as</span> plt
</span></span><span><span>
</span></span><span><span><span>def</span> <span>plot_graph</span>(x, y1, y2, y3):
</span></span><span><span>    plt<span>.</span>figtext(<span>0.92</span>, <span>0.03</span>, <span>'$x$'</span>)
</span></span><span><span>    plt<span>.</span>figtext(<span>0.1</span>, <span>0.9</span>, <span>'$y$'</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y1, label<span>=</span><span>"y1"</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y2, label<span>=</span><span>"y2"</span>)
</span></span><span><span>    plt<span>.</span>plot(x, y3, label<span>=</span><span>"y3"</span>)
</span></span><span><span>    plt<span>.</span>legend()
</span></span><span><span>    plt<span>.</span>savefig(<span>'graph.png'</span>)
</span></span><span><span>    plt<span>.</span>show()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span><span>(</span>lp<span>)</span> 23:09:08:~/lpython_project % lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span><span>(</span>lp<span>)</span> 23:10:44:~/lpython_project % <span># Works see the graph below</span>
</span></span></code></pre></div><p><img src="https://lpython.org/blog/images/graph.png" alt="Output graph"></p>
<p><strong>Visualization using Matplotlib: Mandelbrot Set</strong></p>
<p><strong>main.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> lpython <span>import</span> i32, f64, pythoncall, TypeVar
</span></span><span><span><span>from</span> numpy <span>import</span> empty, int32
</span></span><span><span>
</span></span><span><span>h <span>=</span> TypeVar(<span>"h"</span>)
</span></span><span><span>w <span>=</span> TypeVar(<span>"w"</span>)
</span></span><span><span>d <span>=</span> TypeVar(<span>"d"</span>)
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"util"</span>)
</span></span><span><span><span>def</span> <span>show_img_gray</span>(w: i32, h: i32, A: i32[h, w]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>@pythoncall</span>(module<span>=</span><span>"util"</span>)
</span></span><span><span><span>def</span> <span>show_img_color</span>(w: i32, h: i32, d: i32, A: i32[h, w, d]):
</span></span><span><span>    <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main0</span>():
</span></span><span><span>    Nx: i32 <span>=</span> <span>600</span>; Ny: i32 <span>=</span> <span>450</span>; Nz: i32 <span>=</span> <span>4</span>; n_max: i32 <span>=</span> <span>255</span>
</span></span><span><span>
</span></span><span><span>    xcenter: f64 <span>=</span> f64(<span>-</span><span>0.5</span>); ycenter: f64 <span>=</span> f64(<span>0.0</span>)
</span></span><span><span>    width: f64 <span>=</span> f64(<span>4</span>); height: f64 <span>=</span> f64(<span>3</span>)
</span></span><span><span>    dx_di: f64 <span>=</span> width<span>/</span>f64(Nx); dy_dj: f64 <span>=</span> <span>-</span>height<span>/</span>f64(Ny)
</span></span><span><span>    x_offset: f64 <span>=</span> xcenter <span>-</span> f64(Nx<span>+</span><span>1</span>)<span>*</span>dx_di<span>/</span>f64(<span>2.0</span>)
</span></span><span><span>    y_offset: f64 <span>=</span> ycenter <span>-</span> f64(Ny<span>+</span><span>1</span>)<span>*</span>dy_dj<span>/</span>f64(<span>2.0</span>)
</span></span><span><span>
</span></span><span><span>    i: i32; j: i32; n: i32; idx: i32
</span></span><span><span>    x: f64; y: f64; x_0: f64; y_0: f64; x_sqr: f64; y_sqr: f64
</span></span><span><span>
</span></span><span><span>    image: i32[<span>450</span>, <span>600</span>] <span>=</span> empty([Ny, Nx], dtype<span>=</span>int32)
</span></span><span><span>    image_color: i32[<span>450</span>, <span>600</span>, <span>4</span>] <span>=</span> empty([Ny, Nx, Nz], dtype<span>=</span>int32)
</span></span><span><span>    palette: i32[<span>4</span>, <span>3</span>] <span>=</span> empty([<span>4</span>, <span>3</span>], dtype<span>=</span>int32)
</span></span><span><span>
</span></span><span><span>    <span>for</span> j <span>in</span> range(Ny):
</span></span><span><span>        y_0 <span>=</span> y_offset <span>+</span> dy_dj <span>*</span> f64(j <span>+</span> <span>1</span>)
</span></span><span><span>        <span>for</span> i <span>in</span> range(Nx):
</span></span><span><span>            x_0 <span>=</span> x_offset <span>+</span> dx_di <span>*</span> f64(i <span>+</span> <span>1</span>)
</span></span><span><span>            x <span>=</span> <span>0.0</span>; y <span>=</span> <span>0.0</span>; n <span>=</span> <span>0</span>
</span></span><span><span>            <span>while</span>(<span>True</span>):
</span></span><span><span>                x_sqr <span>=</span> x <span>**</span> <span>2.0</span>
</span></span><span><span>                y_sqr <span>=</span> y <span>**</span> <span>2.0</span>
</span></span><span><span>                <span>if</span> (x_sqr <span>+</span> y_sqr <span>&gt;</span> f64(<span>4</span>) <span>or</span> n <span>==</span> n_max):
</span></span><span><span>                    image[j,i] <span>=</span> <span>255</span> <span>-</span> n
</span></span><span><span>                    <span>break</span>
</span></span><span><span>                y <span>=</span> y_0 <span>+</span> f64(<span>2.0</span>) <span>*</span> x <span>*</span> y
</span></span><span><span>                x <span>=</span> x_0 <span>+</span> x_sqr <span>-</span> y_sqr
</span></span><span><span>                n <span>=</span> n <span>+</span> <span>1</span>
</span></span><span><span>
</span></span><span><span>    palette[<span>0</span>,<span>0</span>] <span>=</span>   <span>0</span>; palette[<span>0</span>,<span>1</span>] <span>=</span> <span>135</span>; palette[<span>0</span>,<span>2</span>] <span>=</span>  <span>68</span>
</span></span><span><span>    palette[<span>1</span>,<span>0</span>] <span>=</span>   <span>0</span>; palette[<span>1</span>,<span>1</span>] <span>=</span>  <span>87</span>; palette[<span>1</span>,<span>2</span>] <span>=</span> <span>231</span>
</span></span><span><span>    palette[<span>2</span>,<span>0</span>] <span>=</span> <span>214</span>; palette[<span>2</span>,<span>1</span>] <span>=</span>  <span>45</span>; palette[<span>2</span>,<span>2</span>] <span>=</span>  <span>32</span>
</span></span><span><span>    palette[<span>3</span>,<span>0</span>] <span>=</span> <span>255</span>; palette[<span>3</span>,<span>1</span>] <span>=</span> <span>167</span>; palette[<span>3</span>,<span>2</span>] <span>=</span>   <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> j <span>in</span> range(Ny):
</span></span><span><span>        <span>for</span> i <span>in</span> range(Nx):
</span></span><span><span>            idx <span>=</span> image[j,i] <span>-</span> i32(image[j,i]<span>/</span><span>4</span>)<span>*</span><span>4</span>
</span></span><span><span>            image_color[j,i,<span>0</span>] <span>=</span> palette[idx,<span>0</span>] <span># Red</span>
</span></span><span><span>            image_color[j,i,<span>1</span>] <span>=</span> palette[idx,<span>1</span>] <span># Green</span>
</span></span><span><span>            image_color[j,i,<span>2</span>] <span>=</span> palette[idx,<span>2</span>] <span># Blue</span>
</span></span><span><span>            image_color[j,i,<span>3</span>] <span>=</span> <span>255</span>            <span># Alpha</span>
</span></span><span><span>
</span></span><span><span>    show_img_gray(Nx, Ny, image)
</span></span><span><span>    show_img_color(Nx, Ny, Nz, image_color)
</span></span><span><span>    print(<span>"Done."</span>)
</span></span><span><span>
</span></span><span><span>main0()
</span></span></code></pre></div><p><strong>util.py</strong></p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>show_img_gray</span>(w, h, A):
</span></span><span><span>    <span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt
</span></span><span><span>    plt<span>.</span>imshow(A, cmap<span>=</span><span>'gray'</span>)
</span></span><span><span>    plt<span>.</span>show()
</span></span><span><span>    plt<span>.</span>close()
</span></span><span><span>
</span></span><span><span><span>def</span> <span>show_img_color</span>(w, h, d, A):
</span></span><span><span>    <span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt
</span></span><span><span>    plt<span>.</span>imshow(A)
</span></span><span><span>    plt<span>.</span>show()
</span></span><span><span>    plt<span>.</span>close()
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="zsh"><span><span>$ ls
</span></span><span><span>main.py util.py
</span></span><span><span>$ lpython main.py --backend<span>=</span>c --link-numpy
</span></span><span><span>Done.
</span></span></code></pre></div><p><img src="https://lpython.org/blog/images/gray.png" alt="mandelbrot-set-gray"></p>
<p><img src="https://lpython.org/blog/images/color.png" alt="mandelbrot-set-color"></p>
<h2 id="conclusion">Conclusion</h2>
<p>The benchmarks support the claim that LPython is competitive with its competitors in all features it offers. In JIT, the execution times of LPython-compiled functions are at least as short as equivalent Numba functions. The speed of JIT compilation, itself, is slow in some cases because it currently depends on a C compiler to generate optimal binary code. For algorithms with rich data structures like <code>dict</code> (hash maps) and <code>list</code>, LPython shows much faster speed than Numba. In AoT compilation for tasks like the Dijkstra algorithm, LPython beats equivalent C++ code very comfortably. For an array-based implementation of the Floyd-Warshall algorithm, LPython generates code almost as fast as C++ does.</p>
<p>The main takeaway is that LPython/LFortran generate fast code by default. Our benchmarks show that it’s straightforward to write high-speed LPython code. We hope to raise expectations that LPython output will be in general at least as fast as the equivalent C++ code. Users love Python because of its many productivity advantages: great tooling, easy syntax, and rich data structures like lists, dicts, sets, and arrays. Because any LPython program is also an ordinary Python program, all the tools – debuggers and profilers, for instance – just work. Then, LPython delivers run-time speeds, even with rich data structures at least as short as alternatives in most cases.</p>


        
          
        

        

        
      </article>

      
        
      


      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plans develop for high-speed rail in the PNW (162 pts)]]></title>
            <link>https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/</link>
            <guid>36916150</guid>
            <pubDate>Sat, 29 Jul 2023 02:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/">https://southseattleemerald.com/2023/07/18/plans-develop-for-high-speed-rail-in-the-pnw/</a>, See on <a href="https://news.ycombinator.com/item?id=36916150">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<h2><em>New research shows how community engagement is integral in its success.</em></h2>



<p><i><b>by Sarah Goh</b></i></p>



<hr>



<p>With a growing population in the Pacific Northwest, the call for better public transportation heightens. This March, Washington’s State Legislature signed off on a transportation milestone, allocating $150 million to a high-speed connection between Oregon, Washington, and British Columbia. </p>



<p>Though this funding could reduce congestion, cut carbon emissions, and better connect these coastal cities, a high-speed rail that travels above 200 miles per hour between major cities has never been done before in the United States. How will Washington get started? How will the State ensure a successful project?</p>



<p>A new <a href="https://mic.comotion.uw.edu/our-work/ultra-high-speed-rail-project/">research report</a> by the University of Washington examines these very questions and identifies key concepts that community members can help with to achieve an efficient high-speed rail. If a rail is built successfully, there will be an extraordinary increase in transportation abilities — saving commuters time while reducing environmental harm. </p>



<p>Professors Jan Whittington and Qing Shen at the UW’s Department of Urban Design and Planning led the research, and with no previous high-speed rail projects in the Northwest, they turned to other states and abroad.</p>



<p>“The purpose of the study was to draw lessons learned from projects, systems, and expertise around the world where high-speed rail has been successful,” Whittington said.</p>



<p>They dedicated six months to both academic and industry research. They interviewed a cadre of transportation experts in France, the Netherlands, Spain, Taiwan, and U.S. cities where high-speed rail is currently developing. </p>



<p>“Oftentimes, [the U.S. is] in a leadership role in developing and growing technologies,” Whittington said. “But here, we’re in a position of needing to learn from people who have had success in their own countries.” </p>



<p>The study allowed interviewees to share their experiences from their own projects. Whittington says that while people are usually unwilling to share their research information, Whittington and Shen’s research allowed experts to talk about their regrets, choices, and early decisions in high-speed rail building. </p>



<p>The <a href="https://mic.comotion.uw.edu/wp-content/uploads/2023/05/Keeping-it-on-the-Tracks-High-speed-Rail-Success-and-Lessons-Learned.pdf">final research report</a> spans over 72 pages, with 40 recommendations for transportation departments. However, Whittington emphasized several key points that will be instrumental to the project’s success: For commuters to prioritize rail transportation over air or other non-environmental ways of travel, the high-speed rail must be at its most convenient. To achieve this convenience of speed and efficiency, there cannot be any shortcuts or deviations to the design. Routes are going to be chosen that minimize turns and any design choices that reduce speed. </p>



<p>And Whittington says the designers must also ensure the rail remains dedicated to its high-speed route and that people have the ability to get to the rail through other means of public transportation. “There are going to be a lot of communities you want to serve,” Whittington said, “but you want to find a way to bring those communities to the routes as opposed to bringing the route to the communities.” </p>



<p>Whittington says early planning must engage commuters and the general community. The report itself states, “Have early, systematic, and sustained community engagement, approaching communities to understand their needs instead of selling the idea of high-speed rail.”</p>



<p>Along with community engagement, limiting political sway is important. The study shows that if political representatives convince planners to route through different locations — deviating from the design — cities could end up with an expensive commuter rail system instead of a competitive high-speed rail.</p>



<p>“You have to be very careful about compromises made in design in these early stages,” Whittington said.</p>



<p>Implementing this delicate balance of compromises and early planning is essential for a high-speed rail project, and the UW research has created a place for U.S. transportation departments to start.</p>



<p>“It is our sincere hope that people will be able to see this collection of recommendations as a set of touchstones to build off of as they take the earliest steps in product design and development,” Whittington said.</p>



<p>The Washington State Department of Transportation (WSDOT) has already begun the early stages of building a high-speed rail in the Cascadia region with help from the UW study. They are looking to secure more funding and focus on the meticulousness of the early design process. Especially in collaboration with Oregon and British Columbia, a project like this is formidable and will take years.</p>



<p>“We don’t want to short-circuit the work we need to do with communities,” said Ron Pate, WSDOT’s director for Rail, Freight and Ports. “Our goal is to make sure we work with communities when moving it forward.” </p>



<hr>



<p><em>This article is funded in part by an</em><a href="https://greenspace.seattle.gov/2023/01/city-of-seattles-environmental-justice-fund-awards-750000-in-grants-for-13-projects-led-by-and-benefiting-those-most-impacted-by-climate-change/#sthash.1NfRR1eK.dpbs"><em>&nbsp;Environmental Justice Fund (EJ Fund) grant</em></a><em>&nbsp;through the City of Seattle’s Office of Sustainability &amp; Environment (OSE).</em></p>



<hr>



<div><figure><img data-lazy-fallback="1" data-attachment-id="83917" data-permalink="https://southseattleemerald.com/2022/03/23/nic-masangkay-is-redefining-mothers-in-a-new-age-of-love/sarahgoh_headshot_cropped/" data-orig-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=1080%2C1080&amp;ssl=1" data-orig-size="1080,1080" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SarahGoh_headshot_cropped" data-image-description="<p>Sarah Goh is a Seattle-based journalist who graduated from the University of Washington with a dual-degree in biology and journalism. At the intersection of community, science, and humanities, she hopes to uplift more voices and explore the overlooked and unexpected. Find her at sarahsgoh.com or on Instagram @sarahsgoh.</p>
" data-image-caption="<p>Sarah Goh</p>
" data-medium-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?fit=474%2C474&amp;ssl=1" decoding="async" loading="lazy" width="474" height="474" src="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=474%2C474&amp;ssl=1" alt="" srcset="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=1080&amp;ssl=1 1080w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=948&amp;ssl=1 948w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=1080&amp;ssl=1 1080w, https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?w=948&amp;ssl=1 948w" data-lazy-src="https://i0.wp.com/southseattleemerald.com/wp-content/uploads/2022/03/SarahGoh_headshot_cropped.jpg?resize=474%2C474&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p><strong><em>Sarah Goh</em></strong><em> is a Singaporean American journalist from Seattle, Washington, and a current medical student at WSU College of Medicine. At the intersection of community, science, and humanities, she hopes to elevate marginalized voices and explore the overlooked and unexpected through her writing. Find her at </em><a href="https://sarahsgoh.com/work"><em>SarahSGoh.com</em></a><em> or </em><a href="https://www.instagram.com/sarahsgoh/"><em>@sarahsgoh</em></a><em>.</em></p></div>



<p>📸 <em>Featured Image: Photo via <a href="https://www.shutterstock.com/image-photo/high-speed-train-motion-on-railway-1661454721">Denis Belitsky</a>/<a href="http://shutterstock.com/">Shutterstock.com</a></em></p>



<pre><strong>Before you move on to the next story …</strong>
The <em>South Seattle Emerald</em> is brought to you by Rainmakers. Rainmakers give recurring gifts at any amount. With over 1,000 Rainmakers, the <em>Emerald</em> is truly community-driven local media. Help us keep BIPOC-led media free and accessible. 
 
If just half of our readers signed up to give $6 a month, we wouldn't have to fundraise for the rest of the year. Small amounts make a difference. 
 
<strong>We cannot do this work without you.</strong> <a href="https://southseattleemerald.kindful.com/">Become a Rainmaker today!</a></pre>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[F# RISC-V Instruction Set formal specification (127 pts)]]></title>
            <link>https://github.com/mrLSD/riscv-fs</link>
            <guid>36915108</guid>
            <pubDate>Sat, 29 Jul 2023 00:04:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mrLSD/riscv-fs">https://github.com/mrLSD/riscv-fs</a>, See on <a href="https://news.ycombinator.com/item?id=36915108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">RISC-V formal ISA Specification</h2>
<p dir="auto"><a href="https://travis-ci.org/mrLSD/riscv-fs" rel="nofollow"><img src="https://camo.githubusercontent.com/a5d7fb852a82237357f7af33f4202290c76f28fef8a039bcfc769114cc018185/68747470733a2f2f7472617669732d63692e6f72672f6d724c53442f72697363762d66732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/mrLSD/riscv-fs.svg?branch=master"></a></p>
<p dir="auto"><strong>Copyright © Evgeny Ukhanov</strong></p>
<p dir="auto">This is a formal (and executable) specification for the
RISC-V ISA (Instruction Set Architecture), written in
<strong>F# purely functional style</strong>. We deliberately choose
an "<em>extremely elementary</em>" implementation of F# to make it
readable and usable by wide audience who do not know F# and who
do not plan to learn F#.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3d3af88857328fa9c384afc75e6dad08edb7ed4285445657413472e08cbc1438/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f323437342f312a38385a6a2d514a713438495a54694347556f356d53512e706e67"><img src="https://camo.githubusercontent.com/3d3af88857328fa9c384afc75e6dad08edb7ed4285445657413472e08cbc1438/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f323437342f312a38385a6a2d514a713438495a54694347556f356d53512e706e67" alt="F# RISC-V ISA Formal Specification" data-canonical-src="https://miro.medium.com/max/2474/1*88Zj-QJq48IZTiCGUo5mSQ.png"></a></p>
<p dir="auto">This is a work-in-progress, one of several similar concurrent
efforts within the <strong>ISA Formal Specification</strong>
Technical Group constituted by The RISC-V Foundation
(<a href="https://riscv.org/" rel="nofollow">https://riscv.org</a>). We welcome your feedback, comments and suggestions.</p>
<h2 tabindex="-1" dir="auto">Content</h2>
<ul dir="auto">
<li><a href="#features--current-status">Features &amp; Current status</a></li>
<li><a href="#reading-the-code">Reading the code</a></li>
<li><a href="#how-to-build-and-run-it-on-risc-v-binaries">How to build and run it on RISC-V binaries</a>
<ul dir="auto">
<li><a href="#install-.net-sdk">Install .NET SDK</a></li>
<li><a href="#make-the-application-executable">Make the application executable</a></li>
<li><a href="#run-the-application-executable">Run the application executable</a></li>
</ul>
</li>
<li><a href="#how-to-contribute">How to Contribute</a></li>
<li><a href="#references">References</a></li>
<li><a href="#licence">Licence</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Features &amp; Current status</h2>
<ul dir="auto">
<li>Supports the following features (or <em>in active development state</em>)
<ul>
<li> Base instruction set: RV32I</li>
<li> Tests RV32I</li>
<li> Base instruction set: RV64I</li>
<li> Tests RV64I</li>
<li> Standard extension M (integer multiply/divide)</li>
<li> Tests for Standard extension M RV32/RV64</li>
<li> Standard extension A (atomic memory ops)</li>
<li> Tests for Standard extension A RV32/RV64</li>
</ul>
</li>
<li>Features under development
<ul dir="auto">
<li>Standard extension C (Compressed 16-bit instructions)</li>
<li>Standard extension F (Single-precision floating point)</li>
<li>Standard extension D (Double-precision floating point)</li>
<li>Privilege Level M (Machine)</li>
<li>Privilege Level U (User)</li>
<li>Privilege Level S (Supervisor)
<ul dir="auto">
<li>Virtual Memory schemes SV32, SV39 and SV48</li>
</ul>
</li>
</ul>
</li>
<li>Application can be executed as a F# program flexible with
CLI (<em>command line interface</em>) support, which in
turn executes RISC-V ELF binaries. This is a sequential
interpretation: one-instruction-at-a-time, sequential
memory model.</li>
<li>Tests passing for RISC-V <strong>under development</strong>:
<ul dir="auto">
<li>Basic instruction flow</li>
<li><code>rv32ui-p-*, rv64ui-p-*</code> (Base instruction set)</li>
<li><code>rv32um-p-*, rv64um-p-*</code> (M extension)</li>
<li><code>rv32ua-p-*, rv64ua-p-*</code> (A extension)</li>
<li><code>rv32uc-p-*, rv64uc-p-*</code> (C extension)</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Reading the code</h2>
<p dir="auto">We expect that many people might use this as a reading
reference (whether or not they build and execute it) to
clarify their understanding of RISC-V ISA semantics.</p>
<p dir="auto">Main part for reading Specification:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Decode*.fs</strong></p>
<p dir="auto">Decodes contain decoders for specific instructions set
and notified with instruction/extension set symbol. For example <code>DecodeI.fs</code></p>
</li>
<li>
<p dir="auto"><strong>Execute*.fs</strong></p>
<p dir="auto">Executes contain executions for specific instructions set
and notified with instruction/extension set symbol. For example <code>ExecuteI.fs</code></p>
</li>
<li>
<p dir="auto">Utilities:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>CLI.fs</code></p>
<p dir="auto">Contain helper function and types for
building effective CLI commands and options.</p>
</li>
<li>
<p dir="auto"><code>Bits.fs</code></p>
<p dir="auto">Basic type specific functions for
manipulations with <code>bits</code>.</p>
</li>
<li>
<p dir="auto"><code>Run.fs</code></p>
<p dir="auto">Basic Run flow - fetch, decode, execute,
logging execution flow.</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Architecture</p>
<ul dir="auto">
<li>
<p dir="auto"><code>Arch.fs</code></p>
<p dir="auto">Basic architecture types for RISC-V specification.</p>
</li>
<li>
<p dir="auto"><code>MachineState.fs</code></p>
<p dir="auto">Basic type and functions described
RISC-V machine state.</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Main app</p>
<ul dir="auto">
<li><code>Program.fs</code></li>
</ul>
<p dir="auto">Main application to execute <strong>RISC-V simulator/emulator</strong>.</p>
</li>
<li>
<p dir="auto">Test</p>
<ul dir="auto">
<li>
<p dir="auto"><code>Test/*.fs</code></p>
<p dir="auto">Contain unit-tests for instructions set
and extensions</p>
</li>
<li>
<p dir="auto">Test/asm/</p>
<p dir="auto">Contain Assembler test programs for
manual testing RISC-V CPI implementation.
It depend on <strong>risc-v toolchain</strong> and
it has special auto-build <code>Makefile</code>.</p>
</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">How to build and run it on RISC-V binaries</h2>
<p dir="auto">Application can be executed as a <em>sequential RISC-V simulator</em>
(sequential, one-instruction-at-a-time semantics), by
building and executing it as a standard F# program.</p>
<p dir="auto">Supported OS:</p>
<ul dir="auto">
<li>Linux</li>
<li>Windows</li>
<li>MacOS</li>
</ul>
<p dir="auto">Supported <strong>.NET SDK</strong>:</p>
<ul dir="auto">
<li>.NET SDK 2.2</li>
<li>.NET SDK 3.0</li>
</ul>
<h3 tabindex="-1" dir="auto">Install .NET SDK</h3>
<p dir="auto">For Windows preferred way to use Visual Studio.</p>
<p dir="auto">Other examples will be for Linux.
Please follow to instruction <a href="https://dotnet.microsoft.com/download" rel="nofollow">https://dotnet.microsoft.com/download</a></p>
<p dir="auto">For Ubuntu:</p>
<div data-snippet-clipboard-copy-content="$ wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
$ sudo dpkg -i packages-microsoft-prod.deb
$ sudo apt-get update
$ sudo apt-get install apt-transport-https
$ sudo apt-get update
$ sudo apt-get install dotnet-sdk-3.0"><pre><code>$ wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
$ sudo dpkg -i packages-microsoft-prod.deb
$ sudo apt-get update
$ sudo apt-get install apt-transport-https
$ sudo apt-get update
$ sudo apt-get install dotnet-sdk-3.0
</code></pre></div>
<p dir="auto">To check installation:</p>
<p dir="auto"><code>$ dotnet --version</code></p>
<p dir="auto">will tell you what version of <code>dotnet</code> you have.</p>
<h3 tabindex="-1" dir="auto">Make the application executable</h3>
<p dir="auto">You can build the application executable with:</p>
<p dir="auto"><code>$ dotnet build</code></p>
<h3 tabindex="-1" dir="auto">Run the application executable</h3>
<p dir="auto">Most simple way to run immediately <code>run</code> (without
additional <code>build</code> command) to see command-line
options on the executable:</p>
<p dir="auto"><code>$ dotnet run -- --help</code></p>
<p dir="auto">If you run the application without option:</p>
<p dir="auto"><code>$ dotnet run</code></p>
<p dir="auto">you'll receive error message:</p>
<blockquote>
<p dir="auto">Wrong parameters put --help to get more information</p>
</blockquote>
<p dir="auto"><strong>Example</strong> to run specific ISA with extensions, verbosity
output and ELF file for execution in RISC-V CPI simulator:</p>
<p dir="auto"><code>$ dotnet run -- -A rv32i -v myapp.elf</code></p>
<h2 tabindex="-1" dir="auto">How to Contribute</h2>
<p dir="auto">Please read file <a href="https://github.com/mrLSD/riscv-fs/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h2 tabindex="-1" dir="auto">References</h2>
<ul dir="auto">
<li>github ISA manual: <a href="https://github.com/riscv/riscv-isa-manual">https://github.com/riscv/riscv-isa-manual</a></li>
<li>RISC-V specification: <a href="https://riscv.org/specifications/" rel="nofollow">https://riscv.org/specifications/</a></li>
<li>RISC-V Formal Verification Framework: <a href="https://github.com/SymbioticEDA/riscv-formal">https://github.com/SymbioticEDA/riscv-formal</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Licence</h2>
<p dir="auto"><strong>MIT License</strong></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite-Utils (122 pts)]]></title>
            <link>https://sqlite-utils.datasette.io/en/stable/index.html</link>
            <guid>36914612</guid>
            <pubDate>Fri, 28 Jul 2023 23:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite-utils.datasette.io/en/stable/index.html">https://sqlite-utils.datasette.io/en/stable/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=36914612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          

  
  <p>
  <a href="https://github.com/simonw/sqlite-utils/edit/c728c255556becc0de6fe73d45008f75f838cb68/docs/index.rst" title="Edit this page">
    
    <span>Edit this page</span>
  </a>
</p>
          <p><label for="__toc">
            <p>Toggle table of contents sidebar</p>
            <i><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No-GIL mode coming for Python (345 pts)]]></title>
            <link>https://lwn.net/Articles/939568/</link>
            <guid>36914401</guid>
            <pubDate>Fri, 28 Jul 2023 22:47:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/939568/">https://lwn.net/Articles/939568/</a>, See on <a href="https://news.ycombinator.com/item?id=36914401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
The Python Steering Council has <a href="https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474">announced
its intent</a> to accept <a href="https://peps.python.org/pep-0703/">PEP
703 (Making the Global Interpreter Lock Optional in CPython)</a>, with
initial support possibly showing up in the 3.13 release.  There are still
some details to work out, though.
</p><blockquote>
	We want to be very careful with backward compatibility. We do not
	want another Python 3 situation, so any changes in third-party code
	needed to accommodate no-GIL builds should just work in with-GIL
	builds (although backward compatibility with older Python versions
	will still need to be addressed). This is not Python 4. We are
	still considering the requirements we want to place on ABI
	compatibility and other details for the two builds and the effect
	on backward compatibility.
</blockquote><br clear="all"><hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/939568/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX punched a hole in the ionosphere (284 pts)]]></title>
            <link>https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/</link>
            <guid>36913835</guid>
            <pubDate>Fri, 28 Jul 2023 21:50:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/">https://spaceweatherarchive.com/2023/07/23/spacex-punched-a-hole-in-the-ionosphere/</a>, See on <a href="https://news.ycombinator.com/item?id=36913835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<main id="main" role="main">

					
			
<article id="post-5582">
	<!-- .entry-header -->

	<div>
		
<p><strong>July 20, 2023:</strong> On the evening of July 19th, SpaceX launched a Falcon 9 rocket from Vandenberg Space Force Base in California. Sky watchers from southern California to Arizona witnessed a <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=197985">magnificent exhaust plume</a>. At the San Francisco Volcanic Field north of Flagstaff, photographer Jeremy Perez saw something extra:</p>



<figure><a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198036"><img src="https://spaceweather.com/images2023/21jul23/redglow_strip2.jpg" alt=""></a></figure>



<p>“After the rocket passed overhead, a red fluorescent glow expanded southward and crossed over the Milky Way,” says Perez. “It was visible for almost 20 minutes.”</p>



<p>The red glow is a sign that the rocket punched a hole in the ionosphere–something SpaceX and others have been doing for years. One famous example occured on August 25, 2017, when a Falcon 9 rocket carrying Taiwan’s FORMOSAT-5 satellite <a href="https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2017SW001738">created a hole</a> four times bigger than the state of California. On June 19, 2022, another Falcon 9 <a href="https://spaceweather.com/archive.php?day=21&amp;month=06&amp;year=2022&amp;view=view">punched a hole</a> over the east coast of the USA, sparking a display of red lights from New York to the Carolinas that many observers mistook for aurora borealis.</p>



<p>“This is a <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2008SW000406">well studied phenomenon</a> when rockets are burning their engines 200 to 300 km above Earth’s surface,” explains space physicist Jeff Baumgardner of Boston University. “The red glow appears when exhaust gasses from the rocket’s 2nd stage cause the ionosphere to recombine quickly.”</p>



<p>Rocket engines spray water (H<sub>2</sub>O) and carbon dioxide (CO<sub>2</sub>) into the ionosphere, quenching local ionization by as much as 70%. A complicated series of charge exchange reactions between oxygen ions (O<sup>+</sup>) and molecules from the rocket exhaust produce photons at a wavelength of 6300 Å–the same color as red auroras.</p>



<p>This movie from David Blanchard outside Flagstaff shows how the red glow developed as the silvery rocket exhaust faded into the ionosphere:</p>



<figure><a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198052"><img src="https://spaceweather.com/images2023/21jul23/db_anim_strip.gif" alt=""></a></figure>



<p>“I watched the show from Upper Lake Mary in the Coconino National Forest,” says Blanchard. “The exhaust plume was spectacular.”</p>



<p>Baumgardner reviewed SpaceX’s video footage from the July 19th launch. “It shows the second stage engine burning at 286 km near the ionosphere’s F-region peak for that time of day. So, it is quite possible that an ionospheric ‘hole’ was made,” he says.</p>



<p>Once rare, ionospheric “punch holes” are increasingly common with <a href="https://www.nature.com/articles/d41586-023-00048-7">record numbers of rocket launches</a> led by SpaceX sending Starlink satellites to low-Earth orbit. Ham radio operators may notice them when shortwave signals fail to skip over the horizon, shooting through holes instead of bouncing back to Earth. Sudden GPS errors can also result from the anomalies. These effects may be troublesome, but they are shortlived; re-ionization occurs as soon as the sun comes up again.</p>



<p>Readers, did you see a red glow from this week’s SpaceX launch? <a href="https://spaceweathergallery2.com/submissions/index.php">Submit your photos here</a>.</p>



<p><strong>more images:</strong> <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198054">from Cheryl Hanscom Wilcox</a> of Mammoth Lakes, CA; <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198055">from MaryBeth Kiczenski</a> in the San Juan Mountains of Colorado; <a href="https://spaceweathergallery2.com/indiv_upload.php?upload_id=198049">from Richard Rast</a> of Mountainair, New Mexico;</p>
			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mess with DNS (104 pts)]]></title>
            <link>https://messwithdns.net</link>
            <guid>36913569</guid>
            <pubDate>Fri, 28 Jul 2023 21:24:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://messwithdns.net">https://messwithdns.net</a>, See on <a href="https://news.ycombinator.com/item?id=36913569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" v-else="">
                <h2>
                    Welcome to mess with dns!
                </h2>
                <p>
                    It's fun to learn by experimenting and
                    breaking things!
                    Here you can do weird DNS experiments
                    with no consequences if you mess something up.
                </p>
                

                <p>
                    Click the button below to get started.
                </p>
                <div>
                    <!-- login with github -->
                    <p><a id="start-experimenting" href="https://messwithdns.net/login">
                        Start experimenting
                    </a>
                </p></div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intent to approve PEP 703: making the GIL optional (401 pts)]]></title>
            <link>https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474</link>
            <guid>36913328</guid>
            <pubDate>Fri, 28 Jul 2023 21:07:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474">https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474</a>, See on <a href="https://news.ycombinator.com/item?id=36913328">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="A Steering Council notice about PEP 703 (Making the Global Interpreter Lock Optional in CPython)">
        <meta itemprop="articleSection" content="Core Development">
      <meta itemprop="keywords" content="">
      

          <div itemprop="articleBody" id="post_1">
              <p>Posting for the whole Steering Council, on the subject of <a href="https://discuss.python.org/u/colesbury">@colesbury</a>’s <a href="https://peps.python.org/pep-0703/">PEP 703 (Making the Global Interpreter Lock Optional in CPython)</a>.</p>
<p>Thank you, everyone, for responding to the <a href="https://discuss.python.org/t/poll-feedback-to-the-sc-on-making-cpython-free-threaded-and-pep-703/28540">poll on the no-GIL proposal</a>. It’s clear that the overall sentiment is positive, both for the general idea and for PEP 703 specifically. The Steering Council is also largely positive on both. We intend to accept PEP 703, although we’re still working on the acceptance details.</p>
<p>As we’ve done a few times in the past, we want to communicate our intent to accept the PEP along with where our current thinking is on the details around acceptance.</p>
<p>Our base assumptions are:</p>
<ul>
<li>Long-term (probably 5+ years), the no-GIL build should be the only build. We do not want to create a permanent split between with-GIL and no-GIL builds (and extension modules).</li>
<li>We want to be very careful with backward compatibility. We do not want another Python 3 situation, so any changes in third-party code needed to accommodate no-GIL builds should just work in with-GIL builds (although backward compatibility with older Python versions will still need to be addressed). This is not Python 4. We are still considering the requirements we want to place on ABI compatibility and other details for the two builds and the effect on backward compatibility.</li>
<li>Before we commit to switching entirely to the no-GIL build, we need to see community support for it. We can’t just flip the default and expect the community to figure out what work they need to do to support it. We, the core devs, need to gain experience with the new build mode and all it entails. We will probably need to figure out new C APIs and Python APIs as we sort out thread safety in existing code. We also need to bring along the rest of the Python community as we gain those insights and make sure the changes we want to make, and the changes we want them to make, are palatable.</li>
<li>We want to be able to change our mind if it turns out, any time before we make no-GIL the default, that it’s just going to be too disruptive for too little gain. Such a decision could mean rolling back all of the work, so until we’re certain we want to make no-GIL the default, code specific to no-GIL should be somewhat identifiable.</li>
</ul>
<p>As such, what we currently see as the way forward is three stages:</p>
<ul>
<li>Short term, we add the no-GIL build as an experimental build mode, presumably in 3.13 (if it slips to 3.14, that is not a problem). We want the build mode to be experimental to make it clear that while the core devs support that build mode, we can’t expect the community to support it outright. We need time to figure out what we need to do, at the very least in terms of API design and packaging and distribution, to enable the community to support it. We also want to discourage distributors from shipping the experimental no-GIL build as a default interpreter.</li>
<li>Mid-term, after we have confidence that there is enough community support to make production use of no-GIL viable, we make the no-GIL build supported but not the default (yet), and set a target date/Python version for making it the default. The timing is going to depend a lot on, for example, how backward compatible the API changes end up being (e.g., what to do about the stable ABI), and how much work the community thinks they still need to do. We expect this to take at least a year or two, possibly more. Once we declare it supported we expect some distributors may start shipping no-GIL by default, although it will probably vary greatly by how many other Python packages support no-GIL at that point.</li>
<li>Long-term, we want no-GIL to be the default, and to remove any vestiges of the GIL (without unnecessarily breaking backward compatibility). We don’t want to wait too long with this, because having two common build modes may be a heavy burden on the community (as, for example, it can double test resources and debugging scenarios), but we can’t rush it either. We think it may take as much as five years to get to this stage.</li>
</ul>
<p>Throughout the process we (the core devs, not just the SC) will need to re-evaluate the progress and the suggested timelines. We don’t want this to turn into another ten year backward compatibility struggle, and we want to be able to call off PEP 703 and find another solution if it looks to become problematic, and so we need to regularly check that the continued work is worth it.</p>
<p>We hope that this gives some clarity into the future of the PEP while we work on the exact acceptance details. The SC will work to finalise the acceptance over the coming weeks.</p>
            </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/bjkeefe"><span itemprop="name">bjkeefe</span></a>
                (bjkeefe)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T22:39:51Z">
                    July 28, 2023, 10:39pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T22:39:51Z">
              <span itemprop="position">2</span>
              </span>
            </p></div>
            <p>I wish I had the words to express my gratitude for the work that you folks put in on things like this.  I don’t, so, just: thank you, so much.  Another reason why I am really glad I decided to start teaching myself Python.</p>

            

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I respect the decision however unfortunately I am not in favor of it. Nevertheless I hope for and wish the core devs all the success and luck for a good positive outcome.</p>

            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/Eclips4"><span itemprop="name">Eclips4</span></a>
                (Kirill Podoprigora)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T23:00:43Z">
                    July 28, 2023, 11:00pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T23:00:43Z">
              <span itemprop="position">4</span>
              </span>
            </p></div>
            <p>Glad to hear that news. That’s incredible news for CPython. I hope that I can help in some way in realization of it. Good luck!</p>

            

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/diegor"><span itemprop="name">diegor</span></a>
                (Diego Russo)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-28T23:26:27Z">
                    July 28, 2023, 11:26pm
                  </time>
                  <meta itemprop="dateModified" content="2023-07-28T23:26:27Z">
              <span itemprop="position">5</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Thanks for the carefulness you are applying to the whole process whilst being positive in getting the changes. The whole CPython community will really appreciate <em>not</em> to have again a python2/3 situation.</p>
<p>Thanks and good luck!</p>
            </div>

            

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/itamaro"><span itemprop="name">itamaro</span></a>
                (Itamar Oren)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T00:11:20Z">
                    July 29, 2023, 12:11am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T00:11:20Z">
              <span itemprop="position">6</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Thank you for sharing this notice in anticipation of the official acceptance - this is super exciting!</p>
<p><a href="https://discuss.python.org/u/colesbury">@colesbury</a> is currently out on vacation, but should be back in a couple of weeks.<br>
We at Meta are excited about the intention to accept PEP-703, and are looking forward to getting to work on a smooth landing of the implementation!</p>
            </div>

            

            

          </div>
          <div itemprop="comment" id="post_7" itemscope="" itemtype="http://schema.org/Comment">
              
<p>I’m happy to be an early adopter, and I know that a handful of packages have already been modified to work with <code>nogil</code>. Are those versions available somewhere?</p>
<p>Maybe this question is jumping the gun and there will be a more “official” way to do this in the future?</p>
            </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/ofek"><span itemprop="name">ofek</span></a>
                (Ofek Lev)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T01:23:48Z">
                    July 29, 2023,  1:23am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T01:23:48Z">
              <span itemprop="position">8</span>
              </span>
            </p></div>
            <p>I am absolutely elated! When the initial implementation is released I will make sure we promptly begin testing <a href="https://discuss.python.org/t/pep-703-making-the-global-interpreter-lock-optional-3-12-updates/26503/92">at work</a>.</p>

            

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/Tinche"><span itemprop="name">Tinche</span></a>
                (Tin Tvrtković)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T01:52:42Z">
                    July 29, 2023,  1:52am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T01:52:42Z">
              <span itemprop="position">9</span>
              </span>
            </p></div>
            <p>Huge congratulations to everyone involved! Exciting times ahead.</p>

            

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/davidism"><span itemprop="name">davidism</span></a>
                (David Lord)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:09:06Z">
                    July 29, 2023,  2:09am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:09:06Z">
              <span itemprop="position">10</span>
              </span>
            </p></div>
            <p>Excited to follow this! As soon as cibuildwheel supports it, I’ll add the additional wheels for MarkupSafe. Or add some experimental builds somewhere before that.</p>

            

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/rednafi"><span itemprop="name">rednafi</span></a>
                (Redowan Delowar)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:43:25Z">
                    July 29, 2023,  2:43am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:43:25Z">
              <span itemprop="position">11</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>I’m beyond stoked for this. If Python can run truly concurrent code without sacrificing the current single core execution speed of 3.12, that’d be a huge win for the community and people who are heavily invested in this ecosystem.</p>
<p>I’ll start testing it on my code the moment the nogil flag becomes publicly available. Also curious to see how it’ll break single threaded code with tons of mutable state.</p>
            </div>

            

            

          </div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.python.org/u/rednafi"><span itemprop="name">rednafi</span></a>
                (Redowan Delowar)
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-07-29T02:45:02Z">
                    July 29, 2023,  2:45am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-29T02:45:02Z">
              <span itemprop="position">12</span>
              </span>
            </p></div>
            <p>Meta is doing some fantastic work on the LLM side as well as on the core Python side. This is fantastic to see <img src="https://emoji.discourse-cdn.com/apple/pray.png?v=12" title=":pray:" alt=":pray:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>This is delightful news! I will make it a goal to get PyO3 ready to support nogil / PEP 703 as soon as possible!</p>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The U.K. government is close to eroding encryption worldwide (570 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide</link>
            <guid>36913268</guid>
            <pubDate>Fri, 28 Jul 2023 21:01:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide">https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide</a>, See on <a href="https://news.ycombinator.com/item?id=36913268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The U.K. Parliament is pushing ahead with a sprawling internet regulation bill that will, among other things, undermine the privacy of people around the world. The </span><a href="https://bills.parliament.uk/bills/3137"><span>Online Safety Bill</span></a><span>, now </span>at the final<span> stage before passage in the House of Lords, gives the British government the ability to force backdoors into messaging services, which will destroy end-to-end encryption. No amendments have been accepted that would mitigate the bill’s most dangerous elements.&nbsp;</span></p>
<p><a href="https://eff.org/osb">TAKE ACTION</a></p>
<p><a href="https://eff.org/osb">TELL&nbsp;the U.K. Parliament: Don't Break Encryption</a></p>
<p>If it passes, the Online Safety Bill will be a huge step backwards for global privacy, and democracy itself. Requiring government-approved software in peoples’ messaging services is an awful precedent. If the Online Safety Bill becomes British law, the damage it causes won’t stop at the borders of the U.K.&nbsp;</p>
<p><span>The sprawling bill, which originated in a </span><a href="https://commonslibrary.parliament.uk/research-briefings/cbp-8743/"><span>white paper</span></a><span> on “online harms” that’s now more than four years old, would be </span><a href="https://www.theverge.com/23708180/united-kingdom-online-safety-bill-explainer-legal-pornography-age-checks"><span>the most wide-ranging internet regulation ever passed</span></a><span>. At EFF, we’ve been </span><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>clearly speaking about its disastrous effects</span></a><span> for more than a year now.&nbsp;</span></p>
<p><span>It would require content filtering, as well as age checks to access erotic content. The bill also requires detailed reports about online activity to be sent to the government. Here, we’re discussing just one fatally flawed aspect of OSB—how it will break encryption.&nbsp;</span></p>
<h3><strong><span>An Obvious Threat To Human Rights</span></strong></h3>
<p><span>It’s a basic human right to have a private conversation. To have those rights realized in the digital world, the best technology we have is end-to-end encryption. And it’s utterly incompatible with the government-approved message-scanning technology required in the Online Safety Bill.&nbsp;</span></p>
<p><span>This is because of something that EFF </span><a href="https://www.eff.org/deeplinks/2015/12/encryption-balance-2015-review"><span>has been saying for years</span></a><span>—there is no backdoor to encryption that only gets used by the “good guys.” Undermining encryption, whether by banning it, pressuring companies away from it, or requiring </span><a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"><span>client side scanning</span></a><span>, will be a boon to bad actors and authoritarian states.</span></p>
<p><span>The U.K. government wants to grant itself the right to scan every message online for content related to child abuse or terrorism—and says it will still, somehow, magically, protect peoples’ privacy. That’s simply impossible. </span><a href="https://www.eff.org/deeplinks/2022/11/experts-condemn-uk-online-safety-bill-harmful-privacy-and-encryption"><span>U.K. civil society groups</span></a><span> have condemned the bill, as have technical experts and </span><a href="https://www.globalencryption.org/2022/11/70-organizations-cyber-security-experts-and-elected-officials-sign-open-letter-expressing-dangers-of-the-uks-online-safety-bill/"><span>human rights groups around the world</span></a><span>.&nbsp;</span></p>
<p><span>The companies that provide encrypted messaging—such as WhatsApp, Signal, and the UK-based Element—have also explained the bill’s danger. In an </span><a href="https://element.io/blog/the-online-safety-bill-an-attack-on-encryption/"><span>open letter published in April</span></a><span>, they explained that OSB “could break end-to-end encryption, opening the door to routine, general and indiscriminate surveillance of personal messages of friends, family members, employees, executives, journalists, human rights activists and even politicians themselves.” Apple </span><a href="https://www.theregister.com/2023/06/29/apple_online_safety_bill_opposition/"><span>joined</span></a><span> this group in June, stating publicly that the bill threatens encryption and “could put U.K. citizens at greater risk.”&nbsp;</span></p>
<h3><strong><span>U.K. Government Says: Nerd Harder</span></strong></h3>
<p><span>In response to this outpouring of resistance, the U.K. government’s response has been to wave its hands and deny reality.</span> <span>In a response letter to the House of Lords seen by EFF, the U.K.’s Minister for Culture, Media and Sport simply re-hashes an imaginary world in which messages can be scanned while user privacy is maintained. “We have seen companies develop such solutions for platforms with end-to-end encryption before,” the letter states, a reference to <a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption">client-side scanning</a>. “Ofcom should be able to require” the use of such technologies, and where “off-the-shelf solutions” are not available, “it is right that the Government has led the way in exploring these technologies.”&nbsp;</span></p>
<p><span>The letter refers to the Safety Tech Challenge Fund, a program in which the U.K. gave small grants to companies to develop software that would allegedly protect user privacy while scanning files. But of course, they couldn’t square the circle. The grant winners’ </span><a href="https://express.adobe.com/page/vxBuQnoqvGhYE/"><span>descriptions of their own prototypes</span></a><span> clearly describe different forms of client-side scanning, in which user files are scoped out with AI before they’re allowed to be sent in an encrypted channel.&nbsp;</span></p>
<p><span>The Minister completes his response on encryption by writing:&nbsp;</span></p>
<blockquote><p><span>We expect the industry to use its extensive expertise and resources to innovate and build robust solutions for individual platforms/services that ensure both privacy and child safety by preventing child abuse content from being freely shared on public and private channels.</span></p>
</blockquote>
<p><span>This is just repeating a fallacy that we’ve heard for years: that if tech companies can’t create a backdoor that magically defends users, they must simply “nerd harder.”&nbsp;</span></p>
<h3><span></span><span>British Lawmakers Still Can And Should Protect Our Privacy</span></h3>
<p><span> U.K. lawmakers still have a chance to stop their nation from taking this shameful leap forward towards mass surveillance. </span>End-to-end encryption was not fully considered and voted on during either committee or report stage in the House of Lords. The Lords can still add a simple amendment that would protect private messaging, and specify that end-to-end encryption won’t be weakened or removed.</p>
<p>Earlier this month, <span>EFF joined U.K. civil society groups and sent </span><a href="https://www.eff.org/files/2023/07/14/all_peers_letter_-_online_safety_bill_lords_committee_stage.pdf"><span>a briefing explaining our position</span></a><span> to the House of Lords. The briefing explains the encryption-related problems with the current bill, and proposes the adoption of an amendment that will protect end-to-end encryption. If such an amendment is not adopted, those who pay the price will be “human rights defenders and journalists who rely on private messaging to do their jobs in hostile environments; and … those who depend on privacy to be able to express themselves freely, like LGBTQ+ people.”&nbsp;</span></p>
<p>It’s a remarkable failure that the House of Lords has not even taken up a serious debate over protecting encryption and privacy, despite ample time to review every every section of the bill.&nbsp;</p>
<p><a href="https://eff.org/osb">TAKE ACTION</a></p>
<p><a href="https://eff.org/osb">TELL the U.K. Parliament:&nbsp;PROTECT Encryption</a>—And our privacy</p>
<p><span>Finally, Parliament should reject this bill because universal scanning and surveillance is abhorrent to their own constituents. It is not what the British people want. </span><a href="https://element.io/blog/end-to-end-encryption-the-will-of-the-british-people/"><span>A recent survey of U.K. citizens</span></a><span> showed that 83% wanted the highest level of security and privacy available on messaging apps like Signal, WhatsApp, and Element.&nbsp;</span></p>
<p><span>Documents related to the U.K. Online Safety Bill:&nbsp;</span></p>
<ul>
<li><span>EFF info page on the <a href="https://www.eff.org/pages/uk-online-safety-bill-massive-threat-online-privacy-security-and-speech">U.K. Online Safety Bill</a></span></li>
<li><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>EFF Deeplinks Blog</span></a><span>: How the OSB attacks Free Speech and Encryption (August 2022)&nbsp;</span></li>
<li><span><a href="https://www.eff.org/deeplinks/2021/07/uks-draft-online-safety-bill-raises-serious-concerns-around-freedom-expression">EFF Deeplinks Blog</a>:&nbsp;UK's Draft Online Safety Bill Raises Serious Concerns Around Freedom of Expression (July 2021)</span></li>
<li><a href="https://www.globalencryption.org/2022/11/70-organizations-cyber-security-experts-and-elected-officials-sign-open-letter-expressing-dangers-of-the-uks-online-safety-bill/"><span>Civil society open letter</span></a><span> on Online Safety Bill (November 2022)</span></li>
<li><a href="https://element.io/blog/the-uks-online-safety-bill-undermines-everyones-safety/"><span>Open Letter</span></a><span> from encrypted messaging providers about Online Safety Bill (April 2023)&nbsp;</span></li>
<li><span>EFF and Allied NGOs </span><a href="https://www.eff.org/files/2023/07/14/joint_civil_society_briefing_for_peers_on_private_messaging_-_report_stage.pdf"><span>Briefing to House of Lords</span></a><span> (July 2023)&nbsp;&nbsp;</span></li>
</ul>


</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lonely Work of Moderating Hacker News (2019) (216 pts)]]></title>
            <link>https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news</link>
            <guid>36911923</guid>
            <pubDate>Fri, 28 Jul 2023 19:22:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news">https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news</a>, See on <a href="https://news.ycombinator.com/item?id=36911923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="IframeEmbed"></figure><p>Open-plan offices offer few pleasures; one of them is snooping on other people’s browsing habits. When, years ago, I began working for tech companies in San Francisco, I noticed that my co-workers were always scrolling through a beige, text-only Web site that resembled a nineteen-nineties Internet forum. They were reading Hacker News—a link aggregator and message board that is something of a Silicon Valley institution. Technologists in Silicon Valley assume familiarity with Hacker News, just as New Yorkers do with the New York <em>Post</em> and the New York <em>Times</em>. For some, it’s the first Web site they pull up in the morning; it captures the mix of technical obsession, business ambition, and aspirational curiosity that’s typical of the Valley. On any given day, its top links might include a Medium post about <a href="https://medium.com/swlh/brief-thoughts-on-getting-hired-as-a-senior-coder-94f38998bb08">technical hiring</a>; a 1997 article from <em>Outside</em> magazine about <a href="https://www.outsideonline.com/2152131/freezing-death?page=all">freezing to death</a>; an open-source <a data-offer-url="https://news.ycombinator.com/item?id=20571739" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=20571739&quot;}" href="https://news.ycombinator.com/item?id=20571739" rel="nofollow noopener" target="_blank">virtual private network</a> hosted on GitHub; an <a href="http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf">academic paper</a>, from 2006, about compiler construction; an <a data-offer-url="https://news.ycombinator.com/item?id=20297446" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=20297446&quot;}" href="https://news.ycombinator.com/item?id=20297446" rel="nofollow noopener" target="_blank">announcement</a> from Facebook’s corporate communications team; a personal blog post about Linux kernels, and another about <a data-offer-url="https://www.deepsouthventures.com/i-sell-onions-on-the-internet/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.deepsouthventures.com/i-sell-onions-on-the-internet/&quot;}" href="https://www.deepsouthventures.com/i-sell-onions-on-the-internet/" rel="nofollow noopener" target="_blank">selling Vidalia onions</a> on the Internet. Nearly all the software engineers I know check it religiously. Not one of them has a neutral opinion about it.</p><p>Like many of the software products that have shaped the Valley, Hacker News began as a side project. In 2007, the venture capitalist Paul Graham, who was then the president of the startup accelerator Y Combinator—an early investor in Dropbox, Stripe, Reddit, Twitch, and other companies—built the site as a way to experiment with Arc, a new programming language that he was co-authoring. Originally, Graham named the site Startup News. He hoped that it would serve as a new home for the startup founders and “would-be founders” who had once gathered on Reddit, before that site grew too popular to feel like a community. Among other benefits, he imagined that Startup News might help him find worthy entrepreneurs. (“There are a number of Reddit users that I know only by their usernames, but I know must be smart from the things they’ve written,” he explained, in his launch announcement. “We’re counting on the same phenomenon to help us decide who to fund.”) Within a few months, though, Graham found that startup-centric conversation had its limits. He renamed the site Hacker News, and expanded its focus to include “anything that good hackers would find interesting&nbsp;.&nbsp;.&nbsp;. anything that gratifies one’s intellectual curiosity.” (Hacker News is still owned by Y Combinator.)</p><p>The site was intentionally simple. It offered a dynamic list of links, submitted by users, each of which could be expanded into its own unique comment thread. Readers could upvote or downvote links and comments, and the top thirty links would be featured on the front page. The guidelines specified that most non-tech-related news—political news, in particular—was off topic. Users discussed the merits of relational databases, the complexities of co-founder relationships, and the pros and cons of dropping out of college. They exchanged screenshots of their work environments and compared their results on a “nerd quiz” that asked them to name a programming language for every letter of the alphabet. They commented on Graham’s essays about programming and entrepreneurship—“Like chess or painting or writing novels,” he <a data-offer-url="https://news.ycombinator.com/item?id=811433" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=811433&quot;}" href="https://news.ycombinator.com/item?id=811433" rel="nofollow noopener" target="_blank">wrote</a>, “making money is a very specialized skill”—and shared advice on how to get into Y Combinator.</p><p>At first, the site attracted about sixteen hundred daily visitors, and Graham moderated and maintained it himself. Today, around five million people read Hacker News each month, and it’s grown more difficult to moderate. The technical discussions remain varied and can be insightful. But social, cultural, and political conversations, which, despite the guidelines, have proliferated, tend to devolve. A recent comment thread about <a href="https://www.nytimes.com/2019/06/05/business/youtube-remove-extremist-videos.html">a <em>Times</em> article</a>, “YouTube to Remove Thousands of Videos Pushing Extreme Views,” yielded a response likening journalism and propaganda; a muddled juxtaposition of pornography and Holocaust denial; a vague side conversation about the average I.Q. of Hacker News commenters; and confused analogies between white supremacists and Black Lives Matter activists. In April, when <a href="https://www.bbc.com/news/science-environment-47891902">a story</a> about Katie Bouman, an M.I.T. researcher who helped develop a technology that captured the first photo of a black hole, rose to the front page, users combed through her code on GitHub in an effort to undermine the weight of her contributions.</p><p>The site’s now characteristic tone of performative erudition—hyperrational, dispassionate, contrarian, authoritative—often masks a deeper recklessness. Ill-advised citations proliferate; thought experiments abound; humane arguments are dismissed as emotional or irrational. Logic, applied narrowly, is used to justify broad moral positions. The most admired arguments are made with data, but the origins, veracity, and malleability of those data tend to be ancillary concerns. The message-board intellectualism that might once have impressed V.C. observers like Graham has developed into an intellectual style all its own. Hacker News readers who visit the site to learn how engineers and entrepreneurs talk, and what they talk about, can find themselves immersed in conversations that resemble the output of duelling Markov bots trained on libertarian economics blogs, “The Tim Ferriss Show,” and the work of Yuval Noah Harari.</p><p>People have been trying to outsmart one another on Internet forums for as long as there have been Internet forums. Still, Hacker News has an unusually wide influence. Landing a blog post or personal project on the front page is a badge of honor for many technologists, and the site has become a regional export: ninety per cent of its traffic comes from outside the Bay Area, and a third of its users are in Europe. The site is now a portal to tech culture for millions of people. At the same time, it has become a punch line and a punching bag for tech workers and engineers who see it as a locus of hubris, myopia, and exclusivity. A word that comes up frequently among its critics is “toxic.”</p><p>Picturing the moderators responsible for steering conversation on Hacker News, I imagined a team of men who proudly self-identify as neoliberals and are active in the effective-altruism movement. (I assumed they’d be white men; it never occurred to me that women, or people of color, could be behind the site.) Meeting them, I feared, would be like participating in a live-action comment thread about the merits of Amazon Web Services or whether women should be referred to as “females.” “Debate us!” I imagined them saying, in unison, from their Aeron chairs.</p><p>The site’s real-life moderators are Daniel Gackle and Scott Bell, two wildly polite old friends. On Facebook and <a href="https://www.newyorker.com/tech/annals-of-technology/the-fight-for-the-future-of-youtube">YouTube</a>, moderation is often done reactively and anonymously, by teams of overworked contractors; on <a href="https://www.newyorker.com/magazine/2018/03/19/reddit-and-the-struggle-to-detoxify-the-internet">Reddit</a>, teams of employees purge whole user communities like surgeons removing tumors. Gackle and Bell, by contrast, practice a personal, focussed, and slow approach to moderation, which they see as a conversational act. They treat their community like an encounter group or Esalen workshop; often, they correspond with individual Hacker News readers over e-mail, coaching and encouraging them in long, heartfelt exchanges.</p><p>Gackle and Bell met in Calgary, in the early two-thousands, at a local user group for the rarefied programming language Lisp. (Arc, the language in which Hacker News is written, is a descendant of it.) Gackle, whose name is pronounced “Gack-lee” and who declined to share his age, is a muscular, bald, and loquacious father of two and a devoted fan of the Canadian sketch-comedy show “The Kids in the Hall.” Bell, who is thirty-four, is willowy and soft-spoken, with closely buzzed hair and tattoos that peek out from beneath his cardigans. The two often finish each other’s sentences; they sometimes dress, accidentally, in matching outfits. (Bell attributes this to office-wide “sartorial mimetics.”) Online and in person, Gackle is chatty, Bell reserved. They are reluctant, protective spokespeople. Pressed to describe Hacker News, they do so by means of extravagant, sometimes tender metaphors: the site is a “social ecosystem,” a “hall of mirrors,” a “public park or garden,” a “fractal tree.”</p><p>“Hacker News is quite a counterintuitive thing,” Gackle said, in a conference room in Y Combinator’s San Francisco office. “At least how we see it, from our perspective, it’s often pretty different from how it appears from the outside.”</p><p>“It doesn’t grab you right away, just on the surface,” Bell said, his hands cradling a mug of tea. “It takes a little bit to get a feel for what it is.”</p><p>“The Hacker News front page is a product of a certain tension,” Gackle said. “There’s multiple tug-of-wars going on over the types of stories people would like to see. The one consensus is that it’s not as good as it used to be. I feel bad when people say that, but I also realize that, in a way, it indicates a certain attachment.”</p><p>“There are some people who don’t realize Hacker News is moderated at all,” Bell continued. “There are some people with whom we’ve been e-mailing for four or five years. My guess is that the distribution is somewhat mostly in the middle. But I don’t know.” He turned to Gackle, looking grave. “I don’t have a strong sense of that. Do you, Dan?”</p><p>“I don’t think I can answer it,” Gackle said, intently. “One of the things I’ve learned is that almost all of the generalizations are wrong. And I’ve learned this because people love to post generalizations about Hacker News to Hacker News.”</p><p>In an Emacs file, Gackle collects a list of contradictory statements that people have used to describe Hacker News. (“SJW cesspool”; “<a data-offer-url="https://news.ycombinator.com/item?id=14205262" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=14205262&quot;}" href="https://news.ycombinator.com/item?id=14205262" rel="nofollow noopener" target="_blank">a haven</a> for alt-right and libertarian people”; “If you don’t support neoliberal fantasies, your comments <a data-offer-url="https://news.ycombinator.com/item?id=14529468" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=14529468&quot;}" href="https://news.ycombinator.com/item?id=14529468" rel="nofollow noopener" target="_blank">probably aren’t welcome here</a>”; “The only thing is left is to change Hacker News icon <a data-offer-url="https://news.ycombinator.com/item?id=18189135" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=18189135&quot;}" href="https://news.ycombinator.com/item?id=18189135" rel="nofollow noopener" target="_blank">to Che Guevara emblem</a>.”) He and Bell assert their own opinions in subtle ways. Recently, they made some small changes to the Hacker News guidelines, which have always hewed closely to those that Graham drafted in 2007. To one about throwaway accounts—acceptable for sensitive information but discouraged as a regular practice—they added the reminder “HN is a community.” In another—“Comments should get more civil and substantive, not less, as a topic becomes more divisive”—they changed the phrase “civil and substantive” to “thoughtful and substantive.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Recently, an essay in the <em>New Atlantis</em> titled “<a data-offer-url="https://www.thenewatlantis.com/publications/do-elephants-have-souls" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.thenewatlantis.com/publications/do-elephants-have-souls&quot;}" href="https://www.thenewatlantis.com/publications/do-elephants-have-souls" rel="nofollow noopener" target="_blank">Do Elephants Have Souls?</a>,” from 2013, hit the front page. The piece generated immediate resistance. Commenters responded literally to the question posed in the title and bickered about the word “soul.” Conversation spiralled, with users making arguments about Cartesian metaphysics and quoting Socrates. “Why is such an unscientific question so high on HN?” one commenter asked. “Or to rephrase, if we don’t know what a soul is, how can we hope to answer it WRT elephants? So how and why should a reasoning person rate an article like this?”</p><p>“The article itself is just this wonderful exploration into the literature around elephants,” Gackle told me. “I don’t know how anybody could read that article and not just go, like, ‘Wow’—I mean, at least if you’re interested in elephants in any way.” Posting under his Hacker News username, dang, he staged a moderate intervention. “All: This article is not about souls,” he wrote. “It’s about elephants, humans, how we relate to elephants, how they relate to us, how humans relate to non-humans.” He continued:</p><blockquote><p>It is erudite and beautiful. It uses the astonishing literature about elephants to ask about ourselves, them, and the world. “Soul” here is a trope for aspects of humanness that we may or may not have in common. Usually, we just edit titles that are triggering people. If I were to do that here, I might rename it “Elephants and Anthropomorphism.” But when an article is this rich, moving, even profound, taking away its title would maim it. It bears a much better discussion than the thread has given it so far, so please let’s talk about what’s interesting and stay off the metaphysics.</p></blockquote><p>One reader, with the username solipsism, <a data-offer-url="https://news.ycombinator.com/item?id=19836914" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=19836914&quot;}" href="https://news.ycombinator.com/item?id=19836914" rel="nofollow noopener" target="_blank">objected to Gackle’s claims</a> about what was and wasn’t interesting. “Most would agree there’s a point at which moderation goes too far,” solipsism wrote. “I can’t tell if you’re making an appeal as a person, or making a decree as a moderator. I read the article, and it’s absolutely full of metaphysics.&nbsp;.&nbsp;.&nbsp;. These metaphysical topics interest me, and apparently they interested the writer, even if they don’t interest you.”</p><p>Gackle conceded that his dismissal was unfair. He removed the reference to metaphysics from his comment. “The point is simply that the article deserves a better discussion,” he wrote, with breezy, cheerful weariness. “I’m making an appeal as a moderator person.”</p><p>Bell and Gackle didn’t set out to become forum moderators. At Stanford, Gackle wrote a master’s thesis on Pyotr Vyazemsky and Nikolay Karamzin, two nineteenth-century Russian poets; Bell studied network engineering, at the Southern Alberta Institute of Technology, after a stint performing in punk, hardcore, and metalcore bands. When they met, in the Lisp user group, they both were working as coders and unfulfilled by their office jobs. Gackle later told me that he sees frustration at work as part of the DNA of Hacker News. “The instinct that there simply has to be a better way to build systems, and the yearning to connect with it,” he said. “If you can’t do that at your job, and few can, then you can at least dream and read and argue about it on the Internet. Hacker News is the inverse image of many people’s jobs, overlaid on top of each other—an escape valve for frustrated idealists.”</p><p>Bell had discovered Lisp while staving off boredom in a college computer-science course (he read technical documentation to pass the time); Gackle learned about it as a child, in <em>Byte</em> magazine. “When I program in other languages, even ones I know well,” he said, “I feel like I’ve flown to Jupiter. Gravity is so strong that every step is a struggle. In Lisp, you can dance.” In the user group, they found they had overlapping intellectual interests and complementary programming skills. Gackle worked at what he calls “a sort of product factory” where he built “little Potemkin products that would mostly get killed.” He had come to feel that he was helping to build software for users who didn’t need it; what they needed, he believed, was a customizable spreadsheet that improved on Microsoft Excel. (“Excel was these users’ Garden of Eden, where they could make their own spreadsheets and play with them in endless bliss, but they were cast out of Eden because their problems were too complex,” he told me.) In 2008, he and Bell formed a startup, Skysheet, with the mission of building a Web-based spreadsheet. A few months later, they were accepted into Y Combinator, which they’d learned about through Graham’s essays. They moved to Silicon Valley at the height of the recession.</p><p>Skysheet’s Y Combinator “class” of sixteen companies included Heyzap, a mobile-ad network that was acquired in 2015, for forty-five million dollars, and a struggling travel startup that would go on to become Airbnb. At the end of the program, the other founders in the group voted Skysheet the third most likely to succeed. But, after Y Combinator, Bell and Gackle found it difficult to fund-raise. It was the spring of 2009, and the market was bottoming out. “We learned that fund-raising means presenting yourself as impressive, desirable, and just about to be huge, even if the person you’re talking to is so mistaken as not to invest,” Gackle recalled. (Hearing this, I thought of the rhetorical style so widely deployed on Hacker News.) “Perhaps it’s partly the Canadianness, but this does not come naturally to either Scott or me.” Eventually, they raised a hundred and eighty thousand dollars and moved back to Canada to build the software. Some of the technical challenges were more complex than they’d anticipated; there was no existing literature to guide them. As delays mounted, Gackle had panic attacks nightly.</p><p>By 2012, Skysheet had yet to launch a public product and had run out of money. Bell made the painful decision to leave the company, taking a job with a software consultancy. Gackle forged ahead. “My feeling was I would rather fail at this than succeed at anything else,” he told me. Later that year, Graham reached out with an invitation to work on Hacker News, which, at that point, had nearly two million users. “I said no, because I knew it would mean no longer being able to think about spreadsheet software all day,” Gackle said.</p><p>That August, Gackle went for a hike in the Rockies. He slipped and fell on a mountainside, tumbling downhill, bouncing off the rocks. Somehow, he rolled to a stop against a boulder. Shaken, he hiked home. “It jolted me deeply, and after that I admitted to myself that I also was out of money and needed a job,” Gackle recalled. He reached out to Graham: “I told him yes, but with a feeling of unfinished business about this technical problem, which I still carry.” He became a behind-the-scenes moderator of Hacker News. A couple of years later, he hired Bell. In a way, they were perfectly prepared. Having briefly lived the dream and failed, they would now immerse themselves in a culture in which winning—an argument, a market—is a top priority.</p><p>Gackle and Bell are the only Y Combinator employees working on the site. In addition to moderating it, they maintain its technical infrastructure. (When I mentioned, at a party, that I was writing about Hacker News, an entrepreneur blurted, “It’s the fastest Web site I use!”) They post in comment threads, defending commenters who encounter combative or aggressive behavior and content that’s been downvoted, flagged, or misunderstood; they sometimes spend hours a day e-mailing with individual users, helping them use Hacker News more conscientiously and effectively. (“Present this not primarily as a moral appeal&nbsp;.&nbsp;.&nbsp;. but as an intellectual one,” Gackle wrote, over e-mail, to a user who was soliciting help for a man who had recently been exonerated after eleven years in prison for a crime he did not commit. “You should frame it as a puzzle or an engineering problem. That will engage the community’s curiosity, which is your only hope for getting a real discussion going.”)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“The only way to learn it is to get it wrong, and, when you get it wrong, you get flamed,” Gackle said, in the conference room. “And you get flamed so hard that it’s like being stung by a swarm of bees. It’s sort of like operant conditioning. If you put yourself in that position, where you’re getting stung on a daily basis, you’re soon going to start learning what makes the bees less likely.&nbsp;.&nbsp;.&nbsp;.” he paused. “Or, actually, I like bees. I would say ‘wasps’—what makes the wasps less likely to bite you.”</p><p>“The other way to learn is to let someone else get stung first,” Bell said, quietly.</p><p>In December, 2016—about a month after Donald Trump’s election—<a href="https://www.washingtonpost.com/news/worldviews/wp/2016/11/30/researchers-may-have-found-many-of-chinas-30-million-missing-girls/?utm_term=.6a8ddb01a670">an article</a> from the Washington <em>Post</em> hit Hacker News’ front page. The article covered a study of China’s “one child” policy, conducted by researchers at the University of Kansas and Shaanxi Normal University, that claimed that female children who were long believed to have been aborted or killed in infancy were simply not registered with the government at birth. The ensuing conversation rapidly devolved into arguments over whether or not institutional barriers exist; whether it was acceptable for users to correct the grammar of commenters whose first language was not English; whether sublimated testosterone was responsible for jihad and sexual assaults in Germany; the merits of Jill Stein; and voter fraud.</p><p>“Every single time poll restrictions have been proposed, it’s been for racist causes,” one user wrote, in response to a commenter with the username rokosbasilisk, who was advocating for a voter-identification system. “You yourself may not be a hooded member of the KKK, but you are pushing for the same things, and that’s all that matters.”</p><p>“so india wanted to voter id to prevent black people from voting?” rokosbasilisk responded. “seriously the race stuff just doesnt matter if we follow the indian model.”</p><p>“I have more faith in black people than you i guess, and think they are perfectly capable of getting an id,” a third user wrote.</p><p>“This has taken us into sociopolitical hell,” Bell posted, “and Hacker News isn’t that kind of site.” He “detached” some of the more inflammatory conversations from the main thread, hiding them from view.</p><p>That discussion, and also several others that emerged in the weeks after the election, prompted Gackle and Bell to experiment with and idea they called Political Detox Week. For seven days, political stories and threads would be considered off-topic and flagged by the moderators. The experiment was met with both relief and derision. “Political discourse is antithetical to rational, intelligent discussion,” one user wrote, in a comment that was upvoted to the top of the thread about the detox week. “Technological topics are always interesting to me&nbsp;.&nbsp;.&nbsp;. I love that there’s this corner of the Internet where I can participate in a reasoned, interesting technical community. Please don’t ruin it with politics, especially the polarizing American variant.”</p><p>Down the page, another user expressed disdain for the experiment. “The idea that we can carve out a space that exists outside of politics and ideology is delusional,” the user wrote. “Squelching political discussion won’t cause us all to transcend ideology, it’ll just make it impossible to discuss or critique a dominant ideology whenever one shows up in someone’s unstated assumptions.”</p><p>“Of course it’s delusional,” Gackle replied. “And still we have to moderate this site.” Three days later, he <a data-offer-url="https://news.ycombinator.com/item?id=13131251" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=13131251&quot;}" href="https://news.ycombinator.com/item?id=13131251" rel="nofollow noopener" target="_blank">announced</a> that Political Detox Week would be coming to an end. They’d learned, among other things, that “it’s impossible to define ‘politics’ with any consensus because that question is itself highly political.”</p><p>The most ideologically motivated or extreme posts and comments on Hacker News—an interview piece from Quillette titled “Understanding Victimhood Culture”; a link to a video of <a href="https://www.newyorker.com/tech/annals-of-technology/how-silicon-valleys-workplace-culture-produced-james-damores-google-memo">James Damore</a> and <a href="https://www.newyorker.com/magazine/2018/03/05/jordan-petersons-gospel-of-masculinity">Jordan Peterson</a> in conversation; one user telling another that all Jewish people should <a data-offer-url="https://news.ycombinator.com/item?id=13056816" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=13056816&quot;}" href="https://news.ycombinator.com/item?id=13056816" rel="nofollow noopener" target="_blank">relocate</a> to Israel—tend to get flagged by the community or the site’s anti-abuse systems, many of which Bell and Gackle have written themselves. (Flagged posts are removed from view, though they remain searchable by URL; flagged comments are rendered in pale gray text, and only visible to logged-in users who have chosen to see “dead” comments.) Still, as an occasional reader, I have noticed certain trends. When stories that focus on structural barriers faced by women in the workplace, or on diversity in tech, or on race or masculinity—stories, admittedly, that are more intriguing to me, a person interested in the humanities, than stories on technical topics—hit the front page, users often flag them, presumably for being off topic, so fast that hardly any comments accrue. When I shared these impressions with Gackle and Bell, they looked distressed. I asked if these were problems that they felt they could, or should, be controlling or trying to change on the site.</p><p>“From our perspective, the big surprise is how little control we actually have. We have to play our cards very carefully and very wisely, or even that control will sort of evaporate,” Gackle said. “There’s often a strong wish to solve these contentious problems by changing the software, and, to the extent that we’ve tried things like that, we haven’t found it to work. What does seem to work better is personal interaction, over and over and over again, with individual users. That, case by case by case, seems to move the needle. But it’s very slow.”</p><p>“If we’re trying to change something deep, the ingredient is time,” Bell said. “Patience allows us to be ambitious—to imagine people being more kind to each other, for example. It sounds kind of crazy.”</p><p>For Gackle and Bell, moderating Hacker News has presented an opportunity for self-work. Together, they have read up on nonviolent communication, sociology, and psychotherapy. (Bell found Carl Rogers’s “<a data-offer-url="https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X&quot;}" href="https://www.amazon.com/Becoming-Person-Therapists-View-Psychotherapy/dp/039575531X" rel="nofollow noopener" target="_blank">On Becoming a Person</a>”—a 1961 book about personal growth that became a bible of the humanistic-psychology movement—particularly valuable.) Gackle is drawn to healing workshops; Bell, to Indian philosophy. They seem, at times, to be applying old, humanist techniques to a culture obsessed with the future.</p><p>“Something that’s deeply interesting, I think, to both of us,” Gackle said, “is the way in which one can arrive at a nonviolent reaction to somebody by having greater awareness of the—” He paused. “I’ll say violence in oneself. By which I mean the kind of agitation and activation that is causing people, including ourselves, to react in a kind of fight-or-flight way that leads to misunderstanding, conflict, and, ultimately, Internet flame wars. This seemingly trivial stuff, about people getting mad at other people on the Internet, is actually tied to this much deeper and more fascinating process of what goes on between people and what goes on in oneself.”</p><p>“It’s another opportunity for us to influence the system, by exemplifying the kind of patterns of discussion that we would like to see,” Bell said. “We just want to constantly set an example.”</p><p>In April, the <em>Times</em> ran <a href="https://www.nytimes.com/2019/04/25/lens/sarah-lewis-racial-bias-photography.html">an essay</a> by Sarah Lewis, a Harvard professor, titled “The Racial Bias Built Into Photography.” The essay was a historical inquiry, inspecting lens development and film-emulsion technology, and was written in the first person. When it landed on Hacker News, users immediately rushed to flag it as off topic. Gackle changed the title to “Photography and racial bias,” and turned off flagging, which restored the essay to its original position on the front page.</p><p>“I take issue with this article simply because photography isn’t a technology at all,” one user commented. “It is an art that uses technology. There are millions of pictures of people of all races that look perfectly fine. I take issue with stirring up people for no reason. If a maker of paints in the 1800s owned slaves does that mean that painting (then, now, in the future) is racist? How ridiculous can we get?” Another user <a data-offer-url="https://news.ycombinator.com/item?id=19755097" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://news.ycombinator.com/item?id=19755097&quot;}" href="https://news.ycombinator.com/item?id=19755097" rel="nofollow noopener" target="_blank">posted</a> the opening lines of Rudyard Kipling’s poem “The White Man’s Burden.” A third wrote, “The people who invented the tech (US/Europe/Japan) optimised it for consumers around them. Why hate on inventors who create something cool just because it doesn’t quite work as well for all groups of people? Surely this also left a gap in the market—someone could have optimized film for darker skin tones and made a lot of money?”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“&nbsp;‘Hating’ is much too strong a word to describe the article, so much so that invoking it in a thread like this is a big upping of the flamewar ante,” Gackle replied, in the thread. He pointed the user to the site guidelines, encouraging more constructive input. He acknowledged that it was “hard to resist” inflammatory language “when a topic stirs up powerful emotions”:</p><blockquote><p>This creates a need for relief, and venting that energy in the form of extreme words is one way to get relief. Unfortunately, it doesn’t relieve anything at a community level. It just tosses the hot potato around in a way that only makes the potato hotter and more painful to the one who catches it next. What provides relief at a community level is when people find ability in themselves to acknowledge truth in what the other is saying.</p></blockquote><p>Over the years, Gackle and Bell have come to recognize their own triggers—patterns of online discourse that enrage them, depress them, or make them want to walk away. “In terms of the psychological experience of doing this job, all of your buttons are being pushed on a regular basis,” Gackle said. He now knows that it will be hard for him to keep his composure when he is being falsely accused or completely misread. (“That’s pretty much what some of the users do all day—accuse the moderators of doing something that they didn’t,” he said.)</p><p>Bell, for his part, becomes soul-weary when exposed to the unceasing spectacle of “people treating other people poorly.” “My reaction for things that get me is depressive,” Bell said. “Rather than respond outwardly, I have that internal depressive response. The issue for me is that this thing I’m very sensitive to is present in nearly everything.”</p><p>Gackle looked on as Bell spoke, then turned to me. “The sheer quantity of it is so overwhelming that one does have a depressive reaction, a hopeless reaction to it, at times,” he said. “I realized at some point that my feelings about it were like the feelings of a child trying to keep the family together. When the family is five million people, that’s a pretty tall order. It isn’t something that’s achievable. One has to learn to let go of them.”</p><p>“Don’t worry, dang is not adding anything to the conversation,” a user wrote, in the thread about race and photography. “He just enjoys virtue signaling. Hard!”</p><p>As Hacker News has grown, it has become the subject of both scrutiny and parody. A Twitter account, @shit_hn_says, highlights standout quotes from the comments section. (“If you want to do business with Iran, why don’t you just use Bitcoin?”) A hashtag, #HNwatch, collects screenshots of racist, sexist, xenophobic, and otherwise offensive or bizarre Hacker News comments. (“As a white man, I have concerns that my ethnic/gender group is being persecuted.” “In a way, the brains of startup founders and those below poverty lines work in the same way.”) Detractors refer to it as “the orange Web site,” a way of demonstrating both insider familiarity and exasperation.</p><p>N-gate, a satirical Web site with the slogan “We can’t both be right” (a NAND gate is a kind of logic gate that only outputs “false” if all of its inputs read “true”), offers a weekly summary of Hacker News discussions, dubbed “webshit weekly.” The N-gate entry about a Hacker News discussion of a <em>Times</em> article on the crashes of two Boeing 737 airliners, in Indonesia and Ethiopia, is typical. “Discussing a pair of crashes that killed almost three hundred and fifty people,” it reads, “Hacker News can’t decide whether the failure was one of user experience or branding. Other Hackernews”—as it calls commenters—“think that this plane would have worked better if it were designed by programmers with a tendency to work late for free. A majority of the comments are Hackernews incorrecting one another about FAA regulations, avionics, and lift.”</p><p>The proprietor of N-gate is an engineer who grew up in Palo Alto and now lives in the Pacific Northwest, where he works in high-performance computing. He agreed to exchange e-mails on condition of anonymity. “Almost every post deals with the same topics: these are people who spend their lives trying to identify all the ways they can extract money from others without quite going to jail,” he wrote. “They’re people who are convinced that they are too special for rules, and too smart for education. They don’t regard themselves as inhabiting the world the way other people do; they’re secret royalty, detached from society’s expectations and unfailingly outraged when faced with normal consequences for bad decisions. Society, and especially economics, is a logic puzzle where you just have to find the right set of loopholes to win the game. Rules are made to be slipped past, never stopping to consider why someone might have made those rules to start with. Silicon Valley has an ethics problem, and ‘Hacker’ ‘News’ is where it’s easiest to see.”</p><p>For decades, the phrase “Eternal September” has been used to describe the tipping point for a message board or online community—the inclusion, or invasion, of new users who dramatically change the existing subculture. (The term originated in September, 1993, after America Online made Usenet, a decades-old message-board system, accessible to many of its members, who were new to the Internet.) The creation of Startup News was a response to Reddit’s Eternal September; some of the problems with which Gackle and Bell are grappling can be traced to a similar phenomenon at Hacker News. The question they face now is whether the site’s original culture can be responsibly scaled up, or adapted, to make space for a more inclusive, wider-ranging vision of technology.</p><p>Gackle and Bell continue to believe in the value of “intellectual curiosity” as a goal. They speak of it more as a relative state than a fixed condition, using terms like “freshness” and “excitement” and “surprise and delight.” They are hopeful that, as Hacker News continues to grow, it will become, simultaneously, more diverse, more interesting, and more humane, while remaining in some fundamental sense a single community with a common goal. “The much larger sites, like Facebook, Twitter, and Reddit, all scaled by sharding,” Gackle told me, over e-mail. “HN has no shards. We have no social graph either. Everybody is in it together whether they like it or not.”</p><p>“Intellectual curiosity is everywhere, and it’s present in all demographics,” Bell said, in the conference room. “We want Hacker News to grow in all demographics, because there’s just intellectually interesting contributions from all of those communities—a greater diversity of content, of conversations, of topics, et cetera.” (He and Gackle have discussed diversifying their team, and adding a third moderator who is non-white, non-male, and, Bell joked, “non-balding.” Gackle clarified: “We've talked to each other about that. But we wouldn't make it a requirement.”) And yet the influx of outsiders doesn’t just change a community; it exposes its assumptions. The tech industry as a whole is having its own Eternal September. The world, with all its experiences and opinions, has come flooding in, and technologists are now reassessing the consequences of the systems and structures they have built or inherited. Some of these systems are social, and include the general modes of thought and expression that Hacker News embodies.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Outside the conference room, it was early evening. Through the frosted glass, we could see the shapes of Y Combinator’s employees shrugging on their backpacks and depositing their mugs in the kitchen sink. “It might seem like ‘intellectual curiosity’ isn’t primarily an ethical concern,” Gackle said. “But it actually turns out that those things are deeply related. There’s something about the way that curiosity works: it needs a kind of gentleness.”</p><p>A few weeks after meeting with Gackle and Bell, I checked Hacker News to see what commenters were saying about a <em>Times</em> story on the Facebook co-founder Chris Hughes’s antitrust work with the Federal Trade Commission. Users speculated about Hughes’s personal motivations and asked whether he had the knowledge necessary to help the government break up Facebook. Elsewhere on the site, people discussed California’s housing crisis (“The whole problem could be solved if we gave people the choice of voting where they work rather than where they live”) and a new scripting language, ChaiScript (“There’s no inherent reason a header-only library should significantly impact compile times, aside from the fact that the authors usually don’t have the foresight to make it efficient”). Skipping from thread to thread felt a bit like arriving at a party where half the room was sipping non-alcoholic shrubs and the other half had spent the afternoon tailgating in a stadium parking lot.</p><p>In the comments for a research paper, on ScienceDaily, about the evolutionary factors that may have been responsible for making humans the only mammals prone to heart attacks, a user criticized the study for having been conducted on mice. “Another couch biologist, there’s one in every thread,” posted a second user. “Thanks for all the observations, we really hadn’t thought of any of that, you single-handedly salvaged modern biological research!”</p><p>Gackle stepped in to ask the user not to break the site guidelines, and to behave more in the intended spirit of Hacker News. “Fair enough,” the user wrote; I felt a small rush of triumph, and pride, on Gackle’s behalf. Then, from the user, a follow-up question: “Why is this low-effort criticism of biology allowed?”</p><p>“It’s allowed in the sense that people are allowed to be wrong and/or ignorant because that’s what most of us are on most topics,” Gackle replied. “We can’t stop that any more than King Canute”—the ancient king of the North Sea who demonstrated the limits of his power by trying, in an ironic spirit, to command the sea—“could stop the waves. The important question is, what’s the best way to handle it if we want to have an internet forum that doesn’t suck? Experience teaches that the answer is: the patient supply of correct information by people who do know about a topic.”</p><p>I thought about the relentless patience and good faith that this style of moderation work required. I pictured Bell and Gackle as swimmers in a resistance pool, doing slow crawls against the currents of online discourse. I hoped the project of Hacker News was worth the effort. I wondered if their work might show that tech really does need humanism—that better online communities can be built one relationship at a time. Then my eyes moved down the thread, where a third user had left a new comment. It read: “King Canute was supposed to stop the tide, you couch alluder.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tremor – The React library to build dashboards fast (144 pts)]]></title>
            <link>https://www.tremor.so/</link>
            <guid>36911481</guid>
            <pubDate>Fri, 28 Jul 2023 18:53:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tremor.so/">https://www.tremor.so/</a>, See on <a href="https://news.ycombinator.com/item?id=36911481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><h2>Modular components to build dashboards in a breeze. Fully open-source, made by data scientists and software engineers with a sweet spot for design.</h2></div><div><p>20+ components</p><p>•</p><p>Apache-2.0 license</p><p>•</p><p>TypeScript Support</p></div><section id="tweets"><h2>Testimonials</h2><a href="#tweets"></a></section><div><div><div><p>Get more than 20 components with beautiful defaults and simple props. From charts to input and layout elements, we covered all the essential components to lift the tedious front-end work from your shoulders. Get ahead with our simple API approach in no time.</p></div><div><div><p><span>&lt;</span><span>Card</span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span><span>Ticket Sales</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;</span><span>Metric</span><span>&gt;</span><span><span>$ 71,465</span></span><span>&lt;/</span><span>Metric</span><span>&gt;</span></p><p><span>&lt;</span><span>Flex</span><span>className<span>=</span><span><span>"mt-3"</span></span></span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span>&lt;</span><span>Bold</span><span>&gt;</span><span><span>32%</span></span><span>&lt;/</span><span>Bold</span><span>&gt;</span><span><span>of annual target</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;</span><span>Text</span><span>&gt;</span><span><span>$ 223,328</span></span><span>&lt;/</span><span>Text</span><span>&gt;</span></p><p><span>&lt;/</span><span>Flex</span><span>&gt;</span></p><p><span>&lt;</span><span>ProgressBar</span><span>value<span>=</span><span><span>{ 32 }</span></span></span><span>className<span>=</span><span><span>"mt-3"</span></span></span><span>/&gt;</span></p><p><span>&lt;/</span><span>Card</span><span>&gt;</span></p></div><div><p>Ticket Sales</p><p>$ 71,465</p><div><p><b>32%</b> of annual target</p><p>$ 223,328</p></div></div></div></div><div><div><p><span>Combines design and analytics</span></p></div><div><p>Creating analytical interfaces is hard. We have distilled all our knowledge from building dashboards into Tremor. Besides our components, we provide a varierty of templates built on top of Tremor to give developers a head start on building great interfaces.</p></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free prison phone calls boost family ties, rehabilitation (357 pts)]]></title>
            <link>https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too</link>
            <guid>36911361</guid>
            <pubDate>Fri, 28 Jul 2023 18:45:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too">https://www.latimes.com/politics/story/2023-07-27/free-calls-restore-inmates-ties-with-the-outside-can-they-reform-californias-prisons-too</a>, See on <a href="https://news.ycombinator.com/item?id=36911361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Zeara Alvarez, 47, never realized just how much her big brother really cared.</p><p>She was a teenager when he was sent to prison for second-degree murder, and the pair spoke only sparingly over three decades.</p><p>That wasn’t because he had shut out the family or they had moved on. Communication between the siblings was drastically curtailed by the exorbitant cost of making prison phone calls.</p><p>At a time when most consumers enjoy free or low-cost calling, prison phone calls at their peak in California cost more than $6 per 15 minutes via a private telecommunications provider. That allowed only hurried, superficial conversations between the siblings — with one eye always on the clock.</p><p>This year California became the second state in the nation, and the largest to date, to mandate free calls in state prisons. Because family members bore the cost of the pricey calls, the new law eliminated a longstanding financial burden that forced many low-income people — particularly those of color — to choose between maintaining contact with incarcerated loved ones and putting food on the table.</p><p>Without the constant worry that the meter was running, Alvarez’s relationship with brother Anthony Perez, 51, has blossomed in recent months. </p><p>They speak several times a week. Rather than rushed conversations, there’s time for laughter and sharing memories. With their regular updates about everyday life and relaxed chats, a deeper bond has emerged.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/ccd3fc9/2147483647/strip/true/crop/3341x2227+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/82c86c2/2147483647/strip/true/crop/3341x2227+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/3d41183/2147483647/strip/true/crop/3341x2227+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/77eb864/2147483647/strip/true/crop/3341x2227+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/de07e61/2147483647/strip/true/crop/3341x2227+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/99c38e4/2147483647/strip/true/crop/3341x2227+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/83cbf9f/2147483647/strip/true/crop/3341x2227+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 2160w" sizes="100vw">     <img alt="A woman talking on a cellphone while sitting at a desk in front of a window" srcset="https://ca-times.brightspotcdn.com/dims4/default/a82a047/2147483647/strip/true/crop/3341x2227+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/57f7292/2147483647/strip/true/crop/3341x2227+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/5ba72a1/2147483647/strip/true/crop/3341x2227+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/5b4e56c/2147483647/strip/true/crop/3341x2227+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/5dece19/2147483647/strip/true/crop/3341x2227+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/e1367c7/2147483647/strip/true/crop/3341x2227+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/ee234a9/2147483647/strip/true/crop/3341x2227+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/8f3d81e/2147483647/strip/true/crop/3341x2227+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fca%2Fcf%2F066517a34e52ae499a9000d79fb9%2F1326263-la-me-zeara-alvarez-prison-phone-calls-010.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Zeara Alvarez, in her office at the Anti-Recidivism Coalition in Los Angeles, talks with brother Anthony Perez, who called from Ironwood State Prison in Blythe.</p>   <p>(Jason Armond / Los Angeles Times)</p>   </div>  </figure></div><div data-click="enhancement" data-align-right=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/2b7fba5/2147483647/strip/true/crop/2370x3555+0+0/resize/320x480!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/69e86bd/2147483647/strip/true/crop/2370x3555+0+0/resize/568x852!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/492c2f6/2147483647/strip/true/crop/2370x3555+0+0/resize/768x1152!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/2ec3147/2147483647/strip/true/crop/2370x3555+0+0/resize/1080x1620!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/de0e076/2147483647/strip/true/crop/2370x3555+0+0/resize/1240x1860!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/f2069a4/2147483647/strip/true/crop/2370x3555+0+0/resize/1440x2160!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/7600bbe/2147483647/strip/true/crop/2370x3555+0+0/resize/2160x3240!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 2160w" sizes="100vw">     <img alt="A woman standing with her back against a gray wall, looking down at her hands " srcset="https://ca-times.brightspotcdn.com/dims4/default/6da0b26/2147483647/strip/true/crop/2370x3555+0+0/resize/320x480!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/9153ed8/2147483647/strip/true/crop/2370x3555+0+0/resize/568x852!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/ff29d06/2147483647/strip/true/crop/2370x3555+0+0/resize/768x1152!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/8604005/2147483647/strip/true/crop/2370x3555+0+0/resize/1080x1620!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/985c1fb/2147483647/strip/true/crop/2370x3555+0+0/resize/1240x1860!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/aaf2917/2147483647/strip/true/crop/2370x3555+0+0/resize/1440x2160!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/dd7ccee/2147483647/strip/true/crop/2370x3555+0+0/resize/2160x3240!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg 2160w" sizes="100vw" width="2000" height="3000" src="https://ca-times.brightspotcdn.com/dims4/default/158d2b2/2147483647/strip/true/crop/2370x3555+0+0/resize/2000x3000!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc2%2F52%2F97b3d5fb46828fd2ac05efc65032%2F1326263-la-me-zeara-alvarez-prison-phone-calls-020.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>“We were actually crying together, and that had not ever happened,” Alvarez said of a recent talk with her brother, made possible by California’s mandated free calls from state prisons.</p>   <p>(Jason Armond / Los Angeles Times)</p>   </div>  </figure></div><p>“We were actually crying together, and that had not ever happened,” Alvarez told The Times, recalling a recent conversation with her brother. “It was very healing for us. I never knew all that he carried, like the emotional burden of not protecting his younger sister.”</p><p>In a telephone interview from Ironwood State Prison in Blythe, Perez said the more frequent contact with his sister was making him a better brother and better person.</p><p>By having these conversations, he said, he and others in prison “are able to kind of really rehabilitate our emotional awareness, and really start to have empathy for our family members that are struggling out there on the streets, so that we can create some type of emotion in ourselves other than always be worried about what is happening on the inside.”</p><p>Prisoner advocates and state correction officials hope the benefits will go even further by speeding rehabilitation, reducing recidivism and easing the way for reentry into society. </p><p>“Incarcerated people who are connected to their families and support systems are more likely to come home and stay home,” said Bianca Tylek, executive director of Worth Rises, a prison reform organization. “That means they are less likely to reengage in criminal activity and more likely to be productive neighbors for all of us. That protects and improves our own public safety.”</p><p>Other states including Colorado and Minnesota are following California and Connecticut, which was the first state to implement a free-call program in prisons. This week, the Los Angeles County Board of Supervisors, in the footsteps of <a href="https://www.politico.com/states/california/story/2020/08/10/san-francisco-becomes-first-county-in-the-nation-to-offer-free-calls-to-jail-inmates-1306715" target="_blank"><u>San Francisco</u></a> and <a href="https://www.sdsheriff.gov/bureaus/detention-services-bureau/telephones#:~:text=Since%20July%201%2C%202021%2C%20all,be%20limited%20to%2015%20minutes." target="_blank"><u>San Diego</u></a><u>,</u> <a href="https://www.latimes.com/california/story/2023-07-25/l-a-county-says-phone-calls-will-be-free-in-all-its-jails-by-dec-1">voted</a> unanimously to give the Sheriff’s Department a Dec. 1 deadline to make phone calls free in the seven county jails. </p><p>Since the California law took effect in January, call volume in state prisons surged from 1.4 million minutes per day in December 2022 to more than 3.5 million minutes in June, according to the California Department of Corrections and Rehabilitation.</p><p>Under the new law, free calls still must originate from prison and end after 15 minutes, but there are no caps on the number of calls an incarcerated person can make. Calling can be restricted to certain hours by individual facilities.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/779ea0a/2147483647/strip/true/crop/5184x3456+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/415a7c1/2147483647/strip/true/crop/5184x3456+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/e53d9c8/2147483647/strip/true/crop/5184x3456+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/6b6761b/2147483647/strip/true/crop/5184x3456+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/9e5b037/2147483647/strip/true/crop/5184x3456+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/9faf5ab/2147483647/strip/true/crop/5184x3456+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/19a601a/2147483647/strip/true/crop/5184x3456+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 2160w" sizes="100vw">     <img alt="Men talking on the phone in side-by-side cubicles as other men stand by" srcset="https://ca-times.brightspotcdn.com/dims4/default/89f80bd/2147483647/strip/true/crop/5184x3456+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/592992a/2147483647/strip/true/crop/5184x3456+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/3d14a7c/2147483647/strip/true/crop/5184x3456+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/53ecf89/2147483647/strip/true/crop/5184x3456+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/789767a/2147483647/strip/true/crop/5184x3456+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/3a0bfcf/2147483647/strip/true/crop/5184x3456+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/d55f54b/2147483647/strip/true/crop/5184x3456+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/8964a47/2147483647/strip/true/crop/5184x3456+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F74%2F54%2F65d06755428b9edeb125c5d948e4%2F326351-na-pol-free-prison-calls001-ls.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Men make phone calls from their cellblock at Folsom State Prison at no charge, part of California’s effort to help incarcerated people maintain relationships with family and friends, which may reduce recidivism.</p>   <p>(Luis Sinco / Los Angeles Times)</p>   </div>  </figure></div><p>In a statement, the state corrections department said it was optimistic that the increased family contact would help incarcerated people “build and maintain relationships that are critical to achieving their rehabilitative goals.”</p><p>Before the law, the state provided each prisoner with two free 15-minute calls every two weeks, costing taxpayers about $214,000 in December. In June, the overall prison phone bill increased more than tenfold, to nearly $2.4 million.</p><p>Oscar Bonilla, a formerly incarcerated person released in 2020, recalls the toll of long periods of not having phone calls. Though he understood his family could not afford the fee, he nevertheless felt forgotten and resentful.</p><p>Having free phone calls during his incarceration would have strengthened the relationship he had with his family, he said.</p><p>It would have “helped my own mental health and my own emotional state of being while I was in there,” he added. “It would have really had me feeling a little happier instead of being in a depressed state of mind. Having that bridge to your family is huge.”</p><p>Separation wore heavily on family members, too.</p><p>Ruth Mancilla, 43, of Duarte, has two brothers in prison. She said the family’s phone bill sometimes hit $900 in the early 2000s. “That was like a full rent back then,” she said.</p><p>She recalled the anguish she felt when one of her brothers would call her cellphone, and she had to watch the screen until it stopped ringing because she could not afford to answer it.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/038509a/2147483647/strip/true/crop/8066x5380+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/4092f12/2147483647/strip/true/crop/8066x5380+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/8eea99f/2147483647/strip/true/crop/8066x5380+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/13b81fd/2147483647/strip/true/crop/8066x5380+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/0ddfeef/2147483647/strip/true/crop/8066x5380+0+0/resize/1240x827!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/4cc409d/2147483647/strip/true/crop/8066x5380+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/a082db8/2147483647/strip/true/crop/8066x5380+0+0/resize/2160x1441!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 2160w" sizes="100vw">     <img alt="A woman sitting at a picnic table as people walk by on the grass in the background" srcset="https://ca-times.brightspotcdn.com/dims4/default/8bf13e1/2147483647/strip/true/crop/8066x5380+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/e1402bf/2147483647/strip/true/crop/8066x5380+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/4fea035/2147483647/strip/true/crop/8066x5380+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/18b78c4/2147483647/strip/true/crop/8066x5380+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/f1be486/2147483647/strip/true/crop/8066x5380+0+0/resize/1240x827!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/ad427f8/2147483647/strip/true/crop/8066x5380+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/1a81e17/2147483647/strip/true/crop/8066x5380+0+0/resize/2160x1441!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg 2160w" sizes="100vw" width="2000" height="1334" src="https://ca-times.brightspotcdn.com/dims4/default/6694bf8/2147483647/strip/true/crop/8066x5380+0+0/resize/2000x1334!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F4c%2Ff5%2Fd635fcb94e71ab8a83726e5fddf2%2F1323466-pol-free-prison-phone-calls-227.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Ruth Mancilla speaks from a park in Duarte to her son’s incarcerated father. She’s still not used to the free calls, which she says seem like “one of those ‘too good to be true’ type of things.”</p>   <p>(Dania Maxwell / Los Angeles Times)</p>   </div>  </figure></div><div data-click="enhancement" data-align-left=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/394edf0/2147483647/strip/true/crop/4778x7164+0+0/resize/320x480!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/bb0660f/2147483647/strip/true/crop/4778x7164+0+0/resize/568x852!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/37888e3/2147483647/strip/true/crop/4778x7164+0+0/resize/768x1152!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/71e6fad/2147483647/strip/true/crop/4778x7164+0+0/resize/1080x1619!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/2f66642/2147483647/strip/true/crop/4778x7164+0+0/resize/1240x1859!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/3653c6b/2147483647/strip/true/crop/4778x7164+0+0/resize/1440x2159!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/7c6a489/2147483647/strip/true/crop/4778x7164+0+0/resize/2160x3239!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 2160w" sizes="100vw">     <img alt="A closeup of a woman with the sun on her face and trees and blue sky behind her" srcset="https://ca-times.brightspotcdn.com/dims4/default/1b345fd/2147483647/strip/true/crop/4778x7164+0+0/resize/320x480!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/9a44dd1/2147483647/strip/true/crop/4778x7164+0+0/resize/568x852!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/19e4b7f/2147483647/strip/true/crop/4778x7164+0+0/resize/768x1152!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/d295882/2147483647/strip/true/crop/4778x7164+0+0/resize/1080x1619!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/db4f2b1/2147483647/strip/true/crop/4778x7164+0+0/resize/1240x1859!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/6482c5f/2147483647/strip/true/crop/4778x7164+0+0/resize/1440x2159!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/c18ce3a/2147483647/strip/true/crop/4778x7164+0+0/resize/2160x3239!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg 2160w" sizes="100vw" width="2000" height="2999" src="https://ca-times.brightspotcdn.com/dims4/default/cdea64c/2147483647/strip/true/crop/4778x7164+0+0/resize/2000x2999!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fc4%2F81%2F391156ff42fead61b7b3aef9d98d%2F1323466-pol-free-prison-phone-calls-276.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>Mancilla says that with two brothers in prison, her family’s phone bill sometimes hit $900 a month in the early 2000s — “like a full rent back then.” Before the new law, the cost of calls kept many families from talking with incarcerated loved ones as much as they would’ve liked.</p>   <p>(Dania Maxwell / Los Angeles Times)</p>   </div>  </figure></div><p>Even though calls are free now, she said that it is hard to break the old habit of second-guessing whether she should pick up.</p><p>“It is kind of a little traumatic,” she said. “I still have to stop and pause at times, because it is one of those ‘too good to be true’ type of things.”</p><p>Gabriel Bonilla, 47, who was convicted of murder in 2000, said the free calls had enabled him to reunite with his three sons, and to share his efforts to rehabilitate himself in prison, including his completion of a degree in May. </p><p>“Previously we had no communication and I was only judged [by] the worst day of my life,” Bonilla, no relation to Oscar, said in a phone call from Folsom State Prison. “I feel a lot better as a father, as a grandfather and as a husband because I am able to communicate with them. I am able to tell them my accomplishments [in prison] and everything that I have done to improve myself so that I’m not looked at for what I did to get myself in here.”</p><p>Free prison phone calls are among a series of recent reforms to overhaul the state’s prison system. </p><p>In March, Gov. Gavin Newsom announced that San Quentin State Prison — California’s oldest — would be transformed into a <a href="https://www.latimes.com/california/story/2023-03-16/newsom-wants-to-transform-san-quentin-using-a-scandinavian-model">“Scandinavian model,”</a> with a focus on education and job training to ease reentry into society and reduce rates of reoffending. The reforms seek to “completely reimagine what prison means,” Newsom said.</p><p>In June, the state closed all of its juvenile prisons in favor of detaining youth at county jails. The state is closing some prisons, and the corrections department has begun offering free transportation for families to visit incarcerated relatives.</p><p>During the pandemic, California prisons rolled out tablets that give incarcerated people limited digital access, including to video calls, text messages and music streaming.</p><p>However, those services are not free, and families have to pay for them if incarcerated relatives are among those who have received the tablets. Video calls cost 20 cents per minute and text messages cost 5 cents per message, according to rates <a href="https://www.cdcr.ca.gov/family-resources/tablets/" target="_blank">published by the state corrections agency.</a> </p> <p>Even before the new law, the cost of prison calls was drastically reduced after the Federal Communications Commission cracked down on hidden service fees and imposed rate caps on the prison telecom industry. A new law signed by President Biden and taking effect in 2024 will give the commission even greater powers to regulate the industry.</p><p>In some states, prison calls were costing as much as $14 a minute. A 15-minute phone call to a number within California peaked at $6.20 in 2007, and at $17.30 for out-of-state calls, according to the department.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/9202433/2147483647/strip/true/crop/4631x3086+0+0/resize/320x213!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/71383a0/2147483647/strip/true/crop/4631x3086+0+0/resize/568x379!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/a368a43/2147483647/strip/true/crop/4631x3086+0+0/resize/768x512!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/dbeeb67/2147483647/strip/true/crop/4631x3086+0+0/resize/1080x720!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/9492f9e/2147483647/strip/true/crop/4631x3086+0+0/resize/1240x826!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/e5bb5a8/2147483647/strip/true/crop/4631x3086+0+0/resize/1440x960!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/1d9266e/2147483647/strip/true/crop/4631x3086+0+0/resize/2160x1440!/format/webp/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 2160w" sizes="100vw">     <img alt="A person walking through a barred doorway near a large black-and-white mural of a man" srcset="https://ca-times.brightspotcdn.com/dims4/default/5a2788f/2147483647/strip/true/crop/4631x3086+0+0/resize/320x213!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/c8df621/2147483647/strip/true/crop/4631x3086+0+0/resize/568x379!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/9ac67d6/2147483647/strip/true/crop/4631x3086+0+0/resize/768x512!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/eafea10/2147483647/strip/true/crop/4631x3086+0+0/resize/1080x720!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1080w,https://ca-times.brightspotcdn.com/dims4/default/3716c90/2147483647/strip/true/crop/4631x3086+0+0/resize/1240x826!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1240w,https://ca-times.brightspotcdn.com/dims4/default/5606c9f/2147483647/strip/true/crop/4631x3086+0+0/resize/1440x960!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 1440w,https://ca-times.brightspotcdn.com/dims4/default/8854c67/2147483647/strip/true/crop/4631x3086+0+0/resize/2160x1440!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg 2160w" sizes="100vw" width="2000" height="1333" src="https://ca-times.brightspotcdn.com/dims4/default/27639a8/2147483647/strip/true/crop/4631x3086+0+0/resize/2000x1333!/quality/80/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F72%2F2f%2F094b867744d2a89078b420c06d39%2F326351-na-pol-free-prison-calls008-ls.jpg" decoding="async" loading="lazy">  </picture>  <div>   <p>California’s free prison phone calls are among a series of recent changes to overhaul Folsom State Prison, pictured, and the rest of the state’s corrections system.</p>   <p>(Luis Sinco / Los Angeles Times)</p>   </div>  </figure></div><p>In 2021, Global Tel Link, the private company handling California’s state prison calls, <a href="https://gtlprepaidsettlement.com/Home/portalid/0" target="_blank">agreed to a $67-million settlement</a> to refund and credit customers whose funds it had taken as profit when the customers didn’t use the funds within a 90-day period. The company is now known as ViaPath.</p><p>“As a provider of these services, ViaPath understands the importance of communication services and is focused on providing quality service and support,” ViaPath said in a statement. “The company was pleased to resolve the legacy litigation ...  and is complying with the settlement agreement.”</p><p>Advocates and relatives interviewed by The Times said although they are happy calls are now free, there is still a need to improve the quality of the service, as calls drop frequently and users are sometimes unable to hear one another.</p><p>The next legislative fight, activists say, is for video calls, text messages and calls from California’s patchwork of county jails to also become free. Those provisions were dropped from the previous bill as it made its way through California’s Legislature.</p><p>Tylek hopes California’s example encourages other states to pursue similar policy shifts in their correctional systems.</p><p>“I think the legislation in California helps demonstrate to other states across the country that this is doable, that this is feasible and that it can help change lives,” she said.</p> </div></div>]]></description>
        </item>
    </channel>
</rss>