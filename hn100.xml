<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 04 Jan 2025 02:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Why I'm quitting the Washington Post (165 pts)]]></title>
            <link>https://anntelnaes.substack.com/p/why-im-quitting-the-washington-post</link>
            <guid>42591221</guid>
            <pubDate>Sat, 04 Jan 2025 01:01:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anntelnaes.substack.com/p/why-im-quitting-the-washington-post">https://anntelnaes.substack.com/p/why-im-quitting-the-washington-post</a>, See on <a href="https://news.ycombinator.com/item?id=42591221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I’ve worked for the </span><em>Washington Post</em><span> since 2008 as an editorial cartoonist.  I have had editorial feedback and productive conversations—and some differences—about cartoons I have submitted for publication, but in all that time I’ve never had a cartoon killed because of who or what I chose to aim my pen at.  Until now.</span></p><p><span>The cartoon that was killed criticizes the billionaire tech and media chief executives who have been doing their best to curry favor with incoming President-elect Trump. There have been multiple </span><a href="https://www.washingtonpost.com/politics/2024/12/19/trump-bezos-musk-dinner/" rel="">articles</a><span> recently about these men with lucrative government contracts and an interest in eliminating regulations making their way to Mar-a-lago. The group in the cartoon included Mark Zuckerberg/Facebook &amp; Meta founder and CEO,  Sam Altman/AI CEO, Patrick Soon-Shiong/</span><em>LA Times </em><span>publisher, the Walt Disney Company/ABC News, and Jeff Bezos/</span><em>Washington Post</em><span> owner.  </span></p><p>While it isn’t uncommon for editorial page editors to object to visual metaphors within a cartoon if it strikes that editor as unclear or isn’t correctly conveying the message intended by the cartoonist, such editorial criticism was not the case regarding this cartoon. To be clear, there have been instances where sketches have been rejected or revisions requested,  but never because of the point of view inherent in the cartoon’s commentary.  That’s a game changer…and dangerous for a free press.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg" width="1456" height="1773" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1773,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:983666,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F185b68c6-9dba-4d15-9282-28cc9dc6aba8_1725x2100.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>(rough of cartoon killed)</p><p><span>Over the years I have watched my overseas colleagues risk their livelihoods and sometimes even their lives to expose injustices and hold their countries’ leaders accountable.  As a member of the </span><a href="https://freedomcartoonists.com/about/#governance" rel="">Advisory board</a><span> for the Geneva based </span><a href="https://freedomcartoonists.com/" rel="">Freedom Cartoonists Foundation </a><span> and a former board member of </span><a href="https://cartoonistsrights.org/" rel="">Cartoonists Rights</a><span>, I believe that editorial cartoonists are vital for civic debate and have an essential role in journalism.  </span></p><p>There will be people who say, “Hey, you work for a company and that company has the right to expect employees to adhere to what’s good for the company”.  That’s true except we’re talking about news organizations that have public obligations and who are obliged to nurture a free press in a democracy.  Owners of such press organizations are responsible for safeguarding that free press— and trying to get in the good graces of an autocrat-in-waiting will only result in undermining that free press.</p><p><span>As an editorial cartoonist, my job is to hold powerful people and institutions accountable.  For the first time, my editor prevented me from doing that critical job.  So I have decided to leave the </span><em>Post</em><span>.  I doubt my decision will cause much of a stir and that it will be dismissed because I’m just a cartoonist. But I will not stop holding truth to power through my cartooning, because as they say, “Democracy dies in darkness”.</span></p><p>Thank you for reading this.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg" width="1456" height="1099" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1099,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1072327,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd7038f-e16e-4993-bca7-227d5dad70d9_2968x2240.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A path to O1 open source (122 pts)]]></title>
            <link>https://arxiv.org/abs/2412.14135</link>
            <guid>42590322</guid>
            <pubDate>Fri, 03 Jan 2025 22:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.14135">https://arxiv.org/abs/2412.14135</a>, See on <a href="https://news.ycombinator.com/item?id=42590322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.14135">View PDF</a>
    <a href="https://arxiv.org/html/2412.14135v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>OpenAI o1 represents a significant milestone in Artificial Inteiligence, which achieves expert-level performances on many challanging tasks that require strong reasoning <a href="http://ability.openai/" rel="external noopener nofollow">this http URL</a> has claimed that the main techinique behinds o1 is the reinforcement learining. Recent works use alternative approaches like knowledge distillation to imitate o1's reasoning style, but their effectiveness is limited by the capability ceiling of the teacher model. Therefore, this paper analyzes the roadmap to achieving o1 from the perspective of reinforcement learning, focusing on four key components: policy initialization, reward design, search, and learning. Policy initialization enables models to develop human-like reasoning behaviors, equipping them with the ability to effectively explore solution spaces for complex problems. Reward design provides dense and effective signals via reward shaping or reward modeling, which is the guidance for both search and learning. Search plays a crucial role in generating high-quality solutions during both training and testing phases, which can produce better solutions with more computation. Learning utilizes the data generated by search for improving policy, which can achieve the better performance with more parameters and more searched data. Existing open-source projects that attempt to reproduce o1 can be seem as a part or a variant of our roadmap. Collectively, these components underscore how learning and search drive o1's advancement, making meaningful contributions to the development of LLM.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Zhiyuan Zeng [<a href="https://arxiv.org/show-email/5561585c/2412.14135" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 18 Dec 2024 18:24:47 UTC (1,122 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VoxelSpace: Terrain rendering algorithm in less than 20 lines of code (2020) (122 pts)]]></title>
            <link>https://github.com/s-macke/VoxelSpace</link>
            <guid>42588956</guid>
            <pubDate>Fri, 03 Jan 2025 20:01:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/s-macke/VoxelSpace">https://github.com/s-macke/VoxelSpace</a>, See on <a href="https://news.ycombinator.com/item?id=42588956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Voxel Space</h2><a id="user-content-voxel-space" aria-label="Permalink: Voxel Space" href="#voxel-space"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/webdemo.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/webdemo.gif" alt="web demonstration" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong><a href="https://s-macke.github.io/VoxelSpace/VoxelSpace.html" rel="nofollow">Web Demo of the Voxel Space Engine</a></strong></h2><a id="user-content-web-demo-of-the-voxel-space-engine" aria-label="Permalink: Web Demo of the Voxel Space Engine" href="#web-demo-of-the-voxel-space-engine"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">Let us go back to the year 1992. The CPUs were 1000 times slower than today and the acceleration via a GPU was unknown or unaffordable. 3D games were calculated exclusively on the CPU and the rendering engine rendered filled polygons with a single color.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/gunship2000-1991.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/gunship2000-1991.gif" alt="Game Gunship 2000 in 1991" data-animated-image=""></a>
<em>Game Gunship 2000 published by MicroProse in 1991</em></p>
<p dir="auto">It was during that year <a href="http://www.novalogic.com/" rel="nofollow">NovaLogic</a> published the game <a href="https://en.wikipedia.org/wiki/Comanche_(video_game_series)" rel="nofollow">Comanche</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/comanche-1992.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/comanche-1992.gif" alt="Game Comanche in 1992" data-animated-image=""></a>
<em>Game Comanche published by NovaLogic in 1992</em></p>
<p dir="auto">The graphics were breathtaking for the time being and in my opinion 3 years ahead of its time. You see many more details such as textures on mountains and valleys, and for the first time a neat shading and even shadows. Sure, it's pixelated, but all games in those years were pixelated.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Render algorithm</h2><a id="user-content-render-algorithm" aria-label="Permalink: Render algorithm" href="#render-algorithm"></a></p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Comanche_(video_game_series)" rel="nofollow">Comanche</a> uses a technique called <a href="https://en.wikipedia.org/wiki/Voxel_Space" rel="nofollow">Voxel Space</a>, which is based on the same ideas like <a href="https://en.wikipedia.org/wiki/Ray_casting" rel="nofollow">ray casting</a>. Hence the Voxel Space engine is a 2.5D engine, it doesn't have all the levels of freedom that a regular 3D engine offers.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Height map and color map</h3><a id="user-content-height-map-and-color-map" aria-label="Permalink: Height map and color map" href="#height-map-and-color-map"></a></p>
<p dir="auto">The easiest way to represent a terrain is through a height map and color map. For the game Comanche a 1024 * 1024 one byte height map and a 1024 * 1024 one byte color map is used which you can download on this site. These maps are periodic:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/periodicmap.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/periodicmap.gif" alt="periodic map" data-animated-image=""></a></p>
<p dir="auto">Such maps limit the terrain to "one height per position on the map" - Complex geometries such as buildings or trees are not possible to represent. However, a great advantage of the colormap is, that it already contains the shading and shadows. The Voxel Space engine just takes the color and doesn't have to compute illumination during the render process.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic algorithm</h3><a id="user-content-basic-algorithm" aria-label="Permalink: Basic algorithm" href="#basic-algorithm"></a></p>
<p dir="auto">For a 3D engine the rendering algorithm is amazingly simple. The Voxel Space engine rasters the height and color map and draws vertical lines. The following figure demonstrate this technique.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/linebyline.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/linebyline.gif" alt="Line by line" data-animated-image=""></a></p>
<ul dir="auto">
<li>Clear Screen.</li>
<li>To guarantee occlusion start from the back and render to the front. This is called painter algorithm.</li>
<li>Determine the line on the map, which corresponds to the same optical distance from the observer. Consider the field of view and the <a href="https://en.wikipedia.org/wiki/3D_projection" rel="nofollow">perspective projection</a> (Objects are smaller farther away)</li>
<li>Raster the line so that it matches the number of columns of the screen.</li>
<li>Retrieve the height and color from the 2D maps corresponding of the segment of the line.</li>
<li>Perform the <a href="https://en.wikipedia.org/wiki/3D_projection" rel="nofollow">perspective projection</a> for the height coordinate.</li>
<li>Draw a vertical line with the corresponding color with the height retrieved from the perspective projection.</li>
</ul>
<p dir="auto">The core algorithm contains in its simplest form only a few lines of code (python syntax):</p>
<div dir="auto" data-snippet-clipboard-copy-content="def Render(p, height, horizon, scale_height, distance, screen_width, screen_height):
    # Draw from back to the front (high z coordinate to low z coordinate)
    for z in range(distance, 1, -1):
        # Find line on map. This calculation corresponds to a field of view of 90°
        pleft  = Point(-z + p.x, -z + p.y)
        pright = Point( z + p.x, -z + p.y)
        # segment the line
        dx = (pright.x - pleft.x) / screen_width
        # Raster line and draw a vertical line for each segment
        for i in range(0, screen_width):
            height_on_screen = (height - heightmap[pleft.x, pleft.y]) / z * scale_height. + horizon
            DrawVerticalLine(i, height_on_screen, screen_height, colormap[pleft.x, pleft.y])
            pleft.x += dx

# Call the render function with the camera parameters:
# position, height, horizon line position,
# scaling factor for the height, the largest distance, 
# screen width and the screen height parameter
Render( Point(0, 0), 50, 120, 120, 300, 800, 600 )"><pre><span>def</span> <span>Render</span>(<span>p</span>, <span>height</span>, <span>horizon</span>, <span>scale_height</span>, <span>distance</span>, <span>screen_width</span>, <span>screen_height</span>):
    <span># Draw from back to the front (high z coordinate to low z coordinate)</span>
    <span>for</span> <span>z</span> <span>in</span> <span>range</span>(<span>distance</span>, <span>1</span>, <span>-</span><span>1</span>):
        <span># Find line on map. This calculation corresponds to a field of view of 90°</span>
        <span>pleft</span>  <span>=</span> <span>Point</span>(<span>-</span><span>z</span> <span>+</span> <span>p</span>.<span>x</span>, <span>-</span><span>z</span> <span>+</span> <span>p</span>.<span>y</span>)
        <span>pright</span> <span>=</span> <span>Point</span>( <span>z</span> <span>+</span> <span>p</span>.<span>x</span>, <span>-</span><span>z</span> <span>+</span> <span>p</span>.<span>y</span>)
        <span># segment the line</span>
        <span>dx</span> <span>=</span> (<span>pright</span>.<span>x</span> <span>-</span> <span>pleft</span>.<span>x</span>) <span>/</span> <span>screen_width</span>
        <span># Raster line and draw a vertical line for each segment</span>
        <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>0</span>, <span>screen_width</span>):
            <span>height_on_screen</span> <span>=</span> (<span>height</span> <span>-</span> <span>heightmap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>]) <span>/</span> <span>z</span> <span>*</span> <span>scale_height</span>. <span>+</span> <span>horizon</span>
            <span>DrawVerticalLine</span>(<span>i</span>, <span>height_on_screen</span>, <span>screen_height</span>, <span>colormap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>])
            <span>pleft</span>.<span>x</span> <span>+=</span> <span>dx</span>

<span># Call the render function with the camera parameters:</span>
<span># position, height, horizon line position,</span>
<span># scaling factor for the height, the largest distance, </span>
<span># screen width and the screen height parameter</span>
<span>Render</span>( <span>Point</span>(<span>0</span>, <span>0</span>), <span>50</span>, <span>120</span>, <span>120</span>, <span>300</span>, <span>800</span>, <span>600</span> )</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Add rotation</h3><a id="user-content-add-rotation" aria-label="Permalink: Add rotation" href="#add-rotation"></a></p>
<p dir="auto">With the algorithm above we can only view to the north. A different angle needs a few more lines of code to rotate the coordinates.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/rotate.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/rotate.gif" alt="rotation" data-animated-image=""></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="def Render(p, phi, height, horizon, scale_height, distance, screen_width, screen_height):
    # precalculate viewing angle parameters
    var sinphi = math.sin(phi);
    var cosphi = math.cos(phi);

    # Draw from back to the front (high z coordinate to low z coordinate)
    for z in range(distance, 1, -1):

        # Find line on map. This calculation corresponds to a field of view of 90°
        pleft = Point(
            (-cosphi*z - sinphi*z) + p.x,
            ( sinphi*z - cosphi*z) + p.y)
        pright = Point(
            ( cosphi*z - sinphi*z) + p.x,
            (-sinphi*z - cosphi*z) + p.y)
        
        # segment the line
        dx = (pright.x - pleft.x) / screen_width
        dy = (pright.y - pleft.y) / screen_width

        # Raster line and draw a vertical line for each segment
        for i in range(0, screen_width):
            height_on_screen = (height - heightmap[pleft.x, pleft.y]) / z * scale_height. + horizon
            DrawVerticalLine(i, height_on_screen, screen_height, colormap[pleft.x, pleft.y])
            pleft.x += dx
            pleft.y += dy

# Call the render function with the camera parameters:
# position, viewing angle, height, horizon line position, 
# scaling factor for the height, the largest distance, 
# screen width and the screen height parameter
Render( Point(0, 0), 0, 50, 120, 120, 300, 800, 600 )"><pre><span>def</span> <span>Render</span>(<span>p</span>, <span>phi</span>, <span>height</span>, <span>horizon</span>, <span>scale_height</span>, <span>distance</span>, <span>screen_width</span>, <span>screen_height</span>):
    <span># precalculate viewing angle parameters</span>
    <span>var</span> <span>sinphi</span> <span>=</span> <span>math</span>.<span>sin</span>(<span>phi</span>);
    <span>var</span> <span>cosphi</span> <span>=</span> <span>math</span>.<span>cos</span>(<span>phi</span>);

    <span># Draw from back to the front (high z coordinate to low z coordinate)</span>
    <span>for</span> <span>z</span> <span>in</span> <span>range</span>(<span>distance</span>, <span>1</span>, <span>-</span><span>1</span>):

        <span># Find line on map. This calculation corresponds to a field of view of 90°</span>
        <span>pleft</span> <span>=</span> <span>Point</span>(
            (<span>-</span><span>cosphi</span><span>*</span><span>z</span> <span>-</span> <span>sinphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>x</span>,
            ( <span>sinphi</span><span>*</span><span>z</span> <span>-</span> <span>cosphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>y</span>)
        <span>pright</span> <span>=</span> <span>Point</span>(
            ( <span>cosphi</span><span>*</span><span>z</span> <span>-</span> <span>sinphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>x</span>,
            (<span>-</span><span>sinphi</span><span>*</span><span>z</span> <span>-</span> <span>cosphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>y</span>)
        
        <span># segment the line</span>
        <span>dx</span> <span>=</span> (<span>pright</span>.<span>x</span> <span>-</span> <span>pleft</span>.<span>x</span>) <span>/</span> <span>screen_width</span>
        <span>dy</span> <span>=</span> (<span>pright</span>.<span>y</span> <span>-</span> <span>pleft</span>.<span>y</span>) <span>/</span> <span>screen_width</span>

        <span># Raster line and draw a vertical line for each segment</span>
        <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>0</span>, <span>screen_width</span>):
            <span>height_on_screen</span> <span>=</span> (<span>height</span> <span>-</span> <span>heightmap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>]) <span>/</span> <span>z</span> <span>*</span> <span>scale_height</span>. <span>+</span> <span>horizon</span>
            <span>DrawVerticalLine</span>(<span>i</span>, <span>height_on_screen</span>, <span>screen_height</span>, <span>colormap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>])
            <span>pleft</span>.<span>x</span> <span>+=</span> <span>dx</span>
            <span>pleft</span>.<span>y</span> <span>+=</span> <span>dy</span>

<span># Call the render function with the camera parameters:</span>
<span># position, viewing angle, height, horizon line position, </span>
<span># scaling factor for the height, the largest distance, </span>
<span># screen width and the screen height parameter</span>
<span>Render</span>( <span>Point</span>(<span>0</span>, <span>0</span>), <span>0</span>, <span>50</span>, <span>120</span>, <span>120</span>, <span>300</span>, <span>800</span>, <span>600</span> )</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">More performance</h3><a id="user-content-more-performance" aria-label="Permalink: More performance" href="#more-performance"></a></p>
<p dir="auto">There are of course a lot of tricks to achieve higher performance.</p>
<ul dir="auto">
<li>Instead of drawing from back to the front we can draw from front to back. The advantage is, the we don't have to draw lines to the bottom of the screen every time because of occlusion. However, to guarantee occlusion we need an additional y-buffer. For every column, the highest y position is stored. Because we are drawing from the front to back, the visible part of the next line can only be larger then the highest line previously drawn.</li>
<li>Level of Detail. Render more details in front but less details far away.</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/fronttoback.gif"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/fronttoback.gif" alt="front to back rendering" data-animated-image=""></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="def Render(p, phi, height, horizon, scale_height, distance, screen_width, screen_height):
    # precalculate viewing angle parameters
    var sinphi = math.sin(phi);
    var cosphi = math.cos(phi);
    
    # initialize visibility array. Y position for each column on screen 
    ybuffer = np.zeros(screen_width)
    for i in range(0, screen_width):
        ybuffer[i] = screen_height

    # Draw from front to the back (low z coordinate to high z coordinate)
    dz = 1.
    z = 1.
    while z < distance
        # Find line on map. This calculation corresponds to a field of view of 90°
        pleft = Point(
            (-cosphi*z - sinphi*z) + p.x,
            ( sinphi*z - cosphi*z) + p.y)
        pright = Point(
            ( cosphi*z - sinphi*z) + p.x,
            (-sinphi*z - cosphi*z) + p.y)

        # segment the line
        dx = (pright.x - pleft.x) / screen_width
        dy = (pright.y - pleft.y) / screen_width

        # Raster line and draw a vertical line for each segment
        for i in range(0, screen_width):
            height_on_screen = (height - heightmap[pleft.x, pleft.y]) / z * scale_height. + horizon
            DrawVerticalLine(i, height_on_screen, ybuffer[i], colormap[pleft.x, pleft.y])
            if height_on_screen < ybuffer[i]:
                ybuffer[i] = height_on_screen
            pleft.x += dx
            pleft.y += dy

        # Go to next line and increase step size when you are far away
        z += dz
        dz += 0.2

# Call the render function with the camera parameters:
# position, viewing angle, height, horizon line position, 
# scaling factor for the height, the largest distance, 
# screen width and the screen height parameter
Render( Point(0, 0), 0, 50, 120, 120, 300, 800, 600 )"><pre><span>def</span> <span>Render</span>(<span>p</span>, <span>phi</span>, <span>height</span>, <span>horizon</span>, <span>scale_height</span>, <span>distance</span>, <span>screen_width</span>, <span>screen_height</span>):
    <span># precalculate viewing angle parameters</span>
    <span>var</span> <span>sinphi</span> <span>=</span> <span>math</span>.<span>sin</span>(<span>phi</span>);
    <span>var</span> <span>cosphi</span> <span>=</span> <span>math</span>.<span>cos</span>(<span>phi</span>);
    
    <span># initialize visibility array. Y position for each column on screen </span>
    <span>ybuffer</span> <span>=</span> <span>np</span>.<span>zeros</span>(<span>screen_width</span>)
    <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>0</span>, <span>screen_width</span>):
        <span>ybuffer</span>[<span>i</span>] <span>=</span> <span>screen_height</span>

    <span># Draw from front to the back (low z coordinate to high z coordinate)</span>
    <span>dz</span> <span>=</span> <span>1.</span>
    <span>z</span> <span>=</span> <span>1.</span>
    <span>while</span> <span>z</span> <span>&lt;</span> <span>distance</span>
        <span># Find line on map. This calculation corresponds to a field of view of 90°</span>
        <span>pleft</span> <span>=</span> <span>Point</span>(
            (<span>-</span><span>cosphi</span><span>*</span><span>z</span> <span>-</span> <span>sinphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>x</span>,
            ( <span>sinphi</span><span>*</span><span>z</span> <span>-</span> <span>cosphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>y</span>)
        <span>pright</span> <span>=</span> <span>Point</span>(
            ( <span>cosphi</span><span>*</span><span>z</span> <span>-</span> <span>sinphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>x</span>,
            (<span>-</span><span>sinphi</span><span>*</span><span>z</span> <span>-</span> <span>cosphi</span><span>*</span><span>z</span>) <span>+</span> <span>p</span>.<span>y</span>)

        <span># segment the line</span>
        <span>dx</span> <span>=</span> (<span>pright</span>.<span>x</span> <span>-</span> <span>pleft</span>.<span>x</span>) <span>/</span> <span>screen_width</span>
        <span>dy</span> <span>=</span> (<span>pright</span>.<span>y</span> <span>-</span> <span>pleft</span>.<span>y</span>) <span>/</span> <span>screen_width</span>

        <span># Raster line and draw a vertical line for each segment</span>
        <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>0</span>, <span>screen_width</span>):
            <span>height_on_screen</span> <span>=</span> (<span>height</span> <span>-</span> <span>heightmap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>]) <span>/</span> <span>z</span> <span>*</span> <span>scale_height</span>. <span>+</span> <span>horizon</span>
            <span>DrawVerticalLine</span>(<span>i</span>, <span>height_on_screen</span>, <span>ybuffer</span>[<span>i</span>], <span>colormap</span>[<span>pleft</span>.<span>x</span>, <span>pleft</span>.<span>y</span>])
            <span>if</span> <span>height_on_screen</span> <span>&lt;</span> <span>ybuffer</span>[<span>i</span>]:
                <span>ybuffer</span>[<span>i</span>] <span>=</span> <span>height_on_screen</span>
            <span>pleft</span>.<span>x</span> <span>+=</span> <span>dx</span>
            <span>pleft</span>.<span>y</span> <span>+=</span> <span>dy</span>

        <span># Go to next line and increase step size when you are far away</span>
        <span>z</span> <span>+=</span> <span>dz</span>
        <span>dz</span> <span>+=</span> <span>0.2</span>

<span># Call the render function with the camera parameters:</span>
<span># position, viewing angle, height, horizon line position, </span>
<span># scaling factor for the height, the largest distance, </span>
<span># screen width and the screen height parameter</span>
<span>Render</span>( <span>Point</span>(<span>0</span>, <span>0</span>), <span>0</span>, <span>50</span>, <span>120</span>, <span>120</span>, <span>300</span>, <span>800</span>, <span>600</span> )</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Links</h2><a id="user-content-links" aria-label="Permalink: Links" href="#links"></a></p>
<p dir="auto"><a href="https://s-macke.github.io/VoxelSpace/VoxelSpace.html" rel="nofollow">Web Project demo</a> page</p>
<p dir="auto"><a href="https://web.archive.org/web/20131113094653/http://www.codermind.com/articles/Voxel-terrain-engine-building-the-terrain.html" rel="nofollow">Voxel terrain engine - an introduction</a></p>
<p dir="auto"><a href="http://www.simulationcorner.net/" rel="nofollow">Personal website</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Maps</h2><a id="user-content-maps" aria-label="Permalink: Maps" href="#maps"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C1W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D1.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C1W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C1W.png" alt="C1W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D1.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D1.png" alt="D1.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C2W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D2.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C2W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C2W.png" alt="C2W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D2.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D2.png" alt="D2.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C3.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D3.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C3.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C3.png" alt="C3.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D3.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D3.png" alt="D3.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C4.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D4.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C4.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C4.png" alt="C4.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D4.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D4.png" alt="D4.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C5W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D5.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C5W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C5W.png" alt="C5W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D5.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D5.png" alt="D5.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C6W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D6.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C6W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C6W.png" alt="C6W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D6.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D6.png" alt="D6.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C7W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D7.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C7W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C7W.png" alt="C7W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D7.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D7.png" alt="D7.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C8.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D6.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C8.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C8.png" alt="C8.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D6.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D6.png" alt="D6.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C9W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D9.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C9W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C9W.png" alt="C9W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D9.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D9.png" alt="D9.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C10W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D10.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C10W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C10W.png" alt="C10W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D10.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D10.png" alt="D10.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C11W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D11.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C11W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C11W.png" alt="C11W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D11.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D11.png" alt="D11.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C12W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D11.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C12W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C12W.png" alt="C12W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D11.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D11.png" alt="D11.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C13.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D13.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C13.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C13.png" alt="C13.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D13.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D13.png" alt="D13.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C14.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D14.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C14.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C14.png" alt="C14.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D14.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D14.png" alt="D14.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C14W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D14.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C14W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C14W.png" alt="C14W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D14.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D14.png" alt="D14.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C15.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D15.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C15.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C15.png" alt="C15.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D15.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D15.png" alt="D15.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C16W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D16.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C16W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C16W.png" alt="C16W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D16.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D16.png" alt="D16.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C17W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D17.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C17W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C17W.png" alt="C17W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D17.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D17.png" alt="D17.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C18W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D18.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C18W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C18W.png" alt="C18W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D18.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D18.png" alt="D18.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C19W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D19.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C19W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C19W.png" alt="C19W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D19.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D19.png" alt="D19.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C20W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D20.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C20W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C20W.png" alt="C20W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D20.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D20.png" alt="D20.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C21.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D21.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C21.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C21.png" alt="C21.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D21.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D21.png" alt="D21.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C22W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D22.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C22W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C22W.png" alt="C22W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D22.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D22.png" alt="D22.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C23W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D21.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C23W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C23W.png" alt="C23W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D21.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D21.png" alt="D21.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C24W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D24.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C24W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C24W.png" alt="C24W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D24.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D24.png" alt="D24.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C25W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D25.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C25W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C25W.png" alt="C25W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D25.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D25.png" alt="D25.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C26W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D18.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C26W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C26W.png" alt="C26W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D18.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D18.png" alt="D18.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C27W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D15.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C27W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C27W.png" alt="C27W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D15.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D15.png" alt="D15.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C28W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D25.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C28W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C28W.png" alt="C28W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D25.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D25.png" alt="D25.png"></a></p>
<p dir="auto"><a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/C29W.png">color</a>,
<a href="https://github.com/s-macke/VoxelSpace/blob/master/maps/D16.png">height</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/C29W.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/C29W.png" alt="C29W.png"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/s-macke/VoxelSpace/blob/master/images/thumbnails/D16.png"><img src="https://github.com/s-macke/VoxelSpace/raw/master/images/thumbnails/D16.png" alt="D16.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The software part of the repository is under the MIT license. Please read the license file for more information. Please keep in mind, that the Voxel Space technology might be still <a href="https://patents.justia.com/assignee/novalogic-inc" rel="nofollow">patented</a> in some countries. The color and height maps are reverse engineered from the game Comanche and are therefore excluded from the license.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OnlyFangs has made 'World of Warcraft' into Twitch's best soap opera (116 pts)]]></title>
            <link>https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-onlyfangs-twitch-roleplay-1235222436/</link>
            <guid>42587829</guid>
            <pubDate>Fri, 03 Jan 2025 17:50:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-onlyfangs-twitch-roleplay-1235222436/">https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-onlyfangs-twitch-roleplay-1235222436/</a>, See on <a href="https://news.ycombinator.com/item?id=42587829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	Sun pours through the lush foliage of a jungle, bleaching the pale limestone as a rotting man stands in the center of an otherwise empty arena, his yellow eyes leering from beneath a fringe of limp, blonde hair. Positioned around the edge are a hundred bodies, Orcs and Trolls and bipedal oxen shouting, demanding, the death of the dishonorable. Their voices swell into a cacophony of noise before one rings out above the rest, howling, “Kill the cheater and you’ll get 20 gold!” There is silence, and then another frenzy. As I watch, eyes fixed on the dim glow of a laptop screen, I think of the colosseum in Rome — sweat running down the muscled arms of battle-tested gladiators, the crowd cheering for blood.</p>



<p>
	This might sound like a moment pulled from a high fantasy drama made for prestige TV, but this is <em><a href="https://www.rollingstone.com/t/world-of-warcraft/" id="auto-tag_world-of-warcraft" data-tag="world-of-warcraft">World of Warcraft</a></em>, a <a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-20-anniversary-1235176713/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-20-anniversary-1235176713/">now 20-year old online RPG</a>. Instead of actors parading in front of green screens, this story’s cast are streamers that occupy a virtual world. Tensions are high not because they’re scripted, but because in <a rel="nofollow" data-id="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore" data-type="link" href="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore" target="_blank"><em>World of Warcr</em></a><em><a rel="noreferrer noopener nofollow" data-id="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore" target="_blank" data-type="link" href="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore">a</a></em><a rel="nofollow" data-id="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore" data-type="link" href="https://worldofwarcraft.blizzard.com/en-us/news/23988130/get-in-and-get-going-classic-hardcore" target="_blank"><em>ft</em>’s<em> </em>Hardcore</a> mode, death is permanent. Dejected, though acknowledging the transgression made, Sequisha — the streamer who was promptly executed for cheating — sighs, and goes back to the character select screen. He creates a new avatar; it’s time to start the game all over again.

	</p>




<p>
	Sequisha’s execution and subsequent reincarnation is just one of hundreds of stories playing out everyday in <em>World of Warcraft</em> as streamers have flocked to the massively multiplayer online RPG (MMORPG) to play together. Through their strife, and a commitment to staying in-character via roleplay, groups like the guild <a rel="noreferrer noopener nofollow" data-id="https://www.onlyfangs.info/" target="_blank" data-type="link" href="https://www.onlyfangs.info/">OnlyFangs</a> have turned <em>World of Warcraft</em> into an RPG within an RPG, playing out improvisational personal drama where the stakes are high.</p>



<figure><div>
<p><iframe loading="lazy" title="OnlyFangs Season 2 is Coming..." width="500" height="281" src="https://www.youtube.com/embed/JOblUnKyZKE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>



<p>
	In Hardcore mode, <em>World of Warcraft</em> has become the best soap opera on the internet, all playing out across over dozens of <a href="https://www.rollingstone.com/t/onlyfangs/" id="auto-tag_onlyfangs" data-tag="onlyfangs">OnlyFangs</a> creator streams every day.


</p><section>
			

	<h2 id="section-heading">

	
		Editor’s picks
	
	</h2>

	
	
</section>




	<h2 id="what-is-onlyfangs">
		What is OnlyFangs?	</h2>



<p>
	To commemorate the 20th anniversary of <em>World of Warcraft, </em>Blizzard Entertainment created a set of new servers designed to draw in fans old and new. This included a “Classic” server, which recreates the look and mechanics of the game’s earliest days, and will eventually be updated to include its expansions, starting with 2007’s <em>The Burning Crusade</em> and 2008’s <em>Wrath of the Lich King</em>.&nbsp;</p>



<p>
	The other big addition is a “Hardcore” server. Unlike standard servers, if you die in Hardcore, that character is lost forever — including rare items and gold. Between these new high-stakes servers and 2024’s <em>The War Within</em> expansion, interest in the game had been renewed, driving creators back to the world of Azeroth to mine a deep well of fresh content. Since the bump in users, <em>World of Warcraft</em> has remained a hot category on platforms like <a href="https://www.rollingstone.com/t/twitch/" id="auto-tag_twitch" data-tag="twitch">Twitch</a> and YouTube, with overall viewership reaching well above 50 thousand, even during usual off hours, and it seems like everyone wants a piece of the pie.</p>



<p>
	Swaths of streamers have decided to team up and create <a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-undaunted-guild-accessibility-1235183220/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/rs-gaming/world-of-warcraft-undaunted-guild-accessibility-1235183220/">guilds, enclosed social networks</a> where players can ask for help or chat in semi-private spaces, for the sole purpose of jumping into the new Hardcore server. One such guild began early with the first wave of Hardcore servers: OnlyFangs — a group of some of the <a rel="noreferrer noopener nofollow" data-id="https://win.gg/news/all-the-members-of-onlyfangs-the-twitch-wow-superguild/" target="_blank" data-type="link" href="https://win.gg/news/all-the-members-of-onlyfangs-the-twitch-wow-superguild/">most popular creators</a> on Twitch like <a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/culture-news/twitch-gambling-ban-sliker-debt-rehab-1234596040/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/culture-news/twitch-gambling-ban-sliker-debt-rehab-1234596040/">Mizkif</a>, <a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/culture-lists/top-social-media-influencers-creators-2024-1235084589/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/culture-lists/top-social-media-influencers-creators-2024-1235084589/">Pokimane</a>, and the guild’s leader Sodapoppin, who is currently the world’s most popular <em>World of Warcraft </em>streamer.

	</p>




<div>
	

<figure>

			
<div>
	
			<p><img src="https://www.rollingstone.com/wp-content/uploads/2025/01/001.jpg?w=1024" data-lazy-src="https://www.rollingstone.com/wp-content/uploads/2025/01/001.jpg?w=1024" alt="" data-lazy-srcset="" data-lazy-sizes="" height="576" width="1024" decoding="async">
			
			</p>
	
	</div>
	
			
			
<figcaption>
	
					<span>Sodapoppin, the world’s biggest <em>WoW</em> streamer, addresses the OnlyFangs guild.</span>
		
									<cite>Sodapoppin; Twitch; Blizzard Entertainment</cite>
					
	</figcaption>

			
</figure>

</div>



<p>
	After amassing a huge following with their first big season of Hardcore mode streaming, OnlyFangs made some big changes, <a rel="noreferrer noopener nofollow" data-id="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/" target="_blank" data-type="link" href="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/">even dropping famou</a><a href="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/" data-type="link" data-id="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/" target="_blank" rel="noreferrer noopener nofollow">s</a><a rel="noreferrer noopener nofollow" data-id="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/" target="_blank" data-type="link" href="https://gameland.gg/sodapoppin-reveals-full-list-of-streamers-kicked-from-onlyfangs/"> names like Pokimane</a> for not being devoted to the leveling grind. Led by <a rel="noreferrer noopener nofollow" data-id="https://www.twitch.tv/sodapoppin" target="_blank" data-type="link" href="https://www.twitch.tv/sodapoppin">Sodapoppin</a>, co-creator and co-owner of the Stream Team (an assembly of massively popular influencers and content creators) “One True King,” or OTK, a new wave of participants across North America and Europe were recruited into the second season of guild play. And there would be a lot more drama this time around as OnlyFangs would be diving headfirst into the world of roleplaying, demanding that everyone involved fully commit to the bit.


</p><section>
			

	<h2 id="section-heading">

	
		Related Content
	
	</h2>

	
	
</section>




<p>
	What they didn’t know was their experiment in <em>World of Warcraft</em> roleplay would inadvertently create one of the best emergent dramas on the internet.</p>



	



<p>
	In November 2024, OnlyFangs began the long journey to Molten Core, a level 60 dungeon, for their second season on the side of the Horde — <em>World of Warcraft</em>’s seemingly nefarious, but far more narratively complex faction. Choosing a faction, be it Horde or Alliance, impacts what quests players can pick up, what major cities and outposts they will have access to, and the races and classes they can select when it comes time to create a character.&nbsp;</p>



<p>
	Comprised of green Orcs, blue-hued and tusked Trolls, rotting Undead, and the bestial, horned Tauren, participating streamers were sorted into these four racial groups based on a personality test taken beforehand. This would also limit streamers on what classes they could play, as the options in Classic (also known as “vanilla”) <em>World of Warcraft </em>were not as expansive as they are now. But most importantly, once a streamer’s character died in game, that character would be gone forever, with the streamer forced to start from zero should they want to continue the challenge of making it to level 60 and completing Molten Core.</p>



<p>
	The nature of these specific servers means that there’s actually something to lose, that time and energy put into a character could be wasted with one bad encounter or another player fumbling with their button inputs or healing potions. This is one of the core components of what makes <em>World of Warcraft </em>Hardcore so compelling. It’s the risk factor that makes games <a href="https://www.rollingstone.com/culture/rs-gaming/elden-ring-shadow-of-the-erdtree-review-1235005986/" data-type="link" data-id="https://www.rollingstone.com/culture/rs-gaming/elden-ring-shadow-of-the-erdtree-review-1235005986/" target="_blank" rel="noreferrer noopener">like <em>Dark Souls</em> </a>so exciting to play or watch.

	</p>




<div>
	

<figure>

			
<div>
	
			<p><img src="https://www.rollingstone.com/wp-content/uploads/2025/01/003.jpg?w=1024" data-lazy-src="https://www.rollingstone.com/wp-content/uploads/2025/01/003.jpg?w=1024" alt="" data-lazy-srcset="" data-lazy-sizes="" height="576" width="1024" decoding="async">
			
			</p>
	
	</div>
	
			
			
<figcaption>
	
					<span>Followers watching PirateSoftware’s streams get his specific POV of the larger OnlyFangs world as a Troll.</span>
		
									<cite>PirateSoftware; Twitch; Blizzard Entertainment</cite>
					
	</figcaption>

			
</figure>

</div>



<p>
	On top of an already rigid set of rules and the high stakes environment, each streamer is expected to role-play as the character they had created, similar to a session of <em><a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/rs-gaming/critical-role-dungeons-and-dragons-interview-1235188141/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/rs-gaming/critical-role-dungeons-and-dragons-interview-1235188141/">Dungeons &amp; Dragons</a></em>. Adhering to the lore of <em>World of Warcraft</em> and responding to situations the way their character might<em>. </em>Are they a hard-headed Orc that had a lust for battle? Or are they an Undead that wouldn’t hesitate letting another player die if it meant their own survival? These factors contribute to how players approach specific situations and weave into how they interact with their fellow guild members. It’s like a <a rel="noreferrer noopener" data-id="https://www.rollingstone.com/culture/rs-gaming/valkyrae-youtuber-gta-v-roleplay-interview-1235005962/" target="_blank" data-type="link" href="https://www.rollingstone.com/culture/rs-gaming/valkyrae-youtuber-gta-v-roleplay-interview-1235005962/"><em>Grand Theft Auto</em> role-playing server</a>, just with high fantasy races and the shadow of perma-death looming over every dungeon run.&nbsp;</p>



<p>
	For the season, over 100 streamers, including members of OTK or other popular independent talents such as <a href="https://www.twitch.tv/piratesoftware" data-type="link" data-id="https://www.twitch.tv/piratesoftware" target="_blank" rel="noreferrer noopener nofollow">PirateSoftware</a>, are placed into factions and must stay in-character to create a sense of emergent storytelling. Some Troll players thank their deities, the “Loa,” (the gods of the Troll faction) for good luck or even claim to feel the death of another player through the invisible gods. In reality, the divine voice they “hear” is actually just an in-game notification that another player had bitten the dust. On top of this, each faction is vying against one another every week for the top spot, with the loser facing some kind of punishment. This fosters rivalries among the individual factions, adding to the narrative that continues to unfold week after week.</p>



<p>
	During each session, it’s up to the streamers to keep up the performance and remain in-character. This self-imposed rule creates organic events, making the streams more engaging to watch as players chat about the current activity of the guild and the latest gossip. With the amount of participants in every time zone, dozens of individual narratives emerge, creating a mix of faction and interpersonal politics within the guild.</p>



<div>
	

<figure>

			
<div>
	
			<p><img src="https://www.rollingstone.com/wp-content/uploads/2025/01/002.jpg?w=1024" data-lazy-src="https://www.rollingstone.com/wp-content/uploads/2025/01/002.jpg?w=1024" alt="" data-lazy-srcset="" data-lazy-sizes="" height="576" width="1024" decoding="async">
			
			</p>
	
	</div>
	
			
			
<figcaption>
	
					<span>Sequisha’s public execution in the arena had a ripple effect throughout the guild.</span>
		
									<cite>Sequisha; Twitch; Blizzard Entertainment</cite>
					
	</figcaption>

			
</figure>

</div>



<p>
	Other limitations are instated, such as the ability to trade materials and crafted items exclusively with one another. This had been an issue with OnlyFangs’ first attempt at Hardcore, with several members of OTK avoiding any direct repercussions for their reckless deaths as their followers floated them valuable items to gear up for follow-up runs after losing everything before.

	</p>




<p>
	Cooperation is essential to survive, as <em>World of Warcraft </em>in its earliest iterations relied on players to party up to complete quests and successfully run dungeons to obtain valuable gear. This allows for organic relationships between characters to form, and through the use of in-game proximity voice chat, which allows players to hear each other by getting physically close in virtual space, viewers become familiar with characters through the sound of their voice.</p>



<p>
	As the campaign evolves, each streamer’s specific schtick provides a different lens into the guild’s daily happenings. Watching PirateSoftware offers viewers a glimpse into the politicking and bickering over who would become the de facto Warchief for the Trolls. Dropping into <a rel="nofollow" data-id="https://www.twitch.tv/sequisha" data-type="link" href="https://www.twitch.tv/sequisha" target="_blank">Sequ</a><a rel="noreferrer noopener nofollow" data-id="https://www.twitch.tv/sequisha" target="_blank" data-type="link" href="https://www.twitch.tv/sequisha">i</a><a rel="nofollow" data-id="https://www.twitch.tv/sequisha" data-type="link" href="https://www.twitch.tv/sequisha" target="_blank">sha’</a>s stream gives a taste of the mundane, slice of life roleplaying the Undead faction engaged in. But this is <em>World of Warcraft</em>, and the world of Azeroth isn’t always kind of filled with the most charitable characters.</p>



	<h2 id="the-drama-begins">
		<strong>The drama begins</strong>	</h2>



<p>
	Early on, one event had already rocked the guild, as Sodapoppin announced that Sequisha had been caught cheating by breaking a cardinal rule. In order to create more inventory space for items he didn’t have room for, Sequisha abused the in-game auction house to store items. This was strictly prohibited, and due to the nature of his crime, he would be sentenced to trial by combat. The guild was abuzz with Trolls, Orcs, Tauren, and Undead sprinting to the Gurubashi arena to watch Sequisha fight for his life. If he could last a total of twenty minutes, killing anyone who entered the arena in honorable one-versus-one combat , he would be allowed to live. It seemed as though Sequisha would be given a second chance, that is, until he met defeat at the hands of another guild member, and all over the sum of 20 gold.</p>



<div>
	

<figure>

			
<div>
	
			<p><img src="https://www.rollingstone.com/wp-content/uploads/2025/01/005.jpg?w=1024" data-lazy-src="https://www.rollingstone.com/wp-content/uploads/2025/01/005.jpg?w=1024" alt="" data-lazy-srcset="" data-lazy-sizes="" height="576" width="1024" decoding="async">
			
			</p>
	
	</div>
	
			
			
<figcaption>
	
					<span>Streamers like Esfand take the roleplay to new heights, donning a cow mask that resembles his Tauren character.</span>
		
									<cite>EsfandTV; Twitch; Blizzard Entertainment</cite>
					
	</figcaption>

			
</figure>

</div>



<p>
	After Sequisha’s cheating, and the chaos that followed in his subsequent execution, the Undead mostly kept to their own. Because of how severe the punishment was, there was division within the guild and tense arguments that occurred on stream both in and out of character. But as the drama snowballed, streamers only leaned deeper into their characters. <a href="https://www.twitch.tv/esfandtv" data-type="link" data-id="https://www.twitch.tv/esfandtv" target="_blank" rel="noreferrer noopener nofollow">Esfand</a> (co-founder of OTK, playing a Tauren) began donning a mask during streams to fully immerse viewers into the character he was playing: a giant bipedal cow. Others even put on accents; in the case of Hubert, the Queen’s English to denote that he is of “higher intellect” and more cultured than his Orc brethren.

	</p>




<p>
	Despite the absurdity of watching a streamer try to navigate through dungeons and forests with a cow’s head pulled over his face, it shows a level of dedication to roleplaying that makes the OnlyFangs universe so enthralling. Its constant chaos becomes addictive to watch, like high fantasy reality TV.</p>



<p>
	Although there weren’t any more executions, OTK’s <a href="https://www.twitch.tv/mizkif" data-type="link" data-id="https://www.twitch.tv/mizkif" target="_blank" rel="noreferrer noopener nofollow">Mizkif </a>had been banished from his group and was temporarily left to fend for himself, leading to a near daily cycle of deaths and restarts. Hubert began gifting his fellow Orc with temporary intellect, which nearly caused an uprising amongst his clansmen.</p>



<p>
	However, as the event stretched on, streamers began to drop like flies. <a href="https://www.twitch.tv/larxa" data-type="link" data-id="https://www.twitch.tv/larxa" target="_blank" rel="noreferrer noopener nofollow">Larxa,</a> who had never played <em>World of Warcraft</em> before, was determined to become the first to reach level 60 without having any real experience with the game. While roaming through The Barrens, a vast field of grass littered with hostile creatures, she stumbled upon a patrol of centaurs, and run down and killed. Reaching the end would require perseverance and dedication — which she showed by jumping back into the saddle for a second attempt weeks later.</p>



<div>
	

<figure>

			
<div>
	
			<p><img src="https://www.rollingstone.com/wp-content/uploads/2025/01/004.jpg?w=1024" data-lazy-src="https://www.rollingstone.com/wp-content/uploads/2025/01/004.jpg?w=1024" alt="" data-lazy-srcset="" data-lazy-sizes="" height="576" width="1024" decoding="async">
			
			</p>
	
	</div>
	
			
			
<figcaption>
	
					<span>Larxa has taken on the level grind challenge, although her minimal experience has made it tough.</span>
		
									<cite>Larxa; Twitch; Blizzard Entertainment</cite>
					
	</figcaption>

			
</figure>

</div>



<p>
	While some members of OnlyFangs have reached level 60 as of reporting, none have tackled Molten Core, and for good reason. PirateSoftware describes the gauntlet of <em>World of Warcraft</em> Hardcore as more or less a test of knowledge. Those familiar with the game will no doubt have the edge over others who have never experienced these dungeons as they existed in the early days of the game. OnlyFangs has had to wait until enough players hit level 60, armed with better equipment, before tackling the final challenge. Without proper education and preparation,&nbsp; the number of possible deaths that could occur might set the entire guild back another series of weeks, or even a month.</p>



<p>
	The harsh reality of their task has pushed more streamers to help each other, easing previous tensions as alchemists created potions as temporary salves for wounds sustained in dungeon expeditions, weavers made cloth armor for healers and valuable bags to store items. It’s now understood that if OnlyFangs wanted to reach the end, they’ll need to do it together.

	</p>




	<h2 id="why-you-should-be-watching">
		<strong>Why you should be watching</strong>	</h2>



<p>
	What has been most surprising is the insistence of specific streamers to continue the long and hard road to level 60. Since the beginning of the event, <em>World of Warcraft</em> has remained within the top five games watched on Twitch, even with the release of highly anticipated titles like <em><a href="https://www.rollingstone.com/culture/rs-gaming/path-of-exile-2-explained-1235195377/" data-type="link" data-id="https://www.rollingstone.com/culture/rs-gaming/path-of-exile-2-explained-1235195377/" target="_blank" rel="noreferrer noopener">Path of Exile 2</a></em> and <em><a href="https://www.rollingstone.com/culture/rs-gaming/marvel-rivals-review-1235200428/" data-type="link" data-id="https://www.rollingstone.com/culture/rs-gaming/marvel-rivals-review-1235200428/" target="_blank" rel="noreferrer noopener">Marvel Rivals</a></em>. While this doesn’t necessarily translate to the amount of players in the MMORPG, it’s been riveting to watch how a nearly two decade old game has been rejuvenated by a simple server launch. As online celebrity-filled guilds like OnlyFangs continue to stretch the storytelling potential of <em>World of Warcraft</em>’s toolkit, the emergent drama and likelihood of ridiculous moments has become a massive draw.</p>



<p>
	For fans of <em>World of Warcraft</em>, there’s a clear upside as the game’s renewed popularity ensures its ongoing survival. With current viewership on Twitch rivaling that of a big new release or a massive content update for the free-to-play flavor of the week, Blizzard are bound to be paying attention in ways that will reflect future content for the game. For streamers, it’s a boon, as the living world of online roleplay makes for easy hours filled with content for their followers. And even for the more casual, the silent observer who knows nothing about <em>World of Warcraft</em> or each content creator’s persona, the interpersonal drama is enough to keep them coming back for more.

</p>



<p>
	Throughout my time watching, I’ve lovingly called these streams “my soaps.” Like any good TV show or online trends, what OnlyFangs is doing comes with a dash of FOMO; you simply have to be there. The emergent roleplay aspects and big names may be replicated, but it won’t be the same. There’s a special kind of in-the-moment urgency that comes with seeing a livestream trend rise in real-time.</p>



<p>
	After all, it’s not every day you tune into Twitch for a public execution.</p>
















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceSim (248 pts)]]></title>
            <link>https://pavelsevecek.github.io/</link>
            <guid>42587356</guid>
            <pubDate>Fri, 03 Jan 2025 17:05:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pavelsevecek.github.io/">https://pavelsevecek.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=42587356">Hacker News</a></p>
Couldn't get https://pavelsevecek.github.io/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[In Memoriam: Noah Gibbs (231 pts)]]></title>
            <link>https://blog.schwad.org/schwogs/6</link>
            <guid>42586879</guid>
            <pubDate>Fri, 03 Jan 2025 16:17:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.schwad.org/schwogs/6">https://blog.schwad.org/schwogs/6</a>, See on <a href="https://news.ycombinator.com/item?id=42586879">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <article>
          <div>
            
            <p><img src="https://blog.schwad.org/assets/noah-ffe1a87f.png" width="500"></p><p><em>Credit: Olivier Lacan</em>
</p><h2>The Ruby Community has lost one of its titans.</h2><p>
Noah Gibbs contributed to our community to <em>such a great an extent</em> in <em>so many different ways</em> in 
<strong>such a long period of time</strong>. It is a genuine challenge to sit down at a keyboard and capture a picture
of this wonderful person.
</p><p>However, I think it's important to take a few moments and give a testimony about someone 
who has meant so much to you. Why? Well, for the <strong>record</strong>. During my years of <a href="https://www.youtube.com/watch?v=rxp2E0efspM">Ruby Archaeology</a> 
(via newsletter, talk, blog or conversation) I found it incredibly valuable to see what the community 
had to say <em>about someone</em> who they had lost. Ezra, Chris, Jason, _why, those impacted by them took 
time to share their story and impact on their lives. Here is mine.
</p><h2>Meeting Noah</h2><p>
I've looked up to Noah since I joined the community in 2014. He was "Ruby Famous" to me, and I very much enjoyed his talks, writing, books and posts.
</p><p>Flash forward to the 2020's, when we were coworkers. Thanks to a lot of work and luck I found myself on the Ruby &amp; Rails Infrastructure Team at Shopify. Not long after, Noah joined. He wasn't a stranger at this point.. We'd engaged a fair bit on social media over the years. But I was <em>thrilled</em> to have him on my team! Isn't that like, your dream?
</p><p>Our interactions got more and more frequent. Noah popped up in a virtual ScotRug meetup (I live in Belfast, Noah in Inverness). I was pitching a talk idea where I would delve into old Ruby code. Noah's encouragement and mentorship resulted in me giving this talk at Ruby Kaigi, Ruby Conf, and Rails Conf. It even inspired a sequel talk that was also given at Ruby Kaigi, Ruby Conf and Rails Conf. Our ensuing work together would inspire my talk in the slot just before Noah at Brighton Ruby on Desktop Ruby development.
</p><p>Isn't it amazing what a little bit of support or encouragement can do?
</p><h2>Working with Noah</h2><p>
Noah was a supreme joy to work with. I'm sure this surprises no one. Noah made me feel <em>proud</em> of myself! He left me feeling inspired, curious and excited for my craft. I would share something "cool" with him and he'd give me half a dozen interesting ideas I could jump into off of that idea. We could talk for hours.
</p><p>In the private team chat you could always rely on him for a good geek out session. We were OBSESSED with the winter and summer solstices and how long/short the days get in Inverness and Belfast. It's really bonkers. We loved a good whisky chat (and why not! we live in whisky central!)
</p><p>Noah could criticize something in good faith in a kind way. He wouldn't really, shy away, from a spicy opinion. But he never gave it in a way that made you feel bad about yourself. What I'm saying is he wasn't squishy! But he was also incredibly aware of others and their feelings and just the nuance of life that we always have to dance around.
</p><p>He always had joy for the craft. It never got old. For fun we once revisited the <a href="https://www.rubykoans.com/">Ruby Koans</a> from Edgecase and I specifically recall
just how fired up he was about the silly little things a string can do in Ruby.
</p><h2>Scarpe</h2><p>
Noah, Marco Rudilosso and I founded the <a href="https://github.com/scarpe-team/scarpe">Scarpe</a> project in January 2022. The project was a simple idea: take a stab at getting feature parity with _why's Shoes.rb using Webview. Our thinking was Webview gives us the backend we want. Here's some HTML, now build it into multiple different packages for different platforms. So, how could we rebuild the Shoes DSL in _Ruby_ to push out raw HTML that would be fed to Webview?
</p><p>We made a decent amount of progress. In the end, Noah became the main engineering force. Although I am the maintainer, Noah (with full admin rights) doubled my commit count in the project. He also was the engineering architect behind most of our challenging work and decisions.
</p><p><img src="https://blog.schwad.org/assets/metrics-6fed81d3.png" width="500"></p><p>During our time on the team, Noah (essentially as the other half leading the project):
</p><ul><li>Helped facilitate weekly Scarpe meetings</li><li>Single handedly wrote our <a href="https://github.com/scarpe-team/scarpe/wiki">massive wiki</a> covering everything from Shoes history to reasoning behind our decisions.</li><li>Mentored multiple engineers who joined us as an official Google Summer of Code Ruby Project</li><li>All the while giving me the space as Maintainer to help set the vision and direction of the project, where he had every right to push me out</li><li>Invented the <a href="https://codefol.io/posts/introducing-spaceshoes/">SpaceShoes</a> prototype, which would let coders write Shoes Ruby code for the browser <strong>directly</strong> in their HTML.</li><li>Published a working fork of _why's music library <a href="https://github.com/scarpe-team/bloopsaphone">bloopsaphone</a>. &lt;-- This was needed for Shoes, but is its own independent library he helped save.</li><li>Implemented half a dozen new repos <a href="https://github.com/scarpe-team">around Scarpe</a>. This included implementations in GTK+ and WASM</li><li>Built <a href="https://github.com/scarpe-team/scarpe/blob/main/examples/highlander.rb">Highlander</a> which is without a doubt my favourite Shoes app <strong>of all time</strong></li></ul><p>I stepped back a bit from Scarpe in 2024 due to the birth of our first child. I am sad knowing that my future work on this project will be a little bit more lonely. Noah knew the codebase and history better than anyone alive. Our most recent chat in mid-October was him thanking me for finally turning off Rubocop. It's funny how much he disliked the linter! Which is fair enough - he had written Ruby in his own flair for years before standardized linting. Many of us have had lint beaten into our heads. I think I'll keep the linter out going forward.
</p><h2>More Noah stuff</h2><ul><li><a href="https://en.wikipedia.org/wiki/Mindstorms_(book">Mindstorms - Seymour Papert</a> 1980. Noah sent me a copy of this a few months ago. It inspired LEGO Mindstorms if you remember that. It encompasses a lot of what Noah thought about. Children, programming, learning, what an interface and coding experience really should <em>be like for people</em>. </li><li><a href="https://worrydream.com/LadderOfAbstraction/">Up and Down the Ladder of Abstraction - Bret Victor</a> Boy, at least in our work together, Noah referenced Bret Victor <em>a lot</em>. This essay is nothing short of beautiful. It discusses the <strong>boundary of theory and unknown</strong> and presents <em>The Ladder of Abstraction</em>.</li><li><a href="https://ncase.me/polygons/">Parable of the Polygons - Nicky Case</a> - Another conversation-starter Noah shared with me.</li><li><a href="https://www.rubyvideo.dev/speakers/noah-gibbs">Noah Speaking</a></li><li><a href="https://codefol.io/posts">Noah Writing</a></li><li><a href="https://www.google.com/search?q=%22noah+gibbs%22+podcast&amp;newwindow=1&amp;sca_esv=89d328a6064c3067&amp;sxsrf=ADLYWIIhESciJ7aCdkyEhnBH8cguAOotDQ%3A1735912457736&amp;source=hp&amp;ei=Cex3Z83bKpeFhbIPpubTmAc&amp;iflsig=AL9hbdgAAAAAZ3f6GevIFryzjY42iN5CKq4NGS4vUt3V&amp;ved=0ahUKEwiNhJzr2dmKAxWXQkEAHSbzFHMQ4dUDCBk&amp;uact=5&amp;oq=%22noah+gibbs%22+podcast&amp;gs_lp=Egdnd3Mtd2l6IhQibm9haCBnaWJicyIgcG9kY2FzdDIHECEYoAEYCjIHECEYoAEYCjIHECEYoAEYCkjmHFAAWKIccAB4AJABA5gBswOgAYcdqgEJNi41LjQuMy4xuAEDyAEA-AEBmAIPoALZEsICERAuGIAEGJECGMcBGIoFGK8BwgILEC4YgAQY0QMYxwHCAhEQLhiABBixAxjRAxiDARjHAcICDhAuGIAEGLEDGIMBGNQCwgILEAAYgAQYsQMYgwHCAhQQLhiABBiRAhjHARiKBRiOBRivAcICCBAAGIAEGLEDwgIFEAAYgATCAgUQLhiABMICCxAuGIAEGLEDGIMBwgIOEC4YgAQYsQMYgwEYigXCAgsQABiABBiRAhiKBcICCBAuGIAEGLEDwgIHEAAYgAQYCsICBRAhGKABmAMAkgcHNi40LjQuMaAHsqEB&amp;sclient=gws-wiz">Noah Gibbs many Podcast appearances</a></li><li><a href="https://codefol.io/portfolio/#interview">More Podcasts</a></li><li><a href="https://codefol.io/portfolio/#writing">Noah's Books</a></li></ul><h2>How to Honour Noah's Memory</h2><p>
Here is a message from Krissy:
</p><blockquote><p><em>What you can do for Noah is to dig deep into where you live. Meet more people. Say hello when it is hard. Take risks on people. Help every chance you get. Never forget his example. There is always more you have to give, and learn and do.</em></p></blockquote><blockquote><p><em>Never stop growing.</em></p></blockquote><blockquote><p><em>That's how you can honor Noah. It's all he wants for you</em></p></blockquote>
          </div>
        </article>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mandelbrot deep zoom theory and practice (2021) (129 pts)]]></title>
            <link>https://mathr.co.uk/blog/2021-05-14_deep_zoom_theory_and_practice.html</link>
            <guid>42586590</guid>
            <pubDate>Fri, 03 Jan 2025 15:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathr.co.uk/blog/2021-05-14_deep_zoom_theory_and_practice.html">https://mathr.co.uk/blog/2021-05-14_deep_zoom_theory_and_practice.html</a>, See on <a href="https://news.ycombinator.com/item?id=42586590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article>
<div xmlns="http://www.w3.org/1999/xhtml">
<h3 id="a2021-05-14_deep_zoom_theory_and_practice_introduction"><a href="#a2021-05-14_deep_zoom_theory_and_practice_introduction" title="Introduction">Introduction</a></h3>
<p>The complex beauty of the world's most famous fractal, the Mandelbrot set,
emerges from the repeated iteration of a simple formula:</p>
<blockquote>\[z \to z^2 + c\]</blockquote>
<p>Zooming into the intricate boundary of the shape reveals ever more detail,
but one needs higher precision numbers and higher iteration counts as you
go deeper.  The computational cost rises quickly with the classical
rendering algorithms which use high precision numbers for each pixel.</p>
<p>In 2013, K.I. Martin's SuperFractalThing and accompanying white paper
<a href="https://web.archive.org/web/20160408070057/http://superfractalthing.co.nf/sft_maths.pdf" title="sft_maths.pdf">sft_maths.pdf</a>
popularized a pair of new acceleration techniques.  First one notes that
the formula \(z \to z^2 + c\) is continuous, so nearby points remain
nearby under iteration.  This means you can iterate one point at high
precision (the reference orbit) and compute differences from the reference
orbit for each pixel in low precision (the perturbed orbits).  Secondly,
iterating the perturbed formula one ends up with a polynomial series in
the initial pertubation in \(c\), which depends only on the reference.  The
degree rises rapidly but you can truncate it to get an approximation.
This means you can compute the series approximation coefficients once, and
substitute in the perturbed \(c\) values for each pixel, allowing you to
initialize the perturbed orbits at a later iteration, skipping potentially
lots of per-pixel work.</p>
<p>The perturbation technique has since been extended to the Burning Ship
fractal and other "abs variations", and it also works for hybrid fractals
combining iterations of several formulas.</p>
<p>Prerequisites for the rest of this article: a familiarity with complex
numbers and algebraic manipulation; knowing how to draw the unzoomed Mandelbrot
set; understanding the limitations of computer implementation of numbers
(see for example <a href="https://fractalwiki.org/wiki/Number_types#Hardware_floating_point_types">Hardware Floating Point Types</a>).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_perturbation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_perturbation" title="Perturbation">Perturbation</a></h3>
<p>In the remainder of this post, lower case and upper case variables with
the same letter mean different things.  Upper case means unperturbed or
reference, usually high precision or high range.  Lower case means perturbed
per pixel delta, low precision and low range.</p>
<p>In perturbation, on starts with the iteration formula <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_1">\[Z \to Z^2 + C\]</blockquote>
<p>Perturb the variables with unevaluated sums <a href="#a2021-05-14_deep_zoom_theory_and_practice_2" title="Equation 2">[2]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_2">\[(Z + z) \to (Z + z)^2 + (C + c)\]</blockquote>
<p>Do symbolic algebra to avoid the catastrophic absorption when adding tiny
values \(z\) to large values \(Z\) (e.g. 1 million plus 1 is still 1 million
if you only have 3 significant digits to work with) <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_3">\[z \to 2 Z z + z^2 + c\]</blockquote>
<p>\(C, Z\) is the "reference" orbit, computed in high precision using <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a>
and rounded to machine double precision, which works fine most of the time.
\(c, z\) are the "pixel" orbit, you can do many of these near each reference
(e.g. an entire image).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_glitches"><a href="#a2021-05-14_deep_zoom_theory_and_practice_glitches" title="Glitches">Glitches</a></h3>
<p>There is a problem that can be noticed when you zoom deeper near certain
features in the fractal.  There are parts that can have a "noisy" appearance,
or there may be weird flat blobs that look out of place.  These are the
infamous perturbation glitches.  It was observed that adding references in
the glitches and recomputing the pixels could fix them, but there was no
reliable way to detect them programmatically until Pauldelbrot
discovered/invented a method:
<a href="http://www.fractalforums.com/announcements-and-news/pertubation-theory-glitches-improvement/msg73027/#msg73027" title="Perturbation Theory Glitches Improvement">Perturbation Theory Glitches Improvement</a>.</p>
<p>The solution: if <a href="#a2021-05-14_deep_zoom_theory_and_practice_4" title="Equation 4">[4]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_4">\[|Z+z| &lt;&lt; |Z|\]</blockquote>
<p>at any iteration, then glitches can occur.  The solution: retry with a
new reference, or (for well-behaved formulas like the Mandelbrot set) rebase
to a new reference and carry on.</p>
<p>Perturbation assumes exact maths, but some images have glitches when
naively using perturbation in low precision.  Pauldelbrot found his glitch
criterion by perturbing the perturbation iterations: one has perturbed iteration
as in <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> (recap: \(z \to 2 Z z + z^2 + c\)).  Then one perturbs this with
\(z \to z + e, c \to c + f\) <a href="#a2021-05-14_deep_zoom_theory_and_practice_5" title="Equation 5">[5]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_5">\[e \to (2 (Z + z) + e) e + f\]</blockquote>
<p>We are interested what happens to the ratio \(e/z\) under iteration, so
rewrite <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> as <a href="#a2021-05-14_deep_zoom_theory_and_practice_6" title="Equation 6">[6]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_6">\[z \to (2 Z + z) z + c\]</blockquote>
<p>Pattern matching, the interesting part (assuming \(c\) and \(f\) are
small) of \(e/z\) is \(2(Z + z) / 2 Z\).  When \(e/z\) is small, the nearby
pixels "stick together" and there is not enough precision in the number
type to distinguish them, which makes a glitch.  So a glitch can be detected
when <a href="#a2021-05-14_deep_zoom_theory_and_practice_7" title="Equation 7">[7]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_7">\[|Z + z|^2 &lt; G |Z|^2\]</blockquote>
<p>where G is a threshold (somewhere between 1e-2 and 1e-8, depending how
strict you want to be).  This does not add much cost, as \(|Z+z|^2\) already
needs to be computed for escape test, and \(G|Z^2|\) can be computed once
for each iteration of the reference orbit and stored.</p>
<p>The problem now is: How to choose G?  Too big and it takes forever as
glitches are detected all over, too small and some glitches can be missed
leading to bad images.</p>
<p>The glitched pixels can be recalculated with a more appropriate
reference point: more glitches may result and adding more references
may be necessary until the image is finished.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_rescaling"><a href="#a2021-05-14_deep_zoom_theory_and_practice_rescaling" title="Rescaling">Rescaling</a></h3>
<p>Double precision floating point (with 53 bits of mantissa) is more than
enough for computing perturbed orbits: even single precision (with 24 bits)
can be used successfully.  But when zooming deeper another problem occurs:
double precision has a limited range, once values get smaller than about
1e-308 then they underflow to 0.  This means perturbation with double
precision can only zoom so far, as eventually the perturbed deltas are
smaller than can be represented.</p>
<p>An early technique for extending range is to store the mantissa as a
double precision value, but normalized to be near 1 in magnitude, with
a separate integer to store the exponent.  This floatexp technique works
for arbitrarily deep zooms, but the performance is terrible because it
needs to handle every arithmetic operation in software (instead of them
being a single CPU instruction).</p>
<p>The solution for efficient performance turned out to be using an
unevaluated product (compare with the unevaluated sum of perturbation)
to rescale the double precision iterations to be nearer 1 and avoid
underflow: substitute \(z = S w\) and \(c = S d\) to get <a href="#a2021-05-14_deep_zoom_theory_and_practice_8" title="Equation 8">[8]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_8">\[S w \to 2 Z S w + S^2 w^2 + S d\]</blockquote>
<p>and now cancel out one scale factor \(S\) throughout <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_9">\[w \to 2 Z w + S w^2 + d\]</blockquote>
<p>Choose \(S\) so that \(|w|\) is around \(1\).  When \(|w|\) is at risk
of overflow (or underflow) after some iterations, redo the scaling; this
is typically a few hundred iterations as \(|Z|\) is bounded by \(2\) except
at final escape.</p>
<p>Optimization: if \(S\) underflowed to \(0\) in double precision, you
don't need to calculate the \(+ S w^2\) term at all when \(Z\) is not small.
Similarly you can skip the \(+ d\) if it underflowed.  For higher powers
there will be terms involving \(S^2 w^3\) (for example), which might not
need to be calculated either due to underflow.  Ideally these tests would
be performed once at rescaling time, instead of in every inner loop iteration
(though they would be highly predictable I suppose).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_full_iterations"><a href="#a2021-05-14_deep_zoom_theory_and_practice_full_iterations" title="Full Iterations">Full Iterations</a></h3>
<p>There is a problem: if \(|Z|\) is very small, it can underflow to \(0\)
in unscaled double in <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>.  One needs to store the full range \(Z\) and
do a full range (e.g. floatexp) iteration at those points, because \(|w|\)
can change dramatically.  Rescaling is necessary afterwards.  This was
described by Pauldelbrot:
<a href="https://fractalforums.org/programming/11/memory-bandwidth-trade-offs-for-perturbation-rendering/3717/msg23497#msg23497" title="Rescaled Iterations in Nanoscope">Rescaled Iterations in Nanoscope</a>.</p>
<p>To do the full iteration, compute \(z = S w\) in floatexp (using a floatexp
for \(S\) so that there is no underflow), do the perturbed iteration <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> with
all variables in floatexp.  To rescale afterwards, compute \(S = |z|\) and
\(w = z/S, d = c/S\) (computed in floatexp with \(w\) and \(d\) rounded to
double precision afterwards).  Then a double precision \(s\) can be computed
for use in <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_abs_variations"><a href="#a2021-05-14_deep_zoom_theory_and_practice_abs_variations" title="Abs Variations">Abs Variations</a></h3>
<p>The Burning Ship fractal modifies the Mandelbrot set formula by taking
absolute values of the real and imaginary parts before the complex squaring <a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_10">\[X + i Y \to (|X| + i |Y|)^2 + C\]</blockquote>
<p>When perturbing the Burning Ship and other "abs variations", one ends up with
things like <a href="#a2021-05-14_deep_zoom_theory_and_practice_11" title="Equation 11">[11]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_11">\[|XY + Xy + xY + xy| - |XY|\]</blockquote>
<p>which naively gives \(0\) by catastrophic absorption and cancellation.
laser blaster made a case analysis
<a href="http://www.fractalforums.com/new-theories-and-research/perturbation-formula-for-burning-ship-(hopefully-correct-p)/msg74090/#msg74090" title="Perturbation Formula for Burning Ship">Perturbation Formula for Burning Ship</a>
which can be written as <a href="#a2021-05-14_deep_zoom_theory_and_practice_12" title="Equation 12">[12]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_12"><pre>diffabs(c, d) := |c+d| - |c| = c &gt;= 0 ? c + d &gt;= 0 ? d : -(2*c+d) : c + d &gt; 0 ? 2*c+d : -d</pre></blockquote>
<p>when \(d\) is small the \(\pm d\) cases are much more likely.  With rescaling
in the mix <a href="#a2021-05-14_deep_zoom_theory_and_practice_11" title="Equation 11">[11]</a> works out as <a href="#a2021-05-14_deep_zoom_theory_and_practice_13" title="Equation 13">[13]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_13">\[\operatorname{diffabs}(XY/s, Xy + xY + sxy)\]</blockquote>
<p>which has the risk of overflow when \(s\) is small, but the signs work
out ok even for infinite \(c\) as \(d\) is known to be finite.  Moreover,
if \(s = 0\) due to underflow, the \(\pm d\) branches will always be taken
(except when \(XY\) is small, when a full floatexp iteration will be performed
instead), and as \(s \ge 0\) by construction, <a href="#a2021-05-14_deep_zoom_theory_and_practice_13" title="Equation 13">[13]</a> reduces to <a href="#a2021-05-14_deep_zoom_theory_and_practice_14" title="Equation 14">[14]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_14">\[\operatorname{sign}(X) * \operatorname{sign}(Y) * (X y + x Y)\]</blockquote>
<p>(Note: this formulation helps avoid underflow in \(\operatorname{sign}(XY)\)
when \(X\) and \(Y\) are small.)</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_deep_needle"><a href="#a2021-05-14_deep_zoom_theory_and_practice_deep_needle" title="Deep Needle">Deep Needle</a></h3>
<p>For well-behaved functions like the Mandelbrot set iterations, one needs
to do full iterations when \(Z\) gets small.  For the Burning Ship and other
abs variations, this is not sufficient: problems occur if either X and Y are
small, not only when both are small at the same time.  Full iterations need
to be done when either variable is small.  This makes rescaled iterations for
locations near the needle slower than just doing full floatexp iterations
all the time (because of the extra wasted work handling the rescaling).
This is because near the needle all the iterations have Y near 0, which means
floatexp iterations will be done anyway.  Using floatexp from the get go avoids
many branches and rescaling in the inner loop, so it's significantly faster.
The problem is worse in single precision because it has much less range: it
underflows below 1e-38 or so, rather than 1e-308 for double precision.</p>
<p>The problem of automatically detecting these "deep needle" locations (which
may be in the needles of miniships) and switching implementations to avoid the
extra slowdown remains unresolved in KF.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_hybrid_fractals"><a href="#a2021-05-14_deep_zoom_theory_and_practice_hybrid_fractals" title="Hybrid Fractals">Hybrid Fractals</a></h3>
<p>The Mandelbrot set has lovely logarithmic spirals all over, and the
Burning Ship has interesting "rigging" on the miniships on its needle.
Hybridization provide a way to get both these features in a single
fractal image.  The basic idea is to interleave the iteration formulas,
for example alternating between <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a> and <a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a>, but more complicated
interleavings are possible (eg <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a> in a loop, etc).</p>
<p>Hybrid fractals in KF are built from stanzas, each has some lines, each
line has two operators, and each operator has controls for absolute x,
absolute y, negate x, negate y, integer power \(p\), complex multiplier \(a\).
The two operators in a line can be combined by addition, subtraction or multiplication,
and currently the number of lines in a stanza can be either 1 or 2 and
there can be 1, 2, 3 or 4 stanzas. The output of each line is fed into
the next, and at the end of each stanza the +c part of the formula happens.
There are controls to choose how many times to repeat each stanza, and which
stanza to continue from after reaching the end.</p>
<p>Implementing perturbation for this is quite methodical.  Start from an
operator, with inputs \(Z\) and \(z\).  Set mutable variables:</p>
<blockquote><pre>z := input
W := Z + z
B := Z</pre></blockquote>
<p>If absolute x enabled in formula, then update</p>
<blockquote><pre>re(z) := diffabs(re(Z), re(z))
re(W) := abs(W)
re(B) := abs(B)</pre></blockquote>
<p>Similarly for the imaginary part.  If negate x enabled in formula, then update</p>
<blockquote><pre>re(z) := -re(z)
W := -W
B := -B</pre></blockquote>
<p>Similarly for the imaginary part. Now compute</p>
<blockquote>\[S = \sum_{i=0}^{p-1} W^i B^{p-1 - i}\]</blockquote>
<p>and return \(a z S\).  Combining operators into lines may be done by
<a href="https://mathr.co.uk/blog/2018-03-12_perturbation_algebra.html" title="Perturbation Algebra">Perturbation Algebra</a>.
Combining lines into stanzas can be done by iterating unperturbed \(Z\)
alongside perturbed \(z\); only the \(+C\) needs high precision, and that
is not done within a stanza.</p>
<p>Rescaling hybrid iterations seems like a big challenge, but it's not that hard:
if either or both the real and imaginary parts of the reference orbit \(Z\)
are small, one needs to do a full range iteration with floatexp and recalculate
the scale factor afterwards, as with formulas like Burning Ship.  Otherwise,
thread \(s\) through from the top level down to the operators.  Initialize with</p>
<blockquote><pre>W := Z + z*s</pre></blockquote>
<p>and modify the absolute cases to divide the reference by \(s\):</p>
<blockquote><pre>re(z) := diffabs(re(Z/s), re(z))</pre></blockquote>
<p>Similarly for imaginary part.  When combining operators (this subterm only
occurs with multiplication) replace \(f(o_1, Z + z)\) with \(f(o_1, Z + z s)\).</p>
<p>And that's almost all the changes that need to be made!</p>
<p>For distance estimation of hybrid formulas I use dual numbers for
automatic differentiation.  One small adjustment was needed for it to work
with rescaled iterations: instead of initializing the dual parts (before
iteration) with 1 and scaling by the pixel spacing at the end for screen-space
colouring, initialize the dual parts with the pixel spacing and don't scale
at the end.  This avoids overflow of the derivative, and the same rescaling
factor can be used for regular and dual parts.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_code_generation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_code_generation" title="Code Generation">Code Generation</a></h3>
<p>Naive implementations of parametric hybrids are very slow due to all
the branches in the inner loops (checking if absolute x enabled at every
iteration for every pixel, etc).  Using for example OpenCL, these branches can
be done once when generating source code for a formula, instead of every
iteration for every pixel.  This runs much faster, even when compiled
to run on the same OpenCL device that is interpreting the parametric code.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_series_approximation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_series_approximation" title="Series Approximation">Series Approximation</a></h3>
<p>The other part of the thing that K I Martin's SuperFractalThing popularized
was that iteration of <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> gives a polynomial series in \(c\) <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_15">\[z_n = \sum A_{n,k} c^k\]</blockquote>
<p>(with 0 constant term). This can be used to "skip" a whole bunch of
iterations, assuming that truncating the series and/or low precision
doesn't cause too much trouble.  Substituting <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a> into <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> gives <a href="#a2021-05-14_deep_zoom_theory_and_practice_16" title="Equation 16">[16]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_16">\[\sum A_{n+1,k} c^k = 2 Z \sum A_{n,k} c^k + (\sum A_{n,k} c^k)^2 + c\]</blockquote>
<p>Equating coefficients of \(c^k\) gives recurrence relations for the
series coefficients \(A_{n,k}\).  See <a href="https://mathr.co.uk/blog/2016-03-06_simpler_series_approximation.html" title="Simpler Series Approximation">Simpler Series Approximation</a>.</p>
<p>The traditional way to evaluate that it's ok to do the series approximation
at an iteration is to check whether it doesn't deviate too far from regular
iterations (or perturbed iterations) at a collection of "probe" points.
When it starts to deviate, roll back an iteration and initialize all the
image pixels with <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a> at that iteration.</p>
<p>Later, knighty extended the series approximation to two complex variables.
If the reference \(C\) is a periodic point (for example the center of a
minibrot), the biseries in \(z, c\) allows skipping a whole period of
iterations.  Then multiple periods can be skipped by repeating the biseries
step.  This gives a further big speedup beyond regular series approximation
near minibrots.  An escape radius is needed for \(z\), based on properties
of the reference, so as not to perform too many biseries iterations.  After
that, regular perturbed iterations are performed until final escape.  This
is available in KF as NanoMB1.</p>
<p>Current research by knighty and others involves a chain of minibrots
at successively deeper zoom levels.  One starts with the deepest minibrot,
performing biseries iterations until it escapes its \(z\) radius.  Then
rebase the iterates to the next outer minibrot, and perform biseries
iterations with that.  Repeat until final escape.  This is available in
KF as NanoMB2, but it's highly experimental and fails for many locations.
Perhaps it needs to be combined with more perturbation or higher precision:
sometimes the iterates may still be too close to each other when they
escape a deep minibrot, such that catastrophic absorption occurs.
In progress...</p>
<p>For Burning Ship and other abs variations (and presumably hybrids too),
series approximation can take the form of two bivariate real series in
\(\Re(c)\) and \(\Im(c)\) for the real and imaginary parts of \(z\).  But
these are only good so long as the region is not folded by an absolute
value, so typically only a few iterations can be skipped.  Maybe the series
can be split into two (or more) parts with the other side(s) shifted when
this occurs?  In progress...</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_conclusion"><a href="#a2021-05-14_deep_zoom_theory_and_practice_conclusion" title="Conclusion">Conclusion</a></h3>
<p>Perturbation techniques that greatly reduce the quantity of high precision
iterations needed, as well as (for well-behaved formulas) series approximation
techniques that reduce the quantity of low precision iterations needed still
further, provide a vast speedup over classical algorithms that use high
precision for every pixel.  Rescaling can provide an additional constant factor
speedup over using full range floatexp number types for most (not "deep needle")
locations.  Chained biseries approximation ("NanoMB2") and series approximation
for abs variations and hybrids are still topics of research.</p>
<p>It remains open how to choose the \(G\) for Pauldelbrot's glitch detection
criterion, and how to robustly compute series approximation skipping: there
is still no complete mathematical proof of correctness with rigourous error
bounds, although the images do most often look plausible and different
implementations do tend to agree.</p>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[System76 built the fastest Windows Arm PC (121 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2025/system76-built-fastest-windows-arm-pc</link>
            <guid>42586291</guid>
            <pubDate>Fri, 03 Jan 2025 15:10:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2025/system76-built-fastest-windows-arm-pc">https://www.jeffgeerling.com/blog/2025/system76-built-fastest-windows-arm-pc</a>, See on <a href="https://news.ycombinator.com/item?id=42586291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>System76 built their first workstation-class Arm PC, the <a href="https://system76.com/desktops/thelio-astra-a1-n1/configure">Thelio Astra</a>, and it's marketed for <a href="https://system76.com/autonomous-vehicles">streamlined autonomous vehicle development</a>.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-hero.jpeg" alt="System76 Thelio Astra - Hero with Launch Keyboard"></p>

<p>But I'm not an automotive developer, just someone who enjoys Linux, Arm, and computing. So I was excited to spend a few weeks (which turned into a few <em>months</em>) testing the latest Ampere-based computer to come to market.</p>

<p>I initially ran my <a href="https://github.com/geerlingguy/sbc-reviews/issues/53">gauntlet of tests</a> under Ubuntu 24.04 (the OS this workstation ships with), but after discovering System76 dropped in ASRock Rack's <a href="https://www.newegg.com/asrock-rack-tpm-spi/p/N82E16816775069">TPM 2.0 module</a>, I switched tracks and installed Windows 11—which went without a hitch!</p>

<p>With that, I spent some time comparing this workstation to the current 'best of breed' Windows on Arm PC, the models based on Snapdragon's X Elite chips. And this thing <em>wipes the floor</em>.</p>

<h2>Hardware - Ampere Altra (Max)</h2>

<p>But before we get into Linux, Windows, benchmark results, and why I'm not running Pop!_OS, we should discuss the hardware.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-rear.jpg" alt="System76 Thelio Astra - Rear"></p>

<p>The base model costs $3,299—which is in line with most x86 workstation-class PCs, at least in the Threadripper and Xeon W range. That'll get you a 64-core CPU, 64GB of ECC RAM, 500 GB of NVMe storage, an Nvidia RTX A400 Workstation GPU, and dual 10 GbE Ethernet.</p>

<p>But the configuration System76 sent me for review had some upgrades:</p>

<ul>
<li>Ampere Altra Max M128-30 CPU (128 Neoverse N1 CPU cores at 3.00 GHz)</li>
<li>512 GB ECC DDR4 RAM</li>
<li>1TB NVMe SSD</li>
<li>Dual 25 GbE Ethernet (on-motherboard, Broadcom NIC)</li>
<li>ASRock Rack TPM 2.0 module</li>
</ul>

<p>This upgraded configuration costs around $7,000—which is the <em>starting price</em> of an M2 Ultra Mac Pro workstation.</p>

<p>Note that you can buy every part of this system—aside from System76's case and support—from a retailer like NewEgg (e.g. <a href="https://www.newegg.com/asrock-rack-altrad8ud-1l2t-q64-22-ampere-altra-max-ampere-altra-processors/p/N82E16813140135">the motherboard + CPU combo</a> for $2349) should you wish to build a custom arm64 workstation PC.</p>

<p>Everything is built into System76's Thelio case, which is very solid sheet metal with a design similar to the Mac Pro, where the entire shell slides over the top, revealing the chassis within:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-inside-cooling.jpg" alt="System76 Thelio Astra - Open Inside Cooling Zones"></p>

<p>There are three distinct cooling zones—and despite having no mesh or holes in the front (it's a solid facade), there is enough airflow for HEDT-class performance. The top contains a custom metal shroud to guide airflow through the <a href="https://amzn.to/3WrVQ7l">Arctic Freezer 4U-M CPU cooler</a>, directing it's airflow over the RAM and motherboard power regulators to an exhaust fan in the back.</p>

<p>The middle section has a wide metal fan bracket which provides a ton of intake for GPUs and other PCIe devices.</p>

<p>The bottom has an additional 140mm intake fan to pull air up to the GPU area and motherboard, as well as the power supply, drawing air from the bottom.</p>

<p>The result is an elegant, if heavy, case, that maximizes airflow while keeping the system <em>very</em> quiet. During long HPL and Cinebench runs, the noise only rose to a low 40 dB range, and with 140mm and 120mm fans, the sound was not unpleasant.</p>

<p>The default fan curve keeps the CPU down to around 60°C fully loaded, so there's even wiggle room if you wanted to adjust it. It should be noted my initial review unit had a bug in the BIOS which resulted in the fan curve not being applied—so my first tests were literally cooking the CPU to thermal limits!</p>

<p>I saw it hit 99°C a few times, with the CPU pulling 250W, and entire system power draw at 450W, then the system would hard lock up until I pulled power!</p>

<p>Luckily, a firmware update fixed that issue universally, and the proper installation of a <code>system76</code> background daemon allowed me to tweak things further.</p>

<p>There are three aspects of the case design I do <em>not</em> like, however:</p>

<ol>
<li>The custom case design includes screwless PCIe slot covers—however, these covers are a bit loose, and besides rattling when transporting the computer, they are prone to popping out whenever you loosen the retention bracket that holds PCIe cards in place. Which is highly annoying when adding or replacing cards in the 4 x16 card slots!</li>
<li>There is no front IO with the current Astra design—and only four USB 3.2 Gen 1 Type-A ports on the rear. So in my use, I needed a USB hub (the first time I've had to use one in a while!). It would be nice to have some front panel IO, even if only one or two USB-C ports.</li>
<li>Unlike the Mac Pro, this case has no handles, and the front edge is flush with the surface it's resting on. This can make picking it up, moving it around, and removing the top case a little awkward. It's not a huge deal, but I <em>do</em> love Apple's case design in that regard, considering you might want to put one of these on wheels and move it around a bit.</li>
</ol>

<h2>Linux (and no Pop!_OS... yet)</h2>

<p>The primary reason someone would buy this thing is for automotive development. Since most cars and infotainment systems run on Arm chips, building software with an Arm workstation makes sense—it's a lot faster compiling Arm software and running tests on it natively on a monster Arm CPU than even the fastest AMD or Intel CPU with emulation.</p>

<p>The nice thing about System76 selling this machine is you get their excellent support (you can choose from 1-3 years of support at purchase). This is a huge boon to businesses who elect to run open source software, because they get a fully-supported hardware configuration instead of having to figure out compatibility themselves.</p>

<p>And System76 builds Pop!_OS (and a new COSMIC desktop environment), which is meant to ease the adoption of Linux for desktop use... unfortunately, Pop!_OS is not yet fully supported on arm64.</p>

<p>In lieu of that, System76 is shipping Ubuntu 24.04 (or 22.04, your choice), which has great support for Ampere CPUs already, and in my experience, is the easiest Linux distribution to run when working on various hardware configurations. Arm64 driver compatibility is excellent with most anything made in the last 5-10 years, including graphics cards from AMD and Nvidia!</p>

<h2>Performance</h2>

<p>To see <em>all</em> my benchmark data, see my <a href="https://github.com/geerlingguy/sbc-reviews/issues/53">GitHub issue on the Thelio Astra</a>. But here are a few selected benchmarks I'd like to highlight:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-benchmark-hpl.png" alt="System76 Thelio Astra - HPL Benchmark Results"></p>

<p>Besides the 192-core AmpereOne, which <a href="https://www.jeffgeerling.com/blog/2024/ampereone-cores-are-new-mhz">I reviewed late last year</a>, no other Arm machine comes close to the overall performance of Ampere's Altra Max—at least as far as multi-core is concerned.</p>

<p>Single-core, the Neoverse N1 cores are getting long in the tooth, but still faster than any of the common SBC cores (like the A76 and A78).</p>

<p>But multi-core, the Thelio Astra takes advantage of all eight DDR4 memory channels available on an Ampere Altra Max CPU, and propels it past the previous champ, the <a href="https://www.jeffgeerling.com/blog/2023/testing-96-core-ampere-altra-developer-platform">Adlink Dev Workstation</a>. That machine was limited to 6 memory channels, though it <em>did</em> have a bit more panache, courtesy of built-in RGB fans :)</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-benchmark-linux.png" alt="System76 Thelio Astra - Linux Timed Compile Benchmark Results"></p>

<p>I benchmarked a number of things with Phoronix Test Suite, and above are some results for the timed Linux compilation benchmark. This machine obviously scores worse than the AmpereOne, but I left in the fastest current Arm SBC I own (an Orange Pi 5 Max), to show the massive difference you get with 128 cores and enough high-speed memory to feed them.</p>

<p>Eagle-eyed readers will note I have not shown any Threadripper or EPYC results, nor anything x86 at all! That's because core-for-core, x86 dominates on many, if not most, benchmarks, especially current-generation core designs like Zen 5. The Ampere Altra is now 5 years old, and though it still has some fight in it, it can't keep up with 'the big boys'.</p>

<p>That is, unless we <em>change the rules of the game</em>...</p>

<h2>Windows on Arm and a Cinebench 2024 WR</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-benchmark-cinebench.png" alt="System76 Thelio Astra - Cinebench 2024 Benchmark Results"></p>

<p>Being the fastest Arm PC means it <em>of course</em> obliterates the fastest Mac Pro money can buy—to say nothing of the puny Snapdragon X Elite I tested in the very-short-lived Dev Kit last year.</p>

<p>But this system is <em>also</em> unofficially the fastest 128-core system on the planet, running Cinebench 2024. At least <a href="https://hwbot.org/benchmark/cinebench_-_2024/rankings?cores=128&amp;hardwareType=cpu">according to HWBot.org</a>.</p>

<p>I've been <a href="https://community.hwbot.org/topic/40155-please-add-other-hardware-thread/page/40/#findComment-684073">attempting to submit a result of <code>5003 cb</code></a>, but am stymied by a technicality: The Ampere Altra Max is apparently too exotic to exist in most Windows PC hardware databases, so submissions aren't able to be made!</p>

<p>I've been in contact with the authors of CPU-Z, and am hopeful we can get more results for high-end Arm chips into HWBot soon. We'll see!</p>

<p>It is a bit difficult to overclock these chips, but I <em>can</em> coax a little more performance out of them by cooling them better. I was able to increase the score consistently by 2-3% running the fans at 100%... one wonders if more gains could be had!</p>

<p>But I'm burying the lede—full Windows 11 is running on this machine. And not like "spend 6 hours patching things together to get Windows running", but <em>download ISO, plug in USB stick, and install</em>.</p>

<p>It's been possible to install Windows on Arm to earlier Ampere Altra systems, but a <a href="https://github.com/AmpereComputing/Windows-11-On-Ampere">rather annoying process involving UUP Dump was required</a>. Now that Microsoft is <em>finally</em> publishing a <a href="https://www.microsoft.com/en-us/software-download/windows11arm64">Windows 11 arm64 ISO</a>, <a href="https://github.com/AmpereComputing/Windows-11-On-Ampere/issues/6">the process has become much easier</a>.</p>

<p>And x86 software that runs in Windows' emulation mode is still limited to using only 64 CPU cores, but native arm64 versions can address all 128 cores on the Ampere Altra Max. Cinebench 2024 had a bug where it would still only address 64 cores on the Arm version, but that has since been fixed:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-cinebench-all-core.jpg" alt="System76 Thelio Astra - Cinebench 2024 multi 128 core task manager"></p>

<h2>Productivity</h2>

<p>If Windows can run, what about the vast library of software Microsoft's been touting as native on Arm, like on their new AI Copilot+ PCs?</p>

<p>Well, I loaded up a number of apps, and Photoshop worked great right away:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-windows-photoshop.jpg" alt="System76 Thelio Astra - Photoshop running on Windows"></p>

<p>Everything ran well, including new AI features like generative AI fill, AI-assisted remove and background isolation tools, etc. It was smooth enough I couldn't really tell a difference from working on my M1 Max Mac Studio (where I normally do work on YouTube thumbnails and graphics for videos).</p>

<p>But I quickly ran into issues launching other applications...</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-windows-arm-davinci-opengl.jpg" alt="System76 Thelio Astra - OpenGL not found in Davinci Resolve"></p>

<p>The problem is, any app that requires GPU support or OpenGL has trouble, because even though <em>from what I've heard</em> Nvidia has working Arm drivers for Windows... none have been released publicly. So no matter what GPU you try, you can't get any kind of graphics acceleration working in Windows.</p>

<p>ASPEED's little BMC chip has a built-in VGA controller, and they even have a Windows Arm driver for it... but despite its best effort, it has no 3D graphics rendering capabilities or GPU compute!</p>

<p>In the video embedded later, I also demonstrated running Minecraft and Crysis Remastered in Windows, but both rely on CPU rendering, which is... just not ideal at all. You could play both games if you enjoy powerpoint-presentation-style gameplay.</p>

<h2>Linux Gaming with Steam, Proton, and Box86</h2>

<p>Luckily, switching back to Linux solves that issue. Games not only run with 3D acceleration, they run <em>smoothly</em>.</p>

<p>Crysis Remastered rendered out smoothly in 'Can It Run Crysis?' mode, Halo 3 ran just as smooth as an Xbox 360, and Doom Eternal—with Ray Tracing enabled—ran well enough to be playable, though the older workstation A4000 GPU I was testing it with is <em>not</em> meant for gaming by any stretch.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/system76-thelio-astra-doom-eternal-gpu-steam.jpg" alt="System76 Thelio Astra - Doom Eternal on Steam with Proton and Box86"></p>

<p>This is <em>not</em> a gaming machine. But I was able to install Box86/Box64 and Steam using <a href="https://pi-apps.io/">Pi-Apps</a> (it's literally one click to get Steam installed!), and then I could play a number of games; almost anything that runs through Proton can play on arm64 nowadays, and <a href="https://box86.org/2024/12/new-version-of-box64-v0-3-2-and-box86-v0-3-8/">Box32 is now trying to fill the gap</a> with more modern Linux distros which are dropping support for 32-bit packages!</p>

<h2>Quirks and Downsides</h2>

<p>To paint a complete picture of the experience running System76's first arm64 desktop, I also have to run through some of the quirks inherent to the hardware design, and to running Ampere's silicon:</p>

<ul>
<li>Video card support for arm64 is still not perfect; <code>nouveau</code> <em>really</em> has issues, depending on kernel version and card, and even Nvidia's proprietary drivers can cause weird issues, like a blank screen with just a mouse cursor, or an invisible second display, and debugging these problems can become challenging, since the ASPEED BMC also supplies a built-in VGA display... which can sometimes confuse both Windows and Linux when you're sorting out driver issues!</li>
<li>AMD GPUs have a text artifacting bug that requires a patch to the <code>amdgpu</code> driver to fix. It didn't seem to break my experience using the machine, but it's just another quirk to deal with on arm64.</li>
<li>There are still very few people running arm64 in a 'professional' manner like through this workstation. So you often have to convince people that <em>yes</em>, you're using arm64, but <em>no</em>, you're not dealing with a puny SBC like a Raspberry Pi. It leads to some interesting support tickets, though, especially for Windows devs who were led to believe Snapdragon is the penultimate Windows on Arm processor :)</li>
</ul>

<h2>Video and more</h2>

<p>If this blog post wasn't enough, I have a full video where I go even more in depth, and give a better idea of how well games and applications run under both Linux and Windows. I also go into more detail on my GPU upgrades and some of the random bugs I ran into (and how I resolved them with System76's help). You can watch it here:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/AshDjtlV6go" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>Thank you to System76 and Ampere for providing the hardware and supporting my three months of testing, leading up to this review. And thank you to Micro Center for providing two workstation graphics cards for more testing.</p>

<p>System76 also recently sent over an Nvidia RTX 4080 Super, and I will be installing that and trying to resolve some lingering issues with Blender and Steam.</p>

<p>My biggest takeaway: <em>Microsoft is missing out on a lotta fun.</em> They need to convince their hardware partners to start supporting Arm64, if they want any chance at catching up to Linux for arm64.</p>

<p>If you're interested in the Thelio Astra, you can <a href="https://system76.com/desktops/thelio-astra-a1-n1/configure">configure and buy one on System76's website</a>.</p>

<h2>If you made it this far...</h2>

<p>If you like the idea of me writing these ad, cookie, and tracking-free blog posts... would you consider sponsoring my work on <a href="https://www.patreon.com/geerlingguy">Patreon</a> or <a href="https://github.com/sponsors/geerlingguy">GitHub</a>?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What we learned copying all the best code assistants (132 pts)]]></title>
            <link>https://blog.val.town/blog/fast-follow/</link>
            <guid>42586042</guid>
            <pubDate>Fri, 03 Jan 2025 14:45:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.val.town/blog/fast-follow/">https://blog.val.town/blog/fast-follow/</a>, See on <a href="https://news.ycombinator.com/item?id=42586042">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-bvzihdzo=""> <article itemscope="" itemtype="https://schema.org/Article" data-astro-cid-bvzihdzo="">  <div data-astro-cid-bvzihdzo=""> <div data-astro-cid-bvzihdzo="">  <p><img src="https://blog.val.town/_astro/steve.X7ylcW9k_ZMjRK9.webp" srcset="https://blog.val.town/_astro/steve.X7ylcW9k_ZMjRK9.webp 1x, https://blog.val.town/_astro/steve.X7ylcW9k_Z1ReC3G.webp 2x, https://blog.val.town/_astro/steve.X7ylcW9k_282LrH.webp 3x" alt="Steve Krouse" title="Steve Krouse" data-astro-cid-h4usap26="true" width="20" height="20" loading="lazy" decoding="async"> 
on
<time datetime="2025-01-03T00:00:00.000Z"> Jan 3, 2025 </time>  </p> </div>  <p>Since the beginning of Val Town, our users have been clamouring for the state-of-the-art <abbr title="Large Language Model">LLM</abbr> code generation experience. When we launched our code hosting service in 2022, the state-of-the-art was GitHub Copilot. But soon it was ChatGPT, then Claude Artifacts, and now <a href="https://bolt.new/">Bolt</a>, <a href="https://www.cursor.com/">Cursor</a>, and <a href="https://codeium.com/windsurf">Windsurf</a>. We’ve been trying our best to keep up. Looking back over 2024, our efforts have mostly been a series of <em>fast-follows</em>, copying the innovation of others. Some have been successful, and others false-starts. This article is a historical account of our efforts, giving credit where it is due.</p>
<h3 id="github-copilot-completions"><a href="#github-copilot-completions">GitHub Copilot Completions</a></h3>
<p>The story starts, of course, with GitHub Copilot. From day 1, Val Town users asked for a GitHub-Copilot-like completions experience.</p>
<p>We were wary of building this ourselves, but one day we stumbled upon Asad Memon’s <a href="https://github.com/asadm/codemirror-copilot">codemirror-copilot</a>, and hooked it up. That gave us our first taste of LLM-driven autocomplete, but behind the scenes, it was using ChatGPT. The prompt essentially asked ChatGPT to cosplay as an autocomplete service and fill in the text at the user’s cursor. So it was fairly slow, occasionally the model would forget its role and do something unexpected, and it didn’t have the accuracy of a purpose-built autocomplete model.</p>
<p>We wanted a faster, more accurate autocomplete sytem, one that used a model trained for the task - which is technically called <a href="https://arxiv.org/abs/2207.14255">‘Fill in the Middle’</a>. Finding an option that we could use within a product like Val Town was tricky – Copilot and most of its competitors lack documented or open APIs. But <a href="https://codeium.com/">Codeium</a> did, and they also had very good accuracy and performance. We <a href="https://blog.val.town/blog/val-town-newsletter-16/#-codeium-completions">launched Codeium completions</a> in April 2024 and open-sourced our <a href="https://github.com/val-town/codemirror-codeium">codemirror-codeium</a> component. It’s been pretty great. It’s enabled by default for new users.</p>
<p><img src="https://blog.val.town/_astro/codeium.DmWVlUN2_ZSR3s9.webp" alt="Codeium" width="903" height="324" loading="lazy" decoding="async"></p>
<h3 id="chatgpt"><a href="#chatgpt">ChatGPT</a></h3>
<p>Then came ChatGPT. We found our users asking it to write Val Town code, and copying and pasting it back into Val Town. We figured we could automate that process for our users: provide an interface with a pre-filled system prompt and a one-click way to save the generated code as a val. The <a href="https://blog.val.town/blog/val-town-newsletter-18/#-townie">first version of Townie</a> was born: a simple chat interface, very much inspired by ChatGPT, powered by GPT-3.5.</p>
<p><img src="https://blog.val.town/_astro/townie.B_9WgDMi_Z1eUctW.webp" alt="Townie" width="2310" height="2012" loading="lazy" decoding="async"></p>
<p>It was just ok. It didn’t get much use, mostly because it was hard to iterate on its results. Getting good results from an LLM usually requires a conversation because programming-via-English is pretty imprecise, and you need follow-up requests to clarify your needs.</p>
<h3 id="chatgpt-tool-use"><a href="#chatgpt-tool-use">ChatGPT Tool Use</a></h3>
<p>Earlier this year, ChatGPT Function Calling, now called ‘tool-use’, was seen as the next big thing. The promise was that with a good OpenAPI spec, AI would be able to do just about anything on Val Town. So we dutifully cleaned up our OpenAPI spec, and <a href="https://blog.val.town/blog/openapi/#our-ai-townie-can-now-call-our-rest-api">rebuilt Townie around it</a>.</p>
<iframe width="100%" height="420" src="https://www.youtube-nocookie.com/embed/clj1prZunW0?si=O7l6qvW8B2OB79NT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<p>It was, ahem, fine. Function calling was a disappointment. You do all the work to provide the LLM with a strict definition of what functions it can call and with which arguments. But even with all of that, the LLM would hallucinate functions that didn’t exist. Function calling has improved since, with the introduction of <a href="https://platform.openai.com/docs/guides/function-calling#structured-outputs">Structured Outputs</a>.</p>
<p>But for us, the issue was that the interface was too generic. In theory, it was capable of doing anything (editing your blobs or sqlite data), but it wasn’t very useful at any specific thing. Most notably, it wasn’t a good interface for iterating on code. It could write a first version of code, but it wasn’t optimized to let you run that code, see the output, debug it, let you ask the AI for more help. In other words, the feedback loop was bad.</p>
<h3 id="claude-artifacts"><a href="#claude-artifacts">Claude Artifacts</a></h3>
<p>We had begun to see the potential of Claude for code generation with the amazing results produced by <a href="https://websim.ai/">Websim</a>. But it was the <a href="https://www.anthropic.com/news/claude-3-5-sonnet">launch of Claude 3.5 Sonnet and Claude Artifacts</a> that really got our attention. Claude 3.5
Sonnet was dramatically better at generating code than anything we’d seen before. It blew all of our minds. And Claude Artifacts solved the tight feedback loop problem that we saw with our ChatGPT tool-use version. And thus after about a month of prototyping and building, the <a href="https://blog.val.town/blog/codegen/">current version of Townie</a> was born in August 2024.</p>
<p>For a couple weeks there, it felt like we had one of the best tools in the space. Townie can generate a fullstack app, with a frontend, backend, and database, in minutes, and fully deployed. The space has since gotten crowded. Live by the fast follow; die by the fast follow.</p>
<h3 id="our-contributions"><a href="#our-contributions">Our Contributions</a></h3>
<p>While we were out in front, we invested in trying to stay there, and we made some contributions of our own that have since found there way into other tools in the space.</p>
<h4 id="speed"><a href="#speed">Speed</a></h4>
<p>The biggest problem with all current codegen systems is the speed of generation. It takes minutes to generate just a couple hundred lines of code. If you regenerate the whole file every time – which is how most systems work – that means minutes between every feedback loop. (Not to mention the cost of regenerating the whole file every time, even when you are making a small change.)</p>
<p>We worked hard to get the LLM producing diffs, based on <a href="https://aider.chat/docs/unified-diffs.html">work we saw in Aider</a>. We were able to get it working most of the time, but not reliably enough. It’s now off by default, but you can ask Townie to “reply in diff” if you’d like to try your luck with it.</p>
<p>Our system prompt has always been open (you can view it in your Townie settings), so you can see how we’re doing that. Here’s the relevant section:</p>
<div><figure><pre data-language="md"><code><div><p><span>Follow the requirements above and respond by generating code in a format based on whether or not the user explicitly requests diff format in their most recent prompt:</span></p></div><div><p><span>-</span><span> If the user does not explicitly request diff format in their prompt, generate the entire val:</span></p></div><div><p><span><span>  </span></span><span>Use &lt;</span><span>existing_code</span><span>&gt; as the basis for generating code if it is provided.</span></p></div><div><p><span><span>  </span></span><span>Write code that is complete and directly runnable.</span></p></div><div><p><span><span>  </span></span><span>DO NOT omit code or use comments such as "more content here" or "code remains unchanged."</span></p></div><div><p><span><span>  </span></span><span>Write the code in `val code fences.</span></p></div><div><p><span>Include the val type as metadata on the code fence, e.g.: `val type=script</span></p></div><div><p><span><span>  </span></span><span>If this is a new val, decide what val type is appropriate based on the user's prompt. Default to choosing http type vals unless the user has requested specific functionality that requires a different type.</span></p></div><div><p><span>-</span><span> If the user requests diff format in their prompt, follow these steps:</span></p></div><div><p><span><span>  </span></span><span>Write a valid unified diff with change hunk headers. The file headers can be omitted.</span></p></div><div><p><span><span>  </span></span><span>Base the diff off of the &lt;</span><span>existing_code</span><span>&gt; tags below.</span></p></div><div><p><span><span>  </span></span><span>Use the ```diff language code fence.</span></p></div></code></pre></figure></div>
<p>We’ve gotten scared off of investing more time in diffs right now, but I expect it may have been solved by others in the space already, or will be shortly. Anthropic’s long-rumored “fast-edit mode” solve this problem in one fell swoop. OpenAI launched their own <a href="https://platform.openai.com/docs/guides/predicted-outputs">Predicted Outputs</a>, which is also compelling, but then we’d have to switch to OpenAI. Or maybe the solution is simply faster models, smaller, mini-models, or faster chips, like Groq or Cerebras. A couple weeks ago I built <a href="https://cerebrascoder.com/">Cerebras Coder</a> to demonstrate how powerful an instant feedback loop is for code generation. <a href="https://cerebrascoder.com/">Try it out yourself</a> or <a href="https://www.val.town/v/stevekrouse/cerebras_coder">fork it here</a>.</p>
<video controls=""><source src="https://blog.val.town/video/cerebras-coder.mp4"></video>
<p>DeepSeek <a href="https://x.com/deepseek_ai/status/1872242657348710721">recently open-sourced an almost-Sonnet-3.5-level model that’s twice as fast and trained for only $6m</a>. A boy can dream of a world where Sonnet-3.5-level codegen (or even smarter!) is available on a chip like Cerebras at a fraction of Anthropic’s cost. I think that would unleash a whole new class of innovation here.</p>
<h4 id="autodetecting-errors"><a href="#autodetecting-errors">Autodetecting errors</a></h4>
<p>We did contribute one possibly-novel UI interaction, where the LLM automatically detects errors and asks you if you’d like it to try to solve them. We detect server-side errors by polling our backend for 500 errors in your logs. We detect client-side errors in the iframe by prompting Townie to import <a href="https://www.val.town/v/std/catch">this client-side library</a>, which pushes errors up to the parent window.</p>
<video controls=""><source src="https://blog.val.town/video/TownieErrorDetection.mp4"></video>
<p>It’s not <em>particularly</em> novel (in that others would have thought of this if we didn’t), but maybe the folks at <a href="https://support.anthropic.com/en/articles/9949260-try-fixing-with-claude-for-artifact-errors">Anthropic</a> or Bolt saw our implementation and it inspired their own. I’d like to think we’re not <em>only</em> free-riding in this space.</p>
<h3 id="hosted-runtime-and-included-apis"><a href="#hosted-runtime-and-included-apis">Hosted runtime and included APIs</a></h3>
<p>Maybe some of our UI ideas made it into GitHub Spark too, including deployment-free hosting, persistent data storage, and the ability to use LLMs in your apps without a your own API key – their versions of <a href="https://docs.val.town/std/sqlite/">@std/sqlite</a> and <a href="https://docs.val.town/std/openai/">@std/openai</a>, respectively. In other words, you can say, “make me a ChatGPT clone with persistent thread history”, and in about 30 seconds, you’ll have a deployed app that does exactly that.</p>
<video controls=""><source src="https://blog.val.town/video/TownieChatGPTClone.mp4"></video>
<p>But we’re not the first hosting company to provide an LLM tool; that
honor likely goes to Vercel’s <a href="https://v0.dev/">v0</a>.</p>
<h3 id="cursor"><a href="#cursor">Cursor</a></h3>
<p>The next big thing was <a href="https://www.cursor.com/">Cursor</a>. I must admit that I never personally fell in love with it, but given how many people I respect love it, I think that’s a me-problem. I think Cursor is best for development in larger codebases, but recently my work has been on making vals in Val Town which are usually under 1,000 lines of code. (Our upcoming launch of multi-file Projects, now in private beta, will change this.) However Cursor is a real pioneer in the space, and has some UI interactions there that we have an eye to copy.</p>
<h3 id="windsurf"><a href="#windsurf">Windsurf</a></h3>
<p>Over the holiday, I fell in love with <a href="https://codeium.com/windsurf">Windsurf</a> by the folks at Codeium. Its Cascade feature is a chat interface, which has tool use and multi-turn agentic capabilities, to search through your codebase and edit multiple files. It feels a bit like we’re coming full-circle back to when we did our tool-use version of Townie. However, I think we now all understand that you can’t simply give your OpenAPI spec to an LLM and expect good results. The magic of Windsurf is that they carefully crafted what actions their agent can take, and that it can take multiple actions in a row without your input.</p>
<p>I am salivating at the idea of giving Townie some of these capabilities. Imagine if Townie could search through all public vals, and maybe even npm, or the public internet, to find code, docs, and other resources to help you.</p>
<h3 id="devin"><a href="#devin">Devin</a></h3>
<p>Watching Windsurf take multiple actions on my behalf without my input is very inspirational. I’m dreaming of a world where Townie not only detects errors, but also automatically tries to fix them, possibly multiple times, possibly in parallel across different branches, without any human interaction. Here, of course, we’d be getting into territory mostly explored by the folks at <a href="https://devin.ai/">Devin</a>.</p>
<p>For starters, we could feed back screenshots of the generated website back to the LLM. But soon you’d want to give the LLM access to a full web browser so it can itself poke around the app, like a human would, to see what features work and which ones don’t. Maybe then it’d even write some tests, also like a human would, to make sure things don’t break as it continues to iterate.</p>
<p>I have a vague sense by the end of this year that you’ll be able to tell Townie to “make a fully realistic Hacker News Clone, with user accounts, nested comments, upvotes, downvotes” and it could iterate for potentially hours on your behalf. You could even go to bed and wake up with it done.</p>
<h3 id="collaboration-and-competition"><a href="#collaboration-and-competition">Collaboration and competition</a></h3>
<p>Is this fast-following competitive or is it collaborative? So far it’s been feeling mostly collaborative. The pie is so freaking large — there are millions and maybe billions who are jumping at the chance to code — that we’re all happy to help each other scramble to keep up with the demand. I love that, and hope it remains this way. We at Val Town certainly don’t keep (m)any secrets. Our system prompt is open, and we blog about all our interesting technical choices. This very post is a case in point.</p>
<h3 id="should-we-bow-out"><a href="#should-we-bow-out">Should we bow out?</a></h3>
<p>All this copying, and how fast everything is moving begs the question: Should we get out of this race entirely? How can we hope to compete against better funded competitors? Should we instead focus on improving our core differentiator, and do a better job integrating with AI editors like VSCode, Cursor, Windsurf, and Bolt? Maybe! We’re planning to dip our toes into integrating: we plan to improve our local development experience, which would allow editors like VSCode, Cursor, and Windsurf to directly edit files in Val Town. We also plan to improve our API, so tools like Bolt could “deploy to Val Town”, like they currently deploy to Netlify.</p>
<p>However, it still feels like there’s a lot to be gained with a fully-integrated web AI code editor experience in Val Town – even if we can only get 80% of the features that the big dogs have, and a couple months later. It doesn’t take <em>that</em> much work to copy the best features we see in other tools. The benefits to a fully integrated experience seems well worth that cost. In short, we’ve had a lot of success fast-following so far, and think it’s worth continuing to do so.</p>
<h3 id="townie"><a href="#townie">Townie</a></h3>
<p>If you’ve made it this far in the article, you should really <a href="https://www.val.town/townie">try out Townie</a>. It’s still is one of the best tools to create fullstack web apps. Make yourself a <a href="https://www.val.town/v/danphilibin/what_did_i_work_on_today">‘what did I work on today’ app that pulls from Linear and GitHub</a> or <a href="https://x.com/destroytoday/status/1856709997737984089">a tool to extract dominant colors from an image</a> or <a href="https://deeperfates.com/">an AI clone for your personality</a>. Your imagination is the limit. And if you do, please let me know (<a href="mailto:steve@val.town">steve@val.town</a>) what features from other tools you’d like to see in Townie. We’re eager to learn from you.</p>
<p><em>Thanks <a href="https://macwright.com/">Tom MacWright</a>, <a href="https://janpaulposma.nl/">JP Posma</a>, and <a href="https://simonwillison.net/">Simon Willison</a> for feedback on drafts of this article.</em></p>  <a href="https://github.com/val-town/val-town-blog/edit/main/src/content/blog/fast-follow.mdx" data-astro-cid-npoeh54f=""><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" data-astro-cid-npoeh54f=""><path stroke-linecap="round" stroke-linejoin="round" d="M16.862 4.487l1.687-1.688a1.875 1.875 0 112.652 2.652L6.832 19.82a4.5 4.5 0 01-1.897 1.13l-2.685.8.8-2.685a4.5 4.5 0 011.13-1.897L16.863 4.487zm0 0L19.5 7.125" data-astro-cid-npoeh54f=""></path></svg>
Edit this page
</a> </div> </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Evolution of SRE at Google (147 pts)]]></title>
            <link>https://www.usenix.org/publications/loginonline/evolution-sre-google</link>
            <guid>42584750</guid>
            <pubDate>Fri, 03 Jan 2025 11:38:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usenix.org/publications/loginonline/evolution-sre-google">https://www.usenix.org/publications/loginonline/evolution-sre-google</a>, See on <a href="https://news.ycombinator.com/item?id=42584750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>An example of this phenomenon occurred at Google in 2021. We set and enforce resource quotas for some kinds of internal software running on our infrastructure. To maximize efficiency, we also monitor how much of its quota each software service uses. If a service consistently uses less resources than its quota, we automatically reduce the quota. In STPA terms, this quota rightsizer has a control action to reduce a service's quota. From a safety perspective, we then ask when this action would be unsafe. As one example, if the rightsizer&nbsp; ever reduced a service's quota below the actual needs of that service, it would be unsafe—the service would be resource-starved. This is what STPA calls an </span><span>unsafe control action</span><span> (UCA).</span></p><p><span>STPA analyzes each interaction in a system to determine comprehensively how the interaction must be controlled in order for the system to be safe. Unsafe control actions lead to the system entering one or more hazard states. There are only four possible types of UCA:</span></p><ol><li><p><span>A required control action is not provided.</span></p></li><li><p><span>An incorrect or inadequate control action is provided.</span></p></li><li><p><span>A control action is provided at the wrong time or in the wrong sequence.</span></p></li><li><p><span>A control action is stopped too soon or applied for too long.</span></p></li></ol><p><span>This particular unsafe control action—reducing an assigned quota to be less than what the service requires—is an example of the second type of UCA.</span></p><p><span>Simply identifying this unsafe control action by itself is only partially useful. If "quota rightsizer reduces the assigned quota under what the service requires" is unsafe, then preventing that behavior is what the system must do, i.e. "quota rightsizer must not reduce the assigned quota under what the service currently requires." This is a </span><span>safety requirement</span><span>. Safety requirements can be very useful for formulating future designs, elaborating testing plans, and helping people understand the system. And let’s be honest—even mature software systems can operate in ways that are undocumented, unclear, and surprising.</span></p><p><span>Nonetheless, what we really want is to anticipate all of the concrete scenarios that lead to a hazard state. Again, STPA has a simple and comprehensive way to structure an analysis to find all of the scenarios that could lead the quota rightsizer to violate this safety requirement.</span></p><p><span>So in the case of the rightsizer, there are four archetypal scenarios that we can investigate.</span></p><ol><li><p><span>Scenarios in which the rightsizer has incorrect behavior.</span></p></li><li><p><span>Scenarios in which the rightsizer gets incorrect feedback (or no feedback at all).</span></p></li><li><p><span>Scenarios in which the quota system never receives an action from the rightsizer (even though the rightsizer tried to send one).</span></p></li><li><p><span>Scenarios in which the quota system has incorrect behavior.</span></p></li></ol><p><span>One specific scenario quickly jumped out to us when analyzing the rightsizer. It gets feedback on the current resource usage from the quota service. As implemented, the calculation of current resource usage is complicated, involving different data collectors and some tricky aggregation logic. What if something went wrong with this complex calculation, resulting in a value that was too low? In short, the rightsizer would react exactly as designed and reliably shrink a service’s quota to the incorrect lower usage level.&nbsp;</span></p><p><span>Exactly the disaster we wanted to prevent.&nbsp;</span></p><p><span>Up to this point, lots of attention had been paid to getting the quota adjustment algorithm right and reliably producing the correct outputs, namely, the action to adjust a service’s quota. However, the feedback path—including the service’s current resource usage—had been less well understood.&nbsp;</span></p><p><span>This highlights a major advantage of STPA—by looking at the system level and by modeling the system in terms of control-feedback loops, we find issues both in the control path and the feedback path. As we run STPA on more and more systems, we see that the feedback path is often less well understood than the control path, but just as important from a system safety perspective.</span></p><p><span>As we dug into the feedback paths for the rightsizer, we saw many opportunities to improve them. None of these changes looked like a traditional reliability solution—it didn’t boil down to managing the rightsizer with a different SLO and error budget. Instead, the solutions showed up in other parts of the system and involved redesigning parts of the stack that had previously appeared to be unrelated–again, an advantage of STPA’s system theory approach.</span></p><p><span>In the 2021 incident, incorrect feedback about the resources used by a critical service in Google's infrastructure was sent to the rightsizer. The rightsizer calculated a new quota, allocating far fewer resources than the service was actually using. As a precautionary measure, this quota reduction was not immediately applied, but was held for several weeks to give time for someone to intervene in case the quota was wrong.&nbsp;</span></p><p><span>Of course, major incidents are never simple events—the next problem was that despite adding the delay as a safety feature, feedback about the pending change was never sent to anyone. The entire system was in a hazard state for weeks, but because we weren't looking for it, we missed our chance to prevent the loss that followed. After several weeks, the quota reduction was applied resulting in a significant outage. Using STPA, we have anticipated problems just like this one in many different systems across Google.</span></p><p><span><span>As Leveson writes in </span><span>Engineering a Safer World</span><span>: "In [STAMP], understanding why an accident occurred requires determining why the control was ineffective. Preventing future accidents requires shifting from a focus on preventing failures to the broader goal of designing and implementing controls that will enforce the necessary constraints."</span><span> This shift in perspective - from trying to prove the absence of problems to effectively managing known and potential hazards - is a key principle in our system safety approach.</span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Court strikes down US net neutrality rules (152 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c4gl417l757o</link>
            <guid>42584621</guid>
            <pubDate>Fri, 03 Jan 2025 11:14:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c4gl417l757o">https://www.bbc.com/news/articles/c4gl417l757o</a>, See on <a href="https://news.ycombinator.com/item?id=42584621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>A US court has rejected the Biden administration's bid to restore "net neutrality" rules, finding that the federal government does not have the authority to regulate internet providers like utilities.<!-- --></p><p>It marks a major defeat for so-called open internet advocates, who have long fought for protections that would require internet providers such as AT&amp;T to treat all legal content equally.<!-- --></p><p>Such rules were first introduced by the Federal Communications Commission under former Democratic president Barack Obama but later repealed during Republican Donald Trump's first term.<!-- --></p><p>The decision, just as Trump is poised to enter the White House for a second term, likely puts an end to the long-running legal battle over the issue.<!-- --></p></div><div data-component="text-block"><p>In their decision, the judges noted that different administrations have gone back and forth on the issue.<!-- --></p><p>But they said the court no longer had to give "deference" to the FCC's reading of the law, pointing to a recent Supreme Court decision that limits the authority of federal agencies to interpret laws, a decision that critics expect will be used to weaken regulation in the years ahead.<!-- --></p><p>"Applying Loper Bright, means we can end the FCC's vacillations," the Sixth Circuit Court of Appeals said.<!-- --></p><p>Brendan Carr, a Republican member of the FCC who Trump has tapped to lead the agency, said he was pleased the court had invalidated the Biden administration's "Internet power grab".<!-- --></p><p>The FCC's outgoing Democratic commissioner said the ruling turned the issue over to Congress.<!-- --></p><p>"Consumers across the country have told us again and again that they want an internet that is fast, open, and fair," Jessica Rosenworcel said. <!-- --></p><p>"With this decision it is clear that Congress now needs to heed their call, take up the charge for net neutrality, and put open internet principles in federal law."<!-- --></p></div><div data-component="text-block"><p>The fight over net neutrality was once a heated issue in the US, pitting internet providers against big tech companies such as Google and Netflix. <!-- --></p><p>Comedian John Oliver famously urged his audience to express support for the rules, leading to a deluge of comments that crashed the government's site. <!-- --></p><p>But the issue has faded in prominence since the rules were repealed in 2018.<!-- --></p><p>Thursday's ruling does not affect state-level net neutrality laws, which in some places offer similar protections.<!-- --></p><p>But advocates, like Mr Oliver, have said that national rules are important to preventing internet providers from having powers to throttle certain content or charge more for speedy delivery of their service.<!-- --></p><p>Public Knowledge, a progressive-leaning internet policy group, said the decision had weakened the FCC's power to shape privacy protections, implement public safety measures and take other action. <!-- --></p><p>It said it believed the court had erred in ruling that internet service providers were simply offering an "information service" rather than acting as telecommunications companies. <!-- --></p><p>"The court has created a dangerous regulatory gap that leaves consumers vulnerable and gives broadband providers unchecked power over Americans' internet access," it said.<!-- --></p><p>But USTelecom, an industry group whose members include AT&amp;T and Verizon, said the decision was "a victory for American consumers that will lead to more investment, innovation, and competition in the dynamic digital marketplace."<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can LLMs write better code if you keep asking them to "write better code"? (619 pts)]]></title>
            <link>https://minimaxir.com/2025/01/write-better-code/</link>
            <guid>42584400</guid>
            <pubDate>Fri, 03 Jan 2025 10:30:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minimaxir.com/2025/01/write-better-code/">https://minimaxir.com/2025/01/write-better-code/</a>, See on <a href="https://news.ycombinator.com/item?id=42584400">Hacker News</a></p>
Couldn't get https://minimaxir.com/2025/01/write-better-code/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[UK ICO response to Google's policy change on device fingerprinting (155 pts)]]></title>
            <link>https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/12/our-response-to-google-s-policy-change-on-fingerprinting/</link>
            <guid>42583726</guid>
            <pubDate>Fri, 03 Jan 2025 08:28:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/12/our-response-to-google-s-policy-change-on-fingerprinting/">https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/12/our-response-to-google-s-policy-change-on-fingerprinting/</a>, See on <a href="https://news.ycombinator.com/item?id=42583726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        
    <table>
<tbody>
<tr>
<td><img src="https://ico.org.uk/media/about-the-ico/images/blog-images/4029666/blog-portrait-stephen_almond.png" alt="Stephen Almond" data-udi="umb://media/c7b4d67e20df49b6aa93816d854c8121"></td>
<td><strong>Stephen Almond</strong> is the ICO's executive director of regulatory risk.</td>
</tr>
</tbody>
</table>
<p><strong>Yesterday, Google announced to organisations that use its advertising products, that from 16 February 2025, it will no longer prohibit them from employing fingerprinting techniques. Our response is clear: businesses do not have free rein to use fingerprinting as they please. Like all advertising technology, it must be lawfully and transparently deployed – and if it is not, the ICO will act.</strong></p>
<p><span>Fingerprinting involves the collection of pieces of information about a device’s software or hardware, which, when combined, can uniquely identify a particular device and user.&nbsp;</span></p>
<p><span>The ICO’s view is that fingerprinting is not a fair means of tracking users online because it is likely to reduce people’s choice and control over how their information is collected. The change to Google’s policy means that fingerprinting could now replace the functions of third-party cookies.&nbsp;</span></p>
<p><span>We think this change is irresponsible. Google itself has previously said that fingerprinting does not meet users’ expectations for privacy, as users cannot easily consent to it as they would cookies. This in turn means they cannot control how their information is collected. To quote Google’s own position on fingerprinting from 2019: “We think this subverts user choice and is wrong.”</span></p>
<p><span>We are continuing to engage with Google on this U-turn in its position and the departure it represents from our expectation of a privacy-friendly internet. When the new policy comes into force on 16 February 2025, organisations using Google’s advertising technology will be able to deploy fingerprinting without being in breach of Google’s own policies. Given Google’s position and scale in the online advertising ecosystem, this is significant.&nbsp;</span></p>
<p><span>In the meantime, there should be no doubt around any business’s obligations when it comes to fingerprinting and privacy. Data protection law, including the Privacy and Electronic Communications Regulations (PECR), applies. Businesses must give users fair choices over whether to be tracked before using fingerprinting technology, including obtaining consent from their users where necessary.</span></p>
<p><span>We have taken the step of publishing draft guidance today on how data protection law, including PECR, applies to <a href="https://ico.org.uk/for-organisations/direct-marketing-and-privacy-and-electronic-communications/guidance-on-the-use-of-storage-and-access-technologies/">storage and access technologies</a> such as fingerprinting. We’ll be launching a consultation on the guidance on Friday 20 December to give organisations the opportunity to feed back their thoughts.</span></p>
<p><span>Organisations seeking to deploy fingerprinting techniques for advertising will need to demonstrate how they are complying with the requirements of data protection law. These include providing users with transparency, securing freely-given consent, ensuring fair processing and upholding information rights such as the right to erasure.&nbsp;</span></p>
<p><span>Based on our understanding of how fingerprinting techniques are currently used for advertising this is a high bar to meet. Businesses should not consider fingerprinting a simple solution to the loss of third-party cookies and other cross-site tracking signals.</span></p>
<p><span>Our guidance forms part of the ICO’s upcoming strategy to give people meaningful control over how their information is used to show them personalised adverts. We will set out more details of our plans in the New Year.</span>&nbsp;</p>
<h2>Explainer: What does fingerprinting mean for the public?</h2>
<ul>
<li aria-level="1"><span>Privacy controls are built around existing technologies. When you choose an option on a consent banner or ‘clear all site data’ in your browser, you are generally controlling the use of cookies and other traditional forms of local storage.&nbsp;</span></li>
<li aria-level="1"><span>Fingerprinting, however, relies on signals that you cannot easily wipe. So, even if you ‘clear all site data’, the organisation using fingerprinting techniques could immediately identify you again. This is not transparent and cannot easily be controlled.</span></li>
<li aria-level="1"><span>Fingerprinting is harder for browsers to block and therefore, even privacy-conscious users will find this difficult to stop.</span></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Canada Should Join the EU (170 pts)]]></title>
            <link>https://www.economist.com/europe/2025/01/02/why-canada-should-join-the-eu</link>
            <guid>42583297</guid>
            <pubDate>Fri, 03 Jan 2025 07:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/europe/2025/01/02/why-canada-should-join-the-eu">https://www.economist.com/europe/2025/01/02/why-canada-should-join-the-eu</a>, See on <a href="https://news.ycombinator.com/item?id=42583297">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><p><span><a href="https://www.economist.com/europe" data-analytics="sidebar:section"><span>Europe</span></a></span><span> | <!-- -->Charlemagne</span></p></div><h2>Europe needs space and resources, Canada needs people. Let’s deal</h2></section><div><div><p><time datetime="2025-01-02T14:06:25.944Z"> <!-- -->Jan 2nd 2025</time></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>s international conflicts</small> go, none did so little to disrupt the global order as the “whisky wars” that pitted Canada against Denmark for four decades. Flaring up in 1984, the unlikely spat involved a one-square-kilometre island in the middle of an icy Arctic channel marking the border between Greenland (now a self-ruling part of Denmark) and the Canadian territory of Nunavut. Both sides assumed the rock was theirs. What might have been considered a <i>casus belli</i> by lesser countries became, for the northern duo, an exercise in diplomatic civility. Canadian officials visiting the island marked their territory by leaving whisky and flags; Danes asserted sovereignty by snaffling the booze and leaving their own schnapps for Canadians to enjoy. In lieu of shots fired, polite letters were occasionally exchanged. When the quarrel grew tiresome a working group spent years agreeing to split the island down the middle, ending all hostilities in 2022.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/canada" data-analytics="tags:canada"><span>Canada</span></a><a href="https://www.economist.com/topics/charlemagne" data-analytics="tags:charlemagne"><span>Charlemagne</span></a></nav></p><p>This article appeared in the Europe section of the print edition under the headline “The EU’s newest member, eh?”</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/europe">Europe</a> <span>January 4th 2025</span></h2><ul><li><a href="https://www.economist.com/europe/2024/12/31/finland-seizes-a-tanker-getting-tough-on-hybrid-warfare"><span>Finland seizes a tanker, getting tough on hybrid warfare</span></a></li><li><a href="https://www.economist.com/europe/2024/12/31/a-prague-berlin-train-loses-its-old-world-dining-cars"><span>A Prague-Berlin train loses its old-world dining cars</span></a></li><li><a href="https://www.economist.com/europe/2025/01/02/elon-musks-praise-for-the-far-right-infuriates-most-of-germany"><span>Elon Musk’s praise for the far right infuriates most of Germany</span></a></li><li><a href="https://www.economist.com/europe/2025/01/02/serbia-and-its-neighbours-are-still-far-from-joining-the-eu"><span>Serbia and its neighbours are still far from joining the EU</span></a></li><li><a href="https://www.economist.com/europe/2025/01/02/why-canada-should-join-the-eu"><span>Why Canada should join the EU</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250104_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the January 4th 2025 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2025-01-04" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div><div><p><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Why%20Canada%20should%20join%20the%20EU&amp;publicationDate=2025-01-02&amp;contentID=%2Fcontent%2Fr9rhvfsfqpsv5nomocc1i8pv1t4mhbhs&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><span>Reuse this content</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Laser mapping reveals oldest Amazonian cities, built 2500 years ago (2024) (157 pts)]]></title>
            <link>https://www.science.org/content/article/laser-mapping-reveals-oldest-amazonian-cities-built-2500-years-ago</link>
            <guid>42583141</guid>
            <pubDate>Fri, 03 Jan 2025 06:36:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/laser-mapping-reveals-oldest-amazonian-cities-built-2500-years-ago">https://www.science.org/content/article/laser-mapping-reveals-oldest-amazonian-cities-built-2500-years-ago</a>, See on <a href="https://news.ycombinator.com/item?id=42583141">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/laser-mapping-reveals-oldest-amazonian-cities-built-2500-years-ago: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Digital gardens people maintain outside the "Big Tech" walled gardens (268 pts)]]></title>
            <link>https://blogscroll.com/</link>
            <guid>42583086</guid>
            <pubDate>Fri, 03 Jan 2025 06:23:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogscroll.com/">https://blogscroll.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42583086">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Welcome to BlogScroll! 👋</p>
            <p>This is an open directory of personal sites and blogs, maintained entirely <a href="https://github.com/blogscroll/blogscroll">on GitHub</a>.</p>
            <p>This project was created by <a href="https://den.dev/">Den Delimarsky</a> in an effort to bring attention to little 🌱 digital gardens and ✨ personal corners of the internet that people maintain outside the "Big Tech" walled gardens. We're all better off maintaining homegrown corners of the Internet.</p>
            <p>If you prefer not to use GitHub to make your contribution, you can also send me a note to <kbd>hi@den.dev</kbd> and I will happily review and publish it.</p>
            <p>You can also subscribe to the <a href="https://blogscroll.com/index.xml">RSS feed</a> to stay up-to-date on latest additions.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kuvasz-streamer: open-source CDC for Postgres for low latency replication (112 pts)]]></title>
            <link>https://streamer.kuvasz.io/</link>
            <guid>42582203</guid>
            <pubDate>Fri, 03 Jan 2025 03:52:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://streamer.kuvasz.io/">https://streamer.kuvasz.io/</a>, See on <a href="https://news.ycombinator.com/item?id=42582203">Hacker News</a></p>
Couldn't get https://streamer.kuvasz.io/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>