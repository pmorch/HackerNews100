<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 20 May 2025 06:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What are people doing? Live-ish estimates based on global population dynamics (102 pts)]]></title>
            <link>https://humans.maxcomperatore.com/</link>
            <guid>44036900</guid>
            <pubDate>Tue, 20 May 2025 01:36:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://humans.maxcomperatore.com/">https://humans.maxcomperatore.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44036900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="utc-time-display">
      <svg id="utc-analog-clock" viewBox="0 0 100 100">
        <circle cx="50" cy="50" r="48"></circle><line id="hour-hand" x1="50" y1="50" x2="50" y2="25"></line><line id="minute-hand" x1="50" y1="50" x2="50" y2="15"></line><line id="second-hand" x1="50" y1="50" x2="50" y2="10"></line><circle cx="50" cy="50" r="3"></circle>
      </svg>
      <p><span id="currentTime">Coordinated Universal Time (UTC): 00:00:00</span>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DDoSecrets publishes 410 GB of heap dumps, hacked from TeleMessage (331 pts)]]></title>
            <link>https://micahflee.com/ddosecrets-publishes-410-gb-of-heap-dumps-hacked-from-telemessages-archive-server/</link>
            <guid>44036647</guid>
            <pubDate>Tue, 20 May 2025 00:52:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://micahflee.com/ddosecrets-publishes-410-gb-of-heap-dumps-hacked-from-telemessages-archive-server/">https://micahflee.com/ddosecrets-publishes-410-gb-of-heap-dumps-hacked-from-telemessages-archive-server/</a>, See on <a href="https://news.ycombinator.com/item?id=44036647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
                    <header>
                        
                            <figure>
        <img srcset="https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=300 300w,
                    https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=720 720w,
                    https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=960 960w,
                    https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1200 1200w,
                    https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000 2000w,
                    https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000" sizes="(max-width: 1200px) 100vw, 1200px" src="https://images.unsplash.com/photo-1642204705127-accc0dcc5779?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGxhbmRmaWxsfGVufDB8fHx8MTc0NzY3MTQzMnww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1200" alt="DDoSecrets publishes 410 GB of heap dumps, hacked from TeleMessage's archive server">
            <figcaption><span>Photo by </span><a href="https://unsplash.com/@katertottz?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Katie Rodriguez</span></a><span> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Unsplash</span></a></figcaption>
    </figure>
                    </header>

                <section>
                    <p>This morning, Distributed Denial of Secrets <a href="https://ddosecrets.com/article/telemessage" rel="noreferrer">published</a> 410 GB of data hacked from TeleMessage, the Israeli firm that makes modified versions of Signal, WhatsApp, Telegram, and WeChat that centrally archive messages. Because the data is sensitive and full of PII, DDoSecrets is only sharing it with journalists and researchers.</p><p>There's a lot of background, so here's a quick timeline of events with relevant links:</p><ul><li>March: Then-national security advisor Mike Waltz <a href="https://web.archive.org/web/20250325174744/https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/" rel="noreferrer">invited</a> a journalist into a Signal group where they planned <a href="https://zeteo.com/p/signal-chat-war-crimes-revealed-yemen-trump-admin" rel="noreferrer">war crimes</a>. This led to Congressional <a href="https://www.pbs.org/newshour/politics/watch-ratcliffe-gabbard-patel-testify-to-senate-after-war-plans-revealed-to-journalist-in-chat" rel="noreferrer">hearings</a> about Trump officials using Signal groups to discuss classified information.</li><li>May 1: Waltz (the day he was demoted from position of national security advisor) was photographed using TM SGNL, a modified version of Signal made by TeleMessage. He had texts up with Tusli Gabbard, JD Vance, and Marco Rubio.</li><li>May 3: I <a href="https://micahflee.com/heres-the-source-code-for-the-unofficial-signal-app-used-by-trump-officials/" rel="noreferrer">published</a> the source code of the TM SGNL to GitHub.</li><li>May 4: TeleMessage got hacked, which I <a href="https://micahflee.com/the-signal-clone-the-trump-admin-uses-was-hacked/" rel="noreferrer">reported</a> in 404 Media with Joseph Cox. </li><li>May 5: TeleMessage got hacked again by someone else, as NBC News <a href="https://www.nbcnews.com/tech/security/telemessage-suspends-services-hackers-say-breached-app-rcna204925" rel="noreferrer">reported</a>.</li><li>May 6: I <a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/" rel="noreferrer">published analysis</a> of the TM SGNL source code, along with some of the hacked data, that prove the TeleMessage lied about its products supporting end-to-end encryption.</li><li>May 18: I <a href="https://micahflee.com/how-the-knock-off-signal-app-used-by-trump-officials-got-hacked-in-20-minutes/" rel="noreferrer">published details</a> about the TeleMessage server's vulnerability in WIRED. <em>TLDR: if anyone on the internet loaded the URL <strong>archive.telemessage.com/management/heapdump</strong>, they would download a Java heap dump from TeleMessage's archive server, containing plaintext chat logs, among other things.</em></li></ul><p>Now, DDoSecrets has published 410 GB of these TeleMessage heap dumps. Here's the DDoSecrets description of <a href="https://ddosecrets.com/article/telemessage" rel="noreferrer">the release</a>:</p><blockquote>Thousands of heap dumps taken May 4, 2025 from TeleMessage, which produces software used to archive encrypted messaging apps such as Signal and WhatsApp. The service came to public notice in 2025 when it was reported that former national security adviser Mike Waltz used TeleMessage while communicating with members of the Trump administration, including Vice President JD Vance and Director of National Intelligence Tulsi Gabbard. TeleMessage has been used by the federal government since at least February 2023.<p>Some of the archived data includes plaintext messages while other portions only include metadata, including sender and recipient information, timestamps, and group names. To facilitate research, Distributed Denial of Secrets has extracted the text from the original heap dumps.</p></blockquote><p>It seems that the SignalGate saga of staggering incompetence is not yet complete. I'm digging into this data right now. It's bonkers.</p><p><em>Note: I'm a member of the DDoSecrets collective. If you can, </em><a href="https://donorbox.org/ddosecrets" rel="noreferrer"><em>donate</em></a><em>! DDoSecrets operates on a shoestring budget and does incredibly impactful work.</em></p>
                    
                </section>

                    

                
            </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[is-even-ai – Check if a number is even using the power of AI (232 pts)]]></title>
            <link>https://www.npmjs.com/package/is-even-ai</link>
            <guid>44036438</guid>
            <pubDate>Tue, 20 May 2025 00:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npmjs.com/package/is-even-ai">https://www.npmjs.com/package/is-even-ai</a>, See on <a href="https://news.ycombinator.com/item?id=44036438">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header></header><main id="main"> <div id="top"><div><p><span>1.0.5<!-- -->&nbsp;•&nbsp;</span><span>Public</span><span>&nbsp;•&nbsp;Published <time datetime="2024-10-19T03:05:20.686Z" title="10/19/2024, 3:05:20 AM">7 months ago</time></span></p></div><ul role="tablist" aria-owns="package-tab-readme package-tab-code package-tab-dependencies package-tab-dependents package-tab-versions"><li role="presentation"><a href="https://www.npmjs.com/package/is-even-ai?activeTab=readme" aria-selected="true" role="tab" aria-controls="tabpanel-readme" id="package-tab-readme" tabindex="0"><span> Readme</span></a></li><li role="presentation"><a href="https://www.npmjs.com/package/is-even-ai?activeTab=code" aria-selected="false" role="tab" aria-controls="tabpanel-explore" id="package-tab-code" tabindex="-1"><span>Code <span><span>Beta</span></span></span></a></li><li role="presentation"><a href="https://www.npmjs.com/package/is-even-ai?activeTab=dependencies" aria-selected="false" role="tab" aria-controls="tabpanel-dependencies" id="package-tab-dependencies" tabindex="-1"><span>1 Dependency</span></a></li><li role="presentation"><a href="https://www.npmjs.com/package/is-even-ai?activeTab=dependents" aria-selected="false" role="tab" aria-controls="tabpanel-dependents" id="package-tab-dependents" tabindex="-1"><span>0 Dependents</span></a></li><li role="presentation"><a href="https://www.npmjs.com/package/is-even-ai?activeTab=versions" aria-selected="false" role="tab" aria-controls="tabpanel-versions" id="package-tab-versions" tabindex="-1"><span>7 Versions</span></a></li></ul><p><span><div id="tabpanel-readme" aria-labelledby="package-tab-readme" role="tabpanel" data-attribute=""><article><div id="readme"><div><h2>is-even-ai</h2></div>
<p><a href="https://www.npmjs.com/package/is-even-ai" rel="nofollow"><img src="https://camo.githubusercontent.com/5ef7ab75d332b2a150f7abd92543b02f404a373538618c481d65e0878bafbce4/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f69732d6576656e2d61692e7376673f7374796c653d666c6174" alt="NPM Version" data-canonical-src="https://img.shields.io/npm/v/is-even-ai.svg?style=flat"></a>
<a href="https://github.com/Calvin-LL/is-even-ai/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/a534d8ca992ccfede6a1ec046afa59d5527e48b05af7e0e3d33ac804adbfe044/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f69732d6576656e2d61692e7376673f7374796c653d666c6174" alt="NPM License" data-canonical-src="https://img.shields.io/npm/l/is-even-ai.svg?style=flat"></a>
<a href="https://www.npmjs.com/package/is-even-ai" rel="nofollow"><img src="https://camo.githubusercontent.com/ee5ff62aeacf7bd48fd4fb5abd217a318db042c59dcfb82b2b9e9be79a3c0a1d/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f64742f69732d6576656e2d61692e7376673f7374796c653d666c6174" alt="NPM Downloads" data-canonical-src="https://img.shields.io/npm/dt/is-even-ai.svg?style=flat"></a></p>
<p>Check if a number is even using the power of ✨AI✨.</p>
<p>Uses OpenAI's GPT-3.5-turbo model under the hood to determine if a number is even.</p>
<p>For all those who want to use AI in their product but don't know how.</p>
<p>Inspired by the famous <a href="https://www.npmjs.com/package/is-even" rel="nofollow"><code>is-even</code></a> npm package and <a href="https://twitter.com/erenbali/status/1766602689863950658" rel="nofollow">this tweet</a>.</p>
<div><h2>Installation</h2></div>
<p><a href="https://www.npmjs.com/package/is-even-ai" rel="nofollow">This package is on npm.</a></p>

<div><h2>Usage</h2></div>
<div><pre><span>import</span> <span>{</span>
  <span>areEqual</span><span>,</span>
  <span>areNotEqual</span><span>,</span>
  <span>isEven</span><span>,</span>
  <span>isGreaterThan</span><span>,</span>
  <span>isLessThan</span><span>,</span>
  <span>isOdd</span><span>,</span>
  <span>setApiKey</span><span>,</span>
<span>}</span> <span>from</span> <span>"is-even-ai"</span><span>;</span>

<span>// won't need this if you have OPENAI_API_KEY in your environment</span>
<span>setApiKey</span><span>(</span><span>"YOUR_API_KEY"</span><span>)</span><span>;</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEven</span><span>(</span><span>2</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEven</span><span>(</span><span>3</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isOdd</span><span>(</span><span>4</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isOdd</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>areEqual</span><span>(</span><span>6</span><span>,</span> <span>6</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>areEqual</span><span>(</span><span>6</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>areNotEqual</span><span>(</span><span>6</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>areNotEqual</span><span>(</span><span>7</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isGreaterThan</span><span>(</span><span>8</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isGreaterThan</span><span>(</span><span>7</span><span>,</span> <span>8</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isLessThan</span><span>(</span><span>9</span><span>,</span> <span>8</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isLessThan</span><span>(</span><span>8</span><span>,</span> <span>9</span><span>)</span><span>)</span><span>;</span> <span>// true</span></pre></div>
<p>for more advance usage like changing which model to use and setting the temperature, use <code>IsEvenAiOpenAi</code> instead</p>
<div><pre><span>import</span> <span>{</span> <span>IsEvenAiOpenAi</span> <span>}</span> <span>from</span> <span>"is-even-ai"</span><span>;</span>

<span>const</span> <span>isEvenAiOpenAi</span> <span>=</span> <span>new</span> <span>IsEvenAiOpenAi</span><span>(</span>
  <span>{</span>
    <span>// won't need this if you have OPENAI_API_KEY in your environment</span>
    <span>apiKey</span>: <span>"YOUR_API_KEY"</span><span>,</span>
  <span>}</span><span>,</span>
  <span>{</span>
    <span>model</span>: <span>"gpt-3.5-turbo"</span><span>,</span>
    <span>temperature</span>: <span>0</span><span>,</span>
  <span>}</span>
<span>)</span><span>;</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isEven</span><span>(</span><span>2</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isEven</span><span>(</span><span>3</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isOdd</span><span>(</span><span>4</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isOdd</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>areEqual</span><span>(</span><span>6</span><span>,</span> <span>6</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>areEqual</span><span>(</span><span>6</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>areNotEqual</span><span>(</span><span>6</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>areNotEqual</span><span>(</span><span>7</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isGreaterThan</span><span>(</span><span>8</span><span>,</span> <span>7</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isGreaterThan</span><span>(</span><span>7</span><span>,</span> <span>8</span><span>)</span><span>)</span><span>;</span> <span>// false</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isLessThan</span><span>(</span><span>8</span><span>,</span> <span>9</span><span>)</span><span>)</span><span>;</span> <span>// true</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>isEvenAiOpenAi</span><span>.</span><span>isLessThan</span><span>(</span><span>9</span><span>,</span> <span>8</span><span>)</span><span>)</span><span>;</span> <span>// false</span></pre></div>
<div><h2>Supported AI platforms</h2></div>
<p>Feel free to make a PR to add more AI platforms.</p>
<ul>
<li>[x] <a href="https://openai.com/" rel="nofollow">OpenAI</a> via <code>IsEvenAiOpenAi</code>
</li>
</ul>
<div><h2>Supported methods</h2></div>
<ul>
<li><code>isEven(n: number)</code></li>
<li><code>isOdd(n: number)</code></li>
<li><code>areEqual(a: number, b: number)</code></li>
<li><code>areNotEqual(a: number, b: number)</code></li>
<li><code>isGreaterThan(a: number, b: number)</code></li>
<li><code>isLessThan(a: number, b: number)</code></li>
</ul>
</div></article></div></span><span aria-live="polite"></span></p></div> </main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Have I Been Pwned 2.0 is Now Live (469 pts)]]></title>
            <link>https://www.troyhunt.com/have-i-been-pwned-2-0-is-now-live/</link>
            <guid>44035158</guid>
            <pubDate>Mon, 19 May 2025 21:37:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.troyhunt.com/have-i-been-pwned-2-0-is-now-live/">https://www.troyhunt.com/have-i-been-pwned-2-0-is-now-live/</a>, See on <a href="https://news.ycombinator.com/item?id=44035158">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>This has been a <em>very</em> long time coming, but finally, after a marathon effort, <a href="https://haveibeenpwned.com/?ref=troyhunt.com" rel="noreferrer">the brand new Have I Been Pwned website is now live</a>!</p><p><img src="https://www.troyhunt.com/content/images/2025/05/2025-05-15_08-25-12.jpg" alt="" loading="lazy"></p>
<p><a href="https://github.com/HaveIBeenPwned/ux-rebuild/commit/38853b79597d3d22afad4ff6822ceaa94b6c49f9?ref=troyhunt.com" rel="noreferrer">Feb last year is when I made the first commit</a> to the public repo for the rebranded service, and <a href="https://www.troyhunt.com/soft-launching-and-open-sourcing-the-have-i-been-pwned-rebrand/" rel="noreferrer">we soft-launched the new brand in March of this year</a>. Over the course of this time, we've completely rebuilt the website, changed the functionality of pretty much every web page, added a heap of new features, and today, we're even launching a merch store 😎</p><p>Let me talk you through just some of the highlights, strap yourself in!</p><h2 id="the-search">The Search</h2><p>The signature feature of HIBP is that big search box on the front page, and now, it's even better - it has confetti!</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-16.png" alt="" loading="lazy" width="1689" height="820" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-16.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-16.png 1000w, https://www.troyhunt.com/content/images/size/w1600/2025/05/image-16.png 1600w, https://www.troyhunt.com/content/images/2025/05/image-16.png 1689w"></figure><p>Well, not for everyone, only about half the people who use it will see a celebratory response. There's a reason why this response is intentionally jovial, let me explain:</p><p>As Charlotte and I have travelled and spent time with so many different users of the service around the world, a theme has emerged over and over again: HIBP is a bit playful. It's not a scary place emblazoned with hoodies, padlock icons, and fearmongering about "the dark web". Instead, we aim to be more consumable to the masses and provide factual, actionable information without the hyperbole. Confetti guns (yes, there are several, and they're animated) lighten the mood a bit. The alternative is that you get the red response:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-21.png" alt="" loading="lazy" width="1343" height="1136" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-21.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-21.png 1000w, https://www.troyhunt.com/content/images/2025/05/image-21.png 1343w"></figure><p>There was a very brief moment where we considered a more light-hearted treatment on this page as well, but somehow a bit of sad trombone really didn't seem appropriate, so we deferred to a more demure response. But now it's on a timeline you can scroll through in reverse chronological order, with each breach summarising what happened.  And if you want more info, we have an all-new page I'll talk about in a moment.</p><p>Just one little thing first - we've dropped username and phone number search support from the website. Username searches were introduced in 2014 for <a href="https://haveibeenpwned.com/Breach/Snapchat?ref=troyhunt.com" rel="noreferrer">the Snapchat incident</a>, and phone number searches in 2021 for <a href="https://haveibeenpwned.com/Breach/Facebook?ref=troyhunt.com" rel="noreferrer">the Facebook incident</a>. And that was it. That's the only time we ever loaded those classes of data, and there are several good reasons why. Firstly, they're both painful to parse out of a breach compared to email addresses, which we simply use a regex to extract (<a href="https://github.com/HaveIBeenPwned/EmailAddressExtractor?ref=troyhunt.com" rel="noreferrer">we've open sourced the code that does this</a>). Usernames are a string. Phone numbers are, well, it depends. They're not just numbers because if you properly internationalise them (like they were in the Facebook incident), they've also got a plus at the front, but they're frequently all over the place in terms of format. And we can't send notifications because nobody "owns" a username, and phone numbers are <em>very </em>expensive to send SMSs to compared to sending emails. Plus, every other incident in HIBP other than those two has had email addresses, so if we're asking "have I been pwned?" we can always answer that question without loading those two hard-to-parse fields, which usually aren't present in most breaches anyway. When the old site offered to accept them in the search box, it created confusion and support overhead: "why wasn't my number in the [whatever] breach?!". That's why it's gone <em>from the website</em>, but we've kept it supported on the API to ensure we don't break anything... just don't expect to see more data there.</p><h2 id="the-breach-page">The Breach Page</h2><p>There are many reasons we created this new page, not least of which is that the search results on the front page were getting too busy, and we wanted to palm off the details elsewhere. So, now we have a dedicated page for each breach, <a href="https://haveibeenpwned.com/Breach/AshleyMadison?ref=troyhunt.com" rel="noreferrer">for example</a>:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-19.png" alt="" loading="lazy" width="1328" height="944" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-19.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-19.png 1000w, https://www.troyhunt.com/content/images/2025/05/image-19.png 1328w"></figure><p>That's largely information we had already (albeit displayed in a much more user-friendly fashion), but what's unique about the new page is much more targeted advice about what to do <em>after</em> the breach:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-20.png" alt="" loading="lazy" width="883" height="716" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-20.png 600w, https://www.troyhunt.com/content/images/2025/05/image-20.png 883w"></figure><p><a href="https://www.troyhunt.com/after-the-breach-finding-new-partners-with-solutions-for-have-i-been-pwned-users/" rel="noreferrer">I recently wrote about this section</a> and how we plan to identify other partners who are able to provide appropriate services to people who find themselves in a breach. Identity protection providers, for example, make a lot of sense for many data breaches.</p><p>Now that we're live, we'll also work on fleshing this page out with more breach and user-specific data. For example, if the service supports 2FA, then we'll call that out specifically rather than rely on the generic advice above. Same with passkeys, and we'll add a section for that. A recent discussion with the NCSC while we were in the UK was around adding localised data breach guidance, for example, showing folks from the UK the NCSC logo and a link to <a href="https://www.troyhunt.com/after-the-breach-finding-new-partners-with-solutions-for-have-i-been-pwned-users/" rel="noreferrer">their resource on the topic</a> (which recommends checking HIBP 🙂).</p><p>I'm sure there's much more we can do here, so if you've got any great ideas, drop me a comment below.</p><h2 id="the-dashboard">The Dashboard</h2><p>Over the course of many years, we introduced more and more features that required us to know who you were (or at least that you had access to the email address you were using). It began with <a href="https://www.troyhunt.com/heres-how-im-going-to-handle-ashley/" rel="noreferrer">introducing the concept of a sensitive breach</a> during the Ashley Madison saga of 2015, which meant the only way to see your involvement in that incident was to receive an email to the address before searching. (Sidenote: <a href="https://www.troyhunt.com/the-ethics-of-running-a-data-breach-search-service/" rel="noreferrer">There are many good reasons why we don't do that on every breach</a>.) In 2019, when <a href="https://www.troyhunt.com/authentication-and-the-have-i-been-pwned-api/" rel="noreferrer">I put an auth layer around the API to tackle abuse</a> (which it did <em>beautifully!</em>) I required email verification first before purchasing a key. And more things followed: a dedicated domain search dashboard, managing your paid subscription and earlier this year, viewing stealer logs for your email address.</p><p>We've now unified all these different places into one central dashboard:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-15.png" alt="" loading="lazy" width="1342" height="1085" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-15.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-15.png 1000w, https://www.troyhunt.com/content/images/2025/05/image-15.png 1342w"></figure><p>From a glance at the nav on the left, you can see a lot of familiar features that are pretty self-explanatory. These combine relevant things for the masses and those that are more business-oriented. They're now all behind the one "Sign In" that verifies access to the email address before being shown. In the future, we'll also add passkey support to avoid needing to send an email first.</p><p>The dashboard approach isn't just about moving existing features under one banner; it will also give us a platform on which to build new features in the future that require email address verification first. For example, we've often been asked to provide people with the ability to subscribe their family's email addresses to notifications, yet have them go to a different address. Many of us play tech support for others, and this would be a genuinely useful feature that makes sense to place at a point where you've already verified your email address. So, stay tuned for that one, among many others.</p><h2 id="the-domain-search-feature">The Domain Search Feature</h2><p>More time went into this one feature than most of the other ones combined. There's a lot we've tried to do here, starting with a much cleaner list of verified domains:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-25.png" alt="" loading="lazy" width="1325" height="508" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-25.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-25.png 1000w, https://www.troyhunt.com/content/images/2025/05/image-25.png 1325w"></figure><p>The search results now give a much cleaner summary and add filtering by both email address and a hotly requested new feature - just the latest breach (it's in the drop-down):</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-27.png" alt="" loading="lazy" width="983" height="673" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-27.png 600w, https://www.troyhunt.com/content/images/2025/05/image-27.png 983w"></figure><p>All those searches now just return JSON from APIs and the whole dashboard acts as a single-page app, so everything is <em>really</em> snappy. The filtering above is done purely client-side against the full JSON of the domain search, an approach we've tested with domains of over a quarter million breached email addresses and still been workable (although arguably, you really want that data via the API rather than scrolling through it in a browser window).</p><p>Verification of domain ownership has also been completely rewritten and has a much cleaner, simpler interface:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-26.png" alt="" loading="lazy" width="824" height="841" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-26.png 600w, https://www.troyhunt.com/content/images/2025/05/image-26.png 824w"></figure><p>We still have work to do to make the non-email verification methods smoother, but that was the case before, too, so at least we haven't regressed. That'll happen shortly, promise!</p><h2 id="the-api">The API</h2><p>First things first: there have been no changes to the API itself. <strong>This update doesn't break anything!</strong></p><p>There's a discussion over on the UX rebuild GitHub repo about <a href="https://github.com/HaveIBeenPwned/ux-rebuild/discussions/52?ref=troyhunt.com" rel="noreferrer">the right way to do API documentation</a>. The general consensus is OpenAPI and we started going down that route using <a href="https://scalar.com/?ref=troyhunt.com" rel="noreferrer">Scalar</a>. In fact, you can even see the work Stefan did on this here at <a href="https://haveibeenpwned.com/scalar/?ref=troyhunt.com">haveibeenpwned.com/scalar</a>:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-28.png" alt="" loading="lazy" width="1049" height="388" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-28.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/image-28.png 1000w, https://www.troyhunt.com/content/images/2025/05/image-28.png 1049w"></figure><p>It's very cool, especially the way it documents samples in all sorts of different languages and even has a test runner, which is effectively Postman in the browser. Cool, but we just couldn't finish it in time. As such, we've kept <a href="https://haveibeenpwned.com/API/v3?ref=troyhunt.com" rel="noreferrer">the old documentation</a> for now and just styled it so it looks like the rest of the site (which I reckon is still pretty slick), but we do intend to roll to the Scalar implementation when we're not under the duress of such a big launch.</p><h2 id="the-merch-store">The Merch Store</h2><p>You know what else is awesome? Merch! No, seriously, we've had <em>so </em>many requests over the years for HIBP branded merch and now, here we are:</p><figure><a href="https://merch.haveibeenpwned.com/?ref=troyhunt.com"><img src="https://www.troyhunt.com/content/images/2025/05/Artboard-1@2000x-100.jpg" alt="" loading="lazy" width="2000" height="728" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/Artboard-1@2000x-100.jpg 600w, https://www.troyhunt.com/content/images/size/w1000/2025/05/Artboard-1@2000x-100.jpg 1000w, https://www.troyhunt.com/content/images/size/w1600/2025/05/Artboard-1@2000x-100.jpg 1600w, https://www.troyhunt.com/content/images/2025/05/Artboard-1@2000x-100.jpg 2000w"></a></figure><p>We actually now have a real-life merch store at <a href="https://merch.haveibeenpwned.com/?ref=troyhunt.com">merch.haveibeenpwned.com</a>! This was probably the worst possible use of our time, considering how much mechanical stuff we had to do to make all the new stuff work, but it was a bit of a passion project for Charlotte, so yeah, now you can actually buy HIBP merch. It's all done through Teespring (<a href="https://haveibeenpwned.com/Breach/Teespring?ref=troyhunt.com" rel="noreferrer">where have I heard that name before?!</a>) and everything listed there is at cost price - we make absolutely zero dollars, it's just a fun initiative for the community 🙂</p><p>We did try out their option for stickers too, but they fell well short of what we already had up with <a href="https://www.stickermule.com/haveibeenpwned?ref=troyhunt.com" rel="noreferrer">our little one-item store on Sticker Mule</a> so for now, that remains the go-to for laptop decorations. Or just go and grab <a href="https://github.com/HaveIBeenPwned/Branding/tree/main/Merch/Stickers?ref=troyhunt.com" rel="noreferrer">the open source artwork</a> and get your own printed from wherever you please.</p><h2 id="the-nerdy-bits">The Nerdy Bits</h2><p>We still run the origin services on Microsoft Azure using a combination of the App Service for the website, "serverless" Functions for most APIs (there are still a few async ones there that are called as a part of browser-based features), SQL Azure "Hyperscale" and storage account features like queues, blobs and tables. Pretty much all the coding there is C# with .NET 9.0 and ASP.NET MVC on .NET Core for the web app. Cloudflare still plays a <em>massive</em> role with a lot of code in workers, data in R2 storage and all their good bits around WAF and caching. We're also now exclusively using their Turnstile service for anti-automation and have ditched Google's reCAPTCHA completely - big yay!</p><p>The front end is now latest gen Bootstrap and we're using SASS for all our CSS and TypeScript for all our JavaScript. Our (other) man in Iceland <a href="https://www.linkedin.com/in/ingiber/?ref=troyhunt.com" rel="noreferrer">Ingiber</a> has just done an absolutely outstanding job with the interfaces and exceeded all our expectations by a massive margin. What we have now goes far beyond what we expected when we started this process, and a big part of that has been Ingiber's ability to take a simple requirement and turn it into a thing of beauty 😍 I'm very glad that Charlotte, Stefan and I got to spend time with him in Reykjavik last month and share some beers.</p><p>We also made some measurable improvements to website performance. For example, I ran a <a href="https://tools.pingdom.com/?ref=troyhunt.com" rel="noreferrer">Pingdom website speed test</a> just before taking the old one offline:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-31.png" alt="" loading="lazy" width="726" height="235" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-31.png 600w, https://www.troyhunt.com/content/images/2025/05/image-31.png 726w" sizes="(min-width: 720px) 720px"></figure><p>And then ran it over the new one:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-30.png" alt="" loading="lazy" width="722" height="228" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-30.png 600w, https://www.troyhunt.com/content/images/2025/05/image-30.png 722w" sizes="(min-width: 720px) 720px"></figure><p>So we cut out 28% of the page size and 31% of the requests. The load time is much of a muchness (and it's highly variable at that), but having solid measures for all the values in the column on the right is a very pleasing result. Consider also the commentary anyone in web dev would have seen over the years about how much bigger web pages have become, and here we are shaving off solid double-digit percentages 11 years later!</p><p>Finally, anything that could remotely be construed as tracking or ad bloat just isn't there, because we simply don't do any of that 🙂 In fact, the only real traffic stats we have are based on what Cloudflare sees when the traffic flows through their edge nodes. And that 1Password product placement is, as it's always been, just text and an image. We don't even track outbound clicks, that's up to them if they want to capture that on the landing page we link to. This actually makes discussions such as we're having with identity theft companies that want product placement much harder as they're used to getting the sorts of numbers that invasive tracking produces, but we wouldn't have it any other way.</p><h2 id="the-ai">The AI</h2><p>I wanted to make a quick note of this here, as AI seems to be either constantly overblown or denigrated. Either it's going to solve the world's problems, or it just produces "slop". I used Chat GPT in particular <em>really</em> extensively during this rebuild, especially in the final days when time got tight and my brain got fried. Here are some examples where it made a big difference:</p>
<!--kg-card-begin: html-->
<pre><code>I'm using Bootstrap icons from here: https://icons.getbootstrap.com/

What's a good icon to illustrate a heading called "Index"?</code></pre>
<!--kg-card-end: html-->
<p>This was right at the 11th hour when we realised we didn't have time to implement Scalar properly, and I needed to quickly migrate all the existing API docs to the new template. There are over 2,000 icons on that page, and this approach meant it took about 30 seconds to find the right one, each and every time.</p><p>We killed off some pages on the old site, but before rolling it over, I wanted to know exactly what was there:</p>
<!--kg-card-begin: html-->
<pre><code>Write me a PowerShell script to crawl haveibeenpwned.com and write out each unique URL it finds</code></pre>
<!--kg-card-end: html-->
<p>And then:</p>
<!--kg-card-begin: html-->
<pre><code>Now write a script to take all the paths it found and see if they exist on stage.haveibeenpwned.com
</code></pre>
<!--kg-card-end: html-->
<p>It found good stuff too, like the security.txt file I'd forgotten to migrate. It also found stuff that never existed, so it's the usual "trust, but verify" situation.</p><p>And just a gazillion little things where every time I needed anything from some CSS advice to configuring Cloudflare rules to idiosyncrasies in the .NET Core web app, the correct answer was seconds away. I'd say it was right 90% of the time, too, and if you're not using AI aggressively in your software development work now (and I'm sure there are much better ways, too) I'm pretty confident in saying "you're doing it wrong".</p><h2 id="the-journey-here">The Journey Here</h2><p>It's hard to explain how much has gone into this, and that goes well beyond just what you see in front of you on the website today. It's seemingly little things, like minor revisions to the terms of use and privacy policy, which required many hours of time and thousands of dollars with lawyers (just minor updates to how we process data and a reflection of new services such as the stealer logs). </p><p>We pushed out the new site in the wee hours of Sunday morning my time, and <em>almost </em>everything went well:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-22.png" alt="" loading="lazy" width="995" height="764" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-22.png 600w, https://www.troyhunt.com/content/images/2025/05/image-22.png 995w"></figure><p>One or two little glitches that we've fixed and pushed quickly, that's it. I've actually waited until now, 2 days after going live, to publish this post just so we could iron out as much stuff as possible first. We've pushed more than a dozen new releases already since that time, just to keep iterating and refining quickly. TBH, it's been a bit intense and has been an <em>enormously</em> time-consuming effort that's dominated our focus, especially over the last few weeks leading up to launch. And just to drive that point home, I literally got a health alert first thing Monday morning:</p><figure><img src="https://www.troyhunt.com/content/images/2025/05/image-24.png" alt="" loading="lazy" width="800" height="385" srcset="https://www.troyhunt.com/content/images/size/w600/2025/05/image-24.png 600w, https://www.troyhunt.com/content/images/2025/05/image-24.png 800w"></figure><p>Nothing like empirical data to make a point! That last weekend when we went live was especially brutal; I don't think I've devoted that much high-intensity time to a software release for decades.</p><p>Have I Been Pwned has been a passion for a quarter of my life now. What I built in 2013 was never intended to take me this far or last this long, and I'm kinda shocked it did if I'm honest. I feel that what we've built with this new site and new brand has elevated this little pet project into a serious service that has a new level of professionalism. But I hope that in reading this, you see that it has maintained everything that has always been great about the service, and I'm so glad to still be here writing about it today in <a href="https://www.troyhunt.com/tag/have-i-been-pwned-3f/" rel="noreferrer">the 205th blog post with that tag</a>. Thanks for reading, <a href="https://haveibeenpwned.com/?ref=troyhunt.com" rel="noreferrer">now go and enjoy the new website</a> 😊</p>

            <section>
                <a href="https://www.troyhunt.com/tag/have-i-been-pwned-3f/">Have I Been Pwned</a>
            </section>
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jules: An Asynchronous Coding Agent (291 pts)]]></title>
            <link>https://jules.google/</link>
            <guid>44034918</guid>
            <pubDate>Mon, 19 May 2025 21:12:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jules.google/">https://jules.google/</a>, See on <a href="https://news.ycombinator.com/item?id=44034918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p><span>1</span></p><div><p>Select your GitHub repository and branch. Write a detailed prompt for Jules.</p><p><span>*coming soon*</span> use "assign-to-jules" label in an issue to assign a task directly in GitHub.</p></div></div><div><p><span><span>@kathy/flipdisc </span><svg xmlns="http://www.w3.org/2000/svg" xml:space="preserve" x="0" y="0" version="1.1" viewBox="0 0 12 12" shape-rendering="crispEdges"><path fill="currentColor" d="M2 4v2h1v1h1v1h1v1h2V8h1V7h1V6h1V4z"></path></svg></span><span><span>main</span><svg xmlns="http://www.w3.org/2000/svg" xml:space="preserve" x="0" y="0" version="1.1" viewBox="0 0 12 12" shape-rendering="crispEdges"><path fill="currentColor" d="M2 4v2h1v1h1v1h1v1h2V8h1V7h1V6h1V4z"></path></svg></span></p><p>Can you bump the version of next.js to v15 and convert the project to use app directory?</p></div></div><div><div><p><span>2</span></p><p>Jules fetches your repository, clones it to a Cloud VM, and develops a plan utilizing the latest <a href="https://deepmind.google/technologies/gemini/pro/">Gemini 2.5 Pro model</a>.</p></div><div><div><p><img src="https://jules.google/jules-avatar-profile.png" width="30" height="30" alt="Jules Avatar"></p><div><p>Here is my plan:</p><p>I plan to update the following files to the new app directory structure.</p></div></div><div><div><p>That looks good. Continue!</p></div><p><img src="https://jules.google/you-avatar.png" width="30" height="30" alt="Your Avatar"></p></div></div></div><div><div><p><span>3</span></p><p>Jules provides a diff of the changes. Quickly browse and approve code edits.</p></div><div><pre> <p><span>9</span><span> </span><code></code></p><p><span>10</span><span> </span><code>  "dependencies": {</code></p><p><span>11</span><span>-</span><code>    "next": "10.2.3",</code></p><p><span>11</span><span>+</span><code>    "next": "15.0.1",</code></p><p><span>12</span><span> </span><code>    "react": "18.3.1",</code></p><p><span>13</span><span> </span><code>    "react-dom": "18.3"</code></p><p><span>14</span><span> </span><code>  }</code></p></pre></div></div><div><p><span>4</span></p><div><p>Jules creates a PR of the changes. Approve the PR, merge it to your branch, and publish it on GitHub.</p><p>Also, you can get caught up <span>fast</span>. Jules creates an audio summary of the changes. </p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC Chair Brendan Carr is letting ISPs merge–as long as they end DEI programs (103 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/05/fcc-chair-brendan-carr-is-letting-isps-merge-as-long-as-they-end-dei-programs/</link>
            <guid>44034536</guid>
            <pubDate>Mon, 19 May 2025 20:35:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/05/fcc-chair-brendan-carr-is-letting-isps-merge-as-long-as-they-end-dei-programs/">https://arstechnica.com/tech-policy/2025/05/fcc-chair-brendan-carr-is-letting-isps-merge-as-long-as-they-end-dei-programs/</a>, See on <a href="https://news.ycombinator.com/item?id=44034536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Verizon's letter said that because of the "changing landscape," the firm "has been evaluating its DEI-related programs, HR processes, supplier programs, training programs and materials, and other initiatives." Among other changes, Verizon said it "will no longer have a team or any individual roles focused on DEI" and will reassign DEI-focused employees to "HR talent objectives."</p>
<p>"Verizon recognizes that some DEI policies and practices could be associated with discrimination," the letter said.</p>
<p>T-Mobile sent a <a href="https://www.fcc.gov/ecfs/document/1032785606628/1">similar letter</a> to Carr on March 27, saying it "is fully committed to identifying and rooting out any policies and practices that enable such discrimination, whether in fulfillment of DEI or any other purpose," and is thus "conducting a comprehensive review of its DEI policies, programs, and activities." One day later, the FCC <a href="https://docs.fcc.gov/public/attachments/DA-25-283A1.pdf">approved</a> a T-Mobile joint venture to <a href="https://www.t-mobile.com/news/business/t-mobile-eqt-close-lumos-fiber-jv">acquire fiber provider Lumos</a>.</p>
<p>With the Verizon and T-Mobile deals approved, Carr has another opportunity to make demands on a major telecom company. On Friday, Charter announced a <a href="https://corporate.charter.com/newsroom/charter-communications-and-cox-communications-announce-definitive-agreement-to-combine-companies">$34.5 billion merger with Cox</a> that would make it the largest home Internet provider in the US, passing Comcast. Several <a href="https://www.fierce-network.com/broadband/what-charter-cox-deal-means-broadband-workers">Charter and Cox programs</a> could be on the chopping block because of Carr's animosity toward diversity initiatives.</p>

<h2>Verizon criticized as “cowardly”</h2>
<p>Media advocacy group Free Press criticized Verizon for agreeing to Carr's demands.</p>
<p>"Verizon's cowardly decision to modify or kill its diversity, equity and inclusion practices is the latest shameful episode in a litany of surrenders to appease our authoritarian president," Free Press Vice President of Policy Matt Wood <a href="https://www.freepress.net/news/verizon-cowardly-capitulates-trump-and-carrs-racist-bullying">said</a>. "The government alleges no specific instances of unlawful employment discrimination, and Verizon admits none. Yet to win a merger approval and the prospect of a few extra dollars, the company meekly suggests that some of its 'DEI policies and practices could be associated with discrimination'—lawyer-speak for we've done nothing wrong, but we can see which way the political winds are blowing."</p>
<p>Wood said that Carr "once defended his agency's independence from the White House when a Democrat was in charge" but is "now gleefully carrying out the president's orders to roll back civil-rights protections and equal-opportunity gains at all costs."</p>

          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kilo: A text editor in less than 1000 LOC with syntax highlight and search (114 pts)]]></title>
            <link>https://github.com/antirez/kilo</link>
            <guid>44034459</guid>
            <pubDate>Mon, 19 May 2025 20:28:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/antirez/kilo">https://github.com/antirez/kilo</a>, See on <a href="https://news.ycombinator.com/item?id=44034459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Kilo</h2><a id="user-content-kilo" aria-label="Permalink: Kilo" href="#kilo"></a></p>
<p dir="auto">Kilo is a small text editor in less than 1K lines of code (counted with cloc).</p>
<p dir="auto">A screencast is available here: <a href="https://asciinema.org/a/90r2i9bq8po03nazhqtsifksb" rel="nofollow">https://asciinema.org/a/90r2i9bq8po03nazhqtsifksb</a></p>
<p dir="auto">Usage: kilo <code>&lt;filename&gt;</code></p>
<p dir="auto">Keys:</p>
<div data-snippet-clipboard-copy-content="CTRL-S: Save
CTRL-Q: Quit
CTRL-F: Find string in file (ESC to exit search, arrows to navigate)"><pre><code>CTRL-S: Save
CTRL-Q: Quit
CTRL-F: Find string in file (ESC to exit search, arrows to navigate)
</code></pre></div>
<p dir="auto">Kilo does not depend on any library (not even curses). It uses fairly standard
VT100 (and similar terminals) escape sequences. The project is in alpha
stage and was written in just a few hours taking code from my other two
projects, load81 and linenoise.</p>
<p dir="auto">People are encouraged to use it as a starting point to write other editors
or command line interfaces that are more advanced than the usual REPL
style CLI.</p>
<p dir="auto">Kilo was written by Salvatore Sanfilippo aka antirez and is released
under the BSD 2 clause license.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The forbidden railway: Vienna-Pyongyang (2008) (167 pts)]]></title>
            <link>http://vienna-pyongyang.blogspot.com/2008/04/how-everything-began.html</link>
            <guid>44033310</guid>
            <pubDate>Mon, 19 May 2025 18:45:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://vienna-pyongyang.blogspot.com/2008/04/how-everything-began.html">http://vienna-pyongyang.blogspot.com/2008/04/how-everything-began.html</a>, See on <a href="https://news.ycombinator.com/item?id=44033310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-7076948956751293997" itemprop="description articleBody">
<p><span>ABOUT ME</span></p><p>


My name is Helmut and I was born in 1980 in Graz (Austria). Trains were my hobby since childhood. My 2nd hobby is travelling. During my trips I always combine those hobbies. I also like nature, mountains, hiking and so on.</p><p>

My hobby is also my profession - since 2007 I work at the <a href="http://www.oebb.at/">Austrian Federal Railway</a><a href="http://www.oebb.at/">s</a>.</p><p>


I had the idea to travel to North Korea by train already since some years. I especially like long, transcontinental train trips, and the idea to start such a trip at the next train station to my home and then reach a distant place only by using trains (or sometimes also other means of public ground/sea transportation).</p><p>

During such train trips over thousands of kilometers I have the time to slowly adapt to another country, to another culture and mentaility - without the hassle of crowded airports, jet-lag and the discomfort of long-distance flights.<br>
I like the feeling of having a sleeper-train-compartment as my living- and bed-room for some days. It gives me a different sense of time and it is the perfect way to escape from the hectic everyday life. Time get's a new meaning.<br>
In our Western everyday life time is scarce. Time is luxury. And my trips for me represent some kind of luxury - the luxury of having time, whereas I'm not interested in the luxury of 5-star-hotels. A decent hostel is OK.</p><p>

Of course just sitting on the train for days isn't enough. An interesting destination and some interesting intermediate stops are also necessary for a good trip.</p><p>

My preferred destinations are not the usual tourist hot spots. I like to go to places, which are not so well known.<br>
I'm especially interested in Eastern Europe and the countries of the former USSR. Also Asian countries raise my interest and I'm also planning trips to the Middle East.<br>
Of course I also have the idea to travel across the other continents by train somewhen in future, but right now there are still much places to discover on Eurasia.</p><p>






<span>THE IDEA - NORTH KOREA BY TRAIN</span></p><p>

I don't know exactly when North Korea came into my mind for the 1st time. There are so many countries in the world, of which you only hear sometimes in the news or which you find on a map and don't have an idea what it is like. Usually you just don't think too much about it.</p><p>

In 1998 I bought my 1st <a href="http://www.thomascookpublishing.com/series.htm?series=Timetables">Thomas Cook Overseas Timetable</a>, a comprehensive guide to rail services over the world.<br>
I only started to explore the internet at that time, so this timetable book (very much recommended) gave me a 1st overview about passenger train services all over the world. At that time I had only travelled by train to some Central/Western European countries, even the so close Eastern European countries were exotic to me at that time.<br>
I remember that I found the timetables for international trains for North Korea in that book. I was surprised to find out that even two different direct train services link Moscow and Pyongyang. One via China and one via the North Korean/Russian border at Tumangan. At that time I only knew that North Korea was a communist country, but I didn't further investigate on possibilities to go there.</p><p>

During the following years I collected a lot of travel experience. Each trip leaded to more exotic destinations than the one before. In 1998 I interrailed across Western/Northern Europe, in 1999 I started to explore the former communist states like Poland.<br>
In 2001 I organized the 1st trip into the Former Soviet Union: Moscow, St. Petersburg and the Baltic states.<br>
With every trip the self confidence grew. In 2002 I travelled with the Transsiberian railway to Irkutsk and back - the 1st transcontinental train trip. 2005 was the year of a <a href="http://eurasia2005.blogspot.com/">3-months-trip</a> across Russia, Mongolia, China, Kazakhstan and Uzbekistan.</p><p>

At around this time my interest into North Korea grew. Im 2004 I read a <a href="http://groups.google.com/group/misc.transport.rail.europe/browse_thread/thread/c127ba911243286a/913a9d7ee1aa95bd?lnk=st&amp;q&amp;rnum=1&amp;hl=de&amp;pli=1">travelogue</a> of David Eerdmanns, who travelled by train from Europe to Pyongyang (via Beijing).</p><p>

In 2005 I saw a documentary on TV about a special trip to North Korea for railway enthusiasts. The company "<a href="http://www.farrail.net/">Farrail</a>" sometimes organizes such trips for groups.<br>
Of course my interest into North Korea wasn't only rail-related, also the political situation and the isolated society drew my attention. I haven't been to the Soviet Union or to Eastern Europe prior the fall of the Iron Curtain at around 1990. It would have been very interesting to see these countries. But I was too late.<br>
North Korea still offers the possibility to see an isolated communist country. Of course as a tourist you only see what the government wants you to see, but nevertheless I thought that it must be an unique experience to go there.</p><p>



Then, in february 2006 I read this <a href="http://groups.google.com/group/misc.transport.rail.europe/browse_thread/thread/ac0d39d25981e4c2/ab80e93ec8f1f20e?lnk=st&amp;q=&amp;rnum=3&amp;hl=de#ab80e93ec8f1f20e">fascinating post</a> by Roderick Smith at the usenet group misc.transport.rail.europe:</p><p>

<span>The Pyongyang trip was 1993-94, marking the 10th anniversary of my trip via </span><span>Mongolia. </span><span>The North Korean visa could be ordered in advance from Australia, but had to </span><span>be collected in Beijing (same as the Mongolian one 10 years earlier). </span><span>The rules were: compulsory guide, at USD100 per day. This was rather </span><span>expensive for a solo traveller; it would have been the same price for a </span><span>group of four. </span><span>Leaving Beijing: Chinese train. I was in a cabin with three Mongolian </span><span>businessmen bringing in huge quantities of consumer goods not available in </span><span>their own country. They spoke English, and shared their crate of beer with </span><span>me. </span><span>The train ran hours late from the border. We arrived in Pyongyang in mid </span><span>evening, too late for my promised visit to a railway workshop. The guide </span><span>took me to a huge hotel, and stayed on for dinner. I seemed to be the only </span><span>guest. </span><span>Next morning he collected me in a car with a driver. We followed some tram </span><span>routes, then had a short metro ride (same style as Moskva, with ornate </span><span>stations), then headed to the station for my departure (IIRC 10.30). </span><span>My through carriage was attached to a long Korean train. Meals were brought </span><span>to me in my compartment. </span><span>This train also ran late. </span><span>Next day, the through car was detached from the train (at Tuman'gang?)and </span><span>taken to the bogie-change yard, but too late to be changed that day. We </span><span>spent the night in the yard. The explanation of this was given to me by the </span><span>wife of an automative engineer from North Korea. His family was travelling </span><span>to a Volvo factory in Sweden. </span><span>Next morning, the carriage had its bogies changed. Nobody stopped me from </span><span>taking photos. </span><span>The carriage was shunted to Hasan, with no connection to Russia that day. </span><span>We spent 24 h there. I had USD to change: there was a food shop beside the </span><span>station, and a wine shop in the station. The hot water samovar was no cold, </span><span>and the carriage had no lighting. This was a dreary wait. </span><span>We continued next day, and were attached to a 'Russia' 2 days later than the </span><span>scheduled one. A couple of other carriages were attached at other stops </span><span>during the first day. </span></p><p>
About four years ago, the agent which handles my bookings to these countries<br>
told me that westerners can no longer use the Hasan crossing. I am not sure<br>
about the crossing for the Pyongyang - Manchuria - Moskva route.</p>
<p><span>Regards, </span><span>Roderick B Smith </span><span>Rail News Victoria Editor </span></p><p>


This message was fateful... it was the only information about the Tumangan-route on the internet I could find at that time. Since then the "Tumangan"-route was in some way engraved in my brain.<br>
I already found out before, that this route is served by a sleeping-wagon of the North Korean railways which only runs twice monthly. Also this fact makes it more interesting than the other Moscow-Pyongyang route via China, which is served by two Russian sleeping-wagons.</p><p>

Two months later at a German railway forum <a href="http://www.drehscheibe-foren.de/foren/read.php?30,138804,138806#msg-138806">a discussion about the Khasan/Tumangan border area</a> (in German) started. Someone posted a question about how to get from Vladivostok to the border - just to have a look over to North Korea.<br>
<a href="http://www.drehscheibe-foren.de/foren/read.php?30,3113329,3113329#msg-3113329">Further discussion about the Tumangan-route</a> (in German) followed, but everyone reported that travel agencies said that this route is currently not offered for tourist trips.</p><p>

In autumn 2006 decided to try a small experiment connected to this route: As I planned a trip to Siberia in winter, I thought: "Why not using this exotic sleeping-wagon of the North Korean railways for a domestic trip inside Russia?"</p><p>

In 2006 no photos of this vehicle were available on the internet yet, so even the idea of being a passenger in it was quite attractive. It departs Moscow only twice monthly, but it was no problem to adapt my travel plan to it's timetable (dep. Moscow on the 11th and 25th of each month).</p><p>

Of course this vagon is not intended for domestic trips inside Russia and tickets are only sold for international trips.<br>
Alexander, a friend of mine in Moscow, whom I know since my 2005 Eurasia trip and who works at a railway ticket agency, bought me a ticket to the 1st station in North Korea. To Tumangan!!!</p><p>

<a href="https://imageshack.com/i/f0M1PnYoj" target="_blank"></a><a href="https://imageshack.com/i/ey1LdVuij" target="_blank"><img src="http://imagizer.imageshack.us/v2/800x600q90/538/1LdVui.jpg"></a></p><p>


My plan was to get off already somewhere near Irkutsk (5000 km east of Moscow, still more than 4000 km away from the North Korean border).</p><p>

Departure from Moscow was on the 25th december 2006. I arrived in Moscow in the morning of the same day, after having spent Christmas evening on the Budapest - Moscow train.<br>
My friend brought me to the station by car and due to a traffic jam I nearly missed my train with the North Korean wagon. We arrived only 10 minutes before departure.<br>
Hint: If you need to be somewhere in Moscow at a certain time - forget about the car, use the metro!</p><p>

The North Korean conductors were quite surprised about a passenger from Europe, but they let me in. I explained that I only go to Irkutsk.</p><p>


<a href="https://imageshack.com/i/f0M1PnYoj" target="_blank"></a><a href="https://imageshack.com/i/f0ko8OSlj" target="_blank"><img src="http://imagizer.imageshack.us/v2/800x600q90/540/ko8OSl.jpg"></a></p><p>


I then spent 4 days in the North Korean sleeping car. For the 1st 24 hours I had my own compartment, but at Yekaterinburg three North Korean men, who worked in Russia and travelled back home, and their enormous quantities of luggage occupied the other three places in the 4-bed-compartment.<br>
We had a good and interesting time together, for me it was exciting to communicate with North Koreans (they spoke a little bit Russian) and for them it was also interesting to talk to a Westerner. We had a friendly relationsship and also shared a bottle of Austrian schnapps together... so, North Korean people are also just ordinary people as everyone in the world.</p><p>

Some more impressions of that trip:</p><p>

<a href="https://imageshack.com/i/f0M1PnYoj" target="_blank"></a><a href="https://imageshack.com/i/ipLphk6Nj" target="_blank"><img src="http://imagizer.imageshack.us/v2/800x600q90/673/Lphk6N.jpg"></a></p><p>

<a href="https://imageshack.com/i/ipEUm4Fpj" target="_blank"><img src="http://imagizer.imageshack.us/v2/800x600q90/673/EUm4Fp.jpg"></a></p><p>

<a href="https://imageshack.com/i/ex8Dqjksj" target="_blank"><img src="http://imagizer.imageshack.us/v2/800x600q90/537/8Dqjks.jpg"></a> <br>
<a href="http://imageshack.us/photo/my-images/802/jl50.jpg/" target="_blank"><br></a>
<a href="http://imageshack.us/photo/my-images/849/n3iz.jpg/" target="_blank"><br></a>
<a href="http://imageshack.us/photo/my-images/208/xgx6.jpg/" target="_blank"><br></a>
A short video from inside the Korean carriage:<br>
<a href="http://www.youtube.com/watch?v=t1wMqNCeG0w">http://www.youtube.com/watch?v=t1wMqNCeG0w</a></p><p>



After this trip the next aim was clear: Going with this wagon over the border to North Korea!!! This was just the logical consequence.</p><p>

But there was still the obstacle, that this route was officially closed for tourists. Travel agencies continued to claim that this routes doesn't exist and the train had been cancelled. I knew that that was wrong, as the Russian train timetable website <a href="http://train.mza.ru/">http://train.mza.ru/</a> showed the sleeping wagon Moscow - Pyongyang via Tumangan and also showed real-time place availability for departure dates within the 44-days-booking period. Another story told by travel agencies was, that this route is too unrealiable due to power-failures inside North Korea and that nobody could say how many days late the train actually would arrive in Pyongyang.</p><p>

On the German "Drehscheibe"-Forum <a href="http://www.drehscheibe-foren.de/foren/read.php?30,3424479,3424479#msg-3424479">discussions about possibilities to enter at Tumangan </a>continued in august 2007.<br>
A result of this discussions was, that Tumangan is by default listed on every North Korean visa, despite the fact that KITC doesn't offer this route to tourists.</p><p>

This was an important information. At least it is not totally illegal to enter at Tumangan...</p><p>

Together with Oliver, a good friend of mine working at the Swiss railways, I further discussed the possibilities to try a trip via Tumangan somewhen in 2008.<br>
So if Tumangan is listed on the visa - it could be possible to just book an ordinary trip to North Korea via Sinujiu but then in reality arrive via Tumangan.... hmmmm</p><p>

We both had time for such a trip in september 2008. The decision to actually make the trip to North Korea was done in spring 2008, but the final decision over the route (via Tumangan or not) was postponed. As you can imagine, it was not easy to decide whether we should take the risks of such a trip....<br>
Of course the idea of a potential routing of our trip via Tumangan was top-secret, only people whom we knew very well were introduced.</p><p>

We booked an individual DPRK-trip with a travel agency specialized on North Korea. Of course we told them that we would go via Sinujiu...<br>
Some weeks after I booked and payed the trip and submitted all data for the further processing, I got a call by a friendly employee of the North Korean embassy in Vienna. He said me, that I could pick up my visa now.</p><p>

I went to the embassy (here you can see the building in a quiet residence area in Vienna: <a href="http://www.buergmann.net/penzing/suchen.php?suchtext=zichy">http://www.buergmann.net/penzing/suchen.php?suchtext=zichy</a>) with my passport and rang at the door. A Korean man in jogging clothes and slippers let me in, I gave him the passport, the visa application form with a passport-photo and the 10 EUR visa fee.<br>
Inside the building there were the typical pictures of the two Kims and so on. The man disappeared with the stuff I gave him, came back 5 minutes later, gave me the passport with the visa inside, guided me back to the door and wished my a nice trip.</p><p>

That was it. 5 minutes. No questions, no bureacratic nightmare (as written on <a href="http://wikitravel.org/en/North_Korea#Get_in">http://wikitravel.org/en/North_Korea#Get_in</a>) at all!</p><p>


<span><a href="http://vienna-pyongyang.blogspot.com/2008/09/vienna-moscow.html"><span>Tumangan, we are coming!!!</span></a></span><span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code SDK (320 pts)]]></title>
            <link>https://docs.anthropic.com/en/docs/claude-code/sdk</link>
            <guid>44032777</guid>
            <pubDate>Mon, 19 May 2025 18:04:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.anthropic.com/en/docs/claude-code/sdk">https://docs.anthropic.com/en/docs/claude-code/sdk</a>, See on <a href="https://news.ycombinator.com/item?id=44032777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Claude Code SDK allows developers to programmatically integrate Claude Code into their applications. It enables running Claude Code as a subprocess, providing a way to build AI-powered coding assistants and tools that leverage Claude’s capabilities.</p>
<p>The SDK currently support command line usage. TypeScript and Python SDKs are coming soon.</p>
<h2 id="basic-sdk-usage"><span>Basic SDK usage</span></h2>
<p>The Claude Code SDK allows you to use Claude Code in non-interactive mode from your applications. Here’s a basic example:</p>

<h2 id="advanced-usage"><span>Advanced usage</span></h2>
<h3 id="multi-turn-conversations"><span>Multi-turn conversations</span></h3>
<p>For multi-turn conversations, you can resume conversations or continue from the most recent session:</p>

<h3 id="custom-system-prompts"><span>Custom system prompts</span></h3>
<p>You can provide custom system prompts to guide Claude’s behavior:</p>

<p>You can also append instructions to the default system prompt:</p>

<h3 id="mcp-configuration"><span>MCP Configuration</span></h3>
<p>The Model Context Protocol (MCP) allows you to extend Claude Code with additional tools and resources from external servers. Using the <code>--mcp-config</code> flag, you can load MCP servers that provide specialized capabilities like database access, API integrations, or custom tooling.</p>
<p>Create a JSON configuration file with your MCP servers:</p>

<p>Then use it with Claude Code:</p>

<p>Note: When using MCP tools, you must explicitly allow them using the <code>--allowedTools</code> flag. MCP tool names follow the pattern <code>mcp__&lt;serverName&gt;__&lt;toolName&gt;</code> where:</p>
<ul>
<li><code>serverName</code> is the key from your MCP configuration file</li>
<li><code>toolName</code> is the specific tool provided by that server</li>
</ul>
<p>This security measure ensures that MCP tools are only used when explicitly permitted.</p>
<h2 id="available-cli-options"><span>Available CLI options</span></h2>
<p>The SDK leverages all the CLI options available in Claude Code. Here are the key ones for SDK usage:</p>
<table><thead><tr><th>Flag</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td><code>--print</code>, <code>-p</code></td><td>Run in non-interactive mode</td><td><code>claude -p "query"</code></td></tr><tr><td><code>--output-format</code></td><td>Specify output format (<code>text</code>, <code>json</code>, <code>stream-json</code>)</td><td><code>claude -p --output-format json</code></td></tr><tr><td><code>--resume</code>, <code>-r</code></td><td>Resume a conversation by session ID</td><td><code>claude --resume abc123</code></td></tr><tr><td><code>--continue</code>, <code>-c</code></td><td>Continue the most recent conversation</td><td><code>claude --continue</code></td></tr><tr><td><code>--verbose</code></td><td>Enable verbose logging</td><td><code>claude --verbose</code></td></tr><tr><td><code>--max-turns</code></td><td>Limit agentic turns in non-interactive mode</td><td><code>claude --max-turns 3</code></td></tr><tr><td><code>--system-prompt</code></td><td>Override system prompt (only with <code>--print</code>)</td><td><code>claude --system-prompt "Custom instruction"</code></td></tr><tr><td><code>--append-system-prompt</code></td><td>Append to system prompt (only with <code>--print</code>)</td><td><code>claude --append-system-prompt "Custom instruction"</code></td></tr><tr><td><code>--allowedTools</code></td><td>Comma/space-separated list of allowed tools (includes MCP tools)</td><td><code>claude --allowedTools "Bash(npm install),mcp__filesystem__*"</code></td></tr><tr><td><code>--disallowedTools</code></td><td>Comma/space-separated list of denied tools</td><td><code>claude --disallowedTools "Bash(git commit),mcp__github__*"</code></td></tr><tr><td><code>--mcp-config</code></td><td>Load MCP servers from a JSON file</td><td><code>claude --mcp-config servers.json</code></td></tr><tr><td><code>--permission-prompt-tool</code></td><td>MCP tool for handling permission prompts (only with <code>--print</code>)</td><td><code>claude --permission-prompt-tool mcp__auth__prompt</code></td></tr></tbody></table>
<p>For a complete list of CLI options and features, see the <a href="https://docs.anthropic.com/en/docs/claude-code/cli-usage">CLI usage</a> documentation.</p>
<h2 id="output-formats"><span>Output formats</span></h2>
<p>The SDK supports multiple output formats:</p>
<h3 id="text-output-default"><span>Text output (default)</span></h3>
<p>Returns just the response text:</p>

<h3 id="json-output"><span>JSON output</span></h3>
<p>Returns structured data including metadata:</p>

<p>Response format:</p>

<h3 id="streaming-json-output"><span>Streaming JSON output</span></h3>
<p>Streams each message as it is received:</p>

<p>Each conversation begins with an initial <code>init</code> system message, followed by a list of user and assistant messages, followed by a final <code>result</code> system message with stats. Each message is emitted as a separate JSON object.</p>
<h2 id="message-schema"><span>Message schema</span></h2>
<p>Messages returned from the JSON API are strictly typed according to the following schema:</p>

<p>We will soon publish these types in a JSONSchema-compatible format. We use semantic versioning for the main Claude Code package to communicate breaking changes to this format.</p>
<h2 id="examples"><span>Examples</span></h2>
<h3 id="simple-script-integration"><span>Simple script integration</span></h3>

<h3 id="processing-files-with-claude"><span>Processing files with Claude</span></h3>

<h3 id="session-management"><span>Session management</span></h3>

<h2 id="best-practices"><span>Best practices</span></h2>
<ol>
<li>
<p><strong>Use JSON output format</strong> for programmatic parsing of responses:</p>

</li>
<li>
<p><strong>Handle errors gracefully</strong> - check exit codes and stderr:</p>

</li>
<li>
<p><strong>Use session management</strong> for maintaining context in multi-turn conversations</p>
</li>
<li>
<p><strong>Consider timeouts</strong> for long-running operations:</p>

</li>
<li>
<p><strong>Respect rate limits</strong> when making multiple requests by adding delays between calls</p>
</li>
</ol>
<h2 id="real-world-applications"><span>Real-world applications</span></h2>
<p>The Claude Code SDK enables powerful integrations with your development workflow. One notable example is the <a href="https://docs.anthropic.com/en/docs/claude-code/github-actions">Claude Code GitHub Actions</a>, which uses the SDK to provide automated code review, PR creation, and issue triage capabilities directly in your GitHub workflow.</p>

<ul>
<li><a href="https://docs.anthropic.com/en/docs/claude-code/cli-usage">CLI usage and controls</a> - Complete CLI documentation</li>
<li><a href="https://docs.anthropic.com/en/docs/claude-code/github-actions">GitHub Actions integration</a> - Automate your GitHub workflow with Claude</li>
<li><a href="https://docs.anthropic.com/en/docs/claude-code/tutorials">Tutorials</a> - Step-by-step guides for common use cases</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's ICC blockade: digital dependence comes at a cost (249 pts)]]></title>
            <link>https://www.techzine.eu/news/privacy-compliance/131536/microsofts-icc-blockade-digital-dependence-comes-at-a-cost/</link>
            <guid>44032717</guid>
            <pubDate>Mon, 19 May 2025 17:59:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techzine.eu/news/privacy-compliance/131536/microsofts-icc-blockade-digital-dependence-comes-at-a-cost/">https://www.techzine.eu/news/privacy-compliance/131536/microsofts-icc-blockade-digital-dependence-comes-at-a-cost/</a>, See on <a href="https://news.ycombinator.com/item?id=44032717">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main">
        <article id="post-131536">
            
          	<div itemprop="articleBody" id="primary">
                    
<p><strong>In February, the United States imposed sanctions on the International Criminal Court (ICC) in The Hague. As a result, Chief Prosecutor Karim Khan has no access to the emails on his Microsoft account. The incident once again demonstrates the risks of dependence on US IT services.</strong></p>



<p>To make matters worse, Khan’s bank accounts have also been frozen, according to the <a href="https://apnews.com/article/icc-trump-sanctions-karim-khan-court-a4b4c02751ab84c09718b1b95cbd5db3" target="_blank">Associated Press</a>. If he takes a flight to the US, he will likely be arrested upon arrival. According to the Associated Press, the ICC has been paralyzed by the forced Microsoft blockade. The conflict between the ICC and the US arose in November, when the former issued an arrest warrant for Israeli Prime Minister Benjamin Netanyahu. This incident tells bystanders more than just how applicable it is to this specific situation. Anyone who does not want to follow the geopolitical stance of the US exactly must have a plan B when it comes to software.</p>



<h2 id="h-good-until-it-isn-t">Good until it isn’t</h2>



<p>European governments may consider the risks of using Microsoft acceptable. That <a href="https://www.techzine.nl/blogs/security/555877/landsbelang-in-geding-overheid-vindt-risicos-microsoft-365-aanvaardbaar/">was the position</a> taken by the Dutch government in October last year, for example. Uncertainty about the sovereignty of Microsoft’s cloud services was not seen as a deal breaker: Azure, 365, and other Microsoft services were judged to offer all kinds of advantages that could mitigate any potential issues. At least, that was how it looked in 2024.</p>



<p>Under President Trump, the US has taken a decidedly less friendly stance toward the European Union and its member states. These geopolitical tensions mean that it is up to the business community to smooth things over. Microsoft, for example, <a href="https://www.techzine.eu/news/infrastructure/83677/microsoft-introduces-sovereign-cloud-for-european-governments/">is adamant</a> that it will defend itself in court if Washington demands access to European citizens’ data. In fact, the encryption and access management of sovereign cloud services should make access from outside the continent technically impossible. Even with the clearest explanation, this may be revoked or secretly circumvented. And if Microsoft loses its case in court, it will still have to change course. Every non-US government will have to keep this scenario in mind when organizing its digital affairs.</p>



<p>In other words, relying solely on Microsoft services for critical purposes has its risks. What if the Dutch government refuses to go along with changed US policy on ASML’s chip machines, to name one example? Do all civil servants have email accounts and bank accounts that are not linked to Microsoft and cannot be blocked by the US? If not, these services may continue to run smoothly until it is too late.</p>



<h2 id="h-contracts-are-worth-little">Contracts are worth little</h2>



<p>The most important achievement is that national security should not depend on the honor of an SLA. On top of that, the ICC is currently looking for European alternatives to the lost services, a smaller version of the larger concerns about Europe’s digital autonomy. There are <a href="https://european-alternatives.eu/" target="_blank">plenty of services</a> that could in principle provide the same functionality as the established names; the question is, however, whether they are enterprise-ready, secure, and fully sovereign.</p>
                </div><!-- #primary -->
                    
            </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Windows 98 themed website in 1 HTML file for my post punk band (178 pts)]]></title>
            <link>https://corp.band</link>
            <guid>44032470</guid>
            <pubDate>Mon, 19 May 2025 17:39:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://corp.band">https://corp.band</a>, See on <a href="https://news.ycombinator.com/item?id=44032470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- Desktop Icons -->
      <div>
        <!-- Events Icon -->
        <div data-window="events">
          <p><img src="https://corp.band/assets/calendar.png" alt="Events">
          </p>
          <p><span>Events</span>
        </p></div>

        <div data-window="social">
          <p><img src="https://corp.band/assets/people.png" alt="Social Media">
          </p>
          <p><span>Social</span>
        </p></div>

        <!-- Merch Icon -->
        <div data-window="merch">
          <p><img src="https://corp.band/assets/spider.png" alt="Merch">
          </p>
          <p><span>Merch</span>
        </p></div>

        <!-- Music Icon -->
        <div data-window="music">
          <p><img src="https://corp.band/assets/music.png" alt="Music">
          </p>
          <p><span>Music</span>
        </p></div>

        <!-- Mailing List Icon -->
        <div data-window="mailing">
          <p><img src="https://corp.band/assets/mail.png" alt="Mailing List">
          </p>
          <p><span>Mailing List</span>
        </p></div>

        <!-- EPK Icon -->
        <div data-window="booking">
          <p><img src="https://corp.band/assets/computer.png" alt="Computer">
          </p>
          <p><span>Booking</span>
        </p></div>

        <!-- Trash Icon -->
        <div data-window="trash">
          <p><img src="https://corp.band/assets/recycle.png" alt="Recycle Bin">
          </p>
          <p><span>Recycle Bin</span>
        </p></div>
      </div>

      <!-- Windows -->
      <!-- Computer Window -->
      <div id="computer">
        
        <p>My Computer contents would go here.</p>
      </div>

      <!-- Music Window -->
      <div id="music">
          <h2>Watch CORP.</h2>
          <iframe src="https://www.youtube.com/embed/OumeCXiSUuU?si=lKZBSALydi3YYRCH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
          <p><a href="https://www.youtube.com/@corp.812" target="_blank">Watch More CORP.</a></p><h2>Listen To CORP.</h2>
          <p>
            It's your favorite band. It always has been.
            <img src="https://corp.band/assets/rock-on.gif" alt="CORP">
          </p>
          
          
        </div>

      <!-- Events Window -->
      

      <!-- Social Window -->
      

      <!-- Merch Window -->
      <div id="merch">
          <h2>Official CORP Merch</h2>
          <p>Be the coolest drone at the water cooler:</p>
          <ul>
            <li>Financial Accounting Services - $25</li>
            <li>Human Resource - $15</li>
            <li>Premium .mp3 - $30</li>
            <li>Insider Trading Tip - $20</li>
          </ul>
          <p><a href="https://corpband.bandcamp.com/" target="_blank">Shop on Bandcamp</a>
        </p></div>

      <!-- Mailing List Window -->
      <div id="mailing">
          <h2>Join Our Mailing List</h2>
          <p>Or become fodder for the machine:</p>
          

          <!-- <div class="mb-4">
            <label class="block mb-1">Email:</label>
            <input
              type="email"
              class="w-full p-1 border border-win98-dark shadow-win98-in"
              placeholder="your@email.com"
            />
          </div>
          <div class="mb-4">
            <label class="block mb-1">Name:</label>
            <input
              type="text"
              class="w-full p-1 border border-win98-dark shadow-win98-in"
              placeholder="Your Name"
            />
          </div>
          <button class="win98-btn">Subscribe</button> -->
        </div>

      <!-- EPK Window -->
      <div id="booking">
          <h2>Book CORP</h2>
          <p>
            Interested in booking CORP for your venue or event? Contact us via
            email:
          </p>
          
          <p>
            Check out our
            <a href="https://sites.google.com/view/corp-epk/home" target="_blank">Electronic Press Kit</a>
            for investment opportunities and tech specs.
          </p>
        </div>

      <!-- Trash Window -->
      <div id="trash">
          <p>The Recycle Bin is empty. Empty for kicks?</p>
          </div>

      <!-- Classified Window -->
      

      <!-- Links Window -->
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dilbert creator Scott Adams says he will die soon from same cancer as Joe Biden (345 pts)]]></title>
            <link>https://www.thewrap.com/dilbert-scott-adams-prostate-cancer-biden/</link>
            <guid>44031917</guid>
            <pubDate>Mon, 19 May 2025 17:00:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thewrap.com/dilbert-scott-adams-prostate-cancer-biden/">https://www.thewrap.com/dilbert-scott-adams-prostate-cancer-biden/</a>, See on <a href="https://news.ycombinator.com/item?id=44031917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>“Dilbert” creator Scott Adams said on Monday morning that he expects to die soon from prostate cancer, the same disease former President Joe Biden announced he is battling.</p>



<p>Adams made the jarring revelation during the latest episode of “Coffee With Scott Adams,” the Rumble show he hosts during weekday mornings. </p>	
	



<p>“I have the same cancer that Joe Biden has. I also have prostate cancer that has also spread to my bones, but I’ve had it longer than he’s had it – well, longer than he’s admitted having it,” Adams said. “So my life expectancy is maybe this summer. I expect to be checking out from this domain sometime this summer.” </p>	
	



<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Scott Adams — I have the exact same cancer as Joe Biden, and it has spread to my bones. I expect to die this summer.<a href="https://t.co/uBrYMihTg5">pic.twitter.com/uBrYMihTg5</a></p>— Citizen Free Press (@CitizenFreePres) <a href="https://twitter.com/CitizenFreePres/status/1924477866915315722?ref_src=twsrc%5Etfw">May 19, 2025</a></blockquote>
</div></figure>



<p>The 67-year-old Adams first gained fame as the creator of “Dilbert,” the satirical comic strip that focused on corporate office inanity, in 1989. </p>



<p>Adams has written dozens of books since then, and has become more outspoken about politics in the last decade, sharing views that are mostly pro-Donald Trump and critical of Democrats, on social media. His Rumble show has 38,000 followers, and on X, he has 1.2 million followers. </p>



<p>Before revealing he also had prostate cancer on Monday’s show, Adams shared his thoughts on the disease. </p>	
	



<p> “If it’s localized and it hasn’t left your prostate, it is 100% curable. But, if it leaves your prostate and spreads to other parts of your body — in this case, Joe Biden has it in his bones — it is not curable. “</p>	
	



<p>His comments came the morning after it was announced Biden was battling an <a href="https://www.thewrap.com/president-joe-biden-diagnosed-aggressive-prostate-cancer/">“aggressive” form of prostate cancer. </a></p>



<p>“I’d like to extend my respect and compassion and sympathy for the ex president and his family, because they’re going to be going through an especially tough time,” Adams added. </p>


<div>
		<p><a href="https://www.thewrap.com/morning-joe-biden-had-cancer-as-president-doctor-says/">
							<img loading="lazy" decoding="async" width="300" height="169" src="https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?fit=300%2C169&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?w=1200&amp;quality=80&amp;ssl=1 1200w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=300%2C169&amp;quality=80&amp;ssl=1 300w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=1024%2C576&amp;quality=80&amp;ssl=1 1024w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=768%2C432&amp;quality=80&amp;ssl=1 768w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=320%2C180&amp;quality=80&amp;ssl=1 320w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=640%2C360&amp;quality=80&amp;ssl=1 640w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=380%2C214&amp;quality=80&amp;ssl=1 380w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=760%2C428&amp;quality=80&amp;ssl=1 760w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=394%2C222&amp;quality=80&amp;ssl=1 394w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=788%2C444&amp;quality=80&amp;ssl=1 788w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=778%2C438&amp;quality=80&amp;ssl=1 778w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=976%2C549&amp;quality=80&amp;ssl=1 976w, https://i0.wp.com/www.thewrap.com/wp-content/uploads/2025/05/morningjoepic.png?resize=990%2C557&amp;quality=80&amp;ssl=1 990w" sizes="auto, (max-width: 300px) 100vw, 300px" data-portal-copyright="TheWrap" data-has-syndication-rights="1">					</a></p>
	</div>




	
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Game theory illustrated by an animated cartoon game (257 pts)]]></title>
            <link>https://ncase.me/trust/</link>
            <guid>44031535</guid>
            <pubDate>Mon, 19 May 2025 16:28:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ncase.me/trust/">https://ncase.me/trust/</a>, See on <a href="https://news.ycombinator.com/item?id=44031535">Hacker News</a></p>
<div id="readability-page-1" class="page">
	<p>loading...</p> <!-- TRANSLATE THIS -->
	
	
















<!-- Core Engine -->













<!-- Simulations -->






<!-- Slides -->











<!-- Main Code -->

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Edit is now open source (227 pts)]]></title>
            <link>https://devblogs.microsoft.com/commandline/edit-is-now-open-source/</link>
            <guid>44031529</guid>
            <pubDate>Mon, 19 May 2025 16:27:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/commandline/edit-is-now-open-source/">https://devblogs.microsoft.com/commandline/edit-is-now-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=44031529">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            
                    </header><!-- .entry-header -->
                <div>
                    <p><img src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2022/09/Christopher-Nguyen-Photo-96x96.png" alt="Christopher Nguyen">
                    </p>
                    <div>
                                                

                        <p>Product Manager II, Windows Terminal</p>                    </div>
                </div>
    </div><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-10694">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <h2>What is Edit?</h2>
<p>Edit is a new command-line text editor in Windows. Edit is open source, so you can <a href="https://github.com/microsoft/edit?tab=readme-ov-file#build-instructions">build</a> the code or <a href="https://github.com/microsoft/edit?tab=readme-ov-file#installation">install</a> the latest version from <a href="https://github.com/microsoft/edit">GitHub</a>!</p>
<p>This CLI text editor will be available to preview in the <a href="https://www.microsoft.com/windowsinsider/">Windows Insider Program</a> in the coming months. After that, it will ship as part of Windows 11!</p>
<h2>How to use Edit</h2>
<p>Open Edit by running <code>edit</code> in the command line or running <code>edit &lt;your-file-name&gt;</code>. With this, you will be able to edit files directly in the command line without context switching.</p>
<p><a href="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Edit.gif"><img fetchpriority="high" decoding="async" data-src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Edit.gif" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABbIAAAOfAQMAAAAnyaccAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAvElEQVR4nO3BgQAAAADDoPlT3+AEVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPAMmmYAAVAEGq0AAAAASUVORK5CYII=" alt="Edit image" width="1458" height="927"></a></p>
<h2>What are Edit’s features?</h2>
<p>Edit is still in an early stage, but it has several features out of the box. Here are some highlights!</p>
<h2>Lightweight</h2>
<p>Edit is a small, lightweight text editor. It is less than 250kB, which allows it to keep a small footprint in the Windows 11 image.</p>
<h2>Mouse Mode Support</h2>
<p>As a modeless editor with a Text User Interface (TUI), all the menu options in Edit have keybindings (which you can see next to the menu options).</p>
<p><a href="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/MouseModeSupport.gif"><img decoding="async" data-src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/MouseModeSupport.gif" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABbIAAAOfAQMAAAAnyaccAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAvElEQVR4nO3BgQAAAADDoPlT3+AEVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPAMmmYAAVAEGq0AAAAASUVORK5CYII=" alt="Mouse Mode Support image" width="1458" height="927"></a></p>
<h2>Open Multiple Files</h2>
<p>You can open multiple files in Edit and switch between them with <kbd>Ctrl+P</kbd> (or by clicking the file list on the lower-right).</p>
<p><a href="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/MultiFileSupport.gif"><img decoding="async" data-src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/MultiFileSupport.gif" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABZgAAAOfAQMAAAB/tjQFAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAuUlEQVR4nO3BAQ0AAADCoPdPbQ43oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4NsAi+oAAdera20AAAAASUVORK5CYII=" alt="Multi File Support image" width="1432" height="927"></a></p>
<h2>Find &amp; Replace</h2>
<p>You can find and replace text with <kbd>Ctrl+R</kbd> or select Edit &gt; Replace in the TUI menu. There is also Match Case and Regular Expression support as well.</p>
<p><a href="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace.png"><img decoding="async" data-src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace.png" src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace.png" alt="Replace image" width="1721" height="333" srcset="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace.png 1721w, https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace-300x58.png 300w, https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace-1024x198.png 1024w, https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace-768x149.png 768w, https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/Replace-1536x297.png 1536w" sizes="(max-width: 1721px) 100vw, 1721px"></a></p>
<h2>Word Wrap</h2>
<p>Edit supports word wrapping. To use Word Wrap, you can use <kbd>Alt+Z</kbd> or select View &gt; Word Wrap on the TUI menu.</p>
<p><a href="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/WordWrapMode.gif"><img decoding="async" data-src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2025/05/WordWrapMode.gif" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABbIAAAOfAQMAAAAnyaccAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAvElEQVR4nO3BgQAAAADDoPlT3+AEVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPAMmmYAAVAEGq0AAAAASUVORK5CYII=" alt="Word Wrap Mode image" width="1458" height="927"></a></p>
<h2>Why build another CLI editor?</h2>
<p>What motivated us to build Edit was the need for a default CLI text editor in 64-bit versions of Windows. 32-bit versions of Windows ship with the MS-DOS Edit or, but 64-bit versions do not have a CLI editor installed inbox. From there, we narrowed down our options…</p>
<p>Many of you are probably familiar with the “How do I exit vim?” meme. While it is relatively simple to learn the magic exit incantation, it’s certainly not a coincidence that this often turns up as a stumbling block for new and old programmers.</p>
<p>Because we wanted to avoid this for a built-in default editor, we decided that we wanted a modeless editor for Windows (versus a modal editor where new users would have to remember different modes of operation and how to switch between them).</p>
<p>This unfortunately limited our choices to a list of editors that either had no first-party support for Windows or were too big to bundle them with every version of the OS. As a result, Edit was born.</p>
<h2>Happy Editing!</h2>
<p>Edit will be rolling out to the <a href="https://www.microsoft.com/windowsinsider/">Windows Insider Program</a> in the coming months. Edit is now open source, so you can <a href="https://github.com/microsoft/edit?tab=readme-ov-file#build-instructions">build the code</a> or <a href="https://github.com/microsoft/edit?tab=readme-ov-file#installation">install it</a> from our GitHub repository.</p>
<p>If you have any feedback or questions, please reach out to the team on the official <a href="https://github.com/microsoft/edit">Edit repository</a>!</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><p><img src="https://devblogs.microsoft.com/commandline/wp-content/uploads/sites/33/2022/09/Christopher-Nguyen-Photo-96x96.png" alt="Christopher Nguyen"></p><div><p>Product Manager II, Windows Terminal</p></div></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Copilot Coding Agent (398 pts)]]></title>
            <link>https://github.blog/changelog/2025-05-19-github-copilot-coding-agent-in-public-preview/</link>
            <guid>44031432</guid>
            <pubDate>Mon, 19 May 2025 16:17:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.blog/changelog/2025-05-19-github-copilot-coding-agent-in-public-preview/">https://github.blog/changelog/2025-05-19-github-copilot-coding-agent-in-public-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=44031432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>Backlog getting you down? Drowning in technical debt? Delegate issues to Copilot so you can focus on the creative, complex, and high-impact work that matters most. Copilot coding agent makes this possible.</p>
<p>Simply assign an issue (or multiple issues) to Copilot just as you would another developer. You can do this from github.com, <a href="https://github.com/mobile">GitHub Mobile</a>, or the <a href="https://cli.github.com/">GitHub CLI</a>. Copilot works in the background, using its own secure cloud-based development environment powered by GitHub Actions. Copilot explores the repository, makes changes, and even validates its work with your tests and linter before it pushes.</p>
<p>Once Copilot is done, it’ll tag you for review. You can ask Copilot to make changes by leaving comments in the pull request. Or, check out the branch locally and continue work in your IDE, with Copilot at your side.</p>

<p>Copilot excels at low-to-medium complexity tasks in well-tested codebases, from adding features and fixing bugs to extending tests, refactoring, and improving documentation. You can even assign multiple issues to Copilot at the same time.</p>
<p>Copilot coding agent is available now for Copilot Pro+ and Copilot Enterprise subscribers. If you’re on Copilot Enterprise, an administrator will need to enable the new <strong>Copilot coding agent</strong> policy before you can get access. Using the agent consumes <a href="https://docs.github.com/en/billing/managing-billing-for-your-products/managing-billing-for-github-actions/about-billing-for-github-actions">GitHub Actions minutes</a> and <a href="https://docs.github.com/en/copilot/managing-copilot/monitoring-usage-and-entitlements/about-premium-requests">Copilot premium requests</a>, starting from entitlements included with your plan.</p>
<p>To get started and see our top tips for getting the best results with Copilot, check out <a href="https://docs.github.com/en/copilot/using-github-copilot/using-copilot-coding-agent-to-work-on-tasks/about-assigning-tasks-to-copilot">our Copilot coding agent documentation</a>.</p>
<p>Starting June 4th, Copilot coding agent will use <a href="https://docs.github.com/en/copilot/managing-copilot/monitoring-usage-and-entitlements/about-premium-requests">one premium request</a> per model request the agent makes. This is a preview feature, and may be changed in the future.</p>
<p>We’d love to hear from you. Join <a href="https://github.com/orgs/community/discussions/159068">the discussion</a> to share your thoughts and ask any questions.</p>
<p><em>Disclaimer: The UI for features in public preview is subject to change.</em></p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[xAI's Grok 3 comes to Microsoft Azure (122 pts)]]></title>
            <link>https://techcrunch.com/2025/05/19/xais-grok-3-comes-to-microsoft-azure/</link>
            <guid>44031387</guid>
            <pubDate>Mon, 19 May 2025 16:14:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/05/19/xais-grok-3-comes-to-microsoft-azure/">https://techcrunch.com/2025/05/19/xais-grok-3-comes-to-microsoft-azure/</a>, See on <a href="https://news.ycombinator.com/item?id=44031387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<div>
		<figure><img width="1024" height="683" src="https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?w=1024" alt="Satya Nadella, chief executive officer of Microsoft Corp." decoding="async" fetchpriority="high" srcset="https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg 3200w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=768,512 768w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=680,453 680w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=1200,800 1200w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=1280,853 1280w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=430,287 430w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=720,480 720w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=900,600 900w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=800,533 800w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=1536,1024 1536w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=2048,1365 2048w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=668,445 668w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=563,375 563w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=926,617 926w, https://techcrunch.com/wp-content/uploads/2017/09/gettyimages-681557990.jpg?resize=708,472 708w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong>Image Credits:</strong>David Ryder/Bloomberg / Getty Images</figcaption></figure>	</div>
	<div>
						<p><time datetime="2025-05-19T09:00:00-07:00">9:00 AM PDT · May 19, 2025</time></p>											</div>
</div><div>
		
		<div>
			<div>
<p id="speakable-summary">Microsoft on Monday became one of the first hyperscalers to provide managed access to Grok, the AI model developed by billionaire Elon Musk’s AI startup, xAI. </p>

<p>Available through Microsoft’s Azure AI Foundry platform, Grok — specifically <a href="https://techcrunch.com/2025/04/09/elon-musks-ai-company-xai-launches-an-api-for-grok-3/">Grok 3 and Grok 3 mini</a> — will “have all the service-level agreements&nbsp;Azure customers expect from any Microsoft product,” says Microsoft. They’ll also be billed directly by Microsoft, as is the case with the other models hosted in Azure AI Foundry.</p>







<p>When Musk announced Grok several years ago, he pitched the AI model as edgy, unfiltered, and anti-“woke” — in general, willing to answer controversial questions other AI systems simply won’t. He delivered on some of that promise. Told to be vulgar, for example, Grok will happily oblige, spewing colorful language you likely wouldn’t hear from&nbsp;<a href="https://techcrunch.com/2024/11/22/chatgpt-everything-to-know-about-the-ai-chatbot/">ChatGPT</a>.</p>

<p>According to SpeechMap, a benchmark comparing how different models treat sensitive subjects, Grok 3 is <a href="https://techcrunch.com/2025/04/16/theres-now-a-benchmark-for-how-free-an-ai-chatbot-is-to-talk-about-controversial-topics/">among the more permissive models</a>.</p>

<p>Grok, which powers a number of features on X, Musk’s social network, has been the subject of much controversy lately. <a href="https://www.pcmag.com/news/gross-elon-musks-grok-ai-will-undress-photos-of-women-on-x-if-you-ask" target="_blank" rel="noreferrer noopener nofollow">A recent report</a>&nbsp;found that Grok would undress photos of women when asked. In February, Grok&nbsp;<a href="https://techcrunch.com/2025/02/23/grok-3-appears-to-have-briefly-censored-unflattering-mentions-of-trump-and-musk/">briefly censored</a>&nbsp;unflattering mentions of Donald Trump and Musk. And just last week, an “unauthorized modification” caused Grok to&nbsp;<a href="https://techcrunch.com/2025/05/14/grok-is-unpromptedly-telling-x-users-about-south-african-genocide/">repeatedly refer</a> to&nbsp;white genocide in South Africa when invoked in certain contexts. </p>

<p>The Grok 3 and Grok 3 mini models in Azure AI Foundry are decidedly more locked down than the Grok models on X. They also come with additional data integration, customization, and governance capabilities not necessarily offered by xAI through <a href="https://techcrunch.com/2025/04/09/elon-musks-ai-company-xai-launches-an-api-for-grok-3/">its API</a>.</p>
</div>

			

			


			
			
			

			




			
			
			

			



			
<div>
	
	
	
	

	
<div>
	<p>
		Kyle Wiggers is TechCrunch’s AI Editor. His writing has appeared in VentureBeat and Digital Trends, as well as a range of gadget blogs including Android Police, Android Authority, Droid-Life, and XDA-Developers. He lives in Manhattan with his partner, a music therapist.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/kyle-wiggers/" data-event="button" href="https://techcrunch.com/author/kyle-wiggers/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>


		</div>
		

		
		<div id="wp-block-techcrunch-most-popular-posts__heading">
<h2 id="h-most-popular">Most Popular</h2>

</div>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Windows Subsystem for Linux is now open source (1233 pts)]]></title>
            <link>https://blogs.windows.com/windowsdeveloper/2025/05/19/the-windows-subsystem-for-linux-is-now-open-source/</link>
            <guid>44031385</guid>
            <pubDate>Mon, 19 May 2025 16:14:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.windows.com/windowsdeveloper/2025/05/19/the-windows-subsystem-for-linux-is-now-open-source/">https://blogs.windows.com/windowsdeveloper/2025/05/19/the-windows-subsystem-for-linux-is-now-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=44031385">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-index="0" data-js="panel" data-type="wysiwyg-with-aside" data-modular-content="" data-modular-content-collection="">
<p>Today we’re very excited to announce the open-source release of the Windows Subsystem for Linux. This is the result of a multiyear effort to prepare for this, and a great closure to the first ever issue raised on the Microsoft/WSL repo: <a href="https://github.com/microsoft/WSL/issues/1">Will this be Open Source? · Issue #1 · microsoft/WSL</a>.</p>
<p>That means that the code that powers WSL is now available on GitHub at <a href="https://github.com/microsoft/WSL/releases/tag/2.5.7">Microsoft/WSL</a> and open sourced to the community! You can download WSL and build it from source, add new fixes and features and participate in WSL’s active development.</p>
<h3>WSL component overview</h3>
<p>WSL is made of a set of distribution components. Some run in Windows, and some run inside the WSL 2 virtual machine. Here’s an overview of WSL’s architecture:</p>
<figure><p><img fetchpriority="high" decoding="async" src="https://winblogs.thesourcemediaassets.com/sites/3/2025/05/wsl-architecture.png" alt="Windows Subsystem for Linux architecture." width="1000" height="934"></p></figure>
<p>WSL’s code can be broken up into these main areas:</p>
<ul>
<li>Command line executables that are the entry points to interact with WSL
<ul>
<li>wsl.exe, wslconfig.exe and wslg.exe</li>
</ul>
</li>
<li>The WSL service that starts the WSL VM, starts distros, mounts file access shares and more
<ul>
<li>wslservice.exe</li>
</ul>
</li>
<li>Linux init and daemon processes, binaries that run in Linux to provide WSL functionality
<ul>
<li>init for start up, gns for networking, localhost for port forwarding, etc.</li>
</ul>
</li>
<li>File sharing Linux files to Windows with WSL’s plan9 server implementation
<ul>
<li>plan9</li>
</ul>
</li>
</ul>
<p>Head over to <a href="https://wsl.dev/">https://wsl.dev</a> to learn more about each component.</p>
<p>This comes as an addition to the already open sourced WSL components:</p>
<ul>
<li><a href="https://github.com/microsoft/wslg">microsoft/wslg: Enabling the Windows Subsystem for Linux to include support for Wayland and X server related scenarios</a></li>
</ul>
<ul>
<li><a href="https://github.com/microsoft/WSL2-Linux-Kernel">microsoft/WSL2-Linux-Kernel: The source for the Linux kernel used in Windows Subsystem for Linux 2 (WSL2)</a></li>
</ul>
<p>The following components are still part of the Windows image and are not open sourced at this time:</p>
<ul>
<li>Lxcore.sys, the kernel side driver that powers WSL 1</li>
</ul>
<ul>
<li>P9rdr.sys and p9np.dll, which runs the “\\wsl.localhost” filesystem redirection (from Windows to Linux)</li>
</ul>
<h3>Why open source now? A bit of history…</h3>
<p>WSL was first announced at BUILD back in 2016 and first shipped with the Windows 10&nbsp;Anniversary update.</p>
<p>At that time WSL was based on a pico process provider, lxcore.sys, which enabled Windows to natively run ELF executables, and implement Linux syscalls inside the Windows kernel. This eventually became what we today know as “WSL 1”, which WSL still supports.</p>
<p>Over time it became clear that the best way to provide optimal compatibility with native Linux was to rely on the Linux kernel itself. WSL 2 was born, and first announced in 2019.</p>
<p>As the community behind WSL grew, WSL gained more features such as GPU support, graphical applications support (via wslg) and support for systemd.</p>
<p>It eventually became clear that to keep up with the growing community and feature requests, WSL had to move faster, and ship separately from Windows. That’s why in 2021 we separated WSL from the Windows codebase, and moved it to its own codebase. This new WSL first shipped as version 0.47.1 to the Microsoft Store, in July 2021. At the time, only Windows 11 was supported, and the package was marked as preview, only recommended to users that wanted to experience the latest and greatest of WSL.</p>
<p>We continued to develop this new “WSL package” until it was ready for general availability. That happened November of 2022, with WSL 1.0.0, which added support for Windows 10 and was the first “stable” release of this new WSL.</p>
<p>From there we kept on improving WSL, with the objective of fully transitioning all users to this new WSL package, and away from the WSL component that shipped with Windows. Windows 11 24H2 was the first Windows build that moved users from the “built-in” WSL to the “new” WSL package. We kept wsl.exe in the Windows image, so it could download the latest package on demand to make the transition easier.</p>
<p>As we kept on improving WSL, we eventually hit another milestone: WSL 2.0.0 (What are the three hardest problems in computer science? Off by one errors and naming things!).</p>
<p>WSL 2.0.0 introduced major improvements such as mirrored networking, DNS tunneling, session 0 support, proxy support, firewall support and more.</p>
<p>And that’s the milestone we’re still building on today! At the time of writing this article, WSL <a href="https://github.com/microsoft/WSL/releases/tag/2.5.7">2.5.7</a> is the latest available version out of our <a href="https://github.com/microsoft/WSL/releases/tag/2.5.7">nine pages of Github releases</a> since 0.47.1 4 years ago !</p>
<h3>The community behind WSL</h3>
<p>Over the years we’ve been incredibly lucky to have a strong community supporting WSL from day 1. We’ve been blessed with people sharing their knowledge, and spending countless hours to help track down bugs, find the best ways to implement new features and improve WSL.</p>
<p>WSL could never have been what it is today without its community. Even without access to WSL’s source code, people have been able to make major contributions that lead to what WSL is now.</p>
<p>This is why we’re incredibly excited to open-source WSL today. We’ve seen how much the community has contributed to WSL without access to the source code, and we can’t wait to see how WSL will evolve now that the community can make direct code contributions to the project.</p>
<h3>Contributing to WSL</h3>
<p>Are you interested in learning how WSL works? Would you like to see how a specific feature works, or make a change? Head over to <a href="https://github.com/microsoft/WSL">microsoft/WSL</a> to learn more!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Open Sources Copilot (104 pts)]]></title>
            <link>https://code.visualstudio.com/blogs/2025/05/19/openSourceAIEditor</link>
            <guid>44031344</guid>
            <pubDate>Mon, 19 May 2025 16:09:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://code.visualstudio.com/blogs/2025/05/19/openSourceAIEditor">https://code.visualstudio.com/blogs/2025/05/19/openSourceAIEditor</a>, See on <a href="https://news.ycombinator.com/item?id=44031344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
        <!-- left nav -->
        <div>
            <nav id="docs-navbar" aria-label="Blog posts">
            	<h4>Blog posts</h4>
            	<ul>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/05/19/openSourceAIEditor" aria-label="Current Page: Open Source AI Editor">Open Source AI Editor</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/05/12/agent-mode-meets-mcp">Adding MCP in VS Code</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/04/07/agentMode">Agent mode available to all users</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/03/26/custom-instructions">Better AI results with custom instructions</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">Copilot Agent Mode (preview)</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2025/02/12/next-edit-suggestions">Copilot Next Edit Suggestions (preview)</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot">Announcing Copilot Free in VS Code</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/11/15/introducing-github-copilot-for-azure">GitHub Copilot for Azure</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/11/12/introducing-copilot-edits">Introducing Copilot Edits</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/06/24/extensions-are-all-you-need">Copilot extensions are all you need</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/06/07/wasm-part2">VS Code Extensions and WebAssembly - Part Two</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/05/08/wasm">VS Code Extensions and WebAssembly</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2024/04/15/vscode-day">VS Code Day 2024</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2023/11/13/vscode-copilot-smarter">Pursuit of wicked smartness in VS Code</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2023/07/20/mangling-vscode">Shrinking VS Code with name mangling</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2023/06/05/vscode-wasm-wasi">VS Code and WebAssemblies</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2023/04/13/vscode-day">VS Code Day</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2023/03/30/vscode-copilot">VS Code and Copilot</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/12/07/remote-even-better">Remote Development Even Better</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/11/28/vscode-sandbox">VS Code Sandboxing</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/10/04/vscode-community-discussions">VS Code Community Discussions</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/09/15/dev-container-features">Dev Container Features</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/08/16/markdown-language-server">Markdown Language Server</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/07/07/vscode-server">The VS Code Server</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/05/18/dev-container-cli">Dev container CLI</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/04/04/increase-productivity-with-containers">Moving from Local to Remote Development</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2022/03/08/the-tutorial-problem">The problem with tutorials</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/11/08/custom-notebooks">Custom Notebooks</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/10/20/vscode-dev">vscode.dev</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/10/11/webview-ui-toolkit">Webview UI Toolkit</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/09/29/bracket-pair-colorization">Bracket Pair Colorization</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/08/05/notebooks">Notebooks</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/07/06/workspace-trust">Workspace Trust</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/06/10/remote-repositories">Remote Repositories</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/06/02/build-2021">Build 2021</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2021/02/16/extension-bisect">Extension bisect</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/12/03/chromebook-get-started">VS Code on Chromebook</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/07/27/containers-edu">Development Containers in Education</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/07/01/containers-wsl">Dev Containers in WSL 2</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/06/09/go-extension">The Go experience</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/05/14/vscode-build-2020">VS Code at Build</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/05/06/github-issues-integration">GitHub Issues Integration</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/03/02/docker-in-wsl2">Docker in WSL 2</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/02/24/custom-data-format">Custom Data Format</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2020/02/18/optimizing-ci">Improving CI Build Times</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/10/31/inspecting-containers">Inspecting Containers</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/10/03/remote-ssh-tips-and-tricks">SSH Tips and Tricks</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/09/03/wsl2">WSL 2</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/07/25/remote-ssh">Remote SSH</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/05/23/strict-null">Strict null checking</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/05/02/remote-development">Remote Development</a>
            			</li>
            		
            			<li>
            				<a href="https://code.visualstudio.com/blogs/2019/02/19/lsif">Language Server Index Format</a>
            			</li>
            		
            	</ul>
            </nav>
            <nav id="small-nav" aria-label="Blog posts">
            	<label for="small-nav-dropdown">Blogs</label>
            	
            </nav>        </div>

        <!-- small right nav -->
        
        <p>
            <nav aria-labelledby="small-right-nav-label">
                <label for="small-right-nav-dropdown" id="small-right-nav-label">In this blog post</label>
                
            </nav>
        </p>
        

        <!-- main content -->
        <main>
            
<p>May 19th, 2025 by the VS Code team</p>
<p>We believe that the future of code editors should be open and powered by AI. For the last decade, VS Code has been one of the <a href="https://github.blog/news-insights/octoverse/octoverse-2024/#the-state-of-open-source" target="_blank">most successful OSS projects on GitHub</a>. We are grateful for our vibrant community of contributors and users who choose VS Code because it is open source. As AI becomes core to the developer experience in VS Code, we intend to stay true to our founding development principles: open, collaborative, and community-driven.</p>
<p>We will open source the code in the <a href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat" target="_blank">GitHub Copilot Chat extension</a> under the MIT license, then carefully refactor the relevant components of the extension into VS Code core. This is the next and logical step for us in making <strong>VS Code an open source AI editor</strong>. It’s a reflection that AI-powered tools are core to how we write code; a reaffirmation of our belief that working in the open leads to a better product for our users and fosters a diverse ecosystem of extensions.</p>
<h2 id="_why-open-source-now" data-needslink="_why-open-source-now">Why open source now?</h2>
<p>Over the last few months, we’ve observed shifts in AI development that motivated us to transition our AI development in VS Code from closed to open source:</p>
<ul>
<li>Large language models have significantly improved, mitigating the need for “secret sauce” prompting strategies.</li>
<li>The most popular and effective UX treatments for AI interactions are now common across editors. We want to enable the community to refine and build on these common UI elements by making them available in a stable, open codebase.</li>
<li>An ecosystem of open source AI tools and VS Code extensions has emerged. We want to make it easier for these extension authors to build, debug, and test their extensions. This is especially challenging today without access to the source code in the Copilot Chat extension.</li>
<li>We’ve gotten a lot of questions about the data that is collected by AI editors. Open sourcing the Copilot Chat extension enables you to see the data we collect, increasing transparency.</li>
<li>Malicious actors are increasingly targeting AI developer tools. Throughout VS Code’s history as OSS, community issues and PRs have helped us find and fix security issues quickly.</li>
</ul>
<h2 id="_next-steps" data-needslink="_next-steps">Next steps</h2>
<p>In the coming weeks, we will work to open source the code in the <a href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat" target="_blank">GitHub Copilot Chat extension</a> and refactor AI features from the extension into VS Code core. Our core priorities remain intact: delivering great performance, powerful extensibility, and an intuitive, beautiful user interface.</p>
<p>Open source works best when communities build around a stable, shared foundation. Thus, our goal is to make contributing AI features as simple as contributing to any part of VS Code. The stochastic nature of large language models makes it especially challenging to test AI features and prompt changes. To ease this, we will also make our prompt test infrastructure open source to ensure that community PRs can build and pass tests.</p>
<p>As usual, you can follow along on <a href="https://github.com/microsoft/vscode/issues/248627" target="_blank">our iteration plan</a>, where we will provide more information on this work. We will also keep <a href="https://code.visualstudio.com/docs/supporting/FAQ">our FAQ</a> updated with answers to questions from the community. <a href="https://github.com/microsoft/vscode/issues" target="_blank">We welcome your feedback</a> as we bring this vision to life.</p>
<p>We’re excited to shape the future of development as an open source AI editor - and we hope you’ll join us on this journey to build in the open.</p>
<p>Happy coding!</p>
<p>The VS Code team</p>

        </main>

        <!-- medium right nav -->
        
        <!-- end of page connect widget -->
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Investment Bank to inject €70B in European tech (281 pts)]]></title>
            <link>https://ioplus.nl/en/posts/european-investment-bank-to-inject-70-billion-in-european-tech</link>
            <guid>44031297</guid>
            <pubDate>Mon, 19 May 2025 16:05:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ioplus.nl/en/posts/european-investment-bank-to-inject-70-billion-in-european-tech">https://ioplus.nl/en/posts/european-investment-bank-to-inject-70-billion-in-european-tech</a>, See on <a href="https://news.ycombinator.com/item?id=44031297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The European Investment Bank (EIB) will invest <a href="https://www.eib.org/en/press/news/president-calvino-tech-firms-innovators-handelsblatt">€70 billion</a> into Europe's technology sector by 2027, aiming to close the innovation gap with the United States. This initiative seeks to strengthen Europe's position in emerging technologies like artificial intelligence and military drones and to draw increased private investment, potentially unlocking €250 billion for the sector. EIB President Nadia Calviño emphasizes the bank's willingness to take more risks, notably speeding up the venture capital financing process, which could be pivotal for startups in a fast-moving market</p><p>The EIB plans to launch this initiative, dubbed TechEU, later this year, creating a centralized hub for financing requests from researchers and companies. This initiative aims to streamline the process, making EU funding processes faster and simpler. A quicker decision-making process can differentiate between the survival and failure of startups navigating tight cash flows and competitive markets.</p><p>In an <a href="https://www.handelsblatt.com/politik/international/eu-foerderbank-eib-will-70-milliarden-fuer-tech-firmen-und-forscher-bereitstellen/100127812.html">interview</a> with German business newspaper <em>Handelsblatt,</em> Calviño has emphasized a newfound willingness to embrace risk within the EIB's financing strategies. The bank aims to process startup financing applications within six months, significantly improving from the current 18-month timespan. Calviño describes this accelerated timeline as a 'gamechanger,' pointing out that the high-paced nature of tech innovation requires nimble response times to keep up with market dynamics.</p><h2>Investment climate in Europe</h2><p>Drawing on the current geopolitical landscape, Calviño sees the uncertainty generated by US President Donald Trump's economic policies as an opportunity for Europe. This environment increasingly attracts international investors interested in the stability and potential offered by the European market. The EIB aims to position itself as a beacon of stability and innovation, leveraging Europe's large market and academic prowess to bolster technological advancement.</p><p>Furthermore, the EIB has prioritized defense and security within its portfolio, recognizing its synergies with technological advancements. This approach acknowledges that investments in these sectors can stimulate technological development and fortify Europe’s technological agenda. As the EIB funds projects across various tech domains, it develops a comprehensive ecosystem where tech innovation is both shielded and nurtured.</p><p>With plans to co-invest with private investors, the EIB aspires to inspire confidence and mitigate risk through its backing, potentially catalyzing up to €250 billion in the European tech ecosystem. As the EIB awaits approval from the 27 EU finance ministers, this initiative underscores Europe's commitment to closing the innovation gap with the US and asserting its role as a global tech leader. The approval is expected to take place next month.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Too Much Go Misdirection (161 pts)]]></title>
            <link>https://flak.tedunangst.com/post/too-much-go-misdirection</link>
            <guid>44031009</guid>
            <pubDate>Mon, 19 May 2025 15:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flak.tedunangst.com/post/too-much-go-misdirection">https://flak.tedunangst.com/post/too-much-go-misdirection</a>, See on <a href="https://news.ycombinator.com/item?id=44031009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Poking through layers of indirection in <b>go</b> trying to recover some efficiency.</p><p>Many functions in <b>go</b> take an <code>io.Reader</code> interface as input. This is a sensible default, allowing for streaming of data, instead of loading the entirety into memory. In some cases, though, we need the bytes. Which we may already have, in which case it would be great to simply use those bytes. Alas, this can be quite difficult.</p><h3 id="context">context</h3><p>I’m decoding some images. I’m using <i>libavif</i> and <i>libheif</i> via C bindings. For reasons primarily motivated by simplicity, I’m using the simple memory interfaces for these libraries, which makes it much easier to get the data from go into C. The streaming interface is much more work, and anyway the libraries would then just buffer the data internally, making another copy. Not every decoder fully works in a streaming fashion.</p><p>So the primary do the work function takes a <code>[]byte</code> and passes it to C, and there’s a wrapper that does things the go way with an <code>io.Reader</code>, which does a full read into a temporary buffer before sending it along. Now, as it happens, my application also uses <code>[]byte</code> internally because that’s what I’m getting out of <i>libsqlite3</i> (because again, the streaming interface is much trickier to wire up) and also because that’s what you get when doing RPC with <i>encoding/gob</i>. I think this is not an unusual scenario.</p><h3 id="bytes">bytes</h3><p>What I would like is for my image decoding function to notice that the <code>io.Reader</code> it has been given is in fact a <code>bytes.Reader</code> so we can skip the copy. Anyone who’s spent any time looking around in the go standard library has noticed that similar shortcuts are commonplace. Interfaces are type checked against specific implementations, and then optimized code paths are taken. Well, we can do the check, but it doesn’t immediately help, because <code>bytes.Reader</code> doesn’t expose its internal byte slice.</p><p>But it’s in there somewhere and I will not be denied.</p><pre><code>    <span>if</span> br<span>,</span> ok <span>:=</span> r<span>.</span><span>(</span><span>*</span>bytes<span>.</span>Reader<span>)</span>; ok <span>{</span>
        data <span>=</span> <span>*</span><span>(</span><span>*</span>[]<span>byte</span><span>)</span><span>(</span>unsafe<span>.</span>Pointer<span>(</span>br<span>)</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>var</span> buf bytes<span>.</span>Buffer
        io<span>.</span>Copy<span>(</span>&amp;buf<span>,</span> r<span>)</span>
        data <span>=</span> buf<span>.</span>Bytes<span>(</span><span>)</span>
    <span>}</span></code></pre><p>This seems to work in simple tests, but not when using the <code>image.Decode</code> function. A copy is still made. What’s wrong?</p><pre><code><span>func</span> Decode<span>(</span>r io<span>.</span>Reader<span>)</span> <span>(</span>Image<span>,</span> <span>string</span><span>,</span> error<span>)</span> <span>{</span>
    rr <span>:=</span> asReader<span>(</span>r<span>)</span>
<span>}</span>
<span>func</span> asReader<span>(</span>r io<span>.</span>Reader<span>)</span> reader <span>{</span>
    <span>if</span> rr<span>,</span> ok <span>:=</span> r<span>.</span><span>(</span>reader<span>)</span>; ok <span>{</span>
        <span>return</span> rr
    <span>}</span>
    <span>return</span> bufio<span>.</span>NewReader<span>(</span>r<span>)</span>
<span>}</span>
<span>type</span> reader <span>interface</span> <span>{</span>
    io<span>.</span>Reader
    Peek<span>(</span><span>int</span><span>)</span> <span>(</span>[]<span>byte</span><span>,</span> error<span>)</span>
<span>}</span></code></pre><p>Turns out the go image library does its own type inspection, looking for a <code>Peek</code> function, and if it’s not found, wraps the reader in a <code>bufio.Reader</code> instead. So the <code>bytes.Reader</code> never makes it into our function as is.</p><p>Now, why doesn’t <code>bytes.Reader</code> implement <code>Peek</code>? It’s just a byte slice, it’s definitely possible to peek ahead without altering stream state. But it was overlooked, and instead this workaround is applied.</p><p>Just knowing that we have a <code>bufio.Reader</code> isn’t sufficient, because, again, it doesn’t expose the underlying reader to us. It’s fine, okay, whatever. I am a master of unception.</p><pre><code><span>type</span> bufioReader <span>struct</span> <span>{</span>
    buf []<span>byte</span>
    rd  io<span>.</span>Reader
<span>}</span>
    <span>if</span> br<span>,</span> ok <span>:=</span> r<span>.</span><span>(</span><span>*</span>bufio<span>.</span>Reader<span>)</span>; ok <span>{</span>
        insides <span>:=</span> <span>(</span><span>*</span>bufioReader<span>)</span><span>(</span>unsafe<span>.</span>Pointer<span>(</span>br<span>)</span><span>)</span>
        r <span>=</span> insides<span>.</span>rd
    <span>}</span></code></pre><p>The new procedure is to look for a <code>bufio.Reader</code> and if so, unpack the inner reader. And then, as before, if it’s a <code>bytes.Reader</code>, we extract the bytes. The zero copy dream is alive.</p><h3 id="trees">trees</h3><p>The <code>bufio.Reader</code> should <i>probably</i> expose the underling reader.</p><p>The <code>bytes.Reader</code> should really implement <code>Peek</code>. I’m pretty sure the reason it doesn’t is because this is the only way of creating read only views of slices. And a naughty user could peek at the bytes and then modify them. Sigh. People hate const poisoning, but I hate this more.</p><p><code>bytes.Buffer</code> provides a <code>Bytes</code> function, but still not <code>Peek</code>, so even if you know that’s required or useful, it’s not a simple swap.</p><h3 id="forest">forest</h3><p>I’ve said this before, but the way <b>go</b> does structural typing, and the way the standard library uses it, creates these shadow APIs where blessed types work better than others. It’s almost never documented what the secret requirements are. But can you blame me for wanting to join the party?</p><p>I think two interpretations are possible. Casting was added to the language, and it’s used throughout the standard library, thus proving the feature is useful. Or pessimistically, every cast is a design oversight. The approach (in general, not my specific wizardry) only scales to the extent people stick with the standard types. It’s obviously not going to be feasible to specialize on third party types.
</p></div><p>
Posted 19 May 2025 14:45 by tedu Updated: 19 May 2025 14:45 
<br>Tagged: <a href="https://flak.tedunangst.com/t/go">go</a> <a href="https://flak.tedunangst.com/t/programming">programming</a>
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discover is now part of Capital One (102 pts)]]></title>
            <link>https://www.discover.com/faqs/merger/</link>
            <guid>44031000</guid>
            <pubDate>Mon, 19 May 2025 15:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.discover.com/faqs/merger/">https://www.discover.com/faqs/merger/</a>, See on <a href="https://news.ycombinator.com/item?id=44031000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content-rwd" role="main">

<div>


 <h2><b>Frequently asked questions</b></h2>
<p>We’re pleased to announce that on May 18, 2025, Discover Bank merged into Capital One, N.A. (“Capital One”). If you have any questions about credit cards, online banking accounts, or loans, we’re here to answer them.</p>
 
</div>
<div>


 <p>We’ll continue to keep you updated, and you can always check back here for more information. If you still have questions, our same friendly U.S.-based service is here to help by phone or online chat.</p>
 
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[23andMe Sells Gene-Testing Business to DNA Drug Maker Regeneron (201 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-05-19/23andme-sells-gene-testing-business-to-dna-drug-maker-regeneron</link>
            <guid>44030873</guid>
            <pubDate>Mon, 19 May 2025 15:27:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-05-19/23andme-sells-gene-testing-business-to-dna-drug-maker-regeneron">https://www.bloomberg.com/news/articles/2025-05-19/23andme-sells-gene-testing-business-to-dna-drug-maker-regeneron</a>, See on <a href="https://news.ycombinator.com/item?id=44030873">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-05-19/23andme-sells-gene-testing-business-to-dna-drug-maker-regeneron: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Zod 4 (604 pts)]]></title>
            <link>https://zod.dev/v4</link>
            <guid>44030850</guid>
            <pubDate>Mon, 19 May 2025 15:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zod.dev/v4">https://zod.dev/v4</a>, See on <a href="https://news.ycombinator.com/item?id=44030850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After a year of active development: Zod 4 is now stable! It's faster, slimmer, more <code>tsc</code>-efficient, and implements some long-requested features.</p>
<div><p>❤️</p><div><p>Huge thanks to <a href="https://go.clerk.com/zod-clerk" rel="noreferrer noopener" target="_blank">Clerk</a>, who supported my work on Zod 4 through their extremely generous <a href="https://clerk.com/blog/zod-fellowship" rel="noreferrer noopener" target="_blank">OSS Fellowship</a>. They were an amazing partner throughout the (much longer than anticipated!) development process.</p></div></div>
<p>To simplify the migration process both for users and Zod's ecosystem of associated libraries, Zod 4 is being published alongside Zod 3 as part of the <code>zod@3.25</code> release. To upgrade:</p>
<figure tabindex="0"></figure>
<p>Then import Zod 4 from the <code>"/v4"</code> subpath:</p>
<figure tabindex="0"></figure>
<p>Refer to the <a href="https://zod.dev/v4/changelog">Migration guide</a> for a complete list of breaking changes. This page covers the new features and improvements.</p>
<!-- -->

<p>Zod v3.0 was released in May 2021 (!). Back then Zod had 2700 stars on GitHub and 600k weekly downloads. Today it has 37.8k stars and 31M weekly downloads (up from 23M when the beta came out 6 weeks ago!). After 24 minor versions, the Zod 3 codebase had hit a ceiling; the most commonly requested features and improvements require breaking changes.</p>
<p>Zod 4 fixes a number of long-standing design limitations of Zod 3 in one fell swoop, paving the way for several long-requested features and a huge leap in performance. It closes 9 of Zod's <a href="https://github.com/colinhacks/zod/issues?q=is%3Aissue%20state%3Aopen%20sort%3Areactions-%2B1-desc" rel="noreferrer noopener" target="_blank">10 most upvoted open issues</a>. With luck, it will serve as the new foundation for many more years to come.</p>
<p>For a scannable breakdown of what's new, see the table of contents. Click on any item to jump to that section.</p>

<p>You can run these benchmarks yourself in the Zod repo:</p>
<figure tabindex="0"></figure>
<p>Then to run a particular benchmark:</p>
<figure tabindex="0"></figure>
<h3 id="14x-faster-string-parsing"><a data-card="" href="https://zod.dev/v4?id=14x-faster-string-parsing">14x faster string parsing</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure tabindex="0"></figure>
<h3 id="3x-faster-array-parsing"><a data-card="" href="https://zod.dev/v4?id=3x-faster-array-parsing">3x faster array parsing</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure tabindex="0"></figure>
<h3 id="65x-faster-object-parsing"><a data-card="" href="https://zod.dev/v4?id=65x-faster-object-parsing">6.5x faster object parsing</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>This runs the <a href="https://moltar.github.io/typescript-runtime-type-benchmarks/" rel="noreferrer noopener" target="_blank">Moltar validation library benchmark</a>.</p>
<figure tabindex="0"></figure>

<p>Consider the following simple file:</p>
<figure tabindex="0"></figure>
<p>Compiling this file with <code>tsc --extendedDiagnostics</code> using <code>"zod/v3"</code> results in &gt;25000 type instantiations. With <code>"zod/v4"</code> it only results in ~175.</p>
<div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div><p>The Zod repo contains a <code>tsc</code> benchmarking playground. Try this for yourself using the compiler benchmarks in <code>packages/tsc</code>. The exact numbers may change as the implementation evolves.</p><figure tabindex="0"></figure></div></div>
<p>More importantly, Zod 4 has redesigned and simplified the generics of <code>ZodObject</code> and other schema classes to avoid some pernicious "instantiation explosions". For instance, chaining <code>.extend()</code> and <code>.omit()</code> repeatedly—something that previously caused compiler issues:</p>
<figure tabindex="0"></figure>
<p>In Zod 3, this took <code>4000ms</code> to compile; and adding additional calls to <code>.extend()</code> would trigger a "Possibly infinite" error. In Zod 4, this compiles in <code>400ms</code>, <code>10x</code> faster.</p>
<div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div><p>Coupled with the upcoming <a href="https://github.com/microsoft/typescript-go" rel="noreferrer noopener" target="_blank"><code>tsgo</code></a> compiler, Zod 4's editor performance will scale to vastly larger schemas and codebases.</p></div></div>

<p>Consider the following simple script.</p>
<figure tabindex="0"></figure>
<p>It's about as simple as it gets when it comes to validation. That's intentional; it's a good way to measure the <em>core bundle size</em>—the code that will end up in the bundle even in simple cases. We'll bundle this with <code>rollup</code> using both Zod 3 and Zod 4 and compare the final bundles.</p>
<div><table><thead><tr><th>Package</th><th>Bundle (gzip)</th></tr></thead><tbody><tr><td><code>zod/v3</code></td><td><code>12.47kb</code></td></tr><tr><td><code>zod/v4</code></td><td><code>5.36kb</code></td></tr></tbody></table></div>
<p>The core bundle is ~57% smaller in Zod 4 (2.3x). That's good! But we can do a lot better.</p>

<p>Zod's method-heavy API is fundamentally difficult to tree-shake. Even our simple <code>z.boolean()</code> script pulls in the implementations of a bunch of methods we didn't use, like <code>.optional()</code>, <code>.array()</code>, etc. Writing slimmer implementations can only get you so far. That's where <code>zod/v4-mini</code> comes in.</p>
<figure tabindex="0"></figure>
<p>It's a Zod variant with a functional, tree-shakable API that corresponds one-to-one with <code>zod</code>. Where Zod uses methods, <code>zod/v4-mini</code> generally uses wrapper functions:</p>

<p>Not all methods are gone! The parsing methods are identical in <code>zod/v4</code> and <code>zod/v4-mini</code>.</p>
<figure tabindex="0"></figure>
<p>There's also a general-purpose <code>.check()</code> method used to add refinements.</p>

<p>The following top-level refinements are available in <code>zod/v4-mini</code>. It should be fairly self-explanatory which methods they correspond to.</p>
<figure tabindex="0"></figure>
<p>This more functional API makes it easier for bundlers to tree-shaking the APIs you don't use. While <code>zod/v4</code> is still recommended for the majority of use cases, any projects with uncommonly strict bundle size constraints should consider <code>zod/v4-mini</code>.</p>
<h3 id="66x-reduction-in-core-bundle-size"><a data-card="" href="https://zod.dev/v4?id=66x-reduction-in-core-bundle-size">6.6x reduction in core bundle size</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Here's the script from above, updated to use <code>"zod/v4-mini"</code> instead of <code>"zod"</code>.</p>
<figure tabindex="0"></figure>
<p>When we build this with <code>rollup</code>, the gzipped bundle size is <code>1.88kb</code>. That's an 85% (6.6x) reduction in core bundle size compared to <code>zod@3</code>.</p>
<div><table><thead><tr><th>Package</th><th>Bundle (gzip)</th></tr></thead><tbody><tr><td><code>zod/v3</code></td><td><code>12.47kb</code></td></tr><tr><td><code>zod/v4</code></td><td><code>5.36kb</code></td></tr><tr><td><code>zod/v4-mini</code></td><td><code>1.88kb</code></td></tr></tbody></table></div>
<p>Learn more on the dedicated <a href="https://zod.dev/packages/mini"><code>zod/v4-mini</code></a> docs page. Complete API details are mixed into existing documentation pages; code blocks contain separate tabs for <code>"Zod"</code> and <code>"Zod Mini"</code> wherever their APIs diverge.</p>

<p>Zod 4 introduces a new system for adding strongly-typed metadata to your schemas. Metadata isn't stored inside the schema itself; instead it's stored in a "schema registry" that associates a schema with some typed metadata. To create a registry with <code>z.registry()</code>:</p>
<figure tabindex="0"></figure>
<p>To add schemas to your registry:</p>
<figure tabindex="0"></figure>
<p>Alternatively, you can use the <code>.register()</code> method on a schema for convenience:</p>
<!-- -->
<figure tabindex="0"></figure>
<h3 id="the-global-registry"><a data-card="" href="https://zod.dev/v4?id=the-global-registry">The global registry</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Zod also exports a global registry <code>z.globalRegistry</code> that accepts some common JSON Schema-compatible metadata:</p>
<figure tabindex="0"></figure>
<h3 id="meta"><a data-card="" href="https://zod.dev/v4?id=meta"><code>.meta()</code></a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>To conveniently add a schema to <code>z.globalRegistry</code>, use the <code>.meta()</code> method.</p>
<!-- -->
<figure tabindex="0"></figure>
<div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div><p>For compatibility with Zod 3, <code>.describe()</code> is still available, but <code>.meta()</code> is preferred.</p><figure tabindex="0"></figure></div></div>

<p>Zod 4 introduces first-party JSON Schema conversion via <code>z.toJSONSchema()</code>.</p>
<figure tabindex="0"></figure>
<p>Any metadata in <code>z.globalRegistry</code> is automatically included in the JSON Schema output.</p>
<figure tabindex="0"></figure>
<p>Refer to the <a href="https://zod.dev/json-schema">JSON Schema docs</a> for information on customizing the generated JSON Schema.</p>

<p>This was an unexpected on. After years of trying to crack this problem, I finally <a href="https://x.com/colinhacks/status/1919286275133378670" rel="noreferrer noopener" target="_blank">found a way</a> to properly infer recursive object types in Zod. To define a recursive type:</p>
<figure tabindex="0"></figure>
<p>You can also represent <em>mutually recursive types</em>:</p>
<figure tabindex="0"></figure>
<p>Unlike the Zod 3 pattern for recursive types, there's no type casting required. The resulting schemas are plain <code>ZodObject</code> instances and have the full set of methods available.</p>
<figure tabindex="0"></figure>

<p>To validate <code>File</code> instances:</p>
<figure tabindex="0"></figure>

<p>Zod 4 introduces a new <code>locales</code> API for globally translating error messages into different languages.</p>
<figure tabindex="0"></figure>
<p>At the time of this writing only the English locale is available; There will be a call for pull request from the community shortly; this section will be updated with a list of supported languages as they become available.</p>

<p>The popularity of the <a href="https://www.npmjs.com/package/zod-validation-error" rel="noreferrer noopener" target="_blank"><code>zod-validation-error</code></a> package demonstrates that there's significant demand for an official API for pretty-printing errors. If you are using that package currently, by all means continue using it.</p>
<p>Zod now implements a top-level <code>z.prettifyError</code> function for converting a <code>ZodError</code> to a user-friendly formatted string.</p>
<figure tabindex="0"></figure>
<p>This returns the following pretty-printable multi-line string:</p>
<figure tabindex="0"></figure>
<p>Currently the formatting isn't configurable; this may change in the future.</p>

<p>All "string formats" (email, etc.) have been promoted to top-level functions on the <code>z</code> module. This is both more concise and more tree-shakable. The method equivalents (<code>z.string().email()</code>, etc.) are still available but have been deprecated. They'll be removed in the next major version.</p>
<figure tabindex="0"></figure>
<h3 id="custom-email-regex"><a data-card="" href="https://zod.dev/v4?id=custom-email-regex">Custom email regex</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>The <code>z.email()</code> API now supports a custom regular expression. There is no one canonical email regex; different applications may choose to be more or less strict. For convenience Zod exports some common ones.</p>
<figure tabindex="0"></figure>

<p>Zod 4 implements <code>z.templateLiteral()</code>. Template literal types are perhaps the biggest feature of TypeScript's type system that wasn't previously representable.</p>
<figure tabindex="0"></figure>
<p>Every Zod schema type that can be stringified stores an internal regex: strings, string formats like <code>z.email()</code>, numbers, boolean, bigint, enums, literals, undefined/optional, null/nullable, and other template literals. The <code>z.templateLiteral</code> constructor concatenates these into a super-regex, so things like string formats (<code>z.email()</code>) are properly enforced (but custom refinements are not!).</p>
<p>Read the <a href="https://zod.dev/api#template-literals">template literal docs</a> for more info.</p>

<p>New numeric "formats" have been added for representing fixed-width integer and float types. These return a <code>ZodNumber</code> instance with proper minimum/maximum constraints already added.</p>
<figure tabindex="0"></figure>
<p>Similarly the following <code>bigint</code> numeric formats have also been added. These integer types exceed what can be safely represented by a <code>number</code> in JavaScript, so these return a <code>ZodBigInt</code> instance with the proper minimum/maximum constraints already added.</p>
<figure tabindex="0"></figure>

<p>The existing <code>z.coerce.boolean()</code> API is very simple: falsy values (<code>false</code>, <code>undefined</code>, <code>null</code>, <code>0</code>, <code>""</code>, <code>NaN</code> etc) become <code>false</code>, truthy values become <code>true</code>.</p>
<p>This is still a good API, and its behavior aligns with the other <code>z.coerce</code> APIs. But some users requested a more sophisticated "env-style" boolean coercion. To support this, Zod 4 introduces <code>z.stringbool()</code>:</p>
<figure tabindex="0"></figure>
<p>To customize the truthy and falsy values:</p>
<figure tabindex="0"></figure>
<p>Refer to the <a href="https://zod.dev/api#stringbools"><code>z.stringbool()</code> docs</a> for more information.</p>

<p>The majority of breaking changes in Zod 4 involve the <em>error customization</em> APIs. They were a bit of a mess in Zod 3; Zod 4 makes things significantly more elegant, to the point where I think it's worth highlighting here.</p>
<p>Long story short, there is now a single, unified <code>error</code> parameter for customizing errors, replacing the following APIs:</p>
<p>Replace <code>message</code> with <code>error</code>. (The <code>message</code> parameter is still supported but deprecated.)</p>
<figure tabindex="0"></figure>
<p>Replace <code>invalid_type_error</code> and <code>required_error</code> with <code>error</code> (function syntax):</p>
<figure tabindex="0"></figure>
<p>Replace <code>errorMap</code> with <code>error</code> (function syntax):</p>
<figure tabindex="0"></figure>

<p>Discriminated unions now support a number of schema types not previously supported, including unions, pipes, and nested objects:</p>
<figure tabindex="0"></figure>
<p>Perhaps most importantly, discriminated unions now <em>compose</em>—you can use one discriminated union as a member of another.</p>
<figure tabindex="0"></figure>

<p>The <code>z.literal()</code> API now optionally supports multiple values.</p>
<figure tabindex="0"></figure>

<p>In Zod 3, they were stored in a <code>ZodEffects</code> class that wrapped the original schema. This was inconvenient, as it meant you couldn't interleave <code>.refine()</code> with other schema methods like <code>.min()</code>.</p>
<figure tabindex="0"></figure>
<p>In Zod 4, refinements are stored inside the schemas themselves, so the code above works as expected.</p>
<figure tabindex="0"></figure>
<h3 id="overwrite"><a data-card="" href="https://zod.dev/v4?id=overwrite"><code>.overwrite()</code></a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>The <code>.transform()</code> method is extremely useful, but it has one major downside: the output type is no longer <em>introspectable</em> at runtime. The transform function is a black box that can return anything. This means (among other things) there's no sound way to convert the schema to JSON Schema.</p>
<figure tabindex="0"></figure>
<p>Zod 4 introduces a new <code>.overwrite()</code> method for representing transforms that <em>don't change the inferred type</em>. Unlike <code>.transform()</code>, this method returns an instance of the original class. The overwrite function is stored as a refinement, so it doesn't (and can't) modify the inferred type.</p>
<figure tabindex="0"></figure>
<div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><div><p>The existing <code>.trim()</code>, <code>.toLowerCase()</code> and <code>.toUpperCase()</code> methods have been reimplemented using <code>.overwrite()</code>.</p></div></div>

<p>While this will not be relevant to the majority of Zod users, it's worth highlighting. The addition of <code>zod/v4-mini</code> necessitated the creation of a shared sub-package <code>zod/v4/core</code> which contains the core functionality shared between <code>zod/v4</code> and <code>zod/v4-mini</code>.</p>
<p>I was resistant to this at first, but now I see it as one of Zod 4's most important features. It lets Zod level up from a simple library to a fast validation "substrate" that can be sprinkled into other libraries.</p>
<p>If you're building a schema library, refer to the implementations of <code>zod/v4</code> and <code>zod/v4-mini</code> to see how to build on top of the foundation <code>zod/v4/core</code> provides. Don't hesitate to get in touch in GitHub discussions or via <a href="https://x.com/colinhacks" rel="noreferrer noopener" target="_blank">X</a>/<a href="https://bsky.app/profile/colinhacks.com" rel="noreferrer noopener" target="_blank">Bluesky</a> for help or feedback.</p>

<p>I'm planning to write up a series of additional posts explaining the design process behind some major features like <code>zod/v4-mini</code>. I'll update this section as those get posted.</p>
<p>For library authors, there is now a dedicated <a href="https://zod.dev/v4/library-authors">For library authors</a> guide that describes the best practices for building on top of Zod. It answers common questions about how to support Zod 3 &amp; Zod 4 (including Mini) simultaneously.</p>
<figure tabindex="0"></figure>
<p>Happy parsing!<br>
— Colin McDonnell <a href="https://x.com/colinhacks" rel="noreferrer noopener" target="_blank">@colinhacks</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Better Auth (YC X25) – Authentication Framework for TypeScript (183 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44030492</link>
            <guid>44030492</guid>
            <pubDate>Mon, 19 May 2025 14:48:03 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44030492">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="44030492">
      <td><span></span></td>      <td><center><a id="up_44030492" href="https://news.ycombinator.com/vote?id=44030492&amp;how=up&amp;goto=item%3Fid%3D44030492"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=44030492">Launch HN: Better Auth (YC X25) – Authentication Framework for TypeScript</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_44030492">117 points</span> by <a href="https://news.ycombinator.com/user?id=bekacru">bekacru</a> <span title="2025-05-19T14:48:03 1747666083"><a href="https://news.ycombinator.com/item?id=44030492">3 hours ago</a></span> <span id="unv_44030492"></span> | <a href="https://news.ycombinator.com/hide?id=44030492&amp;goto=item%3Fid%3D44030492">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Better%20Auth%20%28YC%20X25%29%20%E2%80%93%20Authentication%20Framework%20for%20TypeScript&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=44030492&amp;auth=2c12b1e23efe4e13e17e25e81675a26506cfdb68">favorite</a> | <a href="https://news.ycombinator.com/item?id=44030492">41&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi HN! We’re Bereket and KinfeMichael of Better Auth (<a href="https://www.better-auth.com/">https://www.better-auth.com/</a>), a comprehensive authentication framework for TypeScript that lets you implement
everything from simple auth flows to enterprise-grade systems directly on your own database, embedded in your backend.</p><p>To be clear—we’re not building a 3rd party auth service. Our goal is to make rolling your own auth so ridiculously easy that you’ll never need one.</p><p>Here are some YouTube videos explaining how it works (we did make our own video but weren’t happy with it and these videos do a great job):</p><p><a href="https://www.youtube.com/watch?v=hFtufpaMcLM" rel="nofollow">https://www.youtube.com/watch?v=hFtufpaMcLM</a> - a really good overview</p><p><a href="https://www.youtube.com/watch?v=QurjwJHCoHQ" rel="nofollow">https://www.youtube.com/watch?v=QurjwJHCoHQ</a> - also a good overview and dives a little deeper into the code</p><p><a href="https://www.youtube.com/watch?v=RKqHrE0KyeE" rel="nofollow">https://www.youtube.com/watch?v=RKqHrE0KyeE</a> - short and clear</p><p><a href="https://www.youtube.com/watch?v=Atev8Nxpw7c" rel="nofollow">https://www.youtube.com/watch?v=Atev8Nxpw7c</a> - with TanStack framework</p><p><a href="https://www.youtube.com/watch?v=n6rP9d3RWo8" rel="nofollow">https://www.youtube.com/watch?v=n6rP9d3RWo8</a> - a full-on 2 hour tutorial</p><p>Auth has been a pain point for many developers in the TypeScript ecosystem for a while. Not because there aren’t options but because most fall into 2 buckets: (1) Third-party services like Auth0 which own your user data, lock you into a black-box solution and are often super expensive; or (2) open source libraries like NextAuth that cover the basics but leave you stitching your own solution together from there.</p><p>For Better Auth. the kick off moment was building a web analytics platform and wanting to add an organization feature - things like workspaces, teams, members, and granular permissions. I assumed there’d be something out there I could plug in to NextAuth (the popular and kind of the only library), but there wasn’t. The only options were to build everything from scratch or switch to a 3rd party auth provider. I even tried hacking together a wrapper around NextAuth to support those features, but it was hacky. That’s when we decided to take a step back and build a proper auth library from the ground up with a plugin ecosystem that lets you start simple and scale as needed. That frustration turned into Better Auth.</p><p>Better Auth lets you roll your own auth directly on your backend and database, with support for everything from simple auth flows to enterprise-grade systems without relying on 3rd party services.</p><p>It comes with built-in features for common auth flows, and you can extend it as needed through a plugin ecosystem whether that’s 2FA, passkeys, organizations, multi-session, SSO, or even billing integration with Stripe.</p><p>Unlike 3rd party auth providers, we’re just a library you install in your own project. It’s free forever, lives entirely in your codebase, and gives you full control. You get all the features you’d expect from something like Auth0 or Clerk plus even more through our plugin system, including things like billing integrations with Stripe or Polar. Most libraries stop at the basics but Better Auth is designed to scale with your needs while keeping things simple when you don’t need all the extras.</p><p>We’re currently building an infrastructure layer that works alongside the framework to offer features that are hard to deliver as just a library—e.g. an admin dashboard with user analytics, bot/fraud/abuse detection, secondary session storage, and more. This will be our commercial offering. For this, there’s a waitlist at <a href="https://www.better-auth.build/" rel="nofollow">https://www.better-auth.build</a>. However, this is only optional infrastructure for teams that need these capabilities. The library is free and open source and will remain so.</p><p>We’d love your feedback!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fabric Is Just Plain Unreliable, and Microsoft's Hiding It (103 pts)]]></title>
            <link>https://www.brentozar.com/archive/2025/05/fabric-is-just-plain-unreliable-and-microsofts-hiding-it/</link>
            <guid>44029566</guid>
            <pubDate>Mon, 19 May 2025 13:19:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brentozar.com/archive/2025/05/fabric-is-just-plain-unreliable-and-microsofts-hiding-it/">https://www.brentozar.com/archive/2025/05/fabric-is-just-plain-unreliable-and-microsofts-hiding-it/</a>, See on <a href="https://news.ycombinator.com/item?id=44029566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p>Last week, <a href="https://www.reddit.com/r/MicrosoftFabric/comments/1km4sxh/fabric_down_again/">Microsoft Fabric went down yet again</a> for hours on multiple continents.</p>
<p>Oh, you didn’t hear about it? Let’s talk about why.</p>
<p><strong>First, Fabric’s status page is fabricated bullshit.</strong> The link <a href="https://aka.ms/fabricsupport">https://aka.ms/fabricsupport</a> takes you to a localized status page that almost always shows all green checkmarks – even when the service is on fire. During <a href="https://www.reddit.com/r/MicrosoftFabric/comments/1k9mmm8/fabric_practically_down/">last month’s 12+hour overnight outage</a>, people were screaming on Reddit overnight that things were down, but the status dashboard was showing all green. When Microsoft employees woke up, they asked if people were still having problems – and then eventually got around to updating the status page to reflect the outage when it was clear that things were really borked.</p>
<p>Redditors have resorted to relying on <a href="https://statusgator.com/services/microsoft-fabric">reporting Fabric outages to Statusgator</a>, who then tracks the time gap between a burst of user outage reports, to the time Microsoft actually updates their status page – and it ain’t pretty:</p>
<p><a href="https://statusgator.com/services/microsoft-fabric"><img fetchpriority="high" decoding="async" src="https://www.brentozar.com/wp-content/uploads/2025/05/status-fabric-600x169.jpg" alt="Microsoft Fabric on StatusGator" width="600" height="169" srcset="https://www.brentozar.com/wp-content/uploads/2025/05/status-fabric-600x169.jpg 600w, https://www.brentozar.com/wp-content/uploads/2025/05/status-fabric-250x70.jpg 250w, https://www.brentozar.com/wp-content/uploads/2025/05/status-fabric-768x216.jpg 768w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><strong>Second, the post-mortems are just as fabricated.</strong> After last month’s outage, the team <a href="https://www.reddit.com/r/MicrosoftFabric/comments/1kfzigz/comment/mr43att/">posted on Reddit</a>, and opened with this whopper:</p>
<blockquote><p>Fabric/Power BI is deployed in 58+ regions worldwide and serve approximately 400,000 organizations, and 30 million+ business users every month. This outage impacted 4 regions in Europe and the US for about 4 hours.</p></blockquote>
<p>See what they did there? They used big giant numbers to talk about the subscriber base, and then switched units of measure to talk about the affected population (just “the US”.) That’s like saying, “We served over 30 billion hamburgers last month, but unfortunately, just 1 country (the US) came down with food poisoning.” Gimme a break. Furthermore, the 4-hour thing is just&nbsp;<em>wildly</em> incorrect, as evidenced by the people screaming on Reddit overnight and into the morning.</p>
<blockquote><p>The combination of factors that triggered this issue did not occur until we hit specific regions and usage patterns. This was caught at that point through automated alerting, and our incident management team initiated a rollback.</p></blockquote>
<p>Specific regions like, uh, Europe and the United States. You know, small places. Villages, practically.</p>
<p>I absolutely love the second sentence as a world-class example of fabrication. Microsoft is accidentally admitting that their own&nbsp;<em>internal</em> alerting showed that Fabric was broken – but not their&nbsp;<em>external</em> alerting, aka their status page. They’re accidentally showing their cards that the status dashboard just doesn’t show the truth.</p>
<p><strong>Next, Microsoft hides the Fabric outage history as quickly as they can.</strong> The status dashboard has no list of recent outages. I feel genuinely sorry for Fabric admins who struggle troubleshooting failed Fabric processes that were supposed to run overnight. They think it’s their own problem, not realizing that there was an overnight outage that Microsoft has simply swept under the rug as quickly as possible. The admin checks the status page, sees nothing, and continues troubleshooting, thinking it’s their problem.</p>
<p>Contrast this with the <a href="https://azure.status.microsoft/en-us/status">overall Azure status page</a>, which has a prominent link to <a href="https://azure.status.microsoft/en-us/status/history/">Azure status history</a>, publicly calling out major outages and their post-mortems. Microsoft knows how to do this – but the Fabric team ain’t doin’ it.</p>
<p><a href="https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left.jpg"><img decoding="async" src="https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left-250x245.jpg" alt="" width="250" height="245" srcset="https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left-250x245.jpg 250w, https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left-408x400.jpg 408w, https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left-600x589.jpg 600w, https://www.brentozar.com/wp-content/uploads/2024/04/Brent_Ozar_Shouting_Left-768x754.jpg 768w" sizes="(max-width: 250px) 100vw, 250px"></a>I don’t understand why the Fabric team is so secretive about the outages.</p>
<p>It’s not like Microsoft Fabric even has a service level agreement.</p>
<p>It’s not like they’re giving refunds when your data is gone for hours at a time.</p>
<p>Oh you didn’t realize that?</p>
<p>That brings me to the only reason I can think of that someone would recommend Microsoft Fabric as a critical part of a company’s infrastructure today: <em>ignorance</em>. That’s where the blog post comes in, dear reader – I don’t want you to be ignorant.</p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diffusion Models Explained Simply (121 pts)]]></title>
            <link>https://www.seangoedecke.com/diffusion-models-explained/</link>
            <guid>44029435</guid>
            <pubDate>Mon, 19 May 2025 13:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/diffusion-models-explained/">https://www.seangoedecke.com/diffusion-models-explained/</a>, See on <a href="https://news.ycombinator.com/item?id=44029435">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header></header><section><p>Transformer-based large language models are relatively easy to understand. You break language down into a finite set of “tokens” (words or sub-word components), then train a neural network on millions of token sequences so it can predict the next token based on all the previous ones. Despite some clever tricks (mainly about how the model processes the previous tokens in the sequence), the core mechanism is relatively simple.</p>
<p>It’s harder to build the same kind of intuition about diffusion models (in part because the papers are much harder to read). But diffusion models are almost as big a part of the AI revolution as transformers. High-quality image generation has driven a lot of user interest in AI, particularly ChatGPT’s recent upgraded image generation.</p>
<p>Even if you don’t care much about images, there are also some fairly capable text-based diffusion models - not yet competitive with frontier transformer models, but it’s certainly possible that we’d someday see a diffusion language model that’s state-of-the-art in its niche.</p>
<h3>The core intuition</h3>
<p>So what are diffusion models? How are they different from transformers? What is the animating intuition that makes sense of how diffusion models work?</p>
<p>Imagine a picture of a dog. You could slowly add randomly-colored pixels to that picture - the visual equivalent of “white noise” - until it just looks like noise. You could do the same for any possible image. All those possible images look very different, but the eventual noise looks the same. That means that <strong>for any possible image, there is a gradient of steps between that image and “pure noise”</strong>.</p>
<p><span>
      <a href="https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/a19d2/gaussian-noise.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="gaussian noise" title="gaussian noise" src="https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/1c72d/gaussian-noise.jpg" srcset="https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/a80bd/gaussian-noise.jpg 148w,
https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/1c91a/gaussian-noise.jpg 295w,
https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/1c72d/gaussian-noise.jpg 590w,
https://www.seangoedecke.com/static/b626e5866ab86470fd5e640f73ad085b/a19d2/gaussian-noise.jpg 812w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>What if you could train a model to understand that gradient?</p>
<h3>Training and inference</h3>
<p>To train a diffusion model, you take a large set of images, each expressed as a big tensor, and a caption for each image, each expressed as a normal text-model embedding. At each step in the training, for the current image, you add a little bit of random noise. Then you pass that noisy image and caption to the model, and ask it to predict exactly what noise was added to the image (e.g. which pixels changed from what color to what color). Unlike a language model, there’s no “tokens” - every model step takes a full image as input and produces a “noise report” as output.  Finally, you reward the model<sup id="fnref-1"><a href="#fn-1">1</a></sup> based on how close the model’s prediction was. </p>
<p>It’s important to train on noisy images, all the way from a little bit of noise to images that are indistinguishable from static. Typically that’s done by adding increasing amounts of noise to images in the training set during training (on a fixed schedule). Eventually your model gets really good at identifying the last layer of noise, even from images that just look like the “pure noise” image above.</p>
<p>At inference time, that’s exactly what you do: start with pure noise and a user-provided caption, then run the model to identify the “top” layer of noise. Remove that layer, then keep running the model and removing layers until you’re left with the “original” image. In reality, that image was entirely generated by the model. <strong>This process of identifying a layer of noise and reversing it is called “denoising”.</strong></p>
<p>There are lots of tricks that get used in this process, but the two most important ones are variational auto-encoders and classifier-free guidance.</p>
<h4>Variational auto-encoders</h4>
<p>Expressing an image (or a video) as a big tensor is very expensive. Images have a lot of pixels! In practice, diffusion models operate on a <em>compressed</em> version of each image, kind of like how text models operate on strings of tokens rather than individual letters of bytes. How is that compressed version generated?</p>
<p>Typically with a variational autoencoder (VAE) model that is trained first. That model learns to turn a big image tensor into a smaller random-looking tensor, while still being able to convert it back into the original image. Why use a VAE rather than an existing well-known compression like JPEG?</p>
<ul>
<li>It’s important that the compressed representation be random-looking (i.e. Gaussian-shaped) so the denoising process works properly. JPEG compression is highly structured</li>
<li>The compressed representation must always be the same size, which current compression algorithms don’t do</li>
<li>It’s OK for the VAE to discard some details (e.g. camera noise) which JPEG compression will retain</li>
</ul>
<p>So the usual strategy for training and inference is to run a VAE over your image tensor, add noise, denoise on that, and then decode it back to an original full-size image. Note that there are some models that don’t use VAE, like DALLE-3, but it’s much slower and more expensive.</p>
<h4>Classifier-free guidance</h4>
<p>There’s a common trick to make sure the model is actually learning to generate images based on the caption, instead of just any possible image. During training, you zero out the caption for some images, so the model learns two functions: not just how to remove the noise for a caption, but how to remove the noise for any possible image. During inference, you run once with a caption and once without, and blend the predictions (magnifying the difference between those two vectors). That makes sure the model is paying a lot of attention to the caption.</p>
<h3>Key differences from transformers</h3>
<p>The fundamental operation here is totally different from transformer-based language models, so many of your intuitions about transformers won’t apply. For instance:</p>
<ul>
<li>At each inference step, transformers keep generating new tokens, while diffusion models go from a (e.g.) 256x256 pixel image to a different 256x256 pixel image.</li>
<li>Transformers start with nothing but the prompt, but diffusion models need a “blank canvas” of pure noise to work from.</li>
<li>Transformers don’t “edit” previously generated tokens - once they’re outputted, they’re locked in - but diffusion models can and do change previous output as they go. </li>
<li>If you stop a transformer early, you probably don’t get the answer you were looking for. If you stop a diffusion model early, you get a noisy version of the image you wanted.</li>
</ul>
<p>That last point indicates an interesting capability that diffusion models have: you get a kind of built-in quality knob. If you want fast inference at the cost of quality, you can just run the model for less time and end up with more noise in the final output<sup id="fnref-2"><a href="#fn-2">2</a></sup>. If you want high quality and you’re happy to take your time getting there, you can keep running the model until it’s finished removing noise.</p>
<h3>Why does it work?</h3>
<p>Transformers work because (as it turns out) the structure of human language contains a functional model of the world. If you train a system to predict the next word in a sentence, you therefore get a system that “understands” how the world works at a surprisingly high level. All kinds of exciting capabilities fall out of that - long-term planning, human-like conversation, tool use, programming, and so on.</p>
<p>What is the equivalent animating intuition for diffusion models? I don’t really know, but it’s probably something about the relationship between noise and data - if you can train a system to tell the difference between them, you’re necessarily encoding a model of the world into that system? I bet there’s a much nicer way of articulating this, or a better intuition that could be teased out here.</p>
<p>The same principles that work for images work for other kinds of data: video, audiom, and even text.</p>
<h3>Diffusion video models</h3>
<p>So far this has all been about image diffusion models. What about diffusion models that generate video? As far as I can tell, there are lots of different approaches, but the simplest one is to treat the entire video as a single noisy input. Instead of having your input be a tensor that represents a single picture, your input is a (much larger) tensor that represents all the frames in a video clip. As the model learns to identify noise, it’s also learning each frame relates to the other frames in the clip (object permanence, cause and effect, and so on).</p>
<p>I find it very cool that you can run effectively the same approach for video that you do for single images. It suggests that the fundamental mechanism here is very powerful. It also sheds some light on why the current video diffusion models (like OpenAI’s Sora or Google’s VEO) only generate clips and can’t just “keep going” like a text-based transformer model can.</p>
<p>Incidentally, audio generation works the same way, just with a big audio tensor instead of a big video tensor.</p>
<h3>Diffusion text models</h3>
<p>What about diffusion models that generate text? Text-based diffusion models are really strange, because you can’t just add noisy pixels to text in the same way that you can to images or video. The <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10909201/#sec12">main strategy</a> seems to be adding noise to the text <em>embeddings</em><sup id="fnref-3"><a href="#fn-3">3</a></sup>. At inference time, you start with a big block of pure-noise embeddings (presumably just random numbers) then denoise until it becomes actual decodable text.</p>
<p>How do you turn embeddings back into text? There’s no obvious way. If you just try and look up the “closest” token to each embedding, you often end up with gibberish. If you use a separate decoder model to translate the embeddings, that works but feels a bit like cheating - at that point your diffusion model is really just generating a plan for your real text-generation model.</p>
<h3>Summary</h3>
<ul>
<li>Diffusion models are trained to identify small amounts of noise in images, based on a caption embedding</li>
<li>That means you can start with pure noise and a user-provided caption and just keep chipping away layers of noise until you get to what the model thinks the original image should look like</li>
<li>The operating model is very different from transformers: not sequence-based, operates on previous outputs, and can in principle be sped up or stopped early</li>
<li>Video diffusion works the same way as image diffusion, but it’s harder for the model to learn because it requires tracking consistency over time</li>
<li>Text diffusion is weird because you can’t easily add noise to language, and if you convert to embeddings before adding noise it’s hard to reliably convert back</li>
</ul>
</section><p>If you liked this post, consider <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> to email updates about my new posts.</p><p>May 19, 2025<!-- -->&nbsp;│ Tags: <a href="https://www.seangoedecke.com/tags/ai/">ai</a>, <a href="https://www.seangoedecke.com/tags/explainers/">explainers</a></p><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ClawPDF – Open-Source Virtual/Network PDF Printer with OCR and Image Support (170 pts)]]></title>
            <link>https://github.com/clawsoftware/clawPDF</link>
            <guid>44029142</guid>
            <pubDate>Mon, 19 May 2025 12:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/clawsoftware/clawPDF">https://github.com/clawsoftware/clawPDF</a>, See on <a href="https://news.ycombinator.com/item?id=44029142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">clawPDF - Virtual PDF/OCR/Image (Network) Printer</h2><a id="user-content-clawpdf---virtual-pdfocrimage-network-printer" aria-label="Permalink: clawPDF - Virtual PDF/OCR/Image (Network) Printer" href="#clawpdf---virtual-pdfocrimage-network-printer"></a></p>
<p dir="auto">ClawPDF may seem like yet another Virtual PDF/OCR/Image Printer, but it actually comes packed with features that are typically found in enterprise solutions. With clawPDF, you can create documents in various formats, including PDF/A-1b, PDF/A-2b, PDF/A-3b, PDF/X, PDF/Image, OCR, SVG, PNG, JPEG, TIF, and TXT. You also have easy access to metadata and can remove it before sharing a document. In addition, you can protect your documents with a password and encrypt them with up to 256-bit AES.</p>
<p dir="auto">ClawPDF offers a scripting interface that lets you automate processes and integrate it into your application. Moreover, you can install clawPDF on a print server and print documents over the network, not just locally.</p>
<p dir="auto">ClawPDF is open-source and compatible with all major Windows client and server operating systems (x86/x64/ARM64), and it even supports multi-user environments!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download</h2><a id="user-content-download" aria-label="Permalink: Download" href="#download"></a></p>
<p dir="auto"><a href="https://github.com/clawsoftware/clawPDF/releases/download/0.9.3/clawPDF_0.9.3_setup.msi">https://github.com/clawsoftware/clawPDF/releases/download/0.9.3/clawPDF_0.9.3_setup.msi</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Print to PDF, PDF/A-1b, PDF/A-2b, PDF/A-3b, PDF/X, PDF/Image, OCR, SVG, PNG, JPEG, TIF and TXT</li>
<li>Print 100% valid <a href="https://github.com/clawsoftware/clawPDF/raw/master/docs/pdfa_valid/PDFA-1b.pdf">PDF/A-1b</a>, <a href="https://github.com/clawsoftware/clawPDF/raw/master/docs/pdfa_valid/PDFA-2b.pdf">PDF/A-2b</a> and <a href="https://github.com/clawsoftware/clawPDF/raw/master/docs/pdfa_valid/PDFA-3b.pdf">PDF/A-3b</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Optical-Character-Recognition-(OCR)">Optical Character Recognition (OCR)</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Scripting-Interface">Scripting Interface (Python, Powershell, VBScript...)</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Install-as-Network-Printer">Shared Network Printing</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/SVG-Export">SVG Export</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Drag-and-Drop">Drag and Drop Support</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Merge-Files">Merge Files</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Command-Line-Commands">Command Line Support</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Silent-Printing">Silent Printing</a></li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/(Custom)-Paper-Sizes">Custom Paper Sizes / Standard Paper Sizes</a></li>
<li>256-bit AES encryption</li>
<li>Light/Dark Theme</li>
<li>ARM64 Support</li>
<li>Full Unicode Support</li>
<li>Multiple Profiles</li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Post-Actions">Post Actions</a></li>
<li>Create additional printers with assigned profile</li>
<li><a href="https://github.com/clawsoftware/clawPDF/wiki/Translations">24 translations. Add yours!</a></li>
<li>Easy to deploy (MSI-Installer &amp; Config)</li>
<li>Many settings</li>
<li>Easy to use</li>
<li>No adware, spyware and nagware</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Optical Character Recognition (OCR)</h2><a id="user-content-optical-character-recognition-ocr" aria-label="Permalink: Optical Character Recognition (OCR)" href="#optical-character-recognition-ocr"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/clawsoftware/clawPDF/blob/master/docs/images/ImageOCR.gif?raw=true"><img src="https://github.com/clawsoftware/clawPDF/raw/master/docs/images/ImageOCR.gif?raw=true" alt="OCR" title="OCR" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/clawsoftware/clawPDF/blob/master/docs/com_examples/Powershell/CreatePDFwithPassword.ps1">Scripting Interface</a></h2><a id="user-content-scripting-interface" aria-label="Permalink: Scripting Interface" href="#scripting-interface"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/clawsoftware/clawPDF/blob/master/docs/images/ScriptingInterface.gif?raw=true"><img src="https://github.com/clawsoftware/clawPDF/raw/master/docs/images/ScriptingInterface.gif?raw=true" alt="ScriptingInterface" title="Scripting Interface" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Print a PDF and protect it with a password</h2><a id="user-content-print-a-pdf-and-protect-it-with-a-password" aria-label="Permalink: Print a PDF and protect it with a password" href="#print-a-pdf-and-protect-it-with-a-password"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/clawsoftware/clawPDF/blob/master/docs/images/PrintPDFwithPassword.gif?raw=true"><img src="https://github.com/clawsoftware/clawPDF/raw/master/docs/images/PrintPDFwithPassword.gif?raw=true" alt="PrintPDFwithPassword" title="PrintPDFwithPassword" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Merge multiple documents</h2><a id="user-content-merge-multiple-documents" aria-label="Permalink: Merge multiple documents" href="#merge-multiple-documents"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/clawsoftware/clawPDF/blob/master/docs/images/MergeFiles.gif?raw=true"><img src="https://github.com/clawsoftware/clawPDF/raw/master/docs/images/MergeFiles.gif?raw=true" alt="Merge" title="Merge" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tested under</h2><a id="user-content-tested-under" aria-label="Permalink: Tested under" href="#tested-under"></a></p>
<ul dir="auto">
<li>Windows Server 2022 RDS</li>
<li>Windows Server 2019 RDS</li>
<li>Windows Server 2016 RDS</li>
<li>Windows 11 x64/ARM64</li>
<li>Windows 10 x86/x64/ARM64</li>
<li>Windows 8 x86/x64</li>
<li>Windows 7 x86/x64</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Command Line</h2><a id="user-content-command-line" aria-label="Permalink: Command Line" href="#command-line"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Batch Printing</h2><a id="user-content-batch-printing" aria-label="Permalink: Batch Printing" href="#batch-printing"></a></p>
<div data-snippet-clipboard-copy-content="The GUID for the Profile parameter is located under: HKEY_CURRENT_USER\Software\clawSoft\clawPDF\Settings\ConversionProfiles\[id]\Guid

clawPDF.exe /PrintFile=D:\example.docx /profile=f81ea998-3a76-4104-a574-9a66d6f3039b
clawPDF.exe /PrintFile=D:\example.pdf /profile=JpegGuid
clawPDF.exe /PrintFile=D:\example.pdf /profile=JpegGuid /OutputPath=D:\batchjob

clawPDF.exe /PrintFile=D:\example.txt /printerName=clawPDF2
clawPDF.exe /PrintFile=D:\example.docx /printerName=clawJPG"><pre><code>The GUID for the Profile parameter is located under: HKEY_CURRENT_USER\Software\clawSoft\clawPDF\Settings\ConversionProfiles\[id]\Guid

clawPDF.exe /PrintFile=D:\example.docx /profile=f81ea998-3a76-4104-a574-9a66d6f3039b
clawPDF.exe /PrintFile=D:\example.pdf /profile=JpegGuid
clawPDF.exe /PrintFile=D:\example.pdf /profile=JpegGuid /OutputPath=D:\batchjob

clawPDF.exe /PrintFile=D:\example.txt /printerName=clawPDF2
clawPDF.exe /PrintFile=D:\example.docx /printerName=clawJPG
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overwrite Config</h2><a id="user-content-overwrite-config" aria-label="Permalink: Overwrite Config" href="#overwrite-config"></a></p>
<div data-snippet-clipboard-copy-content="- To deploy a default configuration in an enterprise environment.
- To export a configuration select &quot;Application Settings -> Debug -> Save settings to file&quot;.

clawPDF.exe /Config=D:\clawPDF.ini"><pre><code>- To deploy a default configuration in an enterprise environment.
- To export a configuration select "Application Settings -&gt; Debug -&gt; Save settings to file".

clawPDF.exe /Config=D:\clawPDF.ini
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Printer Managment</h2><a id="user-content-printer-managment" aria-label="Permalink: Printer Managment" href="#printer-managment"></a></p>
<div data-snippet-clipboard-copy-content="SetupHelper.exe /Printer=Add /Name=ExamplePrinter
SetupHelper.exe /Printer=Remove /Name=ExamplePrinter"><pre><code>SetupHelper.exe /Printer=Add /Name=ExamplePrinter
SetupHelper.exe /Printer=Remove /Name=ExamplePrinter
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ManagePrintJobs</h2><a id="user-content-manageprintjobs" aria-label="Permalink: ManagePrintJobs" href="#manageprintjobs"></a></p>
<div data-snippet-clipboard-copy-content="clawPDF.exe /ManagePrintJobs"><pre><code>clawPDF.exe /ManagePrintJobs
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Changelog</h2><a id="user-content-changelog" aria-label="Permalink: Changelog" href="#changelog"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v0.9.3 (2023.05.16)</h2><a id="user-content-v093-20230516" aria-label="Permalink: v0.9.3 (2023.05.16)" href="#v093-20230516"></a></p>
<ul dir="auto">
<li>[bugfix] Fixed a bug where in some cases only administrators could use the shared network printer function</li>
<li>[bugfix] Fixed Windows 7 issues caused since version 0.9.1</li>
</ul>
<p dir="auto"><a href="https://github.com/clawsoftware/clawPDF/wiki/Changelog">more</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>.Net Framework 4.6.2+</li>
<li><a href="https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist#visual-studio-2015-2017-2019-and-2022" rel="nofollow">Visual C++ Redistributable 14</a> (Download: <a href="https://aka.ms/vs/17/release/vc_redist.x86.exe" rel="nofollow">x86</a>/<a href="https://aka.ms/vs/17/release/vc_redist.x64.exe" rel="nofollow">x64</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build</h2><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<ul dir="auto">
<li>Visual Studio 2022</li>
</ul>
<p dir="auto"><a href="https://github.com/clawsoftware/clawPDF/wiki/Build-it-yourself">more</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Third-party</h2><a id="user-content-third-party" aria-label="Permalink: Third-party" href="#third-party"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">clawPDF uses the following licensed software or parts of the source code:</h2><a id="user-content-clawpdf-uses-the-following-licensed-software-or-parts-of-the-source-code" aria-label="Permalink: clawPDF uses the following licensed software or parts of the source code:" href="#clawpdf-uses-the-following-licensed-software-or-parts-of-the-source-code"></a></p>
<ul dir="auto">
<li>PDFCreator (<a href="https://github.com/pdfforge/PDFCreator">https://github.com/pdfforge/PDFCreator</a>), licensed under AGPL v3 license.</li>
<li>Pdftosvg.net (<a href="https://github.com/dmester/pdftosvg.net">https://github.com/dmester/pdftosvg.net</a>), licensed under MIT license.</li>
<li>iText7 (<a href="https://github.com/itext/itext7-dotnet">https://github.com/itext/itext7-dotnet</a>), licensed under AGPL v3 license.</li>
<li>Nlog (<a href="https://github.com/NLog/NLog">https://github.com/NLog/NLog</a>), licensed under BSD 3-Clause.</li>
<li>PdfScribe (<a href="https://github.com/stchan/PdfScribe">https://github.com/stchan/PdfScribe</a>), licensed under AGPL v3 license.</li>
<li>clawmon (<a href="https://github.com/clawsoftware/clawPDF/tree/master/src/clawmon">https://github.com/clawsoftware/clawPDF/tree/master/src/clawmon</a>), licensed under GPL v2 license.</li>
<li>Microsoft Postscript Printer Driver (<a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/print/microsoft-postscript-printer-driver" rel="nofollow">https://docs.microsoft.com/en-us/windows-hardware/drivers/print/microsoft-postscript-printer-driver</a>), copyright (c) Microsoft Corporation. All rights reserved.</li>
<li>Ghostscript (<a href="https://www.ghostscript.com/download/gsdnld.html" rel="nofollow">https://www.ghostscript.com/download/gsdnld.html</a>), licensed under AGPL v3 license.</li>
<li>SystemWrapper (<a href="https://github.com/jozefizso/SystemWrapper">https://github.com/jozefizso/SystemWrapper</a>), licensed under Microsoft Public license.</li>
<li>Ftplib (<a href="https://archive.codeplex.com/?p=ftplib" rel="nofollow">https://archive.codeplex.com/?p=ftplib</a>), licensed under MIT license.</li>
<li>DataStorage.dll, licensed under pdfforge Freeware License.</li>
<li>DynamicTranslator.dll, licensed under pdfforge Freeware License.</li>
<li>Appbar_save (<a href="http://modernuiicons.com/" rel="nofollow">http://modernuiicons.com/</a>), licensed under Attribution-NoDerivs 3.0 Unported.</li>
<li>Appbar_cogs (<a href="http://modernuiicons.com/" rel="nofollow">http://modernuiicons.com/</a>), licensed under Attribution-NoDerivs 3.0 Unported.</li>
<li>Appbar_page_file_pdf (<a href="http://modernuiicons.com/" rel="nofollow">http://modernuiicons.com/</a>), licensed under Attribution-NoDerivs 3.0 Unported.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">clawPDF is licensed under AGPL v3 license<br>
Copyright (C) 2023 // Andrew Hess // clawSoft</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Winter Coming? (2024) (114 pts)]]></title>
            <link>https://www.datagubbe.se/winter/</link>
            <guid>44028384</guid>
            <pubDate>Mon, 19 May 2025 10:50:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.datagubbe.se/winter/">https://www.datagubbe.se/winter/</a>, See on <a href="https://news.ycombinator.com/item?id=44028384">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h2>Is Winter Coming?</h2>

<p><b>Thoughts on articifial intelligence and lofty expectations.</b></p>
<p><i>Spring 2024</i></p>

<p>
In the 1960s, AI researchers tried - and failed - to deliver machine translation of Russian to English. Overly confident researchers, lazy journalists and far too optimistic tech utopianists all built expectations that couldn't be met. Eventually, the lack of results put a stop to the previously generous funding. The project was halted and interest in AI faltered. This was the first "AI winter".
</p>

<p>
Much more recently, a colleague of mine wanted to show some photos he'd taken of a huge peanut spill on a countryside road. A truck carrying a large amount of peanuts had apparently encountered some malfunction, dumped its cargo, and left it there for grabs. He tried searching his smartphone photo library for "peanuts", but no images materialized. I suggested to instead try searching for "pebbles" and, lo and behold, we were immediately met with pictures of a sea of peanuts.
</p>

<p>
The image recognition feature on smartphones is one of the things that now fall under the "AI" umbrella: a piece of software trained on a very large number of photos in order to classify and recognize what they depict. The problem is that even in a very large selection of photos, seas of peanuts are extremely rare. To find a photo of one, a human must step in and do something AI software is so far incapable of: knowing how the software was trained and use that knowledge creatively - such as coming up with the visual similarity between peanuts and pebbles. This practice is called <i>prompt engineering</i>.
</p>

<p>
Prompt engineering is not only a rather silly name, it's also a paradoxical practice in the world of AI. The whole selling point of the latest AI hype is to make computers behave more like humans. It's what end users expect, and it's what all the major players are using to drive the current hype. Type in (or speak!) a question in normal conversational English and get an answer back that reads (or speaks!) in a similar style. Ask it to find pictures of flowers, and pictures of flowers is what you get.
</p>

<p>
The need for prompt engineering, on the other hand, puts us back on square one of computer use: the pesky old conundrum of a human user having to think like a computer, instead of the other way around.
</p>

<p>
<b>***</b>
</p>

<p>
<img src="https://www.datagubbe.se/winter/lemonsoap2.jpg" alt="Soap in the shape of lemons.">
<br>
<i>Is it lemons? Is it soap in the shape of lemons? Is it lemons
in a net for soap in the shape of lemons? The household robot
doesn't know. Therefore, it screams.</i>
</p>

<p>
It's not that AI, in the broadest sense, isn't already useful. A lot has happened since the 1960s, especially regarding hardware. Faster and cheaper machines can run more complex software and process much bigger data sets. We're now at a point when machine translation is prevalent. It might not be perfect, but it's often good enough and - just like smartphone image search - often better than nothing.
</p>

<p>
Image recognition isn't necessarily something to scoff at either, when applied correctly. If it can help human doctors detect certain diseases with improved speed and accuracy, it's already a great tool. The cost of developing and running it is then also easily outweighed by saving lives. The problem is that public perception tends to treat such extremely narrow use cases a bit like it treats computers playing chess.
</p>

<p>
A modern <a href="https://en.wikipedia.org/wiki/Stockfish_(chess)">chess engine</a> can easily outplay even the top ranked chess players of the world. It can be useful for practice and even developing new styles of play, but using one in a chess tournament is considered cheating. Such use is considered  cheating for the same reason it's also considered uninteresting: <i>Humans want to watch human feats</i>. To most people these days, a computer playing chess comes off as an extremely computery activity. Everyone understands that chess is a closed - albeit complex - system. Everyone also realizes that a modern computer can make deeper, faster and better predictions than any human is capable of. It isn't interesting, impressive or entertaining - at least not the same way a 12 year old human chess prodigy is.
</p>

<p>
A computer that can detect a certain type of disease is of course more interesting and beneficial than a highly competent chess engine, and is going to be accepted by the vast majority of humanity as something good. It's not cheating, it's helping. Yet, it's not much to hang a bunch of hype on: Like with a chess engine, or halfway decent machine translation, it's simply a computer finally doing one of the many things we've always been told they should be able to. A one trick pony, basically just another piece of medical software, more like Word or Excel than a thinking machine.
</p>

<p>
<b>***</b>
</p>

<p>
Thinking machines are, after all, not just what the words "artificial intelligence" mean to most of us. It's also what the big companies in the field are currently selling: Software that can't merely communicate in a human-like way, but also ostensibly <i>act</i> human-like - except smarter, more knowledgeable. Thus, the general expectation is that AI implies, at the very least, software that <i>consistently and reliably outperforms a human expert</i> at any task in any given field it claims to be proficient in. Failing that, it should at least be aware of its limits, letting the user know if a certain question can't be answered or a certain task can't be performed satisfactorily.
</p>

<p>
The problem is that so far, we've only managed the  human-like communication part, and even that is still a bit iffy at times - ideally, it shouldn't require curious prompt engineering in order to produce high quality results. The other half remains riddled with ineptitudes, the biggest being so called hallucinations. Hallucinations are when a Large Language Model - currently the popular definition of an AI system - confidently presents falsehoods or utter confabulation as facts. LLMs do this because they cannot think, or know things, and thus cannot discern true from false, and thus can't stop themselves from blurting out stupid or downright dangerous answers. Whether or not this behavior can be completely mitigated or not is dubious at best: At their core, what LLMs do is string together words in a statistically highly probable manner. It's not just about "junk in, junk out" - which remains a problem because of the sheer size of the data sets used to train them - but also about completely eliminating the risk of anomalies, <i>ensuring the model can somehow determine if it's generated one</i>.
</p>

<p>
<b>***</b>
</p>

<p>
OpenAI's ChatGPT is one of the most well known LLM offerings right now, and the company itself is backed by some very wealthy investors, including Microsoft. They're also very good at creating hype. Though they've had their fair share of controversy, they're still treated amicably by the press, who dutifully help them feed said hype when launching a new version of their tech.
</p>

<p>
This hype initially made a lot of people very enthusiastic about LLMs - including yours truly. Some of this enthusiasm can be ascribed to misunderstanding the technology in question - but both academical communication and corporate marketing surrounding these products is to a large degree what's been feeding misunderstandings and unrealistically bolstering expectations.
</p>

<p>
The megacorps behind most of this tech, and a small but vocal group of so called tech bros, are very good at maintaining image. Minor improvements generate major excitement, while complete failures are swiftly forgotten. OpenAI recently demonstrated their newest ChatGPT, version 4o, talking to the user in a very human voice from an iPhone. Whether or not the model still hallucinates freely and confidently presents falsehoods as fact was, of course, not mentioned in the demo. The damn thing adviced some dude not to wear a silly hat to a job interview, so Shut Up and Sit Down: the Future is finally here! 
</p>

<p>
Meanwhile, blatant failures such as Meta's Galactica, the science LLM that immediately after launch hallucinated its way out of any kind of usefulness, are quickly swept under the rug. The fact that such a model was launched at all hint at either a sunk cost fallacy in play - or just people believing their own hype. Neither option is a sign of sound business practices and surefire investment opportunities.
</p>

<p>
<b>***</b>
</p>


<p>
It seems that reality is finally catching up with the hype, and the enthusiasm is predictably starting to fade. More than one lawyer has used ChatGPT in their job only to end up in serious trouble, having to answer for erroneous citations and hallucinated court cases. The instinctive reaction might be to make fun of said lawyers, but in this case some reflection might be pertinent. Was it stupid of them to trust ChatGPT? Yes, of course. And who, if not a lawyer, should study the fine print of a product before using it? Still, this behavior reflects what a lot of people expect of AI: <i>What's an LLM good for if it can't even get a simple case citation right?</i> This feels like a basic minimum considering the hype. It doesn't even require reasoning or creativity, it simply requires correct regurgitation of well documented facts.
</p>

<p>
Even among tech-savvy people, the hype is - or at least was - strong. Not that long ago it was commonplace for conversations with intelligent, successful people working hands-on with IT to completely veer off into AI fantasy land. Wild ideas about how an LLM could supposedly extrapolate a successful corporate budget <i>and</i> strategy based on nothing but a handful of isolated KPIs apparently seemed completely reasonable. Or, based on the same handful of KPIs, an LLM could perhaps write an entire annual financial report, ready for print? Suggestions like these have become noticeably less prevalent in merely a year's time.
</p>

<p>
The truth is that as of yet, LLMs aren't even remotely close to this. In fact, they can't even reliably summarize a text, because they might miss a single piece of vital information hiding in there. Anything coming out of an LLM that's going to be used in any context of importance must be thoroughly double checked by a human. Congratulations: the manual workload now consists of scrutinizing not one, but two bodies of text!
</p>

<p>
Despite this, an LLM can, <i>maybe</i>, be <i>somewhat</i> useful <i>some</i> of the time. Take programming for example. We're still quite far from "no code" development, where an ideas man typing up a few requests in a prompt is all that's required for an AI to churn out a working piece of software. We're even quite far from reliable and consistent code generation even for rather simple cases.
</p>

<p>
However, for common tasks in common frameworks written in common languages, an LLM can produce boilerplate code which can then be corrected and expanded by a programmer. Or, for certain tasks, it can generate code in a language unfamiliar to an otherwise skilled developer, who can then test and correct it using some human know-how and creativity.
</p>

<p>
On the flip side, for example when working with a 20-odd year old legacy code base, an LLM is less useful. The same goes for reliably finding bugs, backtracking previous decisions or even understanding and modifying already existing code. Or how about <i>motivating</i> a decision - for example explaining why something can't be done to the human requesting it?
</p>

<p>
The same can be said about image generation, machine translation and even medical applications. For highly specific use cases, a human professional can be somewhat helped. In even more specific cases, a human could perhaps be entirely replaced - such as for churning out covers for dime-a-dozen sci-fi novels. In all other cases, it's little more than a fun novelty that will repeatedly and predictably make up nonsense, screw up basic human anatomy or mistranslate crucial, domain-specific words. We can, as of yet, not place our trust in a perfect and infallible machine.
</p>

<p>
This also applies to self-driving cars. Driverless vehicles in closed systems have been in use for a long time. The <a href="https://en.wikipedia.org/wiki/Copenhagen_Metro">Copenhagen Metro</a>, for example, has been in operation since 2002 - but like a chess engine, it isn't "AI": it's simply "automated". Currently available software may very well make human drivers both more comfortable and safe, but the hype has promised completely autonomous cars reliably zipping about in rush hour traffic.
</p>

<p>
Much like hallucination free LLMs, this has been "just around the corner" for quite some time now. In reality, the software is still unable to recognize the many types of confusing situations that appear in everyday traffic and, more importantly, lacks the ability to improvise accordingly. In its present state it can be helpful for certain tasks, but only under constant human supervision.
</p>

<p>
<b>***</b>
</p>

<p>
Recently, I wanted to change the start page in Microsoft's Edge browser from their bloated Bing monstrosity to a completely blank page. I searched Bing for an answer but couldn't find one. I then decided to try out the chatbot, as suggested to me by Bing itself. The result was utterly and unequivocally farcical: the bot simply answered with a somewhat rehashed version of the top search hit. When pointing out that the answer mentioned nonexistent menu options and settings, the bot simply apologized and presented a rephrased version of the next search hit, which was equally useless.
</p>

<p>
As a professional programmer with extensive knowledge about computers and software, I can understand why this happens. As an end user, it's both baffling and disappointing: Microsoft's own chatbot running on Microsoft's own site in Microsoft's own browser can't answer a simple question about how to configure that very same browser. It wasn't even "better than nothing": it was a worthless waste of time and effort, making "good enough" seem like a bad joke. If it didn't know, or if the setting doesn't exist, why didn't it say so? And if there is a setting, why couldn't it just fix it for me? Surely a Microsoft AI should know how to safely and correctly
 operate one of Microsoft's own flagship products.
</p>

<p>
Proponents of the current hype will of course say that problems like these can and will be corrected. With big enough data sets and extensive enough reinforcement training, hallucinations and wild goose chases will disappear. Or, at the very least, we'll somehow get models that can say "I don't know" instead of spewing out garbage.
</p>

<p>
Personally, I'm not convinced - but let's be generous and imagine it's achievable. What would that look like?
</p>

<p>
If public confidence in self-driving cars is ever going to match the hype, these cars must perform <i>flawlessly</i>. They can't just be as good as the average human driver. Their mistakes must be so rare and benign that they're completely statistically insignificant, and their performance must be reliable in freak weather conditions and on subpar roads. And even then, the problem of accountability must be resolved satisfactorily when it comes to things like insurance and court mandated victim recompense.
</p>

<p>
If we're going to be able to use LLMs to replace certain professions, they must at 
the 
very least match the average human, yielding consistent, reliable and reproducible results while making fewer and less costly mistakes. And, they should of course be capable of this <i>without extensive and tedious prompt engineering</i>. The question of responsibility and liability is a pressing one here, too.
</p>

<p>
<b>***</b>
</p>

<p>
A third category is one where chatbots, despite their flaws, are already replacing humans. Indeed, customer support seems like a perfect fit for AI: it has already, very aptly, been a dystopian nightmare for ages. Interactive voice response, rigid troubleshooting flowcharts, scripted replies, zero agency or lenience and abysmal working conditions. Who cares if the LLM fails to deliver? The prevalent notion already seems to be that if the complaint falls outside the top three, no procedure exists to handle it. The customer then becomes a sworn enemy - albeit an enemy legally required to keep paying for the duration of the contract.
</p>

<p>
Half-joking aside, will a "digital customer assistant" that sometimes barfs out 
false 
or even dangerous answers ensure smooth and profitable corporate operations? 
Is it cheap enough that the tradeoff, in the long run, is worth it compared to other tech and staffing options? And, most importantly, is crappy customer support really the product AI companies are selling to investors and consumers?
</p>

<p>
<img src="https://www.datagubbe.se/winter/nostripes2.jpg" alt="A screenshot of a Microsoft Copilot query asking for a shirt with no stripes. The top result describes a no-iron shirt with stripes."><br>
<i>A shirt <a href="https://github.com/elsamuko/Shirt-without-Stripes">with no stripes</a>, you say?</i>
</p>

<p>
Even when it comes to something like LLM-assisted programming, where a highly skilled developer can <i>maybe, sometimes, somewhat</i> gain a performance boost, the most pertinent question isn't if it can be done at all - but rather if what can be done <i>good enough</i> can also be done <i>profitably</i>. The number of GPUs and the amount of increasingly expensive energy required remains as unclear as the time frame needed to accomplish it.
</p>

<p>
Still, the hypemeisters are unable to stop dropping thinly veiled hints about artificial general intelligence - "thinking machines" - from time to time. Any day now! And that last LLM that couldn't really do what we said it could? That wasn't real AI. This time though, it is. Honestly. Promise. Sort of. Thus, for every new LLM version, user disappointment with the AI hype seems to increase.
</p>

<p>
And let's not even get started on intellectual property in training sets, 
copyright and ownership of generated content, and liability for erroneous 
information or conduct. These are areas corporate lawyers just can't wait to sink 
their teeth into, given the opportunity. Who wouldn't want to get drawn into a 
big, juicy lawsuit with Disney or IBM over what constitutes fair use or patented 
code? Trust me, investors and execs <i>live</i> for that shit!
</p>

<p>
<b>***</b>
</p>

<p>
Things are looking rather bleak for the tech business as a whole right now. The economy no longer allows for zero interest loans or pouring endless streams of capital into vague promises of "real soon now". AI seems to be the last bastion of this practice: OpenAI, for example, were recently praised for their record growth in revenue and received substantial injections of capital.
</p>

<p>
But we can only pretend for so long that revenue right now says anything at all about profit in the future. There's still no indication of whether a reliable AI will cater to a broad enough customer base, be cheap enough to use and remain lucrative enough to stand on its own two proverbial robot feet.
</p>

<p>
I may, of course, be completely wrong. Perhaps we'll all soon be replaced by a handful of very small shell scripts interfacing with a distant AI's API. But, deservedly or not, it seems more likely to me that winter is coming.
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Telum II at Hot Chips 2024: Mainframe with a Unique Caching Strategy (116 pts)]]></title>
            <link>https://chipsandcheese.com/p/telum-ii-at-hot-chips-2024-mainframe-with-a-unique-caching-strategy</link>
            <guid>44028250</guid>
            <pubDate>Mon, 19 May 2025 10:27:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/telum-ii-at-hot-chips-2024-mainframe-with-a-unique-caching-strategy">https://chipsandcheese.com/p/telum-ii-at-hot-chips-2024-mainframe-with-a-unique-caching-strategy</a>, See on <a href="https://news.ycombinator.com/item?id=44028250">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Mainframes still play a vital role in today, providing extremely high uptime and low latency for financial transactions. Telum II is IBM’s latest mainframe processor, and is designed unlike any other server CPU. It only has eight cores, but runs them at a very high 5.5 GHz and feeds them with 360 MB of on-chip cache. IBM also includes a DPU for accelerating IO, along with an on-board AI accelerator. Telum II is implemented on Samsung’s leading edge 5 nm process node.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31708" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg" width="688" height="359" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:359,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31708&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcde2001f-57f5-4d61-bb2f-e8c311271b25_1915x1000.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>IBM’s presentation has already been covered by other outlets. Therefore I’ll focus on what I feel like is Telum (II)’s most interesting features. DRAM latency and bandwidth limitations often mean good caching is critical to performance, and IBM has a often deployed interesting caching solutions. Telum II is no exception, carrying forward a virtual L3 and virtual L4 strategy from prior IBM chips.</p><p>Telum II has ten 36 MB L2 on-chip, which is absolutely huge. For perspective, the L3 cache on AMD’s Zen 3 desktop and server CPUs is typically 32 MB. Eight of Telum II’s L2 caches areare attached to cores, another is attached to the DPU, and a final tenth one isn’t attached to anything. Another comparison is Qualcomm’s Oryon core in the Snapdragon X Elite, which has a 12 MB L2 cache with 5.29 ns of latency. Qualcomm considers a tightly coupled high capacity cache. Telum II has 3.6 ns of L2 latency, and more capacity to boot.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31710" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg" width="688" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31710&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5a7c6e-4dd8-4332-9713-f344d5d4349c_1530x857.jpeg 1456w" sizes="100vw"></picture></div></a><figcaption>Qualcomm’s Oryon has 5.28 ns of L2 latency</figcaption></figure></div><p>These giant L2s are great for cutting down memory access latency, but put Telum II in a funny position. Modern CPUs typically have a large cache shared across multiple cores. A shared cache can give a single thread more capacity in low-threaded loads, and reduce duplication for shared data in multithreaded loads. But eight cores in Telum II would already use 288 MB of SRAM capacity, along with the associated area and power cost. An even larger L3 would be expensive even for a specialized mainframe chip.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31734" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png" width="682" height="421" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9bfdde09-3abc-432f-9735-57961edb0738_682x421.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:421,&quot;width&quot;:682,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31734&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bfdde09-3abc-432f-9735-57961edb0738_682x421.png 1456w" sizes="100vw"></picture></div></a><figcaption>Green = L2, Red = L3</figcaption></figure></div><p><span>IBM’s solution is to reduce data duplication within its caches, and re-use the chip’s massive L2 capacity to create a virtual L3 cache. From </span><a href="https://trea.com/information/lateral-persistence-directory-states/patentapplication/d5bbb189-7bfe-48fc-98e6-04461950f4fe" rel="">IBM’s patent</a><span>, each L2 has a “Saturation Metric” based on how often its core brings data into it (to satisfy misses). When a L2 kicks out a cache line to make room for incoming data, that evicted line goes another L2 with a lower Saturation Metric. That way, a core already pushing the limits of its own L2 capacity can keep that capacity to itself. The L2 slice without an attached core always has the lowest possible Saturation Metric, making it a preferred destination for lines evicted out of L2. If another L2 already has a copy if the evicted line, Telum II gives that L2 ownership of the line instead of putting it into virtual L3, also reducing data duplication.</span></p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31735" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png" width="682" height="528" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:528,&quot;width&quot;:682,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31735&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2bf3a6-7ac3-4871-8eeb-b8ae3edf45ed_682x528.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Green = L2, Red = Virtual L3 (Lines evicted from L2 persisted in other L2s)</figcaption></figure></div><p>Tracking Saturation Metrics isn’t the only way IBM keeps the virtual L3 from monopolizing L2 capacity. IBM’s patent also mentions inserting virtual L3 lines into intermediate LRU positions. Replacement strategy is how a cache chooses a line to kick out when a new line is brought in. LRU stands for Least Recently Used, and is a replacement policy where the least recently used line gets kicked out. Normally, a newly inserted line gets put into the MRU (most recently used) position, putting it last in line to get replaced. But virtual L3 lines can get put into intermediate positions, giving priority to L2 lines brought in by the core.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/virtual_l3_lru/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png" width="649" height="493" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:493,&quot;width&quot;:649,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/virtual_l3_lru/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70af48a7-82d9-43f4-8c9d-cd86d5e0c335_649x493.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Using intermediate positions also lets IBM control how much L2 capacity the virtual L3 can use. For example, putting virtual L3 fills halfway between the LRU and MRU positions would limit the virtual L3 to using half of L2 capacity. It’s easy to see how IBM can use this to elegantly adapt to changing application demands. If one core goes idle, its L2 could start inserting virtual L3 fills at the LRU position, letting the virtual L3 use all available capacity in that slice.</p><p>Besides making L2 capacity doesn’t get squished out, the virtual L3 faces another challenge. A line in the virtual L3 could be in any of Telum II’s ten L2 slices. In AMD, Arm, and Intel’s L3 caches, an address always goes to the same slice. A core can look at a subset of an address’s bits, and knows exactly which L3 slice to send a request to. That’s not the case for IBM. Apparently IBM handles this by potentially checking all L2 slices for a virtual L3 access. I asked if they were worried about overhead from more tag comparisons, but they said it wasn’t an issue because L2 miss rate was low. It’s important to remember that engineers try to keep a CPU design balanced, rather than pouring resources into making sure it’s great at every last thing. A Telum II core can use up to 36 MB of L2 capacity. Other factors being equal, it should miss L2 less often than a Zen 5 core misses in its 32 MB L3. A L3 access on Zen 5 may cost less power, but AMD needs that to be the case because Zen 5 cores have an order of magnitude less L2 capacity than Telum II’s cores.</p><p>IBM’s mainframe chips aren’t deployed in isolation. Up to 32 Telum II processors can be connected to form a large shared memory system. Again, IBM is looking at a lot of cache capacity, this time across a system instead of a single Telum II chip. And again, they applied the same virtual cache concept. Telum II creates a 2.8 GB virtual L4 by sending L3 victims to other Telum II chips with spare cache capacity.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31848" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png" width="558" height="342" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3d18db49-3764-42e6-968c-c010c4719043_558x342.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:342,&quot;width&quot;:558,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31848&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d18db49-3764-42e6-968c-c010c4719043_558x342.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A CPC (Central Processor Complex) Drawer on the prior Z16/Telum</figcaption></figure></div><p>I’m not sure how IBM implemented the virtual L4, but prior IBM mainframe designs might provide some clues. IBM organizes mainframe CPUs into CPC drawers, which somewhat resemble a rack-mount servers. A CPC can’t operate independently like a server because it doesn’t include non-volatile storage or a power supply unit, but it does place a set of CPUs and DRAM in close physical proximity. Prior IBM designs had a drawer-wide L4, and Telum II might do the same. 2.8 GB of L4 aligns with on-chip cache capacity across eight Telum II chips. If a drawer has eight Telum II dies, just as a Z16 drawer had eight Telum dies, then IBM could be persisting L3 victims across a drawer.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31849" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg" width="688" height="429" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:429,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31849&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3695fa19-a6ea-4c34-ab03-2217b3860fa7_954x595.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Go back another generation, and z15 has a System Controller (SC) chip with a huge 960 MB L4 shared across a drawer</figcaption></figure></div><p>IBM claims 48.5 ns of latency for a virtual L4 access. Achieving that across drawer boundaries would be quite a challenge. As ambitious as Telum II is, I think that would be a bridge too far. On the latency subject, IBM’s likely betting that L3 misses are rare enough that 48.5 ns of L4 latency isn’t a big deal. IBM also deserves a lot of credit for getting latency to be so low when crossing die boundaries. For perspective, Nvidia’s Grace superchip has over 42 ns of L3 latency with a monolithic die.</p><p>When talking about Telum II’s caching strategy, it’s impossible to ignore the original Telum/Z16. That’s where IBM brought virtual L3 and L4 caches into their mainframe line. Telum was presented at last year’s Hot Chips 2023. Since then, IBM has published more info on how Telum’s virtual L3/L4 setup worked. It’s a fairly simple scheme where each 32 MB L2 slice is split into two 16 MB segments. One segments can become part of the virtual L3/L4 if a core doesn’t need all of its L2 capacity. If the core is idle, all 32 MB can go towards the virtual L3/L4.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31855" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg" width="688" height="386" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:386,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31855&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84875f56-73ff-449e-bc01-5bc93f7d1e25_1587x891.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>IBM’s technical overview furthermore clarifies that the virtual L4 is implemented across a drawer. A Z16 drawer has eight Telum chips, each with 256 MB of L2 capacity. A single threaded workload running on a drawer gets its own 32 MB L2. All the other on-die L2 caches become that thread’s 224 MB L3, and other L2 caches within the drawer combine to form a 1.75 GB virtual L4.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31857" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png" width="688" height="387" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:387,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31857&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F08be9dea-3aa4-4027-aa67-329d075b2200_1593x895.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Telum II takes that strategy further, with higher cache capacity at L2, virtual L3, and virtual L4. When I asked how Telum II handled its virtual L3 after Cheese did his interview, they mentioned congruence classes. I had no clue what a congruence class was. IBM after all uses different terminology that I wasn’t familiar with, and it took quite some searching to figure out that a congruence class was basically a cache set.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png" width="1053" height="462" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:462,&quot;width&quot;:1053,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:71282,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f342eb-bb6a-4719-a1ec-02c0553597ad_1053x462.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Funny enough, I asked why IBM had different terminology compared to the rest of the industry. They said IBM came up with the terminology first, and later on the industry adopted different terminology. It was all lighthearted and funny. But it’s also a reminder that IBM was a pioneering company in developing high performance CPUs.</p><p>CPU designers have to strike a balance between single and multithreaded performance. Server CPUs tend to focus on the latter, while client designs do the opposite. Telum II and prior IBM mainframe chips handle server tasks like financial transactions, but curiously seem to prioritize single threaded performance. IBM has actually decreased core counts per die from 12 in Z15 to 8 in Telum and Telum II. The focus on single threaded performance is very visible in IBM’s caching strategy as well. A single thread running on Telum II can enjoy client-like L2 and L3 access latencies, but with an order of magnitude more capacity at each level.</p><p>I wonder if IBM’s strategies can be applicable to client designs. AMD’s highest end CPUs notably have a lot of L3 cache capacity on the chip. For example, the Ryzen 9 9950X has 32 MB of L3 and 8 MB of L2 per CCD. Both CCDs together would give 64 MB of L3 and 16 MB of L2, for 80 MB of total caching capacity. If all that could be used for a single thread, it’s not far off from the 96 MB of L3 cache that a VCache part gets. A hypothetical dual CCD part with VCache on both dies could have over 200 MB of virtual L3 capacity.</p><p>Of course, pulling that off isn’t so straightforward. IBM’s mainframe chips use very fast cross-die interconnects. A Zen 5 CCD’s Infinity Fabric link only provides 64 GB/s and 32 GB/s of read and write bandwidth, respectively. IBM’s prior generation Telum already has twice as much bandwidth between dual-chip modules, and even more than that between Telum chips located on the same module.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=31870" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg" width="688" height="386" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:386,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=31870&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7469e089-2196-4552-a09d-884d1e71f166_1269x712.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Perhaps AMD calculated that consumers weren’t willing the pay the premium for advanced packaging technologies in client CPUs. But I do wonder what would happen if AMD could be the Nvidia of the GPU market, where enthusiasts don’t object to paying over $2000 for a top end SKU. Games tend to be cache sensitive, as VCache has shown. Perhaps such a part with a CoWoS-R RDL interposer or a similar packaging technology and a virtual L3 could push gaming performance even further.</p><p>I’d like to thank IBM for giving an excellent presentation at Hot Chips 2024, as well as discussing parts of their architecture in side conversations.</p><p><span>If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;</span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span>&nbsp;or our&nbsp;</span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;</span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Guess My Language (596 pts)]]></title>
            <link>https://vitonsky.net/blog/2025/05/17/language-detection/</link>
            <guid>44028153</guid>
            <pubDate>Mon, 19 May 2025 10:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vitonsky.net/blog/2025/05/17/language-detection/">https://vitonsky.net/blog/2025/05/17/language-detection/</a>, See on <a href="https://news.ycombinator.com/item?id=44028153">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-3hkc47wh="">  <p>If you’re still using IP geolocation to decide what language to show, stop screwing around. It’s a broken assumption dressed up as a feature.</p>
<p><img src="https://vitonsky.net/_astro/the-dreamers-2003.DK9vJg4z_Z20m2N3.webp" alt="" width="1564" height="1030" loading="lazy" decoding="async"></p>
<p>IP tells you where the request comes from, that’s it. It doesn’t tell you what language the user wants, speaks, or even understands. It fails all the time — VPNs, travel, people living abroad, countries with multiple official languages. This isn’t cleverness, it gives outright annoyance.</p>
<h2 id="country-is-not-language" data-astro-cid-qrg3z7hn="true"><a href="#country-is-not-language" data-astro-cid-qrg3z7hn="">  Country is Not Language  </a></h2> 
<p>There’s no 1:1 mapping. Belgium has three official languages, Switzerland has four, India has 22, Canada is officially bilingual and unofficially multilingual. Users could live in these places, travel through them, or have nothing to do with them besides routing traffic through there. So what are you doing forcing the UI into one language just because some geo-IP database told you what country the IP’s from?</p>
<p>You’re making assumptions on bad data, that’s not clever engineering, that’s laziness pretending to be UX.</p>
<p>No, “but the big websites do it” doesn’t make it right. You’re not a cargo cult. Do it right or don’t do it at all.</p>
<p>Personally, I’m an active user of VPN, and every time I go to Google with an enabled VPN, I can’t understand anything since there is a random language used, just because of IP rotation by my VPN provider.</p>
 
<p>Every browser sends an <code>Accept-Language</code> header. It tells you what language the user prefers, not based on location, not based on IP, based on their OS or browser config. And yes, users can tweak it if they care enough.</p>
<p>It looks like this: <code>Accept-Language: en-US,en;q=0.9,de;q=0.8</code></p>
<p>That’s your signal, use it. It’s accurate, it’s free, it’s already there, no licensing, no guesswork, no maintenance.</p>
<p>You don’t override screen resolution or color scheme with your own guess — so why do it with language?</p>
<h2 id="and-when-you-dont-listen" data-astro-cid-qrg3z7hn="true"><a href="#and-when-you-dont-listen" data-astro-cid-qrg3z7hn="">  And When You Don’t Listen?  </a></h2> 
<p>You serve English to a French user in Germany, you give Dutch to someone in Brussels who reads French, you give Chinese to someone using a Hong Kong VPN who doesn’t speak a word of it. Users get annoyed, some leave, some dig through the UI to fix your mess.</p>
<p>All of this because you trusted a sketchy IP database over the browser’s own header.</p>
<h2 id="heres-the-only-reasonable-approach" data-astro-cid-qrg3z7hn="true"><a href="#heres-the-only-reasonable-approach" data-astro-cid-qrg3z7hn="">  Here’s the Only Reasonable Approach  </a></h2> 
<ul>
<li>Read <code>Accept-Language</code></li>
<li>Respect it</li>
<li>Let the user change it if needed (and remember that choice with a cookie or URL param)</li>
<li>If you want to use GeoIP, fine — but only for currency, shipping, legal stuff, never for language</li>
</ul>
<p>If your software is meant for real people, you have no business second-guessing their preferences — get it right or don’t bother.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Side projects I've built since 2009 (228 pts)]]></title>
            <link>https://naeemnur.com/side-projects/</link>
            <guid>44027867</guid>
            <pubDate>Mon, 19 May 2025 09:17:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://naeemnur.com/side-projects/">https://naeemnur.com/side-projects/</a>, See on <a href="https://news.ycombinator.com/item?id=44027867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header>

</header>






<main>
<article><div>
<div>
<p>I’ve been building side projects since 2009. Some got sold, some are still online, and a few quietly disappeared. This page is where I keep track of everything I’ve built over the years.</p>



<p>My approach to side projects is straightforward: I build what I like.&nbsp;Most of my them have been created using WordPress, with a few exceptions where I used Laravel and React. My one tip is to use the tech stack you are most familiar with; don’t get lost in the frameworks rabbit hole. People don’t care what stack you’ve used to build it. Keep building!</p>
</div>



<main>
<h3>🏃🏻 Active ¬</h3>



<div><ul><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/mild-themes/" target="_self">Mild Themes</a></h2>

<div><p>Premium WordPress Block Themes for Creators</p></div>



</div>

</li><li>



</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/rcflex/" target="_self">RCFlex</a></h2>

<div><p>Create a digital showcase of your RC cars or share build logs</p></div>



</div>

</li><li>



</li></ul></div>
</main>



<main>
<h3>💰 Sold ¬</h3>



<div><ul><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/zeroacquire/" target="_self">ZeroAcquire</a></h2>

<div><p>Sell, Buy &amp; Discover pre-revenue side projects and MVPs.</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/tiny-resume/" target="_self">Tiny Resume</a></h2>

<div><p>Create and share your online resume. No non-sense resumes.</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/policytrail/" target="_self">PolicyTrail</a></h2>

<div><p>Privacy Policy hosting for mobile app developers</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/inventedby/" target="_self">InventedBy</a></h2>

<div><p>Modern era inventions that changed the world</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/symbol-hunt/" target="_self">Symbol Hunt</a></h2>

<div><p>Discover the symbols of the world and their meanings</p></div>



</div>

</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/techrewind/" target="_self">TechRewind</a></h2>

<div><p>Travel thru time and explore your favorite tech products</p></div>



</div>

</li><li>



</li><li>



</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/cssreflex/" target="_self">CSSReflex</a></h2>

<div><p>Code snippets, tools, resources for developers</p></div>



</div>

</li></ul></div>
</main>



<main>
<h3>💀 Dead ¬</h3>



<div><ul><li>

<div><h2><a href="https://naeemnur.com/project/nglot/" target="_self">nGlot</a></h2>

<div><p>Ancient Writing &amp; Numbering systems</p></div>



</div>

</li><li>



</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/usedby/" target="_self">UsedBy</a></h2>

<div><p>A list of most used and popular repositories on Github</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/faangwatch/" target="_self">FAANGWatch</a></h2>

<div><p>Auto updates end of day stock prices of key tech giants</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/working-time/" target="_self">Working Time</a></h2>

<div><p>Average working hours per week around the globe</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/exchainged/" target="_self">ExChainged</a></h2>

<div><p>A hub for token rates, tokens, and exchanges</p></div>



</div>

</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/coinavy/" target="_self">Coinavy</a></h2>

<div><p>A user-driven approach to discussing cryptocurrencies</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/whns/" target="_self">WHNS</a></h2>

<div><p>List of default name servers of web hosting companies</p></div>



</div>

</li><li>



</li><li>

<div><h2><a href="https://naeemnur.com/project/wpvita/" target="_self">WPVita</a></h2>

<div><p>WordPress themes for bloggers by bloggers</p></div>



</div>

</li><li>

<div><h2><a href="https://naeemnur.com/project/footyreflex/" target="_self">FootyReflex</a></h2>

<div><p>Platform focused on Football and highlights</p></div>



</div>

</li><li>



</li></ul></div>
</main>
</div></article>
</main>


</div></div>]]></description>
        </item>
    </channel>
</rss>