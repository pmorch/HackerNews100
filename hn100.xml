<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 24 Jul 2024 08:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[MPPP – The first 'designer drug' disaster (2023) (102 pts)]]></title>
            <link>https://www.chm.bris.ac.uk/motm/mppp/mppph.htm</link>
            <guid>41053383</guid>
            <pubDate>Wed, 24 Jul 2024 03:32:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chm.bris.ac.uk/motm/mppp/mppph.htm">https://www.chm.bris.ac.uk/motm/mppp/mppph.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41053383">Hacker News</a></p>
<div id="readability-page-1" class="page">

<table id="centre">
<tbody><tr>
<td>
<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<h3>1-methyl-4-phenyl-4-propionoxypiperidine,<br>or Desmethylprodine or ‘reversed meperidine’</h3>

<h3>The first ‘designer drug’ disaster</h3>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<p id="centre"><a href="mailto:s.cotton@bham.ac.uk">Simon Cotton</a><br>
<a href="http://www.birmingham.ac.uk/schools/chemistry/index.aspx">University of Birmingham</a></p>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<p id="centre">Molecule of the Month August 2023<br><span>Also available: <a href="https://www.chm.bris.ac.uk/motm/mppp/mpppjs.htm">JSMol</a> version.</span></p>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

</td><td><img src="https://www.chm.bris.ac.uk/motm/mppp/structure.gif" width="362" height="354" alt="Structure of MPPP" title="Structure of MPPP"></td>

</tr>
</tbody></table>

<h2><img src="https://www.chm.bris.ac.uk/motm/mppp/dd.jpg" width="350" height="" alt="Designer drugs" title="Designer drugs">What is a designer drug?</h2>

<p>The origin of the term is credited to Dr Gary L. Henderson, of the University of California at Davis. A designer drug is based on the structure of an existing drug – which may be naturally sourced from a plant (like <a href="http://www.chm.bris.ac.uk/motm/cocaine/cocaineh.htm">cocaine</a> or <a href="http://www.chm.bris.ac.uk/motm/morphine/Morphine.htm">morphine</a>) or be synthetic (like <a href="http://www.chm.bris.ac.uk/motm/methamphetamine/methh.htm">amphetamine</a>) - but with a slightly different structure (often done by changing a side-chain) designed to make it undetectable in routine drug tests. These slight changes to its structure also change the properties of the drug in the body, sometimes dangerously. Thus, recently this has meant the ‘bath salts’ such as mephedrone in place of cathinone (khat), with amphetamine-like effects, or the ‘spice’ drugs, which affect the ‘<a href="http://www.chm.bris.ac.uk/motm/cannabidiol/cannabidiolh.htm">cannabinoid</a>’ receptor and may produce similar symptoms to marijuana.</p>

<h2>So how long has this ‘designer drug’ been around?</h2>

<p>What we call MPPP was first reported in the <i>Journal of Organic Chemistry</i> in 1947 by Albert Ziering and John Lee of the pharmaceutical company Hofmann-La Roche. They were trying to make better painkillers, though MPPP turned out to be no better than existing ones. They tested MPPP on lab rats and found that it seemed to be safe. To make it, you first react 1-methyl-4-piperidone with phenyllithium, then esterify the resulting alcohol with propionic anhydride.</p> 

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/synthesis.gif" width="944" height="350" alt="Synthesis of MPPP" title="Synthesis of MPPP"></p>

<h2>Why is it called reversed meperidine?</h2>

<p>In comparison with the meperidine (a.k.a. pethidine or Demerol, the first synthetic opioid painkiller, originally reported in 1939), the ester group in MPPP is the other way round – it is an isomer of meperidine.</p>

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/reversed.gif" width="760" height="350" alt="MPPP and meperidene" title="MPPP and meperidene"></p>

<h2>So who did find out the nasty side to the molecule?</h2>

<p>A young chemistry graduate named Barry Kidston suddenly developed Parkinson’s disease in 1976, when he was only 23. For nearly a decade, he had been abusing a wide range of drugs, such as marijuana, amphetamines and barbiturates, before finally focussing upon opiates like meperidine and codeine. During the summer of 1976 he discovered the 1947 report of MPPP and decided to try that, successfully making it and testing it on himself, finding that it had an opiate-like ‘high’. He then repeated this synthesis several times. Whether he got over-confident in his ability or not, he seems to have taken some shortcuts in the synthesis and in 1976 developed a state of ‘muteness, severe rigidity, weakness, tremor, flat facial expression, and altered sensorium’, being unable to speak. He was admitted to a psychiatric ward.</p>

<h2>So what happened next?</h2>

<p>A number of treatments were tried. After treatments with a number of drugs including <i>levodopa</i> (a drug which the body converts into dopamine, used to treat Parkinson’s disease), his condition improved, and he received a number of medications until in September 1978 he was found dead from an overdose of cocaine and codeine, having  continued on a path of drug abuse. Post-mortem examination of the brain revealed major destruction of nerve cells in the <i>substantia nigra</i> region, something also observed with Parkinson’s patients. They examined his laboratory in 1976 and found not just the MPPP but also an impurity formed at high temperatures, MPTP.  This was tested on rats (and also on hamsters and guinea pigs), but without revealing any Parkinson’s symptom, so the cause remained a mystery. The medics studying the case wrote it up for publication in a journal called <i>Psychiatry Research</i>, and the medical world largely ignored it for a few years.</p>

<p id="centre"><a href="https://www.chm.bris.ac.uk/motm/mppp/mptp.mol"><img src="https://www.chm.bris.ac.uk/motm/mppp/mptp.gif" width="400" height="132" alt="MPTP" title="MPTP"></a><br>
MPTP</p>

<table>
<tbody><tr>
<td id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/langston.jpg" width="250" height="297" alt="Dr J. William Langston" title="Dr J. William Langston"><br>
Dr J. William Langston<br>
<small>[Photo: <a href="https://www.journalofparkinsonsdisease.com/blog/neuroscientists_corner/profile-j-william-langston"><i>J. Parkinson's Dis</i>.</a>]</small></td>

<td><h2>So what changed?</h2>

<p>In 1982, Dr J. William Langston, the Director of Neurology of the Santa Clara Valley Medical Centre in San José, was called in to examine George Carillo, a 42-year-old heroin addict who had just been admitted into the centre’s locked psychiatry unit. Carillo was ‘frozen’ – he could not move or talk. They spotted limited finger movement and after a while he was able to write very slowly: ‘I’m not sure what is happening to me. I only know I can’t function normally. I can’t move right.’ These symptoms of Parkinson’s disease had suddenly come on, over just a few weeks. And then he said he’d been taking heroin. The man’s 30-year-old girlfriend Juanita had the same symptoms. This puzzled Langston. People in their 30s and 40s were not supposed to get Parkinson’s. Certainly not from taking heroin. Then Langston found out about Bill and David, a young pair of brothers some 30 miles away in Santa Cruz, who had taken a ‘synthetic heroin’ and displayed similar ‘frozen’ symptoms. Through publicising these four cases, they learned of a drug dealer named Toby and his 21-year-old girlfriend Connie, with exactly the same history. At that point, someone recalled the article that had appeared in <i>Psychiatry Research</i>.</p></td>
<td id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/carillo.jpg" width="241" height="350" alt="George Carillo" title="George Carillo"><br>
George Carillo - a 'frozen addict'</td>
</tr>
</tbody></table>

<h2>And?</h2>

<p>Samples of the drugs which they had taken were sent for analysis, and found that what was supposed to be MPPP was largely made up of the impurity MPTP. Animal testing was extended to monkeys, and it was found that MPTP selectively kills cells in the <i>substantia nigra</i>, an area of the brain important in areas like motor control and learning, in rhesus and squirrel monkeys, just as in humans, so it affects the brains of primates in a different way to other animals.</p>

<p>Eventually George, Juanita and Connie were able to receive an experimental surgery in Sweden, during which they underwent transplanting <i>substantia nigra</i> cells from aborted foetuses into the damaged parts of their brains, and this helped them recover much of their motor function.</p>

<h2>How had this happened?</h2>

<p>Kidston seemed to have taken some short cuts in his synthesis in 1976, as had the West-Coast entrepreneur in 1982. If you try to carry out the esterification to make MPPP at too high a temperature, or too low a pH, an elimination reaction occurs. When Langston followed up the original 1947 synthesis of MPPP by going to the library of Stanford University, he found that the paper by Ziering and Lee had been cut out from the volume of <i>Journal of Organic Chemistry</i> with a razor blade. Obviously the chemist making this ‘new heroin’ did not want others in on the game.</p>

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/mppp-plus.gif" width="900" height="588" alt="Synthesis of MPP+" title="Synthesis of MPP+"></p>

<p>MPPP contains a tertiary carbon, which readily eliminates a carboxylate (a good ‘leaving group’) to generate a tertiary carbocation; this in turn loses H<sup>+</sup> and is converted into 1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine (MPTP). MPTP can cross the blood-brain barrier and, once in the brain, is mistaken for dopamine by monoamine oxidase (MAO) enzymes. Thus MPTP undergoes oxidation, forming MPP<sup>+</sup>, the species which is responsible for the neuronal damage.</p>

<h2>Did any good come from this?</h2>

<p>It has led to some new understandings about possible causes of Parkinson’s disease. For one thing, people spotted that MPP<sup>+</sup> had a similar structure to the herbicide <i>Paraquat</i>, and scientists are working on a link between Parkinson’s and herbicide use.</p> 



<p>But - above all - the story of MPPP is another warning, a horrible one, about the dangers of dabbling in the wrong sort of chemistry.</p> 

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<h2>Bibliography</h2>

<ul>
<li>A. Ziering and J. Lee, <i>J. Org. Chem</i>., 1947, <b>12</b>, 911-914 (synthesis of MPPP).</li>
<li>G. C. Davis, A. C. Williams, S. P. Markey, M. H. Ebert, E. D. Caine, C. M. Reichert and I. J. Kopin, 
<i>Psychiatry Research</i>, 1979, <b>1</b>, 249-254 (Barry Kidston diagnosed).</li>
<li>J. W. Langston, P. Ballard, J. W. Tetrud and I. Irwin, <i>Science</i>, 1983, 
<b>219</b>, 979-980 (chronic Parkinsonism in humans due to a product of meperidine-analogue synthesis).</li>
<li>R. S. Burns, C. C. Chieh, S. P. Markey, M. H., Ebert, D. M. Jacobowitz and I. J. Kopin, 
<i>Proc. Natl. Acad. Sci. USA</i>, 1983, <b>80</b>, 4546-4550 (testing MPTP in rhesus monkeys).</li>
<li>J. W. Langston, I Irwin, E. B. Langston and L. S. Forno, <i>Science</i>, 1984, 
<b>225</b>, 1480-1482 (pargyline prevents MPTP-induced Parkinsonism in primates).</li>
<li>J. W. Langston, I. Irwin, E. B. Langston and L. S. Forno, <i>Neurosci. Lett</i>., 1984, 
<b>48</b>, 87-92. (MPP<sup>+</sup> as a toxin selective to the <i>substantia nigra</i>).</li>
<li>J. N. Johannessen and S. P. Markey, <i>Drug and Alcohol Dependence</i>, 1984, 
<b>13</b>, 367-374 (analysis of MPTP/MPPP mixture).</li>
<li>P. A. Ballard, J. W. Tetrud and J. W. Langston, <i>Neurology</i>, 1985, <b>35</b>, 949-956. (human Parkinsonism due to MPTP).</li>
<li>R. M. Baum, <i>Chem. Eng. News</i>, 1985, <b>63</b>, 7–16 (designer drugs)</li>
<li>I. J. Kopin, <i>Environmental Health Perspectives</i>, 1987, <b>75</b>, 45-51 (MPTP and Parkinson’s disease).</li>
<li>G. L. Henderson, <i>J. Forensic Sci</i>., 1988, <b>33</b>, 569-575 (designer drugs)</li>
<li>H. Widner, J. Tetrud, S. Rehncrona, B. Snow, P. Brundin, B. Gustavii, A. Björklund, O. Lindvall and J. W. Langston, <i>N. Engl. J. Med</i>., 1992, <b>327</b>, 1556-1563 (transplantation of fetal dopaminergic neurons as a treatment for MPTP-induced Parkinsonism).</li>
<li>D. M. Perrine, <i>The Chemistry of Mind-Altering Drugs</i>, Washington DC, American Chemical Society, 1996, pp 78-81. (MPPP and the MPTP story).</li>
<li>J. W. Langston and J. Palfreman, <i>The case of the frozen addicts: how the solution of an extraordinary medical mystery spawned a revolution in the understanding and treatment of Parkinson's disease</i>, New York, Pantheon, 1996.</li>
<li>C. M. Tanner, F. Kamel <i>et al., Environ. Health Perspect.</i>, 2011, <b>119</b>, 866-872 (Rotenone, Paraquat, and Parkinson’s Disease).</li>
<li>F. Kamel, <i>Science</i>, 2013, <b>341</b>, 722-723 (herbicide-Parkinson’s link).</li>
<li>J. W. Langston, <i>Journal of Parkinson’s Disease</i>, 2017, <b>7</b>, S11–S22 (MPPP and the MPTP story)</li>
<li>C. Vaccari, R. El Dib. and J. L. V. de Camargo, <i>Systematic Reviews</i>, 2017, <b>6</b>, 98 (Paraquat and Parkinson’s disease: a systematic review protocol).</li>
<li><a href="https://neuwritesd.org/2016/08/18/mind-your-ps-and-ts-how-tainted-drugs-revolutionized-parkinsons-research/">How tainted drugs revolutionized Parkinsons research</a></li> 
<li><a href="https://www.journalofparkinsonsdisease.com/blog/neuroscientists_corner/profile-j-william-langston">Profile of Dr William Langston</a></li>
<li><a href="https://www.scientificamerican.com/article/parkinsons-disease-and-pesticides-whats-the-connection/">Parkinsons disease and pesticides - what's the connection?</a></li>
</ul>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="560" height="3" alt=""></p> 

<p><img src="https://www.chm.bris.ac.uk/cgi-bin/Count.cgi?df=mppph.dat|md=7|pad=Y|dd=D" alt="counter"><img src="https://www.chm.bris.ac.uk/backto.gif" width="29" height="29" alt=""> <a href="https://www.chm.bris.ac.uk/motm/motm.htm">Back to Molecule of the Month page</a>.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[DOI:<a href="http://dx.doi.org/10.6084/m9.figshare.22013048">10.6084/m9.figshare.22013048</a>]</p>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[What "consent" looks like for the DEA and TSA (169 pts)]]></title>
            <link>https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</link>
            <guid>41053329</guid>
            <pubDate>Wed, 24 Jul 2024 03:16:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/">https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</a>, See on <a href="https://news.ycombinator.com/item?id=41053329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary" role="main">	
			
<article id="post-18773">
			
	
	<p><span>Jul</span>
		<span>23</span>
		<span>2024</span>
	</p>
		
	<div>
		<p>The Drug Enforcement Agency (DEA) and the Transportation Security Administration (TSA) have been <a href="https://papersplease.org/wp/2015/05/01/secondary-inspection-used-as-pretext-for-airport-drug-searches/">working together</a> for years to steal travelers’ money.</p>
<p>The DEA <a href="https://papersplease.org/wp/2016/08/10/dea-recruits-airline-travel-industry-staff-to-inform-on-travelers/">pays informers</a> to finger people who might be flying with large amounts of cash, and gets the TSA to identify these people when they go through TSA checkpoints at airports, claims that they “consent” to be searched, and then finds any money they are carrying and seizes it through “civil forfeiture”.</p>
<p>The DEA carries out <a href="https://papersplease.org/wp/2016/10/03/how-the-dea-uses-travel-company-spies-to-confiscate-travelers-cash/">similar cash-seizure operations on Amtrak trains</a> — mostly domestic trains that don’t cross the US border — in collaboration with US Customs and Border Protection (CBP).</p>
<p>A new <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a> released by the <a href="https://ij.org/press-release/new-institute-for-justice-video-exposes-unconstitutional-airport-interdiction-tactic">Institute for Justice</a> shows how this “consent” works in practice.</p>
<p>In the w <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a>, a DEA agent won’t take “<a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">I don’t consent to a search</a>” for an answer. The agent follows an airline passenger onto their plane (without objection by airline staff), snatches the passenger’s carry-on bag, carries it off the plane, and refuses to return it. The agent claims the right to keep the passenger’s bag as long as it takes to get a warrant (although they don’t have that right, and don’t actually get a warrant).</p>
<p>This is not meaningful “consent”, and it’s not a valid legal basis for a search.</p>
<p>An ongoing <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">class-action lawsuit</a> by the <a href="https://ij.org/case/dea-tsa-forfeitures/">Institute for Justice</a> on behalf&nbsp; of air travelers who have been searched without probable cause on the pretextual claim of “consent” in order to find, seize, and “forfeit” their cash has shown just how common this pattern of illegal search and seizure is.</p>
<p>We reported on the <a href="https://papersplease.org/wp/2020/01/17/is-the-tsa-screening-for-threats-to-aviation-or-for-cash-and-drugs/">filing&nbsp; of this lawsuit</a> in 2020, and on the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">first substantive ruling</a> in the case, in favor of the plaintiffs and allowing the case to move forward, in 2021.</p>
<p>Since then, the case has <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">bogged down</a> in foot-dragging by the DEA and TSA, <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">resisting discovery</a> of their records of&nbsp; searches and seizures of cash from travelers at airports.</p>
<p>The DEA and TSA continue to claim — despite the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">initial ruling against them</a> on this point —&nbsp; that they don’t have an actionable “policy” of targeting travelers with cash for searches because they haven’t put this policy in writing. But the latest <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">status report</a> on discovery to date indicates that the DEA and TSA have made thousands of seizures of “bulk currency” from air travelers in recent years. This is clearly a routine and officially sanctioned agency practice, whether or not anyone has put it in writing.</p>
<p>The DEA and TSA claim that the volume of records of these searches and seizures would make producing them unduly burdensome. But the volume of these records is symptomatic of the scale and systemic nature of the problem — which is what the plaintiffs are trying to prove. The plaintiffs have suggested examining a statistical sample of the records of airport searches and seizures, but the DEA and TSA are resisting even that.</p>
<p>We wish the plaintiffs in this case and their lawyers success in their pursuit of justice for travelers.</p>
			</div>
</article><!-- #post-18773 -->
	<!-- #nav-below -->
	

	<!-- #comments .comments-area -->
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We made glhf.chat – run almost any open-source LLM, including 405B (111 pts)]]></title>
            <link>https://glhf.chat/landing/home</link>
            <guid>41052934</guid>
            <pubDate>Wed, 24 Jul 2024 01:52:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://glhf.chat/landing/home">https://glhf.chat/landing/home</a>, See on <a href="https://news.ycombinator.com/item?id=41052934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Run<br> <!-- -->(almost)<br> <!-- -->any<br> <!-- -->language<br> <!-- -->model</h2><div><p>We use</p><!-- --> <p><a href="https://docs.vllm.ai/en/stable/">vLLM</a></p><!-- --><p>and a custom-built, autoscaling GPU scheduler to run</p><!-- --> <p><span>(almost)</span></p><!-- --><p>any open-source large language model for you: just paste a link to the Hugging Face repo. You can use our chat UI, or our OpenAI-compatible API. We'll let you use up to eight Nvidia A100 80Gb GPUs.</p></div><div><p>Works with any full-weight or 4-bit AWQ repo on Hugging Face that vLLM supports, including:</p><ul><li>Meta Llama 3.1 405b Instruct (and 70b, and 8b)</li><li>Qwen 2 72b</li><li>Mixtral 8x22b</li><li>Gemma 2 27b</li><li>Deepseek V2 Coder Lite (support for the full model is in the works)</li><li>Phi-3</li></ul><p>And many more. We'll run full-weight finetunes as well, like those from Nous Research or uncensored anti-refusal abliterated models.</p></div><p>For the most popular models, we proxy to always-on inference providers for you automatically. For the more bespoke models, we'll spin up a cluster for you on-demand, and spin it down once you're done using it.</p><p>It's free during the beta period, while we work out the kinks and figure out how to price it. Once the beta is over, we expect to significantly beat pricing of the major cloud GPU vendors due to our ability to run the models multi-tenant.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scrapscript: A functional, content-addressable programming language (105 pts)]]></title>
            <link>https://github.com/tekknolagi/scrapscript</link>
            <guid>41052371</guid>
            <pubDate>Wed, 24 Jul 2024 00:08:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tekknolagi/scrapscript">https://github.com/tekknolagi/scrapscript</a>, See on <a href="https://news.ycombinator.com/item?id=41052371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Scrapscript Interpreter</h2><a id="user-content-scrapscript-interpreter" aria-label="Permalink: Scrapscript Interpreter" href="#scrapscript-interpreter"></a></p>
<p dir="auto">See <a href="https://scrapscript.org/" rel="nofollow">scrapscript.org</a> for some more information. Keep
in mind that the syntax on the website will change a little bit in the coming
weeks to match this repository.</p>
<p dir="auto">Take a look inside <a href="https://github.com/tekknolagi/scrapscript/blob/trunk/scrapscript.py">scrapscript.py</a> and all of its tests to get
an idea for how the language works.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">We support python3.8+.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# With a file
python3 scrapscript.py eval examples/0_home/factorial.scrap

# With a string literal
python3 scrapscript.py apply &quot;1 + 2&quot;

# With a REPL
python3 scrapscript.py repl"><pre><span><span>#</span> With a file</span>
python3 scrapscript.py <span>eval</span> examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
python3 scrapscript.py apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
python3 scrapscript.py repl</pre></div>
<p dir="auto">or with <a href="https://justine.lol/cosmopolitan/index.html" rel="nofollow">Cosmopolitan</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./build-com

# With a file
./scrapscript.com eval examples/0_home/factorial.scrap

# With a string literal
./scrapscript.com apply &quot;1 + 2&quot;

# With a REPL
./scrapscript.com repl"><pre>./build-com

<span><span>#</span> With a file</span>
./scrapscript.com <span>eval</span> examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
./scrapscript.com apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
./scrapscript.com repl</pre></div>
<p dir="auto">(if you have an exec format error and use Zsh, either upgrade Zsh or prefix
with <code>sh</code>)</p>
<p dir="auto">or with Docker:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# With a file (mount your local directory)
docker run --mount type=bind,source=&quot;$(pwd)&quot;,target=/mnt -i -t ghcr.io/tekknolagi/scrapscript:trunk eval /mnt/examples/0_home/factorial.scrap

# With a string literal
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk apply &quot;1 + 2&quot;

# With a REPL
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk repl"><pre><span><span>#</span> With a file (mount your local directory)</span>
docker run --mount type=bind,source=<span><span>"</span><span><span>$(</span>pwd<span>)</span></span><span>"</span></span>,target=/mnt -i -t ghcr.io/tekknolagi/scrapscript:trunk <span>eval</span> /mnt/examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk repl</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">The experimental compiler:</h3><a id="user-content-the-experimental-compiler" aria-label="Permalink: The experimental compiler:" href="#the-experimental-compiler"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Normal ELF</h4><a id="user-content-normal-elf" aria-label="Permalink: Normal ELF" href="#normal-elf"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="./scrapscript.py compile some.scrap  # produces output.c
./scrapscript.py compile some.scrap --compile  # produces a.out"><pre>./scrapscript.py compile some.scrap  <span><span>#</span> produces output.c</span>
./scrapscript.py compile some.scrap --compile  <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Cosmopolitan</h4><a id="user-content-cosmopolitan" aria-label="Permalink: Cosmopolitan" href="#cosmopolitan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="CC=~/Downloads/cosmos/bin/cosmocc ./scrapscript.py compile some.scrap  --compile # produces a.out"><pre>CC=<span>~</span>/Downloads/cosmos/bin/cosmocc ./scrapscript.py compile some.scrap  --compile <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Wasm</h4><a id="user-content-wasm" aria-label="Permalink: Wasm" href="#wasm"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="CC=/opt/wasi-sdk/bin/clang \
CFLAGS=-D_WASI_EMULATED_MMAN \
LDFLAGS=-lwasi-emulated-mman \
./scrapscript.py compile some.scrap --compile  # produces a.out"><pre>CC=/opt/wasi-sdk/bin/clang \
CFLAGS=-D_WASI_EMULATED_MMAN \
LDFLAGS=-lwasi-emulated-mman \
./scrapscript.py compile some.scrap --compile  <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running Tests</h2><a id="user-content-running-tests" aria-label="Permalink: Running Tests" href="#running-tests"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 scrapscript.py test"><pre>python3 scrapscript.py <span>test</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taking my diabetes treatment into my own hands (2024) (103 pts)]]></title>
            <link>https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html</link>
            <guid>41052365</guid>
            <pubDate>Wed, 24 Jul 2024 00:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html">https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html</a>, See on <a href="https://news.ycombinator.com/item?id=41052365">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>First of all, this blogpost is kinda long. Let me prove to you reading it <em>will</em> actually have some payoff:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png" alt="See, I wrote something!"></a></p>

<p>OK, now that you’ll stay, let’s start from the beginning…</p>

<hr>

<p>I’m a Type 1 diabetic. This means my pancreas doesn’t produce insulin (which allows cells to use blood glucose for energy) and I have to provide it externally.</p>

<p>This is a finnicky process, because you need to balance your glucose in the right “zone” - not too high (hyperglycemia, &gt;10 mmol/l, is a long-term danger to your body) and not too low (hypoglycemia, &lt;4 mmol/l, is a short-term danger to your body). If it’s too high, you need to inject insulin, and if it’s too low, you need to eat some sugars.</p>

<p>A commonly used metaphor for this is flying a plane. There are games illustrating the process as well: click blue button, bird flies down, click orange button, bird flies up. Too high bad, too low bad, just right good.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/icarus.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/icarus.png" alt="A game showing the process"></a></p>

<p>The issues with manually managing this process you’ve inherited from your douchebag pancreas are manifold:</p>

<ul>
  <li>the insulin doesn’t act immediately, there’s around 20min delay (depending on the brand) before your blood glucose goes down</li>
  <li>the <em>food</em> doesn’t act immediately, there’s around 20min delay (depending on the food!) before your blood glucose goes up
    <ul>
      <li>simple sugars (eg. fruit) are faster (and stop acting faster as well)</li>
      <li>complex sugars (rice / potatoes / …) are slower. You usually want your blood glucose as constant and flat as possible. The worst thing you can do is to go from hypo to hyper to hypo to hyper in huge amplitude swings.</li>
      <li>fats also somehow affect the digestion of sugars. I can’t be bothered to remember how, I just ignore them honestly.</li>
    </ul>
  </li>
  <li>injecting insulin ~15min before you start eating would do <em>wonders</em> for neutralizing the BG spike, the issue is, nobody does it, because what if you then get a smaller serving at the restaurant or it gets delayed? What if you get called somewhere urgently and can’t finish your meal? People usually inject right before the meal / after the meal as a result.</li>
  <li>there’s no generic formula (that I know of) for estimating how much will a gram of sugar increase your blood glucose, nor how much will an unit of insulin decrease your blood glucose. <em>It’s all vibes.</em></li>
  <li>mathematical models <em>do</em> exist but you need to find your body’s parameters - I’ll get to it below!</li>
  <li>the body has its own emergency reserves of glucose, which it can sometimes decide to use (though beware, this system turns off when you’re drunk), so <em>maybe</em> the Snickers bar you just ate to save your life wasn’t actually needed anymore, and you end up with a hyper</li>
  <li>you’re not quite yourself during a hypo (you get slower, dumber, I’ve heard of people getting stuck in thought loops in front of an open fridge), and so even though you intellectually know you just ate enough to get back into the correct levels <em>eventually</em>, your brain is screaming at you <strong>“EAT! YOU’RE DYING! I AM LOW ON SUGAR <em>NOW!!</em>“</strong> and in my case this leads to overcompensating quite knowingly and willingly. <em>Yeah one more yoghurt can’t hurt.</em> Well…</li>
  <li>insulin doesn’t work when eaten, you need to inject yourself with it (though nowadays we do it under skin, not into veins, I sure am glad I’m not living 50 years ago) or inhale it. Since injections aren’t the most pleasant thing in the world, the dosage is usually limited to 4x a day (to counteract the three main meals + a long-acting different type of insulin once a day), even though you’d be more stable if you injected more often, with smaller doses.
    <ul>
      <li>(no experience with inhalations here, so I’ll skip this)</li>
      <li>(insulin pumps do exist, I’ll mention those briefly in a moment… maybe)</li>
    </ul>
  </li>
  <li>measuring your blood glucose level is painful if you are using test strips and need to prick your fingers to provide a blood drop, so measuring your sugar is usually limited to 4-6x a day – again, even though it would be better to have more data points.
    <ul>
      <li>this is less of a problem nowadays with Continuous Glucose Monitoring systems like Freestyle Libre, which you install into your arm once every 14 days and get a measurement every minute through Bluetooth to your phone</li>
    </ul>
  </li>
  <li>things like physical effort, illness, stress, <em>heck, even seasons of the year</em> do all affect how your body behaves and reacts to sugar / insulin</li>
  <li>there’s this damn thing called <a href="https://en.wikipedia.org/wiki/Dawn_phenomenon">dawn phenomenon</a> that some diabetics, me included, experience: in the morning your sugar will just start going up and up. If you wanted to sleep in on the weekend, well tough luck, you’re now in the 15 mmol/l range.</li>
</ul>

<p>I hope this incomplete list gives you an idea of how wonky the process of trying to make your blood glucose stay in the right levels is.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/phone.jpeg">
<img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/phone.jpeg" alt="My 7-day average">
</a>
</p>

<p>My treatment is usually: keep the Freestyle Libre app on my phone open as much as possible and when I see my BG’s getting high, I inject a small amount of insulin. How much? No idea. <em>IT’S ALL VIBES.</em></p>

<p>But sometimes the app is yelling at you: “you’re at 15 mmol/l for an hour now, idiot!” and you just don’t (want to) pay attention. Alert fatigue is a real thing.</p>

<p>I have some recommended insulin dosages that we’ve settled on with my diabetologist, whom I visit every three months. So my regimen can look like:</p>

<ul>
  <li>Breakfast: inject 18 units, eat 24g of sugars</li>
  <li>Lunch: inject 22 units, eat 60g of sugars</li>
  <li>Dinner: inject 21 units, eat 60g of sugars</li>
  <li>Before sleep: inject 32 units of long-acting insulin</li>
</ul>

<p>And then I see my diabetologist, she looks at the 7d / 14d / 30d averages and says “maybe you can try fixing the 15:00 hypers you’re getting quite regularly, by injecting more insulin before lunch. You should also lose weight, when you started coming here you had 80kg, now you’re a centurion. Like seriously, WTF. OK cool bye, see you in 3 months!”</p>

<p>Lovely.</p>

<p>If you can’t tell, the thing that irks me the most about the whole thing is: <em><span>Ï̷̛̛̮̏̀̊͠T̵̨̡̏͝’̵̧͍̐̂̑̈́͐̐͜S̸͉̖͒̈̀̕͝ ̴̢̺̤̜͎͚̙́Ạ̷͕̱͖͙̉̊L̴̼̞̺̤̞̬̟̅̈́L̷̠̔̏̐̃̚ ̴̞̊͛͝V̸͇͚̱͑̄̈̌̊Ḯ̴̧̧͚̰̞̈́͝B̸̡̬̪͊̌͂̓̐E̵͙̼̰̞̹͇̎̽̈́̓Ş̷̱͍͖̼͍̯̉̾͊̂̾͝</span>.</em> I’d seriously appreciate it if my diabetologist used a model, or a simulation of some kind, got my body’s parameters there somehow, and found the improvements to my schedule <em>that way</em>. Maybe she has some expert knowledge in her head but from my perspective it’s all guessworks. Err, I mean <span>v̴̼̂i̴̥̇b̸̠̌e̶͙̕ś̴̲</span>.</p>

<p>And this is where my programmer mind comes in.</p>

<hr>

<p>There are people who take <strong>insulin pumps</strong> (which provide insulin in very small very frequent doses and are ~permanently injected into your body, but are otherwise dumb as a brick) and combine them with <strong>continuous glucose monitors,</strong> and make the glucose measurements inform and control the pump. This is called “closed loop” or “artificial pancreas”, and getting one officially is very hard or impossible: not FDA approved yet / you need to be part of an university study to get one / … It’s one of those things that “will be here in 5 years”, <em>they say every year for the past 30 years.</em></p>

<blockquote>
  <p>Aside: I try not to be too butthurt about it: CGMs have just recently started being available and even fully sponsored by the Czech health insurance companies, and having a 1440-datapoints-a-day graph is a <em>MASSIVE</em> improvement compared to pricking your finger 4x a day and getting 4 datapoints for your blood glucose graph with nothing in between. So, the artificial pancreas is slowly coming. Unlike nuclear fusion.</p>
</blockquote>

<p>The most prominent of these people hacking their devices together, in my social bubble at least, is <a href="https://www.hanselman.com/">Scott Hanselman</a>, the Microsoft programmer guy. (Check out his <a href="https://www.youtube.com/watch?v=uNhYhlBQoEY">talk</a>.) He’s a T1DM as well and has been promoting the <a href="https://wearenotwaiting.net/">#WeAreNotWaiting</a> initiative where people take their own pump and their own CGM and hack them together despite the healthcare companies’ pleas that it’s not approved and not safe etc. #TheyAreNotWaiting.</p>

<p>And that is really inspirational.</p>

<p>I don’t have a pump myself (and to have a chance of getting one I’d first have to find another diabetologist, which makes this into a <em>“too much work, can’t be bothered”</em> issue for me), so I can’t currently do quite what they are doing, but I can go with the high-level idea and #NotWait in my own way.</p>

<hr>

<p>A few days ago I was fumbling down the stairs to our kitchen at ~3:00 in the morning to fix my hypo. (Night hypoglycemias are <em>especially</em> bad: what if you don’t wake up?) On the stairs I had the thought: why the hell is there no app into which I’d put my past X blood glucose values, my usual daily schedule, my weight, height, gender, age, whatever, and it would let me play with some kind of prediction (interactively!) and find good dosages / meal times / injection times? Then I would have a potentially good target to get to, and over the course of a few days I could gradually adjust my real dosage to that level and see how it behaves, and hopefully stay in the 4-10 mmol/l range much more easily.</p>

<p>Why doesn’t such a thing exist?</p>

<p>(Coincidentally I’ve also started chatting about this and other app ideas with <a href="https://twitter.com/lambdapriest">John Pavlick</a>. Thanks for your encouragement, John!)</p>

<p>So I started googling. Turns out there are <em>many</em> papers detailing differential equations for a model of how glucose and insulin interact, and how an artificial pancreas could get you to the correct range automatically. The issue is, I DON’T HAVE AN ARTIFICIAL PANCREAS. I have four daily injections. Give me something useful for those!</p>

<p>There’s not too much to pick from.</p>

<blockquote>
  <p>To be honest, I also don’t really know how to translate those differential equations into a simulation algorithm, even if I found a good model. I’m guessing I need to write an <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ODE</a> solver like <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">Runge-Kutta</a> for the specific set of equations and somehow find <em>my</em> specific parameters for it. It’s been a while since I studied this in uni.</p>
</blockquote>

<p>One of the links led me to <a href="https://diabetes.zcu.cz/">diabetes.zcu.cz</a> though, and in particular their <a href="https://diabetes.zcu.cz/smartcgms/">SmartCGMS</a> app (open-source too!). From the screenshots it seemed kinda relevant, or at least similar to what I had in mind for my dream app.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/smartcgms.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/smartcgms.png" alt="SmartCGMS"></a></p>

<p>So I sent an email to the authors. Found one maintainer on GitHub and wrote them an email detailing my woes and the app I’d love to write, and whether they could point me to some existing software or good papers on modelling multiple-dose-injection treatment (as opposed to a pump / artificial pancreas).</p>

<p>What they gave me was better than I could imagine. (Thanks again, <a href="https://github.com/MartinUbl">Martin</a>!) They had a wrapper for the core SmartCGMS engine (which contains <a href="https://github.com/SmartCGMS/core/blob/dffdd89a274144d0e9ecbe9f581db9eca0e4b8ed/model/src/bergman/bergman.cpp#L82">implementations of some of these models</a> already) for the C# language. The API was quite simple:</p>

<ul>
  <li><code>.Create(...)</code> - initialize the simulation</li>
  <li><code>.Step()</code> - step one time-unit (typically a minute) in the simulation</li>
  <li><code>.ScheduleInsulinBasalRate(double unitsPerHour)</code> - schedule a (pump, sadly) insulin dosage</li>
  <li><code>.ScheduleInsulinBolus(double units)</code> - schedule a short-acting insulin injection</li>
  <li><code>.ScheduleCarbohydratesIntake(double grams)</code> - schedule food consumption</li>
  <li><code>.Terminate()</code> - stop the simulation</li>
</ul>

<p>And then there was the current simulation state:</p>

<ul>
  <li><code>.BloodGlucose</code> - current blood sugar, in mmol/l</li>
  <li><code>.InterstitialGlucose</code> - glucose in your interstitial fluid - let’s skip it, not important</li>
  <li><code>.InsulinOnBoard</code> - how much insulin is still left to be absorbed</li>
  <li><code>.CarbohydratesOnBoard</code> - how much sugar is still left to be absorbed</li>
</ul>

<p>As you can see, with some caveats this would let me make a simulation for my daily schedule.</p>

<p>So a few moments later I had something like this (in C# but here presented as Elm)</p>

<pre><code>type IntakeType
  = BasalInsulin -- long-acting
  | BolusInsulin -- short-acting
  | Carbs        -- fooooooooooooood!

type alias Intake =
  { intakeType : IntakeType
  , amount : Float
  , timeMinutes : Int
  }

type alias Input =
  { basalInsulin : Intake
  , bolusInsulins : List Intake
  , carbs : List Intake
  }

type alias OutputRow =
  { minute : Float
  , bloodGlucose : Float
  , carbohydratesOnBoard : Float
  , insulinOnBoard : Float
  , interstitialGlucose : Float
  }

simulate : Input -&gt; Int -&gt; List OutputRow
simulate input days =
  ...

mySchedule : Input
mySchedule =
  { basalInsulin = Intake BasalInsulin (22 * 60) 32
  , bolusInsulins =
      [ Intake BolusInsulin (10 * 60) 18
      , Intake BolusInsulin (13 * 60) 22
      , Intake BolusInsulin (19 * 60) 21
      ]
  , carbs =
      [ Intake Carbs (10 * 60) 24
      , Intake Carbs (13 * 60) 60
      , Intake Carbs (19 * 60) 60
      , Intake Carbs (22 * 60) 24
      ]
  }

myPrediction : List OutputRow
myPrediction =
  simulate mySchedule 3
</code></pre>

<p>Never have I copied the resulting CSV into Google Sheets so fast. Tada:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/00-accidental-art.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/00-accidental-art.png" alt="I'm the artist now."></a></p>

<p>Oh, wait, that’s not it. Cool piece of accidental art though! Now let me use the correct column for the X axis.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/01-google-sheets.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/01-google-sheets.png" alt="Google Sheets"></a></p>

<p>Well hot damn. The graph actually makes sense!</p>

<p>Granted, it’s not <em>me</em> in the graph but I can simulate <em>someone</em> now!</p>

<p><em>Let’s stash away “I need to actually simulate</em> me, <em>you know” as a TODO for future Martin and continue.</em></p>

<hr>

<p>Next I made a Windows Forms application with an OxyPlot chart so that I don’t need to write a CSV to a file and manually copy it to Google Sheets.</p>

<blockquote>
  <p>Aside: what do you .NET folks use nowadays? MAUI? WPF? Xamarin Forms? It’s kinda confusing for an outsider.</p>
</blockquote>

<p>This took me a while to figure out (I’m not a C# guy; honestly I’ve thought about rewriting this into F# instead the moment I had to start learning about event handlers and delegates), but I succeeded:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/02-initial-graph.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/02-initial-graph.png" alt="Initial graph"></a></p>

<p>There’s one little issue with seeing just the first day of the simulation though, and that’s the fact that I inject my basal (long-acting) insulin at 22:00. So for the majority of the first day the glucose will just be higher because I haven’t injected the long-acting insulin yet. So let’s simulate more days just to see what happens.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/03-ranges.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/03-ranges.png" alt="Ranges"></a></p>

<p>Oh wow, it gets periodic by day 3! Cool!</p>

<p>As you can see I’ve also added the hypo- and hyperglycemic ranges so that it’s clearer where the “Goldilocks zone” lies. As it turns out, my insulin dosage is absolutely inappropriate for the person simulated by SmartCGMS right now. Hitting such severe hypoglycemia, they’d probably be dead by now (or their liver has to work overtime on dosing that emergency glucose).</p>

<p>OK, well then, now it’s just a small step from simulating a hardcoded</p>

<pre><code>mySchedule : Input
mySchedule =
  { basalInsulin = Intake BasalInsulin (22 * 60) 32
  , bolusInsulins =
      [ Intake BolusInsulin (10 * 60) 18
      , Intake BolusInsulin (13 * 60) 22
      , Intake BolusInsulin (19 * 60) 21
      ]
  , carbs =
      [ Intake Carbs (10 * 60) 24
      , Intake Carbs (13 * 60) 60
      , Intake Carbs (19 * 60) 60
      , Intake Carbs (22 * 60) 24
      ]
  }
</code></pre>

<p>to automatically finding a more optimal dosage!</p>

<hr>

<p>I’ve opened the NuGet package manager, wrote <code>genetic</code> and installed the most popular package: <a href="https://github.com/giacomelli/GeneticSharp">GeneticSharp</a>. Turns out it’s <em>really solid.</em> It needed me to provide the usual stuff: chromosomes, crossover, selection, population size, termination criteria… and the fitness function.</p>

<p>The fitness function actually deserves a fuller description. It looks like this:</p>

<pre><code>fitness : Input -&gt; Float
fitness input =
  let
    output : List OutputRow
    output = simulate input 3

    longtermHypos = output |&gt; List.takeLast (24*60) |&gt; List.count (\row -&gt; row.bloodGlucose &lt; 4)
    longtermHypers = output |&gt; List.takeLast (24*60) |&gt; List.count (\row -&gt; row.bloodGlucose &gt;= 10)
    ...

    longtermHyposNormalized = longtermHypos / List.length output
    longtermHypersNormalized = longtermHypers / List.length output
    ...

    longtermHyposWeight = 15
    longtermHypersWeight = 12
    ...

    weightSum = longtermHyposWeight + longtermHypersWeight + ...
  in
  ( longtermHyposNormalized * longtermHyposWeight
  + longtermHypersNormalized * longtermHypersWeight
  + ...
  ) / weightSum
</code></pre>

<p><em>(Yes I know stuff is computed needlessly here; in the real C# code I’m doing all the intermediate result reuse you wish I did here, but I’m optimizing for understanding instead here.)</em></p>

<p>Turns out I care about many things. The following list evolved gradually but I’m only giving you the final version:</p>
<ul>
  <li>minimize # of hypoglycemic readings in the (stabilized) last day</li>
  <li>minimize # of hyperglycemic readings in the last day</li>
  <li>as small amplitude between min and max glucose reading as possible in the last day</li>
  <li>minimize the sum of bolus insulin dosages</li>
  <li>minimize the basal insulin dosage</li>
  <li>minimize # of hypoglycemic readings in the stabilization phase (first 2 days)</li>
  <li>minimize # of hyperglycemic readings in the stabilization phase</li>
</ul>

<p>Note that I don’t care about all of those equally. I’ve actually sorted the above list by priority: long-term hypos are the most urgent, the temporary hypers while the system settles I care about the least. I’m encoding that via the weights. Each of the normalized measurements is a number <code>0..1</code>, which then gets multiplied by the weight.</p>

<p>I’m not quite sure whether this is the right way to encode multiple concerns into a single number, but it’s the best I could come up with without consulting math books, and it seems to work well. At least I couldn’t find a case where an input with lower (better) fitness was less preferable to me (according to my brain’s fuzzy intuition) than another input with higher (worse) fitness.</p>

<p>If I was able to construct all the values and sort them, I’d probably do something like</p>

<pre><code>allCombinations
  |&gt; List.sortBy (\output -&gt;
       [ longtermHypos output
       , longtermHypers output
       , amplitude output
       , ...
       ]
     )
</code></pre>

<p>(that is, I can order outputs pairwise), but that’s not how the genetic programming libraries work. I believe explicitly not going through the whole space is one of their very top priorities :)</p>

<blockquote>
  <p>Aside: how many inputs are there? This to me looks like permutations with repetitions (order does matter), <code>n^r</code> , so in my case <code>injectionPossibilities ^ injectionCount</code>, and for my specific example schedule, <code>51^4</code>  (assuming I can inject <code>0..50</code> units of insulin). That’s around 6.7 million.</p>
</blockquote>

<p>So this could be bruteforceable. But I have to run the whole simulation inside the fitness function, and it takes around a second or two.</p>

<p>At least it’s parallelizable then! (And believe me, I’m making use of my 16 cores.)</p>

<p>Given it’s a pure function (basically… the results vary around the 10th decimal digit - negligible), I can memoize the fitness function for the input of four ints. The genetic algorithm ends up repeating some guesses quite a lot near the end of the simulation, so this actually saves a lot of time.</p>

<p>Writing a memoization function in C# was a breath of fresh air, coming from the pure FP world of Elm:</p>

<pre><code>private Dictionary&lt;List&lt;Intake&gt;, double&gt; fitnessCache = new(new IntakesSameAmount());

// ...

if (fitnessCache.TryGetValue(amounts, out var cachedFitness))
    return cachedFitness;

// ...

var fitness = Fitness(newInput);
fitnessCache.Add(amounts, fitness);
return fitness;
</code></pre>

<p><em>Amazing what you can do with a bit of mutation. Yeah I’ll go return my Elm badge now.</em></p>

<hr>

<p>So, with this fitness function created, I can now run the genetic algorithm. Let’s add a button and some more info to the UI, and start it off!</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png" alt="Intakes on the side, and a button"></a></p>

<p><em>WELL HOT DAMN.</em> It has optimized the insulin intakes and the patient (again, sadly not <em>me</em>) is now stable inside the 4-10 mmol/l range.</p>

<p>That’s really magical. I feel like I’ve solved diabetes. Of course it’s not as simple. There will always  be unexpected things and changes you need to react to. You’ll have hypers, you’ll have hypos and it’s OK. But still. It managed to squeeze the blood glucose into the correct range.</p>

<hr>

<p>So, what do I need to make this useful <em>to me?</em></p>

<p>I feel like interactivity would go a long way. Being able to add injections or meals, move them up and down, left and right, and seeing the graph change based on that, would give the diabetic much better understanding than the <em>“OK I’m gonna inject more before lunch today and see what happens two hours from now”</em> feedback loop, or even worse, the <em>“consult a doctor every three months”</em> one. Did I mention I’m a big fan of short feedback loops?</p>

<p>Of course, it needs to simulate <em>me</em> instead of somebody else. I can’t use these optimized dosages because my body reacts differently. I need to consult this with the SmartCGMS folks, but the process will likely involve me downloading my historical blood glucose data off my Freestyle Libre sensor and somebody somewhere fitting the model parameters to that data. The math escapes me but it can be done.</p>

<p>Another issue is that the algorithm is optimized for pumps, and my basal (long-acting) insulin will need to be tracked into the model a bit differently. Right now it’s as if I was injecting 1/24-th of the dosage every hour, instead of the full dosage once a day. But once the specific insulin brand and its behaviour is tracked in the software, I will be able to call <code>.ScheduleInsulinBasal(double units)</code> and all should be well (and more precise), hopefully.</p>

<p>So, there’s a bunch of stuff yet to be done and collaborate with the SmartCGMS folks on, but I’m <em>really</em> excited by this, and feel empowered taking care of my diabetes better than I thought I could. WE’VE GOT THE TECHNOLOGY! Genetic algorithms and Markov Chains, baby!</p>

<hr>

<p>What’s that? I didn’t mention Markov Chains <em>once</em> in the article?</p>

<p>Oh yeah, well, I experimented with a bunch of stuff. To end off the blogpost, here’s a stupid random walk arriving at a value iteratively. (Change each intake by a random value <code>-2..+2</code>, and if the fitness of that tweaked input is better, keep the change, otherwise rollback.)</p>

<video src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/recording.mp4" controls="">
</video>

    <hr>





  </div>

  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can opt out of airport face scans (225 pts)]]></title>
            <link>https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</link>
            <guid>41051327</guid>
            <pubDate>Tue, 23 Jul 2024 21:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan">https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</a>, See on <a href="https://news.ycombinator.com/item?id=41051327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Here’s something I’m embarrassed to admit: Even though I’ve been reporting on <a href="https://www.vox.com/future-perfect/2019/4/27/18518598/ai-facial-recognition-ban-apple-amazon-microsoft">the problems</a> with <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">facial recognition</a> for <a href="https://www.theatlantic.com/international/archive/2018/08/china-surveillance-technology-muslims/567443/">half a dozen years</a>, I have allowed my face to be scanned at airports. Not once. Not twice. Many times. </p><p>There are lots of reasons for that. For one thing, traveling is stressful. I feel time pressure to make it to my gate quickly and social pressure not to hold up long lines. (This alone makes it feel like I’m not truly consenting to the face scans so much as being coerced into them.) Plus, I’m always getting “randomly selected” for additional screenings, maybe because of my Middle Eastern background. So I get nervous about doing anything that might lead to extra delays or interrogations.</p><p>But the main reason I haven’t declined airport face scans is actually very simple: I had no idea I could opt out. </p><p>It turns out that saying no is not only doable, but <a href="https://keepbeyond.com/optout/">surprisingly easy</a> — at least in theory. Everyone, regardless of citizenship, can opt out when it comes to domestic flights in the US. (For international flights, US citizens can opt out but foreign nationals have to participate in face scanning, <a href="https://www.cbp.gov/about/congressional-resources/testimony/statement-record-assessing-cbps-use-facial-recognition-technology">with some exceptions</a>.) Simply stand away from the camera or keep your face covered with a mask, present your ID, and say, “I opt out of biometrics. I want the standard verification process.” </p><div><p>In theory, an officer is then supposed to manually look over your ID and compare it to your face, as they used to do before facial recognition. But in practice, there have been <a href="https://www.washingtonpost.com/technology/2023/07/11/tsa-airport-security-facial-recognition/">reports of passengers — even a senator — facing resistance or intimidation</a> when they try to go this route. </p></div><p>The Transportation Security Administration (TSA) and Customs and Border Protection (CBP) are also supposed to have clear signs informing passengers of the right to opt out. But at many airports, you have to look really, really hard to spot that message. Be prepared to crane your neck at an unnatural angle or squint at a very small font!</p><p>This is why the Algorithmic Justice League, a nonprofit that sheds light on AI harms, launched a campaign this month called <a href="https://www.ajl.org/campaigns/fly">“Freedom Flyers”</a> to raise awareness of your right to opt out. The timing is perfect: The TSA <a href="https://thehill.com/regulation/transportation/4738416-transportation-security-administration-record-air-travel-day/">recorded</a> an all-time record day for air travel on June 23, with nearly 3 million people screened at the country’s airports as summer vacation season picked up. </p><p>Now is the ideal time to make sure you know your rights when you pass through airport security — and understand exactly what’s at stake. The implications go way beyond air travel. </p><div><p id="how-facial-recognition-works-at-the-airport"><h2>How facial recognition works at the airport</h2></p></div><p>In the US, <a href="https://apnews.com/article/facial-recognition-tsa-airport-security-privacy-7b97462591c49184d1cb19cda9c95211">over 80 airports</a> are currently piloting facial recognition technology. The TSA’s goal is to roll out the tech in all of the more than 430 airports that it covers, <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">arguing</a> that this kind of automation would reduce “friction” at airports — meaning, presumably, how long it takes passengers to move through security. </p><p>That should raise some eyebrows, because there are known risks with this AI technology, from the possibility that your face data will be <a href="https://www.oversight.gov/report/dhs/review-cbps-major-cybersecurity-incident-during-2019-biometric-pilot">stolen due to breaches</a> to the chance that you’ll be <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">misidentified as a criminal suspect — and jailed</a>. Neither of these are hypothetical scenarios; the former has happened due to CBP system vulnerabilities and the latter has happened at the hands of police. And then, of course, there’s <a href="https://www.vox.com/future-perfect/22916602/ai-bias-fairness-tradeoffs-artificial-intelligence">AI bias</a>; facial recognition tech is known to disproportionately <a href="https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender">misidentify people of color</a>. (A CBP spokesperson insisted that the agency’s facial comparison algorithm “shows virtually no measurable differential performance in results based on demographic factors.”)</p><p>But as dangerous as face recognition can be if it goes wrong, a greater concern could be what happens if it’s seen to work as intended. When I asked <a href="https://www.vox.com/future-perfect/23365558/future-perfect-50-ai-joy-buolamwini-founder-algorithmic-justice-league">Joy Buolamwini</a>, the founder of the Algorithmic Justice League, what worries her about the use of this tech in airports, she said, “The big one for me is normalizing surveillance.”</p><p>Buolamwini argued that airport face recognition is a way of acclimating the public to having more and more sensitive information taken. “I see this on a longer trajectory,” she said. “And they’ve shown you the trajectory.”</p><p>She was referring to <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">a roadmap released in 2018 by the TSA</a>. It distinguishes between two types of facial recognition: There’s one-to-one matching, where the TSA compares the photo in your passport with the photo they take of you at the airport, to make sure that the photos match. (If you ever use your face to unlock your iPhone, this is the kind of facial recognition you’re using.)</p><p>Then there’s one-to-many matching, where your image is compared with images of others. One-to-many matching is already in use by CBP and airline partners in that they compare a passenger’s photo to a database of government documents (like US passports) for verification, TSA press secretary Carter Langston told me by email.</p><p>A particularly worrisome form of one-to-many matching is live biometrics. “Live biometrics is the <em>Minority Report</em> kind of thing — where you’re just walking around and they can identify you,” Buolamwini said. And if everyone’s face becomes fair game for live biometrics, your likeness could one day be checked against a criminal database any time you walk through a drug store or show up at a protest, which may <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">create a dangerous chilling effect</a> across society. </p><p>The TSA’s own 2018 roadmap says they aim to use “live biometrics” in the future. However, Langston disputed Buolamwini’s interpretation of that term. “That interpretation of TSA’s use case is nothing that I have heard anyone involved in the program indicate. TSA’s use case is and continues to be about identity verification,” he told me.</p><p>For now, Buolamwini said, “You might hear people say ‘Oh, we’re only doing one-to-one matching. You show us your ID, you show us your face, and we delete the data.’” But, she stressed, the full story is more complicated.</p><div><p id="do-airports-really-delete-your-photo-after-taking-it"><h2>Do airports really delete your photo after taking it?</h2></p></div><p>The first thing to know is that if you’re not a US citizen, you have no guarantee that your photo will be deleted. </p><p>In fact, <a href="https://www.cbp.gov/sites/default/files/assets/documents/2022-Sep/CPE%20Final%20Report%20Traveler%20Verification%20Service%2020220815%20Final_%20Redacted_0.pdf">according to CBP documents</a>, “Facial images for in-scope [noncitizen] travelers are also transmitted to the Department’s Automated Biometric Identification System (IDENT) and Homeland Advanced Recognition Technology System (HART). All biometrics of in-scope travelers are transmitted to IDENT/HART as encounters and are retained for 75 years in support of immigration, border management, and law enforcement activities.”</p><p>That means your photo could end up in the database for the rest of your life. What’s more, CBP <a href="https://www.dhs.gov/sites/default/files/publications/privacy-pia-cbp056-tvs-february2021.pdf">notes</a> that “CBP may share information with federal, state, and local authorities, which may be authorized to use the information for purposes beyond the scope of CBP’s mission.”</p><p>If you’re a US citizen, you might breathe a bit easier upon reading on the CBP <a href="https://www.cbp.gov/travel/biometrics/biometric-privacy-policy">website</a>, “CBP retains U.S. citizen photos for no more than 12 hours after identity verification, and only for continuity of operations purposes.” But even so, Buolamwini says, there’s reason to wonder whether all your data is really deleted after those 12 hours.</p><p>When you submit to facial recognition, the tech analyzes a photo of your face and creates what’s called a “face print” or “face template.” This is not an image — it comes in the form of a series of numbers. You can think of it as your face’s metadata. </p><p>The problem is, even if airports do delete your photo, that does not necessarily mean they’re deleting your face print. And that face print is the real informational gold. Researchers have shown that <a href="https://ieeexplore.ieee.org/document/8338413">they can reconstruct an image of your actual face</a> as long as they’ve got the face print. </p><p>I asked CBP what happens to that precious series of numbers. A CBP spokesperson did not answer the question about whether face prints get deleted in time for publication. After we published this story, the CBP spokesperson said that “CBP does not store or share the templates generated during the matching process, for either US citizens or non-citizens.”</p><div><p id="if-youve-already-let-airports-scan-your-face-is-there-a-point-in-saying-no-next-time"><h2>If you’ve already let airports scan your face, is there a point in saying no next time?</h2></p></div><p>Maybe you’re in the same situation as me. Maybe you’ve already let airports scan your face. And maybe you’re wondering whether saying no in the future will make any difference, given that your face data is probably already in a database — or two — or three. (Separate from TSA, your individual airline may also scan your face instead of your boarding pass before letting you on the plane, though airlines <a href="https://www.pcmag.com/opinions/you-can-say-no-to-face-scans-for-airplane-boarding">say</a> you can opt out for domestic flights.)</p><p>Buolamwini’s opinion? It’s definitely still worth declining the face scan next time you fly. “Every opt-out opportunity is a way to vote for your biometric rights,” she said.</p><p>We’ve already seen that when there’s enough of a public outcry, it can lead to deletion of face data. After Facebook’s facial recognition system sparked a class-action lawsuit, government investigations, and public furor, the company ended up <a href="https://www.nytimes.com/2021/11/02/technology/facebook-facial-recognition.html">deleting the face prints of more than a billion users</a> in 2021. </p><p>“Face purges can and do happen,” Buolamwini said. </p><p>Remember, the TSA’s stated reason for rolling out facial recognition in airports is to minimize friction. If you’re unhappy about the use of the tech, you can consider generating more friction next time you fly. </p><div><p><em>A version of this story originally appeared in the </em><a href="https://www.vox.com/future-perfect"><em><strong>Future Perfect</strong></em></a><em> newsletter. </em><a href="https://www.vox.com/pages/future-perfect-newsletter-signup"><em><strong>Sign up here!</strong></em></a></p></div><p><em><strong>Update, July 19, 2:30 pm ET: </strong>This story was originally published July 17 and has been updated with new comment from US Customs and Border Protection.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hydrothermal explosion at Yellowstone National Park (384 pts)]]></title>
            <link>https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</link>
            <guid>41050055</guid>
            <pubDate>Tue, 23 Jul 2024 19:49:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html">https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</a>, See on <a href="https://news.ycombinator.com/item?id=41050055">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p><label for="field-postal-state-super-purchase">
                            State
                        </label>
                        
                    </p>
                    <p><label for="field-postal-postcode-super-purchase">
                            Zip Code
                        </label>
                        
                    </p>
                    <p><label for="field-postal-country-super-purchase">
                            Country
                        </label>
                        
                    </p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: All VC Funded Startups Aggregated (Statistics) (370 pts)]]></title>
            <link>https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</link>
            <guid>41049968</guid>
            <pubDate>Tue, 23 Jul 2024 19:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/">https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</a>, See on <a href="https://news.ycombinator.com/item?id=41049968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/LeadGeneration</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Drive scans files for copyright infringement (116 pts)]]></title>
            <link>https://twitter.com/1littlecoder/status/1815830211612586255</link>
            <guid>41049799</guid>
            <pubDate>Tue, 23 Jul 2024 19:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/1littlecoder/status/1815830211612586255">https://twitter.com/1littlecoder/status/1815830211612586255</a>, See on <a href="https://news.ycombinator.com/item?id=41049799">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How Olympics officials try to catch “motor doping” (160 pts)]]></title>
            <link>https://spectrum.ieee.org/motor-doping-cycling</link>
            <guid>41049399</guid>
            <pubDate>Tue, 23 Jul 2024 18:43:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/motor-doping-cycling">https://spectrum.ieee.org/motor-doping-cycling</a>, See on <a href="https://news.ycombinator.com/item?id=41049399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="How Olympics Officials Try to Catch “Motor Doping”"><p>A French cycling official confronts a rider suspected of doping and ends up jumping onto the hood of a van making a high-speed getaway. This isn’t a tragicomedy starring <a href="https://en.wikipedia.org/wiki/G%C3%A9rard_Depardieu" target="_blank">Gérard Depardieu</a>, sending up the sport’s well-earned reputation for cheating. This scenario played out in May at the <a href="https://www.cyclingweekly.com/news/motor-doping-suspect-runs-down-race-organiser-while-escaping-inspection" target="_blank">Routes de l’Oise cycling competition</a> near Paris, and the van was believed to contain evidence of a distinctly 21st-century cheat: a hidden electric motor.<strong></strong></p><p>Cyclists call it “motor doping.” At the Paris Olympics opening on Friday, officials will be deploying electromagnetic scanners and X-ray imaging to combat it, as cyclists race for gold in and around the French capital. The officials’ prey can be quite small: Cycling experts say just 20 or 30 watts of extra power is enough to tilt the field and clinch a race.</p><p>Motor doping has been confirmed only once in professional cycling, way back in 2016. And the sport’s governing body, the <a href="https://www.uci.org/" target="_blank"><u>Union Cycliste Internationale</u></a> (UCI), has since introduced increasingly sophisticated motor-detection methods. But illicit motors remain a scourge at high-profile amateur events like the Routes de l’Oise. Some top professionals, past and present, continue to raise an alarm.</p><p>“It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” <strong>—Jean-Christophe Péraud, former Union Cycliste Internationale official</strong></p><p>Riders and experts reached by <em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em> say it’s unlikely that technological doping still exists at the professional level. “I’m confident it’s not happening any more. I think as soon as we began to speak about it, it stopped. Because at a high level it’s too dangerous for a team and an athlete,” says <a href="https://www.procyclingstats.com/rider/jean-christophe-peraud" target="_blank"><u>Jean-Christophe Péraud</u></a>, an <a href="https://olympics.com/en/athletes/jean-christophe-peraud" target="_blank"><u>Olympic silver medalist</u></a> who <strong></strong>was UCI’s first <a href="https://www.uci.org/pressrelease/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud/6omY2RZitUwewjShNVCAYH" target="_blank">Manager of Equipment and the Fight against Technological Fraud</a>. </p><p>But trust is limited. Cycling is still recovering from the scandals surrounding U.S. Olympian Lance Armstrong, whose extensive use of transfusions and drugs to boost blood-oxygen levels fueled <a href="https://www.theguardian.com/sport/2015/mar/09/lance-armstrong-uci-colluded-circ-report-cycling" target="_blank"><u>allegations of collusion by UCI officials</u></a> and threats to <a href="https://www.reuters.com/article/idUSBRE90E0ZX/" target="_blank"><u>boot cycling out of the Olympics</u></a>. </p><p>Many—including Péraud—say more vigilance is needed. The solution may be next-generation detection tech: onboard scanners that provide continuous assurance that human muscle alone is powering the sport’s dramatic sprints and climbs.</p><h2>How Officials Have Hunted for Motor Doping in Cycling</h2><p>Rumors of hidden motors first <a href="https://www.france24.com/en/20100602-fabio-cancellara-youtube-video-motorized-bike-rubbish-cycling-cheating" target="_blank"><u>swirled into the mainstream in 2010</u></a> after a Swiss cyclist clinched several European events with stunning accelerations. At the time the UCI lacked means of detecting concealed motors, and its technical director promised to “speed up” work on a “quick and efficient way” to do so. </p><p>The UCI began with <a href="https://road.cc/content/news/188441-mechanical-doping-uci-tested-and-rejected-thermal-imaging-detect-motors" target="_blank"><u>infrared cameras</u></a>, but they are useless for pre- and post-race checks when a hidden motor is cold. Not until 2015, amidst <a href="https://www.espn.com/sports/endurance/story/_/id/13272428/endurance-sports-velonews-tour-de-france-leader-chris-froome-facing-more-accusations" target="_blank"><u>further motor doping rumors</u></a> and <a href="https://road.cc/content/news/186575-hidden-motors-used-strade-bianche-claims-french-tv-video#:~:text=Jean-Pierre%20Vedry,%20the%20former,no%20reply,%20no%20checks.%E2%80%9D" target="_blank"><u>allegations of UCI inaction</u></a>, did the organization begin beta testing a better tool: an iPad-based “magnetometric tablet” scanner. </p><p>According to the UCI, an adapter plugged into one of these tablet scanners creates an ambient magnetic field. Then, a magnetometer and custom software register disruptions to the field that may indicate the presence of metal or magnets in and around a bike’s carbon-fiber frame.</p><p>UCI’s tablets delivered in their debut appearance, at the 2016 Cyclocross World Championships held that year in Belgium. Scans of bikes at the rugged event—a blend of road and mountain biking—<a href="https://www.cxmagazine.com/motor-mechanical-doping-femke-van-den-driessche-suspected-2016-cyclocross-world-championships-update" target="_blank"><u>flagged a bike</u></a> bearing the name of local favorite Femke Van den Driessche. Closer inspection revealed a motor and battery lodged within the hollow frame element that angles down from a bike’s saddle to its pedals, and wires connecting the seat tube’s hidden hardware to a push-button switch under the handlebars. </p><p><img alt="person in biking gear pushing bike up a hill on muddy terrain" data-rm-shortcode-id="7595488c2c38efa50c0515ed1fc5e689" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" height="1875" id="57041" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" width="2500"><small placeholder="Add Photo Caption...">In 2016, a concealed motor was found in a bike bearing Belgian cyclist Femke Van Den Driessche’s name at the world cyclo-cross championships. (Van Den Driessche is shown here with a different bike.)</small><small placeholder="Add Photo Credit...">AFP/Getty Images</small></p><p>Van den Driessche, banned from competition for six years, withdrew from racing while maintaining her innocence. (Giovambattista Lera, the amateur cyclist implicated earlier this year in France, <u><a href="https://road.cc/content/news/cyclist-accused-motor-doping-denies-wrong-doing-308633" target="_blank">also denies using electric assistance</a></u> in competition.)</p><p>The motor in Van den Driessche’s bike engaged with the bike’s crankshaft and added 200 W of power. The equipment’s Austrian manufacturer, <a href="https://web.archive.org/web/20171015031645/http://www.vivax-assist.com/en/" target="_blank"><u>Vivax Drive</u></a>, is now defunct. But anyone with cash to spare can experience 200 W of extra push via a racer equipped by Monaco-based HPS-Bike, such as the HPS-equipped <a href="https://www.lotuscars.com/en-GB/type-136" target="_blank">Lotus Type 136 racing bike</a> from U.K. sports car producer Lotus Group, which starts at £15,199 (US $19,715).<strong></strong></p><p>HPS founder &amp; CEO <a href="https://www.linkedin.com/in/harry-gibbings-ab8065201/?originalSubdomain=mc" target="_blank"><u>Harry Gibbings</u></a> says the company seeks to empower weekend riders who don’t want to struggle up steep hills or who need an extra boost here and there to keep up with the pack. Gibbings says the technology is not available for retrofits, and is thus off limits to would-be cheats. Still, <a href="https://www.ride-hps.com/watt-assist/" target="_blank"><u>the HPS Watt Assist system</u></a> shows the outer bounds of what’s possible in discreet high-performance electric assist. </p><p>The 30-millimeter-diameter, 300-gram motor, is manufactured by Swiss motor maker <a href="https://www.maxongroup.com/en" target="_blank"><u>Maxon Group</u></a>, and Gibbings says it uses essentially the same power-dense brushless design that’s propelling NASA’s <a href="https://robotsguide.com/robots/perseverance" target="_blank">Perseverance rover</a> on Mars. HPS builds the motor into a bike’s downtube, the frame element angling up from a bike’s crank toward its handlebars. </p><p>Notwithstanding persistent media speculation about <a href="https://spectrum.ieee.org/tag/electric-motors">electric motors</a> built into rear hubs or solid wheels, Gibbings says only a motor placed in a frame’s tubes can add power without jeopardizing the look, feel, and performance of a racing bike. </p><h2>UCI’s New Techniques to Spot Cheating in Cycling</h2><p>Professional cycling got its most sophisticated detection systems in 2018, after criticism of UCI motor-doping policies <a href="https://www.bbc.com/sport/cycling/41347950.amp" target="_blank"><u>helped fuel a change of leadership</u></a>. Incoming President David Lappartient <a href="http://www.apple.com/" target="_blank"><u>appointed Péraud to push detection</u></a> to new levels, and five months later UCI announced its first X-ray equipment at a press conference in Geneva. </p><p>Unlike the tablet scanners, which yield many false positives and require dismantling of suspect bikes, X-ray imaging is definitive. The <a href="https://www.youtube.com/watch?v=-iRwwquk7v0&amp;t=3s" target="_blank"><u>detector</u></a> is built into a shielded container and driven to events.</p><p>UCI told the cycling press that its X-ray cabinet would “remove any suspicion regarding race results.” And it says it maintains a high level of testing, with close to <a href="https://www.uci.org/pressrelease/the-uci-unveils-its-programme-to-combat-doping-and-technological-fraud-for/5j3GqEVkRlbPZaa3HfwVag#:~:text=At%20last%20year's%20Tour%20de,of%20technological%20fraud%20were%20detected." target="_blank"><u>1,000 motor-doping checks at last year’s Tour de France</u></a>. </p><p>UCI declined to speak with <em>IEEE Spectrum</em> about its motor-detection program, including plans for the Paris Olympics. But it appears to have stepped up vigilance. Lappartient recently acknowledged that UCI’s controls are “<a href="https://www.theguardian.com/sport/article/2024/jun/27/uci-to-pay-whistleblowers-for-motor-doping-tip-offs-at-tour-de-france?CMP=share_btn_url" target="_blank"><u>not 100 percent secure</u></a>” and announced a reward for whistleblowers who deliver evidence of motor fraud. In May, UCI once again <a href="https://www.uci.org/pressrelease/uci-appoints-nicholas-raudenski-as-head-of-the-fight-against-technological/2pu13dvS3ykOj9YOiCg4Aj" target="_blank"><u>appointed a motor-doping czar</u></a>—a first since <a href="https://www.insidethegames.biz/articles/1096111/peraud-loses-uci-role" target="_blank">Péraud departed</a> amidst budget cuts in 2020. Among other duties, former U.S. Department of Homeland Security criminal investigator Nicholas Raudenski is tasked with “development of new methods to detect technological fraud.” </p><p>Unlike the tablet scanners, X-ray imaging is definitive.</p><p>Péraud is convinced that only real-time monitoring of bikes throughout major races can prove that motor fraud is in the past, since big races provide ample opportunities to sneak in an additional bike and thus evade UCI’s current tools.</p><p>UCI has already laid the groundwork for such live monitoring, partnering with France’s <a href="https://www.cea.fr/english/Pages/Welcome.aspx" target="_blank">Alternative Energies and Atomic Energy Commission</a> (Commissariat à l’énergie atomique et aux énergies alternatives, or CEA) to capitalize on the national lab’s deep magnetometry expertise. UCI disclosed some details at its 2018 Geneva press conference, where a CEA official <a href="https://www.uci.org/article/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud-185708/1RaUU9mAQ4qkyXKwN0rXp0" target="_blank"><u>presented its concept</u></a>: an embedded, high-resolution magnetometer to detect a hidden motor’s electromagnetic signature and wirelessly alert officials via receivers on race support vehicles. </p><p>As of June 2018, CEA researchers in Grenoble had <a href="https://www.minatec.org/en/cycling-detecting-hidden-electric-motors/" target="_blank"><u>identified an appropriate magnetometer</u></a> and were evaluating the electromagnetic noise that could challenge the system—“from rotating wheels and pedals to passing motorcycles and cars.” </p><p>Mounting detectors on every bike would not be cheap, but Péraud says he is convinced that cycling needs it: “It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is it so hard to share links on LinkedIn? (117 pts)]]></title>
            <link>https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</link>
            <guid>41049016</guid>
            <pubDate>Tue, 23 Jul 2024 18:08:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/">https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</a>, See on <a href="https://news.ycombinator.com/item?id=41049016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p><strong>LinkedIn is a social network</strong> that deeply confuses me. It’s a social network that sends messages with such a level of vagueness, seemingly to ensure you’ll never figure them out.</p>
<p>It gamifies profile-viewing in a way that feels less professional and more creepy. Plus, it charges money—a lot of money—for most of its features. It’s a hugely successful network, one that some have suggested is the true heir to the “new Twitter” discourse.</p>
<p>But it has an algorithmic problem that must be called out: Despite the fact that “link” is literally in the network’s name, the network has an allergy towards external links.</p>
<p>And increasingly desperate posters and social media marketers are going through comically complex hoops to work around it. Recently, I caught a video from a guy named <a href="https://www.linkedin.com/in/markpjung/">Mark P. Jung</a>, a consultant whose startup <a href="https://authorityb2b.com/">Authority B2B</a> basically teaches companies and desired influencers the road they need to take to attain LinkedIn success. And to me, it seemed like he was trying to sell some magic beans that appear to actually function.</p>
</div><div>
    
<p>Jung, in a video <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">shared by content marketer Lindsay McGuire</a>, characterizes the changes as “interesting UI decisions” made since Microsoft acquired the company about eight years ago, changes that have invalidated linking hacks used by the network in prior eras.</p>
<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/"><img data-src="https://images.tedium.co/uploads/zeroclick.jpg" width="1000" height="529" alt="Zeroclick" src="https://images.tedium.co/uploads/zeroclick.jpg"></a></p>
<p><em>Jung, in the video of his <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">that drew attention recently</a>. The use of the term “zero-click” is telling.</em></p>
<p>“Back in the day, people used to sort of get around LinkedIn stuff by just dropping a link in the comments and saying, ‘Hey, check out the comments,’” Jung explains. “Problem is, LinkedIn actually parses if you're the first person to comment in your post, if you're the first person to add a link, even if you actually write, like, the website, but remove the .com and say ‘dot com,’ this algorithm is on to you. It's immediately going to take your post and downrank it.”</p>
<p>So basically, Jung explains the alternative options for sharing a link on LinkedIn as such:</p>
<ol>
<li><strong>Post your thing,</strong> making it sufficiently long so the algorithm might enjoy it.  </li>
<li><strong>Get a little engagement</strong> on said thing, so you signal the post has some interest.</li>
<li><strong>Wait about 15 or 20 minutes.</strong>  </li>
<li><strong>Edit the post,</strong> adding content equivalent to up to 15 percent of the post length, including a URL (which you should shortlink, using a service like Bitly, because every character of the URL counts against the added length). </li>
<li><strong>If you did it right,</strong> watch number go up.</li>
</ol>
<p>Does that sound like a lot of work for a single social post? You betcha. You basically have to make this someone’s job because of how long it takes to do. And it’s likely why every post on LinkedIn is like 100,000 words.</p>
<p>To be clear, my beef is not with Jung, who knows how to build social influence and understands the secrets to algorithmic growth. He sounds like someone who spent his time in the salt mines and doesn’t particularly like that it works like this, either. That he knows about it, apparently having uncovered it through a bunch of trial and error with client work, and is sharing his secrets, is fair.</p>
<p>Rather, my issue is with LinkedIn itself, which has clearly put in a lot of work to devalue the link, even more than other networks that do the same thing, like Instagram and Facebook.</p>
<p>At the ISP and mobile provider level, <a href="https://www.eff.org/deeplinks/2016/02/zero-rating-what-it-is-why-you-should-care">there’s this concept called zero-rating</a>, in which an internet provider provides free access to a selection of sites without the sites counting against the bandwidth limits. (An example of this is T-Mobile <a href="https://www.theregister.com/2015/12/23/youtube_t_mobile_us/">limiting users to 480p-quality videos</a> when streaming on mobile, but requiring you to pay an upcharge for higher-quality videos.) It is seen as a controversial workaround for net neutrality rules—though, while it’s still out there, it has become less of a problem in developed nations as internet connections have gotten faster and more unlimited. LinkedIn is doing something similar with its platform, something called zero-click content, as Jung puts it.</p>
<p>The terminology Jung uses is more telling than you might expect—essentially, it basically implies a social media version of zero-rating, which is a very controversial concept on telecom circles. LinkedIn wants you to create more content for its platform, and it wants you to do so at the cost of any outwardly facing content. So, it downranks anything it sees as damaging to that goal, even if it means breaking the original point of the internet in the process. It is essentially the same concept as zero-rating, except at a more granular level.</p>
<p>The problem with this is twofold: First, it forces content on LinkedIn to take an extremely unnatural shape that doesn’t make sense for a social media platform, often extending well beyond what people want out of it, and two, it limits reach to anyone that doesn’t play by LinkedIn’s rules. It’s a free-trade issue, essentially, and LinkedIn is dominant enough in its niche of business content that a regulator should look into this.</p>
<p>In many ways, social media has these kinds of issues in spades—including on that site I still call Twitter, which has forced people to write gigantic threads instead of linking to blog posts, and Instagram, which is so dominant that it has allowed the creation of secondary businesses around the link in bio.</p>
<p>This is what social media has become, an attempt to work around algorithms, rather than a way to engage with people. <a href="https://www.anildash.com/2019/12/10/link-in-bio-is-how-they-tried-to-kill-the-web/">As Anil Dash wrote</a> back in 2019, with a focus on Instagram rather than LinkedIn, social media seems to be doing all it can to destroy the value of the link:</p>
<blockquote><p>There are some legitimate reasons platforms limit links. Spammers abuse links. Trust is hard to verify around links—too many scammers make links that look real, but lead to sketchy sites. Building a system to monitor all the links being posted on a big platform does take some cost. Maybe you can have a link again, if you are already in the 1% most influential users on the platform and put it in a story—the part of Instagram's experience that drives the engagement metrics they care about. Maybe you just give up, and pay for links, by buying advertising.</p>
<p>But killing off links is a strategy. It may be presented as a cost-saving measure, or as a way of reducing the sharing of untrusted links. But it is a strategy, designed to keep people from the open web, the place where they can control how, and whether, someone makes money off of an audience. The web is where we can make sites that don’t abuse data in the ways that Facebook properties do.</p>
</blockquote>
<p>If you’re committed to one ecosystem or another, you’re really committed. And LinkedIn wants committed users. But on the other hand, people don’t run their entire lives on LinkedIn. It’s not like Nike or Blackstone or your local cupcake shop or your local neighborhood content hustlers can just live on LinkedIn. But LinkedIn acts as if that’s what you need to do to get ahead, and it feels like something we should start talking about in earnest.</p>
<p>What is the value of the link? Why are there so many barricades between the audience you’ve built and the link you want to share? (Hint: They think it’s not really your audience.) And when should regulators step in to ensure that our social networks aren’t impeding commerce by impeding links?</p>
<p>I know Lina Khan is pretty busy these days, but it feels like a question she might be well-suited to help answer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese-born chemist cleared of last conviction under US’s espionage probe (142 pts)]]></title>
            <link>https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</link>
            <guid>41048747</guid>
            <pubDate>Tue, 23 Jul 2024 17:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article">https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</a>, See on <a href="https://news.ycombinator.com/item?id=41048747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Following a five-year legal battle, Chinese-born former University of Kansas chemistry professor Feng ‘Franklin’ Tao, who was <a href="https://www.chemistryworld.com/news/us-chemistry-professor-convicted-under-now-defunct-china-initiative/4015510.article">arrested and convicted under the former Trump administration’s now-defunct ‘China Initiative’</a>, has been vindicated. An appeals court in Denver, Colorado has <a href="https://x.com/Profleoyu/status/1811593615514259592">acquitted Tao of his one remaining conviction</a> that he made a false statement about his relationship with a Chinese university.</p>
<p>In April 2022, Tao – a permanent US resident who before his arrest in 2019 had served as a tenured associate professor at the University of Kansas since 2014 – was not only convicted of making a ‘materially false statement’, but also of three counts of wire fraud. He faced up to 20 years in prison and substantial fines. However, he <a href="https://www.chemistryworld.com/news/us-chemist-feng-tao-avoids-prison-sentence-for-hiding-ties-to-china/4016855.article">was subsequently acquitted of the wire fraud charges and so only the now-overturned false statements conviction remained</a>. Ultimately, he was sentenced to time served with a $100 (£81) fine.</p>
<p>At issue in the new ruling, issued 11 July, is whether Tao’s lack of disclosure about his affiliation with Fuzhou University in China affected federal agency funding decisions. The Denver appeals court agreed 2-1 that it was irrelevant because Tao had no grant proposals pending before those two agencies in question – the US Department of Energy and National Science Foundation – at the time he made his affiliation statement.</p>
<p>Tao’s lawyer, Peter Zeidenberg welcomed the court’s ruling. ‘Even though there was not a scintilla of evidence that Dr Tao was engaged in espionage or theft of trade secrets, the government nevertheless relentlessly investigated him and ultimately charged him with 10 felonies – all based on an alleged omission on a single internal form he submitted to the University of Kansas research office and which was never shared with any federal agency,’ he stated. Those initial 10 charges were first reduced to three, then one, and now zero.</p>
<p>Zeidenberg emphasised that Tao’s reputation has been ‘unfairly dragged to the mud’, and he was ‘wrongly fired’ by the University of Kansas. ‘Dr Tao, a world-renowned expert in catalysis, has been unable to do his research, depriving all of us who benefit from scientific advances,’ Zeidenberg continued, noting that his legal fight has virtually bankrupted his family. Even with assistance from friends and family and a GoFundMe campaign, Tao still owes over $1 million in legal fees, he said.</p>
<p>Tao was one of an estimated two dozen academics who were charged under the US government’s China Initiative. The programme, launched in<strong> </strong>2018 to counter trade secret theft and economic espionage, was widely criticised as racially biased and harmful to academic freedom. It was eventually <a href="https://www.chemistryworld.com/news/us-ends-anti-espionage-china-initiative/4015301.article">terminated under President Biden in 2022</a> following <a href="https://www.chemistryworld.com/news/us-programme-targeting-researchers-with-china-links-crumbling-under-intense-scrutiny/4014572.article">the dismissal of many of the government’s criminal cases that were brought against university researchers under the initiative</a>.</p>
<p>The Asian–American Scholar Forum <a href="https://www.aasforum.org/2024/07/17/aasf-celebrates-dr-franklin-taos-appeal-victory/">called Tao’s latest court win ‘a significant victory’</a> and celebrated it as ‘a crucial step toward rectifying the unjust treatment of Chinese American and immigrant scientists under the now-defunct China Initiative’.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Warsaw came close to never being rebuilt (2015) (165 pts)]]></title>
            <link>https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</link>
            <guid>41048677</guid>
            <pubDate>Tue, 23 Jul 2024 17:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt">https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</a>, See on <a href="https://news.ycombinator.com/item?id=41048677">Hacker News</a></p>
Couldn't get https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zerox – Document OCR with GPT-mini (147 pts)]]></title>
            <link>https://github.com/getomni-ai/zerox</link>
            <guid>41048194</guid>
            <pubDate>Tue, 23 Jul 2024 16:49:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/getomni-ai/zerox">https://github.com/getomni-ai/zerox</a>, See on <a href="https://news.ycombinator.com/item?id=41048194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/getomni-ai/zerox/blob/main/examples/heroImage.png"><img src="https://github.com/getomni-ai/zerox/raw/main/examples/heroImage.png" alt="Hero Image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zerox OCR</h2><a id="user-content-zerox-ocr" aria-label="Permalink: Zerox OCR" href="#zerox-ocr"></a></p>
<p dir="auto">A dead simple way of OCR-ing a document for AI ingestion. Documents are meant to be a visual representation after all. With weird layouts, tables, charts, etc. The vision models just make sense!</p>
<p dir="auto">The general logic:</p>
<ul dir="auto">
<li>Pass in a PDF (URL or file buffer)</li>
<li>Turn the PDF into a series of images</li>
<li>Pass each image to GPT and ask nicely for Markdown</li>
<li>Aggregate the responses and return Markdown</li>
</ul>
<p dir="auto">Sounds pretty basic! But with the <code>gpt-4o-mini</code> this method is price competitive with existing products, with meaningfully better results.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pricing Comparison</h4><a id="user-content-pricing-comparison" aria-label="Permalink: Pricing Comparison" href="#pricing-comparison"></a></p>
<p dir="auto">This is how the pricing stacks up to other document processers. Running 1,000 pages with Zerox uses about 25M input tokens and 0.4M output tokens.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Service</th>
<th>Cost</th>
<th>Accuracy</th>
<th>Table Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Textract <a href="https://aws.amazon.com/textract/pricing/#:~:text=Amazon%20Textract%20API%20pricing" rel="nofollow">[1]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Google Document AI <a href="https://cloud.google.com/document-ai/pricing" rel="nofollow">[2]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Azure Document AI <a href="https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/" rel="nofollow">[3]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Mid</td>
<td>Low</td>
</tr>
<tr>
<td>Unstructured (PDF) <a href="https://unstructured.io/api-key-hosted#:~:text=Cost%20and%20Usage%20%0AGuidelines" rel="nofollow">[4]</a></td>
<td>$10.00 / 1,000 pages</td>
<td>Mid</td>
<td>Mid</td>
</tr>
<tr>
<td>------------------------</td>
<td>--------------------</td>
<td>--------</td>
<td>-------------</td>
</tr>
<tr>
<td>Zerox (gpt-mini)</td>
<td>$ 4.00 / 1,000 pages</td>
<td>High</td>
<td>High</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">Zerox uses <code>graphicsmagick</code> and <code>ghostscript</code> for the pdf =&gt; image processing step. These should be pulled automatically, but you may need to manually install.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><strong>With file URL</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: &quot;https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>"https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><strong>From local path</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import path from &quot;path&quot;;
import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: path.resolve(__dirname, &quot;./cs101.pdf&quot;),
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>path</span> <span>from</span> <span>"path"</span><span>;</span>
<span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>"./cs101.pdf"</span><span>)</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Options</h3><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const result = await zerox({
  // Required
  filePath: &quot;path/to/file&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,

  // Optional
  concurrency: 10, // Number of pages to run at a time.
  maintainFormat: false, // Slower but helps maintain consistent formatting.
  cleanup: true, // Clear images from tmp after run.
  outputDir: undefined, // Save combined result.md to a file
  tempDir: &quot;/os/tmp&quot;, // Directory to use for temporary files (default: system temp directory)
});"><pre><span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>// Required</span>
  <span>filePath</span>: <span>"path/to/file"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>

  <span>// Optional</span>
  <span>concurrency</span>: <span>10</span><span>,</span> <span>// Number of pages to run at a time.</span>
  <span>maintainFormat</span>: <span>false</span><span>,</span> <span>// Slower but helps maintain consistent formatting.</span>
  <span>cleanup</span>: <span>true</span><span>,</span> <span>// Clear images from tmp after run.</span>
  <span>outputDir</span>: <span>undefined</span><span>,</span> <span>// Save combined result.md to a file</span>
  <span>tempDir</span>: <span>"/os/tmp"</span><span>,</span> <span>// Directory to use for temporary files (default: system temp directory)</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <code>maintainFormat</code> option trys to return the markdown in a consistent format by passing the output of a prior page in as additional context for the next page. This requires the requests to run synchronously, so it's a lot slower. But valueable if your documents have a lot of tabular data, or frequently have tables that cross pages.</p>
<div data-snippet-clipboard-copy-content="Request #1 => page_1_image
Request #2 => page_1_markdown + page_2_image
Request #3 => page_2_markdown + page_3_image"><pre><code>Request #1 =&gt; page_1_image
Request #2 =&gt; page_1_markdown + page_2_image
Request #3 =&gt; page_2_markdown + page_3_image
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Output</h3><a id="user-content-example-output" aria-label="Permalink: Example Output" href="#example-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  completionTime: 10038,
  fileName: 'invoice_36258',
  inputTokens: 25543,
  outputTokens: 210,
  pages: [
    {
      content: '# INVOICE # 36258\n' +
        '**Date:** Mar 06 2012  \n' +
        '**Ship Mode:** First Class  \n' +
        '**Balance Due:** $50.10  \n' +
        '## Bill To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '## Ship To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '\n' +
        '| Item                                       | Quantity | Rate   | Amount  |\n' +
        '|--------------------------------------------|----------|--------|---------|\n' +
        &quot;| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n&quot; +
        '| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n' +
        '\n' +
        '**Subtotal:** $48.71  \n' +
        '**Discount (20%):** $9.74  \n' +
        '**Shipping:** $11.13  \n' +
        '**Total:** $50.10  \n' +
        '---\n' +
        '**Notes:**  \n' +
        'Thanks for your business!  \n' +
        '**Terms:**  \n' +
        'Order ID : CA-2012-AB10015140-40974  ',
      page: 1,
      contentLength: 747
    }
  ]
}"><pre><span>{</span>
  <span>completionTime</span>: <span>10038</span><span>,</span>
  <span>fileName</span>: <span>'invoice_36258'</span><span>,</span>
  <span>inputTokens</span>: <span>25543</span><span>,</span>
  <span>outputTokens</span>: <span>210</span><span>,</span>
  <span>pages</span>: <span>[</span>
    <span>{</span>
      <span>content</span>: <span>'# INVOICE # 36258\n'</span> <span>+</span>
        <span>'**Date:** Mar 06 2012  \n'</span> <span>+</span>
        <span>'**Ship Mode:** First Class  \n'</span> <span>+</span>
        <span>'**Balance Due:** $50.10  \n'</span> <span>+</span>
        <span>'## Bill To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'## Ship To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'| Item                                       | Quantity | Rate   | Amount  |\n'</span> <span>+</span>
        <span>'|--------------------------------------------|----------|--------|---------|\n'</span> <span>+</span>
        <span>"| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n"</span> <span>+</span>
        <span>'| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'**Subtotal:** $48.71  \n'</span> <span>+</span>
        <span>'**Discount (20%):** $9.74  \n'</span> <span>+</span>
        <span>'**Shipping:** $11.13  \n'</span> <span>+</span>
        <span>'**Total:** $50.10  \n'</span> <span>+</span>
        <span>'---\n'</span> <span>+</span>
        <span>'**Notes:**  \n'</span> <span>+</span>
        <span>'Thanks for your business!  \n'</span> <span>+</span>
        <span>'**Terms:**  \n'</span> <span>+</span>
        <span>'Order ID : CA-2012-AB10015140-40974  '</span><span>,</span>
      <span>page</span>: <span>1</span><span>,</span>
      <span>contentLength</span>: <span>747</span>
    <span>}</span>
  <span>]</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Switzerland now requires all government software to be open source (137 pts)]]></title>
            <link>https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/</link>
            <guid>41047172</guid>
            <pubDate>Tue, 23 Jul 2024 15:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/">https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=41047172">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><div><picture><source media="(max-width: 767px)" srcset="https://www.zdnet.com/a/img/resize/370ca9eb455fc4b33122e82c2bc262cde418770a/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=768" alt="Switzerland flag on keyboard"><source media="(max-width: 1023px)" srcset="https://www.zdnet.com/a/img/resize/48c1efdb118a09fdf69b74e130635533fef2db04/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1024" alt="Switzerland flag on keyboard"><source media="(max-width: 1440px)" srcset="https://www.zdnet.com/a/img/resize/65fa58548e14c621214db2cdf42bec50d30b4185/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1280" alt="Switzerland flag on keyboard"> <img src="https://www.zdnet.com/a/img/resize/65fa58548e14c621214db2cdf42bec50d30b4185/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1280" alt="Switzerland flag on keyboard" width="1280" height="837.3527272727273" fetchpriority="low"></picture></div> <figcaption> <span>Bojanikus/Getty Images</span></figcaption></figure><p>Several European countries are betting on open-source software. In the United States, eh, not so much. In the latest news from across the Atlantic, Switzerland has taken a major step forward with its "<a href="https://datenrecht.ch/en/bundesgesetz-ueber-den-einsatz-elektronischer-mittel-zur-erfuellung-von-behoerdenaufgaben-embag-in-schlussabstimmung-angenommen/" target="_blank" rel="noopener nofollow">Federal Law on the Use of Electronic Means for the Fulfillment of Government Tasks" (EMBAG).</a> This groundbreaking legislation mandates using open-source software (OSS) in the public sector.</p><p>This new law requires all public bodies to disclose the source code of software developed by or for them unless third-party rights or security concerns prevent it. This "public money, public code" approach aims to enhance government operations' transparency, security, and efficiency.</p><p><strong>Also: <a href="https://www.zdnet.com/article/german-state-ditches-microsoft-for-linux-and-libreoffice/" rel="follow">German state ditches Microsoft for Linux and LibreOffice</a></strong></p><p>Making this move wasn't easy. It began in 2011 when the Swiss Federal Supreme Court <a href="https://www.openjustitia.ch/DE/interne_Open_Justitia.html" target="_blank" rel="noopener nofollow">published its court application, Open Justitia, under an OSS license</a>. The proprietary legal software company <a href="https://www.weblaw.ch/" target="_blank" rel="noopener nofollow">Weblaw</a> wasn't happy about this. There were heated political and legal fights for more than a decade. Finally, the EMBAG was passed in 2023. Now, the law not only allows the release of OSS by the Swiss government or its contractors, but also requires the code to be released under an open-source license "unless the rights of third parties or security-related reasons would exclude or restrict this."</p><p>Professor Dr. Matthias Stürmer, head of the Institute for Public Sector Transformation at the <a href="https://www.bfh.ch/en/" target="_blank" rel="noopener nofollow">Bern University of Applied Sciences</a>, led the fight for this law. He hailed it as&nbsp;<a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland" target="_blank" rel="noopener nofollow">"a great opportunity for government, the IT industry, and society."</a> Stürmer believes everyone will benefit from this regulation, as it reduces vendor lock-in for the public sector, allows companies to expand their digital business solutions, and potentially leads to reduced IT costs and improved services for taxpayers.</p><!----><p>In addition to mandating OSS, the EMBAG also requires the release of non-personal and non-security-sensitive government data as Open Government Data (OGD). This dual "open by default" approach marks a significant paradigm shift towards greater openness and practical reuse of software and data.</p><p>Implementing the EMBAG is expected to serve as a model for other countries considering similar measures. It aims to promote digital sovereignty and encourage innovation and collaboration within the public sector.</p><p>The Swiss Federal Statistical Office (BFS) is leading the law's implementation, but the organizational and financial aspects of the OSS releases still need to be clarified.</p><p><strong>Also:&nbsp;<a href="https://www.zdnet.com/article/why-dont-more-people-use-desktop-linux-i-have-a-theory-you-might-not-like/" rel="follow">Why don't more people use desktop Linux? I have a theory you might not like</a></strong></p><p>Other countries in Europe have long supported open source. For example, in 2023, <a href="https://eucloudedgeiot.eu/summary-of-the-open-source-key-areas-for-digital-autonomy-workshop/" target="_blank" rel="noopener nofollow">French President Macron stated, "We love open source,"</a> and France's National Gendarmerie (Think FBI if you're an American) <a href="https://www.zdnet.com/article/french-police-move-from-windows-to-ubuntu-linux/" rel="follow">uses Linux on its PCs</a>. The European Union (EU) has long worked on securing OSS via the EU's&nbsp;<a href="https://commission.europa.eu/about-european-commission/departments-and-executive-agencies/digital-services/eu-fossa-2-free-and-open-source-software-auditing_en" target="_blank" rel="noopener nofollow">Free and Open Source Software Auditing (FOSSA)</a> project.</p><p>That said, it's not all wine and roses in the EU. There's some worry that the European Commission will <a href="https://fossforce.com/2024/07/is-the-european-commission-dropping-support-for-important-open-source-funding/" target="_blank" rel="noopener nofollow">cut funding for the NGI Zero Commons Fund</a>, an important funding source for OSS projects.</p><p>In the US, there's some support for open source, but not nearly as much as in Europe. The <a href="https://open.gsa.gov/oss-policy/" target="_blank" rel="noopener nofollow">Federal Source Code Policy,</a> for instance, requires federal agencies to release at least 20% of new custom-developed code as open-source software. It doesn't, however, mandate the use of open source.</p><p><strong>Also: <a href="https://www.zdnet.com/article/do-you-need-antivirus-on-linux/" rel="follow">Do you need antivirus on Linux?</a></strong></p><p>Similarly, the General Services Administration (GSA) has an <a href="https://open.gsa.gov/oss-policy/#:~:text=c.-,GSA%20Service%20and%20Staff%20Offices%20(Project%20teams)%20are%20responsible%20for,knowledge%20to%20improve%20the%20project." target="_blank" rel="noopener nofollow">OSS Policy that requires GSA organizations to account for and publish their open-source code</a>. This policy promotes an "open first" approach for new custom code development.</p><p>So, while this legislative move positions Switzerland at the forefront of the global open-source movement, more work needs to be done both in Europe and the US.</p><div id="pinbox-d1027a65-751c-48cb-a4ee-4b3907aaaccf"><h4>Featured</h4> <!---->  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unix Pipe Card Game (197 pts)]]></title>
            <link>https://punkx.org/unix-pipe-game/</link>
            <guid>41047110</guid>
            <pubDate>Tue, 23 Jul 2024 15:35:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://punkx.org/unix-pipe-game/">https://punkx.org/unix-pipe-game/</a>, See on <a href="https://news.ycombinator.com/item?id=41047110">Hacker News</a></p>
<div id="readability-page-1" class="page">
    

    This is a card game for teaching kids how to combine unix commands through <mark>pipes</mark>.<p>
    This game assumes the parent knows the basic unix commands: <code>cat, grep, tail, head, wc, sort, uniq</code>. The parent should show also show those commands in action the computer as well, if you do not have any UNIX system you can use <a href="https://bellard.org/jslinux/vm.html?url=alpine-x86.cfg&amp;mem=192">jslinux</a> in your browser.

    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/deck.jpg"><img src="https://punkx.org/unix-pipe-game/photos/deck.jpg" height="70%"></a><br>

    <a href="https://shop.punkx.org/products/unix-pipe-game">Buy now: €5,00 EUR</a></p><ul>
      <li>print it yourself: <a href="https://punkx.org/unix-pipe-game/unix-pipe-cards.pdf">unix-pipe-cards.pdf</a>, <a href="https://punkx.org/unix-pipe-game/unix-pipe-box.pdf">unix-pipe-box.pdf</a></li>
      <li>code: <a href="https://github.com/jackdoe/programming-for-kids/tree/master/projects/unix-pipe-game">unix-pipe-game</a></li>
      <li>author: <a href="https://github.com/jackdoe">github.com/jackdoe</a></li>
      <li>co author: <a href="https://punkjazz.org/jackie">Jackie</a></li>
      <li>contact: <a href="mailto:b0000@fastmail.com">b0000@fastmail.com</a></li>
      <li>license: CC BY 4.0</li>
    </ul>

    If you want to play the <b>more difficult</b> version, you can also get the Expansion pack: <a href="https://punkx.org/unix-pipe-game/ext-0.1/index.html">UNIX Pipe Game - Process Substitution</a><p>

    
    Example game round:

    </p><dl>task: <b>print the most common line from a file</b>, we need to first cat the file (in our case the file is card 03.txt), then sort it, uniq count it, then do numeric sort, then tail -1:
      <p>

    <b>cat 03.txt | sort | uniq -c | sort -n | tail -1</b></p></dl>


    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/example.jpg"><img src="https://punkx.org/unix-pipe-game/photos/example.jpg" width="100%"></a>

    <br>

    <pre>                 RULES:

&gt; 0. The youngest player chooses one of
  two formats for the game:

* Whoever has the <span>smallest</span> pipe chain to 
  complete the task wins the round.
* Whoever has the <span>largest</span> pipe chain to 
  complete the task wins the round.

&gt; 1. The youngest player picks a task
  from the tasks card. You can not pick
  the same task twice.

&gt; 2. Shuffle the cards.

&gt; 3. Put the cards face down on the
  table.

&gt; 4. Going clockwise each player picks
  the top card from the deck and tries 
  to complete the task.

&gt; 5. The first player who completes the
  task gets a point.

&gt; 6. <span>IF</span> there are no more tasks, <span>GOTO</span> 8

&gt; 7. <span>GOTO</span> 1.

&gt; 8. GAME OVER. INSERT COIN. <span>GOTO</span> 8

TASKS

  * print the second line

  * print the second to last line

  * print the 7th line

  * print the most common line

  * print the least common line

  * count how many lines have "rises"

  * print the first line that has W in it

  * count the lines that have "in" in them

  * show two random lines

  * count the words on the last two lines

  * print the 7th and 8th line

  * count the lines with !

  * count the lines without !

  * make a command chain that does not
    print anything
</pre>

    This is how the card decks look:

    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/many-decks.jpg"><img src="https://punkx.org/unix-pipe-game/photos/many-decks.jpg" width="100%"></a>



    If you are a parent teaching your kid, and is exploring more tools to help you, I made few other card games:

    <p>
      <a target="_blank" href="https://punkjazz.org/programming-time/">
        <img src="https://punkjazz.org/programming-time/photos/b-800.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkjazz.org/programming-time/">Programming Time</a>, which is a game to teach python and some more fundamental algorithms, from hash tables to RSA
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/c-pointer-game/">
        <img src="https://punkx.org/c-pointer-game/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/c-pointer-game/">The C Pointer Game - Pointers, Arrays and Strings</a>, a game to teach kids to look at the computer memory and understand references and values
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/4917/">
        <img src="https://punkx.org/4917/photos/a.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/4917/">4917</a>, a game to teach kids machine code and how the CPU works with memory and registers
      </span>
    </p>


    <p>
      <a target="_blank" href="https://punkx.org/unix-pipe-game/ext-0.1">
        <img src="https://punkx.org/unix-pipe-game/ext-0.1/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/unix-pipe-game/ext-0.1">The Unix Pipes Game - Process Substitution</a>, an expansion of the Unix Pipes Game to teach process substitution and also: <code>paste, tr, cut, bc</code>
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/runlength-for-kids/">
        <img src="https://punkx.org/runlength-for-kids/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/runlength-for-kids/">RunLength Encoding for Kids</a>, small cards "game" to explain runlength encoding
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/punk0/">
        <img src="https://punkx.org/punk0/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/punk0/">PUNK0 - The Function Composition Card Game</a>, use cards to manipulate a list and use its values to win the game
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/overflow/">
        <img src="https://punkx.org/overflow/logo.svg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/overflow/">PROJEKT: OVERFLOW</a>, RISCV assembler boardgame
      </span>
    </p>


    <p>
      <a target="_blank" href="https://github.com/jackdoe/programming-for-kids/blob/master/book.md">
        <img src="https://punkx.org/github.png">
      </a>
      <span>
        <a target="_blank" href="https://github.com/jackdoe/programming-for-kids/blob/master/book.md">Programming for kids</a>, a log of my journey of teaching my daughter how to code
      </span>
    </p>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intent to End OCSP Service (311 pts)]]></title>
            <link>https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html</link>
            <guid>41046956</guid>
            <pubDate>Tue, 23 Jul 2024 15:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html">https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html</a>, See on <a href="https://news.ycombinator.com/item?id=41046956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<article>
		<p>Today we are announcing our intent to end <a href="https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">Online Certificate Status Protocol (OCSP)</a> support in favor of <a href="https://letsencrypt.org/2022/09/07/new-life-for-crls">Certificate Revocation Lists (CRLs)</a> as soon as possible. OCSP and CRLs are both mechanisms by which CAs can communicate certificate revocation information, but CRLs have significant advantages over OCSP. Let’s Encrypt has been providing an OCSP responder since our launch nearly ten years ago. We added support for CRLs in 2022.</p>
<p>Websites and people who visit them will not be affected by this change, but some non-browser software might be.</p>
<p>We plan to end support for OCSP primarily because it represents a considerable risk to privacy on the Internet. When someone visits a website using a browser or other software that checks for certificate revocation via OCSP, the Certificate Authority (CA) operating the OCSP responder immediately becomes aware of which website is being visited from that visitor’s particular IP address. Even when a CA intentionally does not retain this information, as is the case with Let’s Encrypt, CAs could be legally compelled to collect it. CRLs do not have this issue.</p>
<p>We are also taking this step because keeping our CA infrastructure as simple as possible is critical for the continuity of compliance, reliability, and efficiency at Let’s Encrypt. For every year that we have existed, operating OCSP services has taken up considerable resources that can soon be better spent on other aspects of our operations. Now that we support CRLs, our OCSP service has become unnecessary.</p>
<p>In August of 2023 the <a href="https://cabforum.org/">CA/Browser Forum</a> passed <a href="https://lists.cabforum.org/pipermail/servercert-wg/2023-September/003998.html">a ballot</a> to make providing OCSP services optional for publicly trusted CAs like Let’s Encrypt. With one exception, Microsoft, the root programs themselves no longer require OCSP. As soon as the <a href="https://learn.microsoft.com/en-us/security/trusted-root/program-requirements">Microsoft Root Program</a> also makes OCSP optional, which we are optimistic will happen within the next six to twelve months, Let’s Encrypt intends to announce a specific and rapid timeline for shutting down our OCSP services. We hope to serve our last OCSP response between three and six months after that announcement. The best way to stay apprised of updates on these plans is to <a href="https://community.letsencrypt.org/c/api-announcements/18">subscribe to our API Announcements</a> category on Discourse.</p>
<p>We recommend that anyone relying on OCSP services today start the process of ending that reliance as soon as possible. If you use Let’s Encrypt certificates to secure non-browser communications such as a VPN, you should ensure that your software operates correctly if certificates contain no OCSP URL. Fortunately, most OCSP implementations “fail open” which means that an inability to fetch an OCSP response will not break the system.</p>
<p><em><a href="https://abetterinternet.org/">Internet Security Research Group (ISRG)</a> is the parent organization of <a href="http://letsencrypt.org/">Let’s Encrypt</a>, <a href="http://memorysafety.org/">Prossimo</a>, and <a href="http://divviup.org/">Divvi Up</a>. ISRG is a 501(c)(3) nonprofit. If you’d like to support our work, please consider <a href="https://www.abetterinternet.org/getinvolved/">getting involved</a>, <a href="https://www.abetterinternet.org/donate/">donating</a>, or encouraging your company to <a href="https://www.abetterinternet.org/sponsor/">become a sponsor</a>.</em></p>

	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Source AI Is the Path Forward (1803 pts)]]></title>
            <link>https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/</link>
            <guid>41046773</guid>
            <pubDate>Tue, 23 Jul 2024 15:08:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/</a>, See on <a href="https://news.ycombinator.com/item?id=41046773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span>In the early days of high-performance computing, the major tech companies of the day each invested heavily in developing their own closed source versions of Unix. It was hard to imagine at the time that any other approach could develop such advanced software. Eventually though, open source Linux gained popularity – initially because it allowed developers to modify its code however they wanted and was more affordable, and over time because it became more advanced, more secure, and had a broader ecosystem supporting more capabilities than any closed Unix. Today, Linux is the industry standard foundation for both cloud computing and the operating systems that run most mobile devices – and we all benefit from superior products because of it.</span></p>
<p><span>I believe that AI will develop in a similar way. Today, several tech companies are developing leading closed models. But open source is quickly closing the gap. Last year, Llama 2 was only comparable to an older generation of models behind the frontier. This year, Llama 3 is competitive with the most advanced models and leading in some areas. Starting next year, we expect future Llama models to become the most advanced in the industry. But even before that, Llama is already leading on openness, modifiability, and cost efficiency.</span></p>
<p><span>Today we’re taking the next steps towards open source AI becoming the industry standard. We’re releasing Llama 3.1 405B, the first frontier-level open source AI model, as well as new and improved Llama 3.1 70B and 8B models. In addition to having significantly better cost/performance relative to closed models, the fact that the 405B model is open will make it the best choice for fine-tuning and distilling smaller models.</span></p>
<p><span>Beyond releasing these models, we’re working with a range of companies to grow the broader ecosystem. Amazon, Databricks, and Nvidia are launching full suites of services to support developers fine-tuning and distilling their own models. Innovators like Groq have built low-latency, low-cost inference serving for all the new models. The models will be available on all major clouds including AWS, Azure, Google, Oracle, and more. Companies like Scale.AI, Dell, Deloitte, and others are ready to help enterprises adopt Llama and train custom models with their own data. As the community grows and more companies develop new services, we can collectively make Llama the industry standard and bring the benefits of AI to everyone.</span></p>
<p><span>Meta is committed to open source AI. I’ll outline why I believe open source is the best development stack for you, why open sourcing Llama is good for Meta, and why open source AI is good for the world and therefore a platform that will be around for the long term.</span></p>
<h2><span>Why Open Source AI Is Good for Developers</span></h2>
<p><span>When I talk to developers, CEOs, and government officials across the world, I usually hear several themes:</span></p>
<ul>
<li><b>We need to train, fine-tune, and distill our own models.</b><span> Every organization has different needs that are best met with models of different sizes that are trained or fine-tuned with their specific data. On-device tasks and classification tasks require small models, while more complicated tasks require larger models. Now you’ll be able to take the most advanced Llama models, continue training them with your own data and then distill them down to a model of your optimal size – without us or anyone else seeing your data.</span></li>
<li><b>We need to control our own destiny and not get locked into a closed vendor.</b><span> Many organizations don’t want to depend on models they cannot run and control themselves. They don’t want closed model providers to be able to change their model, alter their terms of use, or even stop serving them entirely. They also don’t want to get locked into a single cloud that has exclusive rights to a model. Open source enables a broad ecosystem of companies with compatible toolchains that you can move between easily.&nbsp;</span></li>
<li><b>We need to protect our data.</b><span> Many organizations handle sensitive data that they need to secure and can’t send to closed models over cloud APIs. Other organizations simply don’t trust the closed model providers with their data. Open source addresses these issues by enabling you to run the models wherever you want. It is well-accepted that open source software tends to be more secure because it is developed more transparently.</span></li>
<li><b>We need a model that is efficient and affordable to run. </b><span>Developers can run inference on Llama 3.1 405B on their own infra at roughly 50% the cost of using closed models like GPT-4o, for both user-facing and offline inference tasks.</span></li>
<li><b>We want to invest in the ecosystem that’s going to be the standard for the long term.</b><span> Lots of people see that open source is advancing at a faster rate than closed models, and they want to build their systems on the architecture that will give them the greatest advantage long term.&nbsp;</span></li>
</ul>
<h2><span>Why Open Source AI Is Good for Meta</span></h2>
<p><span>Meta’s business model is about building the best experiences and services for people. To do this, we must ensure that we always have access to the best technology, and that we’re not locking into a competitor’s closed ecosystem where they can restrict what we build.</span></p>
<p><span>One of my formative experiences has been building our services constrained by what Apple will let us build on their platforms. Between the way they tax developers, the arbitrary rules they apply, and all the product innovations they block from shipping, it’s clear that Meta and many other companies would be freed up to build much better services for people if we could build the best versions of our products and competitors were not able to constrain what we could build. On a philosophical level, this is a major reason why I believe so strongly in building open ecosystems in AI and AR/VR for the next generation of computing.</span></p>
<p><span>People often ask if I’m worried about giving up a technical advantage by open sourcing Llama, but I think this misses the big picture for a few reasons:</span></p>
<p><span>First, to ensure that we have access to the best technology and aren’t locked into a closed ecosystem over the long term, Llama needs to develop into a full ecosystem of tools, efficiency improvements, silicon optimizations, and other integrations. If we were the only company using Llama, this ecosystem wouldn’t develop and we’d fare no better than the closed variants of Unix.</span></p>
<p><span>Second, I expect AI development will continue to be very competitive, which means that open sourcing any given model isn’t giving away a massive advantage over the next best models at that point in time. The path for Llama to become the industry standard is by being consistently competitive, efficient, and open generation after generation.</span></p>
<p><span>Third, a key difference between Meta and closed model providers is that selling access to AI models isn’t our business model. That means openly releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.)</span></p>
<p><span>Finally, Meta has a long history of open source projects and successes. We’ve saved billions of dollars by releasing our server, network, and data center designs with Open Compute Project and having supply chains standardize on our designs. We benefited from the ecosystem’s innovations by open sourcing leading tools like PyTorch, React, and many more tools. This approach has consistently worked for us when we stick with it over the long term.</span></p>
<h2><span>Why Open Source AI Is Good for the World</span></h2>
<p><span>I believe that open source is necessary for a positive AI future. AI has more potential than any other modern technology to increase human productivity, creativity, and quality of life – and to accelerate economic growth while unlocking progress in medical and scientific research. Open source will ensure that more people around the world have access to the benefits and opportunities of AI, that power isn’t concentrated in the hands of a small number of companies, and that the technology can be deployed more evenly and safely across society.</span></p>
<p><span>There is an ongoing debate about the safety of open source AI models, and my view is that open source AI will be safer than the alternatives. I think governments will conclude it’s in their interest to support open source because it will make the world more prosperous and safer.</span></p>
<p><span>My framework for understanding safety is that we need to protect against two categories of harm: unintentional and intentional. Unintentional harm is when an AI system may cause harm even when it was not the intent of those running it to do so. For example, modern AI models may inadvertently give bad health advice. Or, in more futuristic scenarios, some worry that models may unintentionally self-replicate or hyper-optimize goals to the detriment of humanity. Intentional harm is when a bad actor uses an AI model with the goal of causing harm.</span></p>
<p><span>It’s worth noting that unintentional harm covers the majority of concerns people have around AI – ranging from what influence AI systems will have on the billions of people who will use them to most of the truly catastrophic science fiction scenarios for humanity. On this front, open source should be significantly safer since the systems are more transparent and can be widely scrutinized. Historically, open source software has been more secure for this reason. Similarly, using Llama with its safety systems like Llama Guard will likely be safer and more secure than closed models. For this reason, most conversations around open source AI safety focus on intentional harm.</span></p>
<p><span>Our safety process includes rigorous testing and red-teaming to assess whether our models are capable of meaningful harm, with the goal of mitigating risks before release. Since the models are open, anyone is capable of testing for themselves as well. We must keep in mind that these models are trained by information that’s already on the internet, so the starting point when considering harm should be whether a model can facilitate more harm than information that can quickly be retrieved from Google or other search results.&nbsp;</span></p>
<p><span>When reasoning about intentional harm, it’s helpful to distinguish between what individual or small scale actors may be able to do as opposed to what large scale actors like nation states with vast resources may be able to do.</span></p>
<p><span>At some point in the future, individual bad actors may be able to use the intelligence of AI models to fabricate entirely new harms from the information available on the internet. At this point, the balance of power will be critical to AI safety. I think it will be better to live in a world where AI is widely deployed so that larger actors can check the power of smaller bad actors. This is how we’ve managed security on our social networks – our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. More broadly, larger institutions deploying AI at scale will promote security and stability across society. As long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute.&nbsp;</span></p>
<p><span>The next question is how the US and democratic nations should handle the threat of states with massive resources like China. The United States’ advantage is decentralized and open innovation. Some people argue that we must close our models to prevent China from gaining access to them, but my view is that this will not work and will only disadvantage the US and its allies. Our adversaries are great at espionage, stealing models that fit on a thumb drive is relatively easy, and most tech companies are far from operating in a way that would make this more difficult. It seems most likely that a world of only closed models results in a small number of big companies plus our geopolitical adversaries having access to leading models, while startups, universities, and small businesses miss out on opportunities. Plus, constraining American innovation to closed development increases the chance that we don’t lead at all. Instead, I think our best strategy is to build a robust open ecosystem and have our leading companies work closely with our government and allies to ensure they can best take advantage of the latest advances and achieve a sustainable first-mover advantage over the long term.</span></p>
<p><span>When you consider the opportunities ahead, remember that most of today’s leading tech companies and scientific research are built on open source software. The next generation of companies and research will use open source AI if we collectively invest in it. That includes startups just getting off the ground as well as people in universities and countries that may not have the resources to develop their own state-of-the-art AI from scratch.</span></p>
<p><span>The bottom line is that open source AI represents the world’s best shot at harnessing this technology to create the greatest economic opportunity and security for everyone.</span></p>
<h2><span>Let’s Build This Together</span></h2>
<p><span>With past Llama models, Meta developed them for ourselves and then released them, but didn’t focus much on building a broader ecosystem. We’re taking a different approach with this release. We’re building teams internally to enable as many developers and partners as possible to use Llama, and we’re actively building partnerships so that more companies in the ecosystem can offer unique functionality to their customers as well.&nbsp;</span></p>
<p><span>I believe the Llama 3.1 release will be an inflection point in the industry where most developers begin to primarily use open source, and I expect that approach to only grow from here. I hope you’ll join us on this journey to bring the benefits of AI to everyone in the world.</span></p>
<p><span>You can access the models now at <a href="https://llama.meta.com/">llama.meta.com</a>.&nbsp;</span></p>
<p><span>💪,&nbsp;</span></p>
<p><span>MZ</span></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.1 Official Launch (374 pts)]]></title>
            <link>https://llama.meta.com/</link>
            <guid>41046540</guid>
            <pubDate>Tue, 23 Jul 2024 14:47:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://llama.meta.com/">https://llama.meta.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41046540">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A free tool to quickly detect counterfeit flash (2017) (171 pts)]]></title>
            <link>https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix</link>
            <guid>41046397</guid>
            <pubDate>Tue, 23 Jul 2024 14:34:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix">https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix</a>, See on <a href="https://news.ycombinator.com/item?id=41046397">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
            
  <div id="f3-fight-flash-fraud">

<p>f3 is a simple tool that tests flash cards capacity and performance to
see if they live up to claimed specifications. It fills the device with
pseudorandom data and then checks if it returns the same on reading.</p>
<p>F3 stands for Fight Flash Fraud, or Fight Fake Flash.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#examples">Examples</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#other-resources">Other resources</a></li>
</ul>
</div>
<div id="examples-1">
<h2>Examples<a href="#examples-1" title="Permalink to this headline">¶</a></h2>
<p>We’ll use <code><span>/dev/sdX</span></code> as a placeholder here, you need to replace
<code><span>X</span></code> with a lowercase letter so that it matches the device you
want to use.
<code><span>lsblk</span></code> will show you an overview of your current devices.</p>
<div id="testing-performance-with-f3read-f3write">
<h2>Testing performance with f3read/f3write<a href="#testing-performance-with-f3read-f3write" title="Permalink to this headline">¶</a></h2>
<p>Use these two programs in this order. f3write will write large files to
your mounted disk and f3read will check if the flash disk contains
exactly the written files:</p>
<div><pre><span></span>$ ./f3write /media/michel/5EBD-5C80/
$ ./f3read /media/michel/5EBD-5C80/
</pre></div>
<p>Please replace “/media/michel/5EBD-5C80/” with the appropriate path. USB
devices are mounted in “/Volumes” on Macs.</p>
<p>If you have installed f3read and f3write, you can remove the “./” that
is shown before their names.</p>
</div>
<div id="quick-capacity-tests-with-f3probe">
<h2>Quick capacity tests with f3probe<a href="#quick-capacity-tests-with-f3probe" title="Permalink to this headline">¶</a></h2>
<p>f3probe is the fastest drive test and suitable for large disks because
it only writes what’s necessary to test the drive. It operates directly
on the (unmounted) block device and needs to be run as a privileged
user:</p>
<div><pre><span></span><span># ./f3probe --destructive --time-ops /dev/sdX</span>
</pre></div>
<div>
<p>Warning</p>
<p>This will destroy any previously stored data on your disk!</p>
</div>
</div>
<div id="correcting-capacity-to-actual-size-with-f3fix">
<h2>Correcting capacity to actual size with f3fix<a href="#correcting-capacity-to-actual-size-with-f3fix" title="Permalink to this headline">¶</a></h2>
<p>f3fix creates a partition that fits the actual size of the fake drive.
Use f3probe’s output to determine the parameters for f3fix:</p>
<div><pre><span></span><span># ./f3fix --last-sec=16477878 /dev/sdX</span>
</pre></div>
</div>
</div>
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<div id="download-and-compile">
<h2>Download and Compile<a href="#download-and-compile" title="Permalink to this headline">¶</a></h2>
<p>The files of the stable version of F3 are
<a href="https://github.com/AltraMayor/f3/tags">here</a>. The
following command uncompresses the files:</p>

</div>
<div id="compile-stable-software-on-linux-or-freebsd">
<h2>Compile stable software on Linux or FreeBSD<a href="#compile-stable-software-on-linux-or-freebsd" title="Permalink to this headline">¶</a></h2>
<p>To build:</p>

<p>If you want to install f3write and f3read, run the following command:</p>

</div>
<div id="compile-stable-software-on-windows-cygwin">
<h2>Compile stable software on Windows/Cygwin<a href="#compile-stable-software-on-windows-cygwin" title="Permalink to this headline">¶</a></h2>
<p>f3write and f3read can be installed on Windows, but currently f3probe, f3fix,
and f3brew <a href="#the-extra-applications-for-linux">require Linux</a>.  To use them
on a Windows machine, use the <a href="#docker">Docker Installation</a>.  For f3write
and f3read, read on.</p>
<p>If you haven’t already, install the following Cygwin packages and their dependencies:</p>
<ul>
<li><cite>gcc-core</cite></li>
<li><cite>make</cite></li>
<li><cite>libargp-devel</cite></li>
</ul>
<p>To build, you need special flags:</p>
<div><pre><span></span><span>export</span> <span>LDFLAGS</span><span>=</span><span>"</span><span>$LDFLAGS</span><span> -Wl,--stack,4000000 -largp"</span>
make
</pre></div>
<p>If you want to install f3write and f3read, run the following command:</p>

</div>
<div id="compile-stable-software-on-apple-mac">
<h2>Compile stable software on Apple Mac<a href="#compile-stable-software-on-apple-mac" title="Permalink to this headline">¶</a></h2>
<p>f3write and f3read can be installed on Mac, but currently f3probe, f3fix, and
f3brew <a href="#the-extra-applications-for-linux">require Linux</a>.  To use them on
Mac, use the <a href="#docker">Docker Installation</a>.  For f3write and f3read, read
on.</p>
<div id="using-homebrew">
<h3>Using HomeBrew<a href="#using-homebrew" title="Permalink to this headline">¶</a></h3>
<p>If you have Homebrew already installed in your computer, the command
below will install F3:</p>

</div>
<div id="using-macports">
<h3>Using MacPorts<a href="#using-macports" title="Permalink to this headline">¶</a></h3>
<p>If you use MacPorts instead, use the following command:</p>

</div>

</div>
<div id="docker">
<h2>Docker<a href="#docker" title="Permalink to this headline">¶</a></h2>
<div id="quick-start">
<h3>Quick Start<a href="#quick-start" title="Permalink to this headline">¶</a></h3>
<p>A pre-built <a href="https://cloud.docker.com/repository/docker/peron/f3">image</a>
is available over at Docker Hub, ready to be used.  With docker started, just
run:</p>
<div><pre><span></span>docker run -it --rm --device &lt;device&gt; peron/f3 &lt;f3-command&gt; <span>[</span>&lt;f3-options&gt;<span>]</span> &lt;device&gt;
</pre></div>
<p>For example, to probe a drive mounted at /dev/sdX:</p>
<div><pre><span></span>docker run -it --rm --device /dev/sdX peron/f3 f3probe --destructive --time-ops /dev/sdX
</pre></div>
<p>Optionally, you can also build your own container <em>if</em> you don’t want to use the
pre-built image.  From this directory, run:</p>

<p>or:</p>
<div><pre><span></span>docker build -t f3:latest .
</pre></div>
<p>To run f3 commands using your newly built Docker image:</p>
<div><pre><span></span>docker run -it --rm --device &lt;device&gt; f3:latest &lt;f3-command&gt; <span>[</span>&lt;f3-options&gt;<span>]</span> &lt;device&gt;

docker run -it --rm --device /dev/sdX f3:latest f3probe --destructive --time-ops /dev/sdX
docker run -it --rm -v /path/to/mounted/device:/mnt/ f3:latest f3write /mnt/
docker run -it --rm -v /path/to/mounted/device:/mnt/ f3:latest f3read /mnt/
</pre></div>
</div>
<div id="drive-permissions-passthrough">
<h3>Drive Permissions / Passthrough<a href="#drive-permissions-passthrough" title="Permalink to this headline">¶</a></h3>
<p>Getting the drive device to map into the Docker container is tricky for Mac and
Windows.  Passing through devices on Mac and Windows is a well-documented issue
(<a href="https://github.com/docker/for-mac/issues/3110#issuecomment-456853036">[github]</a>
<a href="https://devops.stackexchange.com/questions/4572/how-to-pass-a-dev-disk-device-on-macos-into-linux-docker/6076#6076">[stackexchange]</a>
<a href="https://christopherjmcclellan.wordpress.com/2019/04/21/using-usb-with-docker-for-mac/#tldr">[tty]</a>)
On Linux it should just work, but on Mac or Windows, Docker tends to map the
drive as a normal directory rather than a mounted drive and you will get an
error like <code><span>f3probe:</span> <span>Can't</span> <span>open</span> <span>device</span> <span>'/opt/usb':</span> <span>Is</span> <span>a</span> <span>directory</span></code>, that
is if you can map it at all.</p>
<p>To solve this, we can use docker-machine to create a VirtualBox VM
(boot2docker), in which to run the Docker container.  Since VirtualBox <em>can</em>
handle device pass-through, we can pass the device through to the VirtualBox VM
which can then pass the device through to the Docker container.  Milad Alizadeh
wrote up some good instructions <a href="https://mil.ad/blog/2018/access-usb-devices-in-container-in-mac.html">here</a>
which are geared towards USB devices, but it shouldn’t be too hard to adapt to
other drive types.  Here’s what I typed into my Mac terminal (probably
similar for Windows, but untested):</p>
<div><pre><span></span>docker-machine create -d virtualbox default
docker-machine stop
vboxmanage modifyvm default --usb on
docker-machine start
vboxmanage usbfilter add <span>0</span> --target default --name flashdrive --vendorid 0x0123 --productid 0x4567
<span>eval</span> <span>$(</span>docker-machine env default<span>)</span>
</pre></div>
<p>For the usbfilter add command, note that the “name” argument is the new name
you’re giving the filter so you can name it whatever you want.
<code><span>--vendorid</span></code> and <code><span>--productid</span></code> can be found on Mac in “System
Information” under “USB”. You can also try searching for the right device in
<code><span>vboxmanage</span> <span>list</span> <span>usbhost</span></code>.</p>
<p>Alternatively, you may opt to add the device through the VirtualBox GUI
application instead:</p>
<div><pre><span></span>docker-machine create -d virtualbox default
docker-machine stop
<span># open VirtualBox and manually add the drive device before proceeding to the next command</span>
docker-machine start
<span>eval</span> <span>$(</span>docker-machine env default<span>)</span>
</pre></div>
<p>Once you’ve run the above commands, unplug and replug the flash drive and run:</p>
<div><pre><span></span>docker-machine ssh default <span>"lsblk"</span>
</pre></div>
<p>to list the devices. Search for the correct drive - the “SIZE” column may be
helpful in locating the device of interest. For example, <code><span>sdb</span></code> is a common
mount point for a USB drive.  Now you should be able to run the command from
Quick Start:</p>
<div><pre><span></span>docker run --rm -it --device /dev/sdX peron/f3 f3probe --destructive --time-ops /dev/sdX
</pre></div>
<p>You may find it useful to enter a bash prompt in the Docker container to poke
around the filesystem:</p>
<div><pre><span></span>docker run --rm -it --device /dev/sdX peron/f3 bash
</pre></div>
<p>so that you can run commands like <code><span>ls</span> <span>/dev/*</span></code>.</p>
</div>
</div>

</div>
<div id="other-resources">
<h2>Other resources<a href="#other-resources" title="Permalink to this headline">¶</a></h2>
<div id="graphical-user-interfaces">
<h2>Graphical User Interfaces<a href="#graphical-user-interfaces" title="Permalink to this headline">¶</a></h2>
<p>Thanks to our growing community of flash fraud fighters,
we have the following graphical user interfaces (GUI) available for F3:</p>
<p><a href="https://github.com/zwpwjwtz/f3-qt">F3 QT</a> is a Linux GUI that uses
QT. F3 QT supports <code><span>f3write</span></code>, <code><span>f3read</span></code>, <code><span>f3probe</span></code>, and <code><span>f3fix</span></code>. Author:
Tianze.</p>
<p><a href="https://github.com/vrunkel/F3XSwift">F3XSwift</a> is a Mac GUI. F3XSwift supports <code><span>f3write</span></code> and <code><span>f3read</span></code>. Author:
Volker Runkel.</p>
<p>Please support the above projects by testing them and giving feedback to their
authors. This will improve their code as it has improved mine.</p>
</div>
<div id="files">
<h2>Files<a href="#files" title="Permalink to this headline">¶</a></h2>
<div><pre><span></span>changelog   - Change log <span>for</span> package maintainers
f3read.1    - Man page <span>for</span> f3read and f3write
            In order to <span>read</span> this manual page, run <span>`</span>man ./f3read.1<span>`</span>
            To install the page, run
            <span>`</span>install --owner<span>=</span>root --group<span>=</span>root --mode<span>=</span><span>644</span> f3read.1 /usr/share/man/man1<span>`</span>
LICENSE     - License <span>(</span>GPLv3<span>)</span>
Makefile    - make<span>(</span><span>1</span><span>)</span> file
README      - This file
*.h and *.c - C code of F3
</pre></div>
</div>
<div id="bash-scripts">
<h2>Bash scripts<a href="#bash-scripts" title="Permalink to this headline">¶</a></h2>
<p>Although the simple scripts listed in this section are ready for use,
they are really meant to help you to write your own scripts. So you can
personalize F3 to your specific needs:</p>
<div><pre><span></span>f3write.h2w - Script to create files exactly like H2testw.
    Use example: <span>`</span>f3write.h2w /media/michel/5EBD-5C80/<span>`</span>

log-f3wr    - Script that runs f3write and f3read, and records
              their output into a log file.
    Use example: <span>`</span>log-f3wr log-filename /media/michel/5EBD-5C80/<span>`</span>
</pre></div>
<p>Please notice that all scripts and use examples above assume that
f3write, f3read, and the scripts are in the same folder.</p>
</div>
<div id="flakyflash">
<h2>Flakyflash<a href="#flakyflash" title="Permalink to this headline">¶</a></h2>
<p>If your flash isn’t fraudulent (or you’ve run f3fix to “fix” it) but
you’re still seeing some sporadic data corruption, then you may have
“flaky flash.” If your flash is formatted using the FAT file system,
then you can use <a href="https://github.com/whitslack/flakyflash">Flakyflash</a>
to find the flaky data clusters and mark them as bad in the FAT. This
may allow you to get a little more use out of your flash, but you
should still consider it as failing and replace it ASAP.</p>
</div>
</div>


          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trunk: Build, bundle and ship your Rust WASM application to the web (101 pts)]]></title>
            <link>https://trunkrs.dev/</link>
            <guid>41046226</guid>
            <pubDate>Tue, 23 Jul 2024 14:15:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trunkrs.dev/">https://trunkrs.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=41046226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p>Overview</p>
            <p>Trunk is a WASM web application bundler for Rust. Trunk uses a simple, optional-config pattern for building &amp; bundling WASM, JS snippets &amp; other assets (images, css, scss) via a source HTML file.</p>
<h2 id="getting-started">Getting Started</h2>
<h2 id="install">Install</h2>
<p>First, install Trunk via one of the following options.</p>
<h3 id="plain-cargo">Plain cargo</h3>
<p>Download the sources and build them yourself:</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo install --locked trunk
</span></code></pre>
<p>You can also toggle some features using the <code>--features</code> flag:</p>
<dl>
<dt><code>rustls</code> (default)</dt><dd>Use rustls for client and server sockets</dd>
<dt><code>native-tls</code></dt><dd>Enable the use of the system native TLS stack for client sockets, and `openssl` for server sockets</dd>
<dt><code>update_check</code> (default)</dt><dd>Enable the update check on startup</dd>
</dl>
<p><strong>NOTE:</strong> If both <code>rustls</code> and <code>native-tls</code> are enabled, <code>rustls</code> will be used. You can disable the default <code>rustls</code> using
<code>--no-default-features</code>.</p>
<h3 id="cargo-binstall">Cargo binstall</h3>
<p>You can download a released binary from GitHub releases through <a href="https://github.com/cargo-bins/cargo-binstall"><code>binstall</code></a>.</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo binstall trunk
</span></code></pre>
<h3 id="github-release-download">GitHub release download</h3>
<p>Fetch and unpack a released binary from the <a href="https://github.com/trunk-rs/trunk/releases">release page</a>.</p>
<p>For example (be sure to check for the most recent version):</p>
<pre data-lang="bash"><code data-lang="bash"><span>wget -qO- https://github.com/trunk-rs/trunk/releases/download/0.17.10/trunk-x86_64-unknown-linux-gnu.tar.gz </span><span>| </span><span>tar -xzf-
</span></code></pre>
<h3 id="nixos">NixOS</h3>
<pre data-lang="bash"><code data-lang="bash"><span>nix-env -i trunk
</span></code></pre>
<h3 id="brew">Brew</h3>
<pre data-lang="bash"><code data-lang="bash"><span>brew install trunk
</span></code></pre>

<p>Any additional tools like <code>wasm-bindgen</code> and <code>wasm-opt</code> are automatically downloaded and managed by trunk. Therefore, no further steps required 🎉.</p>
<p><strong>Note:</strong> Until <code>wasm-bindgen</code> has pre-built binaries for Apple M1, M1 users will need to install <code>wasm-bindgen</code> manually.</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo install --locked wasm-bindgen-cli
</span></code></pre>
<h2 id="app-setup">App Setup</h2>
<p>Any <code>wasm-bindgen</code>-based framework will work with Trunk. If you're new to <a href="https://github.com/flosse/rust-web-framework-comparison#frontend-frameworks-wasm">frontend development in Rust</a>, <a href="https://yew.rs/">Yew</a> and <a href="https://leptos.dev/">Leptos</a> are two popular options.</p>
<p>The easiest way to ensure that your application launches properly is to <a href="https://doc.rust-lang.org/cargo/guide/project-layout.html">setup your app as an executable</a> with a standard <code>main</code> function:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>main</span><span>() {
</span><span>    </span><span>// ... your app setup code here ...
</span><span>}
</span></code></pre>
<p>Trunk uses a source HTML file to drive all asset building and bundling. Trunk also uses the official <a href="https://github.com/sass/dart-sass">dart-sass</a>, so let's get started with the following example. Copy this HTML to the root of your project's repo as <code>index.html</code>:</p>
<pre data-lang="html"><code data-lang="html"><span>&lt;</span><span>html</span><span>&gt;
</span><span>  &lt;</span><span>head</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>data-trunk rel</span><span>=</span><span>"scss" </span><span>href</span><span>=</span><span>"path/to/index.scss"</span><span>/&gt;
</span><span>  &lt;/</span><span>head</span><span>&gt;
</span><span>&lt;/</span><span>html</span><span>&gt;
</span></code></pre>
<p><code>trunk build</code> will produce the following HTML at <code>dist/index.html</code>, along with the compiled scss, WASM &amp; the JS loader for the WASM:</p>
<pre data-lang="html"><code data-lang="html"><span>&lt;</span><span>html</span><span>&gt;
</span><span>  &lt;</span><span>head</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"stylesheet" </span><span>href</span><span>=</span><span>"/index-c920ca43256fdcb9.css"</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"preload" </span><span>href</span><span>=</span><span>"/index-7eeee8fa37b7636a_bg.wasm" </span><span>as</span><span>=</span><span>"fetch" </span><span>type</span><span>=</span><span>"application/wasm" </span><span>crossorigin</span><span>=</span><span>""</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"modulepreload" </span><span>href</span><span>=</span><span>"/index-7eeee8fa37b7636a.js"</span><span>&gt;
</span><span>  &lt;/</span><span>head</span><span>&gt;
</span><span>  &lt;</span><span>body</span><span>&gt;
</span><span>    &lt;</span><span>script </span><span>type</span><span>=</span><span>"module"</span><span>&gt;
</span><span>      </span><span>import </span><span>init, </span><span>* </span><span>as </span><span>bindings </span><span>from </span><span>'/index-7eeee8fa37b7636a.js'</span><span>;
</span><span>      </span><span>window</span><span>.wasmBindings </span><span>= </span><span>bindings;
</span><span>      init(</span><span>'/index-7eeee8fa37b7636a_bg.wasm'</span><span>);
</span><span>    &lt;/</span><span>script</span><span>&gt;
</span><span>  &lt;/</span><span>body</span><span>&gt;
</span><span>&lt;/</span><span>html</span><span>&gt;
</span></code></pre>
<p>The contents of your <code>dist</code> dir are now ready to be served on the web.</p>
<h2 id="next-steps">Next Steps</h2>
<p>That's not all! Trunk has even more useful features. Head on over to the following sections to learn more about how to use Trunk effectively.</p>
<ul>
<li><a href="https://trunkrs.dev/assets/">Assets</a>: learn about all of Trunk's supported asset types.</li>
<li><a href="https://trunkrs.dev/configuration/">Configuration</a>: learn about Trunk's configuration system and how to use the Trunk proxy.</li>
<li><a href="https://trunkrs.dev/commands/">Commands</a>: learn about Trunk's CLI commands for use in your development workflows.</li>
<li><a href="https://trunkrs.dev/advanced/">Advanced topics</a>: learn about some more advanced topics.</li>
<li>Join us on Discord by following this link <a href="https://discord.gg/JEPdBujTDr"><img src="https://img.shields.io/discord/793890238267260958?logo=discord&amp;style=flat-square" alt="" title="Discord Chat"></a></li>
</ul>
<h2 id="contributing">Contributing</h2>
<p>Anyone and everyone is welcome to contribute! Please review the <a href="https://github.com/trunk-rs/trunk/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> document for more details. The best way to get started is to find an open issue, and then start hacking on implementing it. Letting other folks know that you are working on it, and sharing progress is a great approach. Open pull requests early and often, and please use GitHub's draft pull request feature.</p>
<h2 id="license">License</h2>
<p><span><img src="https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?style=flat-square" alt="license badge"></span>
<br>
trunk is licensed under the terms of the MIT License or the Apache License 2.0, at your choosing.</p>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Briefer – multiplayer notebooks with schedules, SQL, and built-in LLMs (157 pts)]]></title>
            <link>https://briefer.cloud/launches/notebooks/</link>
            <guid>41045834</guid>
            <pubDate>Tue, 23 Jul 2024 13:30:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://briefer.cloud/launches/notebooks/">https://briefer.cloud/launches/notebooks/</a>, See on <a href="https://news.ycombinator.com/item?id=41045834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="the-file-tree"><h2>The file tree</h2><div><article><p><strong>The file tree is where you can manage your notebooks and navigate through them.</strong></p>
<p>Like in Notion, you can choose icons for each notebook, reorder them, or put one inside another. That way, you can organize your notebooks in a way that makes sense to you and your team.</p>
<p>Additionally, whenever you delete a notebook, we keep a copy in the trash so you can restore it if needed.</p>
</article></div></div><div id="blocks-and-tabs"><h2>Blocks and tabs</h2><div><article><p><strong>Briefer notebooks are made of blocks of different types.</strong></p>
<p>Each block has a specific purpose and performs different tasks.</p>
<ul>
<li><strong>Text blocks</strong> are for you to add context to your notebook.</li>
<li><strong>Query blocks</strong> are for you to gather data from files or connected data sources, like Postgres, BigQuery, Redshift, Athena, and others.</li>
<li><strong>File upload blocks</strong> are for you to add CSV, XLS, or other files to your notebook in case your data is not in a connected data source.</li>
<li><strong>Python blocks</strong> are for you to write Python code to manipulate data, create visualizations, or do whatever else you want.</li>
<li><strong>Input blocks</strong> are for you to add interactive elements to your notebook, like text inputs or dropdowns.</li>
<li><strong>Visualization blocks</strong> are for you to create visualizations without writing any code.</li>
</ul>
<p><strong>After adding blocks to your notebook, you can group them into tabs to organize your notebook and make it easier to navigate through.</strong></p>
</article></div></div><div id="files-and-databases"><h2>Files and databases</h2><div><article><p><strong>You can use query blocks to query data from files and databases without having to write wrappers or connectors.</strong></p>
<p>If your data is in a database, you can use query blocks to write SQL queries and get the data you need.</p>
<p>In case your data is in a file (CSV, XLSX, Parquet, or others), you can upload that file and query it using regular SQL.</p>
<p>Briefer's query blocks also allow you to query dataframes using regular SQL.</p>
</article></div></div><div id="automatic-dataframes"><h2>Automatic dataframes</h2><div><article><p><strong>Every query block automatically creates a Pandas dataframe containing the query's result.</strong></p>
<p>This way, you can use this data in further Python blocks.</p>
<p>Let's say you want to plot your app's signups per month.</p>
<p>To do that, you can start by using a query block to fetch the signups from your database. This query block will automatically create a dataframe containing the query's results.</p>
<p>Then, you can use this dataframe in Python blocks to aggregate the data by month and create a plot using <code>matplotlib</code> or <code>seaborn</code>, for example.</p>
<p>By default, dataframes have names like <code>query_1</code>, but you can rename them to something more meaningful.</p>
</article></div></div><div id="ai-assistant"><h2>AI Assistant</h2><div><article><p>SQL and Python blocks include an AI assistant.</p>
<p>Whenever you want the AI assistant's help, you can click "edit with AI" and tell it what you want to do.</p>
<p>Then, the AI assistant will come up with a suggestion and show you a diff that you can try, accept, or reject.</p>
<p>In the Python block, the AI assistant is aware of the existing dataframes and its columns.</p>
<p>In the SQL block, the AI assistant already knows the tables and columns in your database, so it can give better suggestions and help you get complex queries right.</p>
<p>Whenever an error comes up, you can click "Fix with AI" to get the AI assistant to try to fix it for you.</p>
</article></div></div><div id="schedules"><h2>Schedules</h2><div><article><p><strong>You can schedule your notebooks to run at a specific interval, like every hour, every day, every week, or every month.</strong></p>
<p>Let's say you're working on a notebook that fetches live data from a database and creates a detailed report with leads generated by your marketing campaigns.</p>
<p>In that case, you can schedule this notebook to run every day at 8:00 AM, so you have the report ready for your sales team when they start their day.</p>
<p>When creating schedules, you can also set up notifications to receive an email or Slack message when the schedule runs successfully or fails. In the case of successful runs you will also receive a PDF file with the notebook's outputs.</p>
</article></div></div><div id="snapshots-versioning"><div><h2>Snapshots and versioning</h2><div><article><p><strong>Whenever you publish a notebook, we automatically save the notebook's state so you can see the changes over time and roll back to previous versions if needed.</strong></p>
<p>This way, you can keep track of the changes you make to your notebooks and revert to a previous version if something goes wrong.</p>
<p><strong>Additionally, every successful scheduled run creates a snapshot of the notebook's state at that time.</strong></p>
<p>Snapshots are useful when you want to see how results changed over time or compare the outputs of different runs.</p>
</article></div></div><div><p><span>snapshots_and_versioning.mp4</span></p></div></div><div id="notebooks-to-dashboards"><div><h2>Notebooks to dashboards</h2><div><article><p><strong>You can use your notebook's outputs to create dashboards.</strong></p>
<p>This way, you can share results with others without including unnecessary code or explanations, like when you have to do a lot of data wrangling before plotting a chart.</p>
<p>Dashboard views are also useful for building data apps, where you want to allow users to interact with inputs and dropdowns but don't want them to see the code behind the scenes.</p>
</article></div></div><div><p><span>notebooks_to_dashboards.mp4</span></p></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>