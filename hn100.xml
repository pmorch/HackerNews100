(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Mar 2025 17:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Chaos in the Cloudflare Lisbon Office (119 pts)]]></title>
            <link>https://blog.cloudflare.com/chaos-in-cloudflare-lisbon-office-securing-the-internet-with-wave-motion/</link>
            <guid>43389064</guid>
            <pubDate>Mon, 17 Mar 2025 14:38:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/chaos-in-cloudflare-lisbon-office-securing-the-internet-with-wave-motion/">https://blog.cloudflare.com/chaos-in-cloudflare-lisbon-office-securing-the-internet-with-wave-motion/</a>, See on <a href="https://news.ycombinator.com/item?id=43389064">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><h2>Chaos in Cloudflare’s Lisbon office: securing the Internet with wave motion</h2><p>2025-03-17</p><section><p>7 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2J0BiaLyDMtbEcZrETkdWu/26d0ae2c2dd564138723922bd9612dec/image1.png" alt=""><div><p>Over the years, Cloudflare has gained fame for many things, including our technical blog, but also as <a href="https://www.wired.com/story/cloudflare-lava-lamps-protect-from-hackers/"><u>a tech company securing the Internet using </u><b><u>lava lamps</u></b></a>, a story that began as a research/science project almost 10 years ago. In March 2025, we added another layer to its legacy: a "wall of entropy" made of 50 <b>wave machines </b>in constant motion at our Lisbon office, the company's European HQ.&nbsp;</p><p>These wave machines are a new source of entropy, joining <b>lava lamps</b> in San Francisco, <b>suspended rainbows</b> in Austin, and <b>double chaotic pendulums </b>in London. The entropy they generate contributes to securing the Internet <a href="#lavarand-origins-and-walls-of-entropy"><u>through LavaRand</u></a>.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6sp4ZXYnpwUGAabVB0fRKW/f56edd916efeb49173c623e99b87bc70/DSC00336.JPG" alt="" width="3104" height="2064" loading="lazy">
          </figure>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1D1cayhBpPyuUNKV4JCcvF/e6d493a71e41c3622dd4f895505a3f43/DSC00450.JPG" alt="" width="3104" height="2064" loading="lazy">
          </figure>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/EE2gOFRrXCGM5ASh3uCl7/b282e0ed651cb5c354b183bc33aff116/image4.jpg" alt="" width="1999" height="1330" loading="lazy">
          </figure><p><sup><i>The new waves wall at Cloudflare’s Lisbon office sits beside the Radar Display of global Internet insights, with the 25th of April Bridge overlooking the Tagus River in the background.</i></sup></p><p>It’s exciting to see waves in Portugal now playing a role in keeping the Internet secure, especially given Portugal’s deep maritime history.</p><p>The installation honors Portugal’s passion for the sea and exploration of the unknown, famously beginning over 600 years ago, in 1415, with pioneering vessels like <a href="https://en.wikipedia.org/wiki/Caravel"><u>caravels</u></a> and naus/carracks, precursors to galleons and other ships. Portuguese sea exploration was driven by navigation schools and historic voyages <i>“through seas never sailed before”</i> (<i>“Por mares nunca dantes navegados” </i>in Portuguese), as described by Portugal’s famous poet, Luís Vaz de Camões, born 500 years ago (1524).</p><p>Anyone familiar with Portugal knows the <a href="https://en.wikipedia.org/wiki/History_of_Portugal#Naval_exploration_and_Portuguese_Empire_(15th%E2%80%9316th_centuries)"><u>sea is central</u></a> to its identity. The small country has 980 km of coastline, where most of its main cities are located. Maritime areas make up 90% of its territory, including the mid-Atlantic Azores. In 1998, Lisbon’s <a href="https://en.wikipedia.org/wiki/Expo_%2798"><u>Expo 98</u></a> celebrated the oceans and this maritime heritage. Since 2011, the small town of Nazaré also became globally <a href="https://allwaves.surf/waves-explained-nazare/"><u>famous among the surfing community</u></a> for its <a href="https://earthobservatory.nasa.gov/images/149486/monster-waves-of-nazare"><u>giant waves</u></a>.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2zN2XfhmWnjbFmkXfTiYGw/fa321c61b54e676136f93d050364ee8b/image6.jpg" alt="" width="1916" height="639" loading="lazy">
          </figure>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/Tyu4Wlgn1NMihceYSCUvI/45905ee3820880371b508dc13c32f11b/image2.jpg" alt="" width="1999" height="692" loading="lazy">
          </figure><p><sup><i>Nazaré’s waves, famous since Garrett McNamara’s 23.8&nbsp;m (78 ft) ride in 2011, hold </i></sup><a href="https://www.guinnessworldrecords.com/world-records/78115-largest-wave-surfed-unlimited"><sup><i><u>Guinness World Records</u></i></sup></a><sup><i> for the biggest waves ever surfed. Photos: Sam Khawasé &amp; Beatriz Paula, from Cloudflare.</i></sup></p><p>Portugal’s maritime culture also inspired literature and music, including poet Fernando Pessoa, who referenced it in his 1934 book <a href="https://en.wikipedia.org/wiki/Mensagem"><u>Mensagem</u></a>, and musician Rui Veloso, who dedicated his 1990s album <a href="https://open.spotify.com/album/2mzMuD3bxwFaFgfjU2vigY"><u>Auto da Pimenta</u></a> to Portugal’s historic connection to the sea.</p>
          <p>
            <h3 id="how-this-chaos-came-to-be">How this chaos came to be</h3>
            
          </p>
        <p>As Cloudflare’s CEO, Matthew Prince, <a href="https://x.com/eastdakota/status/1899226252956827846"><u>said</u></a> recently, this new wall of entropy began with an idea back in 2023: “What could we use for randomness that was like our lava lamp wall in San Francisco but represented our team in Portugal?”</p><p>The original inspiration came from wave motion machine desk toys, which were popular among some of our team members. Waves and the ocean not only provide a source of movement and randomness, but also align with Portugal’s maritime history and the office’s scenic view.</p><p>However, this was easier said than done. It turns out that making a wave machine wall is a real challenge, given that these toys are not as popular as they were in the past,&nbsp; and aren’t being manufactured in the size we needed any more. We scoured eBay and other sources but couldn't find enough, consistent in style and in working order wave machines. We also discovered that off-the-shelf models weren’t designed to run 24/7, which was a critical requirement for our use.</p><h4>Artistry to create wave machines</h4><p>Undaunted, <a href="https://blog.cloudflare.com/cloudflare-top-100-most-loved-workplaces-in-2022"><u>Cloudflare’s Places team</u></a>, which ensures our offices reflect our values and culture, found a <a href="https://wavemotionmachines.com/"><u>U.S.-based artisan</u></a> that specializes in ocean wave displays to create the wave machines for us. Since 2009, his one-person business, <a href="https://wavemotionmachines.com/"><u>Hughes Wave Motion Machines</u></a>, has blended artistry, engineering, and research, following his transition from Lockheed Martin Space Systems, where he designed military and commercial satellites.</p>
<p><sup><i>Timelapse of the mesmerizing office waves, set to the tune of an AI-generated song.</i></sup></p><p>Collaborating closely, we developed a custom rectangular wave machine (18 inches/45 cm long) that runs nonstop — not an easy task — which required hundreds of hours of testing and many iterations. Featuring rotating wheels, continuous motors, and a unique fluid formula, these machines create realistic ocean-like waves in green, blue, and Cloudflare’s signature orange.&nbsp;</p><p>Here’s a quote from the artist himself about these wave machines:</p><blockquote><p><i>“The machine’s design is a balancing act of matching components and their placement to how the fluid responds in a given configuration. There is a complex yet delicate relationship between viscosity, specific gravity, the size and design of the vessel, and the placement of each mechanical interface. Everything must be precisely aligned, centered around the fluid like a mathematical function. I like to say it’s akin to ’balancing a checkerboard on a beach ball in the wind.’”</i></p></blockquote>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3K9fpTU0D0xi831MHFOFBj/570b8c307fea1078f3c0262e13447bf6/image7.jpg" alt="" width="1500" height="1999" loading="lazy">
          </figure><p><sup><i>The Cloudflare Places Team with Lisbon office architects and contractor testing wave machine placement, shelves, lighting, and mirrors to enhance movement and reflection, March 2024.</i></sup></p><p>Despite delays, the Lisbon wave machines finally debuted on March 10, 2025 — an incredibly exciting moment for the Places team.</p><p><b>Some numbers about our wave-machine entropy wall:</b></p><ul><li><p>50 wave machines, 50 motion wheels &amp; motors, 50 acrylic containers filled with Hughes Wave Fluid Formula (two <a href="https://www.sciencedirect.com/topics/engineering/immiscible-liquid"><u>immiscible liquids</u></a>)</p></li><li><p>3 liquid colors: blue, green, and orange</p></li><li><p>15 months from concept to completion</p></li><li><p>14 flips (side-to-side balancing movements) per minute — over 20,000 per day</p></li><li><p>Over 15 waves per minute</p></li><li><p>~0.5 liters of liquid per machine</p></li></ul>
          <p>
            <h3 id="lavarand-origins-and-walls-of-entropy">LavaRand origins and walls of entropy</h3>
            
          </p>
        <p>Cloudflare’s servers handle 71 million HTTP requests per second on average, with 100 million HTTP requests per second at peak. <a href="https://radar.cloudflare.com/adoption-and-usage#http-vs-https"><u>Most of these requests are secured via TLS</u></a>, which relies on secure randomness for cryptographic integrity. A Cryptographically Secure Pseudorandom Number Generator (<a href="https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/"><u>CSPRNG</u></a>) ensures unpredictability, but only when seeded with high-quality entropy. Since chaotic movement in the real world is truly random, Cloudflare designed a system to harness it. Our <a href="https://blog.cloudflare.com/harnessing-office-chaos/"><u>2024 blog post</u></a> expands on this topic in a more technical way, but here’s a quick summary.</p><p>In <a href="https://blog.cloudflare.com/randomness-101-lavarand-in-production/"><u>2017</u></a>, Cloudflare launched LavaRand, inspired by <a href="https://www.wired.com/1997/03/lava-lites-easy-to-break-hard-to-crack/"><u>Silicon Graphics’ 1997 concept</u></a> However, the need for randomness in security was already a hot topic on our blog before that, such as in our discussions of <a href="https://blog.cloudflare.com/why-randomness-matters/"><u>securing systems</u></a> and <a href="https://blog.cloudflare.com/a-relatively-easy-to-understand-primer-on-elliptic-curve-cryptography/"><u>cryptography</u></a>. Originally, LavaRand collected entropy from a wall of lava lamps in our San Francisco office, feeding an internal API that servers periodically query to include in their entropy pools. Over time, we expanded LavaRand beyond lava lamps, incorporating <a href="https://blog.cloudflare.com/harnessing-office-chaos/#londons-unpredictable-pendulums"><u>new sources of office chaos</u></a> while maintaining the same core method.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2v6Wvde8j8R7482QjBsSrV/89b37c652654e27c13d328e9acac6489/image9.png" alt="" width="1612" height="381" loading="lazy">
          </figure><p>A camera captures images of dynamic, unpredictable randomness displays. Shadows, lighting changes, and even sensor noise contribute entropy. Each image is then processed into a compact hash, converting it into a sequence of random bytes. These, combined with the previous seed and local system entropy, serve as input for a Key Derivation Function (<a href="https://en.wikipedia.org/wiki/Key_derivation_function"><u>KDF</u></a>), which generates a new seed for a CSPRNG — capable of producing virtually unlimited random bytes upon request. The waves in our Lisbon office are now contributing to this pool of randomness.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1XFFjr4jhRMQlz6akHKZm4/44759c4e879de3792cd21b4ce2525c90/image5.png" alt="" width="1491" height="400" loading="lazy">
          </figure><p>Cloudflare’s LavaRand API makes this randomness accessible internally, strengthening cryptographic security across our global infrastructure. For example, when you use <i>Math.random()</i> in <a href="https://workers.cloudflare.com/"><u>Cloudflare Workers</u></a>, part of that randomness comes from LavaRand. Similarly, querying our <a href="https://blog.cloudflare.com/harnessing-office-chaos/#drand-distributed-and-verifiable-public-randomness"><u>drand API</u></a> taps into LavaRand as well. Cloudflare offers this API to enable anyone to generate random numbers and even seed their own systems.</p>
          <p>
            <h3 id="our-new-lisbon-office-space">Our new Lisbon office space</h3>
            
          </p>
        
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5ivPkCfTkGxfo6Swt6p9qY/e7414a14b88bef7ac7e0ef6f737b58c6/image8.jpg" alt="" width="1999" height="1330" loading="lazy">
          </figure><p><sup><i>Photo of the view from our Lisbon office, featuring ceiling lights arranged in a wave-like pattern.</i></sup></p><p>Entropy also inspired the design ethos of our new Lisbon office, given that the wall of waves and the office are part of the same project. As soon as you enter, you're greeted not only by the motion of the entropy wall but also by the constant movement of planet Earth on our Cloudflare Radar Display screen that stands next to it. But the waves don’t stop there — more elements throughout the space mimic the dynamic flow of the Internet itself. Unlike ocean tides, however, Internet traffic ebbs and flows with the motion of the Sun, not the Moon.</p><p>As you walk through the office, waves are everywhere — in the ceiling lights, the architectural contours, and even the floor plan, thoughtfully designed by our architect to reflect the fluid movement of water. The visual elements create a cohesive experience, reinforcing a sense of motion. Each meeting room embraces this maritime theme, named after famous Portuguese beaches — including, naturally, Nazaré.</p><p>We partnered with an incredible group of local Portuguese vendors for this construction project, where all the leads were women — something incredibly rare for the industry. The local teams worked with passion, proudly wore Cloudflare t-shirts, and fostered a warm, family-like atmosphere. They openly expressed pride in the project, sharing how it stood out from anything they had worked on before.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7lpuurEtWfpIPKvHVqmD0L/0b0561097859f286d6b5e98db82f1e0f/image3.jpg" alt="" width="1999" height="1125" loading="lazy">
          </figure><p><sup><i>Our amazing third-party team and internal Places team, proudly rocking Cloudflare shirts after bringing this project to life.</i></sup></p>
          <p>
            <h3 id="help-us-select-a-name-for-our-new-wall-of-entropy">Help us select a name for our new wall of entropy</h3>
            
          </p>
        <p>Next, we have several name options for this new wall of entropy. Help us decide the best one, and register your vote using <a href="https://forms.gle/L2gAqoJTwQmJFkmy8"><u>this form</u></a>.</p><blockquote><p><b>The Surf Board</b></p><p><b>Chaos Reef</b></p><p><b>Waves of Entropy</b></p><p><b>Wall of Waves</b></p><p><b>Whirling Wave Wall</b></p><p><b>Chaotic Wave Wall</b></p><p><b>Waves of Chaos</b></p></blockquote><p>If you’re interested in working in Cloudflare’s Lisbon office, we’re hiring! Our <a href="https://www.cloudflare.com/careers/jobs/"><b><u>career page</u></b></a> lists our open roles in Lisbon, as well as our other locations in the U.S., Mexico, Europe and Asia.</p><p><sup><i>Acknowledgements: This project was only possible with the effort, vision and help of John Graham-Cumming, Caroline Quick, Jen Preston, Laura Atwall, Carolina Beja, Hughes Wave Motion Machines, P4 Planning and Project Management, Gensler Europe, Openbook Architecture, and Vector Mais.</i></sup></p></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/lavarand/">LavaRand</a><a href="https://blog.cloudflare.com/tag/entropy/">Entropy</a><a href="https://blog.cloudflare.com/tag/security/">Security</a><a href="https://blog.cloudflare.com/tag/randomness/">Randomness</a><a href="https://blog.cloudflare.com/tag/cryptography/">Cryptography</a><a href="https://blog.cloudflare.com/tag/portugal/">Portugal</a><a href="https://blog.cloudflare.com/tag/life-at-cloudflare/">Life at Cloudflare</a><a href="https://blog.cloudflare.com/tag/lisbon/">Lisbon</a><a href="https://blog.cloudflare.com/tag/offices/">Offices</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Undergraduate Disproves 40-Year-Old Conjecture, Invents New Kind of Hash Table (104 pts)]]></title>
            <link>https://www.wired.com/story/undergraduate-upends-a-40-year-old-data-science-conjecture/</link>
            <guid>43388296</guid>
            <pubDate>Mon, 17 Mar 2025 13:19:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/undergraduate-upends-a-40-year-old-data-science-conjecture/">https://www.wired.com/story/undergraduate-upends-a-40-year-old-data-science-conjecture/</a>, See on <a href="https://news.ycombinator.com/item?id=43388296">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><em><span>The original version</span> of</em> <a href="https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/"><em>this story</em></a> <em>appeared in <a href="https://www.quantamagazine.org/">Quanta Magazine</a>.</em></p><p>Sometime in the fall of 2021, Andrew Krapivin, an undergraduate at Rutgers University, encountered a paper that would change his life. At the time, Krapivin didn’t give it much thought. But two years later, when he finally set aside time to go through the paper (“just for fun,” as he put it), his efforts would lead to a rethinking of a widely used tool in computer science.</p><p>The paper’s title, “<a data-offer-url="https://arxiv.org/abs/2111.12800" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://arxiv.org/abs/2111.12800&quot;}" href="https://arxiv.org/abs/2111.12800" rel="nofollow noopener" target="_blank">Tiny Pointers</a>,” referred to arrowlike entities that can direct you to a piece of information, or element, in a computer’s memory. Krapivin soon came up with a potential way to further miniaturize the pointers so they consumed less memory. However, to achieve that, he needed a better way of organizing the data that the pointers would point to.</p><p>He turned to a common approach for storing data known as a hash table. But in the midst of his tinkering, Krapivin realized that he had invented a new kind of hash table, one that worked faster than expected—taking less time and fewer steps to find specific elements.</p><p><a href="https://engineering.nyu.edu/faculty/martin-farach-colton" target="_blank">Martín Farach-Colton</a>, a coauthor of the “Tiny Pointers” paper and Krapivin’s former professor at Rutgers, was initially skeptical of Krapivin’s new design. Hash tables are among the most thoroughly studied data structures in all of computer science; the advance sounded too good to be true. But just to be sure, he asked a frequent collaborator (and a “Tiny Pointers” coauthor), <a data-offer-url="https://csd.cmu.edu/people/faculty/william-kuszmaul" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://csd.cmu.edu/people/faculty/william-kuszmaul&quot;}" href="https://csd.cmu.edu/people/faculty/william-kuszmaul" rel="nofollow noopener" target="_blank">William Kuszmaul</a> of Carnegie Mellon University, to check out his student’s invention. Kuszmaul had a different reaction. “You didn’t just come up with a cool hash table,” he remembers telling Krapivin. “You’ve actually completely wiped out a 40-year-old conjecture!”</p><figure><p><span><p>Without setting out to do so, Andrew Krapivin upended the common thinking around hash tables—one of the best-studied tools in computer science.</p>
</span><span>Photograph: Phillip Ammon for Quanta Magazine</span></p></figure><p>Together, Krapivin (now a graduate student at the University of Cambridge), Farach-Colton (now at New York University), and Kuszmaul demonstrated in a <a data-offer-url="https://arxiv.org/abs/2501.02305" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://arxiv.org/abs/2501.02305&quot;}" href="https://arxiv.org/abs/2501.02305" rel="nofollow noopener" target="_blank">January 2025 paper</a> that this new hash table can indeed find elements faster than was considered possible. ln so doing, they had disproved a conjecture long held to be true.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“It’s an important paper,” said <a data-offer-url="https://ajhconway.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://ajhconway.com/&quot;}" href="https://ajhconway.com/" rel="nofollow noopener" target="_blank">Alex Conway</a> of Cornell Tech in New York City. “Hash tables are among the oldest data structures we have. And they’re still one of the most efficient ways to store data.” Yet open questions remain about how they work, he said. “This paper answers a couple of them in surprising ways.”</p><p>Hash tables have become ubiquitous in computing, partly because of their simplicity and ease of use. They’re designed to allow users to do exactly three things: “query” (search for) an element, delete an element, or insert one into an empty slot. The first hash tables date back to the early 1950s, and computer scientists have studied and used them ever since. Among other things, researchers wanted to figure out the speed limits for some of these operations. How fast, for example, could a new search or insertion possibly be?</p><figure><p><span><p>Martín Farach-Colton helped Krapivin prove that his new hash table contradicted a long-standing conjecture.</p>
</span><span>Photograph: Andrew Farach-Colton</span></p></figure><p>The answer generally depends on the amount of time it takes to find an empty spot in a hash table. This, in turn, typically depends on how full the hash table is. Fullness can be described in terms of an overall percentage—this table is 50 percent full, that one’s 90 percent—but researchers often deal with much fuller tables. So instead, they may use a whole number, denoted by <em>x</em>, to specify how close the hash table is to 100 percent full. If <em>x</em> is 100, then the table is 99 percent full. If <em>x</em> is 1,000, the table is 99.9 percent full. This measure of fullness offers a convenient way to evaluate how long it should take to perform actions like queries or insertions.</p><p>Researchers have long known that for certain common hash tables, the expected time required to make the worst possible insertion—putting an item into, say, the last remaining open spot—is proportional to <em>x</em>. “If your hash table is 99 percent full,” Kuszmaul said, “it makes sense that you would have to look at around 100 different positions to find a free slot.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In a <a data-offer-url="https://dl.acm.org/doi/10.1145/3828.3836" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://dl.acm.org/doi/10.1145/3828.3836&quot;}" href="https://dl.acm.org/doi/10.1145/3828.3836" rel="nofollow noopener" target="_blank">1985 paper</a>, the computer scientist <a data-offer-url="https://amturing.acm.org/award_winners/yao_1611524.cfm" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://amturing.acm.org/award_winners/yao_1611524.cfm&quot;}" href="https://amturing.acm.org/award_winners/yao_1611524.cfm" rel="nofollow noopener" target="_blank">Andrew Yao</a>, who would go on to win the A.M. Turing Award, asserted that among hash tables with a specific set of properties, the best way to find an individual element or an empty spot is to just go through potential spots randomly—an approach known as uniform probing. He also stated that, in the worst-case scenario, where you’re searching for the last remaining open spot, you can never do better than <em>x</em>. For 40 years, most computer scientists assumed that Yao’s conjecture was true.</p><p>Krapivin was not held back by the conventional wisdom for the simple reason that he was unaware of it. “I did this without knowing about Yao’s conjecture,” he said. His explorations with tiny pointers led to a new kind of hash table—one that did not rely on uniform probing. And for this new hash table, the time required for worst-case queries and insertions is proportional to (log <em>x</em>)<sup>2</sup>—far faster than <em>x</em>. This result directly contradicted Yao’s conjecture. Farach-Colton and Kuszmaul helped Krapivin show that (log <em>x</em>)<sup>2</sup> is the optimal, unbeatable bound for the popular class of hash tables Yao had written about.</p><p>“This result is beautiful in that it addresses and solves such a classic problem,” said <a data-offer-url="http://www.cs.cmu.edu/~guyb/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.cs.cmu.edu/~guyb/&quot;}" href="http://www.cs.cmu.edu/~guyb/" rel="nofollow noopener" target="_blank">Guy Blelloch</a> of Carnegie Mellon.</p><p>“It’s not just that they disproved [Yao’s conjecture], they also found the best possible answer to his question,” said <a data-offer-url="https://cs.uwaterloo.ca/about/people/sassadi" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://cs.uwaterloo.ca/about/people/sassadi&quot;}" href="https://cs.uwaterloo.ca/about/people/sassadi" rel="nofollow noopener" target="_blank">Sepehr Assadi</a> of the University of Waterloo. “We could have gone another 40 years before we knew the right answer.”</p><figure><p><span><p>Krapivin on the King’s College Bridge at the University of Cambridge. His new hash table can find and store data faster than researchers ever thought possible.</p>
</span><span>Photoraph: Phillip Ammon for Quanta Magazine</span></p></figure><p>In addition to refuting Yao’s conjecture, the new paper also contains what many consider an even more astonishing result. It pertains to a related, though slightly different, situation: In 1985, Yao looked not only at the worst-case times for queries, but also at the average time taken across all possible queries. He proved that hash tables with certain properties—including those that are labeled “greedy,” which means that new elements must be placed in the first available spot—could never achieve an average time better than log <em>x</em>.</p><p>Farach-Colton, Krapivin, and Kuszmaul wanted to see if that same limit also applied to non-greedy hash tables. They showed that it did not by providing a counterexample, a non-greedy hash table with an average query time that’s much, much better than log <em>x</em>. In fact, it doesn’t depend on <em>x</em> at all. “You get a number,” Farach-Colton said, “something that is just a constant and doesn’t depend on how full the hash table is.” The fact that you can achieve a constant average query time, regardless of the hash table’s fullness, was wholly unexpected—even to the authors themselves.</p><p>The team’s results may not lead to any immediate applications, but that’s not all that matters, Conway said. “It’s important to understand these kinds of data structures better. You don’t know when a result like this will unlock something that lets you do better in practice.”</p><hr><p><a href="https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/"><em>Original story</em></a> <em>reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>, an editorially independent publication of the</em> <a href="https://www.simonsfoundation.org/"><em>Simons Foundation</em></a> <em>whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi RP2350 Now Available for Purchase, Stacked Memory Variant Coming (102 pts)]]></title>
            <link>https://www.phoronix.com/news/Raspberry-Pi-RP2350-Buy</link>
            <guid>43388221</guid>
            <pubDate>Mon, 17 Mar 2025 13:11:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/Raspberry-Pi-RP2350-Buy">https://www.phoronix.com/news/Raspberry-Pi-RP2350-Buy</a>, See on <a href="https://news.ycombinator.com/item?id=43388221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="RASPBERRY PI" src="https://www.phoronix.com/assets/categories/raspberrypi.webp" width="100" height="100"></p><p>
Raspberry Pi last year announced the RP2350 second-generation micro-controller that debuted within their $5 Raspberry Pi Pico 2 single board computer. Today they announced the RP2350 micro-controller is now available to purchase for your own micro-controller needs.
</p><p>
The Raspberry Pi RP2350 features two Arm Cortex-M33 processors at 150MHz and with floating point and DSP support. The RP2350A 7×7 QFN60 is priced at $1.10 USD per unit or the RP2350B 10×10 QFN80 is priced at $1.20 per unit when purchasing individually. Or if buying the RP2350A on a 13" reel for 3400 units it comes down to just $0.80 USD per unit or $0.90 for the RP2350B. There are also 7" reel 500 unit options for $0.90 or $1.00 as well.
</p><p><img src="https://www.phoronix.net/image.php?id=2025&amp;image=rp2350" alt="Raspberry Pi RP2350"></p>
<p>Raspberry Pi is also working on RP2354A and RP2354B variants that will feature 2MB of stacked flash memory. Those Raspberry Pi micro-controllers with stacked memory should be in mass production later this year and available via approved resellers.
</p><p>
Those wishing to learn more about the Raspberry Pi RP2350 micro-controller can do so via <a href="https://www.raspberrypi.com/news/rp2350-now-available-to-buy-a-high-performance-secure-microcontroller-for-your-next-project/">RaspberryPi.com</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta puts stop on promotion of tell-all book by former employee (167 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/mar/13/meta-careless-people-book-former-employee</link>
            <guid>43387325</guid>
            <pubDate>Mon, 17 Mar 2025 11:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/mar/13/meta-careless-people-book-former-employee">https://www.theguardian.com/technology/2025/mar/13/meta-careless-people-book-former-employee</a>, See on <a href="https://news.ycombinator.com/item?id=43387325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><a href="https://www.theguardian.com/technology/meta" data-link-name="in body link">Meta</a> on Wednesday won an emergency arbitration ruling to temporarily stop promotion of the tell-all book Careless People by a former employee, according to a copy of the ruling published by the social media company.</p><p>The book, written by a former director of global public policy at Meta, Sarah Wynn-Williams, <a href="https://www.nytimes.com/2025/03/10/books/review/careless-people-sarah-wynn-williams.html" data-link-name="in body link">was called by the New York Times</a> book review “an ugly, detailed portrait of one of the most powerful companies in the world”, and its leading executives, including CEO Mark Zuckerberg, former chief operating officer Sheryl Sandberg and chief global affairs officer Joel Kaplan.</p><p>Meta will suffer “immediate and irreparable loss” in the absence of an emergency relief, the American Arbitration Association’s emergency arbitrator, Nicholas Gowen, said in a ruling after a hearing, which Wynn-Williams did not attend.</p><p>Book publisher Macmillan attended and argued it was not bound by the arbitration agreement, which was part of a severance agreement between the employee and company.</p><p>The ruling says that Wynn-Williams should stop promoting the book and, to the extent she could, stop further publication. It did not order any action by the publisher.</p><p>A Meta spokesperson, Andy Stone, said in a post on Threads: “This ruling affirms that Sarah Wynn Williams’ false and defamatory book should never have been published”. Wynn-Williams and Macmillan did not immediately respond to a request for comment on the ruling.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-6">skip past newsletter promotion</a><p id="EmailSignup-skip-link-6" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>A spokesperson for Pan Macmillan gave the Guardian this statement on Thursday: “Careless People is a first person narrative account of what the author herself, Sarah Wynn Williams, witnessed during seven years at Meta (formerly Facebook). As publishers, we are committed to upholding freedom of speech and her right to tell her story. Due to legal process instituted by Meta, the author has been prevented from continuing to participate in the book’s publicity.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[uv downloads overtake Poetry for Wagtail users (205 pts)]]></title>
            <link>https://wagtail.org/blog/uv-overtakes-poetry/</link>
            <guid>43386357</guid>
            <pubDate>Mon, 17 Mar 2025 08:49:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wagtail.org/blog/uv-overtakes-poetry/">https://wagtail.org/blog/uv-overtakes-poetry/</a>, See on <a href="https://news.ycombinator.com/item?id=43386357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p data-block-key="wj9wf">The data ^ seems pretty clear – <a href="https://docs.astral.sh/uv/"><b>uv</b></a><b> is now the second most popular package installer for Wagtail users</b>, after pip, taking over from <a href="https://python-poetry.org/docs/">Poetry</a>.</p><p data-block-key="flrn5">Poetry is still pretty popular – and so is pip. But the growth in uv usage likely isn’t just from new users of Wagtail like the data might convey at a glance (see <a href="https://github.com/thibaudcolas/wagtail-tooling/blob/main/downloads-analysis/installers-stats.sql">the query</a> - PyPI download statistics in BigQuery).</p><p data-block-key="bcgc1">Note the chart above has July-August 2024 numbers manually adjusted – it looks like someone did an oopsie around that time, perhaps a uv early adopter letting CI go wild? (❤️ happens to the best of us) Or a version resolution gotcha for people testing Django pre-releases? Hmm.</p><p><img alt="pip and uv monthly downloads of Wagtail" height="371" src="https://media.wagtail.org/images/pip_and_uv_monthly_downloads_of_Wagtail.width-800.png" width="600"></p><h2 data-block-key="8mu50">What it means for Wagtail</h2><p data-block-key="4ure9">We need to make sure it works well with uv, in addition to other tools! Possibly update some of our docs. uv as a first-class citizen for <a href="https://github.com/wagtail/bakerydemo">bakerydemo site</a>? Updating the <a href="https://github.com/wagtail/news-template">news template</a>? We want to be careful that usage instructions make sense for all package managers, but also adapt to Python developers’ shifting expectations.</p><p data-block-key="evtgu">This is our <a href="https://github.com/wagtail/wagtail#-getting-started">current recommended</a> install steps for first-time users:</p>
    </div><div>
    <p data-block-key="3g8ar">There’s ways we could go further here, perhaps have more of a one-liner "uvx wagtail@latest start mysite --autorun" scaffolding experience (rare in the Django world). Tooling evolutions like those in uv this are a great opportunity for us to revisit those developer experience fundamentals.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Alexa feature "Do Not Send Voice Recordings" you enabled no longer available (762 pts)]]></title>
            <link>https://discuss.systems/@dev/114161826926246661</link>
            <guid>43385268</guid>
            <pubDate>Mon, 17 Mar 2025 04:41:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.systems/@dev/114161826926246661">https://discuss.systems/@dev/114161826926246661</a>, See on <a href="https://news.ycombinator.com/item?id=43385268">Hacker News</a></p>
Couldn't get https://discuss.systems/@dev/114161826926246661: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Conducting forensics of mobile devices to find signs of a potential compromise (119 pts)]]></title>
            <link>https://github.com/mvt-project/mvt</link>
            <guid>43384894</guid>
            <pubDate>Mon, 17 Mar 2025 03:25:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mvt-project/mvt">https://github.com/mvt-project/mvt</a>, See on <a href="https://news.ycombinator.com/item?id=43384894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
     <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a545b05395270e4383838329a58589a89b2476f217e8eb3bba22afdf0177a809/68747470733a2f2f646f63732e6d76742e72652f656e2f6c61746573742f6d76742e706e67"><img src="https://camo.githubusercontent.com/a545b05395270e4383838329a58589a89b2476f217e8eb3bba22afdf0177a809/68747470733a2f2f646f63732e6d76742e72652f656e2f6c61746573742f6d76742e706e67" width="200" data-canonical-src="https://docs.mvt.re/en/latest/mvt.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mobile Verification Toolkit</h2><a id="user-content-mobile-verification-toolkit" aria-label="Permalink: Mobile Verification Toolkit" href="#mobile-verification-toolkit"></a></p>
<p dir="auto"><a href="https://pypi.org/project/mvt/" rel="nofollow"><img src="https://camo.githubusercontent.com/d47f0f4ef327bd2cb2d9bf1d1b0bcb0a05560dfe0b3fd72e62f7051ef57db449/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d7674" alt="" data-canonical-src="https://img.shields.io/pypi/v/mvt"></a>
<a href="https://docs.mvt.re/en/latest/?badge=latest" rel="nofollow"><img src="https://camo.githubusercontent.com/506cc619196a2076aa7c7a616b1814389d9ed8f6cae1516d64067d62a96c6668/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d76742f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/mvt/badge/?version=latest"></a>
<a href="https://github.com/mvt-project/mvt/actions/workflows/tests.yml"><img src="https://github.com/mvt-project/mvt/actions/workflows/tests.yml/badge.svg" alt="CI"></a>
<a href="https://pepy.tech/project/mvt" rel="nofollow"><img src="https://camo.githubusercontent.com/559f2ada7ecf46681346f7bc5e7927952662545f870476a24aaeb6ac959122b5/68747470733a2f2f706570792e746563682f62616467652f6d7674" alt="Downloads" data-canonical-src="https://pepy.tech/badge/mvt"></a></p>
<p dir="auto">Mobile Verification Toolkit (MVT) is a collection of utilities to simplify and automate the process of gathering forensic traces helpful to identify a potential compromise of Android and iOS devices.</p>
<p dir="auto">It has been developed and released by the <a href="https://securitylab.amnesty.org/" rel="nofollow">Amnesty International Security Lab</a> in July 2021 in the context of the <a href="https://forbiddenstories.org/about-the-pegasus-project/" rel="nofollow">Pegasus Project</a> along with <a href="https://www.amnesty.org/en/latest/research/2021/07/forensic-methodology-report-how-to-catch-nso-groups-pegasus/" rel="nofollow">a technical forensic methodology</a>. It continues to be maintained by Amnesty International and other contributors.</p>
<blockquote>
<p dir="auto"><strong>Note</strong>
MVT is a forensic research tool intended for technologists and investigators. It requires understanding digital forensics and using command-line tools. This is not intended for end-user self-assessment. If you are concerned with the security of your device please seek reputable expert assistance.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Indicators of Compromise</h3><a id="user-content-indicators-of-compromise" aria-label="Permalink: Indicators of Compromise" href="#indicators-of-compromise"></a></p>
<p dir="auto">MVT supports using public <a href="https://github.com/mvt-project/mvt-indicators">indicators of compromise (IOCs)</a> to scan mobile devices for potential traces of targeting or infection by known spyware campaigns. This includes IOCs published by <a href="https://github.com/AmnestyTech/investigations/">Amnesty International</a> and other  research groups.</p>
<blockquote>
<p dir="auto"><strong>Warning</strong>
Public indicators of compromise are insufficient to determine that a device is "clean", and not targeted with a particular spyware tool. Reliance on public indicators alone can miss recent forensic traces and give a false sense of security.</p>
<p dir="auto">Reliable and comprehensive digital forensic support and triage requires access to non-public indicators, research and threat intelligence.</p>
<p dir="auto">Such support is available to civil society through <a href="https://securitylab.amnesty.org/get-help/?c=mvt_docs" rel="nofollow">Amnesty International's Security Lab</a> or through our forensic partnership with <a href="https://www.accessnow.org/help/" rel="nofollow">Access Now’s Digital Security Helpline</a>.</p>
</blockquote>
<p dir="auto">More information about using indicators of compromise with MVT is available in the <a href="https://docs.mvt.re/en/latest/iocs/" rel="nofollow">documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">MVT can be installed from sources or from <a href="https://pypi.org/project/mvt/" rel="nofollow">PyPI</a> (you will need some dependencies, check the <a href="https://docs.mvt.re/en/latest/install/" rel="nofollow">documentation</a>):</p>

<p dir="auto">For alternative installation options and known issues, please refer to the <a href="https://docs.mvt.re/en/latest/install/" rel="nofollow">documentation</a> as well as <a href="https://github.com/mvt-project/mvt/issues">GitHub Issues</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">MVT provides two commands <code>mvt-ios</code> and <code>mvt-android</code>. <a href="https://docs.mvt.re/" rel="nofollow">Check out the documentation to learn how to use them!</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The purpose of MVT is to facilitate the <em><strong>consensual forensic analysis</strong></em> of devices of those who might be targets of sophisticated mobile spyware attacks, especially members of civil society and marginalized communities. We do not want MVT to enable privacy violations of non-consenting individuals.  In order to achieve this, MVT is released under its own license. <a href="https://docs.mvt.re/en/latest/license/" rel="nofollow">Read more here.</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's knock down social media's walled gardens – Tim Berners-Lee (102 pts)]]></title>
            <link>https://www.ft.com/content/79d2d19a-08df-48fc-9a6f-a9dbef58f642</link>
            <guid>43384786</guid>
            <pubDate>Mon, 17 Mar 2025 03:00:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/79d2d19a-08df-48fc-9a6f-a9dbef58f642">https://www.ft.com/content/79d2d19a-08df-48fc-9a6f-a9dbef58f642</a>, See on <a href="https://news.ycombinator.com/item?id=43384786">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-o-grid-colspan="12 L6"><p><h2><span>Join FT Edit</span></h2><h2><strong><span>Only </span><span>CHF5</span><span> per month</span></strong></h2></p><p><span>Access to eight surprising articles a day, hand-picked by FT editors. For seamless reading, access content via the FT Edit page on FT.com, receive the FT Edit newsletter or download our award winning FT Edit app on iOS devices.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brown University Professor Is Deported Despite a Judge's Order (120 pts)]]></title>
            <link>https://www.nytimes.com/2025/03/16/us/brown-university-rasha-alawieh-professor-deported.html</link>
            <guid>43384730</guid>
            <pubDate>Mon, 17 Mar 2025 02:48:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/03/16/us/brown-university-rasha-alawieh-professor-deported.html">https://www.nytimes.com/2025/03/16/us/brown-university-rasha-alawieh-professor-deported.html</a>, See on <a href="https://news.ycombinator.com/item?id=43384730">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/03/16/us/brown-university-rasha-alawieh-professor-deported.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Sunsetting Whois (760 pts)]]></title>
            <link>https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en</link>
            <guid>43384069</guid>
            <pubDate>Mon, 17 Mar 2025 00:48:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en">https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en</a>, See on <a href="https://news.ycombinator.com/item?id=43384069">Hacker News</a></p>
Couldn't get https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla drives into Wile E. Coyote fake road wall in camera vs. Lidar test (138 pts)]]></title>
            <link>https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</link>
            <guid>43382230</guid>
            <pubDate>Sun, 16 Mar 2025 20:55:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/">https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</a>, See on <a href="https://news.ycombinator.com/item?id=43382230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="834" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1600" alt="Tesla cameras vs radar wall" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla Autopilot drove into Wile E. Coyote-style fake road wall in the middle of the road in a camera versus lidar test.</p>



<p>While most companies developing self-driving technologies have been using a mix of sensors (cameras, radar, lidar, and ultrasonic), Tesla insists on only using cameras.</p>



<p>The automaker removed radars from its vehicle lineup and even deactivated radars already installed in existing vehicles.</p>



<p>The strategy has yet to pay off as Tesla’s systems are still stuck at level 2 driver assist systems.</p>	
	



<p>CEO Elon Musk claims that Tesla’s advantage is that once it solves autonomy, it will be able to scale faster than competitors because its vision plus neural net system is designed to work like a human driver and, therefore, will be able to adapt to any road.</p>



<p>Critics have pushed back against those claims, especially since Musk mentioned Tesla achieving “level 5 autonomy”, which means “in any conditions,” and cameras have limitations on that front that are fixed by lidar sensors.</p>



<p>A new video by engineering Youtuber Mark Rober has provided a very interesting demonstration of that very problem:</p>



<figure><p>
<iframe id="post-youtube-video-1" title="Can You Fool A Self Driving Car?" width="500" height="281" data-src="https://www.youtube.com/embed/IQJL3htsDyQ?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>In the video, Rober puts a Tesla Model Y on Autopilot against a vehicle using a lidar system in a series of tests in different conditions.</p>



<p>The Tesla on Autopilot managed to stop for a kid mannequin in the middle of the road when statics, moving, and blinded by lights, but it couldn’t stop in fog or heavy rain:</p>



<figure><img decoding="async" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Screenshot-2025-03-16-at-12.25.18%E2%80%AFPM.png?w=1024" alt=""></figure>



<p>It’s not surprising that the lidar, a laser-based system, is capable of detecting better in heavy fog than a camera system.</p>



<p>The heavy rain was a bit more surprising, but to be fair, the level of rain was quite spectacular.</p>



<p>The last scenario of a Wile E. Coyote-style wall with a fake road painted on it was obviously not realistic, but it serves to illustrate the issue with cameras versus radar or lidar sensors: they rely on the perception of potential obstacles rather than hard data about potential obstacles.</p>



<p>In simple words, the lidar sensors didn’t care what was painted on the wall, they only cared that it was a wall, while cameras can be tricked.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>I think it’s clear that no Tesla vehicle currently available will be capable of level 5 autonomy as Elon claimed.</p>




	<p>Level 4 is also questionable.</p>



<p>I think you can accomplish a lot with cameras, but I think it’s undeniable that adding radars and lidars can make systems safer.</p>



<p>In DMs with us during Tesla’s transition to vision only, Elon even admitted that “very high-resolution radars would be better than pure vision”, but he claimed that “such a radar does not exist”: </p>



<blockquote>
<p>“A very high-resolution radar would be better than pure vision, but such a radar does not exist.”</p>
</blockquote>



<p>When we pointed one out to him, he didn’t respond. Also, while they use light rather than radio waves, lidars are basically high-resolution radars, but the problem is that Musk has taken such a strong stance against them for so long that now that they have improved immensely and reduced in prices, he still can’t admit that he was wrong and use them.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Military grade sonic weapon is used against protesters in Serbia (513 pts)]]></title>
            <link>https://twitter.com/nexta_tv/status/1901244199220982213</link>
            <guid>43382093</guid>
            <pubDate>Sun, 16 Mar 2025 20:40:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/nexta_tv/status/1901244199220982213">https://twitter.com/nexta_tv/status/1901244199220982213</a>, See on <a href="https://news.ycombinator.com/item?id=43382093">Hacker News</a></p>
Couldn't get https://twitter.com/nexta_tv/status/1901244199220982213: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Zlib-rs is faster than C (302 pts)]]></title>
            <link>https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</link>
            <guid>43381512</guid>
            <pubDate>Sun, 16 Mar 2025 19:35:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trifectatech.org/blog/zlib-rs-is-faster-than-c/">https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</a>, See on <a href="https://news.ycombinator.com/item?id=43381512">Hacker News</a></p>
Couldn't get https://trifectatech.org/blog/zlib-rs-is-faster-than-c/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI Is Making Developers Dumb (169 pts)]]></title>
            <link>https://eli.cx/blog/ai-is-making-developers-dumb</link>
            <guid>43381215</guid>
            <pubDate>Sun, 16 Mar 2025 18:51:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.cx/blog/ai-is-making-developers-dumb">https://eli.cx/blog/ai-is-making-developers-dumb</a>, See on <a href="https://news.ycombinator.com/item?id=43381215">Hacker News</a></p>
Couldn't get https://eli.cx/blog/ai-is-making-developers-dumb: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tcl Tutorial (157 pts)]]></title>
            <link>https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html</link>
            <guid>43381195</guid>
            <pubDate>Sun, 16 Mar 2025 18:48:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html">https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html</a>, See on <a href="https://news.ycombinator.com/item?id=43381195">Hacker News</a></p>
Couldn't get https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's 1986 IPO (109 pts)]]></title>
            <link>https://dfarq.homeip.net/microsofts-1986-ipo/</link>
            <guid>43381141</guid>
            <pubDate>Sun, 16 Mar 2025 18:41:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dfarq.homeip.net/microsofts-1986-ipo/">https://dfarq.homeip.net/microsofts-1986-ipo/</a>, See on <a href="https://news.ycombinator.com/item?id=43381141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On March 13, 1986, Microsoft shook up the financial world, and to some degree, we are still feeling the reverberations from that 40 years later. That was the day of Microsoft’s very successful IPO. The hunt for the next Microsoft began immediately, leading directly to the <a href="https://dfarq.homeip.net/when-the-dotcom-bubble-burst/">dotcom bubble</a> of the turn of the century.</p><h2>How big was Microsoft’s IPO?</h2><figure id="attachment_37141" aria-describedby="caption-attachment-37141"><a href="https://dfarq.homeip.net/?attachment_id=37141" rel="attachment wp-att-37141"><img data-recalc-dims="1" fetchpriority="high" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Microsoft_Dubai.jpg?resize=225%2C300&amp;ssl=1" alt="Microsoft standing tall" width="225" height="300" srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Microsoft_Dubai.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Microsoft_Dubai.jpg?w=450&amp;ssl=1 450w" sizes="(max-width: 225px) 100vw, 225px"></a><figcaption id="caption-attachment-37141">Microsoft stood so tall after its 1986 IPO that the search for a repeat was a major contributor to a recession.</figcaption></figure><p>Microsoft’s IPO initially valued company at $21.00 per share. It raised $61 million for the company, and put its market capitalization at $777 million. The price peaked at $35.50 per share before settling to $27.75 at the end of the day. Microsoft expected it to take weeks to reach $27.75. Bill Gates owned 45% of the company’s stock, which meant on March 14, 1986, he was worth almost $350 million. He had not yet turned 31. The next year, he became the youngest person to become a billionaire, before he had turned 32.</p><h2>Why Microsoft waited so long</h2><p>Founded in 1975, Microsoft was an 11-year-old company at the time it went public. They waited so long because Bill Gates wanted to maintain control over the company as long as he could. By 1986, Microsoft had to go public. This wasn’t because they needed money. Their profit margins were enviable, at 34% of their pre tax revenue. Microsoft didn’t need the $61 million the IPO raised.</p><p>The reason Microsoft had to go public in 1986 was because Bill Gates had been using stock to attract talent. Microsoft projected that by sometime in 1987, they would have 500 shareholders, which would require Microsoft to register with the Securities and Exchange Commission, effectively turning them into a publicly traded company, but without the benefits of going public in the conventional way.</p><p>Backed into this corner, Gates agreed in late 1985 to pursue an IPO.</p><h2>Why was Microsoft so profitable?</h2><p>Motley Fool greatly oversimplifies Microsoft’s early years, as do others. They’re better at SEO than analysis. Microsoft’s best known products in 1986 were PC DOS and MS-DOS, the text-based operating systems for IBM and IBM-compatible PCs. In 1986, <a href="https://dfarq.homeip.net/microsoft-windows-first-announced-nov-10-1983/">Microsoft Windows existed</a>, barely, but wasn’t yet successful.</p><p>Microsoft’s secret was that virtually every computer on the market was running some Microsoft product. Its operating system powered the booming PC market. But Excel was the most popular spreadsheet on the Macintosh. Its predecessor, Multiplan, was a reasonably popular spreadsheet on other platforms. Microsoft Word was an up and coming word processor. Microsoft Basic was one of the most popular programming languages, and ran on virtually every platform.</p><p>Sometimes Microsoft licensed software on a royalty basis and sometimes for a flat rate up front. Getting the flat rate up front shielded Microsoft from losing profits to piracy early on. But once Microsoft could afford to risk some loss to piracy, it was more profitable to take a royalty per unit sold. There were <a href="https://dfarq.homeip.net/how-many-ibm-pcs-sold/">60 million IBM and IBM-compatible PCs</a> sold in the 1980s, and Microsoft collected a royalty on virtually every single one. Then in 1991, it discovered it could sell new versions of MS-DOS as upgrades and make money on each unit sold a second time.</p><p>When Windows 3.0 hit the market in May 1990, the game was essentially over. Microsoft could sell you an operating system, a graphical environment, and versions of Word and Excel that ran in that environment, all running on commodity hardware that was getting cheaper by the quarter, if not the month. Although it would be a few years before other companies would give up, a monopoly in operating systems and office suites was inevitable before 1990 was over.</p><p>The more successful Microsoft became, the more afraid of failure and anticompetitive it became. This led to legal issues in the late 1990s. Microsoft reformed to a degree and is more tolerant of certain competing products continuing to exist than it was in the 90s.</p><p>Today, Apple, Amazon, and Alphabet (formerly Google) are larger than Microsoft, but the four companies are the only technology firms in the 2024 Fortune 20 list. The fifth largest technology firm is Meta, the social media company everyone loves to hate, at #30.</p><h2>The legacy of Microsoft’s IPO</h2><p>To this day, young ambitious people enroll in school to get technical degrees in hopes of becoming the next Bill Gates, and venture capitalists like <a href="https://dfarq.homeip.net/how-shark-tanks-kevin-oleary-became-rich/">Kevin O’Leary</a> and Marc Andreessen (himself a cofounder of a <a href="https://dfarq.homeip.net/netscape-the-ipo-that-went-boom-on-its-way-up-and-down/">failed dotcom</a>) prey on them. These ambitious programmer/entrepreneurs rarely get rich, but the venture capitalists have figured out how to make money even as the businesses they fund fail.</p><p>Today’s entrepreneurs would do well to note that Microsoft made minimal use of venture capital. Microsoft’s only VC only owned 6.2 percent of the company. Gates didn’t trust them.</p><p>If you’re thinking of trying your hand at being the next Bill Gates, keep that in mind.</p><p>Another direct consequence of the Microsoft IPO was the dotcom bubble of the late 1990s and the subsequent recession. Fear of missing out on the next Microsoft drove up the value of anything tech- or Internet-related. Investors believed the next Microsoft would come out of that generation of companies. In the end they were kind of right. Two companies from that wave ended up matching and eventually eclipsing Microsoft. But it wasn’t exactly clear until a few years after the dotcom bust that Amazon and Google would be the ones to do it. Short-lived randos like <a href="https://dfarq.homeip.net/va-linux-the-biggest-dotcom-ipo/">VA Linux</a>, Geocities, Cyberrebate, and <a href="https://dfarq.homeip.net/the-most-excessive-dotcom-internet-america/">Internet America</a> were able to come along for the ride while the market shook out.</p><div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" width="100" height="100" alt="" itemprop="image"></p><div><p>David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Our Interfaces Have Lost Their Senses (336 pts)]]></title>
            <link>https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</link>
            <guid>43380930</guid>
            <pubDate>Sun, 16 Mar 2025 18:11:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses">https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</a>, See on <a href="https://news.ycombinator.com/item?id=43380930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>





<article id="our-interfaces-have-lost-their-senses">



<a href="https://wattenberger.com/"><svg style="width: min(8vw, 8vh)" viewBox="0 0 245 213" fill="none" xmlns="http://www.w3.org/2000/svg"><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M122.692 0.712992L163.395 71.213L163.394 71.2143L204.097 141.713H122.7L122.692 141.713L122.69 141.713H41.2939L81.993 71.2201L81.9889 71.213L122.692 0.712992Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M81.9889 212.213L122.692 141.713L122.691 141.712L163.394 71.213H81.9972L81.9889 71.2129L81.9873 71.213H0.590759L41.2898 141.706L41.2857 141.713L81.9889 212.213Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M163.39 212.213L204.094 141.713L204.093 141.712L244.795 71.213H163.399L163.39 71.2129L163.389 71.213H81.9922L122.691 141.706L122.687 141.713L163.39 212.213Z" fill="#102A3D22"></path></g></svg></a>




<p>Think about how you experience the world—</p>
<p>you touch, you hear, you move.</p>

<div>
		
		<p>But our digital world has been getting flatter, more muted.</p>
		<p>Reduced to text under glass screens.</p>
		<p>This shift made interfaces simpler.<br>But was that really the goal?
			</p></div>


<p>An interface is the bridge between
	</p>



<div><p>It's how we tell computers what we want,
			</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-right.png" alt=""></p><p>and it's how computers communicate back to us.
		</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-left.png" alt=""></p><div><div><p>The shape should fit how we work,
				</p><p>for ergonomics and ease of use</p></div>
			<div><p>and it should fit how the computer works.
			</p><p>for simplicity and a good mental model</p></div></div>

	<p>Recently, we've been too focused on fitting to the computer's shape, and not enough to our own bodies.
	</p></div>

<h2>The Great Flattening</h2>
<p>Computers used to be physical beasts.</p>
<p>We programmed them by punching cards, plugging in wires, and flipping switches. Programmers walked among banks of switches and cables, physically choreographing their logic. Being on a computer used to be a full-body experience.
</p>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition1.png"></p>
	<p><span><span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition2.png"></p>
	<p><span><span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span></span></p></div>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition3.png"></p>
	<p><span><span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition4.png"></p>
	<p><span><span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span></span></p></div>



<h2>The Joy of Doing</h2>

<p>We've been successfully removing all friction from our apps — think about how effortless it is to scroll
	through a social feed. But is that what we want? Compare the feeling of doomscrolling to kneading
	dough, playing an instrument, sketching... these take effort, but they're also deeply
	satisfying. When you strip away too much friction, meaning and satisfaction go with it.
</p>

<p>Think about how you use physical tools. Drawing isn't just moving your hand—it's the
	feel of the pencil against paper, the tiny adjustments of pressure, the sound of graphite
	scratching. You shift your body to reach the other side of the canvas. You erase with your other
	hand. You step back to see the whole picture.
</p>

<p>We made painting feel like typing,</p>

<div>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing.png"></p>
	
	<div><p>but we should have made <em>typing</em> feel like <em>painting</em>.
			</p>
			<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/artist.png"></p></div></div>

<h2>Putting the you back in UI</h2>

<p>So how might our interfaces look if we shaped them to fit us?
</p>


<div><p>We think in <em>movement</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/movement.png"></p>
	<p>in <em>space</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/space.png"></p>
	
	<div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/sound.png"></p></div>
	<div><p>in <em>patterns</em>.
		</p><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/patterns.png"></p></div>
	</div>
<p>We use our hands to sculpt, our eyes to scan, our ears to catch patterns.
	</p>







<p>Our computers can communicate to us in many different formats, each with their own strengths:</p>

<div><div><div><p>Text</p>
			<p>Great for depth, detail, and precision.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/images.png"></p><p>But it doesn't always have to be in full paragraphs. How about showing key points first, then letting users expand?
		</p></div>
	<div><div><p>Visualizations</p>
			<p>Ideal for spatial relationships, trends, and quick insights.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/vision.png"></p><p>Can we show more content spatially? Or encode it in charts or colors?</p></div>
	<div><div><p>Sound</p>
			<p>Perfect for alerts and background awareness. Also, patterns.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/hearing.png"></p><p>Why are most web UIs silent? Can we use subtle chimes or sonification to highlight patterns?</p></div>
	<div><div><p>Haptics</p>
			<p>Provides passive feedback (vibrations, force).</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/touch.png"></p><p>Here's one I always forget about! We can vibrate phones to alert or convey patterns.
		</p></div></div>

<p>And what about the reverse! We can communicate to our computers in many different ways, each with their own strengths:
</p>

<div><div><div><p>Typing</p>
			<p>Precise, detailed, and familiar</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing2.png"></p><p>Good for composing long-form thoughts, keyboard shortcuts, and rough direction.
		</p></div>
	<div><div><p>Clicking &amp; Dragging</p>
			<p>Direct, fine-grained control.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/clicking.png"></p><p>Great for spatial tasks (design, organization) and pointing at things-on-a-screen.
		</p></div>
	<div><div><p>Tapping, Swiping, Pinching</p>
			<p>Intuitive for direct manipulation.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/tapping.png"></p><p>Great for mobile, but do we have to limit guestures to mimicking mouse interactions?
		</p></div>
	<div><div><p>Gesturing</p>
			<p>Hands-free, fluid, and expressive.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesturing.png"></p><p>Could be powerful for accessibility, quick actions, and complex fine control—reliable detection feels very possible at this time.
		</p></div>
	<div><div><p>Speaking</p>
			<p>Easy for loose thoughts.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/speaking.png"></p><p>LLMs have made speech more viable—can we let users think out loud or navigate roughly with their voice?
		</p></div></div>



<p>And the real magic happens when we combine different modalities. You can't read and listen and speak
	at the same time—try reading this excerpt while talking about your day:
</p>

<div><p>If it had not rained on a certain May morning Valancy Stirling’s whole life would have been
		entirely different. She would have gone, with the rest of her clan, to Aunt Wellington’s
		engagement picnic and Dr. Trent would have gone to Montreal. But it did rain and you shall hear
		what happened to her because of it.
	</p>
	</div>

<div><div><p>But you can talk while clicking,</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/click.png"></p></div>
<div><p>listen while reading,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/listen.png"></p></div>
<div><p>look at an image while spinning a knob,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/look.png"></p></div>
<div><p>guesture while talking.</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesture.png"></p></div>
</div>

<p>Let's build interfaces that let us multitask across senses.</p>

<h2>Rebuilding the bridge</h2>
<p>So, what might a richer interface look like? I have strong conviction that our future interfaces should:
</p>
<ul><li>let us collaborate on <strong>tangible artifacts</strong>, not just ephemeral chat logs.</li>
	<li>support <strong>multiple concurrent modalities</strong>—voice, gestures,
		visuals, spatial components.
	</li>
	<li>respond to <strong>ambient signals</strong>—detecting context, organizing information, helping
		us think better.
	</li></ul>

<p>Last year, I did a rough exploration of what this could look like for a thought organizing tool. One that listened as you talked or typed, and organized your rambling thoughts into cards.
</p>



<p>This interface is very rough, but felt like a different way of working with technology. Especially how it let me bumble through rough ideas one second, then responded to commands like "re-group my cards" or "add 3 cards about this" the next.
</p>

<p>I would love to see more explorations like this!
</p>

<h2>Our interfaces have lost their senses</h2>
<p>All day, we poke, swipe, and scroll through flat, silent
	screens. But we're more than just eyes and a pointer finger. We think with our hands, our ears,
	our bodies.
</p>

<p>The future of computing is being designed right now. Can we build something richer—something that
	moves with us, speaks our language, and molds to our bodies?
</p>

<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/footer.png">
</article>


			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teach, Don't Tell (2013) (195 pts)]]></title>
            <link>https://stevelosh.com/blog/2013/09/teach-dont-tell/</link>
            <guid>43380833</guid>
            <pubDate>Sun, 16 Mar 2025 17:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevelosh.com/blog/2013/09/teach-dont-tell/">https://stevelosh.com/blog/2013/09/teach-dont-tell/</a>, See on <a href="https://news.ycombinator.com/item?id=43380833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on September 3rd, 2013.</p><p>This post is about writing technical documentation.  More specifically: it's
about writing documentation for programming languages and libraries.</p>

<p>I love reading great documentation.  When I have a question and the
documentations explains the answer almost as if the author has magically
anticipated my problem, I get a warm, fuzzy feeling inside.  I feel a connection
with the writer that makes me smile.</p>

<p>I also love writing documentation.  Being able to rewire the neurons in
someone's brain so that they understand something they didn't understand before
is extremely satisfying.  Seeing (or hearing about) the "click" when a bunch of
concepts suddenly fall together and make sense never fails to make my day.</p>

<p>This post is going to be about what I think good documentation is and how
I think you should go about writing it.  I'm not perfect, so you should take
everything with a grain of salt, but I hope you'll find it useful and
thought-provoking even if you don't agree with me about everything.</p>

<p>I'd like to say thanks to <a href="http://craigzheng.com/">Craig Zheng</a> and <a href="http://honza.ca/">Honza Pokorny</a> for
proofreading this.</p>

<ol><li><a href="#s1-prior-reading">Prior Reading</a></li><li><a href="#s2-why-do-we-document">Why Do We Document?</a></li><li><a href="#s3-teaching">Teaching</a></li><li><a href="#s4-a-play-in-seven-acts">A Play in Seven Acts</a></li><li><a href="#s5-act-1-read-the-source">Act 1: "Read the Source"</a></li><li><a href="#s6-tools-of-the-trade">Tools of the Trade</a></li><li><a href="#s7-act-2-read-the-tests">Act 2: "Read the Tests"</a></li><li><a href="#s8-how-to-teach">How to Teach</a></li><li><a href="#s9-act-3-literate-programming">Act 3: "Literate Programming"</a></li><li><a href="#s10-the-anatomy-of-good-documentation">The Anatomy of Good Documentation</a></li><li><a href="#s11-first-contact">First Contact</a></li><li><a href="#s12-act-4-read-the-docstrings">Act 4: "Read the Docstrings"</a></li><li><a href="#s13-the-black-triangle">The Black Triangle</a></li><li><a href="#s14-act-5-read-the-api-docs">Act 5: "Read the API Docs"</a></li><li><a href="#s15-the-hairball">The Hairball</a></li><li><a href="#s16-act-6-read-the-wiki">Act 6: "Read the Wiki"</a></li><li><a href="#s17-the-reference">The Reference</a></li><li><a href="#s18-act-7-a-new-hope">Act 7: "A New Hope"</a></li></ol>

<h2 id="s1-prior-reading"><a href="#s1-prior-reading">Prior Reading</a></h2>

<p>Before you read this post there are two other things I think you should read
first.</p>

<p>The first is Jacob Kaplan-Moss' <a href="http://jacobian.org/writing/great-documentation/">Writing Great Documentation</a> series.  He's
certainly more qualified than I am to write about this stuff, so you should
check that out if you haven't already.  A lot of what I say here is going to
agree with and build on the ideas he talked about.</p>

<p>The other thing you should read is <a href="http://www.americanscientist.org/issues/id.877,y.0,no.,content.true,page.1,css.print/issue.aspx">The Science of Scientific Writing</a> by
George Gopen and Judith Swan.  Don't be put off by the fact that it's written
for scientists publishing papers in journals.  Everything in that article
applies equally well to programmers writing technical docs.  Read the entire
thing.  It's worth it.</p>

<h2 id="s2-why-do-we-document"><a href="#s2-why-do-we-document">Why Do We Document?</a></h2>

<p>Let's get started.  The first thing to nail down is <em>why</em> we're documenting
a programming language or library in the first place.  There are many things you
might want to accomplish, but I'm going to boil them down into a single
statement:</p>

<p><strong>The purpose of technical documentation is to take someone who has never seen
your project, teach them to be an expert user of it, and support them once they
become an expert.</strong></p>

<p>At first glance this probably doesn't seem too controversial or interesting.
But there's one word in there that makes <em>all</em> the difference, and it frames my
entire perspective on documentation.</p>

<h2 id="s3-teaching"><a href="#s3-teaching">Teaching</a></h2>

<p>If you want to take a person who has never played the guitar and turn them into
a virtuoso guitarist, how can you do that?</p>

<p>You <em>teach</em> them.</p>

<p>If you want to take a high school student and turn them into a computer
scientist, how can you do that?</p>

<p>You <em>teach</em> them.</p>

<p>If you want to take a programmer who has never seen your library before and turn
them into an expert user of it, how can you do that?</p>

<p>You <em>teach</em> them!</p>

<p>Guitar lessons are usually taught in person, one-on-one, with a teacher.
Computer Science is usually taught by professors in classrooms.  Programming
library usage is usually taught by documentation.</p>

<p>If the goal of documentation is to turn novices into experts, then <em>the
documentation must teach</em>.  You should think of your documentation as a lesson
(or series of lessons) because <em>that's what it is</em>.</p>

<p>When writing technical documentation you (usually) don't have the advantage of
having a one-on-one dialog with the learners.  This makes it a bit more
difficult, but not impossible as long as you're careful.  Your documentation
needs to fill the role of both the in-person lessons <em>and</em> the textbook.</p>

<p>The rest of this post will be almost entirely about how to apply the
"documentation is teaching" mindset to writing programming docs.</p>

<h2 id="s4-a-play-in-seven-acts"><a href="#s4-a-play-in-seven-acts">A Play in Seven Acts</a></h2>

<p>I'm going to break up the content of this post with some venting about <em>bad</em>
documentation.  If you want to skip these little rants, go ahead.</p>

<p>Each act in our play has two characters: a teenager and a parent.  The teenager
has just turned sixteen and would like to learn to drive so they can hang out
with their friends without relying on their parents to drive them everywhere.</p>

<p>Each act will demonstrate a caricature of a particularly <em>bad</em> form of
documentation.  I hope these little metaphors will help show why certain forms
of documentation are ineffective cop-outs and why you should write <em>real</em>
documentation instead.</p>

<h2 id="s5-act-1-read-the-source"><a href="#s5-act-1-read-the-source">Act 1: "Read the Source"</a></h2>

<p>Our play starts with a son and father sitting at the breakfast table.  The son
is munching on some cereal before school while the father reads his iPad before
leaving for work.</p>

<p>The son says: "Hey Dad, you said you were going to teach me how to drive after
school today.  Are we still going to do that?"</p>

<p>The father, without looking up from his iPad, replies: "Of course, son.  The car
is in the garage and I laid out a set of wrenches on the workbench.  Take the
car apart and look at each piece, then put it back together.  Once you've done
that I'll take you to the DMV for your driving test."</p>

<p>The son quietly continued eating his cereal.</p>

<p>If you use many open source libraries you've undoubtedly encountered some whose
README says something like "read the source".  Every time I see one, I die
a little bit inside.</p>

<p>Source code is <em>not</em> documentation.  Can you learn to be a guitarist by simply
listening to a piece of music intently?  Can you become a painter by visiting
a lot of museums?  Of course not!</p>

<p>Let me be clear: I'm not trying to say that reading source code isn't a valuable
thing to do.  It is!</p>

<p>Looking at other artists' paintings is extremely useful <em>once you know how to
paint</em>.  Learning how the brakes of a car are constructed can save your life,
<em>once you know how to drive</em>.</p>

<p>Once your library's users know how to work with it, reading its source is
absolutely worth their time.  But you can't look at the finished product and
understand the perspective and ideas that went into it without additional
guidance.  That's a job for documentation.</p>



<p>Writing good documentation doesn't take much in the way of tools.</p>

<p>For example: you don't need a thesaurus.  Don't try to avoid using the same
words by substituting synonyms.  Just talk to your users like you would talk to
another human being in real life!</p>

<p>If you use the same word ten times in a row your readers probably won't even
notice.  But I guarantee they're going to notice if you throw in strange,
uncommon words for no good reason.</p>

<p>There are two tools I <em>will</em> recommend before moving on.  The first isn't
actually a tool, but a skill.</p>

<p>To write great documentation, you need to be able to type.</p>

<p>When you write docs you'll inevitably write yourself into a corner and realize
you need to take a new direction.  If you don't type quickly, you might be
hesitant to throw away writing that doesn't really work.  You need to learn to
type well so you don't feel bad throwing away a chunk of a thousand words that
don't fit.</p>

<p>Steve Yegge's article <a href="http://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html">Programming's Dirty Little Secret</a> is
a great rant on this topic.</p>

<p>You should also get yourself a nice keyboard.  A good keyboard won't make you
a good writer (just like a good guitar won't make you a good guitarist), but it
<em>will</em> make you want to write more just for the sheer joy of using
a well-designed piece of equipment.</p>

<p>I started practicing guitar a lot more after I got a new guitar that was much
nicer than my old one.  If you spend a hundred dollars, get a nice keyboard, and
end up wanting to write more, it was worth it!</p>

<p>Be thankful that a nice keyboard only costs $100 to $300 and not several
thousand dollars like a nice instrument.</p>

<h2 id="s7-act-2-read-the-tests"><a href="#s7-act-2-read-the-tests">Act 2: "Read the Tests"</a></h2>

<p>The next scene opens with a mother picking her daughter up from high school.</p>

<p>"Hi Mom", she says, "are you still going to teach me to drive today?"</p>

<p>"Yep!" she replies.  "Let's get going."</p>

<p>After ten minutes of driving they arrive at the Chevrolet factory.</p>

<p>The girl looks around, puzzled.  She asks: "What are we doing here?"</p>

<p>The mother smiles and says: "You're in luck, honey, my friend Jim works here at
the Chevy plant, and he's gonna let you watch a few crash tests of the new
Malibu!  Once you see a few cars smash into each other, I'll take you down to
the DMV for your driving test."</p>

<p>Another common form of "documentation" is the README instructing users to "read
the tests".</p>

<p>Tests aren't docs.</p>

<p>Again, let's be clear: once you already know how to use a library, reading the
tests is <em>very</em> useful.  But you need documentation to make you an expert user
first!</p>

<p>You don't learn to drive by watching crash tests.  But learning how your car
behaves during a crash can save your life <em>once you know how to drive</em>.</p>

<p>A common argument I see goes something like this:</p>

<p>"The tests use the library, so they're a good example of how to use it!"</p>

<p>This is true in some very superficial sense, but completely misses the mark.</p>

<p>Most of the tests are probably going to deal with edge cases.  Edge cases are
things a normal user won't be encountering very often (otherwise they wouldn't
be edge cases!).</p>

<p>If you're lucky, you might get a test that verifies the library works correctly
on a normal set of input.  But a "normal set of input" is what the users are
going to be working with the majority the time!</p>

<p>Tests simply aren't a good guide to what a user is going to be encountering on
a day-to-day basis.  They can't teach a novice to be an expert.</p>

<h2 id="s8-how-to-teach"><a href="#s8-how-to-teach">How to Teach</a></h2>

<p>If you accept my idea that the purpose of documentation is to <em>teach</em> users, the
next question is obviously: "How do I teach my users?"</p>

<p>I've been lucky enough to have the chance to teach dancing semi-formally for
around 6 or 7 years, and lots of various other things informally for a long
time.  The only way to <em>really</em> learn how to teach is to <em>do it</em>.</p>

<p>There's no substitute for sitting down with someone face-to-face and teaching
them something.  <strong>If you want to write better documentation, you need to
practice teaching</strong>.</p>

<p>I'm not talking about writing out lesson plans or anything nearly so formal.  Do
you have a hobby (not programming)?  If so, spend a couple of hours on a weekend
teaching a friend about it.  You'll get some practice teaching and they'll get
to learn something new.</p>

<p>(If you don't have any non-programming hobbies, maybe you should find some.)</p>

<p>If you like photography, teach someone the basics of exposure and composition.
If you dance, teach them some basic steps.  If you play an instrument, teach
them how to play a simple song.  If you like camping, teach them what all the
gear is for.  You get the idea.</p>

<p>Don't go overboard.  You don't need to give someone a degree, you just need to
practice teaching a little bit.  You need to practice the art of rewiring
someone's neurons with your words.</p>

<p>Once you jump into teaching something (even something simple) you'll probably
realize that although you know how to do it yourself, it's a lot harder to teach
someone else.</p>

<p>This is obvious when you're working face-to-face with someone.  When you tell
them how to play a C major chord on the guitar and they only produce a strangled
squeak, it's clear that you need to slow down and talk about how to press down
on the strings properly.</p>

<p>As programmers, we almost <em>never</em> get this kind of feedback about our
documentation.  We don't see that the person on the other end of the wire is
hopelessly confused and blundering around because they're missing something we
thought was obvious (but wasn't).  Teaching someone in person helps you learn to
anticipate this, which will pay off (for your users) when you're writing
documentation.</p>

<p>With all that said, I do want to also talk a little about the actual process of
teaching.</p>

<p>The best description of how to teach that I've seen so far is from the book <a href="http://www.amazon.com/dp/069111966X/?tag=stelos-20">How
to Solve It</a>.  Everyone who wants to teach should read this book.  The passage
that really jumped out at me is right in the first page of the first chapter:</p>

<blockquote>
<p>The best [way for the teacher to help their student] is to help the student
naturally.  The teacher should put himself in the student's place, he should
see the student's case, he should try to understand what is going on in the
student's mind, and ask a question or indicate a step that <em>could have
occurred to the student himself</em>.</p>
</blockquote>

<p>This, right here, is the core of teaching.  This is it.  This is how you do it.</p>

<p>People don't learn by simply absorbing lots of unstructured information as it's
thrown at them.  You can't read a Spanish dictionary to someone to teach them
Spanish.</p>

<p>When you want to teach someone you need to put yourself in their shoes and walk
along the path with them.  Hold their hand, guide them around the dangerous
obstacles and catch them when they fall.  <em>Don't</em> carry them.  <em>Certainly
don't</em> just drive them to the destination in your car!</p>

<p>The process needs to go something like this:</p>

<ol>
<li>Figure out what they already know.</li>
<li>Figure out what you want them to know after you finish.</li>
<li>Figure out a single idea or concept that will move state 1 a little bit
   closer to state 2.</li>
<li>Nudge the student in the direction of that idea.</li>
<li>Repeat until state 1 becomes state 2.</li>
</ol>

<p>Too often I see documentation that has very carefully considered step 2, and
then simply presents it to the reader as a pronouncement from God.  That isn't
teaching.  That's telling.  People don't learn by being <em>told</em>, they
learn by being <em>taught</em>.</p>

<h2 id="s9-act-3-literate-programming"><a href="#s9-act-3-literate-programming">Act 3: "Literate Programming"</a></h2>

<p>The third act opens with a daughter talking to her mother the day before her
sixteenth birthday.</p>

<p>"Hey Mom," she says, "I don't know if you got me a present yet, but if not, what
I'd <em>really</em> like for my birthday are driving lessons."</p>

<p>The mother smiles and says: "Don't worry, it's all taken care of.  Just wait for
tomorrow."</p>

<p>The next day at her birthday party she unwraps the present from her mom.  Inside
is a DVD of the show How It's Made.  She looks quizzically at her mother.</p>

<p>"That DVD has an episode about the factory that builds your car!  Once you watch
the whole thing I'll take you for your driving test."</p>

<p>A horrible trend I've noticed lately is using "literate programming" tools like
Docco, Rocco, etc and telling users to read the results for documentation.</p>

<p>Programming languages and libraries are tools.  Knowing how a tool was made
doesn't mean you know how to use it.  When you take guitar lessons, you don't
visit a luthier to watch her shape a Telecaster out of Ash wood.</p>

<p>Knowing how your car was built can help you, <em>once you know how to drive</em>.</p>

<p>Knowing how your guitar was built can help you, <em>once you know how to play</em>.</p>

<p>A common theme throughout these acts/rants is that all of these things I'm
picking on (source, tests, literate programming, and more) are good things with
real benefits <em>once you have actual documentation in place to teach users</em>. </p>

<p>But until that happens, they're actually <em>bad</em> because they let you pretend
you've written documentation and your job is done (JKM mentions this in his
series).  Your job is not done until you've taught your users enough to become
experts.  <em>Then</em> they can take advantage of all these extras.</p>

<h2 id="s10-the-anatomy-of-good-documentation"><a href="#s10-the-anatomy-of-good-documentation">The Anatomy of Good Documentation</a></h2>

<p>The rest of this post is going to be about the individual components that make
up good documentation.  My views are pretty similar to JKM's, so if you haven't
read the series I mentioned in the first section you should probably do that.</p>

<p>In my mind I divide good documentation into roughly four parts:</p>

<ol>
<li>First Contact</li>
<li>The Black Triangle</li>
<li>The Hairball</li>
<li>The Reference</li>
</ol>

<p>There don't necessarily have to be four separate documents for each of these.
In fact the first two can usually be combined into a single file, while the last
two should probably be split into many pieces.  But I think each component is
a distinct, important part of good documentation.</p>

<p>Let's take a look at each.</p>



<p>When you release a new programming language or library into the wild, the
initial state of your "users" is going to be blank.  The things they need
to know when they encounter your library are:</p>

<ol>
<li>What is this thing?</li>
<li>Why would I care about this thing?</li>
<li>Is it worth the effort to learn this thing?</li>
</ol>

<p>Your "first contact" documentation should explain these things to them.</p>

<p>You don't need to explain things from first principles.  Try to put yourself in
the shoes of your users.  When you're teaching your teenager to drive, you don't
need to explain what a "wheel" is.  They probably have some experience with
"things on wheels that you move around in" like lawn mowers or golf carts (or
even video games).</p>

<p>Likewise: if you're creating a web framework, most of the people that stumble on
to your project are probably going to know what "HTML" is.  It's good to err
a little bit on the side of caution and explain a little more than to assume too
much, but you can be practical here.</p>

<p>Your "first contact" docs should explain what, in plain words, your thing does.
It should show someone why they should care about that.  Will it save them time?
Will it take more time, but be more stable in exchange?  Is it just plain fun?</p>

<p>For bonus points, you can also mention why someone might want to <em>not</em> use your
project.  Barely anyone ever mentions the tradeoffs involved with using their
work, so to see a project do this is refreshing.</p>

<p>Finally, the user needs to know if it's worth spending some of their finite
amount of time on this planet learning more about your project.  You should
explicitly spell out things like:</p>

<ul>
<li>What license the project uses (so they know if it's practical to use).</li>
<li>Where the bug tracker is (so they can see issues).</li>
<li>Where the source code is (so they can see if it's (relatively) recently
  maintained).</li>
<li>Where the documentation is (so they can skim it and get an idea of the effort
  that's going to be involved in becoming an expert).</li>
</ul>

<h2 id="s12-act-4-read-the-docstrings"><a href="#s12-act-4-read-the-docstrings">Act 4: "Read the Docstrings"</a></h2>

<p>Scene four.  A father is finally making good on his promise to give his daughter
driving lessons.</p>

<p>"Okay Dad," she says, "I'm ready.  I've never driven a car before.  Where do we
start?"</p>

<p>A woman in her mid-forties walks through the door.  "Who's this?" the daughter
asks.</p>

<p>"This is your driving teacher, Ms. Smith." the father replies.  "She's going to
sit in the passenger seat with you while you drive the two hour trip to visit
grandpa.  If you have any questions about a part of the car while you're
driving, you can ask her and she'll tell you all about that piece.  Here are
the keys, good luck!"</p>

<p>In languages with <a href="https://en.wikipedia.org/wiki/Docstring">docstrings</a> there's a tendency to write great docstrings
and call them documentation.  I'm sure the "doc" in the word "docstrings"
contributes to this.</p>

<p>Docstrings don't provide any organization or order (beyond "the namespace they
happen to be implemented in").  Users need to somehow know the name of the
function they need to even be able to <em>see</em> the docstring, and they can't know
that unless you <em>teach</em> them.</p>

<p>Again, docstrings are great <em>once you know the project</em>.  But when you're
teaching a novice how to use your library, you need to guide them along they
way and not sit back and answer questions when they manage to guess a magic
word correctly.</p>

<h2 id="s13-the-black-triangle"><a href="#s13-the-black-triangle">The Black Triangle</a></h2>

<p>The next important piece of documentation is <a href="http://rampantgames.com/blog/2004/10/black-triangle.html">the "black triangle"</a>.  It
should be a relatively short guide to getting your project up and running so the
user can poke at it.</p>

<p>This serves a couple of purposes.  First, it lets the user verify that yes, this
collection of bytes is actually going to run and <em>do something</em> on their
machine.  It's a quick sanity check that the project hasn't bit rotted and is
still viable to use at that point in time.  More importantly, it lets your
prospective user <a href="http://worrydream.com/LearnableProgramming/#react">get some paint on the canvas</a>.</p>

<p>Imagine if you went to your first guitar lesson and the teacher said: "Okay,
we're going to start by learning 150 different chords.  Then in about six months
we can play some songs."  No guitar teacher does that.  They teach you three
chords and give you a couple of cheesy pop songs to play.  It helps the student
get a feel for what being a guitarist as a whole is going to be like, and it
gives them something to help keep their interest.</p>

<p>Your "black triangle" documentation should be a short guide that runs the user
through the process of retrieving, installing, and poking your project or
language.</p>

<p>"Short" here is a relative word.  Some projects are going to require more setup
to get running.  If the benefits are enough to justify the effort, that's not
necessarily a problem.  But try to keep this as short as possible.  <em>Just get
something on the screen</em> and move on.</p>

<h2 id="s14-act-5-read-the-api-docs"><a href="#s14-act-5-read-the-api-docs">Act 5: "Read the API Docs"</a></h2>

<p>Our next scene opens a year after the last, with the father from the last scene
talking to his son.</p>

<p>(Sadly, the daughter in that scene died in a car crash because she didn't know
to ask Ms. Smith about seatbelts before getting on the expressway.  Ms.  Smith
was wearing hers, of course.)</p>

<p>"Okay son, I know you're a little scared of driving because of what happened to
your sister, but I've fixed the problem."</p>

<p>He hands the young man an inch-thick book.  "Asking Ms. Smith questions along
the way clearly didn't work, so we had her write out a paragraph or two about
each piece of your car.  Go ahead and read the entire manual cover to cover and
then drive down to see grandpa."</p>

<p>API documentation is like the user's manual of a car.  When something goes wrong
and you need to replace a tire it's a godsend.  But if you're learning to drive
it's not going to help you because <em>people don't learn by reading alphabetized
lists of disconnected information</em>.</p>

<p>If you actually try to teach someone to use your project face-to-face, you'll
probably find yourself talking about things in one namespace for a while, then
switching to another to cover something related, then switching back to the
first.  Learning isn't a straight path through the alphabet, it's a zig-zaggy
ramble through someone else's brain.</p>

<h2 id="s15-the-hairball"><a href="#s15-the-hairball">The Hairball</a></h2>

<p>This brings me to the next type of documentation: "the hairball".  By now the
user has hopefully seen the "first contact" docs and the "black triangle" docs.
You've got them hooked and ready to learn, but they're still novices.</p>

<p>The "hairball" is the twisted, tangled maze of teaching that is going to take
these novices and turn them into expert users.  It's going to mold their brains,
one nudge at a time, until they have a pretty good understanding of how your
project works.</p>

<p>You'll usually want to organize the "hairball" into sections (unless this is
a very small project).  These sections will probably <em>kind of</em> line up with
namespaces in your project's public API, but when it makes sense to deviate you
should do so.</p>

<p>Don't be afraid to write.  Be concise but err on the side of explaining a bit
too much.  Programmers are pretty good at skimming over things they already
know, but if you forget to include a crucial connection it can leave your users
lost and stumbling around in the woods.</p>

<p>You should have a table of contents that lists each section of the "hairball".
And then each section should have its own table of contents that lists the
sections inside it.  A table of contents is a wonderful way to get a birds-eye
view of what you're about to read, to prepare your brain for it.  And of
course it's also handy for navigating around.</p>

<p>This is where your hobby-teaching practice and your reading of How to Solve It
are going to come in handy.  Put yourself in a user's brain and figure out each
little connective leap they're going to need to make to become an expert.</p>

<h2 id="s16-act-6-read-the-wiki"><a href="#s16-act-6-read-the-wiki">Act 6: "Read the Wiki"</a></h2>

<p>In the penultimate scene, a mother has signed her teenage son up for an
after-school driving class.</p>

<p>On the first day, the teacher hands them a syllabus detailing what they're going
to cover, talks about grading, and sends them home a bit early.</p>

<p>On the second day, she gives them a brief overview of the various pieces of
a car and how they work together.  She also talks about a few of the most
important laws they'll need to be aware of.</p>

<p>On the third day, the teacher calls in sick and they have a substitute.  He
covers the material for half of the fifth day in the syllabus.  He has to leave
early, so he brings in his nineteen year old daughter to finish the class.
She covers the first half of the fourth day's material.</p>

<p>The fourth day the students arrive to find a note on the door saying the class
has been cancelled because the teacher is still sick and they can't find
a substitute.  There's a note saying "TODO: we'll talk about the material
later."</p>

<p>The fifth day the teacher has partially recovered, so she returns and covers the
material for the fifth day.  It's a bit hard to understand her because she's had
half a bottle of Nyquil and is slurring most of her words and keeps saying
"cat" instead of "car".</p>

<p>All the students fail the driving test.</p>

<p>Wikis are an abomination.  They are the worst form of "documentation".</p>

<p>First of all: assuming they work as intended, they have no coherent voice.</p>

<p>Have you ever taken a class with multiple teachers at once?  Probably not,
because it doesn't work very well (with exceptions for things like partnered
dancing where there are distinct lead/follow parts).</p>

<p>Worse still: have you ever taken a class where there's one jackass in the room
who keeps constantly raising his hand and offering his own (often incorrect)
opinions?  Wikis are like that, except they <em>actively encourage</em> random people
to interrupt the teacher with their own interjections.</p>

<p>I can hear the objections now: "But putting our docs on a wiki means <em>anyone</em>
can fix typos!"</p>

<p>Jesus.  Christ.</p>

<p>"It makes it easy to fix typos" is a horrible argument for using a wiki.</p>

<p>First of all, as JKM says, you should have an editor (or at least someone to
proofread) which will catch a lot of the typos.</p>

<p>And even if there <em>are</em> typos, they're one of the least important things you
need to worry about anyway.  Misspelling "their" isn't going to impact the
effectiveness of your teaching very much.  Your lessons being a disorganized
mess because they were written by three different people across six months <em>is</em>
going to make them less effective.</p>

<p>Keeping your documentation in a wiki also makes it hard or impossible to keep it
where it belongs: in version control right alongside your code.</p>

<p>But all that is irrelevant because aside from Wikipedia itself and video game
wikis, <em>they don't fucking work</em>.</p>

<p>The project maintainer sets up a wiki, sits back and pats herself on the back
saying: "I have set up a way for other people to do this boring job of writing
documentation for me.  Now we wait." </p>

<p>Maybe one or two people fix some typos.  A dude who thinks he understands
a topic but actually doesn't writes some completely wrong docs.  Maybe they get
reverted, maybe they don't.</p>

<p>The project changes.  A new user reads some of the (sparse) documentation which
is now out of date.  Eventually they discover this and complain only to be met
with: "Well it's a wiki, fix it yourself!"</p>

<p>It is not the responsibility of the student to fix a broken lesson plan.  For
fuck's sake, <em>the entire point of having a teacher</em> is that they know what the
students need to learn and the students don't!</p>

<p>It's completely okay to ask your students for criticism so you can improve your
lesson plan.  Asking "what parts did you find difficult?" is fine.  It's another
thing entirely to ask them to <em>write your lesson plan for you</em>.</p>

<p>Seriously: fuck wikis.  They are bad and terrible.  Do not use them.  Take the
time and effort to write some real documentation instead.</p>

<h2 id="s17-the-reference"><a href="#s17-the-reference">The Reference</a></h2>

<p>The final type of documentation is "the reference".  This section is for the
users who have traveled through the "hairball" and made it to the other side.
They're now your experts, and the reference should support them as they use your
project in their daily work.</p>

<p>This section should contain things that experienced users are likely to need,
such as:</p>

<ul>
<li>"API documentation" for every user-facing part of your project.</li>
<li>A full changelog, with particular attention to backwards-incompatible changes
  between versions.</li>
<li>Details about the internal implementation of the project.</li>
<li>Contribution policies (if your project accepts outside contributions).</li>
</ul>

<p>Tools like JavaDoc can produce something that looks like the first, but I share
the same opinion as Jacob Kaplan-Moss:</p>

<blockquote>
<p>Auto-generated documentation is almost worthless. At best it's a slightly
improved version of simply browsing through the source, but most of the time
it's easier just to read the source than to navigate the bullshit that these
autodoc tools produce. About the only thing auto-generated documentation is
good for is filling printed pages when contracts dictate delivery of a certain
number of pages of documentation. I feel a particularly deep form of rage
every time I click on a "documentation" link and see auto-generated
documentation.</p>

<p>There's no substitute for documentation written, organized, and edited by
hand.</p>
</blockquote>

<p>Yes, you can probably find a tool to read your project's source and shit out
some HTML files with the function names in them.  Maybe it will even include the
docstrings!</p>

<p>I would still urge you to write your API docs by hand.  It's going to be
a little more typing, but the results will be much better for a number of
reasons.</p>

<p>API docs and docstrings, while similar, serve different purposes.  Docstrings
have to provide what you need in the heat of coding in a REPL-friendly format.
API docs can afford the luxury of a bit more explanation, as well as links to
other things the user might want to know while browsing them on their couch.
API docs should also be Google-friendly.</p>

<p>A common objection here is that you're going to be retyping a lot of words.
Copy and paste mostly solves that problem, and learning to type makes the rest
a non-issue.</p>

<p>Some will say: "But copy and pasting is evil!  You're duplicating effort!  How
will you keep the changes in the docstrings and the API docs in sync if they
change?"</p>

<p>My opinion here is that if your public-facing API is changing often, you're
probably going to be making your users' lives harder when they need to
constantly update their code to work with yours.  So the least you can do is
make <em>your</em> life a little harder to provide them with the best documentation
possible to help ease the pain.</p>

<p>Auto-generated documentation has no coherent voice.  It pulls in everything in
the code without regard for overall structure and vision.  You can <em>probably</em>
get away with it for the API docs in your "reference" documentation, or you
could take some pride in your work and write the best docs possible!</p>

<h2 id="s18-act-7-a-new-hope"><a href="#s18-act-7-a-new-hope">Act 7: "A New Hope"</a></h2>

<p>The final act of our play is set in a mall parking lot on a Sunday afternoon.
A single car is in the parking lot.  Inside is a family: a mother and father who
are teaching their son to drive.</p>

<p>They start by driving the car into the middle of the lot, away from any
obstacles.  The son gets into the driver's seat, and the parents explain briefly
what the main controls do.  They let him drive around the empty lot a bit to get
a feel for how the car works.</p>

<p>When it's time for him to park he shifts to park and takes off his seatbelt.
His mom reminds him of the control called a "parking brake".  He realizes that
he should use this when parking.  A set of neurons is now linked in his brain
and he will remember to use the parking brake properly for the rest of his life.</p>

<p>Over time the parents take their son driving many times, always being sure that
they're putting him into situations he can handle (but will still learn from).
He drives on a road, then learns to parallel park, then drives on a highway.</p>

<p>He has questions along the way.  Sometimes the parents are ready with an answer.
Sometimes the questions reveal something else missing deeper down in his
knowledge which the parents correct.</p>

<p>Over time he learns more and more.  He gets his license and begins driving on
his own.</p>

<p>When he gets a flat tire he reads the owner's manual and fixes it.</p>

<p>He watches the How It's Made episode about his car because he's curious how the
brakes which saved his life at a stop sign last week actually work.</p>

<p>His windshield wipers stop working one day.  He opens up the hood and figures
out the problem, fixing it himself.</p>

<p>One day he is hit by a drunk driver.  He walks away with only bruises.  He never
saw the countless crash tests the engineers performed to create the airbag
system, but they saved his life.</p>

<p>In the last scene we see the son many years later.  His hair is a bit gray now,
but otherwise he looks a lot like the teenager who forgot to use the parking
brake.</p>

<p>He's in a car with his teenage daughter, and he's teaching her how to drive.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>