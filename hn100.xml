<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 25 Aug 2025 12:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What are OKLCH colors? (343 pts)]]></title>
            <link>https://jakub.kr/components/oklch-colors</link>
            <guid>45010876</guid>
            <pubDate>Mon, 25 Aug 2025 06:32:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakub.kr/components/oklch-colors">https://jakub.kr/components/oklch-colors</a>, See on <a href="https://news.ycombinator.com/item?id=45010876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header></header>
<p>OKLCH is a newer color model that is designed to be perceptually uniform. This means that colors are much more accurate in terms of how humans perceive them and it makes working with them much easier.</p>


<p>Color Models</p>
<p>Before being able to understand how OKLCH differs from the other color models, it is important to understand some of the basic color concepts.</p>

<p>Color models are systems to describe colors. These include RGB, HSL, LCH, OKLCH and more. The model determines how easy it is to manipulate or think about a color.</p>

<p>Gamut</p>
<p>Gamut is a playing field where the model lives and defines what colors are possible. Common gamuts include sRGB (the web default) and Display-P3 (used on modern devices).</p>

<p>There is a lot more nuance when you get into color spaces. They don’t just define a gamut, but also things like the white point and transfer function. I decided to leave those out for the sake of keeping the article simple.</p>

<p>Structure</p>
<p>OKLCH, same as LCH, consists of three values: Lightness, Chroma and Hue. The difference between the two is the underlying color space that the color model uses, which in case of OKLCH, is <a href="https://en.wikipedia.org/wiki/Oklab_color_space" target="_blank" rel="noreferrer">OKLab</a>.</p>

<p>Lightness - Equal steps feel like equal changes in brightness. Ranges from value between 0 and 1 or percentage ranging from 0% to 100%.</p>

<p>Chroma - Controls intensity of the color, similar to saturation.</p>

<p>Hue - Controls the hue, measured in degrees ranging from 0 to 360.</p>


<p>Consistent Brightness</p>
<p>Let's say you want to create a couple of pill buttons and you want each one to have a different color. The usual workflow with sRGB colors would be defining the first color and then handpicking others to match it.</p>

<p>With OKLCH, you can use the same value for all of them and only change hue. That way you create colors that look and feel the same.</p>

<p>You can do the same thing with color models like HSL, but as you can see above, the colors don't look uniform. Some are lighter, some darker, some pop more and some less.</p>

<p>This is one of the major advantages of OKLCH over other color models. Creating perceptually uniform color palettes and working with them is very easy.</p>
<p>Predictable Shades</p>
<p>It also works the other way around, where you can change the lightness value to create various color shades and there is no hue or saturation drift unlike in other color modes.</p>

<p>In the example above, you can see that the OKLCH colors maintain consistent blueness across all of the shades, while in the HSL example, the lighter shades drift to purple and the darker ones muddy out towards grayish.</p>
<p>Better Gradients</p>
<p>The way gradients work in OKLCH is pretty different compared to sRGB. In sRGB, gradients are calculated in red, green, and blue values, which often leads to muddy midpoints and uneven brightness.</p>

<p>With OKLCH, the math follows lightness, chroma, and hue. In the example above you can see that the starting and ending points are the same but the colors the gradient passes through are quite different.</p>

<p>Color Space Support</p>
<p>sRGB can’t reach a lot of colors that modern screens can show. In OKLCH you can write colors that are only possible to render on a screen that supports Display-P3 colors.</p>

<p>If you are on a display that supports Display-P3, you will see the right color much more vivid than the left one. If you are on a display that only supports sRGB, the color should look identical, as the browser maps the out of gamut color back inside the sRGB gamut.</p>

<p>Keep in mind that grays are identical in sRGB and Display-P3, so there would be no difference there.</p>
<p>Maximum Chroma</p>
<p>OKLCH can also define more colors than any real screen can show. It can specify values that don't fit inside any actual gamut like sRGB or Display-P3.</p>

<p>Let's take this color as an example <code>color: oklch(0.7 0.4 40)</code>. It has a very high chroma value and it could mathematically exist but in practice it lies outside of any real display's gamut. When this color is used, it will get clipped or mapped to the nearest representable color inside the gamut.</p>
<pre tabindex="0"><code data-language="css" data-theme="github-dark github-light"><span data-line=""><span>@layer</span><span> base {</span></span>
<span data-line=""><span>  :root</span><span> {</span></span>
<span data-line=""><span>    color</span><span>: </span><span>oklch</span><span>(</span><span>0.7</span><span> 0.4</span><span> 40</span><span>);</span></span>
<span data-line=""><span>  }</span></span>
<span data-line=""><span>}</span></span></code></pre>
<p>Generally you don't want this to happen, as the clipped color can often look very different from the defined one.</p>

<p>Therefore, there is a concept of a maximum chroma value, which calculates the maximum chroma that a display can show based on the lightness, hue and the selected gamut like sRGB or Display-P3.</p>

<p>Browser Support &amp; Fallbacks</p>
<p>OKLCH colors were introduced in <a href="https://www.w3.org/TR/css-color-4/" target="_blank" rel="noreferrer">CSS Color Module Level 4</a> and they are well supported across all modern browsers.</p>

<p>However, there are still some surfaces where OKLCH colors are not supported such as outdated browsers. In case you are worried about this, you can add fallbacks and use the <code>@supports</code> directive in CSS.</p>
<pre tabindex="0"><code data-language="css" data-theme="github-dark github-light"><span data-line=""><span>@layer</span><span> base {</span></span>
<span data-line=""><span>  :root</span><span> {</span></span>
<span data-line=""><span>    /* sRGB hex */</span></span>
<span data-line=""><span>    --color-gray-100</span><span>: </span><span>#fcfcfc</span><span>;</span></span>
<span data-line=""><span>    --color-gray-200</span><span>: </span><span>#fafafa</span><span>;</span></span>
<span data-line=""><span>    --color-gray-300</span><span>: </span><span>#f4f4f4</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    @</span><span>supports</span><span> (</span><span>color</span><span>: </span><span>oklch</span><span>(</span><span>0</span><span> 0</span><span> 0</span><span>)) {</span></span>
<span data-line=""><span>      /* OKLCH */</span></span>
<span data-line=""><span>      --color-gray-100</span><span>: </span><span>oklch</span><span>(</span><span>0.991</span><span> 0</span><span> 0</span><span>);</span></span>
<span data-line=""><span>      --color-gray-200</span><span>: </span><span>oklch</span><span>(</span><span>0.982</span><span> 0</span><span> 0</span><span>);</span></span>
<span data-line=""><span>      --color-gray-300</span><span>: </span><span>oklch</span><span>(</span><span>0.955</span><span> 0</span><span> 0</span><span>);</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>  }</span></span>
<span data-line=""><span>}</span></span></code></pre>
<p>This way the browser uses OKLCH colors if they are supported, otherwise it falls back to sRGB.</p>

<p>oklch.fyi</p>
<p>I built a small tool dedicated to OKLCH colors called <a href="https://oklch.fyi/" target="_blank" rel="noreferrer">oklch.fyi</a>. It helps generate OKLCH colors palettes, it can take your existing CSS variables and convert them to OKLCH and more.</p>
<span><img alt="oklch.fyi" loading="lazy" width="1200" height="630" decoding="async" data-nimg="1" srcset="https://jakub.kr/_next/image?url=https%3A%2F%2Foiszjiwtfc65cwa2.public.blob.vercel-storage.com%2Foklch%2Foklchfyi.png&amp;w=1200&amp;q=75 1x, https://jakub.kr/_next/image?url=https%3A%2F%2Foiszjiwtfc65cwa2.public.blob.vercel-storage.com%2Foklch%2Foklchfyi.png&amp;w=3840&amp;q=75 2x" src="https://jakub.kr/_next/image?url=https%3A%2F%2Foiszjiwtfc65cwa2.public.blob.vercel-storage.com%2Foklch%2Foklchfyi.png&amp;w=3840&amp;q=75"><span></span></span>
<a target="_blank" rel="noreferrer" href="https://oklch.fyi/">Try it out!</a>

<p>More</p>
<p>In case you have any questions reach me at <a href="mailto:jakub@kbo.sk" target="_blank" rel="noreferrer">jakub@kbo.sk</a> or see more of my work on <a href="https://twitter.com/jakubkrehel" target="_blank" rel="noreferrer">Twitter</a>.</p><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bro, ban me at the IP level if you don't like me (339 pts)]]></title>
            <link>https://boston.conman.org/2025/08/21.1</link>
            <guid>45010183</guid>
            <pubDate>Mon, 25 Aug 2025 04:23:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://boston.conman.org/2025/08/21.1">https://boston.conman.org/2025/08/21.1</a>, See on <a href="https://news.ycombinator.com/item?id=45010183">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<!-- google_ad_section_start --> <!-- Hey, it can't hurt! -->
<h2><a name="2025-08-21" href="https://boston.conman.org/2025/08/21">Thursday, August 21, 2025</a></h2>

<h3><a rel="bookmark" name="2025-08-21.1" href="https://boston.conman.org/2025/08/21.1">“Bro, ban me at the IP level if you don't like me!”</a></h3>

<!-- Butlerian Jihad, bad webbots, Thinkbot, blocking by ASN -->

<p>More and more I think I'm coming around to <a href="https://alexschroeder.ch/view/Butlerian_Jihad">Jihad Alex Schroeder's Butlerian Jihad</a>.
For reasons,
I'm looking into web activity and so far,
the top webbot this month is one identifying itself as “Thinkbot,”
which <em>may</em> be related to <a href="https://www.thinkbot.agency/">this <abbr title="Artificial Intelligence">AI</abbr> company</a> but I can't be sure.
Here's how it itentifies itself: “Mozilla/5.0 (compatible; Thinkbot/0.5.8; +In­_the­_test­_phase,­_if­_the­_Thinkbot­_brings­_you­_trouble,­_please­_block­_its_<abbr title="Internet Protocol">IP</abbr>_address._Thank_you.)”.</p>

<p>Seriously,
that's it.
No <abbr title="Uniform Resource Locator">URL</abbr> to read up on it.
It doesn't look at the <code>robots.txt</code> file.
Just “bro,
ban me at the <abbr title="Internet Protocol">IP</abbr> level if you don't like me!”

</p><p>Yeah,
block its <abbr title="Internet Protocol">IP</abbr> address.
You mean the 74 unique addresses it used this month alone?
<a href="https://boston.conman.org/2025/03/21.2">Checking each <abbr title="Internet Protocol">IP</abbr> address for the <abbr title="Autonomous System Number">ASN</abbr> it's from</a> shows the 74 address coming from 41 (41!) network blocks!</p>

<p>A further check showed that all the network blocks are owned by one organization—<a href="https://en.wikipedia.org/wiki/Tencent">Tencent</a>.
I'm seriously thinking that the <abbr title="Chinese Communist Party">CCP</abbr> encourage this with maybe the hope of externalizing the cost of the <a href="https://en.wikipedia.org/wiki/Great_Firewall">Great Firewall</a> to the rest of the world.
If China scrapes content,
that's fine as far as the <abbr title="Chinese Communist Party">CCP</abbr> goes;
If it's blocked,
that's fine by the <abbr title="Chinese Communist Party">CCP</abbr> too
(I say,
as I adjust my <a href="https://en.wikipedia.org/wiki/Tin_foil_hat">tin foil hat</a>).</p>

<p>In any case,
I added the following network blocks to my “badbots firewall rule set:”

</p><pre>43.130.0.0/18
43.130.64.0/18
43.130.128.0/19
43.130.160.0/19
43.131.0.0/18
43.132.192.0/18
43.133.64.0/19
43.134.128.0/18
43.135.0.0/18
43.135.64.0/18
43.135.192.0/19
43.153.0.0/18
43.153.192.0/18
43.154.64.0/18
43.154.128.0/18
43.154.192.0/18
43.155.0.0/18
43.155.128.0/18
43.156.192.0/18
43.157.0.0/18
43.157.64.0/18
43.157.128.0/18
43.159.128.0/19
43.163.64.0/18
43.164.192.0/18
43.165.128.0/18
43.166.128.0/18
43.166.224.0/19
49.51.132.0/23
49.51.140.0/23
49.51.166.0/23
101.32.0.0/20
101.32.48.0/20
101.33.64.0/19
119.28.64.0/19
119.28.128.0/20
129.226.160.0/19
150.109.32.0/19
150.109.96.0/19
170.106.32.0/19
170.106.176.0/20
</pre>

<p>The above list probably doesn't exhaustively enummerate Tencent's network block ownership,
but it's a start.
The above covers 476,590 unique <abbr title="Internet Protocol">IP</abbr> addresses
(excluding the base network and broadcast address for each network block).
I think it's bad that I had to do this,
but with the current landscape of the Internet,
it seems inevitable.
We can't have nice things it seems.</p>

<hr>

<h4>Discussions about this entry</h4>

<ul>
<li><a href="https://lobste.rs/s/pmfuza/bro_ban_me_at_ip_level_if_you_don_t_like_me">Bro, ban me at the IP level if you don't like me | Lobsters</a></li>
<li><a href="https://lemmy.bestiver.se/post/575504">Bro, ban me at the IP level if you don't like me - Lemmy: Bestiverse</a></li>
<li><a href="https://news.ycombinator.com/item?id=45010183">Bro, ban me at the IP level if you don't like me | Hacker News</a></li>

</ul>


<!-- google_ad_section_end -->
</div><div id="lawyer">

        <p>You have my permission to link freely to any entry here.  Go
        ahead, I won't bite.  I promise.</p>
        
        <p>The dates are the permanent links to that day's entries (or
        entry, if there is only one entry).  The titles are the permanent
        links to <em>that</em> entry only.  The format for the links are
        simple: Start with the base link for this site: <a class="page" href="https://boston.conman.org/">https://boston.conman.org/</a>, then add the date you are
        interested in, say <a href="https://boston.conman.org/2000/08/01">2000/08/01</a>,
        so that would make the final <abbr title="Uniform Resource
        Locator">URL</abbr>:</p>
        
        <p><a class="page" href="https://boston.conman.org/2000/08/01">https://boston.conman.org/2000/08/01</a></p>
        
        <p>You can also specify the entire month by leaving off the day
        portion.  You can even select <a class="page" href="https://boston.conman.org/about/technical.html">an arbitrary portion of time.</a></p>
        
        <p>You may also note subtle shading of the links and that's
        intentional: the “closer” the link is (relative to the
        page) the “brighter” it appears.  It's an experiment in
        using color shading to denote the distance a link is from here.  If
        you don't notice it, don't worry; it's not all <em>that</em>
        important.</p>
        
        <p>It is assumed that every brand name, slogan, corporate name,
        symbol, design element, et cetera mentioned in these pages is a
        protected and/or trademarked entity, the sole property of its
        owner(s), and acknowledgement of this status is implied.</p>
        
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git-Annex (142 pts)]]></title>
            <link>https://git-annex.branchable.com/</link>
            <guid>45010161</guid>
            <pubDate>Mon, 25 Aug 2025 04:18:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://git-annex.branchable.com/">https://git-annex.branchable.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45010161">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">









<section id="pagebody" role="main">
<p>git-annex allows managing large files with git, without storing the file
contents in git. It can sync, backup, and archive your data, offline
and online. Checksums and encryption keep your data safe and secure. Bring
the power and distributed nature of git to bear on your large files with
git-annex.</p>

<p><a href="https://git-annex.branchable.com/assistant/"><img src="https://git-annex.branchable.com/assistant/thumbnail.png" width="216" height="28"></a>
git-annex is designed for git users who love the command line.
For everyone else, the <a href="https://git-annex.branchable.com/assistant/">git-annex assistant</a> turns
git-annex into an easy to use folder synchroniser.</p>

<p>To get a feel for git-annex, see the <a href="https://git-annex.branchable.com/walkthrough/">walkthrough</a>.</p>






<table>
<tbody><tr>
<td><h3>use case: The Archivist</h3>

<p>Bob has many drives to archive his data, most of them
<a href="https://git-annex.branchable.com/tips/offline_archive_drives/">kept offline</a>, in a safe place.</p>

<p>With git-annex, Bob has a single directory tree that includes all
his files, even if their content is being stored offline. He can
reorganize his files using that tree, committing new versions to git,
without worry about accidentally deleting anything.</p>

<p>When Bob needs access to some files, git-annex can tell him which drive(s)
they're on, and easily make them available. Indeed, every drive knows what
is on every other drive.<br>
<small><a href="https://git-annex.branchable.com/location_tracking/">more about location tracking</a></small></p>

<p>Bob thinks long-term, and so he appreciates that git-annex uses a simple
repository format. He knows his files will be accessible in the future
even if the world has forgotten about git-annex and git.<br>
<small><a href="https://git-annex.branchable.com/future_proofing/">more about future-proofing</a></small></p>

<p>Run in a cron job, git-annex adds new files to archival drives at night. It
also helps Bob keep track of intentional and unintentional copies of
files, and logs information he can use to decide when it's time to duplicate
the content of old drives.<br>
<small><a href="https://git-annex.branchable.com/copies/">more about backup copies</a></small></p>



</td>
<td><h3>use case: The Nomad</h3>

<p>Alice is always on the move, often with her trusty netbook and a small
handheld terabyte USB drive, or a smaller USB keydrive. She has a server
out there on the net. She stores data, encrypted in the Cloud.</p>

<p>All these things can have different files on them, but Alice no longer
has to deal with the tedious process of keeping them manually in sync,
or remembering where she put a file. git-annex manages all these data
sources as if they were git remotes.<br>
<small><a href="https://git-annex.branchable.com/special_remotes/">more about special remotes</a></small></p>

<p>When she has 1 bar on her cell, Alice queues up interesting files on her
server for later. At a coffee shop, she has git-annex download them to her
USB drive. High in the sky or in a remote cabin, she catches up on
podcasts, videos, and games, first letting git-annex copy them from
her USB drive to the netbook (this saves battery power).<br>
<small><a href="https://git-annex.branchable.com/transferring_data/">more about transferring data</a></small></p>

<p>When she's done, she tells git-annex which to keep and which to remove.
They're all removed from her netbook to save space, and Alice knows
that next time she syncs up to the net, her changes will be synced back
to her server.<br>
<small><a href="https://git-annex.branchable.com/distributed_version_control/">more about distributed version control</a></small></p>



</td>
</tr>
</tbody></table>


<p>If that describes you, or if you're some from column A and some from column
B, then git-annex may be the tool you've been looking for to expand from
keeping all your small important files in git, to managing your large
files with git.</p>




<hr>

<p>git-annex is <a href="https://git-annex.branchable.com/license/">Free Software</a>, written in <a href="http://www.haskell.org/">Haskell</a>.
You can <a href="https://git-annex.branchable.com/contribute/">contribute</a>!</p>

<p>git-annex's wiki is powered by <a href="http://ikiwiki.info/">Ikiwiki</a> and
hosted by <a href="http://branchable.com/">Branchable</a>.</p>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unix-Haters Handbook (1994) [pdf] (105 pts)]]></title>
            <link>https://simson.net/ref/ugh.pdf</link>
            <guid>45009164</guid>
            <pubDate>Mon, 25 Aug 2025 00:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simson.net/ref/ugh.pdf">https://simson.net/ref/ugh.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45009164">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Sping – An HTTP/TCP latency tool that's easy on the eye (140 pts)]]></title>
            <link>https://dseltzer.gitlab.io/sping/docs/</link>
            <guid>45008819</guid>
            <pubDate>Sun, 24 Aug 2025 23:42:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dseltzer.gitlab.io/sping/docs/">https://dseltzer.gitlab.io/sping/docs/</a>, See on <a href="https://news.ycombinator.com/item?id=45008819">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p>Latest Version: 0.2.11</p>
<h2>service-ping (sping)</h2>

<p>Modern terminal HTTP/TCP latency monitoring tool with real-time visualization. Think <code>httping</code> meets modern CLI design with rich terminal UI, phase timing, and advanced analytics.</p>

<p><strong>Status</strong>: Feature-complete MVP with HTTP/TCP support, phase timing, outlier detection, and comprehensive monitoring capabilities.</p>

<h2>Demo</h2>

<p><img src="https://dseltzer.gitlab.io/sping/docs/demo.gif" alt="sping Interactive Demo" width="50%"></p>

<p><em>Real-time latency monitoring with interactive charts showing HTTP response times, outlier detection, and live statistics.</em></p>

<h2>Why?</h2>

<p>I've frequently found myself using <a href="https://github.com/XuehaiPan/nvitop">nvitop</a> to diagnose GPU/CPU contention issues.</p>

<p>The two best things about it are:</p>

<ul>
<li>It's easy to install if I can access pip in the container</li>
<li>It makes a compelling screenshot (which helps me communicate with coworkers.)</li>
</ul>

<p>With those two lessons in mind: <strong>Here is Sping!</strong></p>

<p><strong>Purpose</strong>: Help observe and diagnose latency issues at layer 4+ (TCP/HTTP/HTTPS)</p>

<p>Two good things about it:</p>

<ul>
<li>It's easy to install if you have pip. (Available at <a href="https://pypi.org/project/service-ping-sping/">service-ping-sping</a> on PyPi)</li>
<li>It makes a compelling screenshot.</li>
</ul>

<h2>Features</h2>

<ul>
<li>🌐 <strong>HTTP &amp; TCP Monitoring</strong>: Support for <code>http://</code>, <code>https://</code>, and <code>tcp://</code> protocols</li>
<li>📊 <strong>Real-time Visualization</strong>: Interactive charts and live statistics in your terminal</li>
<li>🔍 <strong>Phase Breakdown</strong>: DNS, connection, TLS, request, and response timing</li>
<li>🚨 <strong>Outlier Detection</strong>: Automatic outlier detection using MAD (Median Absolute Deviation)</li>
<li>⚠️ <strong>Threshold Alerting</strong>: Warning and critical thresholds with exit codes</li>
<li>🌍 <strong>DNS Control</strong>: IPv4/IPv6 selection and DNS resolution caching</li>
<li>📈 <strong>Advanced Statistics</strong>: Percentiles (p50, p90, p95, p99), standard deviation</li>
<li>💾 <strong>Multiple Output Formats</strong>: Interactive UI, plain text, JSON, and JSON export</li>
<li>🔐 <strong>Authentication</strong>: Bearer tokens and basic auth support</li>
<li>🎨 <strong>Rich Terminal UI</strong>: Beautiful charts, color-coded logs, and responsive layouts</li>
<li>🌈 <strong>Color Palettes</strong>: Choose from 8 themed color schemes (sunset, ocean, forest, volcano, galaxy, arctic, neon, monochrome)</li>
</ul>

<h2>Install</h2>

<div>
<pre><span></span><code>pip<span> </span>install<span> </span>service-ping-sping
</code></pre>
</div>

<p>For development:</p>



<h2>Quick Start</h2>

<div>
<pre><span></span><code><span># HTTP monitoring with interactive UI</span>
sping<span> </span>google.com

<span># TCP connection monitoring</span>
sping<span> </span>tcp://google.com:80

<span># HTTPS with custom options</span>
sping<span> </span>https://api.example.com<span> </span>--interval<span> </span><span>0</span>.5<span> </span>--count<span> </span><span>20</span>

<span># JSON output for automation</span>
sping<span> </span>google.com<span> </span>--json<span> </span>--count<span> </span><span>5</span>

<span># Advanced monitoring with thresholds</span>
sping<span> </span>example.com<span> </span>--warn<span> </span><span>100</span><span> </span>--crit<span> </span><span>500</span><span> </span>--percentiles

<span># Try different color themes</span>
sping<span> </span>example.com<span> </span>--palette<span> </span>ocean
</code></pre>
</div>

<h2>Usage Examples</h2>

<h3>HTTP/HTTPS Monitoring</h3>

<div>
<pre><span></span><code><span># Basic HTTP monitoring (auto-adds http://)</span>
sping<span> </span>example.com

<span># HTTPS with custom method and body transfer</span>
sping<span> </span>https://api.example.com<span> </span>--method<span> </span>POST<span> </span>--body

<span># IPv4 only with DNS caching</span>
sping<span> </span>google.com<span> </span>--ipv4<span> </span>--resolve-once

<span># With authentication</span>
sping<span> </span>api.example.com<span> </span>--auth<span> </span><span>"bearer:your-token"</span>
sping<span> </span>api.example.com<span> </span>--auth<span> </span><span>"user:password"</span>
</code></pre>
</div>

<h3>TCP Connection Monitoring</h3>

<div>
<pre><span></span><code><span># Test TCP connectivity</span>
sping<span> </span>tcp://google.com:80
sping<span> </span>tcp://example.com:443

<span># Monitor database connections</span>
sping<span> </span>tcp://localhost:5432<span> </span>--interval<span> </span><span>0</span>.1
</code></pre>
</div>

<h3>Advanced Features</h3>

<div>
<pre><span></span><code><span># Outlier detection and thresholds</span>
sping<span> </span>example.com<span> </span>--warn<span> </span><span>100</span><span> </span>--crit<span> </span><span>500</span><span> </span>--count<span> </span><span>100</span>

<span># Export detailed timing data</span>
sping<span> </span>example.com<span> </span>--export-file<span> </span>results.json<span> </span>--count<span> </span><span>50</span>

<span># Show percentile statistics</span>
sping<span> </span>example.com<span> </span>--percentiles<span> </span>--count<span> </span><span>100</span>

<span># Plain output for scripting</span>
sping<span> </span>example.com<span> </span>--plain<span> </span>--count<span> </span><span>5</span>
</code></pre>
</div>

<h2>Outlier Detection</h2>

<p>sping automatically detects unusual latency spikes using <strong>Median Absolute Deviation (MAD)</strong> analysis:</p>

<h3>What Counts as an Outlier</h3>

<ul>
<li><strong>Latency outliers</strong>: Response times that deviate significantly from recent baseline performance</li>
<li><strong>Statistical threshold</strong>: Latencies that are more than <strong>6x the MAD</strong> away from the median</li>
<li><strong>Baseline requirement</strong>: Needs at least 10 successful samples to establish baseline  </li>
<li><strong>Rolling window</strong>: Uses the last 30 successful requests to calculate normal behavior</li>
<li><strong>Successful requests only</strong>: Only analyzes successful responses (errors are tracked separately)</li>
</ul>

<h3>How It Works</h3>

<ol>
<li><strong>Baseline calculation</strong>: Median of recent 30 successful latencies (e.g., 100ms)</li>
<li><strong>Variability measure</strong>: MAD of those latencies (e.g., 15ms)  </li>
<li><strong>Outlier threshold</strong>: <code>|current_latency - median| / MAD &gt; 6.0</code></li>
<li><strong>Example</strong>: If baseline is 100ms ± 15ms MAD, requests &gt; 190ms or &lt; 10ms would be outliers</li>
</ol>

<h3>Visual Indicators</h3>

<ul>
<li><strong>Interactive mode</strong>: Outlier requests show <code>[OUTLIER]</code> marker in the log</li>
<li><strong>Statistics bar</strong>: Shows red outlier count when detected (e.g., <code>outliers 3</code>)</li>
<li><strong>JSON output</strong>: <code>"anomaly": true</code> field in export data (kept for API compatibility)</li>
</ul>

<p><em>Note: Outlier detection helps identify performance degradation, network issues, or service problems that might not trigger error thresholds.</em></p>

<h2>Command Line Options</h2>

<h3>Core Options</h3>

<ul>
<li><code>-i, --interval FLOAT</code>: Seconds between probes (default: 1.0)</li>
<li><code>-c, --count INT</code>: Number of probes then exit</li>
<li><code>--timeout FLOAT</code>: Request timeout in seconds (default: 10.0)</li>
<li><code>-X, --method TEXT</code>: HTTP method (default: HEAD)</li>
</ul>

<h3>Protocol &amp; DNS</h3>

<ul>
<li><code>--ipv4</code>: Force IPv4 only</li>
<li><code>--ipv6</code>: Force IPv6 only  </li>
<li><code>--resolve-once</code>: Resolve DNS only once and cache</li>
</ul>

<h3>HTTP Options</h3>

<ul>
<li><code>--body</code>: Include full body transfer time</li>
<li><code>--no-keepalive</code>: Disable persistent connections</li>
<li><code>--user-agent TEXT</code>: Custom User-Agent string</li>
<li><code>--auth TEXT</code>: Authentication (user:pass or bearer:token)</li>
<li><code>--insecure</code>: Skip TLS verification</li>
</ul>

<h3>Monitoring &amp; Alerts</h3>

<ul>
<li><code>--warn FLOAT</code>: Warning threshold in milliseconds</li>
<li><code>--crit FLOAT</code>: Critical threshold in milliseconds</li>
<li><code>--percentiles</code>: Show percentile statistics in summary</li>
</ul>

<h3>UI &amp; Display</h3>

<ul>
<li><code>--refresh-rate FLOAT</code>: UI update throttling in Hz (default: 4.0, higher = more responsive, lower = less CPU)</li>
<li><code>--palette PALETTE</code>: Color palette for latency visualization (default: sunset)</li>
<li><code>--xterm-colors-only</code>: Force basic terminal color compatibility (useful for older terminals)</li>
</ul>

<h3>Color Palettes</h3>

<p>Choose from beautiful themed color palettes to customize your latency visualization:</p>

<h4>Sunset Palette (Default)</h4>

<p><em>Warm oranges and reds reminiscent of a beautiful sunset</em></p>

<p><span title="#626262"></span><code>#626262</code> <span title="#808080"></span><code>#808080</code> <span title="#6B59C3"></span><code>#6B59C3</code> <span title="#836FFF"></span><code>#836FFF</code> <span title="#8968CD"></span><code>#8968CD</code> <span title="#AB82FF"></span><code>#AB82FF</code> <span title="#CD96CD"></span><code>#CD96CD</code> <span title="#FFBBFF"></span><code>#FFBBFF</code> <span title="#CD8C95"></span><code>#CD8C95</code> <span title="#FFAEB9"></span><code>#FFAEB9</code></p>

<details><br>
<summary><strong>View All Color Palettes</strong></summary>

<h4>Ocean Palette</h4>

<p><em>Cool blues and teals like ocean depths</em></p>

<p><span title="#000080"></span><code>#000080</code> <span title="#0000FF"></span><code>#0000FF</code> <span title="#1874CD"></span><code>#1874CD</code> <span title="#1E90FF"></span><code>#1E90FF</code> <span title="#009ACD"></span><code>#009ACD</code> <span title="#00BFFF"></span><code>#00BFFF</code> <span title="#00CDCD"></span><code>#00CDCD</code> <span title="#00FFFF"></span><code>#00FFFF</code> <span title="#66CDAA"></span><code>#66CDAA</code> <span title="#7FFFD4"></span><code>#7FFFD4</code></p>

<h4>Forest Palette</h4>

<p><em>Natural greens from deep forest to bright sunlight</em></p>

<p><span title="#BC8F8F"></span><code>#BC8F8F</code> <span title="#D2B48C"></span><code>#D2B48C</code> <span title="#F4A460"></span><code>#F4A460</code> <span title="#A2CD5A"></span><code>#A2CD5A</code> <span title="#BCEE68"></span><code>#BCEE68</code> <span title="#006400"></span><code>#006400</code> <span title="#008B00"></span><code>#008B00</code> <span title="#00CD00"></span><code>#00CD00</code> <span title="#00FF00"></span><code>#00FF00</code> <span title="#66FF66"></span><code>#66FF66</code></p>

<h4>Volcano Palette</h4>

<p><em>Fiery reds and oranges like molten lava</em></p>

<p><span title="#8B0000"></span><code>#8B0000</code> <span title="#CD0000"></span><code>#CD0000</code> <span title="#FF0000"></span><code>#FF0000</code> <span title="#FF4500"></span><code>#FF4500</code> <span title="#CD6600"></span><code>#CD6600</code> <span title="#FF8C00"></span><code>#FF8C00</code> <span title="#FFA500"></span><code>#FFA500</code> <span title="#CDAD00"></span><code>#CDAD00</code> <span title="#FFD700"></span><code>#FFD700</code> <span title="#FFFF66"></span><code>#FFFF66</code></p>

<h4>Galaxy Palette</h4>

<p><em>Cosmic purples and magentas of deep space</em></p>

<p><span title="#551A8B"></span><code>#551A8B</code> <span title="#7D26CD"></span><code>#7D26CD</code> <span title="#AB82FF"></span><code>#AB82FF</code> <span title="#CD00CD"></span><code>#CD00CD</code> <span title="#EE00EE"></span><code>#EE00EE</code> <span title="#FF00FF"></span><code>#FF00FF</code> <span title="#CD6090"></span><code>#CD6090</code> <span title="#FF1493"></span><code>#FF1493</code> <span title="#CD919E"></span><code>#CD919E</code> <span title="#FF00FF"></span><code>#FF00FF</code></p>

<h4>Arctic Palette</h4>

<p><em>Crisp blues and whites of polar ice</em></p>

<p><span title="#4682B4"></span><code>#4682B4</code> <span title="#A2B5CD"></span><code>#A2B5CD</code> <span title="#CAE1FF"></span><code>#CAE1FF</code> <span title="#E0EEEE"></span><code>#E0EEEE</code> <span title="#E0FFFF"></span><code>#E0FFFF</code> <span title="#FFFFFF"></span><code>#FFFFFF</code> <span title="#8DB6CD"></span><code>#8DB6CD</code> <span title="#B0E2FF"></span><code>#B0E2FF</code> <span title="#87CEEB"></span><code>#87CEEB</code> <span title="#FFFFFF"></span><code>#FFFFFF</code></p>

<h4>Neon Palette</h4>

<p><em>Bright electric colors for a cyberpunk feel</em></p>

<p><span title="#1C1C1C"></span><code>#1C1C1C</code> <span title="#4D4D4D"></span><code>#4D4D4D</code> <span title="#0000FF"></span><code>#0000FF</code> <span title="#1E90FF"></span><code>#1E90FF</code> <span title="#00FFFF"></span><code>#00FFFF</code> <span title="#00FF7F"></span><code>#00FF7F</code> <span title="#7FFF00"></span><code>#7FFF00</code> <span title="#FFFF00"></span><code>#FFFF00</code> <span title="#FF1493"></span><code>#FF1493</code> <span title="#FF00FF"></span><code>#FF00FF</code></p>

<h4>Monochrome Palette</h4>

<p><em>Classic grayscale gradient</em></p>

<p><span title="#121212"></span><code>#121212</code> <span title="#262626"></span><code>#262626</code> <span title="#3A3A3A"></span><code>#3A3A3A</code> <span title="#4D4D4D"></span><code>#4D4D4D</code> <span title="#626262"></span><code>#626262</code> <span title="#808080"></span><code>#808080</code> <span title="#9E9E9E"></span><code>#9E9E9E</code> <span title="#B2B2B2"></span><code>#B2B2B2</code> <span title="#D6D6D6"></span><code>#D6D6D6</code> <span title="#EDEDED"></span><code>#EDEDED</code></p>

</details>

<div>
<pre><span></span><code><span># Examples with different palettes</span>
sping<span> </span>example.com<span> </span>--palette<span> </span>ocean
sping<span> </span>example.com<span> </span>--palette<span> </span>volcano<span> </span>--count<span> </span><span>20</span>
sping<span> </span>example.com<span> </span>--palette<span> </span>neon<span> </span>--percentiles
</code></pre>
</div>

<h4>Color Compatibility Notes</h4>

<p><strong>Terminal Color Support</strong>: sping automatically detects your terminal's color capabilities and adjusts accordingly. However, older terminals or certain environments may experience:</p>

<ul>
<li><strong>Limited Color Support</strong>: Older terminals may only support basic ANSI colors rather than rich RGB colors</li>
<li><strong>Solution</strong>: Set <code>TERM=xterm-256color</code> in your environment or use <code>--xterm-colors-only</code> for consistent basic colors</li>
<li><strong>Compatibility Mode</strong>: Use <code>--xterm-colors-only</code> to force basic terminal colors that work everywhere</li>
</ul>

<div>
<pre><span></span><code><span># For maximum compatibility with older terminals</span>
sping<span> </span>example.com<span> </span>--xterm-colors-only

<span># Or set environment variable for better color support</span>
<span>TERM</span><span>=</span>xterm-256color<span> </span>sping<span> </span>example.com
</code></pre>
</div>

<h3>Output Formats</h3>

<ul>
<li><code>--json</code>: JSON output mode (one object per line)</li>
<li><code>--plain</code>: Plain text output mode</li>
<li><code>--export-file FILE</code>: Export JSON results to file</li>
</ul>

<h2>Output Formats</h2>

<h3>Interactive Mode (Default)</h3>

<p>Real-time terminal UI with:</p>

<ul>
<li>Live latency chart with gradient coloring</li>
<li>Recent requests log with timing details</li>
<li>Statistics panel with min/mean/max/stdev</li>
<li>Outlier highlighting and threshold indicators</li>
</ul>

<h3>Plain Text Mode (<code>--plain</code>)</h3>

<pre><code>[1] 1755658486.287: 484.313ms 200 (application/json) from httpbin.org (52.1.207.236)
--- https://httpbin.org/get sping summary ---
1 probes, 1 ok, 0 errors
Latency (ms): min 484.313 mean 484.313 max 484.313
</code></pre>

<h3>JSON Mode (<code>--json</code>)</h3>

<div>
<pre><span></span><code><span>{</span><span>"seq"</span><span>:</span><span> </span><span>1</span><span>,</span><span> </span><span>"timestamp"</span><span>:</span><span> </span><span>1755658729.193</span><span>,</span><span> </span><span>"latency_ms"</span><span>:</span><span> </span><span>11.110</span><span>,</span><span> </span><span>"status_code"</span><span>:</span><span> </span><span>0</span><span>,</span><span> </span><span>"error"</span><span>:</span><span> </span><span>null</span><span>,</span><span> </span><span>"bytes_read"</span><span>:</span><span> </span><span>0</span><span>,</span><span> </span><span>"content_type"</span><span>:</span><span> </span><span>"tcp/connection"</span><span>,</span><span> </span><span>"host_address"</span><span>:</span><span> </span><span>"google.com (142.250.65.238)"</span><span>,</span><span> </span><span>"anomaly"</span><span>:</span><span> </span><span>false</span><span>,</span><span> </span><span>"phases"</span><span>:</span><span> </span><span>{</span><span>"dns_ms"</span><span>:</span><span> </span><span>5.444</span><span>,</span><span> </span><span>"connect_ms"</span><span>:</span><span> </span><span>5.598</span><span>,</span><span> </span><span>"tls_ms"</span><span>:</span><span> </span><span>null</span><span>,</span><span> </span><span>"request_write_ms"</span><span>:</span><span> </span><span>null</span><span>,</span><span> </span><span>"ttfb_ms"</span><span>:</span><span> </span><span>null</span><span>,</span><span> </span><span>"body_read_ms"</span><span>:</span><span> </span><span>null</span><span>,</span><span> </span><span>"total_ms"</span><span>:</span><span> </span><span>11.110</span><span>}}</span>
</code></pre>
</div>

<h2>Phase Timing Breakdown</h2>

<p>sping provides detailed timing for each phase of the connection:</p>

<ul>
<li><strong>DNS</strong>: Domain name resolution time</li>
<li><strong>Connect</strong>: TCP connection establishment  </li>
<li><strong>TLS</strong>: TLS/SSL handshake time (HTTPS only)</li>
<li><strong>Request Write</strong>: Time to send HTTP request</li>
<li><strong>TTFB</strong>: Time to first byte (response headers)</li>
<li><strong>Body Read</strong>: Time to read response body</li>
<li><strong>Total</strong>: End-to-end request time</li>
</ul>

<h2>Exit Codes</h2>

<ul>
<li><code>0</code>: Success</li>
<li><code>1</code>: Warning threshold exceeded (when <code>--warn</code> specified)</li>
<li><code>2</code>: Critical threshold exceeded (when <code>--crit</code> specified)</li>
</ul>

<p>Perfect for monitoring scripts and alerting systems.</p>

<h2>Quit Interactive Mode</h2>

<p>Press <code>Ctrl+C</code> to gracefully exit and see the final summary.</p>

<h2>Requirements</h2>

<ul>
<li>Python 3.9+</li>
<li>Modern terminal with color support recommended</li>
<li>Works on Linux, macOS, and Windows</li>
</ul>

<h2>License</h2>

<p>MIT - see <a href="https://gitlab.com/dseltzer/sping/-/blob/master/LICENSE.md">LICENSE.md</a></p>
<hr><p><small>Latest documentation • <a href="https://dseltzer.gitlab.io/sping/docs/0.2.11/">Version 0.2.11 specific docs</a> • <a href="https://pypi.org/project/service-ping-sping/" target="_blank">Install from PyPI</a></small></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ghrc.io Appears to Be Malicious (365 pts)]]></title>
            <link>https://bmitch.net/blog/2025-08-22-ghrc-appears-malicious/</link>
            <guid>45008740</guid>
            <pubDate>Sun, 24 Aug 2025 23:27:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bmitch.net/blog/2025-08-22-ghrc-appears-malicious/">https://bmitch.net/blog/2025-08-22-ghrc-appears-malicious/</a>, See on <a href="https://news.ycombinator.com/item?id=45008740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>A simple typo of ghcr.io to ghrc.io would normally be a small goof.
You’d typically get a 404 or similar error, finally work out the issue, fix it, and move along.
But in this case, that typo appears to be doing something very malicious, stealing GitHub credentials.</p><h2 id="whats-ghcrio">What’s ghcr.io?</h2><p>First, a quick bit of background.
<code>ghcr.io</code> is an OCI conformant registry for container images and OCI artifacts used by a lot of projects.
It’s part of GitHub and is a very popular image and artifact repository used by open source projects.</p><h2 id="ghrcio-is-just-a-default-nginx">ghrc.io Is Just a Default Nginx</h2><p>At first glance, <code>ghrc.io</code> is just a default nginx install:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://ghrc.io/
</span></span><span><span>HTTP/2 <span>200</span>
</span></span><span><span>server: nginx
</span></span><span><span>date: Fri, <span>22</span> Aug <span>2025</span> 17:58:01 GMT
</span></span><span><span>content-type: text/html
</span></span><span><span>content-length: <span>615</span>
</span></span><span><span>last-modified: Tue, <span>23</span> Apr <span>2024</span> 14:04:32 GMT
</span></span><span><span>etag: <span>"6627bff0-267"</span>
</span></span><span><span>strict-transport-security: max-age<span>=</span>31536000<span>;</span> includeSubDomains
</span></span><span><span>accept-ranges: bytes
</span></span><span><span>
</span></span><span><span>&lt;!DOCTYPE html&gt;
</span></span><span><span>&lt;html&gt;
</span></span><span><span>&lt;head&gt;
</span></span><span><span>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span><span>&lt;style&gt;
</span></span><span><span>html <span>{</span> color-scheme: light dark<span>;</span> <span>}</span>
</span></span><span><span>body <span>{</span> width: 35em<span>;</span> margin: <span>0</span> auto<span>;</span>
</span></span><span><span>font-family: Tahoma, Verdana, Arial, sans-serif<span>;</span> <span>}</span>
</span></span><span><span>&lt;/style&gt;
</span></span><span><span>&lt;/head&gt;
</span></span><span><span>&lt;body&gt;
</span></span><span><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span><span><span>&lt;p&gt;If you see this page, the nginx web server is successfully installed and
</span></span><span><span>working. Further configuration is required.&lt;/p&gt;
</span></span><span><span>
</span></span><span><span>&lt;p&gt;For online documentation and support please refer to
</span></span><span><span>&lt;a <span>href</span><span>=</span><span>"http://nginx.org/"</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
</span></span><span><span>Commercial support is available at
</span></span><span><span>&lt;a <span>href</span><span>=</span><span>"http://nginx.com/"</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;
</span></span><span><span>
</span></span><span><span>&lt;p&gt;&lt;em&gt;Thank you <span>for</span> using nginx.&lt;/em&gt;&lt;/p&gt;
</span></span><span><span>&lt;/body&gt;
</span></span><span><span>&lt;/html&gt;
</span></span></code></pre></div><p>Even checking other links gives a typical 404 error:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://ghrc.io/404/
</span></span><span><span>HTTP/2 <span>404</span>
</span></span><span><span>server: nginx
</span></span><span><span>date: Fri, <span>22</span> Aug <span>2025</span> 17:58:04 GMT
</span></span><span><span>content-type: text/html
</span></span><span><span>content-length: <span>146</span>
</span></span><span><span>strict-transport-security: max-age<span>=</span>31536000<span>;</span> includeSubDomains
</span></span><span><span>
</span></span><span><span>&lt;html&gt;
</span></span><span><span>&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;
</span></span><span><span>&lt;body&gt;
</span></span><span><span>&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;
</span></span><span><span>&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;
</span></span><span><span>&lt;/body&gt;
</span></span><span><span>&lt;/html&gt;
</span></span></code></pre></div><h2 id="why-is-it-malicious">Why Is It Malicious?</h2><p>The concerning part comes in when looking at the OCI API’s.
Those are all under the <code>/v2/</code> prefix for legacy reasons.
Looking at <code>ghrc.io</code>, suddenly it’s not acting like a default nginx install anymore:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://ghrc.io/v2/
</span></span><span><span>HTTP/2 <span>401</span>
</span></span><span><span>server: nginx
</span></span><span><span>date: Fri, <span>22</span> Aug <span>2025</span> 17:56:36 GMT
</span></span><span><span>content-type: application/json
</span></span><span><span>content-length: <span>72</span>
</span></span><span><span>www-authenticate: Bearer <span>realm</span><span>=</span><span>"https://ghrc.io/token"</span>
</span></span><span><span>
</span></span><span><span><span>{</span><span>"errors"</span>:<span>[{</span><span>"code"</span>:<span>"UNAUTHORIZED"</span>,<span>"message"</span>:<span>"authentication required"</span><span>}]}</span>
</span></span></code></pre></div><p>Compare that to some other registries and you’ll see the 401 status, <code>www-authenticate</code> header, and error message look very similar:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://ghcr.io/v2/
</span></span><span><span>HTTP/2 <span>401</span>
</span></span><span><span>content-type: application/json
</span></span><span><span>docker-distribution-api-version: registry/2.0
</span></span><span><span>strict-transport-security: max-age<span>=</span>63072000<span>;</span> includeSubDomains<span>;</span> preload
</span></span><span><span>www-authenticate: Bearer <span>realm</span><span>=</span><span>"https://ghcr.io/token"</span>,service<span>=</span><span>"ghcr.io"</span>,scope<span>=</span><span>"repository:user/image:pull"</span>
</span></span><span><span>date: Fri, <span>22</span> Aug <span>2025</span> 17:51:36 GMT
</span></span><span><span>content-length: <span>73</span>
</span></span><span><span>x-github-request-id: DA46:5B047:5EDB5D:66E5C2:68A8AE28
</span></span><span><span>
</span></span><span><span><span>{</span><span>"errors"</span>:<span>[{</span><span>"code"</span>:<span>"UNAUTHORIZED"</span>,<span>"message"</span>:<span>"authentication required"</span><span>}]}</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://registry-1.docker.io/v2/
</span></span><span><span>HTTP/2 <span>401</span>
</span></span><span><span>date: Sun, <span>24</span> Aug <span>2025</span> 17:31:43 GMT
</span></span><span><span>content-type: application/json
</span></span><span><span>content-length: <span>87</span>
</span></span><span><span>docker-distribution-api-version: registry/2.0
</span></span><span><span>www-authenticate: Bearer <span>realm</span><span>=</span><span>"https://auth.docker.io/token"</span>,service<span>=</span><span>"registry.docker.io"</span>
</span></span><span><span>strict-transport-security: max-age<span>=</span><span>31536000</span>
</span></span><span><span>
</span></span><span><span><span>{</span><span>"errors"</span>:<span>[{</span><span>"code"</span>:<span>"UNAUTHORIZED"</span>,<span>"message"</span>:<span>"authentication required"</span>,<span>"detail"</span>:null<span>}]}</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="shell"><span><span>$ curl -i https://quay.io/v2/
</span></span><span><span>HTTP/2 <span>401</span>
</span></span><span><span>date: Sun, <span>24</span> Aug <span>2025</span> 17:32:18 GMT
</span></span><span><span>content-type: text/html<span>;</span> <span>charset</span><span>=</span>utf-8
</span></span><span><span>content-length: <span>4</span>
</span></span><span><span>server: nginx/1.22.1
</span></span><span><span>www-authenticate: Bearer <span>realm</span><span>=</span><span>"https://quay.io/v2/auth"</span>,service<span>=</span><span>"quay.io"</span>
</span></span><span><span>docker-distribution-api-version: registry/2.0
</span></span><span><span>
</span></span><span><span><span>true</span>
</span></span></code></pre></div><p>The (optional) error message is defined by the <a href="https://github.com/opencontainers/distribution-spec/">OCI Distribution Spec</a> along with the various OCI APIs under the <code>/v2/</code> prefix.
Authentication hasn’t been standardized by OCI, yet, but projects all use the <a href="https://distribution.github.io/distribution/spec/auth/token/">token auth workflow</a> currently defined by the distribution project.</p><p><strong>The important detail is this <code>www-authenticate</code> header is telling OCI clients, like Docker, containerd, podman, and the various CRI’s used by Kubernetes, to send their user credentials to that <code>https://ghrc.io/token</code> API.</strong>
There is no legitimate reason to configure this header on a default nginx install, and other parts of the server indicate that this is not a container registry.</p><h2 id="whats-the-risk">What’s the Risk?</h2><p>All signs point to this being a credential stealing typo-squatting attack.
Credentials would be stolen only if you stored credentials for the <code>ghrc.io</code> registry, because clients won’t send credentials for a different host to <code>ghcr.io</code>.</p><p>Some scenarios that would result in credentials being leaked include:</p><ul><li>Running <code>docker login ghrc.io</code>.</li><li>A GitHub action with <code>uses: docker/login-action</code> and with <code>registry: ghrc.io</code>.</li><li>Creating a Kubernetes secret with registry credentials for <code>ghrc.io</code> and then trying to pull an image from that typoed host.</li></ul><p>Simply trying to push or pull an image to this registry without logging in will not leak credentials and will not leak any data other than your repository name.
These commands default to trying to acquire an anonymous token, which will quickly fail.</p><h2 id="what-should-you-do">What Should You Do?</h2><p>If you’ve ever accidentally performed the login to the wrong server, you should change your password, revoke any PATs you used, and look for any potentially malicious activity in your GitHub account.
An attacker could use it to push malicious images to your <code>ghcr.io</code> repositories, or they may gain access to your GitHub account directly depending on what login credentials were used.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A bubble that knows it's a bubble (108 pts)]]></title>
            <link>https://craigmccaskill.com/ai-bubble-history</link>
            <guid>45008209</guid>
            <pubDate>Sun, 24 Aug 2025 22:02:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://craigmccaskill.com/ai-bubble-history">https://craigmccaskill.com/ai-bubble-history</a>, See on <a href="https://news.ycombinator.com/item?id=45008209">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

            <!-- .post-header -->

            
            <div>
                <p>The four words that precede every crash: “This time is different.”</p>

<!-- more -->

<p>Except this time, the person warning about a bubble is Sam Altman, the CEO most responsible for creating it. When OpenAI’s chief executive warned last week that investors were “overexcited” about AI, markets reacted immediately. Nvidia fell 3.5%, Palantir dropped nearly 10%, and the selloff spread globally.</p>

<p>The warning came amid a cascade of seemingly supporting data. That same week, MIT researchers published findings that 95% of companies investing in generative AI were seeing no measurable returns. Apollo Global Management’s chief economist warned that current valuations exceeded even dot-com bubble peaks. And Federal Reserve data showed AI investment consuming more than half of America’s total capital expenditure.</p>

<p>The numbers tell the story. Anthropic raised $450 million at a $4.1 billion valuation despite negligible revenue. Character.AI hit $1 billion in valuation with 1.7 million monthly users—roughly $588 per user. Inflection AI raised $1.3 billion before essentially acqui-hiring its team to Microsoft, leaving investors with an empty shell.</p>

<p>Ray Dalio, founder of Bridgewater Associates, told the Financial Times the current environment mirrors 1998-1999, warning that while AI will certainly transform the economy, investors are “confusing that with the investments being successful.”</p>

<p>Sound familiar? It should. This exact sequence—revolutionary technology, abundant capital, speculative frenzy, then sudden reality checks—has played out with remarkable consistency for over 180 years. Railway Mania in the 1840s. Radio stocks in the 1920s. Dot-com fever in the 1990s. Each time, the technology was real. Each time, the speculation was unsustainable. Each time, the overbuilding became tomorrow’s foundation.</p>

<h2 id="the-original-tech-bubble-when-britain-went-mad-for-railways">The Original Tech Bubble: When Britain Went Mad for Railways</h2>

<p>To understand what’s happening with AI today, we need to travel back to 1840s Britain, where the world’s first true technology bubble was taking shape around the railway.</p>

<p>The Railway Mania of the 1840s makes today’s AI frenzy look restrained. Between 1843 and 1846, Parliament approved 263 Acts for new railway companies proposing 9,500 miles of track, nearly matching today’s entire UK railway network. The speculation democratized investing in a way never seen before. Clerks, shopkeepers, and domestic servants, people who had never owned stocks before, mortgaged their homes and borrowed money to buy railway shares. The mania pulled in everyone from farmers to factory workers, all convinced they were investing in the future.</p>

<p>The mania started with genuine success. The Liverpool-Manchester Railway had proven the concept, reducing the London-Glasgow journey from days to 24 hours. This wasn’t just faster transportation but a compression of time and space that seemed magical to people who had never traveled faster than a horse could run.</p>

<p>Economic conditions enabled speculation. Low interest rates pushed Britain’s middle class toward railway stocks. Shares could be purchased with just a 10% deposit, with the balance paid later through capital calls. This leverage meant ordinary people could control far more stock than they could afford—imagine buying $10,000 of stock with $1,000 down. By 1846, railway companies comprised 71% of total stock market value, up from 23% eight years earlier.</p>

<p>Then reality intruded. In October 1845, the Bank of England raised rates. Suddenly, leveraged investors faced capital calls they couldn’t meet. Families who thought they were making modest investments discovered they owed thousands of pounds they didn’t have. By 1850, railway shares had lost 85% of their peak values. Over 200 companies went bankrupt. The Commercial Crisis of 1847 became one of Britain’s worst financial disasters.</p>

<p>But while investors lost fortunes, Britain gained invaluable infrastructure. All that speculative investment had built a railway network that became the backbone of the Industrial Revolution. The overbuilt, redundant tracks that seemed like waste in 1847 enabled Britain’s industrial dominance for the next century.</p>



<p>Fast-forward 150 years, and the pattern repeated with eerie precision. The late 1990s internet bubble demonstrated how compelling narratives can completely detach valuations from any semblance of business reality.</p>

<p>The numbers were staggering. The NASDAQ rose 800% from 1995 to its March 2000 peak of 5,048. By traditional measures, the insanity was obvious: the index’s price-to-earnings (P/E) ratio reached 200. In plain English, investors were paying $200 for every $1 of actual profit these companies generated. For context, a healthy market typically sees P/E ratios of 15-20. Even Japan’s infamous 1989 bubble peaked at 80. But dot-com investors had convinced themselves that earnings didn’t matter anymore. What mattered was “eyeballs” and future potential. Many of these companies had no earnings at all, making their P/E ratios technically infinite. This mathematical impossibility should have been a warning sign. Investors had completely abandoned fundamental analysis in favor of pure speculation about future potential, convinced that traditional metrics like revenue, profit margins, and cash flow were obsolete in the ‘new economy.</p>

<p>The Wall Street Journal, that bastion of financial sobriety, suggested investors “re-think” the “quaint idea” that companies should be profitable.</p>

<p>As with railways, the underlying technology was genuinely revolutionary. The internet was indeed going to change everything—just not as quickly or as profitably as investors assumed. And just like the railway boom, perfect economic conditions enabled the speculation. The Federal Reserve had cut rates after the 1998 Long-Term Capital Management collapse, flooding the system with cheap money. The 1997 Taxpayer Relief Act lowered capital gains taxes, making speculation more attractive.</p>

<p>But it was the psychology that made the dot-com bubble truly extraordinary. Any company that added “.com” to its name could attract investment. VA Linux Systems gained 698% on its IPO day. Pets.com, which sold pet food online at a loss, reached a $300 million market capitalization. TheGlobe.com went public with no revenue and saw its stock price rise 606% in a single day.
The democratization of investing through online brokers meant that by spring 1999, one in twelve Americans claimed to be starting a business. Individual investors poured $260 billion into equity funds in 2000, with margin debt peaking at $300 billion. Day trading became a cultural phenomenon. CNBC became appointment television.</p>

<p>The philosophy of the era was captured perfectly by a Kleiner Perkins partner who said, “In the old days, you needed a business model. Now you need a business concept.” Revenue was yesterday’s metric; “eyeballs” and “mindshare” were what mattered. Traditional metrics were dismissed as relics of the industrial age.</p>

<p>The crash, when it came, was swift and merciless. From March 2000 to October 2002, the NASDAQ fell 78%. Total market capitalization losses reached $5 trillion, roughly half of US GDP at the time. But these staggering numbers don’t capture the human cost to everyday people. The dot-com crash eliminated 200,000 jobs in Silicon Valley alone, while millions of ordinary investors watched their retirement accounts and college funds evaporate. The same middle-class Americans who had been told they were foolish not to participate in the ‘new economy’ now faced financial ruin. Teachers’ pension funds were halved. Family savings meant for homes and education vanished. Web designers who commanded six figures found themselves competing for $15/hour contracts. Communities built around tech hubs hollowed out as workers fled to cheaper cities. Of the 7,000 to 10,000 internet companies launched in the late 1990s, only 48% survived past 2004.</p>

<p>Creative destruction is brutal math. The capital? Gone. Completely vaporized. But infrastructure isn’t stock certificates. Those fiber optic cables didn’t vanish when Pets.com did. The data centers kept humming after Webvan went dark. All that ‘wasted’ investment had already transformed into something physical. The pipes, servers, and networks that would become the foundation for Google, Facebook, Amazon Web Services, and the digital transformation that actually did change everything. The bubble’s victims unknowingly funded the future. They just paid a decade too early.</p>

<h2 id="no-country-is-immune">No Country Is Immune</h2>

<p>The bubble pattern isn’t uniquely Anglo-American. Japan’s 1980s asset price bubble saw the Nikkei rise 300% in five years before losing 60% of its value. The grounds of the Imperial Palace in Tokyo were theoretically worth more than all the real estate in California. When it crashed, Japan entered a “lost decade” of economic stagnation.</p>

<p>China has perfected the art of managed bubbles. Its 2007 stock market bubble saw the Shanghai Composite rise 480% in two years before crashing 72%. Its 2015 bubble was even more dramatic: a 150% rise in six months followed by a 43% crash in just two months. Each time, state intervention prevented total collapse but couldn’t prevent massive wealth destruction.</p>

<p>Today’s AI bubble is distinctly global. China races to match US capabilities, pouring state resources into domestic champions. The EU struggles to regulate while trying not to fall behind. Saudi Arabia commits $40 billion to AI investments through its sovereign wealth fund. This synchronized global speculation might amplify both the boom and any eventual bust.</p>

<h2 id="the-pattern-we-cant-escape">The Pattern We Can’t Escape</h2>

<p>Step back from the specifics, and a pattern emerges across centuries:</p>

<ol>
  <li>
    <p><strong>Genuine breakthrough creates legitimate excitement.</strong> Railways, electricity, internet, AI—each represented real technological leaps, not just incremental improvements.</p>
  </li>
  <li>
    <p><strong>Early success stories make believers out of skeptics.</strong> The Liverpool-Manchester Railway shrank days to hours. Amazon survived when 90% of dot-coms died. ChatGPT hit 100 million users in two months. These proof points silence doubters just long enough for speculation to take hold.</p>
  </li>
  <li>
    <p><strong>Capital markets provide the fuel.</strong> Low interest rates, new investment vehicles, democratized access—different mechanisms, same result: too much money chasing the future.</p>
  </li>
  <li>
    <p><strong>Social proof overwhelms skepticism.</strong> When your neighbor gets rich on railway stocks or your coworker quits to join a startup, FOMO beats rational analysis every time.</p>
  </li>
  <li>
    <p><strong>Reality reasserts itself.</strong> Capital calls come due. Revenue fails to materialize. The future arrives, just slower and differently than promised.</p>
  </li>
  <li>
    <p><strong>Infrastructure remains after speculators flee.</strong> Britain’s rail network, America’s fiber optic cables, today’s GPU clusters—overbuilding becomes tomorrow’s competitive advantage.</p>
  </li>
</ol>

<p>This pattern held true across different continents, centuries, and technologies. The actors change but the script remains remarkably consistent. Which brings us to today’s AI boom and an unprecedented twist: what happens when everyone can see the pattern while living it?</p>



<p>Here’s what’s never happened before: everyone knows the script.</p>

<p>CEOs are calling their own sectors overheated. Researchers are publishing failure rates in real time. Even casual investors track AI valuations. This isn’t insider knowledge anymore, it’s mainstream discourse.</p>

<p>Compare that to history. Railway Mania? Information traveled at horse speed. The dot-com crash? CNBC existed, but Twitter didn’t. Most people learned about the bubble after their 401k got vaporized.</p>

<p>Now we have instant global commentary on every funding round, every overhyped demo, every cautionary study. MIT publishes data showing failure rates, and it’s trending on LinkedIn within hours. Bloomberg runs “Is This a Bubble?” segments weekly. Retail investors share articles about historical bubble patterns.</p>

<p>The modern version of “adding .com to your name” is even more brazen. Companies append “AI” to their descriptions and watch valuations soar. Buzzfeed stock jumped 300% after announcing AI-generated content. C3.ai trades at 15 times revenue despite losing money on every dollar of sales. Even established companies play this game: consulting firms that once sold “digital transformation” now sell “AI transformation” at premium prices.</p>

<p>Nvidia’s numbers capture the mania perfectly. The company trades at a P/E ratio floating between 58 and 72, more than triple the S&amp;P 500 average. Its market cap exceeds $4 trillion based largely on selling shovels to AI gold miners. Microsoft commits $13 billion to OpenAI. Amazon pledges $4 billion to Anthropic. Google races to match with Gemini investments. The capital expenditure on AI infrastructure already exceeds the entire dot-com bubble when adjusted for inflation. To put this in perspective, AI infrastructure spending is approaching hundreds of billions annually, a level of concentrated technological investment not seen since the space race.</p>

<p>This creates a paradox: the most transparent bubble in history might also be the most inevitable. Because knowing you’re in a bubble doesn’t stop you from participating. Ask anyone who bought GameStop during the meme stock frenzy. They knew it was insane. They did it anyway.</p>

<p>The question isn’t whether awareness prevents stupidity. It’s whether it changes the flavor of stupidity we’re about to witness.</p>

<h2 id="why-ai-might-actually-be-different-this-time">Why AI Might Actually Be Different This Time</h2>

<p>Maybe AI will break the mold. The optimists aren’t completely delusional. There are genuine reasons why this technology could defy historical patterns:</p>

<p><strong>Speed of deployment changes everything.</strong> Railways took decades to build. Even software requires downloads, integrations, and training. But AI? ChatGPT reached 100 million users in two months. When infrastructure is cloud-based and products are accessible through browsers, adoption curves go vertical in ways physical products never could.</p>

<p><strong>The recursive improvement possibility.</strong> Every previous technology improved through human innovation. AI might be the first technology capable of improving itself. If AI can enhance AI development, we could see exponential rather than linear progress. This isn’t science fiction. Current models already help train next-generation models.</p>

<p><strong>Network effects on steroids.</strong> More users make social networks more valuable, but more users make AI smarter. Every prompt teaches the system. Every correction improves performance. The company that achieves AI dominance might have an insurmountable advantage because their lead compounds daily.</p>

<p><strong>Why the giants might create their own competition.</strong> Here’s the twist: the massive training costs and compute requirements that make today’s AI leaders seem unassailable might actually democratize the technology. Once foundation models exist, smaller companies can build specialized applications without bearing the upfront costs. OpenAI spends billions so a startup can spend thousands. But unlike previous platform monopolies, AI might be uniquely resistant to moats. When your competitor’s model improves, you can often incorporate those advances. When open-source alternatives emerge, they benefit from collective innovation. The result? Instead of winner-take-all dynamics, we might see an explosion of AI-powered businesses that collectively grow the pie faster than any bubble can inflate. The very nature of the technology (reproducible, composable, improvable) could create more value than it destroys.</p>

<p>These arguments deserve serious consideration. Maybe this time really is different. But that’s exactly what investors thought about railways (“annihilating distance!”), radio (“wireless changes everything!”), and the internet (“bits not atoms!”). Revolutionary technologies can be both transformative and overvalued. The question isn’t whether AI will change the world. It will. The question isn’t whether AI will change the world. It will. The question is whether current valuations reflect realistic timelines and profit potential, or whether we’re once again paying tomorrow’s prices with today’s money.</p>

<p>And if I’m wrong? If AI really does break every historical pattern? Well, then we’re about to witness the greatest creation of wealth in human history. That’s a bet many find worth taking.</p>

<h2 id="when-will-the-music-stop">When Will the Music Stop?</h2>

<p>History offers clues but no certainties about timing. Railway Mania lasted roughly four years from acceleration to crash (1843-1847). The dot-com bubble’s acute phase ran about five years (1995-2000). The pattern suggests major technology bubbles take 4-6 years from mainstream awareness to collapse.</p>

<p>For AI, if we date mainstream awareness from ChatGPT’s November 2022 launch, we’re now almost three years into the cycle. History suggests we’re approaching the middle innings. The typical progression:</p>
<ul>
  <li>Year 1-2: Wonder and experimentation (2022-2024)</li>
  <li>Year 2-3: Massive capital deployment and infrastructure building (we are here)</li>
  <li>Year 3-4: Market saturation and disappointing returns become evident</li>
  <li>Year 4-5: The music stops</li>
</ul>

<p>But several factors could accelerate or delay this timeline. Rising interest rates historically trigger bubble collapses, and we’re already seeing rate increases. Conversely, government support for AI as a national security priority could extend the bubble beyond historical norms.</p>

<p>The most reliable indicator? Watch for the moment when AI companies start acquiring each other with stock instead of cash. That’s historically been the last stage before collapse.</p>

<h2 id="profiting-from-the-wreckage">Profiting from the Wreckage</h2>

<p>While everyone’s debating whether we’re in a bubble, some investors are asking different questions: What’s getting overbuilt? What will be cheap after the crash? Who’s actually solving problems versus who’s just riding the hype wave?</p>

<p>If history is any guide, here’s what the playbook might look like:</p>

<p><strong>First, follow the infrastructure.</strong> During Railway Mania, the smartest move wasn’t buying railway stocks but investing in steel, land, and engineering firms. When dot-com imploded, someone had to buy all those fiber optic cables for pennies on the dollar. Today? Data centers, semiconductor fabs, and power infrastructure are getting massive investment. That hardware doesn’t disappear when valuations crash.</p>

<p><strong>Second, look for real revenue.</strong> If the MIT study is right, 95% of AI companies are burning cash on “customer discovery” and “market education.” But somewhere in that mix, 5% are actually charging money for solutions people need today. Companies with boring enterprise contracts might outlast those creating viral demos.</p>

<p><strong>Third, consider betting on necessity, not novelty.</strong> Amazon wasn’t sexy during the dot-com crash. It was selling books to people who needed books. Adobe wasn’t exciting during the financial crisis. It was selling tools that designers and businesses couldn’t work without. The AI companies that survive might be those automating tasks people hate doing, not those promising artificial general intelligence.</p>

<p><strong>Fourth, prepare for potential fire sales.</strong> Every bubble ends with good companies getting dumped alongside bad ones. In 2002, you could buy Google’s pre-IPO shares for a fraction of their eventual worth. In 2008, Netflix traded at $3 per share while being dismissed as a DVD-by-mail dinosaur. By 2010, those $3 shares were worth $30. By 2020, after stock splits, that $3 investment was worth over $300. The next cycle might serve up similar opportunities for those with cash and patience.</p>

<p>The bubble creates the exact conditions that make post-bubble investing potentially profitable. Massive overinvestment drives down infrastructure costs. Market crashes eliminate weak competitors. Talent becomes available as overfunded startups implode.</p>

<p>History’s lesson isn’t “avoid bubbles.” It’s “position for what comes after.”</p>



<p>As I write this, my LinkedIn feed is flooded with AI funding announcements. Every tech conference features panels on “Why AI Changes Everything.” The majority of pitch decks I see now include an AI angle, whether it fits or not. The pattern is impossible to miss.</p>

<p>If you’ve read this far, these claims probably sound familiar. Not because you’ve heard them about AI before, but because they echo every transformative technology for the past 200 years.</p>

<p>But here’s what’s genuinely different this time: we’re not blind to the patterns anymore. Sam Altman’s bubble warning isn’t just refreshing honesty. It’s evidence that we might be learning from history instead of repeating it exactly.</p>

<p>We have tools previous generations lacked. Start with regulation: Sarbanes-Oxley emerged from dot-com’s ashes, requiring real financial disclosure. The Volcker Rule limits banks from making speculative bets with depositor money. Stress testing means major financial institutions must prove they can survive market shocks.</p>

<p>The investor base has evolved too. Where Railway Mania saw shopkeepers betting their life savings and dot-com drew day traders chasing quick profits, today’s AI investments flow primarily through venture funds and institutional investors. Yes, retail can buy Nvidia, but they can’t access pre-IPO rounds where the real speculation happens. This concentration among professional investors won’t prevent a bubble, but it might prevent the kind of widespread financial devastation that followed previous crashes.</p>

<p>Risk management has transformed. Portfolio theory, derivatives for hedging, and real-time data mean sophisticated investors can protect themselves in ways previous generations couldn’t imagine. The Federal Reserve now has tools like quantitative easing that didn’t exist during past crises. Whether they’ll use them wisely is another question, but the toolkit exists.</p>

<p>Most importantly, we have communication networks that spread both hype and skepticism at equal speed. MIT’s study showing 95% failure rates went viral the same week it published. Every breathless AI announcement triggers immediate fact-checking. This doesn’t stop speculation, but it arms investors with information their predecessors desperately lacked.</p>

<p>The speculation, excitement, and even some degree of overinvestment are probably necessary parts of how society handles revolutionary change. But the catastrophic boom-bust cycles aren’t inevitable features of progress. They’re bugs in our system that we can potentially fix.</p>

<p>The AI revolution is real, transformative, and probably unstoppable. Whether it unfolds through sustainable growth or boom-bust cycles depends largely on the choices we make in the next few years. The early signs (including voices like Altman’s warning about overexcitement) suggest we might actually be learning from history.</p>

<p>The AI bubble’s human impact could be fundamentally different. Previous bubbles destroyed jobs when they burst. AI might destroy jobs while it’s still inflating. If AI actually delivers on its automation promises, we could see the first bubble that eliminates more employment during its rise than its fall.</p>

<p>This creates an unprecedented social risk: a technology bubble that succeeds in its goals might cause more disruption than one that fails. The Railway Mania gave Britain train networks and industrial jobs. The dot-com bubble gave us e-commerce and digital careers. The AI bubble might give us unprecedented productivity and fewer jobs. That’s a social equation we haven’t solved.</p>

<h2 id="what-we-know-vs-what-well-do">What We Know vs. What We’ll Do</h2>

<p>After 180 years of spectacular booms and devastating busts, the patterns are clear. The question is whether we can act on them.</p>

<p>History suggests most of us can’t. We’ll participate in the mania despite knowing better, just as railway clerks mortgaged their homes and day traders quit their jobs. That’s human nature. But perhaps knowing the script at least lets us play our parts more consciously.</p>

<p>The truth is, everyone already knows we’re in a bubble. You know AI valuations are insane. You know most of these companies will fail. You know the crash is coming. The question isn’t what to do—it’s whether you’ll actually do it when the time comes.</p>

<p>Because when Nvidia drops 50%, you won’t think “opportunity.” You’ll think “it’s going to zero.” When AI becomes toxic and unfashionable, you won’t remember that the technology is real. You’ll question everything. That’s the psychological trap: understanding bubbles intellectually is easy. Maintaining perspective inside them is nearly impossible.</p>

<p>If you must participate (and let’s be honest, the FOMO is real), history offers some guardrails. The infrastructure builders tend to survive even if their valuations don’t. The companies solving mundane problems outlast those promising revolution. And the best opportunities emerge not during the mania, but in the wreckage that follows.</p>

<p>Keep powder dry. When everyone declares AI “dead,” that’s your moment. Not today, when your barista is giving stock tips. The future always arrives. It just takes longer and looks different than anyone expects.</p>

<p>The most radical act might be patience. Let others fund the infrastructure. Let them discover which use cases actually matter. Let them burn through capital learning hard lessons. Then, when the dust settles and the tourists have fled, see what’s left.</p>

<p>Because something always is. Britain got its railways. We got the internet. And we’ll get AI. The only question is whether you’ll be among those who paid for it or those who profited from it.</p>

<p>Bubbles are wealth transfer mechanisms. Money flows from the impatient to the patient, from the leveraged to the liquid, from the emotional to the analytical. The only real edge is temperament. Can you remain skeptical during euphoria and optimistic during despair? History says probably not. But at least now you know the script you’re following.</p>

<p>The real revolution isn’t in the technology we’re building. It’s in whether we’ve finally learned how to build it without destroying ourselves in the process.</p>

<p>The four words that precede every crash: ‘This time is different.’ But the four words that might prevent one? ‘We’ve seen this before.’</p>

<p><em>I work at ServiceNow, but these views are entirely my own and don’t represent my employer’s position on AI, bubbles, or anything else. This is definitely not investment advice, just one person’s attempt to make sense of history rhyming once again.</em></p>

            </div>
            
            
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uncle Sam shouldn't own Intel stock (227 pts)]]></title>
            <link>https://www.wsj.com/opinion/uncle-sam-shouldnt-own-intel-stock-ccd6986d</link>
            <guid>45008056</guid>
            <pubDate>Sun, 24 Aug 2025 21:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/opinion/uncle-sam-shouldnt-own-intel-stock-ccd6986d">https://www.wsj.com/opinion/uncle-sam-shouldnt-own-intel-stock-ccd6986d</a>, See on <a href="https://news.ycombinator.com/item?id=45008056">Hacker News</a></p>
Couldn't get https://www.wsj.com/opinion/uncle-sam-shouldnt-own-intel-stock-ccd6986d: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Starship's Tenth Flight Test (116 pts)]]></title>
            <link>https://www.spacex.com/launches/starship-flight-10</link>
            <guid>45007907</guid>
            <pubDate>Sun, 24 Aug 2025 21:22:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spacex.com/launches/starship-flight-10">https://www.spacex.com/launches/starship-flight-10</a>, See on <a href="https://news.ycombinator.com/item?id=45007907">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Looking back at my transition from Windows to Linux (111 pts)]]></title>
            <link>https://www.scottrlarson.com/publications/publication-looking-back-windows-to-linux/</link>
            <guid>45007437</guid>
            <pubDate>Sun, 24 Aug 2025 20:22:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottrlarson.com/publications/publication-looking-back-windows-to-linux/">https://www.scottrlarson.com/publications/publication-looking-back-windows-to-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=45007437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p><em>I am a computer professional that helps the public with technology. I have been troubleshooting computer problems for over 25 years. To find out more about me, visit my <a href="https://scottrlarson.com/" target="_blank">home page</a>.</em></p>

<p>In August of 2023, I <a href="http://scottrlarson.com/publications/publication-transition-windows-to-linux/" target="_blank">wrote</a> about my switch to Linux as a Windows-centric professional. I’ve dabbled in Linux as a daily driver in the past, but it has always ended in some form of defeat. Eventually returning to my abuser, Windows. It was a hard road leaving it behind, but determination can work wonders when flying the freedom skies. Starting with the release of Windows 11, Microsoft’s shady tactics increased to the point where it’s no longer a viable option for an operating system, unless you don’t mind that your desktop is used as an advertising platform, or being forced to allow Copilot, Recall and OneDrive abuse the relationship to your data. Much of the commercial software industry invested into proprietary applications have descended into chaos in the last five years. Recently an intense feeding frenzy for control over the user experience rose to an all time high. Subscriptions replacing purchases of software products is the biggest example of this.</p>

<p>In my previous article I was worried that I might give up, and switch back. Did I make it this time? Yes! Yes, I did. It’s been two years now. I finally weaned myself off of Big Daddy. &nbsp;I do everything in Linux now. Obviously, there are still some pain points that I have a hard time with, but isn’t that true with any operating system?</p>

<p>As a survivor of that dependency, I sometimes feel that I am making the problem worse by installing and supporting Windows 11 for my customers. A new violation of trust is always just around the corner, even though I work very hard to remove or circumvent these hostile features. &nbsp;OneDrive even silently reinstalled itself and moved one customer’s data to the cloud, all without consent. One day their data was on the local drive and the next it became online-only files that had to be downloaded from Microsoft’s servers. I see an avalanche of justifications from people still stuck on Windows. “It’s just a bug”, “These things will get ironed out in time” But the truth is that the freedom to choose is slowly being eroded. When we live in a consumer society where anti-trust seems to mean nothing, what does one do? &nbsp;</p>

<p>The <a href="https://www.stopkillinggames.com/" target="_blank">StopKillingGames</a> movement is of a similar line. Someone decided enough is enough and went toe to toe with what I consider corporate culture run amok in the AAA game industry. And then we have our friends in Europe that passed the Digital Markets Act, challenging Apple’s stranglehold on the App Store. I think Europe is positioning itself as the last bastion of hope for customer rights worldwide. With digital commerce, when rights are upheld in one country, other countries can receive the downstream effects. We are also starting to see <a href="https://pirg.org/campaigns/right-to-repair/" target="_blank">RightToRepair</a> challenges with <a href="https://www.youtube.com/watch?v=8EWAIlX5d1Y" target="_blank">3rd party equipment providers that attempt to prevent 1st party servicing using IP arguments</a>.</p>

<p>So what have I learned through all this? I’ve learned that making myself free requires effort. The technical challenges of Linux are a bit steeper, but not impossible. Ownership and control over products I purchased are more important than I realized. When I lose control over something I purchased, it disrupts my freedom, and this disruption affects the relationship with myself and the world. It happens slowly. First, I brush off violations to my freedom as an annoyance that needs to be routed around. Then, when more violations occur, I start to get angry that I have to waste more of my time fixing something that I didn’t break.</p>

<p>I realized that this anger is directed at myself. It’s actually a form of resentment towards myself for sacrificing something important for a minor inconvenience that’s designed to become a major roadblock by each iteration.</p>

<p>And this is the major sticking point. I cannot ignore that slow boil any longer. It’s time to see these dark patterns for what they are: a slow movement towards a feudal system where I will own nothing and be happy.</p>

<p>This problem is not just happening with software ownership; it’s happening everywhere.</p>

<p>I’ll leave you with this quote from the character Nemik in the Star Wars TV series “Andor”:&nbsp;</p>

<blockquote>
<p>Remember this, Freedom is a pure idea. It occurs spontaneously and without instruction. Random acts of insurrection are occurring constantly throughout the galaxy. There are whole armies, battalions that have no idea that they’ve already enlisted in the cause.</p>

<p>Remember that the frontier of the Rebellion is everywhere. And even the smallest act of insurrection pushes our lines forward.</p>

<p>And remember this: the Imperial need for control is so desperate because it is so unnatural. Tyranny requires constant effort. It breaks, it leaks. Authority is brittle. Oppression is the mask of fear.</p>

<p>Remember that. And know this, the day will come when all these skirmishes and battles, these moments of defiance will have flooded the banks of the Empires’s authority and then there will be one too many. One single thing will break the siege.</p>

<p>Remember this: Try.</p>
</blockquote>

<p>If you are a power user like me, Linux is getting closer to a real alternative to Windows and it’s about time as more and more companies move to anti-competitive practices, harming public trust and individual choice. In the long run, the products we use should be in our control and not the other way around. <a href="https://www.fightforthefuture.org/" target="_blank">Do what you can to make it harder for shady companies like Microsoft to dominate markets</a> and support the <a href="https://www.endcreativemonopolies.com/" target="_blank">end of creative monopolies</a>.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Halt and Catch Fire Syllabus (2021) (156 pts)]]></title>
            <link>https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</link>
            <guid>45007414</guid>
            <pubDate>Sun, 24 Aug 2025 20:19:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/">https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</a>, See on <a href="https://news.ycombinator.com/item?id=45007414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="about">
      <h2 id="readme">README</h2>

<p>This site features a curriculum developed around the television series, <a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=halt+and+catch+fire">Halt and Catch Fire</a> (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.</p>

<p>The intent is for this website to be used by self-forming small groups that want to create a “watching club” (like a book club) and discuss aspects of technology history that are featured in this series.</p>

<p>There are 15 classes, for a “semester-long” course:<br>
~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/01.html">#01</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/02.html">#02</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/03.html">#03</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/04.html">#04</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/05.html">#05</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/06.html">#06</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/07.html">#07</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/08.html">#08</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/09.html">#09</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/10.html">#10</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/11.html">#11</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/12.html">#12</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/13.html">#13</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/14.html">#14</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/15.html">#15</a> ~</p>

<p><strong>Prefer a <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/HaltAndCatchFireSyllabus.pdf">PDF</a>?</strong></p>

<p>Brief guide to class layout:</p>
<ul>
  <li><strong>Apéritifs</strong> Casual viewing presented before gathering. This is entertainment; not required viewing.</li>
  <li><strong>RFC as koan</strong> A Request for Comments from the Internet Engineering Task Force, for reflecting on.</li>
  <li><strong>Emulation as koan</strong> An emulated computer in the browser, also for reflection.</li>
  <li><strong>Themes</strong> Recommendations for topics to be discussed.</li>
  <li><strong>Prompts</strong> Questions to inspire conversation when gathering.</li>
  <li><strong>Readings</strong> Related material for deeper thinking on the class topic.</li>
  <li><strong>Description</strong> Brief summary of what’s going on in the episodes and how it relates to tech history at large / the weekly topic.</li>
  <li><strong>Episode summaries</strong> A link to summaries of the episodes that should be watched prior to meeting as a group. Watching each episode is not required; if time doesn’t allow, refer to the summaries. Content warnings are provided for relevant episodes. If there are specific concerns, this can determine which episodes should be skipped or anticipated before viewing.</li>
</ul>

<p><br>
Curriculum and website designed by <a href="https://ashleyblewer.com/">Ashley Blewer</a>.<br>
see also ↠ <a href="https://github.com/ablwr/halt-and-catch-fire-syllabus">source code &amp; site metadata</a></p>

<p><img src="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/assets/img/construction.gif" alt="under construction"></p>

    	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything I know about good API design (320 pts)]]></title>
            <link>https://www.seangoedecke.com/good-api-design/</link>
            <guid>45006801</guid>
            <pubDate>Sun, 24 Aug 2025 19:10:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/good-api-design/">https://www.seangoedecke.com/good-api-design/</a>, See on <a href="https://news.ycombinator.com/item?id=45006801">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Most of what modern software engineers do<sup id="fnref-1"><a href="#fn-1">1</a></sup> involves APIs: public interfaces for communicating with a program, like <a href="https://www.twilio.com/docs/iam/api/account#fetch-an-account-resource">this one</a> from Twilio. I’ve spent a <em>lot</em> of time working with APIs, both building and using them. I’ve written public APIs for third-party developers, private APIs for internal use (or consumption by a single frontend page), REST and GraphQL APIs, and even non-network interfaces like the ones for command-line tools.</p>
<p>Like <a href="https://www.seangoedecke.com/good-system-design">designing good software systems</a>, I think much of the advice floating around about API design is too fancy. People get wrapped up in what “real” REST is, or whether HATEOAS is a good idea, and so on. This post is my attempt at writing down everything I know about designing good APIs.</p>
<h3>Designing APIs is a balance between familiarity and flexibility</h3>
<p>If this is true about systems - and it is - it’s even more true about APIs: <strong>good APIs are boring</strong>. An API that’s interesting is a bad API (or at least it would be a better one if it were less interesting). For the developers who build them, APIs are complex products that they spend time designing and polishing. But for the developers who use them, APIs are tools that they use in order to accomplish some other goal. Any time they spend thinking about the API instead of about that goal is time wasted. From their perspective, an ideal API should be so familiar that they will more or less know how to use it before they read any documentation<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>However, one big difference from most software systems is that <strong>APIs are hard to change</strong>. Once you publish an API and people start using it, any change to the interface will break your users’ software. Of course, it is <em>possible</em> to make changes. But (as I’ll say below) each change imposes a serious cost: every time you force your users to update their software, they will give serious thought to using a different API that’s more stable. That gives API-builders a strong incentive to design carefully and get it right the first time. </p>
<p>This tension leads to an interesting dynamic for engineers who build APIs. On the one hand, they want to build the simplest API possible. On the other hand, they want to do clever things to maintain flexibility long-term. In broad strokes, API design is about finding a balance between those two incompatible goals.</p>
<h3>WE DO NOT BREAK USERSPACE</h3>
<p>What happens when you need to make changes to your API? Additive changes - for instance, putting a new field in the response - are typically fine. There are some consumers which will blow up if they’re getting more fields than they expect, but in my view this is irresponsible. You should expect API consumers to ignore unexpected fields (sensible JSON-parsing typed languages do this by default).</p>
<p>However, you can’t <em>remove</em> or change the types of fields. You can’t change the structure of existing fields (for instance, moving <code>user.address</code> to <code>user.details.address</code> in the JSON response). If you do, every single piece of code that relies on those fields will immediately break. Consumers of that code will report it as a bug, and the maintainers of the code will (when they figure it out) be rightfully furious that you deliberately broke their software.</p>
<p>The principle here is something like Linus Torvalds’ famous slogan <a href="https://lore.kernel.org/all/CA+55aFy98A+LJK4+GWMcbzaa1zsPBRo76q+ioEjbx-uaMKH6Uw@mail.gmail.com/">WE DO NOT BREAK USERSPACE</a>. As a maintainer of an API, you have something like a sacred duty to avoid harming your downstream consumers. The norm is so strong because so much software depends on so many APIs (which in turn depend on upstream APIs, and so on). One careless API maintainer far enough upstream can break hundreds or thousands of pieces of software downstream.</p>
<p>You should never make a change to an API just because it’d be neater, or because it’s a little awkward. The “referer” header in the HTTP specification is famously a misspelling of the word “referrer”, but they haven’t changed it, <em>because we do not break userspace</em>.</p>
<h3>Changing APIs without breaking userspace</h3>
<p>It’s honestly hard to think of examples where an API really <em>needs</em> a breaking change. But sometimes the technical value of a change is high enough that you decide to bite the bullet and do it anyway. In those cases, how can you change your API responsibly? The answer is <em>versioning</em>.</p>
<p>API versioning means “serve both the old and new version of your API at the same time”. Existing consumers can continue to use the old version, while new consumers can opt-in to the new one. The easiest way to do this is to include something like <code>/v1/</code> in your API url. OpenAI’s chat API is at <a href="https://platform.openai.com/docs/api-reference/chat/create">v1/chat/completions</a>, so if they ever want to totally rework the structure, they can do that in <code>v2/chat/completions</code> and keep the existing consumers working.</p>
<p>Once you have the new and old version working simultaneously, you can start telling users to upgrade to the new version. This takes a <em>long</em> time: months or even years. Even with banners on the website, docs, custom emails, and headers on the API response, when you finally remove the old version, you will still get a lot of angry users upset that you’ve broken their software. But at least you’ll have done what you can about it.</p>
<p>There are lots of other ways to do API versioning. The Stripe API does versioning in a <a href="https://docs.stripe.com/api/versioning">header</a>, and lets accounts set their default version in the UI. But the principle is the same - any consumers of the Stripe API can be confident that Stripe won’t decide to break their applications, and they can upgrade versions at their own pace.</p>
<p><strong>I don’t like API versioning.</strong> I think at best it’s a necessary evil, but it’s still evil. It’s confusing to users, who can’t easily search for your API docs without making sure that the version selector matches the version they’re using. And it’s a <em>nightmare</em> for maintainers. If you have thirty API endpoints, every new version you add introduces thirty new endpoints to maintain. You will rapidly end up with hundreds of APIs that all need testing, debugging, and customer support.</p>
<p>Of course, adding a new version doesn’t double the size of your codebase. Any sensible API versioning backend will have something like a translation layer that can turn a response into any of your public API versions. Stripe has <a href="https://stripe.com/blog/api-versioning">something like this</a>: the actual business logic is the same for all versions, so only the parameter serializing and deserializing needs to be aware of versioning. However, abstractions like that will always leak. See this 2017 <a href="https://news.ycombinator.com/item?id=13711171">HN comment</a> from a Stripe employee, pointing out that some versioning changes need conditional logic throughout the “core code”. </p>
<p>In short, <strong>you should only use API versioning as a last resort</strong>.</p>
<h3>The success of your API depends entirely on the product</h3>
<p>An API by itself doesn’t do anything. It’s a layer between the user and the thing they actually want. For the <a href="https://platform.openai.com/docs/api-reference/chat/create">OpenAI API</a>, that’s the ability to do inference with a language model. For the <a href="https://www.twilio.com/docs/iam/api/account#fetch-an-account-resource">Twilio API</a>, that’s sending SMS messages. Nobody uses an API because the API itself is so elegantly designed. They use it to <em>interact with your product</em>. <strong>If your product is valuable enough, users will flock to even a terrible API.</strong></p>
<p>This is why some of the most popular APIs are a nightmare to use. Facebook and Jira are famous for having appalling APIs, but it doesn’t matter - if you want to integrate with Facebook or Jira, which you do, you need to spend the time to figure them out. Sure, it would be nice if those companies had a better API. But why invest the time and money into improving it when people are going to integrate with it anyway? Writing good APIs is <em>really hard</em>.</p>
<p>I’m going to give a lot of concrete advice in the rest of this post about how to write good APIs. But it’s worth remembering that most of the time it doesn’t matter. If your product is desirable, any barely-functional API will do; if it isn’t, it doesn’t matter how good your API is. API quality is a marginal feature: it only matters when a consumer is choosing between two basically-equivalent products.</p>
<p>Incidentally, the <em>presence</em> of an API is an entirely different story. If one product doesn’t have an API at all, that’s a big problem. Technical users will demand some way to integrate with the software they’re buying via code.</p>
<h3>Poorly-designed products will usually have bad APIs</h3>
<p>A technically-great API can’t save a product that nobody wants to use. However, <strong>a technically-poor product can make it nearly impossible to build an elegant API</strong>. That’s because API design usually tracks the “basic resources” of a product (for instance, Jira’s resources would be <a href="https://developer.atlassian.com/cloud/jira/platform/rest/v2/api-group-issues/#api-rest-api-2-issue-issueidorkey-get">issues</a>, <a href="https://developer.atlassian.com/cloud/jira/platform/rest/v2/api-group-projects/#api-rest-api-2-project-projectidorkey-get">projects</a>, <a href="https://developer.atlassian.com/cloud/jira/platform/rest/v2/api-group-users/#api-rest-api-2-user-get">users</a> and so on). When those resources are set up awkwardly, that makes the API awkward as well.</p>
<p>As an example, consider a blogging system that stored comments in-memory as a linked list (each comment has a <code>next</code> field that points to the next comment in the thread). This is a terrible way to store comments. The naive way to bolt a REST API onto this system would be to have an interface that looks like this:</p>
<p><code>GET /comments/1 -&gt; { id: 1, body: "...", next_comment_id: 2 }</code></p>
<p>Or even worse, like this:</p>
<p><code>GET /comments -&gt; {body: "...", next_comment: { body: "...", next_comment: {...}}}</code></p>
<p>This might seem like a silly example, because in practice you’d just iterate over the linked list and return an array of comments in the API response. But even if you’re willing to do that extra work, how far down do you iterate? In a thread with thousands of comments, is it just impossible to fetch any comment after the first few hundred? Will your comment-fetching API have to use a background job, forcing the interface to turn into something like:</p>
<p><code>POST /comments/fetch_job/1 -&gt; { job_id: 589 }</code>
<code>GET /comments_job/589 -&gt; { status: 'complete', comments: [...] }</code></p>
<p>This is how some of the worst APIs happen. Technical constraints that can be cleverly hidden in the UI are laid bare in the API, forcing API consumers to understand far more of the system design than they should reasonably have to.</p>
<h3>Authentication</h3>
<p><strong>You should let people use your APIs with a long-lived API key.</strong> Yes, API keys are not as secure as various forms of short-lived credentials, like OAuth (which you should probably also support). It doesn’t matter. Every integration with your API begins life as a simple script, and using an API key is the easiest way to get a simple script working. You want to make it as easy as possible for engineers to get started.</p>
<p>Although consumers of an API will (almost by definition) be writing code, <strong>many of your users will not be professional engineers</strong>. They may be salespeople, product managers, students, hobbyists, and so on. When you’re an engineer at a tech company building an API, it’s easy to imagine that you’re building it for other people like yourself: full-time, competent, professional software engineers. But you’re not. You’re building it for a very wide cross-section of people, many of whom are not comfortable writing or reading code. If your API requires users to do anything difficult - like performing an OAuth handshake - many of those users will struggle.</p>
<h3>Idempotency and retries</h3>
<p>When an API request succeeds, you know it did what it tried to do. What about when it fails? Some types of failure tell you what happened: a 422 typically means it failed during the request-validation stage, before any action was taken<sup id="fnref-3"><a href="#fn-3">3</a></sup>. But what about a 500? What about a timeout?</p>
<p>This is important for API operations that <em>take action</em>. If you’re hitting some Jira API to create an issue comment, and the request 500s or times out, should you retry? You don’t know for sure whether the comment has been created or not, since the error might be happening after that operation. If you retry, you might end up posting two comments. This is even more important when there’s more at stake than a Jira comment. What if you’re transferring some amount of money? What if you’re dispensing medication?</p>
<p>The solution is <em>idempotency</em>, which is a fancy word for “the request should be safely retriable without creating duplicates”. The standard way to do this is to support an “idempotency key” in the request (say, some user-defined string in a parameter or header). When the API server gets a “create comment” request with an idempotency key, it first looks to see if it’s seen this idempotency key before. If so, it does nothing; otherwise it goes and creates the comment, then saves the idempotency key. That way you can send as many retries as you like, as long as they’ve all got the same idempotency key - the operation will only be performed once.</p>
<p>How should you store the key? I’ve seen people store it in some durable, resource-specific way (e.g. as a column on the <code>comments</code> table), but I don’t think that’s strictly necessary. The easiest way is to put them in Redis or some similar key/value store (with the idempotency key as the key). UUIDs are unique enough that you don’t need to scope them by user, but you may as well. If you’re not dealing with payments, you can even expire them after a few hours, since most retries happen immediately.</p>
<p>Do you need idempotency keys for every request? Well, you don’t need them for read requests, since double-reads are harmless. You also typically<sup id="fnref-4"><a href="#fn-4">4</a></sup> don’t need them for delete requests, since if you’re deleting by resource ID, that ID serves as the idempotency key. Think about it - if you send three <code>DELETE comments/32</code> requests in a row, it won’t delete three comments. The first successful request will delete the comment with ID 32, and the remaining requests will 404 when they can’t find the already-deleted comment.</p>
<p>For most cases, idempotency should be optional. Like I said above, you want to make sure that your API is accessible to non-engineers (who often find idempotency a tricky concept). In the grand scheme of things, getting more people on your API is more important than the occasional duplicated comment from users who didn’t read the documentation. </p>
<h3>Safety and rate limiting</h3>
<p>Users who are interacting with your UI are limited by the speed of their hands. If there’s some flow that’s expensive for your backend to serve, a malicious or careless user can only trigger that flow as fast as they can click through it. APIs are different. <strong>Any operation you expose via an API can be called at the speed of code.</strong></p>
<p>Be careful about APIs that do a lot of work in a single request. When I worked at Zendesk, we had an API that let you fan out notifications to all the users of a particular app. Some enterprising third-party developer<sup id="fnref-5"><a href="#fn-5">5</a></sup> used this to build an in-app chat system, where every message sent a notification to every other user on the account. For accounts with more than a handful of active users, this reliably killed the Apps backend server.</p>
<p>We didn’t anticipate people building a chat app on top of this API. But once it was out there, people did what they wanted with it. I’ve been in many, many incident calls where the root cause was some hand-rolled customer integration that was doing something silly, like:</p>
<ul>
<li>Creating and deleting the same records hundreds of times per-minute, for no real reason</li>
<li>Polling a big <code>/index</code> endpoint with no delay in between, forever</li>
<li>Importing or exporting a ton of data without backing off in case of errors</li>
</ul>
<p><strong>You should put a rate limit on your API, with tighter limits for expensive operations.</strong> It’s also sensible to reserve the ability to temporarily disable the API for specific customers, so you can take the pressure off your backend system if it’s really getting hammered.</p>
<p>Include rate limiting metadata in your API responses. <code>X-Limit-Remaining</code> and <code>Retry-After</code> headers give clients the information they need to be respectful consumers of your API, and allow you to set stricter rate limits than you would otherwise be able to.</p>
<h3>Pagination</h3>
<p>Almost every API has to serve a long list of records. Sometimes a very long list (for instance, the Zendesk <code>/tickets</code> API can contain millions of tickets). How can you serve those records?</p>
<p>A naive <code>SELECT * FROM tickets WHERE...</code> approach will blow out your available memory (if not in the database, then in the application layer where you’re trying to serialize this million-item list). You just can’t serve every ticket in a single request. Instead, you have to <em>paginate</em>.</p>
<p>The simplest way to paginate is to use pages (or “offsets”, more generically). When you hit <code>/tickets</code>, you get the first ten tickets on the account. To get more, you have to hit either <code>/tickets?page=2</code> or <code>/tickets?offset=20</code>. This is easy to implement, since the server can just add <code>OFFSET 20 LIMIT 10</code> to the end of the database query. But it doesn’t scale to really high numbers of records. Relational databases have to count through your offset every time, so each page you serve gets a little slower than the last page. By the time your offset is in the hundreds of thousands, it’s a real problem.</p>
<p>The solution is “cursor-based pagination”. Instead of passing <code>offset=20</code> to get the second page, you take the final ticket on the first page (say, with ID 32) and pass <code>cursor=32</code>. The API will then return the next ten tickets, <em>starting with ticket number 32</em>. Instead of using <code>OFFSET</code>, the query becomes <code>WHERE id &gt; cursor ORDER BY id LIMIT 10</code>. That query is equally quick whether you’re at the start of the collection or hundreds of thousands of tickets in, because the database can instantly find the (indexed) position of your cursor ticket instead of having to count through the entire offset.</p>
<p><strong>You should always use cursor-based pagination for datasets that might end up being large.</strong> Even though it’s harder for consumers to grasp, when you run into scaling problems you might <em>have</em> to change to cursor-based pagination anyway, and the cost of making that change is often very high. However, I think it’s fine to use page or offset-based pagination otherwise.</p>
<p>It’s usually wise to include a <code>next_page</code> field in your API list responses. That saves consumers having to figure out the next page number or cursor on their own.</p>
<h3>Optional fields and GraphQL</h3>
<p><strong>If parts of your API response are expensive to serve, make them optional.</strong> For instance, if fetching the user’s subscription status requires your backend to make an API call, consider making your <code>/users/:id</code> endpoint not return subscription unless the request passes an <code>include_subscription</code> parameter. As a more general approach, you could have an <code>includes</code> array parameter with all your optional fields. This is often used for records that are associated (for instance, you could pass <code>includes: [posts]</code> to your user request to get the user’s posts in the response).</p>
<p>This is part of the idea behind <a href="https://graphql.org/">GraphQL</a>, a style of API where instead of hitting different endpoints per-operation, you craft a single query with all the data you need and the backend figures it out<sup id="fnref-6"><a href="#fn-6">6</a></sup>.</p>
<p><strong>I don’t like GraphQL very much</strong>, for three reasons. First, it’s completely impenetrable to non-engineers (and to many engineers). Once you learn it, it’s a tool like any other, but the barrier to entry is just so much higher than <code>GET /users/1</code>. Second, I don’t like giving users the freedom to craft arbitrary queries. It makes caching more complicated and increases the number of edge cases you have to think about. Third, in my experience the backend implementation is so much more fiddly than your standard REST API.</p>
<p>I don’t feel <em>that</em> strongly about my dislike of GraphQL. I’ve spent maybe six months working with it in various contexts and am far from an expert. I’m sure there are use cases where it buys you enough flexibility to be worth the costs. But right now I’d only use it where I absolutely had to.</p>
<h3>Internal APIs</h3>
<p>Everything I’ve said so far is about <em>public</em> APIs. What about internal APIs: APIs that are only used by your colleagues at a particular company? Some of the assumptions I’ve made above don’t hold for internal APIs. For instance, your consumers are usually professional software engineers. It’s also possible to safely make breaking changes, because (a) you often have an order of magnitude fewer users, and (b) you have the ability to go in and ship new code for all of those users. You can require as complex a form of authentication as you want.</p>
<p>However, internal APIs can still be a source of incidents, and still need to be idempotent for key operations.</p>
<h3>Summary</h3>
<ul>
<li>APIs are hard to build because they’re inflexible but must be easy to adopt</li>
<li>API maintainers’ primary duty is to NOT BREAK USERSPACE. Never make breaking changes to public APIs</li>
<li>Versioning your API lets you make changes, but imposes significant implementation and adoption barriers</li>
<li>If your product is valuable enough, it doesn’t really matter how good your API is, people will use it anyway</li>
<li>If your product is badly-designed enough, it doesn’t matter how carefully you design your API, it will likely suck</li>
<li>Your API should support simple API keys for authentication, because many of your users will not be professional engineers</li>
<li>Requests that take action (particularly high-stakes action like payments) should include some kind of idempotency key to make retries safe</li>
<li>Your API will always be a source of incidents. Make sure you have rate limits and killswitches in place</li>
<li>Use cursor-based pagination for datasets that might end up being very large</li>
<li>Make expensive fields optional and off-by-default, but (in my opinion) GraphQL is overkill</li>
<li>Internal APIs are different in some ways (because your consumers are very different)</li>
</ul>
<p>What haven’t I written about? I haven’t written much about REST vs SOAP, or JSON vs XML, because I don’t think that stuff is particularly important. I like REST and JSON, but I don’t feel strongly about it. I also haven’t mentioned OpenAPI schema - it’s a useful tool, but I think it’s also fine to just write your API docs in Markdown if you want.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paracetamol disrupts early embryogenesis by cell cycle inhibition (172 pts)]]></title>
            <link>https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396</link>
            <guid>45006296</guid>
            <pubDate>Sun, 24 Aug 2025 18:02:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396">https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396</a>, See on <a href="https://news.ycombinator.com/item?id=45006296">Hacker News</a></p>
Couldn't get https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Is 4chan the perfect Pirate Bay poster child to justify wider UK site-blocking? (288 pts)]]></title>
            <link>https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/</link>
            <guid>45005545</guid>
            <pubDate>Sun, 24 Aug 2025 16:30:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/">https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/</a>, See on <a href="https://news.ycombinator.com/item?id=45005545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/trollfac-uk.png.webp 724w, https://torrentfreak.com/images/trollfac-uk-300x188.png.webp 300w" sizes="auto, (max-width: 300px) 100vw, 300px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/trollfac-uk.png" alt="" width="300" height="188" srcset="https://torrentfreak.com/images/trollfac-uk.png 724w, https://torrentfreak.com/images/trollfac-uk-300x188.png 300w, https://torrentfreak.com/images/trollfac-uk-600x376.png 600w, https://torrentfreak.com/images/trollfac-uk-150x94.png 150w" sizes="auto, (max-width: 300px) 100vw, 300px">
</picture>
The UK’s Online Safety Act (OSA) claims to protect children but has faced fierce criticism for censoring everything from legitimate news reporting from war zones, to critical discussion of the Act itself.</p>
<p>There are many problems, not least a requirement for adults in the UK to prove their identity when accessing sites meeting criteria dictated by Ofcom. Large sites, many in the United States, face huge fines for allowing children to access age-inappropriate content. </p>
<p>This means that unverified adults are treated as children with the same content restrictions. Ofcom’s global threats have led some sites to conclude that the safest option is to ban UK visitors altogether.</p>
<h2>Degraded Internet Experience? Hand Over Your Papers</h2>
<p>Successive UK governments understood there were risks, or rather, they were informed of the risks and went ahead regardless. Whether the internet is any safer is almost impossible to measure; the same can’t be said for the hours wasted or lost, and the corresponding increases in blood pressure, all thanks to artificial restrictions that punish those who value their privacy. </p>
<p>Guided by the mantra, “a problem shared is a problem halved” those who air their OSA grievances in public find themselves presented with a 50/50 ultimatum. According to Peter Kyle, Secretary of State for Science, Innovation and Technology, those with an opinion on the legislation fall into two categories: </p>
<p>1) People who want to protect kids and 2) People who side with online predators.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/osa-predator.png.webp 498w, https://torrentfreak.com/images/osa-predator-300x109.png.webp 300w" sizes="auto, (max-width: 498px) 100vw, 498px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/osa-predator.png" alt="osa-predator" width="498" height="181" srcset="https://torrentfreak.com/images/osa-predator.png 498w, https://torrentfreak.com/images/osa-predator-300x109.png 300w, https://torrentfreak.com/images/osa-predator-150x55.png 150w" sizes="auto, (max-width: 498px) 100vw, 498px">
</picture>
</center>
<h2>You’re Either With Us, or Against Us</h2>
<p>The imposition of a binary choice is a well-worn political tactic. It aims to shut down dissent and/or discredit the speaker; in this case ordinary members of the public branded ‘predator enablers’ by a government minister.</p>
<p>VPN users warranted direct advice; no allegations this time but a suggestion that, just like the unverified, VPN users aren’t helping to keep children safe.</p>
<center><em>Just verify your age (impossible without verifying your identity)</em><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/vpn-uk.png.webp 676w, https://torrentfreak.com/images/vpn-uk-300x85.png.webp 300w" sizes="auto, (max-width: 676px) 100vw, 676px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/vpn-uk.png" alt="vpn-uk" width="676" height="192" srcset="https://torrentfreak.com/images/vpn-uk.png 676w, https://torrentfreak.com/images/vpn-uk-300x85.png 300w, https://torrentfreak.com/images/vpn-uk-600x170.png 600w, https://torrentfreak.com/images/vpn-uk-150x43.png 150w" sizes="auto, (max-width: 676px) 100vw, 676px">
</picture>
</center>
<p>In the event that the above fails to silence the troublemakers, the UK government has recently been discovered filing requests with overseas companies to delete posts made by UK citizens’ criticizing certain aspects of government policy. A United States Department of State <a href="https://www.state.gov/reports/2024-country-reports-on-human-rights-practices/united-kingdom">report</a>, criticizing the UK government for degrading the right to freedom of expression, remains stubbornly accessible. </p>
<h2>No Border Too Distant</h2>
<p>Of course, attempting to silence the State Department would be a truly historic mistake, especially in the wake of comments made by Metropolitan Police Commissioner Sir Mark Rowley. </p>
<p>Last summer Rowley threatened to “throw the full force of the law at people” for unacceptable social media comments, warning that “whether you’re in this country committing crimes on the streets or committing crimes from further afield online, we will come after you.”</p>
<p>Widely interpreted as a warning to citizens of the United States, and by extension a direct threat to their constitutional rights, U.S. officials intervened. Congressman Keith Self warned that “harassing Americans will do absolutely nothing to resolve Great Britain’s internal issues” and risks damaging the US/UK alliance.</p>
<p>As the United States attempts to introduce home turf pirate site blocking from <a href="https://torrentfreak.com/new-bill-aims-to-block-foreign-pirate-sites-in-the-u-s-250129/">three</a> <a href="https://torrentfreak.com/second-u-s-piracyiblocking-bill-incoming-mpa-google-verizon-meet-to-discuss-250227/">different</a> <a href="https://torrentfreak.com/unveiled-new-u-s-anti-piracy-bill-acpa-proposes-alternative-site-blocking-path/">directions</a>, the UK government is already preparing to take site blocking to the next level. </p>
<p>Thanks to provisions in the Online Safety Act, the UK will soon begin drawing on 15 years of pirate site blocking experiences, to block regular sites that fail to meet their ‘obligations’ as laid out <a href="https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer">in the legislation</a>.</p>
<h2>Site Blocking For The People?</h2>
<p>Ofcom’s stated purpose is to serve the public, within duties defined by parliament, independently, using funds provided by the companies in the sectors it regulates. As regulator, Ofcom doesn’t need permission from the public to start blocking sites, although general approval would likely make the process less controversial. </p>
<p>With the whole world watching and various platforms waiting to see if Ofcom’s threats of global enforcement can be ignored, there’s little room for error.</p>
<p>In the current climate any blocking could be perceived as a further restriction of free speech, or even straightforward censorship. The conundrum is how to make site blocking appear less like censorship while satisfying the people that it’s absolutely necessary. It’s a big ask, but not impossible.</p>
<h2>The Pirate Bay: Default Poster Child of Piracy Blocking</h2>
<p>In 2012 when the major recording labels obtained their first UK site blocking injunction on copyright grounds, they could’ve picked a no-name MP3 download site and walked away with an easy win. They picked The Pirate Bay instead, and not just because of the site’s profile and unparalleled infamy. </p>
<p><strong>#1 Perfect Candidate:</strong> After years in the headlines, The Pirate Bay’s belligerent stance was well understood and at this point, helpfully predictable. First, there was never any chance of TPB spontaneously complying with copyright law. Since blocking injunctions came to exist for the purpose of tackling uncooperative entities, no candidate was more perfectly matched than the most uncooperative pirate site in the world.</p>
<p><strong>#2 No Appearance? No Win:</strong> The odds of TPB’s operators making an appearance at the High Court in London were always vanishingly slim, but not just for the reasons one might expect. The site’s alleged operators were never served in the blocking case, and they never appeared at the hearing. In fact, the site wasn’t represented in any way, at any stage. </p>
<p><strong>#3 If Done Right, No Defense:</strong> After it was determined that the law didn’t require TPB’s operators to be named as defendants, they were effectively excluded from the process. The ISPs were the defendants in this “no fault” case, and when they were ordered to block TPB, the terms of the injunction were those previously agreed in discussion with the labels.</p>
<p>Describing this as an ‘easy win’ would be a disservice to the work put in by the labels. Nothing was left to chance and the end result spoke for itself. The Pirate Bay and its function needed no introduction, and among supporters and opponents alike, acceptance that it exists for the purpose of infringement on a massive scale, was never in doubt. </p>
<p>That the process was entirely one-sided was neither here nor there. Nobody was surprised by the choice of target or the eventual outcome; in the bigger picture, controversy was kept to a minimum.</p>
<p>Now it’s Ofcom’s turn to convince, or simply inform the public, that blocking non-pirate sites benefits everyone. On paper, the notorious  4chan forum ticks all the right boxes and presumably no match for the well-resourced Ofcom.</p>
<h2>4chan: Poster Child of Regular Site Blocking?</h2>
<p>One can only imagine the reaction at 4chan when Ofcom advised that it had new obligations under a foreign law. Section 9(2) of the Act requires certain platforms to undertake an illegal content risk assessment, to assess the risks of users encountering ‘illegal’ content on their platforms. </p>
<p>The requirements were <a href="https://www.ofcom.org.uk/siteassets/resources/documents/consultations/category-1-10-weeks/185926-consultation-online-safety-information-guidance/associated-documents/draft-illegal-content-codes-of-practice-for-user-to-user-services.pdf?v=392429">published</a> February 24, 2025, and the ‘Illegal Content Duties’ came into effect on 17 March 2025. On April 14, Ofcom issued a ‘formal information notice’ to 4chan demanding a copy of its Illegal Content Risk Assessment and not surprisingly, received no reply.</p>
<p>In common with The Pirate Bay, 4chan’s non-compliance was <em>almost</em> inevitable. When accompanied by threats to disrupt its business, including by obtaining a court order to compel payment processors, advertisers, and hosting providers to stop doing business, while levying fines of £20,000 per day, non-compliance was effectively guaranteed. In this respect, 4chan’s response was entirely predictable.</p>
<h2>4chan Unlikely to Attend Court in the UK</h2>
<p>As highlighted previously, cases are more easily won when it’s understood that the defendant won’t make an appearance. We can safely assume that 4chan has the same number of tickets to London as it does Illegal Content Risk Assessments so, no, it will not attend. So far, so good then? Not exactly. </p>
<p>Ofcom launched its 4chan investigation on June 10, to determine compliance with various duties under the Online Safety Act. </p>
<p>Did 4chan adequately respond to a statutory information request? Has it conducted and kept a record of its illegal content risk assessment? Is it complying with its safety duties, including protecting its users from ‘illegal’ content? </p>
<p>Ofcom currently has no answers to these questions but did learn something new this week. Not only has 4chan hired extremely capable attorneys in response to Ofcom’s threats, any action by Ofcom will be resisted in the United States under Federal Law. </p>
<h2>New Jurisdiction, Different Ball Game</h2>
<p>Since Ofcom’s threats are viewed as undermining 4chan’s constitutional rights, its attorneys believe that no court in America will allow foreign penalties to be enforced in the United States. Once people begin speaking about that, the damage will have been done.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/ofcom-4chan.png.webp 649w, https://torrentfreak.com/images/ofcom-4chan-300x360.png.webp 300w" sizes="auto, (max-width: 649px) 100vw, 649px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/ofcom-4chan.png" alt="ofcom-4chan" width="649" height="779" srcset="https://torrentfreak.com/images/ofcom-4chan.png 649w, https://torrentfreak.com/images/ofcom-4chan-300x360.png 300w, https://torrentfreak.com/images/ofcom-4chan-600x720.png 600w, https://torrentfreak.com/images/ofcom-4chan-125x150.png 125w" sizes="auto, (max-width: 649px) 100vw, 649px">
</picture>
</center>
<p>Given the offense caused by last year’s threats by UK police against U.S. citizens, and similar events since then, the final three paragraphs of the statement above seem especially relevant. </p>
<p>By selecting 4chan as a potential target for enforcement, knowing all too well it would refuse to comply, a stand-off has been engineered between UK censorship measures nobody asked for, and the constitutional rights of all Americans.</p>
<p>If the hallmarks of the win in The Pirate Bay case were predictability, inability to mount any defense, and the avoidance of controversy, this is only just short of a complete disaster. .</p>
<h2>Who’s in Charge of Government Policy?</h2>
<p>Further escalation at the political level in the event Ofcom digs in, may demand intervention at the highest level. For Prime Minister Keir Starmer, that does not bode well</p>
<p>First, Ofcom is independent, so that may not even be possible. Second, consider this recent exchange between JD Vance and Keir Starmer himself on the erosion of free speech in the UK.</p>
<p><em><strong>Vance:</strong> “We also know that there have been infringements on free speech that actually affect not just the British. Of course, what the British do in their own country is up to them, but they also affect American technology companies and by extension American citizens. So that is something that we’ll talk about today at lunch.”</em></p><p><em><strong>Starmer</strong>: “We’ve had free speech for a very long time in the United Kingdom and uh..uh.. and it will last for a very, very long time. Well no, I mean we certainly wouldn’t want to reach across to US citizens…and we don’t…and that’s absolutely right.</em></p>
<p>Ofcom begs to differ, clearly; so who is in charge here? Why doesn’t the Prime Minister know that the UK is actively “reaching across to US citizens?” Unfortunately, Ofcom has a reputation for not backing down. On the plus side, it hasn’t imposed any penalties to back down from yet, so there is that.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/safety.png.webp 348w, https://torrentfreak.com/images/safety-300x177.png.webp 300w" sizes="auto, (max-width: 348px) 100vw, 348px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/safety.png" alt="safety" width="348" height="205" srcset="https://torrentfreak.com/images/safety.png 348w, https://torrentfreak.com/images/safety-300x177.png 300w, https://torrentfreak.com/images/safety-150x88.png 150w, https://torrentfreak.com/images/safety-220x130.png 220w" sizes="auto, (max-width: 348px) 100vw, 348px">
</picture>
</center>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We put a coding agent in a while loop (275 pts)]]></title>
            <link>https://github.com/repomirrorhq/repomirror/blob/main/repomirror.md</link>
            <guid>45005434</guid>
            <pubDate>Sun, 24 Aug 2025 16:18:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/repomirrorhq/repomirror/blob/main/repomirror.md">https://github.com/repomirrorhq/repomirror/blob/main/repomirror.md</a>, See on <a href="https://news.ycombinator.com/item?id=45005434">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_product_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
          <p>
            GitHub Spark
              <span>
                New
              </span>
          </p><p>
        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    
                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:repomirrorhq/repomirror" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="ruW8NA9nnUwcapK3-_ZUyFl-0-1LYqt3R2BEwHzR3VqW450j5Mi9l73GD2eIX1vQ6sm-NerrPkewqlK9S29N9g" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="repomirrorhq/repomirror" data-current-org="repomirrorhq" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=repomirrorhq%2Frepomirror" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/repomirrorhq/repomirror/blob/main/repomirror.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="be5fc9f8f2458dfd6671808d38b89ca4335cdc3358fca86a57ffa37d8e2a8d5e" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-3162669a-10ae-46d8-b163-a717f9aa08d1" for="icon-button-10782354-4de3-41e9-a5ca-e89918c908dd" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.0c0051664a94f0e136ff.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.c82a4db79200850fb016.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite (with WAL) doesn't do `fsync` on each commit under default settings (102 pts)]]></title>
            <link>https://avi.im/blag/2025/sqlite-fsync/</link>
            <guid>45005071</guid>
            <pubDate>Sun, 24 Aug 2025 15:40:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avi.im/blag/2025/sqlite-fsync/">https://avi.im/blag/2025/sqlite-fsync/</a>, See on <a href="https://news.ycombinator.com/item?id=45005071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p><strong>edit</strong>: the title is incorrect, may be applies to macOS or specific compilations. Check the update below.</p><p>SQLite has a WAL mode (the default is journal mode), but you’re likely using it if you want higher write throughput. SQLite also has a PRAGMA called <code>synchronous</code> which configures how <code>fsync</code> is called. The default is <code>NORMAL</code>. This is what the docs say:</p><blockquote><p>[..] but WAL mode does lose durability. A transaction committed in WAL mode with <code>synchronous=NORMAL</code> might roll back following a power loss or system crash.</p></blockquote><blockquote><p>In WAL mode when synchronous is <code>NORMAL (1)</code>, the WAL file is synchronized before each checkpoint and the database file is synchronized after each completed checkpoint and the WAL file header is synchronized when a WAL file begins to be reused after a checkpoint, but no sync operations occur during most transactions.</p></blockquote><blockquote><p>If durability is not a concern, then synchronous=NORMAL is normally all one needs in WAL mode.</p></blockquote><p>If you want <code>fsync</code> to be called on each commit, use <code>FULL</code>:</p><blockquote><p>With <code>synchronous=FULL</code> in WAL mode, an additional sync operation of the WAL file happens after each transaction commit. The extra WAL sync following each transaction helps ensure that transactions are durable across a power loss. Transactions are consistent with or without the extra syncs provided by <code>synchronous=FULL</code>.</p></blockquote><p><a href="https://www.sqlite.org/pragma.html#pragma_synchronous">https://www.sqlite.org/pragma.html#pragma_synchronous</a></p><h3 id="update"><strong>update</strong>:</h3><p>I was wrong about this one! It seems the default SQLite3 on macOS behaves like this:</p><pre tabindex="0"><code>$ sqlite3 test.db

SQLite version 3.43.2 2023-10-10 13:08:14
Enter ".help" for usage hints.
sqlite&gt; PRAGMA journal_mode=wal;
wal
sqlite&gt; PRAGMA synchronous;
1
sqlite&gt;
</code></pre><p>but a fresh copy from homebrew behaved differently:</p><pre tabindex="0"><code>$ /opt/homebrew/opt/sqlite/bin/sqlite3 test.db

SQLite version 3.50.4 2025-07-30 19:33:53
Enter ".help" for usage hints.
sqlite&gt; PRAGMA journal_mode=wal;
wal
sqlite&gt; PRAGMA synchronous;
2
sqlite&gt;
</code></pre><p>Furthermore, as pointed out by charleslmunger on HN, the compile time options do set it to <code>FULL</code>:</p><blockquote><p><code>SQLITE_DEFAULT_SYNCHRONOUS=&lt;0-3&gt;</code> This macro determines the default value of the PRAGMA synchronous setting. If not overridden at compile-time, the default setting is 2 (FULL).</p></blockquote><blockquote><p><code>SQLITE_DEFAULT_WAL_SYNCHRONOUS=&lt;0-3&gt;</code> This macro determines the default value of the PRAGMA synchronous setting for database files that open in WAL mode. If not overridden at compile-time, this value is the same as <code>SQLITE_DEFAULT_SYNCHRONOUS</code>.</p></blockquote><p><a href="https://sqlite.org/compile.html#default_synchronous">https://sqlite.org/compile.html#default_synchronous</a></p><hr><p><small>Someone passed me this post <a href="https://blog.cf8.gg/surrealdbs-ch/">SurrealDB is sacrificing data durability to make benchmarks look better</a> and asked me how SQLite works.</small></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comet AI browser can get prompt injected from any site, drain your bank account (571 pts)]]></title>
            <link>https://twitter.com/zack_overflow/status/1959308058200551721</link>
            <guid>45004846</guid>
            <pubDate>Sun, 24 Aug 2025 15:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/zack_overflow/status/1959308058200551721">https://twitter.com/zack_overflow/status/1959308058200551721</a>, See on <a href="https://news.ycombinator.com/item?id=45004846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making games in Go: 3 months without LLMs vs. 3 days with LLMs (314 pts)]]></title>
            <link>https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/</link>
            <guid>45004728</guid>
            <pubDate>Sun, 24 Aug 2025 15:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/">https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/</a>, See on <a href="https://news.ycombinator.com/item?id=45004728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>After 15 years as a software engineer, I realized I had never actually built and published a game.</p><p>Since I grew up in 🇦🇷 Argentina playing card games with my friends, I figured I’d choose one of those. I asked myself:</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/most-common.png" alt="most-common-card-games"></p><h2 id="truco-3-months-without-llms">Truco: 3 Months Without LLMs</h2><p>On <a href="https://github.com/marianogappa/truco/commit/80ad842f546ac5bdf0d680d105afc10b66626d0f">June 18th of 2024</a> I started building <a href="https://en.wikipedia.org/wiki/Truco">Truco</a> in my free time. As a longtime Go backend developer, the backend was obvious. The challenge was the UI and long-term hosting without a paid server.</p><table><thead><tr><th>Problem</th><th>Solution</th></tr></thead><tbody><tr><td>UI</td><td>Bit the bullet and learned the minimal required <a href="https://reactjs.org/">React</a> for the UI.</td></tr><tr><td>No server</td><td>Transpiled the server to <a href="https://en.wikipedia.org/wiki/WebAssembly">WASM</a> using <a href="https://tinygo.org/">TinyGo</a>.</td></tr><tr><td>Hosting</td><td>Used <a href="https://pages.github.com/">GitHub Pages</a> to host the static files.</td></tr></tbody></table><p>This was pre-LLM, so every detail had to be figured out by hand. It took about 3 months of trial and error to get it ready.</p><p>I never planned to advertise or monetize it; I just wanted to finish, and maybe give someone the joy of playing their childhood game again. A year later, without any extra effort on my part, people are still playing it!</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/truco-analytics.png" alt="truco-analytics"></p><p>In case you want to check it out, here are some links for it:</p><p><a href="https://marianogappa.github.io/truco-argentino">Truco (play the game)</a></p><p><a href="https://github.com/marianogappa/truco">Backend in Go</a></p><p><a href="https://github.com/marianogappa/truco-argentino">Frontend in React</a> (don’t judge me 🤷‍♂️ best I can do with 1-hour React knowledge)</p><h2 id="escoba-3-days-with-llms">“Escoba”: 3 Days With LLMs</h2><p>A year later, visiting family in Argentina, I taught my nephew <a href="https://en.wikipedia.org/wiki/Escoba">Escoba</a>—the country’s second most popular card game (despite what ChatGPT insists).</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/two-most-common.png" alt="two-most-common-card-games"></p><p>With LLMs now mainstream, I wondered how much faster building a game might be—so I decided to test it.</p><p>I cloned the backend for Truco and gave <a href="https://claude.ai/">Claude</a> a long prompt explaining the rules of Escoba and asking it to refactor the code to implement it. To my surprise, it worked almost perfectly on the first prompt 😱. For a moment I thought: goodbye, job 😰.</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/prompt.png" alt="prompt"></p><p>The only bug I found was that it used <code>append</code> <a href="https://github.com/marianogappa/escoba/commit/e9c373a38cb2ca5e7eefca2870f91e7def1579f7#diff-8e38aecf51e5858a66646d328292fc8abf36f6a602ef3ea4ed7fc1ca2b1a0240L104-L105">incorrectly in one place and mutated actions</a>. Except for that, I only added a few bells and whistles on top (like <a href="https://github.com/marianogappa/escoba/commit/fe1c87bed8e9b60cc902dfc563c356506c2faf4c">a better bot</a>).</p><p>The frontend was a different story; it took me a few days to get it right. The real challenge probably wasn’t just the LLM — it was my own React skills, combined with the unusual setup of letting a black-box WASM function manage game state. Debugging in JavaScript also didn’t make life easier.</p><p>In case you want to check it out, here are some links for it:</p><p><a href="https://marianogappa.github.io/escoba-de-15">Escoba (play the game)</a></p><p><a href="https://github.com/marianogappa/escoba">Backend in Go</a></p><p><a href="https://github.com/marianogappa/escoba-de-15">Frontend in React</a></p><h2 id="step-by-step-how-to-build-your-own-game">Step-by-Step: How to Build Your Own Game</h2><p>I’m assuming you might have come here to see if it’s not too hard to give it a try yourself! So I’ll give you the minimalistic primer to make your own game with this stack.</p><p>I wrote a minimalistic Tic-Tac-Toe game set of repos so you can fork them to get started:</p><p><a href="https://github.com/marianogappa/tictactoe-backend">https://github.com/marianogappa/tictactoe-backend</a>
<a href="https://github.com/marianogappa/tictactoe-frontend">https://github.com/marianogappa/tictactoe-frontend</a></p><p>You can check it out here:</p><p><a href="https://marianogappa.github.io/tictactoe-frontend/">https://marianogappa.github.io/tictactoe-frontend/</a></p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/tictactoe.png" alt="TicTacToe"></p><h3 id="backend-side">Backend-side</h3><p>A turn-based backend is straightforward to outline:</p><ul><li><a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L157">Initialize</a> a <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L16">GameState struct</a> (e.g. initial board setup, empty actions list).</li><li>Implement <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L378"><code>CalculatePossibleActions</code></a>, so clients know what’s valid.</li><li>Add <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L213">RunAction</a> to mutate the GameState.</li><li>If there’s a bot, write a function to <a href="https://github.com/marianogappa/truco/blob/v0.2.0/examplebot/newbot/bot.go#L38">pick an action</a> from the current state.</li></ul><p>That’s it!</p><p><em>Note: forget human vs human, unless you’re willing to pay for that server.</em></p><h3 id="frontend-side">Frontend-side</h3><p>I’m no frontend expert, but the tasks are simple:</p><ul><li>Call the backend to create a new <code>GameState</code>.</li><li>Render it in the UI.</li><li>Let the player pick an action from the valid options.</li><li>Call the backend to apply the action.</li><li>Trigger the bot’s action when it’s their turn.</li></ul><p>That’s it!</p><h3 id="backend-side-interop">Backend-side interop</h3><p>To transpile the backend to WASM, you can build with (docs <a href="https://go.dev/wiki/WebAssembly">here</a>):</p><div><pre tabindex="0"><code data-lang="bash"><span><span>GOARCH<span>=</span>wasm GOOS<span>=</span>js go build -o main.wasm main.go
</span></span></code></pre></div><p>But that produces huge binaries (which is slow on mobile). Use <a href="https://tinygo.org/">TinyGo</a> for smaller ones.</p><p>Before compiling, you need a different entrypoint to the functions that you’re going to make available to the frontend. <a href="https://github.com/marianogappa/truco/blob/v0.2.0/main_wasm.go">Make a different <code>main.go</code></a> file that exports the functions that you need, and <a href="https://github.com/marianogappa/truco/blob/v0.2.0/main_wasm.go#L2">guard it via build flags</a>:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>//go:build tinygo</span>
</span></span><span><span><span>// +build tinygo</span>
</span></span><span><span>
</span></span><span><span><span>package</span> <span>main</span>
</span></span><span><span>
</span></span><span><span>[<span>...</span>]
</span></span><span><span>
</span></span><span><span><span>func</span> <span>main</span>() {
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoNew"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoNew</span>))
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoRunAction"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoRunAction</span>))
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoBotRunAction"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoBotRunAction</span>))
</span></span><span><span>	<span>select</span> {}
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>var</span> (
</span></span><span><span>	<span>state</span> <span>*</span><span>truco</span>.<span>GameState</span> <span>// "Global variable" for the GameState</span>
</span></span><span><span>	<span>bot</span>   <span>truco</span>.<span>Bot</span>
</span></span><span><span>)
</span></span></code></pre></div><p>Don’t forget to block at the end of <code>main()</code> with <code>select {}</code> to prevent the program from exiting immediately.</p><h3 id="backend-data-interop">Backend data interop</h3><p><code>GameState</code> is typically a free-form struct that you define in Go. WASM can’t directly serialize/deserialize structs. The trick is to pass everything as JSON. After digging through <a href="https://tinygo.org/docs/guides/webassembly/">TinyGo docs</a>, here’s the formula:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>trucoRunAction</span>(<span>this</span> <span>js</span>.<span>Value</span>, <span>p</span> []<span>js</span>.<span>Value</span>) <span>interface</span>{} { <span>// Always this signature</span>
</span></span><span><span>	<span>// Read the input JSON</span>
</span></span><span><span>    <span>jsonBytes</span> <span>:=</span> make([]<span>byte</span>, <span>p</span>[<span>0</span>].<span>Length</span>()) 
</span></span><span><span>	<span>js</span>.<span>CopyBytesToGo</span>(<span>jsonBytes</span>, <span>p</span>[<span>0</span>])
</span></span><span><span>
</span></span><span><span>	<span>// 1. Decode the input JSON to your struct</span>
</span></span><span><span>    <span>// 2. Run your Go code, return an output struct</span>
</span></span><span><span>	<span>// 3. Encode the output struct to JSON</span>
</span></span><span><span>	<span>newBytes</span> <span>:=</span> <span>_runAction</span>(<span>jsonBytes</span>)
</span></span><span><span>
</span></span><span><span>	<span>// Return the output JSON</span>
</span></span><span><span>	<span>buffer</span> <span>:=</span> <span>js</span>.<span>Global</span>().<span>Get</span>(<span>"Uint8Array"</span>).<span>New</span>(len(<span>newBytes</span>))
</span></span><span><span>	<span>js</span>.<span>CopyBytesToJS</span>(<span>buffer</span>, <span>newBytes</span>)
</span></span><span><span>	<span>return</span> <span>buffer</span>
</span></span><span><span>}
</span></span></code></pre></div><h3 id="frontend-side-interop">Frontend-side interop</h3><p>Finally, <a href="https://github.com/marianogappa/truco-argentino/blob/main/public/index.html#L45">call the backend functions from the frontend</a> and [track the GameState in a global variable]((<a href="https://github.com/marianogappa/truco-argentino/blob/main/src/gameState.js#L19)">https://github.com/marianogappa/truco-argentino/blob/main/src/gameState.js#L19)</a>:</p><div><pre tabindex="0"><code data-lang="js"><span><span><span>function</span> <span>jsRunAction</span>(<span>data</span>) {
</span></span><span><span>    <span>const</span> <span>encoder</span> <span>=</span> <span>new</span> <span>TextEncoder</span>();
</span></span><span><span>    <span>const</span> <span>encodedData</span> <span>=</span> <span>encoder</span>.<span>encode</span>(<span>JSON</span>.<span>stringify</span>(<span>data</span>));
</span></span><span><span>    <span>const</span> <span>result</span> <span>=</span> <span>trucoRunAction</span>(<span>encodedData</span>);
</span></span><span><span>    <span>const</span> <span>json</span> <span>=</span> <span>new</span> <span>TextDecoder</span>().<span>decode</span>(<span>result</span>);
</span></span><span><span>    <span>return</span> <span>JSON</span>.<span>parse</span>(<span>json</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>let</span> <span>gameState</span> <span>=</span> <span>jsNewGame</span>();
</span></span><span><span>
</span></span><span><span><span>// Note that RunAction doesn't take a GameState.
</span></span></span><span><span><span>// WASM is the source of truth; your frontend can't mutate it.
</span></span></span><span><span><span></span><span>gameState</span> <span>=</span> <span>jsRunAction</span>(<span>action</span>); 
</span></span></code></pre></div><p>Every time you modify the backend, you need to recompile it to WASM and replace the old file in the frontend. I put this in <a href="https://github.com/marianogappa/escoba-de-15/blob/main/Makefile">the Makefile</a>:</p><pre tabindex="0"><code>compile_library:
	cd $(GOPATH)/src/github.com/marianogappa/escoba &amp;&amp; \
	TINYGOROOT=/usr/local/Cellar/tinygo/0.38.0 tinygo build -o main.wasm -target wasm main_wasm.go &amp;&amp; \
	mv main.wasm $(CURDIR)/public/wasm/wasm.wasm &amp;&amp; \
	cp /usr/local/Cellar/tinygo/0.38.0/targets/wasm_exec.js $(CURDIR)/public/wasm/wasm_exec.js &amp;&amp; \
	cd -
</code></pre><p>Note that I’m also copying over <code>wasm_exec.js</code>. This is a requirement for running WASM code. The other requirement is to add the <a href="https://github.com/marianogappa/truco-argentino/blob/main/public/index.html#L16">script tag to the HEAD of the HTML file</a>:</p><div><pre tabindex="0"><code data-lang="html"><span><span>
</span></span><span><span>    &lt;<span>script</span> <span>src</span><span>=</span><span>"wasm/wasm_exec.js"</span>&gt;&lt;/<span>script</span>&gt;
</span></span><span><span>	&lt;<span>script</span>&gt;
</span></span><span><span>        <span>const</span> <span>go</span> <span>=</span> <span>new</span> <span>Go</span>(); <span>// Defined in wasm_exec.js
</span></span></span><span><span><span></span>        <span>const</span> <span>WASM_URL</span> <span>=</span> <span>'wasm/wasm.wasm'</span>;
</span></span><span><span>
</span></span><span><span>        <span>var</span> <span>wasm</span>;
</span></span><span><span>        <span>let</span> <span>wasmReady</span> <span>=</span> <span>false</span>;
</span></span><span><span>
</span></span><span><span>        <span>if</span> (<span>'instantiateStreaming'</span> <span>in</span> <span>WebAssembly</span>) {
</span></span><span><span>            <span>WebAssembly</span>.<span>instantiateStreaming</span>(<span>fetch</span>(<span>WASM_URL</span>), <span>go</span>.<span>importObject</span>).<span>then</span>(<span>function</span> (<span>obj</span>) {
</span></span><span><span>                <span>wasm</span> <span>=</span> <span>obj</span>.<span>instance</span>;
</span></span><span><span>                <span>go</span>.<span>run</span>(<span>wasm</span>);
</span></span><span><span>                <span>wasmReady</span> <span>=</span> <span>true</span>;
</span></span><span><span>            })
</span></span><span><span>        } <span>else</span> {
</span></span><span><span>            <span>fetch</span>(<span>WASM_URL</span>).<span>then</span>(<span>resp</span> =&gt;
</span></span><span><span>                <span>resp</span>.<span>arrayBuffer</span>()
</span></span><span><span>            ).<span>then</span>(<span>bytes</span> =&gt;
</span></span><span><span>                <span>WebAssembly</span>.<span>instantiate</span>(<span>bytes</span>, <span>go</span>.<span>importObject</span>).<span>then</span>(<span>function</span> (<span>obj</span>) {
</span></span><span><span>                    <span>wasm</span> <span>=</span> <span>obj</span>.<span>instance</span>;
</span></span><span><span>                    <span>go</span>.<span>run</span>(<span>wasm</span>);
</span></span><span><span>                    <span>wasmReady</span> <span>=</span> <span>true</span>;
</span></span><span><span>                })
</span></span><span><span>            )
</span></span><span><span>        }
</span></span><span><span>    &lt;/<span>script</span>&gt;
</span></span></code></pre></div><h2 id="troubleshooting">Troubleshooting</h2><h3 id="the-wasm-file-is-not-loading">The WASM file is not loading</h3><p>This works automatically in Github Pages, but locally, you need to serve the files over HTTP. You can use <a href="https://www.npmjs.com/package/http-server">http-server</a> for this:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>npx http-server ./public -p <span>8080</span>
</span></span></code></pre></div><p>And then visit <code>http://localhost:8080</code> in your browser.</p><h2 id="conclusion">Conclusion</h2><p>I had a lot of fun making these games and I hope you find it interesting to see how it works. I also hope you find it useful to make your own games! If you have questions, I’m not hard to find.</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/escoba.png" alt="escoba"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US attack on renewables will lead to power crunch that spikes electricity prices (227 pts)]]></title>
            <link>https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html</link>
            <guid>45004466</guid>
            <pubDate>Sun, 24 Aug 2025 14:22:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html">https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html</a>, See on <a href="https://news.ycombinator.com/item?id=45004466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107172309" data-test="InlineImage"><p>Witthaya Prasongsin | Moment | Getty Images</p></div><div><p>President <a href="https://www.cnbc.com/donald-trump/">Donald Trump</a>'s attack on solar and wind projects threatens to raise energy prices for consumers and undermine a stretched electric grid that's already straining to meet rapidly growing demand, renewable energy executives warn.</p><p>Trump has long said wind power turbines are unattractive and endanger birds, and that solar installations take up too much land. This week, he said his administration <a href="https://www.cnbc.com/2025/08/20/trump-says-us-will-not-approve-solar-or-wind-power-projects.html">will not approve solar and wind</a> projects, the latest salvo in a campaign the president has waged against the renewable energy industry since taking office.</p><p>"We will not approve wind or farmer destroying Solar," Trump <a href="https://truthsocial.com/@realDonaldTrump/115061417084982814" target="_blank">posted on Truth Social</a> Wednesday. "The days of stupidity are over in the USA!!!"</p><p>Trump's statement this week seemed to confirm industry fears that the Interior Department will block federal permits for solar and wind projects. Interior Secretary Doug Burgum <a href="https://www.cnbc.com/2025/07/17/solar-wind-permit-interior-department-burgum-trump.html">took control of all permit approvals</a> last month in a move that the American Clean Power Association criticized as "obstruction," calling it "unprecedented political review."</p><p>The Interior Department blocking permits would slow the growth of the entire solar and wind industry, top executives at renewable developers <a href="https://arevonenergy.com/" target="_blank">Arevon</a>, <a href="https://avantus.com/about-us" target="_blank">Avantus</a> and <a href="https://www.engie-na.com/" target="_blank">Engie North America</a> told CNBC.</p><p>Even solar and wind projects on private land may need approvals from the U.S. Fish and Wildlife Service if, for example, a waterway or animal species is affected, the executives told CNBC. The three power companies are among the top 10 renewable developers in the U.S., according to energy research firm Enverus.</p><p>The Interior Department "will not give preferential treatment to massive, unreliable projects that make no sense for the American people or that risk harming communities or the environment," a spokesperson told CNBC when asked if new permits would be issued for solar and wind construction.</p><p>Choking off renewables will worsen a looming power supply shortage, harm the electric grid and lead to higher electricity prices for consumers, said Kevin Smith, CEO of Arevon, a solar and battery storage developer headquartered in Scottsdale, Arizona, that's active in 17 states. Arevon operates five gigawatts of power equivalent to $10 billion of capital investment.</p><p>"I don't think everybody realizes how big the crunch is going to be," Smith said. "We're making that crunch more and more difficult with these policy changes."</p><h3>Uncertainty hits investment</h3><p>The red tape at the Interior Department and rising costs from Trump's copper and steel tariffs have created market instability that makes planning difficult, the renewable executives said.</p><p>"We don't want to sign contracts until we know what the playing field is," said Cliff Graham, CEO of Avantus, a solar and battery storage developer headquartered in San Diego. Avantus has built three gigawatts of solar and storage across the desert Southwest.</p><p>"I can do whatever you want me to do and have a viable business, I just need the rules set and in place," Graham said.</p></div><div><p>Engie North America, the U.S. arm of a global energy company based in Paris, is slashing its planned investment in the U.S. by 50% due to tariffs and regulatory uncertainty, said David Carroll, the chief renewables officer who leads the American subsidiary. Engie could cut its plans even more, he said.</p><p>Engie's North American subsidiary, headquartered in Houston, will operate about 11 gigawatts of solar, battery storage and wind power by year end.</p><p>Multinationals like Engie have long viewed the U.S. as one of the most stable business environments in the world, Carroll said. But that assessment is changing in Engie's boardroom and across the industry, he said.</p><p>"The stability of the U.S. business market is no longer really the gold standard," Carroll said.</p><h3>Rising costs</h3><p>Arevon is seeing costs for solar and battery storage projects increase by as much as 30% due to the metal tariffs, said Smith, the CEO. Many renewable developers are renegotiating power prices with utilities to cover the sudden spike in costs because projects no longer pencil out financially, he said.</p><p>Trump's One Big Beautiful Bill Act ends two key tax credits for solar and wind projects in late 2027, making conditions even more challenging. The investment tax credit supported new renewable construction and the production credit boosted clean electricity generation.</p><p>Those tax credits were just passed on to consumers, Smith said. Their termination and the rising costs from tariffs will mean higher utility bills for families and businesses, he said.</p><p>The price that Avantus charges for solar power has roughly doubled to $60 per megawatt-hour as interest rates and tariffs have increased over the years, said CEO Graham. Prices will surge again to around $100 per megawatt-hour when the tax credits are gone, he said.</p><p>"The small manufacturers, small companies and mom and pops will see their electric bills go up, and it'll start pushing the small entrepreneurs out of the industry or out of the marketplace," Graham said.</p><p>Renewable projects that start construction by next July, a year after the One Big Beautiful Act became law, will still qualify for the tax credits. Arevon, Avantus and Engie are moving forward with projects currently under construction, but the outlook is less certain for projects later in the decade.</p><p>The U.S. will see a big downturn in new renewable power generation starting in the second half of 2026 through 2028 as new projects no longer qualify for tax credits, said Smith, the head of Arevon.</p><p>"The small- and medium-sized players that can't take the financial risk, some of them will disappear," Smith said. "You're going to see less projects built in the sector."</p><h3>Artificial intelligence power crunch</h3><p>Fewer renewable power plants could increase the risk of brownouts or blackouts, Smith said. Electricity <a href="https://www.cnbc.com/2024/11/23/data-centers-powering-ai-could-use-more-electricity-than-entire-cities.html">demand is surging from the data centers</a> that technology companies are building to train artificial intelligence systems. <a href="https://www.pjm.com/about-pjm" target="_blank">PJM Interconnection</a>, the largest electrical grid in the U.S. that coordinates wholesale electricity in 13 states&nbsp;and the District of Columbia, has warned of <a href="https://www.cnbc.com/2024/08/28/utilities-face-looming-crunch-as-electricity-demand-from-ai-surges.html">tight power supplies </a>because too little new generation is coming online.</p><p>Renewables are the power source that can most quickly meet demand, Smith at Arevon said. More than 90% of the power waiting to connect to the grid is solar, battery storage or wind, according to data from Enverus.</p><p>"The power requirement is largely going to be coming from the new energy sector or not at all," so without it, "the grid becomes substantially hampered," Smith said.</p></div><div><p>Trump is prioritizing oil, gas and nuclear power as "the most effective and reliable tools to power our country," White House spokesperson Anna Kelly said.</p><p>"President Trump serves the American people who voted to implement his America First energy agenda – not solar and wind executives who are sad that Biden's Green New Scam subsidies are ending," Kelly said.</p><p>But new natural gas plants won't come online for another five years due to supply issues, new nuclear power is a decade away and no new coal plants are on the drawing board.</p><p>Utilities may have to turn away data centers at some point because there isn't enough surplus power to run them, and no one wants to risk blackouts at hospitals, schools and homes, Arevon's Smith said. This would pressure the U.S. in its race against China to master AI, a Trump administration priority.</p><p>"The panic in the data center, AI world is probably not going to set in for another 12 months or so, when they start realizing that they can't get the power they need in some of these areas where they're planning to build data centers," Smith said.</p><p>"Then we'll see what happens," said the University of Chicago MBA, who's worked in the energy industry for 35 years. "There may be a reversal in policy to try and build whatever we can and get power onto the grid."</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE uses celebrity loophole to hide deportation flights (137 pts)]]></title>
            <link>https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/</link>
            <guid>45003819</guid>
            <pubDate>Sun, 24 Aug 2025 12:40:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/">https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/</a>, See on <a href="https://news.ycombinator.com/item?id=45003819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content">

                <!-- Antescript -->

                
                  
                

                <!-- Intro -->
                
                  
                

                
                  
                    <section id="ch-0">
                      <p>For years, the country’s rich and famous have used a little-known Federal Aviation Administration program to shield their private jets’ flight records from public view — among them Taylor Swift, Oprah Winfrey, and Steven Spielberg.</p>
<p>Now this decades-old program has a new client: Immigration and Customs Enforcement (ICE), the agency carrying out President Donald&nbsp;Trump’s mass deportations.</p>
<p>To obscure its planes, which ship immigrants out of the country on deportation flights, ICE is taking advantage of a longstanding program created by the private jet lobby,&nbsp;<i>The Lever&nbsp;</i>can confirm. For years, the scheme has allowed celebrities and Wall Street CEOs to partially block their flight data from public view.</p>
<p>Its use by the Trump administration’s immigration enforcers is part of a mounting effort by ICE and its contracted&nbsp;<a href="https://www.levernews.com/inside-the-billion-dollar-business-of-deportation-flights/">private charter airlines</a>&nbsp;to keep the planes’ flight paths hidden from the public. CNN first&nbsp;<a href="https://www.cnn.com/2025/08/13/politics/ice-flights-locations-tracking-maps%22%20%5Ct%20%22_blank">reported</a>&nbsp;on the trend, noting that ICE’s charter airlines were requesting some of the planes in their fleets be scrubbed from public flight tracking sites.</p>
<p>Deportation flights — like Swift’s private jet, whose enormous carbon footprint&nbsp;has stoked <a href="https://www.bbc.com/travel/article/20240213-taylor-swift-private-jet-flight-travel-carbon-footprint%22%20%5Ct%20%22_blank">public outcry</a>&nbsp;— can still be tracked in real time using other public data. But ICE’s use of the Federal Aviation Administration (FAA)’s private jet blacklist underscores how a growing push for privacy by the corporate jet lobby is being deployed to limit public oversight of ICE’s draconian immigration crackdown.</p>
<p>Activists and journalists have for many years tracked ICE’s secretive deportation flights, which critics say subject passengers to cruel and inhumane conditions. People being flown out of the country by ICE&nbsp;are frequently <a href="https://www.propublica.org/article/inside-ice-air-deportation-flights%22%20%5Ct%20%22_blank">shackled</a>&nbsp;for the duration of the journey, and advocates have documented a pattern of&nbsp;<a href="https://www.theguardian.com/us-news/2020/sep/19/ice-air-immigration-medical-negligence%22%20%5Ct%20%22_blank">medical neglect</a>&nbsp;on the planes. As one ICE Air flight attendant&nbsp;<a href="https://www.propublica.org/article/inside-ice-air-deportation-flights%22%20%5Ct%20%22_blank">told</a>&nbsp;<i>ProPublica&nbsp;</i>this spring, a disaster on one of the flights is likely “only a matter of time.”</p>
<p>The charter airlines to whom ICE&nbsp;pays <a href="https://www.levernews.com/inside-the-billion-dollar-business-of-deportation-flights/">enormous sums</a>&nbsp;for deportation flights are the&nbsp;<a href="https://www.nytimes.com/athletic/6416337/2025/06/12/ice-ncaa-globalx-deportation/%22%20%5Ct%20%22_blank">same airlines</a>, like Avelo Airlines and GlobalX Air, that&nbsp;<a href="https://www.nytimes.com/2025/05/12/business/trump-deportation-flights-avelo-airlines.html%22%20%5Ct%20%22_blank">transport</a>&nbsp;professional sports teams around the country. Until recently, these airlines’ fleets could be tracked on public websites like FlightAware and Flightradar24, the same sites that track whether your flight on a commercial airline like Delta or United is delayed.</p>
<p>In recent months, according to multiple sources, these obscure charter airlines have for the first time begun requesting that some planes in their fleet be added to the FAA’s Limiting Aircraft Data Displayed list — LADD — a specialized program developed by the private jet lobby decades ago to keep aircraft data off of public aggregator sites like FlightAware.</p>
<p>“We’re seeing these commercial aircraft being added to the LADD list and then subsequently being employed under contract by the government for these deportation flights,” Ian Petchenik, the communications director with flight aggregator website Flightradar24, told&nbsp;<i>The Lever</i>.</p>
<p>Commercial planes have in the past been occasionally added to the LADD list, he said, for “very specific reasons,” like charter planes flown in the course of a presidential campaign. But ICE’s use of the list appears to be unprecedented: “It’s certainly new,” Petchenik said.</p>

                    </section>
                  
                

                <!-- Main Content -->

                
    
      
        
          <section id="ch-1">
            
              <h2>First ElonJet, Now ICE Air</h2>
              
            
            <p>In the 1990s, the FAA began&nbsp;<a href="https://publicintegrity.org/politics/barr-battle-obama-administration-to-make-more-corporate-jet-data-public-despite-flak/%22%20%5Ct%20%22_blank">sharing</a> real-time air traffic data&nbsp;with airlines, hoping to improve operations across the industry. Other commercial vendors were eventually allowed access to this data, some of which — including the website FlightAware, which launched in 2005 — began publishing real-time flight data for both commercial and private aircraft, both for the public and for industry use.</p>
<p>The new transparency drew opposition from the&nbsp;<a href="https://download.aopa.org/Media/General-Aviation-Explained-r5.pdf%22%20%5Ct%20%22_blank">$250 billion</a>&nbsp;private aviation industry, which argued that publishing the flight data of billionaires’ and celebrities’ jets posed “security” risks.</p>
<p>In&nbsp;<a href="https://www.ainonline.com/aviation-news/business-aviation/2011-07-31/lawmakers-decry-barr-restrictions%22%20%5Ct%20%22_blank">collaboration</a> with Congress, the National Business Aviation Association, a corporate jet lobbying group, in 2000 launched a program that would allow private jet owners to block their aircraft’s identification information from FAA data released to private vendors — cloaking their jets’ movements.</p>
<p>The group “has long believed that security and other imperatives make it absolutely essential to protect our Members’ aircraft and flight information from being made widely available, which is why we created [the program],” a representative&nbsp;<a href="https://nbaa.org/press-releases/nbaa-court-rules-against-long-term-protection-of-flight-data-in-barr-program/%22%20%5Ct%20%22_blank">said</a> in 2010.</p>
<p>For more than a decade, the program was managed by the National Business Aviation Association, which fed the requests to federal aviation regulators. But in 2011, under the Obama administration, federal regulators&nbsp;<a href="https://publicintegrity.org/politics/barr-battle-obama-administration-to-make-more-corporate-jet-data-public-despite-flak/%22%20%5Ct%20%22_blank">signaled</a>&nbsp;that they no longer planned to honor the block requests unless private jet owners submitted evidence of a legitimate “security concern” — essentially gutting the program.</p>
<p>This sent the private jet lobby into a panic. The National Business Aviation Association&nbsp;quickly <a href="https://nbaa.org/membership/letters-to-membership/2011-2/act-now-to-preserve-the-barr-program/%22%20%5Ct%20%22_blank">sued</a>&nbsp;and marshalled hundreds of groups to line up in opposition. The Heritage Foundation, a conservative think tank&nbsp;<a href="https://www.levernews.com/dark-money-just-got-darker-wall-street-helped-fund-project-2025/">bankrolled</a>&nbsp;by right-wing dark money interests, announced that the new rules&nbsp;would “<a href="https://google.com/search?q=heritage+foundation+barr+2011+obama+aircraft&amp;sca_esv=ce44fb6aa5ce43e4&amp;sxsrf=AE3TifMAPKXOUr2LpYB4jCzlmiGIJDi_iw%253A1755873566366&amp;ei=HoGoaJeJFvWs5NoPpNf1kQg&amp;ved=0ahUKEwiXkMbh0p6PAxV1FlkFHaRrPYIQ4dUDCBE&amp;uact=5&amp;oq=heritage+foundation+barr+2011+obama+aircraft&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiLGhlcml0YWdlIGZvdW5kYXRpb24gYmFyciAyMDExIG9iYW1hIGFpcmNyYWZ0MgUQIRigATIFECEYoAEyBRAhGKABSKYHUAFY6AZwAHgAkAEBmAG3AaAB-QiqAQMyLje4AQPIAQD4AQGYAgegArgHwgIFECEYqwKYAwCIBgGSBwMxLjagB7gqsgcDMS42uAe4B8IHATfIBwU&amp;sclient=gws-wiz-serp%22%20%5Ct%20%22_blank">destroy</a>”&nbsp;the privacy of corporate jet fliers. Under industry pressure, the FAA&nbsp;<a href="https://www.regulations.gov/document/FAA-2013-0259-0072%22%20%5Ct%20%22_blank">backtracked</a>&nbsp;just months after the 2011 announcement, allowing the Block Aircraft Registration Request program to continue. But now it would be managed directly by federal regulators, not by trade groups. In 2019, the program’s name was changed to LADD.</p>
<p>There&nbsp;are <a href="https://laddlist.com/stats/%22%20%5Ct%20%22_blank">tens of thousands</a>&nbsp;of private planes currently on the blacklist, according to a tracker maintained by Jack Sweeney, the online researcher who has become famous for tracking private jets owned by — among others — Taylor Swift and&nbsp;<a href="https://www.levernews.com/tag/elon-musk/">Elon Musk</a>.</p>
<p>Both the pop singer and the billionaire were incensed by Sweeney’s live trackers, which post real-time flight data on social media about the comings and goings of the private planes. In December 2023, Swift’s lawyers&nbsp;<a href="https://www.cbsnews.com/news/taylor-swift-private-jet-jack-sweeney-responds-cease-and-desist-lawyers-letter/%22%20%5Ct%20%22_blank">sent</a> Sweeney&nbsp;a cease-and-desist letter. Musk&nbsp;<a href="https://www.nytimes.com/2022/12/14/technology/twitter-private-jet-accounts-suspended.html%22%20%5Ct%20%22_blank">for a time</a>&nbsp;banned Sweeney from Twitter over “ElonJet,” the account that tracked Musk’s jet location. But Sweeney has refused to take down the trackers.</p>
<p>Musk’s and Swift’s private jets are both on the LADD list, which means people can’t find them on sites that rely on the FAA for flight-tracking data, like FlightAware. Sweeney, however, uses entirely crowd-sourced flight data,&nbsp;<a href="https://arstechnica.com/tech-policy/2023/01/the-flight-tracker-that-powered-elonjet-has-taken-a-left-turn/%22%20%5Ct%20%22_blank">collected</a> by volunteers&nbsp;around the world who use their own DIY receivers to pick up live data from planes overhead — allowing him to bypass the LADD list’s restrictions.</p>
<p>Just like Musk’s private jet, the positions of ICE’s deportation flights will remain available even if they are flown on blacklisted planes, thanks to the enthusiasts who feed this information, called ADS-B data, into open-source exchanges. The workaround has infuriated Musk, who has&nbsp;<a href="https://www.wired.com/story/ads-b-exchange-jetnet-sale/%22%20%5Ct%20%22_blank">advocated against</a>&nbsp;flight-data crowdsourcing.</p>
<p>Sweeney was surprised by the recent additions of private charter airline planes used in deportation flights to the LADD list. Earlier this month, he&nbsp;<a href="https://x.com/Jxck_Sweeney/status/1953550777072390194%22%20%5Ct%20%22_blank">highlighted</a>&nbsp;two aircraft owned by Avelo Airlines that had been quietly added to the program.</p>
<p>“I was like, ‘Why are these Avelo planes on the list?’” he told&nbsp;<i>The Lever</i>. “Those are commercial airliners. I hadn’t really seen that.”</p>
<p>According to a review by&nbsp;<i>The Lever</i>, two Avelo Airlines planes and seven GlobalX planes are currently on the LADD list, per data on the charter airlines’ fleets&nbsp;<a href="https://www.airfleets.net/flottecie/Avelo%2520Airlines-active-b737ng.htm%22%20%5Ct%20%22_blank">maintained</a> by Airfleets&nbsp;and Sweeney’s public&nbsp;LADD list <a href="https://laddlist.com/table/%22%20%5Ct%20%22_blank">reproduction</a>.</p>
<p>At the behest of the private jet lobby, the FAA has recently moved to roll back other transparency requirements for private jets. Last year, in the months after Musk launched a crusade against Sweeney over the&nbsp;still up-and-running <a href="https://bsky.app/profile/did:plc:62cuohm6c6nefpnw4uujepty%22%20%5Ct%20%22_blank">ElonJet</a>, lawmakers inserted a provision into must-pass aviation policy legislation that established a new program to allow private jet owners to obscure their planes’ ownership information, information that was once publicly available. The FAA began to&nbsp;<a href="https://www.faa.gov/newsroom/faa-moves-protect-aircraft-owners-private-information%22%20%5Ct%20%22_blank">roll out</a>&nbsp;that program in March.</p>
<p>The move followed expansions of the LADD list, as well as the&nbsp;<a href="https://nbaa.org/aircraft-operations/security/privacy/privacy-icao-address-pia/%22%20%5Ct%20%22_blank">launch</a> of a new program&nbsp;to make it more difficult for planes to be tracked using ADS-B data.</p>

          </section>
        
      
    
  

              </div></div>]]></description>
        </item>
    </channel>
</rss>