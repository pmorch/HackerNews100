<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 19 Aug 2024 03:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Markov chains are funnier than LLMs (102 pts)]]></title>
            <link>https://emnudge.dev/blog/markov-chains-are-funny/</link>
            <guid>41286203</guid>
            <pubDate>Sun, 18 Aug 2024 22:52:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://emnudge.dev/blog/markov-chains-are-funny/">https://emnudge.dev/blog/markov-chains-are-funny/</a>, See on <a href="https://news.ycombinator.com/item?id=41286203">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-astro-cid-w6n32adp=""> <details><summary>Table Of Contents</summary><ol><li><a href="#what-is-a-markov-chain">What is a Markov chain</a></li><li><a href="#what-is-funny">What is funny</a></li><li><a href="#the-predictability-of-llms">The predictability of LLMs</a></li><li><a href="#why-this-is-interesting">Why this is interesting</a></li></ol></details><p>Before explaining any of these terms, let’s try to establish this anecdotally.</p>
<blockquote>
<p>12:2 And I will make all my goodness pass before thee, and our sins be upon us, because of our use of not and lisp-value.</p>
</blockquote>
<p>And</p>
<blockquote>
<p>In the beginning was the lambda expression, and the lambda expression was with Scheme, and the lambda expression was Scheme.</p>
</blockquote>
<p>One of these is the result of a Markov chain trained on the dataset of the King James Bible and a Computer Science textbook. The other is ChatGPT 3.5 given instructions to form a similar output.</p>
<p>These 2 examples are somewhat cherry-picked, but each was given a fair fight. I tried to choose the best candidate from both sides. Can you tell which one was which?</p>
<p>You have a good chance of guessing correctly. The sentence with funky semantics is the Markov chain. It almost makes sense, but makes a right turn into gibberish before you reach the end of the sentence.</p>
<p>The second sentence is Chat GPT.</p>
<p>My goal in this article is to convince you that humor is measurable and that Markov chains are funny. To do this, I will need to define both Markov chains and humor itself. Let’s start with the easier one.</p>
<h2 id="what-is-a-markov-chain">What is a Markov chain</h2>
<p>When LLMs first came on the scene, people would describe them as a very smart Markov chain. These days, people are more familiar with LLMs than Markov chains, so I’ll describe a Markov chain as a very dumb LLM.</p>
<p>If it wasn’t clear earlier, ChatGPT is a kind of LLM - a Large Language Model. We have LLMs that are very large (greater than 300GB) and ones that are much smaller (less than 10GB), but you wouldn’t call them a “small language model” - they’re just a small LLM.</p>
<p>You could call Markov chains a very very small, very simple, very naive LLM.</p>
<p>Like an LLM, it predicts the next word based off the current context. However, it doesn’t take into account semantics, dimensionality, and a whole bunch of other specialized vector math. It’s a really primitive statistical model.</p>
<p>Have you ever used those “next word suggestions” on the top of your phone’s keyboard? That’s generally built using a Markov chain. It’s cheap to run and can be easily updated with suggestions more common to your own texting style.</p>
<p>I could go into depth talking about how both LLMs and Markov chains work, but I only need you to know this - Markov chains are worse at doing the work that LLMs are used for. If you ask it to generate a sentence with a certain goal in mind, an LLM will often outperform the Markov chain.</p>
<p>But accuracy is not what makes something funny.</p>
<h2 id="what-is-funny">What is funny</h2>
<p>This is a weird obsession of mine. I’ve wrote at length about it several times, so just to summarize - humor is about unserious surprise.</p>
<p>The best jokes involve a pleasant and significant “snap”. I use “snap” instead of “punchline” to avoid the semantic baggage. A snap is the whiplash received from the surprise. The less surprise, the less funny.</p>
<p>This is why jokes you’ve heard many times become less funny. It’s why “random” humor feels humorless - although the exact words are unpredictable, the expectation of unpredictability is predictable. If you truly expect the unexpected, you probably won’t laugh.</p>
<p>You can strengthen the snap by reusing common patterns with predictable endings and violating the user’s expectation. As an example, the word coupling “banana, apple, orange, vehicular manslaughter” sets up a pattern of single-word fruit and violates the expectation with a crime.</p>
<p>Joke writing is mostly about violating a pattern.</p>
<p>The snap is also made stronger via the “realization of scene”. If you use more original or descriptive language, you can make the scene appear more real. Instead of “he was shot”, you might say “he was pierced by a 35mm”. Instead of “he fell”, perhaps “his face met the ground”.</p>
<p>You also might want to try starting from the middle of a scene. Imagining what happened before will also help with realization. For example “a urinal cake? I’m not falling for that one again” implies a scene we have to imagine, increasing its realization.</p>
<p>You’ll notice many parallels between good <em>joke</em> writing and good writing in general. Both sorts of authors have similar goals. Using cliche is just wasting words because you leave your scenes <em>unrealized</em>.</p>
<p>We call humor subjective because what qualifies as “unserious surprise” is not universal. Crass humor might not be funny because it is not unserious; it’s blasphemy! Or, it might not be funny because it’s not a surprise; it’s expected.</p>
<p>Anti-jokes are only funny if the joke structure itself is predictable. Absurdism has to be bought into. You can violate cultural norms, but the violation must be well understood unserious.</p>
<p>As a monolingual American, I still managed to make (successful) jokes in a very non-english environment by using the word “no” in ways that were culturally unexpected. I refused certain gifts in an unserious way.</p>
<p>Jokes are varied and humor is subject. Yet, at the end of the day, it is unserious surprise.</p>
<h2 id="the-predictability-of-llms">The predictability of LLMs</h2>
<p>To predict a sentence successfully, you need a lot of context. Large language models have a lot of context. They do tons of fancy math and find the most probable next token. A “better” LLM will necessarily be more predictable if its corpus is sensible speech.</p>
<p>This makes LLMs a really poor choice for creative writing. Without a ton of “prompt engineering”, it’s actually quite easy to spot if some paragraph was LLM generated. It sounds soulless. It’s the most average thing you could have possibly produced given the context.</p>
<p>Asking an LLM for an “original thought” is almost oxymoronic, if not just moronic. It was built with the express purpose of not doing that.</p>
<p>To generate a joke, an LLM would have to be surprising. It would need to take a common turn of phrase and shift its meaning in an unusual way. Good LLMs don’t do this.</p>
<p>I’ve heard people claim that comedy cannot be generated by an algorithm. If it wasn’t obvious, I disagree with this. I think comedy can be analyzed and measured. I think, given a large enough grant, we could probably generate comedy on demand. I think it’s doable - not that we should do it.</p>
<p>The LLMs we have today are just the wrong tool for this task.</p>
<p>LLMs were funniest at their earliest stages. Image generation was funniest here as well. Remember those “trail cam” images we got from <em>Dall-e mini</em>? As our systems got better, the humor was lost.</p>
<p>A really good predictability machine is not very helpful in artistic expression. There is still much use, sure, but it’s not the perfect tool for the job. An LLM will often miss interesting concepts that a child can readily offer.</p>
<p>I’m open to the idea that, given this framework, we can probably build a kind of language model which takes this task into account. It would just need to be categorically different than the kinds of LLMs we have today. It would be different enough that we probably wouldn’t call it an LLM.</p>
<h2 id="why-this-is-interesting">Why this is interesting</h2>
<p>This is a weird thing to get passionate about. It’s manifestly true, but I think it speaks to something deeper.</p>
<p>Again, I am not making the spiritual man versus machine argument. It’s simply a flaw you’ll see come up time and time again when interacting with these models, no matter how advanced they seem to be getting. It’s a leaky abstraction, baring its inner architecture when it meant to masquerade as an anthropomorphism.</p>
<p>This is why every message from ChatGPT reads like a high school essay. It has taken the most average kind of output and reproduced it. It has been stripped of personality and toughened with scholastic rigor. It is bland, corporate speak.</p>
<p>It’s easy to spot fake Amazon reviews these days by thinking “would I ever write something like this?“. Would you add an intro and conclusion to your experiences with Oxiclean dish wipes? Would you thank the manufacturers and acknowledge their dedication to customer service?</p>
<p>Our LLM detection models, like an on-screen captcha, must soon start screening for personality.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google took three months to remove scam app that stole over $5M (205 pts)]]></title>
            <link>https://www.theblock.co/post/311707/google-took-three-months-to-remove-scam-app-that-stole-over-5-million-in-crypto-lawsuit</link>
            <guid>41286045</guid>
            <pubDate>Sun, 18 Aug 2024 22:25:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theblock.co/post/311707/google-took-three-months-to-remove-scam-app-that-stole-over-5-million-in-crypto-lawsuit">https://www.theblock.co/post/311707/google-took-three-months-to-remove-scam-app-that-stole-over-5-million-in-crypto-lawsuit</a>, See on <a href="https://news.ycombinator.com/item?id=41286045">Hacker News</a></p>
Couldn't get https://www.theblock.co/post/311707/google-took-three-months-to-remove-scam-app-that-stole-over-5-million-in-crypto-lawsuit: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Mike Magee, founder of the Register, has died (168 pts)]]></title>
            <link>https://fudzilla.com/news/59503-mike-mageek-is-dead</link>
            <guid>41285851</guid>
            <pubDate>Sun, 18 Aug 2024 21:56:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fudzilla.com/news/59503-mike-mageek-is-dead">https://fudzilla.com/news/59503-mike-mageek-is-dead</a>, See on <a href="https://news.ycombinator.com/item?id=41285851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	  	<p><br><strong>Industry gadfly and mate died yesterday</strong></p>
<p>One of the legends of the IT industry, tantric guru, and the inventor of the cynical red-top tech tabloid, Mike Magee, has died at the age of 74.</p>
	  </div><div>
	  	
<p>Magee started his career as a printer before working for VNU Business Publications on PC Dealer and then at their IT news venture, VNU Newswire. This was where I met him; his effective method proved a handful for his editors.</p>
<p>His technique was simple: He would disappear for most of the day and somehow write the lead story. If needed, he could be found in one of Soho’s nearby waterholes. If you were a good editor you learnt not to interfere.</p>
<p>He left the Newswire and co-founded The Register, the UK's first Internet-based IT tabloid, with John Lettice in 1994. Magee focused on computer chip reporting in the newsletter, and Lettice covered software.</p>
<p>"We realised the chip industry was worth about $200bn a year then, and we were down the pub one day and said, ‘Why don't we do a newsletter because we can and this is a big, big market, and nobody else seems to be doing much about&nbsp;<a href="https://web.archive.org/web/20090710051814/http:/www.pressgazette.co.uk/story.asp?sectioncode=1&amp;storycode=34330">it</a>," Magee said.</p>
<p>The Rodgister used the slogan "Biting the Hand That Feeds IT" to reflect its iconoclastic attitude, attracting a following among IT professionals and investors.</p>
<p>In December 2000, Magee suffered a heart attack and died on the operating table only to revive and being told that he would have to do the same operation in ten years (he didn’t). When he returned to work, he stated publicly that he disagreed with the editorial direction of The Register.</p>
<p>He left to found The Inquirer, which reflected the original editorial philosophy. Unlike The Register, which received a lot of investment, The Inquirer received little financing but managed to make a profit. Magee was the only full-time employee. The entire magazine was based on freelance submissions, and staff and advertising were outsourced. Many technology journalists who got their start at the INQ owe something to Mike.</p>
<p>In 2006, Magee met with VNU leaders over their alleged use of a web layout similar to that of The Inquirer. Later that year, Magee sold The Inquirer to VNU. He remained as editor of The Inquirer until February 2008, when he left to pursue other publishing ventures, including TechEye and ChannelEye. He joined Fudzilla as Editor-at-Large in July 2016.</p>
<p>In 2009 the Daily Telegraph placed Magee 35 in its list of Top 50 most influential Britons in technology.</p>
<p>Mike was a poster child for ignoring the doctor’s advice. Despite some severe illness in later life, he continued his life as always.</p>
<p>While most people know about his fame as a tech industry gadfly, fewer are aware of his interest in the esoteric and the occult. This began with his work with Alistair Crowley’s secretary, Kenneth Grant.</p>
<p>In 1971, he started an occult fanzine called Azoth, and in 1973, in conjunction with David Hall and his then girlfriend Janet Bailey, he started a more ambitious six-monthly magazine called SOTHiS.</p>
<p>This brought him into contact with Led Zeppelin guitarist Jimmy Page. Despite his fame, his accountant did not allow Page to have much money, so he approached Magee for a loan to buy an esoteric bookstore. The loan was never repaid. &nbsp;</p>
<p>In 1973, while on holiday, he had a lucid dream about the Indian goddess Kali, which left him keen to learn more about Indian traditions. After various mystical experiences, he became interested in the tantric tradition.</p>
<p>In 1977, he went to India and met with an English tantrik guru called HH Shri Gurudev Mahendranath (1911-1992) who was a guru (some say the last guru) of the Uttarakaula Tantric Order of northern India. Mahendranath gave him the title of a guru and a charter to form a group of students.</p>
<p>Later, this was to become a nucleus for the "Arcane Magical Order of the Knights of Shambhala" (AMOOKOS). This group was highly influential, particularly in bringing Tantrik teachings to the&nbsp;West.&nbsp;In the UK, it had about 500 members.</p>
<p>In 1980, Mahendranath claimed, despite some evidence, that he had never given Magee the right to form AMOOKOS and the group fragmented. Magee went on to do his own thing, concentrating more on&nbsp;<a href="https://web.archive.org/web/20090710051814/http:/www.shivashakti.com/PersonalStatement.htm">Tantra.</a>&nbsp;He has also provided translations for Tantra website&nbsp;<a href="https://web.archive.org/web/20090710051814/http:/www.religiousworlds.com/mandalam/index.html%20">Shiva Shakti Mandalam</a>.</p>
<p>He formed his own publishing company producing translations of Indian tantric texts.</p>
<p>He married Jan Bailey in a civil ceremony at Edgware Registry Office in 1978. Two witnesses were present, one of whom was pulled in from the Street. They had a son, Tamlin, who was an occasion Techeye writer.</p>
<p>Writing a mate’s obit is an arse. Whatever you want to write about, cannot do justice to a bloke who lived life to the full and made a difference to many. &nbsp;You want to write something like “I am sure he is in the heavenly Star and Garter with Dave Evans and others he worked with.” &nbsp;But that would dumb down someone who was incredibly complex and multifaceted. How can you be sad that someone who literally walked through Indian cemeteries to find a death goddess finally found what he was searching for?</p>
<p>Still it is an arse for the rest of the planet.</p>	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parents outraged at Snoo after smart bassinet company charges fee to rock crib (101 pts)]]></title>
            <link>https://www.independent.co.uk/news/world/americas/snoo-bassinet-baby-sleeping-subscription-b2597869.html</link>
            <guid>41285484</guid>
            <pubDate>Sun, 18 Aug 2024 21:02:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/news/world/americas/snoo-bassinet-baby-sleeping-subscription-b2597869.html">https://www.independent.co.uk/news/world/americas/snoo-bassinet-baby-sleeping-subscription-b2597869.html</a>, See on <a href="https://news.ycombinator.com/item?id=41285484">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-newsletter-key="receiveEveningHeadlinesUSNews"><p><img src="https://static.independent.co.uk/static-assets/images/newsletter/evening-headlines/evening-headlines.png" loading="lazy" alt="Evening Headlines"></p><div><p><h3 data-nosnippet="">The latest headlines from our reporters across the US sent straight to your inbox each weekday</h3><h3 data-nosnippet="">Your briefing on the latest headlines from across the US</h3></p></div></div><p>Some <a href="https://www.independent.co.uk/topic/parents">parents</a> are complaining that a <a href="https://www.independent.co.uk/extras/indybest/kids/baby-tech-essentials/snoo-smart-sleeper-baby-cot-bassinet-review-pod-test-uk-a9470376.html">high-tech bassinet</a> company is nickel and dime-ing them through a monthly subscription program. </p><p>The new parents are upset because some of the <a href="https://www.independent.co.uk/life-style/health-and-families/robotic-cot-baby-sleep-parents-debate-viral-video-snoo-a8323836.html">basic functions</a> of the <a href="https://www.independent.co.uk/life-style/mila-kunis-ashton-kutcher-robotic-crib-snoo-smart-sleeper-lazy-a8230411.html">$1,700 Snoo</a> bassinets are locked behind subscription paywalls, the <a rel="nofollow" data-affiliate="true" target="_blank" href="https://clicks.trx-hub.com/xid/esimedia_t58ukgmjkf95_theindependent?q=http%3A%2F%2Fgo.redirectingat.com%2F%3Fid%3D44681X1458326%26url%3Dhttps%253A%252F%252Fwww.nytimes.com%252F2024%252F08%252F16%252Fstyle%252Fsnoo-bassinet-smart-sleeper.html%26sref%3Dhttps%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fworld%2Famericas%2Fsnoo-bassinet-baby-sleeping-subscription-b2597869.html&amp;p=https%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fworld%2Famericas%2Fsnoo-bassinet-baby-sleeping-subscription-b2597869.html&amp;article_id=2597869&amp;author=Graig+Graziosi&amp;tag=New+York+Times%2Cparents&amp;section=World&amp;category=Americas&amp;sub_category=&amp;updated_time=2024-08-17T18%3A09%3A06.000Z&amp;utm_campaign=news-body&amp;utm_term=B-3&amp;utm_content=&amp;utm_medium=&amp;ref=&amp;utm_source=direct&amp;fbclid=&amp;gclid="></a><a href="https://www.independent.co.uk/topic/new-york-times"><em>New York Times</em></a> reports.</p><p>One might ask: "what — beyond being being soft and portable — other functions could a bassinet have?" </p><p>The Snoo, made by the "Happiest Baby" company, is equipped with sensors that detect when the baby is crying and simulates the sounds of the womb to help keep babies — and their parents — sleeping with fewer interruptions. The bassinet also includes a self-rocking and sleep tracking feature, among others. </p><p>Those features all used to be free with the substantial $1,700 purchase, but now some of them are locked behind a $20 per month paywall. If parents use the bassinet for five months, that's an extra $100 fee on top of the hefty purchase price. </p><div><figure><p><img src="https://static.independent.co.uk/2024/08/17/18/newFile-1.jpg" srcset="https://static.independent.co.uk/2024/08/17/18/newFile-1.jpg?quality=75&amp;width=320&amp;auto=webp 320w, https://static.independent.co.uk/2024/08/17/18/newFile-1.jpg?quality=75&amp;width=640&amp;auto=webp 640w" loading="lazy" alt="A child sleeping in a Snoo bassinet. The Snoo bassinet is equipped with sensors to track a baby’s sleep, a self-rocking feature, and requires the infant to be strapped in to help prevent SIDS. Happiest Baby, which makes the Snoo, recently changed its pricing structure, locking some of its basic features behind a $20 per month subscription" on="tap:auto-image-gallery,inline-image-carousel.goToSlide(index=0)" tabindex="0" role="button" data-gallery-length="3"></p><figcaption>A child sleeping in a Snoo bassinet. The Snoo bassinet is equipped with sensors to track a baby’s sleep, a self-rocking feature, and requires the infant to be strapped in to help prevent SIDS. Happiest Baby, which makes the Snoo, recently changed its pricing structure, locking some of its basic features behind a $20 per month subscription<span> <!-- -->(<!-- -->Snoo/Happiest Baby<!-- -->)</span></figcaption></figure></div><p>Since babies grow quickly, a bassinet is only useful to parents for approximately four to five months. At that point, many parents either hand down their newborn gear to friends or relatives with newborns, or post them for sale on online hand-me-down markets. </p><p>With the new pricing scheme in place, the Snoo will be able to continue collecting cash from parents even after its been handed down several times. </p><p>Parents angry with the change has prompted some backlash, with calls for review bombs and instructions for how to complain to the company being shared on social media. </p><p>Happy Baby customers received an email in June alerting them to the change in pricing. Buyers who picked up a Snoo before July 15 were grandfathered into the previous structure, while anyone who bought after that was locked into the subscription model. </p><p>Andrew Gwin, a father who bought the Snoo, told the <em>Times</em> he likened the new pay structure to having to shell out extra to use an iPhone's camera or a car's radio. </p><p>He said he had a great experience using the Snoo with his first child. The family has a second on the way, but said they won't be paying for the subscription. He has gone so far as to file a complaint with the Federal Trade Commission over the app's price. </p><div><figure><p><img src="https://static.independent.co.uk/2024/08/08/09/db2c7451e790996846edf93c7063cb52Y29udGVudHNlYXJjaGFwaSwxNzIzMTg5OTQ2-2.73233002.jpg" srcset="https://static.independent.co.uk/2024/08/08/09/db2c7451e790996846edf93c7063cb52Y29udGVudHNlYXJjaGFwaSwxNzIzMTg5OTQ2-2.73233002.jpg?quality=75&amp;width=320&amp;auto=webp 320w, https://static.independent.co.uk/2024/08/08/09/db2c7451e790996846edf93c7063cb52Y29udGVudHNlYXJjaGFwaSwxNzIzMTg5OTQ2-2.73233002.jpg?quality=75&amp;width=640&amp;auto=webp 640w" loading="lazy" alt="A baby who is wide awake and not sleeping in its Snoo" on="tap:auto-image-gallery,inline-image-carousel.goToSlide(index=2)" tabindex="0" role="button" data-gallery-length="3"></p><figcaption>A baby who is wide awake and not sleeping in its Snoo<span> <!-- -->(<!-- -->PA Archive<!-- -->)</span></figcaption></figure></div><p>“It’s clearly a way to punish those who go to the secondhand market and just add a tax on top of the expenses the parents already face,” he told the <em>Times</em>. </p><p>The company's founder, Harvey Karp, said the pricing change was necessary to "bring in revenue," noting that the company was not underwritten by a university or the government, and must survive on its sales alone. </p><p>He said his ultimate goal would be to see the Snoo paid for by the government or by insurance companies, but it's unclear if there has been any substantive movement toward achieving that end. </p><p>Karp is a former pediatrician, and said he developed the Snoo in order to help prevent SIDS — sudden infant death syndrome. Babies placed in the Snoo have to be strapped in, preventing them from rolling around. That nighttime movement can lead to SIDS, according to the<a rel="nofollow" target="_blank" href="https://www.cdc.gov/sids/data.htm"> US Centers for Disease Control</a>. </p><p>Approximately 3,400 babies die from SIDS every year, the CDC reports. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The brain simulates actions and their consequences during REM sleep (111 pts)]]></title>
            <link>https://www.biorxiv.org/content/10.1101/2024.08.13.607810v1</link>
            <guid>41284873</guid>
            <pubDate>Sun, 18 Aug 2024 19:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biorxiv.org/content/10.1101/2024.08.13.607810v1">https://www.biorxiv.org/content/10.1101/2024.08.13.607810v1</a>, See on <a href="https://news.ycombinator.com/item?id=41284873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" id="page"><div data-node-nid="4023992" id="node-4023992--2138276754" data-pisa="biorxiv;2024.08.13.607810v1" data-pisa-master="biorxiv;2024.08.13.607810" data-apath="/biorxiv/early/2024/08/16/2024.08.13.607810.atom" data-hw-author-tooltip-instance="highwire_author_tooltip">

      <p><span>
        New Results    </span></p>  
      
  
      <p><span><span>doi:</span> https://doi.org/10.1101/2024.08.13.607810 </span></p>
  
  
  </div>

<div data-panels-ajax-tab-preloaded="biorxiv_tab_art" id="panels-ajax-tab-container-highwire_article_tabs"><div xmlns="http://www.w3.org/1999/xhtml" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" xmlns:xhtml="http://www.w3.org/1999/xhtml"><div id="abstract-1"><h2>Abstract</h2><p id="p-2">Vivid dreams mostly occur during a phase of sleep called REM. During REM sleep, the brain's internal representation of direction keeps shifting like that of an awake animal moving through its environment. What causes these shifts, given the immobility of the sleeping animal?  Here we show that the superior colliculus of the mouse, a motor command center involved in orienting movements, issues motor commands during REM sleep, e.g. turn left, that are similar to those issued in the awake behaving animal. Strikingly, these motor commands, despite not being executed, shift the internal representation of direction as if the animal had turned. Thus, during REM sleep, the brain simulates actions by issuing motor commands that, while not executed, have consequences as if they had been. This study suggests that the sleeping brain, while disengaged from the external world, uses its internal model of the world to simulate interactions with it.</p></div><h3>Competing Interest Statement</h3><p id="p-3">The authors have declared no competing interest.</p></div>
<div><p>Copyright&nbsp;</p><div><p>The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.<span> All rights reserved. No reuse allowed without permission.</span></p></div></div>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: PgQueuer – Transform PostgreSQL into a Job Queue (154 pts)]]></title>
            <link>https://github.com/janbjorge/PgQueuer</link>
            <guid>41284703</guid>
            <pubDate>Sun, 18 Aug 2024 19:22:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/janbjorge/PgQueuer">https://github.com/janbjorge/PgQueuer</a>, See on <a href="https://news.ycombinator.com/item?id=41284703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h3 tabindex="-1" dir="auto">Readme</h3><a id="user-content-readme" aria-label="Permalink: Readme" href="#readme"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 PgQueuer - Building Smoother Workflows One Queue at a Time 🚀</h2><a id="user-content--pgqueuer---building-smoother-workflows-one-queue-at-a-time-" aria-label="Permalink: 🚀 PgQueuer - Building Smoother Workflows One Queue at a Time 🚀" href="#-pgqueuer---building-smoother-workflows-one-queue-at-a-time-"></a></p>
<p dir="auto"><a href="https://github.com/janbjorge/PgQueuer/actions/workflows/ci.yml?query=branch%3Amain"><img src="https://github.com/janbjorge/PgQueuer/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://pypi.python.org/pypi/PgQueuer" rel="nofollow"><img src="https://camo.githubusercontent.com/3ed5f661e8b8f69d87ecdc757dc90611c3cb2e779c24471a9cde62d2e72aa0d8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f50675175657565722e737667" alt="pypi" data-canonical-src="https://img.shields.io/pypi/v/PgQueuer.svg"></a>
<a href="https://pepy.tech/project/PgQueuer" rel="nofollow"><img src="https://camo.githubusercontent.com/00e23d45c630c4f1265ffd374d12f511e427973e5614801b1f2362e1a492b89e/68747470733a2f2f7374617469632e706570792e746563682f62616467652f50675175657565722f6d6f6e7468" alt="downloads" data-canonical-src="https://static.pepy.tech/badge/PgQueuer/month"></a>
<a href="https://github.com/janbjorge/PgQueuer"><img src="https://camo.githubusercontent.com/b02d89cd2cbefb23891326d63a1e72e3a7a643ccdd083eff83d0f4d701f42ae3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f50675175657565722e737667" alt="versions" data-canonical-src="https://img.shields.io/pypi/pyversions/PgQueuer.svg"></a></p>
<hr>
<p dir="auto">📚 <strong>Documentation</strong>: <a href="https://pgqueuer.readthedocs.io/en/latest/" rel="nofollow">Explore the Docs 📖</a></p>
<p dir="auto">🔍 <strong>Source Code</strong>: <a href="https://github.com/janbjorge/PgQueuer/">View on GitHub 💾</a></p>
<p dir="auto">💬 <strong>Join the Discussion</strong>: <a href="https://discord.gg/C7YMBzcRMQ" rel="nofollow">Discord Community</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">PgQueuer</h2><a id="user-content-pgqueuer" aria-label="Permalink: PgQueuer" href="#pgqueuer"></a></p>
<p dir="auto">PgQueuer is a minimalist, high-performance job queue library for Python, leveraging the robustness of PostgreSQL. Designed for simplicity and efficiency, PgQueuer uses PostgreSQL's LISTEN/NOTIFY to manage job queues effortlessly.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Simple Integration</strong>: Easy to integrate with existing Python applications using PostgreSQL.</li>
<li><strong>Efficient Concurrency Handling</strong>: Utilizes PostgreSQL's <code>FOR UPDATE SKIP LOCKED</code> for reliable and concurrent job processing.</li>
<li><strong>Real-time Notifications</strong>: Leverages <code>LISTEN</code> and <code>NOTIFY</code> for real-time updates on job status changes.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install PgQueuer, simply install with pip the following command:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Example Usage</h3><a id="user-content-example-usage" aria-label="Permalink: Example Usage" href="#example-usage"></a></p>
<p dir="auto">Here's how you can use PgQueuer in a typical scenario processing incoming data messages:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Write and run a consumer</h4><a id="user-content-write-and-run-a-consumer" aria-label="Permalink: Write and run a consumer" href="#write-and-run-a-consumer"></a></p>
<p dir="auto">Start a long-lived consumer that will begin processing jobs as soon as they are enqueued by another process. In this case we want to be a bit more carefull as we want gracefull shutdowns, <code>PgQueuer run</code> will setup signals to
ensure this.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from __future__ import annotations

import asyncpg
from PgQueuer.db import AsyncpgDriver, dsn
from PgQueuer.models import Job
from PgQueuer.qm import QueueManager


async def main() -> QueueManager:
    connection = await asyncpg.connect(dsn())
    driver = AsyncpgDriver(connection)
    qm = QueueManager(driver)

    # Setup the 'fetch' entrypoint
    @qm.entrypoint(&quot;fetch&quot;)
    async def process_message(job: Job) -> None:
        print(f&quot;Processed message: {job}&quot;)

    return qm"><pre><span>from</span> __future__ <span>import</span> <span>annotations</span>

<span>import</span> <span>asyncpg</span>
<span>from</span> <span>PgQueuer</span>.<span>db</span> <span>import</span> <span>AsyncpgDriver</span>, <span>dsn</span>
<span>from</span> <span>PgQueuer</span>.<span>models</span> <span>import</span> <span>Job</span>
<span>from</span> <span>PgQueuer</span>.<span>qm</span> <span>import</span> <span>QueueManager</span>


<span>async</span> <span>def</span> <span>main</span>() <span>-&gt;</span> <span>QueueManager</span>:
    <span>connection</span> <span>=</span> <span>await</span> <span>asyncpg</span>.<span>connect</span>(<span>dsn</span>())
    <span>driver</span> <span>=</span> <span>AsyncpgDriver</span>(<span>connection</span>)
    <span>qm</span> <span>=</span> <span>QueueManager</span>(<span>driver</span>)

    <span># Setup the 'fetch' entrypoint</span>
    <span>@<span>qm</span>.<span>entrypoint</span>(<span>"fetch"</span>)</span>
    <span>async</span> <span>def</span> <span>process_message</span>(<span>job</span>: <span>Job</span>) <span>-&gt;</span> <span>None</span>:
        <span>print</span>(<span>f"Processed message: <span><span>{</span><span>job</span><span>}</span></span>"</span>)

    <span>return</span> <span>qm</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m PgQueuer run tools.consumer.main"><pre>python3 -m PgQueuer run tools.consumer.main</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Write and run a producer</h4><a id="user-content-write-and-run-a-producer" aria-label="Permalink: Write and run a producer" href="#write-and-run-a-producer"></a></p>
<p dir="auto">Start a short-lived producer that will enqueue 10,000 jobs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from __future__ import annotations

import asyncio
import sys

import asyncpg
from PgQueuer.db import AsyncpgDriver
from PgQueuer.queries import Queries


async def main(N: int) -> None:
    connection = await asyncpg.connect()
    driver = AsyncpgDriver(connection)
    queries = Queries(driver)
    await queries.enqueue(
        [&quot;fetch&quot;] * N,
        [f&quot;this is from me: {n}&quot;.encode() for n in range(1, N+1)],
        [0] * N,
    )


if __name__ == &quot;__main__&quot;:
    print(sys.argv)
    N = 1_000 if len(sys.argv) == 1 else int(sys.argv[1])
    asyncio.run(main(N))"><pre><span>from</span> __future__ <span>import</span> <span>annotations</span>

<span>import</span> <span>asyncio</span>
<span>import</span> <span>sys</span>

<span>import</span> <span>asyncpg</span>
<span>from</span> <span>PgQueuer</span>.<span>db</span> <span>import</span> <span>AsyncpgDriver</span>
<span>from</span> <span>PgQueuer</span>.<span>queries</span> <span>import</span> <span>Queries</span>


<span>async</span> <span>def</span> <span>main</span>(<span>N</span>: <span>int</span>) <span>-&gt;</span> <span>None</span>:
    <span>connection</span> <span>=</span> <span>await</span> <span>asyncpg</span>.<span>connect</span>()
    <span>driver</span> <span>=</span> <span>AsyncpgDriver</span>(<span>connection</span>)
    <span>queries</span> <span>=</span> <span>Queries</span>(<span>driver</span>)
    <span>await</span> <span>queries</span>.<span>enqueue</span>(
        [<span>"fetch"</span>] <span>*</span> <span>N</span>,
        [<span>f"this is from me: <span><span>{</span><span>n</span><span>}</span></span>"</span>.<span>encode</span>() <span>for</span> <span>n</span> <span>in</span> <span>range</span>(<span>1</span>, <span>N</span><span>+</span><span>1</span>)],
        [<span>0</span>] <span>*</span> <span>N</span>,
    )


<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>print</span>(<span>sys</span>.<span>argv</span>)
    <span>N</span> <span>=</span> <span>1_000</span> <span>if</span> <span>len</span>(<span>sys</span>.<span>argv</span>) <span>==</span> <span>1</span> <span>else</span> <span>int</span>(<span>sys</span>.<span>argv</span>[<span>1</span>])
    <span>asyncio</span>.<span>run</span>(<span>main</span>(<span>N</span>))</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="python3 tools/producer.py 10000"><pre>python3 tools/producer.py 10000</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple might be implementing a VPN censorship order in Brazil (106 pts)]]></title>
            <link>https://status.proton.me/incidents/0frlp8crn7kx</link>
            <guid>41284549</guid>
            <pubDate>Sun, 18 Aug 2024 19:04:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://status.proton.me/incidents/0frlp8crn7kx">https://status.proton.me/incidents/0frlp8crn7kx</a>, See on <a href="https://news.ycombinator.com/item?id=41284549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><span>PT <p>Recebemos vários relatos hoje de usuários no Brasil com dificuldades para instalar o aplicativo Proton VPN em dispositivos iOS via a Apple App Store. Podemos confirmar que o problema não está do nosso lado, mas provavelmente na própria App Store, que é controlada pela Apple. O que torna essa coincidência extremamente estranha é que também está impactando vários outros VPNs na loja de aplicativos brasileira.</p><p>Muito provavelmente, algo aconteceu do lado da Apple, e não sabemos se é acidental ou se a Apple está implementando secretamente uma ordem de censura. Mas, devido ao monopólio da Apple na distribuição de aplicativos iOS, não há outra maneira de obter o aplicativo em dispositivos iOS.</p><p>Como solução alternativa para usuários de iOS, sugerimos tentar a versão beta do iOS via Testflight (<a target="_blank" href="https://protonvpn.com/blog/vpn-ios-beta/">https://protonvpn.com/blog/vpn-ios-beta/</a>), ou alternativamente, uma configuração manual do WireGuard pode ser usada (<a target="_blank" href="https://protonvpn.com/support/wireguard-manual-ios">https://protonvpn.com/support/wireguard-manual-ios</a>) para acessar nossos servidores VPN.</p><p>Observe que os aplicativos Proton VPN ainda estão disponíveis em todas as outras plataformas no Brasil (<a target="_blank" href="https://protonvpn.com/download">https://protonvpn.com/download</a>) e outros aplicativos Proton, como Proton Mail, Proton Drive e Proton Pass, permanecem inalterados neste momento.</p><p>EN </p><p>We have received multiple reports today from users in Brazil having difficulties installing the Proton VPN app on iOS devices via the Apple App Store. We can confirm that the issue is not on our side, but likely with the App Store itself, which is controlled by Apple. What makes this an extremely strange coincidence is that it is also impacting multiple other VPNs in the Brazilian app store.</p><p>Most likely, something has happened on the Apple side, and we do not know if it is accidental, or if Apple is secretly implementing a censorship order. But because of Apple's monopoly on iOS app distribution, there is no other way to get the app on iOS devices.</p><p>As a workaround for iOS users, we suggest trying the iOS beta version via Testflight ( <a target="_blank" href="https://protonvpn.com/blog/vpn-ios-beta/">https://protonvpn.com/blog/vpn-ios-beta/</a> ), or alternatively, a manual WireGuard setup can be used ( <a target="_blank" href="https://protonvpn.com/support/wireguard-manual-ios">https://protonvpn.com/support/wireguard-manual-ios</a> ) to access our VPN servers.</p><p>Note that Proton VPN apps are still available through all other platforms in Brazil (<a target="_blank" href="https://protonvpn.com/download">https://protonvpn.com/download</a>) and other Proton Apps such as Proton Mail, Proton Drive and Proton Pass remain unaffected at this time.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1723988758000"></span>Aug <var data-var="date">18</var>, <var data-var="year">2024</var> - <var data-var="time">15:45</var> CEST
            </p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Algorithms we develop software by (167 pts)]]></title>
            <link>https://grantslatton.com/software-pathfinding</link>
            <guid>41284409</guid>
            <pubDate>Sun, 18 Aug 2024 18:47:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grantslatton.com/software-pathfinding">https://grantslatton.com/software-pathfinding</a>, See on <a href="https://news.ycombinator.com/item?id=41284409">Hacker News</a></p>
<div id="readability-page-1" class="page"><header>
        <nav>
            <a href="https://grantslatton.com/">Home</a>
        </nav>
    </header>
    
        
<p>I recently had a conversation with a distinguished tech CEO and engineer. I loved hearing his description of a software development methodology he's occasionally used, and it got me thinking about other heuristics and generalizations.</p>
<h2 id="his-method"><a href="#his-method">His method</a></h2>
<p>Start working on the feature at the beginning of the day. If you don't finish by the end of the day, delete it all and start over the next day. You're allowed to keep unit tests you wrote.</p>
<p>If, after a few days, you can't actually implement the feature, think of what groundwork, infrastructure, or refactoring would need to be done to enable it. Use this method to implement <em>that</em>, then come back to the feature.</p>
<p>He said he didn't invent this, but it was something adjacent to the <a href="https://en.wikipedia.org/wiki/Extreme_programming">Extreme Programming</a> movement of the late 90s and early 00s.</p>
<h2 id="some-thoughts-on-the-method"><a href="#some-thoughts-on-the-method">Some thoughts on the method</a></h2>
<h3 id="write-everything-twice"><a href="#write-everything-twice">"Write everything twice"</a></h3>
<p>A piece of advice I've given junior engineers is to write everything twice. Solve the problem. Stash your code onto a branch. Then write all the code again.</p>
<p>I discovered this method by accident after the laptop containing a few days of work died. Rewriting the solution only took 25% the time as the initial implementation, and the result was <em>much better</em>.</p>
<p>So you get maybe 2x higher quality code for 1.25x the time — this trade is usually a good one to make on projects you'll have to maintain for a long time.</p>
<p>N.B. Obviously, don't write <em>literally everything</em> twice. It's a heuristic. Apply intelligently.</p>
<p>The "start over each day" method is an even more extreme version of this. Every time you rewrite, you carve a smoother path to the solution. The final solution can be really, really clean.</p>
<h3 id="quantity-has-a-quality-all-of-its-own"><a href="#quantity-has-a-quality-all-of-its-own">"Quantity has a quality all of its own"</a></h3>
<p>Almost certainly apocryphal Stalin quote is applicable to becoming a good software engineer. As a junior engineer, there's simply no substitute for getting the first 100K lines of code under your belt. The "start over each day" method will help get you to those 100K lines faster.</p>
<p>You might think covering the same ground multiple times isn't as valuable as getting 100K diverse lines of code. I disagree. Solving the same problem repeatedly is actually really beneficial for <em>retaining</em> knowledge of patterns you figure out.</p>
<p>You only need 5K perfect lines to see all the major patterns once. The other 95K lines are repetition to rewire your neurons.</p>
<h3 id="comparison-to-the-gun-to-the-head-heuristic"><a href="#comparison-to-the-gun-to-the-head-heuristic">Comparison to the "gun to the head" heuristic</a></h3>
<p>Another heuristic I've used is to ask someone to come up with a solution to a problem. Maybe they say it'll take 4 weeks to implement. Then I say "gun to your head, you have to finish in 24 hours, what do you do?"</p>
<p>The purpose here is to break their frame and their anchoring bias. If you've just said something will take a month, doing it in a day must require a radically different solution.</p>
<p>The surprising thing about this technique is <em>how often it works</em>. How often someone — minutes after presenting their month-long plan — can be induced to figure out a plan that could potentially be done in a day.</p>
<p>In practice, none of the day-long plans are actually a day. The gun isn't actually to your head. You can go home and sleep. But the new solution can often actually be done in just a few days. A ten-minute thought experiment becomes a 10x time saving.</p>
<p>The purpose of the thought experiment isn't to generate the <em>real</em> solution. It's meant to put a lower bound on the solution. Then you think of a <em>real</em> solution with that lower bound in eyesight, and you'll find it's often better than your original solution.</p>
<h2 id="pathfinding"><a href="#pathfinding">Pathfinding</a></h2>
<p>The core of the matter here is pathfinding in problem space. Each path is a solution, and it's the engineer's job to find the best one.</p>
<p>There are a lot of kind of sketchy analogies to be drawn between these heuristics and different pathfinding algorithms. There's some relation to <a href="https://en.wikipedia.org/wiki/Iterative_deepening_A%2A">iterative deepening</a>, <a href="https://en.wikipedia.org/wiki/A*_search_algorithm#Bounded_relaxation">bounded relaxation A*</a>, <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a>, <a href="https://en.wikipedia.org/wiki/Simulated_annealing">simulated annealing</a>, and others.</p>
<p>I don't think there's <em>too</em> much to be learned by trying to concretize that analogy, but it's valuable to think about it conceptually. All the different search algorithms have different pros and cons, depending on your constraints and knowledge of the domain.</p>
<p>So to with the engineering heuristics. Becoming a better engineer is becoming a better pathfinder in problem space.</p>
<p>There's probably a compelling general theory to be concocted in this space, but that's beyond the scope of this post. Spin up a background thread in your brain and think about it. Maybe you'll find a good path to an answer.</p>

    
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Micro-libraries should never be used (126 pts)]]></title>
            <link>https://bvisness.me/microlibraries/</link>
            <guid>41284335</guid>
            <pubDate>Sun, 18 Aug 2024 18:38:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bvisness.me/microlibraries/">https://bvisness.me/microlibraries/</a>, See on <a href="https://news.ycombinator.com/item?id=41284335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        
    <article>
      <header>
        
        
        <p><time datetime="2024-08-18T12:00:00+0000" itemprop="datePublished">August 18, 2024</time>
        </p>
    
      </header>
      
  <p>
    It is the year 2024. It has been eight years since <code>left-pad</code> first made people realize that, hey, maybe it’s not a great idea to outsource trivial functionality to random people on the internet.
  </p>
  <p>
    But in the year 2024, I still see some people arguing that actually, micro-libraries are good, and we should do more of them. We should make packages smaller and use even more dependencies. The problem with npm is really that we just haven’t made the packages small enough yet.
  </p>
  <p>
    This is so unbelievably wrong that it should not even be up for debate. But because there is a debate regardless, someone needs to exhaustively and painfully explain why bad practices are bad.
  </p>
  <p>
    Here is my thesis: <strong>Micro-libraries should never be used. They should either be copy-pasted into your codebase, or not used at all.</strong>
  </p>
  <p>
    However, my actual goal with this article is to break down the way I think about the costs and benefits of dependencies. I won’t be <em>quantifying</em> these costs and benefits, but I hope that by explaining the way I think about dependencies, it will be clear why I think micro-libraries are all downside and no upside.
  </p>

  <h2 id="costs-and-benefits">Costs and benefits</h2>
  <p>
    Everyone knows that programming is all about <a href="https://bvisness.me/tradeoffs/">tradeoffs</a>. You gotta use the right tool for the job, you know?
  </p>
  <p>
    Well, you can’t make a reasonable tradeoff unless you can actually articulate the costs and benefits. So let’s examine the pros and cons of libraries in general, starting with the benefits:
  </p>
  <ul>
    <li>
      <strong>It saves development time.</strong> This is the most obvious benefit of a library, especially if the problem it solves is complicated.
    </li>
    <li>
      <strong>The code is (hopefully) more robust.</strong> Library authors have presumably thought a lot about the problem, and if their implementation is mature, it might handle more edge cases and subtle pitfalls. Their implementation may also be more “future-proof”, anticipating future use cases. This property is strongest when the library has lots of users—it may not be <em>good</em>, but it is less likely to be <em>wrong</em>.
    </li>
    <li>
      <strong>You can upgrade to get features, bug fixes, or security updates.</strong> This extends the first point: not only do other people write the code for you, but other people <em>maintain</em> it for you. In the best case, an upgrade can simply make your life better without breaking compatibility.
    </li>
  </ul>
  <p>
    That’s about it for benefits. Unfortunately, there are also many costs associated with dependencies—more than most people account for:
  </p>
  <ul>
    <li>
      <p>
        <strong>The library may be a bad fit for your problem.</strong> This often cancels out the primary benefit of libraries. No, you don’t have to write the code, but you <em>do</em> have to adapt your problem to fit the library, and adapt the library’s results to fit your app again. This cost can be very extreme!
      </p>
      <p>
        For example, at my last job, we tried using Amazon’s Simple Notification Service to send push notifications to both iOS and Android devices. In theory, we could have saved time by targeting just one API instead of two. But after juggling AWS auth and device registration and SQS queues and SNS topics and API incompatibilities, it turned out to be much easier to just target the Apple and Google push APIs directly.
      </p>
    </li>
    <li>
      <p>
        <strong>The library may be poorly written.</strong> Programmers typically assume that library code is higher-quality than their code. This is often just not true. Any random person can publish an npm package, and many npm packages are just bad. This is even true of very popular packages; the correlation between popularity and quality is extremely weak.
      </p>
      <p>
        Using libraries also often results in performance penalties, even when “well-written”. Libraries are for everyone, therefore they are optimized for no one.
      </p>
    </li>
    <li>
      <strong>Third-party code is inherently risky.</strong> The library may have critical bugs, or the author may be overtly malicious. It is very hard to properly audit everything, and the more complex the library, the more opportunities there are for mistakes or attacks. On the other hand, if you write the code yourself, you know there’s nothing malicious about it, and you have an opportunity to vet it for bugs.
    </li>
    <li>
      <strong>Every dependency is a supply chain attack vector.</strong> Any package, from the biggest framework to the tiniest utility, could be compromised, and would have equal access to sensitive resources. The more packages you have, and the more maintainers there are, the more opportunities there are to get pwned.
    </li>
    <li>
      <p>
        <strong>The library may have a large footprint.</strong> Libraries are often just way bigger than you need. This bloat can come from multiple sources: features you never use, metadata in <code>node_modules</code>, duplicate versions of the same package, and of course piles and piles of transitive dependencies. Furthermore, this footprint is highly variable—a routine update can invisibly quadruple the footprint of a package.
      </p>
      <p>
        This footprint negatively affects all stages of the process: increased install times, increased build times, larger bundle sizes for users. This problem is so prevalent in the JavaScript ecosystem that many common packages have a total footprint in the hundreds of megabytes, a truly shocking amount of waste. The issue has gotten so bad that there is now an initiative called <a href="https://e18e.dev/">e18e</a> that is attempting to clean things up.
      </p>
    </li>
    <li>
      <strong>Updates are not free.</strong> In theory, updating a package should be fine as long as the version is compatible. But in practice, updating causes all kinds of problems: breaking changes, deprecated functions (and associated rewrites), performance regressions, bundle size bloat, new bugs. This cost is unpredictable; you never really know what might have changed upstream.
    </li>
    <li>
      <strong>Libraries may have lots of transitive dependencies.</strong> Transitive dependencies are also dependencies. Everything in your <code>package_lock.json</code> is a real dependency with real costs that you cannot ignore. Transitive dependencies increase the risk of bad code, increase the risk of security issues, and of course increase the footprint of your application.
    </li>
  </ul>
  <p>
    This is how I look at dependencies—and clearly, in my view, there are many more costs than benefits. The benefits can be very strong, but you cannot make a wise decision without considering the costs as well. Beginners in particular tend to ignore the costs—but their libraries will betray them eventually.
  </p>

  <h2 id="is-number-a-case-study"><code>is-number</code>: a case study</h2>
  <p>
    Let’s examine a popular micro-library, <a href="https://www.npmjs.com/package/is-number"><code>is-number</code></a>. This is an npm package with just a single function, <code>isNumber</code>. It takes a value and tells you if it’s a finite number, or a finite non-empty numeric string. This spectacularly useful function exemplifies all the problems with micro-libraries in the JS ecosystem.
  </p>
  <p>
    Let’s examine the benefits of this package:
  </p>
  <ul>
    <li>
      You can write <code>isNumber(foo)</code> instead of <code>typeof foo === "number"</code>.
    </li>
  </ul>
  <p>
    That’s quite a list.
  </p>
  <p>
    But seriously, test it against our possible benefits from earlier:
  </p>
  <ul>
    <li>
      <strong>Does it save development time? Barely.</strong> Assuming you do, for some reason, need to check if a value is a finite number or a finite non-empty numeric string, this library may save you a few minutes. But in practice this function is almost entirely useless, as we’ll see below.
    </li>
    <li>
      <strong>Is it more robust than what you could write? No.</strong> The code is extremely straightforward and easy to verify.
    </li>
    <li>
      <strong>Would future updates be useful? No.</strong> The library is so simple that any change to the logic would be breaking, and it is already clear that there are no bugs.
    </li>
  </ul>
  <p>
    And now we get to the costs:
  </p>
  <ul>
    <li>
      <strong>Is it a good fit for your problem? Almost certainly not.</strong> 99% of the time, all you need is <code>typeof foo === "number"</code>. 0.9% of the time, all you need is <code>foo == Number(foo)</code> (which will include numeric strings and exclude <code>NaN</code>). At most 0.1% of the time do you <em>also</em> need to exclude empty strings and <code>Infinity</code>. These are trivial to write and should be familiar to any JavaScript programmer. Therefore, <code>is-number</code> is almost always just bloat, performing unnecessary checks out of paranoia and likely breaking some optimizations that the JS engine could otherwise make.
    </li>
    <li>
      <p>
        <strong>Are updates breaking? Yes.</strong> Incredibly, <code>is-number</code> is already on major version 7.0.0. This is an amazing number of breaking changes for such a simple function.
      </p>
      <p>
        Why all these new versions? Many reasons, none of them good. Sometimes the author arbitrarily changes his mind about what’s a “number”—for example, <code>NaN</code> used to be considered a number; now it’s not. One breaking change simply upgraded the minimum supported Node version from 0.10.0 to 0.12.0 and changed <em>nothing else</em>. And sometimes he just calls it a breaking change because he feels like it.
      </p>
    </li>
    <li>
      <strong>Is it bloated? Kinda.</strong> Although the actual code is a mere 245 bytes, the size when installed is 9.62 kB. That is, the footprint on your computer is 39x larger than necessary, due to metadata like the README, LICENSE, and package.json. Thankfully this shouldn’t affect build times or bundle sizes, but this amazing level of waste adds up across the thousands of packages installed in people’s <code>node_modules</code>. Furthermore, because the author releases so many major versions, it’s common to find multiple copies of the library in your <code>node_modules</code> for no good reason.
    </li>
    <li>
      <strong>Is it risky? Yes.</strong> It’s a supply chain attack opportunity like any other, and because it updates fairly frequently, updates are less likely to trigger scrutiny.
    </li>
  </ul>
  <p>
    So, by my count, we have <strong>zero upsides</strong> and <strong>several downsides</strong>. So much for that tradeoff.
  </p>

  <h2 id="copy-paste-a-case-study">Copy-paste: a case study</h2>
  <p>
    Suppose that, for whatever incomprehensible reason, we actually did need to check if a JS value was either a finite number or a finite non-empty numeric string. Instead of installing an npm package, we could just copy-paste the entirety of <code>is-number</code> into our program:
  </p>
  <pre><code><span><span><span>function</span> <span>isNumber</span><span>(</span><span>num</span><span>)</span> <span>{</span>
</span></span><span><span>  <span>if</span> <span>(</span><span>typeof</span> <span>num</span> <span>===</span> <span>'number'</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>return</span> <span>num</span> <span>-</span> <span>num</span> <span>===</span> <span>0</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span>
</span></span><span><span>  <span>if</span> <span>(</span><span>typeof</span> <span>num</span> <span>===</span> <span>'string'</span> <span>&amp;&amp;</span> <span>num</span><span>.</span><span>trim</span><span>()</span> <span>!==</span> <span>''</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>return</span> <span>Number</span><span>.</span><span>isFinite</span> <span>?</span> <span>Number</span><span>.</span><span>isFinite</span><span>(</span><span>+</span><span>num</span><span>)</span> <span>:</span> <span>isFinite</span><span>(</span><span>+</span><span>num</span><span>);</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span>
</span></span><span><span>  <span>return</span> <span>false</span><span>;</span>
</span></span><span><span><span>}</span></span></span></code></pre>
  <p>
    This mitigates all the remaining downsides. We still <strong>save development time</strong> by copy-pasting. It <strong>cannot cause breakage</strong> in the future, since it will never change. It has a <strong>smaller footprint</strong>, since it doesn’t include unnecessary metadata, and it will never mysteriously duplicate itself. It is <strong>not risky</strong>, since its functionality is obvious and it cannot be attacked via the supply chain.
  </p>
  <p>
    And of course, we probably could have just written <code>typeof foo === "number"</code>.
  </p>

  <h2 id="what-about-duplication-">What about duplication?</h2>
  <p>
    One of the purported benefits of tiny libraries is reduced duplication across your whole app. Say your app has a utility like <code>isNumber</code>, and several libraries have utilities like <code>isNumber</code>—wouldn’t it be better to reduce all the duplication and let them all share one version of the utility?
  </p>
  <p>
    In practice this is obviously not what happens. Look at the dependency graphs for popular projects and you will see amazing amounts of duplication. Often there are multiple packages performing similar functions, but also there often multiple major versions of the <em>same package</em>.
  </p>
  <p>
    It should be obvious why this happens: not all users have the exact same requirements. Wherever the requirements differ, there will be a different implementation. We wouldn’t expect every copy-pasted utility to be exactly the same, so why would we expect the duplication to disappear when using a package manager instead?
  </p>
  <p>
    But really, it’s worse than that, because when multiple major versions of <code>is-number</code> are installed in your <code>node_modules</code>, something else is clearly wrong. Semantic versioning simply isn’t the sharp tool people think it is. If you’re on Node 20, it is <em>not a breaking change</em> for the library to raise the minimum Node version from 0.10.0 to 0.12.0. There would be no need for a duplicate version, but your tools do not know this. Likewise if the package author releases a major version because of an edge case. Technically breaking for <em>some</em> users, but not for you.
  </p>
  <p>
    And finally—many use cases of tiny libraries can literally be replaced with one-liners. In this case you don’t have to worry about duplication at all anyway. Your code will still be small. It will be a tiny amount of source code and just a handful of bytecode ops. You don’t need a package manager to solve this problem for you.
  </p>

  <h2 id="stop-already">Stop already!</h2>
  <p>
    I could have written the same analysis about <code>left-pad</code> eight years ago, or <a href="https://www.npmjs.com/package/shebang-regex">many</a> <a href="https://www.npmjs.com/package/is-regexp">other</a> <a href="https://www.npmjs.com/package/run-applescript">packages</a> today. <strong>Tiny utilities simply should not be libraries.</strong>
  </p>
  <p>
    There is absolutely nothing wrong with copy-pasting code into your project. Sometimes it really is useful to grab a snippet of code from Stack Overflow, but there is literally zero benefit to installing these things through a package manager. You are exposing yourself to a whole world of pain, which you can trivially avoid by just copy-pasting.
  </p>
  <p>
    I have talked a lot about the costs of libraries, and I do hope people are more cautious about them. But there’s one factor I left out from my previous discussion. I think there’s one more reason why people use libraries: <strong>fear</strong>.
  </p>
  <p>
    Programmers are afraid of causing bugs. Afraid of making mistakes. Afraid of missing edge cases. Afraid that they won’t be able to understand how things work. In their fear they fall back on libraries. “Thank goodness someone else has solved the problem; surely I <em>never</em> would have been able to.”
  </p>
  <p>
    But they should not be afraid! Libraries are not magic. They are just code someone else wrote. After all, I pasted the entirety of <code>is-number</code> above, and nothing in there is too mysterious. And beyond libraries—languages are not magic, operating systems are not magic, nothing is magic. Dig into the source code and you will find code you can read and understand. This attitude is fundamental to the <a href="https://handmade.network/manifesto">Handmade ethos</a> and I endorse it fully.
  </p>
  <p>
    If you are a proponent of tiny libraries, I encourage you to overcome your fear and try writing the code yourself. You are more capable than you think.
  </p>

    </article>
  
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaving Neovim for Zed (221 pts)]]></title>
            <link>https://stevedylan.dev/posts/leaving-neovim-for-zed/</link>
            <guid>41284322</guid>
            <pubDate>Sun, 18 Aug 2024 18:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevedylan.dev/posts/leaving-neovim-for-zed/">https://stevedylan.dev/posts/leaving-neovim-for-zed/</a>, See on <a href="https://news.ycombinator.com/item?id=41284322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
	<p><img src="https://dweb.mypinata.cloud/ipfs/Qmc6r5uT5GiAonoo98YLTzxysvjV8x6cVaT1cQnToLsva6?img-quality=60" alt="cover-image"></p><p>I think every developer has their own text editor journey and how they landed on the tool they use today. Perhaps I’m a geek but I love those stories. I have a great appreciation for developer tools and the work that goes into them. This post is for the other geeks out there that also care, and I hope my journey and perspective can prompt others to experiment and try developer tools outside their comfort zones. You never know what you might land on and how much you might enjoy it!</p>
<p>My text editor journey starts with a faint memory of Atom. I was learning the true fundamentals of HTML CSS and Javascript, and I honestly can’t tell you how I landed on Atom as a text editor. I do remember using it for a few weeks, and I kept seeing other people use or mention VSCode, so of course I gave it a shot and used it for a while. However this didn’t last long. At the time my wife needed my laptop for her photo editing job, so I used my brother’s old Macbook that was holding on for dear life. VSCode’s Electron build started taking a noticeable toll on performance, and by chance I also discovered Vim around the same time.</p>
<p>Immediately I was mesmerized by the speed and powers demonstrated by The Primeagen’s early videos. I was already a keyboard maximalist from <a href="https://stevedylan.dev/posts/leaving-neovim-for-zed/posts/why-i-learned-vim">previous jobs</a> where I learned speed = productivity, so it was a no brainer that I had to learn it. Started with the basic motions and Vim tutor, and I had the advantage that I was just learning programming on the side instead of doing it full time. Within a few weeks I was in Vim consistently, writing and learning to code. The tweaking of my Vim RC eventually led to discovering Neovim thanks to <a href="https://www.youtube.com/@chrisatmachine">chris@machine</a> and his early videos.</p>
<p>For the next several years I stuck with Neovim and I loved it, and I owe a mass amount of my productivity to it. There were countless hours spent configuring it like many of us do. I eventually got to a point where I didn’t adjust my config much, but that soon didn’t matter.</p>
<h2 id="what-changed">What Changed</h2>
<p>Every now and then I would update a plugin in Neovim and everything would break, and I would have to spend time fixing it instead of getting work done. This resulted in slimming down my config more and more, but there was still so much that went into making all the basics work. I stuck with it because it was still better than using VSCode, which I did try for a two week sprint to see if it could be any better. It was also key to a <a href="https://stevedylan.dev/posts/a-terminal-based-workflow">terminal based workflow</a> that other editors couldn’t really match.</p>
<p>The sentiment started to shift again not too long ago as I started working in some really large code bases, and boy Neovim was struggling. I would have random hang ups, frozen screens, stuff that just drove me nuts when productivity was king. I tried switching to other terminal emulators too such as Alacritty and Wezterm but it didn’t help much.</p>
<p>This is when Zed came back into my sights. I heard about it months before and even gave it a shot back then, but didn’t stick with it because it wasn’t a terminal workflow. However it boasted as being fast, and I decided it was worth another shot. Two months later and I’ve been daily driving it since. I wasn’t sure if it would really hold up, but I can say now it has been an amazing experience and I don’t see myself going back.</p>
<h2 id="my-experience-with-zed">My Experience with Zed</h2>
<p>In order to understand why I eventually settled on Zed we’ll look at my general experience with it so far and how I made it work for me.</p>
<h3 id="it-just-works">It Just Works</h3>
<p>One of the biggest things that has stood out to me using Zed so far is how “everything just works.” There are so many features of an IDE or text editor that people take for granted until they have to set it up themselves in something lower level like Neovim. LSP (language server protocol) is certainly one of them. If you’re not familiar it’s the hints or errors that show up while you’re writing up your code, giving you deep insights to your repo on a language level. When you setup LSP in Neovim it’s a lot of work, and sometimes it can be a bit harder to figure out why it might be bugging out. However it does give you way more control and the option to do a lot of customization. With Zed LSP just works. There are configurations you can make to edit some things, but as a whole it just zips out of the box. There are already keybindings for things like “show definition”, “go to definition”, or even code actions. The only downside is outside of an extension you can’t use your own LSP that’s installed on your machine, but there’s always a pretty large language support that I haven’t had this issue yet.</p>
<p><img src="https://dweb.mypinata.cloud/ipfs/QmNkysZ5Roy723sphUST8abmHakKR86K2YHXeeVTU22ASH" alt="image of LSP"></p><p>Another piece that’s related to LSP is completions. This is when you’re typing some code and get  suggestions for auto completions that quickly fill the rest of the code out. LSPs usually have great auto-completion because they’re aware of the patterns used in that language. Just to be clear we’re not talking about Copilot yet, this is just completions for snippets and LSP. Once again with Zed it just works out of the box, unlike Neovim which ends up requiring several plugins to make it work right.</p>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmVEqwPxAoWgDwCLM3PrVxseLtLjCDK8LMxxz6DyD5fjxz"></video>
<p>Finally there’s Git integrations. What normally required multiple plugins in Neovim is again ready out of the box with Zed, including feature like toggling Git Blame, viewing diffs, and gutter symbols showing the status of edited lines.</p>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/Qmcqv6kXnHHVbX8RxWpK6coPZHyNcPU7bxPfZ2Zwbsm6bz"></video>
<p>If I had to make a crude comparison, it’s similar to Linux and Apple. Linux will give you far more control over every piece of your software and hardware at the cost of spending time to configure it. Apple will give you less control but it will likely run smoother.</p>
<h3 id="speed">Speed</h3>
<p>Of course one of the biggest reasons I gave Zed a shot was speed, and boy it was worth it. It is noticeably snappy, handles larger codebases like a champ, and I haven’t experienced any lag so far. Normally I wouldn’t recommend building most things in Rust, but this app kinda makes me reconsider. There are so many developer tools written in Rust and perhaps that’s one of its biggest boasts. The team at Zed have really outdone themselves as this app; its truly a work of art.</p>
<p>Could I possibly make neovim faster by adjusting my config? Perhaps, but in the end it’s more time down the drain that I could have used writing code and being productive. For productivity nerds like me I believe there is a delicate scale: how much time I spend automating a task vs how much time the task would have taken without automation. In this case the benefits aren’t worth the cost when there’s a tool like Zed that will do just fine.</p>
<h3 id="vim-mode">Vim Mode</h3>
<p>While in the middle of my time with Neovim I came across other frustrated Neovim users that found themselves spending too much time fixing issues in Neovim to the point they switched to VSCode. Of course I had a few moments like this myself and I wondered if I had missed something. At this point I had a much faster computer, so I figured I would give it another shot. Of course I downloaded the Vim plugin as the Vim keybindings are worth learning no matter what text editor you use, and it was incredibly disappointing. Nothing had every felt so buggy and jagged, and it remained one of the big reasons I couldn’t stick with VSCode. I was back in Neovim within a week or two.</p>
<p>When I was considering Zed again I read <a href="https://registerspill.thorstenball.com/p/from-vim-to-zed">a blog post</a> about the custom Vim mode built into Zed. This was not a third party plugin; this was a labor of love from the developers building Zed. They’ve made it clear that they don’t plan to port absolutely everything to Zed, but they have done a fantastic job supporting the important stuff that makes the editor an S-tier experience.</p>
<p>I’ll likely get into this further into the post, but the way you can structure keybindings for Vim mode in Zed is fantastic. The structure allows for your typical VScode style config, but with the ability to scope a keybinding to a Vim mode is such a huge win for Neovim users. For instance, I can cheat my way into using a leader key when in normal mode and get things like <code>space d</code> to see diagnostics, or <code>space t</code> to open a full window terminal. It’s a pattern many Vim users will appreciate and I wish there was more docs for it as I’ve had to figure some of it out myself.</p>
<p>Beyond keybindings all the other stuff you would expect in Vim motions are here, with of course a few obscure ones slowly being added release by release. Some of them take a unique approach by using some of Zed’s built in features as a replacement for what Vim would normally use, like search and replace for example. Generally you would have to do a Vim command to search for a word and replace it, and those commands still do what you expect, but it brings up Zed’s Multibuffer view when doing a project wide search. You get Vim mode but it’s still Zed and it’s unique feature set.</p>
<h3 id="ai-stuff">AI Stuff</h3>
<p>When it comes to AI features I think Zed provides some great built in tools. I will disclose that I’m not a big user of AI within the text editor (a topic for another blog post), so there might be things you’re looking for compared to Cursor that I can’t speak to. With that said it does have Copilot built in which is probably what most people want to know.</p>
<p>Zed also features an assistant panel where you can access several AI models via API, including OpenAI, Ollama, and Anthropic. Just requires a few lines of config to get started.</p>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmPo8nXP8w9hJfxnhCpggrGKP89VbtiV1Rf3mFRHj9fUqA"></video>
<p>One feature that I think is particularly nice is the inline assistant, where you can select some lines of code and use <code>ctrl-enter</code> to trigger a request to be made to your code via the AI assistance configuration mentioned previously. If you like the results then you can confirm and keep coding.</p>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmTTGznMRr64oqJG7hXFiCrqrTqXiY3kaPuQnhWbCCSAaL"></video>
<h3 id="zed--neovim">Zed ≠ Neovim</h3>
<p>You can probably gather so far that I’m a huge Zed fan, however I will say it’s not a 1/1 replacement to Neovim. What makes Neovim so special is that it’s native to the terminal. Whenever I need to edit a configuration file for an app or just edit something really quickly while I’m already navigating in a terminal, nothing beats the convenience of whipping out Neovim. Opening Zed for every single file like that would get exhausting, but for longer term sessions or projects it’s perfect. If you compare to motorcycles, Neovim is my dirt bike and Zed is my cruiser.</p>
<h2 id="making-zed-work-for-a-neovim-user">Making Zed Work for A Neovim User</h2>
<p>While Zed can’t truly be a drop in replacement of Neovim, there are a lot of small configurations that really help improve the experience and make it familiar to a Neovim/Vim user.</p>
<h3 id="vim-mode--keybindings">Vim Mode &amp; Keybindings</h3>
<p>First one is obvious, turn on Vim mode. Zed has a great <a href="https://zed.dev/docs/vim">docs page</a> with loads of extra info, some default Vim bindings, and some extra configs available to make it work for you. By far my favorite piece that I mentioned earlier is the ability to do key bindings based on Vim modes. Here’s some examples:</p>
<pre><code><span><span>[</span></span>
<span><span>	</span><span>{</span></span>
<span><span>		</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Editor &amp;&amp; VimControl &amp;&amp; !VimWaiting &amp;&amp; !menu</span><span>"</span><span>,</span></span>
<span><span>		</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>			</span><span>"</span><span>space b</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::ToggleGitBlame</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>shift-k</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::Hover</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space l f</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::Format</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space d</span><span>"</span><span>:</span><span> </span><span>"</span><span>diagnostics::Deploy</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space f f</span><span>"</span><span>:</span><span> </span><span>"</span><span>file_finder::Toggle</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space o</span><span>"</span><span>:</span><span> </span><span>"</span><span>tab_switcher::Toggle</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space e</span><span>"</span><span>:</span><span> </span><span>"</span><span>workspace::ToggleLeftDock</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space /</span><span>"</span><span>:</span><span> </span><span>"</span><span>workspace::NewSearch</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>n</span><span>"</span><span>:</span><span> </span><span>"</span><span>search::SelectNextMatch</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>shift-n</span><span>"</span><span>:</span><span> </span><span>"</span><span>search::SelectPrevMatch</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space t</span><span>"</span><span>:</span><span> </span><span>"</span><span>workspace::NewCenterTerminal</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>g b</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::ToggleComments</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>+ +</span><span>"</span><span>:</span><span> </span><span>"</span><span>workspace::Save</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>space c</span><span>"</span><span>:</span><span> </span><span>"</span><span>pane::CloseActiveItem</span><span>"</span></span>
<span><span>		</span><span>}</span></span>
<span><span>	</span><span>},</span></span>
<span><span>	</span><span>{</span></span>
<span><span>		</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Editor &amp;&amp; vim_mode == visual &amp;&amp; !VimWaiting &amp;&amp; !VimObject</span><span>"</span><span>,</span></span>
<span><span>		</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>			</span><span>"</span><span>shift-j</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::MoveLineDown</span><span>"</span><span>,</span></span>
<span><span>			</span><span>"</span><span>shift-k</span><span>"</span><span>:</span><span> </span><span>"</span><span>editor::MoveLineUp</span><span>"</span></span>
<span><span>		</span><span>}</span></span>
<span><span>	</span><span>},</span></span>
<span><span>]</span></span></code></pre>
<p>Most of these are pretty self explanatory, but the key is that the first set is in “Normal” mode, while the next set is “Visual.” There’s also small improvements or shortcuts they provide in the docs like this set of key bindings that allows you to switch panes similar to how most people have Neovim setup.</p>
<pre><code><span><span>[</span></span>
<span><span>	</span><span>{</span></span>
<span><span>		</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Dock || Terminal || Editor</span><span>"</span><span>,</span></span>
<span><span>		</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>			</span><span>"</span><span>ctrl-h</span><span>"</span><span>:</span><span> </span><span>[</span><span>"</span><span>workspace::ActivatePaneInDirection</span><span>"</span><span>,</span><span> </span><span>"</span><span>Left</span><span>"</span><span>],</span></span>
<span><span>			</span><span>"</span><span>ctrl-l</span><span>"</span><span>:</span><span> </span><span>[</span><span>"</span><span>workspace::ActivatePaneInDirection</span><span>"</span><span>,</span><span> </span><span>"</span><span>Right</span><span>"</span><span>],</span></span>
<span><span>			</span><span>"</span><span>ctrl-k</span><span>"</span><span>:</span><span> </span><span>[</span><span>"</span><span>workspace::ActivatePaneInDirection</span><span>"</span><span>,</span><span> </span><span>"</span><span>Up</span><span>"</span><span>],</span></span>
<span><span>			</span><span>"</span><span>ctrl-j</span><span>"</span><span>:</span><span> </span><span>[</span><span>"</span><span>workspace::ActivatePaneInDirection</span><span>"</span><span>,</span><span> </span><span>"</span><span>Down</span><span>"</span><span>]</span></span>
<span><span>		</span><span>}</span></span>
<span><span>	</span><span>},</span></span>
<span><span>]</span></span></code></pre>
<p>Something else I would recommend to anyone who is trying to migrate from Vim/Neovim to Zed is checking out the <a href="https://github.com/zed-industries/zed/blob/340a1d145ed15e39a4a27afc5a189851308fb91d/assets/keymaps/vim.json#L4">default Vim keymap</a>. There’s so much there that acts as a helpful reference of what’s supported and what you may want to adjust!</p>
<h3 id="reduced-ui">Reduced UI</h3>
<p>Zed already has a pretty nice minimal UI, but I prefer something closer to my Neovim setup. Thankfully Zed offers these options, such as disabling the tab bar, scroll bar, reduced toolbar, and relative line numbers</p>
<pre><code><span><span>{</span></span>
<span><span>	</span><span>"</span><span>cursor_blink</span><span>"</span><span>:</span><span> </span><span>false</span><span>,</span></span>
<span><span>	</span><span>"</span><span>relative_line_numbers</span><span>"</span><span>:</span><span> </span><span>true</span><span>,</span></span>
<span><span>	</span><span>"</span><span>scrollbar</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>		</span><span>"</span><span>show</span><span>"</span><span>:</span><span> </span><span>"</span><span>never</span><span>"</span></span>
<span><span>	</span><span>},</span></span>
<span><span>	</span><span>"</span><span>vertical_scroll_margin</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>	</span><span>"</span><span>tab_bar</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>		</span><span>"</span><span>show</span><span>"</span><span>:</span><span> </span><span>false</span></span>
<span><span>	</span><span>},</span></span>
<span><span>	</span><span>"</span><span>toolbar</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>	    </span><span>"</span><span>breadcrumbs</span><span>"</span><span>:</span><span> </span><span>true</span><span>,</span></span>
<span><span>	    </span><span>"</span><span>quick_actions</span><span>"</span><span>:</span><span> </span><span>false</span></span>
<span><span>	</span><span>},</span></span>
<span><span>}</span></span></code></pre>
<p><img src="https://dweb.mypinata.cloud/ipfs/QmVtqSNc6Ff9Zy8vBxr92AcVdh9eAGYkU8zWGLoyTnoeDL?img-quality=60" alt="reduced UI"></p><h3 id="plugin-replacements">Plugin Replacements</h3>
<p>Since I don’t use the tab bar I wanted something similar to Telescope to navigate between buffers or files, and thankfully there is an option for that! This key binding will show currently open all buffers, which is separate from the file finder.</p>
<pre><code><span><span>{</span></span>
<span><span>	</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Editor &amp;&amp; VimControl &amp;&amp; !VimWaiting &amp;&amp; !menu</span><span>"</span><span>,</span></span>
<span><span>	</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>		</span><span>"</span><span>space o</span><span>"</span><span>:</span><span> </span><span>"</span><span>tab_switcher::Toggle</span><span>"</span><span>,</span></span>
<span><span>	</span><span>}</span></span>
<span><span>}</span></span></code></pre>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmQntcJQkJKoh2bmreRYun4BfDuLb8rXry6ZFmiVYPaeRx"></video>
<p>Speaking of Telescope, one big replacement is project wide search. While Zed doesn’t have a fuzzy find feature, the project wide search is excellent. It will show all results in a multibuffer view which is pretty slick, and allows you to jump between that view and the buffer itself pretty easily.</p>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmY2Cs7zBk7bEa7skNLBcA5dFnSmTS7CotFjftcMA2r3m1"></video>
<p>The terminal toggle is pretty similar to something like VSCode but there are some other hidden ways to get a better terminal experience. One of them is a shortcut to toggle the bottom terminal to be full screen, but even better is opening a terminal as a buffer in the main editing view.</p>
<pre><code><span><span>{</span></span>
<span><span>	</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Editor &amp;&amp; VimControl &amp;&amp; !VimWaiting &amp;&amp; !menu</span><span>"</span><span>,</span></span>
<span><span>	</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>		</span><span>"</span><span>space t</span><span>"</span><span>:</span><span> </span><span>"</span><span>workspace::NewCenterTerminal</span><span>"</span><span>,</span></span>
<span><span>	</span><span>}</span></span>
<span><span>}</span></span></code></pre>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmYGcEqane6cpVPJj9H7qjgYmV75GPhmy7hkKob6YPVscY"></video>
<p>One of the big things I had to leave behind was Tmux and switching projects. While it isn’t a perfect replacement, Zed has a “switch projects” feature which works really well and makes it pretty easy to switch contexts. You just won’t get the exact same control and layout setup that you can get with Tmux</p>
<pre><code><span><span>{</span></span>
<span><span>	</span><span>"</span><span>context</span><span>"</span><span>:</span><span> </span><span>"</span><span>Workspace</span><span>"</span><span>,</span></span>
<span><span>	</span><span>"</span><span>bindings</span><span>"</span><span>:</span><span> </span><span>{</span></span>
<span><span>		</span><span>"</span><span>cmd-k</span><span>"</span><span>:</span><span> </span><span>[</span></span>
<span><span>			</span><span>"</span><span>projects::OpenRecent</span><span>"</span><span>,</span></span>
<span><span>			</span><span>{</span></span>
<span><span>				</span><span>"</span><span>create_new_window</span><span>"</span><span>:</span><span> </span><span>false</span></span>
<span><span>			</span><span>}</span></span>
<span><span>		</span><span>]</span></span>
<span><span>	</span><span>}</span></span>
<span><span>}</span></span></code></pre>
<video autoplay="" muted="true" loop="" playsinline="" src="https://dweb.mypinata.cloud/ipfs/QmXh5mDRJyQRSCfmHNeZ5DDwnzPr3uo5mqCMQN1mLzGh6T"></video>
<h2 id="should-you-use-zed">Should You Use Zed?</h2>
<p>If you’re still on the fence of trying Zed I would say it’s at least worth giving it a shot for a few days. In my experience so far it’s a unique and capable text editor, but ultimately I vouch for anything that makes you more productive. That might end up being VS Code or Jetbrains or hell maybe even EMacs. Do what’s best for you, but don’t be too stubborn to try something new.</p>
<p>Edit: Thank you for all the love on this post! If you want to see my full settings and keymaps I have them linked below for your convenience.</p>
<p><a href="https://www.snippets.so/snip/bafkreia4sliyaggmemdbvfl2cv4iakkz343pn4bjbdxcig6mmekjvy2o5a">settings.json</a></p>
<p><a href="https://www.snippets.so/snip/bafkreifwoopkah2ouf7iuuvnx5n4b7slcoqyo6c3uwifenw4ikp3rzauuq">keymap.json</a></p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Detailed Map of Cancer-Causing Industrial Air Pollution in the U.S. (139 pts)]]></title>
            <link>https://projects.propublica.org/toxmap/</link>
            <guid>41283675</guid>
            <pubDate>Sun, 18 Aug 2024 17:18:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://projects.propublica.org/toxmap/">https://projects.propublica.org/toxmap/</a>, See on <a href="https://news.ycombinator.com/item?id=41283675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a href="https://projects.propublica.org/"><svg role="image" width="574" height="75"><use xlink:href="#propublica-logo"></use><text>ProPublica</text></svg></a><p>© Copyright <span id="year"></span> Pro Publica Inc.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Police Cannot Seize Property Indefinitely After an Arrest, Federal Court Rules (528 pts)]]></title>
            <link>https://reason.com/2024/08/16/police-cannot-seize-property-indefinitely-after-an-arrest-federal-court-rules/</link>
            <guid>41283310</guid>
            <pubDate>Sun, 18 Aug 2024 16:28:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2024/08/16/police-cannot-seize-property-indefinitely-after-an-arrest-federal-court-rules/">https://reason.com/2024/08/16/police-cannot-seize-property-indefinitely-after-an-arrest-federal-court-rules/</a>, See on <a href="https://news.ycombinator.com/item?id=41283310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p><span>The Fourth Amendment's protection against unreasonable searches and seizures extends to the <em>length</em> of a seizure, a federal court ruled last week, significantly restricting how long law enforcement can retain private property after an arrest.</span></p> <p><span>"When the government seizes property incident to a lawful arrest, the Fourth Amendment requires that any continued possession of the property must be reasonable," </span><a href="https://www.cadc.uscourts.gov/internet/opinions.nsf/543BA8AD10156CE685258B7400533CE0/$file/22-7129-2069152.pdf"><span>wrote</span></a><span> Judge Gregory Katsas of the U.S. Court of Appeals for the District of Columbia in a unanimous ruling.</span></p> <p><span>Most courts of appeal to pass judgment on the issue—namely, the </span><a href="https://www.cadc.uscourts.gov/internet/opinions.nsf/543BA8AD10156CE685258B7400533CE0/$file/22-7129-2069152.pdf"><span>1st, 2nd, 6th, 7th, and 11th circuits</span></a><span>—have held that, once an item is seized, law enforcement can retain the item indefinitely without violating the <a href="https://www.reaganlibrary.gov/constitutional-amendments-amendment-4-right-privacy#:~:text=%E2%80%9CThe%20right%20of,to%20be%20seized.%E2%80%9D">Fourth Amendment</a>. These precedents have allowed police to retain personal property without clear legal grounds, effectively stripping people of their property rights merely because they were arrested. The D.C. Court of Appeals' ruling complicates this general consensus.</span></p> <p><span>Though law enforcement does not have to return property "instantaneously," Katsas wrote, the Fourth Amendment requires that any "continuing retention of seized property" be reasonable. So while police can use seized items for "legitimate law-enforcement purposes," such as for evidence at trial, and are permitted some delay for "matching a person with his effects," prolonged seizures serving no important function can implicate the Fourth Amendment, the court ruled.</span></p> <p><span>Given that the D.C. court finds itself in the minority on the question, some say that the case may be primed for the Supreme Court if the District chooses to appeal. "This case has potential to make national precedent," Paul Belonick, a professor at the University of California, San Francisco law school, tells </span><i><span>Reason</span></i><span>. "The influential D.C. Circuit deliberately intensified a circuit split and put itself in the minority of circuits on the question, teeing it up cleanly for certiorari."</span></p> <p><span>The plaintiffs each had their property seized by D.C.'s Metropolitan Police Department (MPD). Five of the plaintiffs were arrested during a Black Lives Matter protest in the Adams Morgan neighborhood of D.C. on August 13, 2020.</span></p> <p><span>As they were arrested, MPD officers seized their phones and other items. Though the protesters did not face any charges and were, in Katsas' words, "quickly released," MPD retained their phones for around a year. Some of the plaintiffs had to wait over 14 months to get their property back.</span></p> <p><span>In the meantime, the plaintiffs say that they were forced to replace their phones and lost access to the important information on the originals, including personal files, contacts, and passwords. </span><span>"The plaintiffs have alleged that the seizures at issue, though lawful at their inception, later came to unreasonably interfere with their protected possessory interests in their own property," Katsas explained.</span></p> <p><span>"MPD is aware of the ruling and will continue to work with our partners at the United States Attorney's Office to ensure that our members are trained appropriately to ensure compliance with recent rulings," a spokesperson for MPD&nbsp;tells </span><i><span>Reason</span></i><span>.</span></p> <p><span>"Practically, this case is important because police have been exploiting a gap in the Fourth Amendment," Andrew Ferguson, a professor at American University's Washington College of Law, tells </span><i><span>Reason</span></i><span>. "In situations where there is a lawful arrest, but no prosecution, there are no clear rules on retaining personal property. In these cases, police have been confiscating phones to punish protestors."</span></p> <p><span>Michael Perloff, the lead attorney for the plaintiffs, agreed that the D.C. Circuit's decision could set an important precedent going forward. "Nationally, we've seen litigants attempt to challenge similar practices only to fail because the court concluded that the Fourth Amendment does not limit the duration of a seizure," he tells </span><i><span>Reason</span></i><span>. "Moving forward, we are hopeful that the D.C. Circuit's opinion will lead courts to reconsider those rulings and, instead, enforce the Fourth Amendment as fully as the framers intended."</span></p>						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tell HN: X stopped requiring authentication, nitter works again (111 pts)]]></title>
            <link>https://nitter.lucabased.xyz/x</link>
            <guid>41283209</guid>
            <pubDate>Sun, 18 Aug 2024 16:11:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nitter.lucabased.xyz/x">https://nitter.lucabased.xyz/x</a>, See on <a href="https://news.ycombinator.com/item?id=41283209">Hacker News</a></p>
Couldn't get https://nitter.lucabased.xyz/x: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Surveillance Watch – the hidden connections within the surveillance industry (141 pts)]]></title>
            <link>https://www.surveillancewatch.io</link>
            <guid>41283149</guid>
            <pubDate>Sun, 18 Aug 2024 16:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.surveillancewatch.io">https://www.surveillancewatch.io</a>, See on <a href="https://news.ycombinator.com/item?id=41283149">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><p><span><span>They know who you are.</span><span></span></span></p><p><span><span>It's time to uncover</span><span></span></span><span><span>who they are.</span><span></span></span></p></h2><p>Surveillance Watch is an interactive map revealing the intricate connections between surveillance companies, their funding sources and affiliations.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS adds vertical centering in 2024 (122 pts)]]></title>
            <link>https://build-your-own.org/blog/20240813_css_vertical_center/</link>
            <guid>41282889</guid>
            <pubDate>Sun, 18 Aug 2024 15:21:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://build-your-own.org/blog/20240813_css_vertical_center/">https://build-your-own.org/blog/20240813_css_vertical_center/</a>, See on <a href="https://news.ycombinator.com/item?id=41282889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><code>align-content</code> works in the default layout in 2024,
allowing vertical centering with <strong>1 CSS property</strong>.</p>
<div><pre><code>&lt;div style="<strong>align-content: center;</strong> height: 100px;"&gt;
  &lt;code&gt;align-content&lt;/code&gt; just works!
&lt;/div&gt;
</code></pre></div>


<p><code>align-content</code> just works!
</p>


<p><a href="https://caniuse.com/mdn-css_properties_align-content_block_context">Supported
since</a>: <br>
<img width="16" height="16" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACaklEQVR42nWTA6xsVxhG17/3mXm2bds2w96oRlgzqo34IqxtG1GNsDbmPtvG+b/OHtRdx1jfduAflGaOXfrrrHHNpTkTSq1zJ2rD/Em+YcGUzzctmvrQlrlTh/IPrPTnu66etbkZ7MoQAsFM6WQhYGaVI6SD2HwknLwV2Atgn1cDunYMxXeDhSkWLFGXFGLSUOU5BQcD48sj8mUpJAB0DIVU8lSBUcEQUEmo3lBNxAQGYWrHLCs7yXqqYeglb2wuLf1uX7XaZlYYMIBeN93Ftp6jiJ06MSB/C//5anS0JENIMsMl1/IswM3Pze/FrF8P0PG4rNB/AN7yHGe/KT799RhwjEHd5vLc+R/S75fFpqOtYE6FQEPwnKnbOxV4Y1p3Ej2uuppTHz9Zlo9TZ8OenKueN+K4uzGLYBkQMcIpAWmqy/XalK5s71xg9+RlbCwL/yQFbjwxHiXRgkRmsjA0uDtyt4NF4/4FPeQHD/B/dOnYDUJERCNUaxIkb1XCnc+GtbdthfXMG1Hkn0zon9Hp8DsYGVZrAha/SH3wslwmCbm47v1GbmuIFaFGObBA85kF8l9vRRYQAbOIEb+wifetXZrDuxIgIaB/h95cN/9CZvedx4a9BzjoJT79/EYu6/oVIKQcQ8Tch9mY+9YANMl1BQJJhoRLAiHHBhRP8tiobQwsngAc5JjUDFwVAI4dPHarXF/Wm+IuSPd59fm83ocY1FbCIiKi1PY83gpgQ5uWUqNrzOItolYThMoMLLq9N2UXIMCR5y3ZiRO31BdToEbtxZV+0oe59IhcX0jisgFHwGKrCC0ylqV/6nLid9CxMOX4sHSyAAAAAElFTkSuQmCC">
Chrome: 123 |
<img width="16" height="16" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAZ0lEQVR42q2SAQbAMBRD/2VztF1p18lsiCJ7Nhqiqt7ztZ2aw659izVeQWuqwOc8Z1UAMEoiWEpwkRQBiALf61eYJQj3BraKgECeoIuyxwmg++/ACmwLXgJh0T/gdgFLGAYJwpw/4AWWCw/0v3nNDwAAAABJRU5ErkJggg==">
Firefox: 125 |
<img width="16" height="16" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQBAMAAADt3eJSAAAAJ1BMVEUAAAAQfd0fhvkSrvH/UVAGwudtnampc33RpKe23ubx8fGQyt1mq9Ygasa0AAAAAXRSTlMAQObYZgAAAGdJREFUeNpjYGBgFBQUYADRQkpKiiCWoBIQCIIFjI2VHAUYGJWMQ0NTlAQYhJRMQ8PclBQZhJRDQ0tSjcCMCPdQCGNWK4QRvTIUzFA6tTU0VEkRqH1NaGgwUDujlBJIQABmBcJSuDMAytIVRxPqOxAAAAAASUVORK5CYII=">
Safari: 17.4</p>
<h2 id="whats-new">What’s new?</h2>
<p>The status quo for CSS alignment is to switch to <em>flexbox</em> or
<em>grid</em> because <code>align-content</code> doesn’t work in the
default layout (<em>flow</em>). In 2024, browsers have <a href="https://web.dev/blog/align-content-block">implemented</a>
<code>align-content</code> for <em>flow layout</em>. This has some
advantages:</p>
<ul>
<li>You do not need flexbox or grid, just 1 CSS property for
alignment.</li>
<li>Therefore, the content doesn’t need to be wrapped in a div.</li>
</ul>
<div><pre><code>&lt;!-- Works --&gt;
&lt;div style="<strong>display: grid; align-content: center;</strong>"&gt;
  Content.
&lt;/div&gt;
</code></pre></div>
<div><pre><code>&lt;!-- <span>FAIL!</span> --&gt;
&lt;div style="<strong>display: grid; align-content: center;</strong>"&gt;
  Content with <strong>&lt;em&gt;multiple&lt;/em&gt;</strong> nodes.
&lt;/div&gt;
</code></pre></div>
<div><pre><code>&lt;!-- Works with the content wrapper --&gt;
&lt;div style="<strong>display: grid; align-content: center;</strong>"&gt;
  &lt;div&gt;  &lt;!-- The extra wrapper --&gt;
    Content with <strong>&lt;em&gt;multiple&lt;/em&gt;</strong> nodes.
  &lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<div><pre><code>&lt;!-- Works without the content wrapper --&gt;
&lt;div style="<strong>align-content: center;</strong>"&gt;
  Content with <strong>&lt;em&gt;multiple&lt;/em&gt;</strong> nodes.
&lt;/div&gt;
</code></pre></div>
<p>It’s amazing that CSS finally has a <strong>single property</strong>
to control vertical align after decades of progress!</p>
<h2 id="vertical-centering-a-history">Vertical centering — a
history</h2>
<p>Browsers are funny, basic needs like aligning stuff do not have
simple answers for a very long time. Here is how to center stuff in
libreoffice:</p>
<p><img src="https://build-your-own.org/blog/20240813_css_vertical_center/libreoffice_center.png"></p>
<p>Here is how to center <em>vertically</em> in a browser
(<em>horizontal</em> centering is another topic):</p>
<h3 id="method-1-table-cell">Method 1: table cell</h3>
<p>Sanity: ★★★☆☆</p>
<p>There are 4 major layouts: flow (default), table, flexbox, grid. How
to align stuff depends on the layout of the container. Flexbox and grid
were added rather late, so table was the first option.</p>
<div><pre><code>&lt;div style="<strong>display: table;</strong>"&gt;
  &lt;div style="<strong>display: table-cell; vertical-align: middle;</strong>"&gt;
    Content.
  &lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<p>A table can be summoned purely from CSS, but it’s a shame that such
an indirection was needed.</p>
<h3 id="method-2-absolute-positioning">Method 2: absolute
positioning</h3>
<p>Sanity: ☆☆☆☆☆</p>
<p>For reasons I don’t understand. People kept inventing more indirect
ways to do things.</p>
<div><pre><code>&lt;div style="<strong>position: relative;</strong>"&gt;
  &lt;div style="<strong>position: absolute; top: 50%; transform: translateY(-50%);</strong>"&gt;
    Content.
  &lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<p>This one uses absolute positioning to bypass the layout, since the
flow layout doesn’t help us:</p>
<ol start="0" type="1">
<li>Mark the reference container with
<code>position: relative</code>.</li>
<li>Place the edge of the content at the center with
<code>position: absolute; top: 50%</code>.</li>
<li>Offset the content center to the edge with
<code>transform: translateY(-50%)</code>.</li>
</ol>
<h3 id="method-3-inline-content">Method 3: inline content</h3>
<p>Sanity: ☆☆☆☆☆</p>
<p>While the flow layout doesn’t help with content alignment. It allows
vertical alignment <em>within</em> a line. So why not make a line as
tall as the container?</p>
<div><pre><code>&lt;div class="<strong>container</strong>"&gt;
  <strong>::before</strong>
  &lt;div class="<strong>content</strong>"&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<div><pre><code>.container::before {
  content: '';
  height: 100%;
  display: inline-block;
  vertical-align: middle;
}
.content {
  display: inline-block;
  vertical-align: middle;
}
</code></pre></div>
<p>This has some flaws: besides sacrificing a pseudo-element, there’s a
zero-width <a href="https://christopheraue.net/design/vertical-align#:~:text=strut">“strut”
character</a> at the beginning that can mess stuff up.</p>
<h3 id="method-4-single-line-flexbox">Method 4: single-line flexbox</h3>
<p>Sanity: ★★★☆☆</p>
<p>Flexbox became widely available 2 decades after the Web has taken
off. It has 2 modes: single-line and multi-line. In single-line mode
(default), the line fills the vertical space, and
<code>align-items</code> aligns stuff inside the line.</p>
<div><pre><code>&lt;div style="<strong>display: flex; align-items: center;</strong>"&gt;
  &lt;div&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<p>Alternatively, make the line columnar and align items with
<code>justify-content</code>.</p>
<div><pre><code>&lt;div style="<strong>display: flex; flex-flow: column; justify-content: center;</strong>"&gt;
  &lt;div&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<h3 id="method-5-multi-line-flexbox">Method 5: multi-line flexbox</h3>
<p>Sanity: ★★★☆☆</p>
<p>In a multi-line flexbox, the line no longer fills the vertical space,
so the line (with just 1 item in it) can be aligned with
<code>align-content</code>.</p>
<div><pre><code>&lt;div style="<strong>display: flex; flex-flow: row wrap; align-content: center;</strong>"&gt;
  &lt;div&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<h3 id="method-6-grid-content">Method 6: grid content</h3>
<p>Sanity: ★★★★☆</p>
<p>Grid was even later. Alignment became simpler.</p>
<div><pre><code>&lt;div style="<strong>display: grid; align-content: center;</strong>"&gt;
  &lt;div&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<h3 id="method-7-grid-cell">Method 7: grid cell</h3>
<p>Sanity: ★★★★☆</p>
<p>Note the subtle difference from the previous one:</p>
<ul>
<li><code>align-content</code> centers the <em>cell</em> to the
<em>container</em>.</li>
<li><code>align-items</code> centers the <em>content</em> to the
<em>cell</em> while the <em>cell</em> stretches to fit the
<em>container</em>.</li>
</ul>
<div><pre><code>&lt;div style="<strong>display: grid; align-items: center;</strong>"&gt;
  &lt;div&gt;Content.&lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<p>There seems to be many ways to do the same thing.</p>
<h3 id="method-8-auto-margin">Method 8: auto-margin</h3>
<p>Sanity: ★★★☆☆</p>
<p>In flow layout, <code>margin:auto</code> centers horizontally, but
not vertically. Flexbox and grid do not share this absurdity.</p>
<div><pre><code>&lt;div style="<strong>display: grid;</strong>"&gt;
  &lt;div style="<strong>margin-block: auto;</strong>"&gt;
    Content.
  &lt;/div&gt;
&lt;/div&gt;
</code></pre></div>
<p>Still, it puzzled me why margin was designed to also control
alignment.</p>
<h3 id="method-9-this-post-in-2024">Method 9: this post in 2024</h3>
<p>Sanity: ★★★★★</p>
<p>Why didn’t browsers add this in the first place?</p>
<div><pre><code>&lt;div style="<strong>align-content: center;</strong>"&gt;
  &lt;code&gt;align-content&lt;/code&gt; just works!
&lt;/div&gt;
</code></pre></div>
<p>The table cell from the <a href="#method-1-table-cell">Method 1</a>,
like this method, also doesn’t require a content wrapper (it requires a
table wrapper, though). We’re back to square one!</p>
<h3 id="summary">Summary</h3>
<p>All vertical centering methods in this <a href="https://codepen.io/byo-books/pen/Porpmab?editors=1000">codepen</a>.
Know other methods? Feel free to <a href="https://build-your-own.org/cdn-cgi/l/email-protection#3b51487b594e52575f1642544e4916544c551554495c">tell me</a>.</p>
<h2 id="going-2-dimensional">Going 2-dimensional</h2>
<p>Is there a <strong>single property</strong> for <em>horizontal</em>
align? What’s the counterpart of <code>align-content</code>? Let’s take
a look at various alignment properties:</p>
<table>
<caption>Table: alignment properties in different layouts</caption>
<colgroup>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th></th>
<th>flow</th>
<th>flexbox</th>
<th>grid</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&nbsp;&nbsp;align-content</code></td>
<td>block axis</td>
<td>cross axis (line)</td>
<td>block axis (grid)</td>
</tr>
<tr>
<td><code>justify-content</code></td>
<td>no effect</td>
<td>main axis</td>
<td>inline axis (grid)</td>
</tr>
<tr>
<td><code>&nbsp;&nbsp;align-items</code></td>
<td>no effect</td>
<td>cross axis (item)</td>
<td>block axis (cell)</td>
</tr>
<tr>
<td><code>justify-items</code></td>
<td>no effect</td>
<td>no effect</td>
<td>inline axis (cell)</td>
</tr>
</tbody>
</table>
<h3 id="background-css-axis-terminology">Background: CSS axis
terminology</h3>
<p>The <em>block axis</em> is usually <em>vertical</em>, and the
<em>inline axis</em> is <em>horizontal</em>. These terms are needed
because <a href="https://build-your-own.org/visual_css/2p40_box_model.html#:~:text=Logical%20properties">vertical
<code>writing-mode</code></a> is a thing, so <strong>block axis and
inline axis are relative to the text direction</strong>. This is similar
to how <em>main axis</em> and <em>cross axis</em> are relative to the
flexbox item direction.</p>

<svg version="1.1" id="svg1" viewBox="0 0 385.51181 143.62206" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg">
  <defs id="defs1">
    <clipPath clipPathUnits="userSpaceOnUse" id="clipPath3">
      <path d="M 0,0.028 H 289.105 V 107.716 L 0,107.716 Z" clip-rule="evenodd" id="path3"></path>
    </clipPath>
  </defs>
  <g id="g1">
    <g id="g2">
      <path id="path2" d="M 0,107.716 H 289.106 V 0.028 L 0,0.028 Z" style="fill:#ffffff;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)" clip-path="url(#clipPath3)"></path>
    </g>
    <g id="g3">
      <path id="path4" d="M 41.102,19.842 H 19.843 v 42.52 h 42.519 v -42.52 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g4">
      <path id="path5" d="M 19.843,70.866 H 68.4" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path6" d="m 68.031,73.7 5.67,-2.834 -5.67,-2.835 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g6">
      <text id="text6" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,26.457333,39.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan6">inline axis</tspan></text>
    </g>
    <g id="g7">
      <path id="path7" d="M 70.866,62.362 V 13.804" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path8" d="m 73.701,14.173 -2.835,-5.67 -2.835,5.67 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g8">
      <text id="text8" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,60.472714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan8">b</tspan></text>
      <text id="text9" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,67.200714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan9">l</tspan></text>
      <text id="text10" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,73.928714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan10">o</tspan></text>
      <text id="text11" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,80.618047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan11">c</tspan></text>
      <text id="text12" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,87.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan12">k</tspan></text>
      <text id="text13" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,100.80071)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan13">a</tspan></text>
      <text id="text14" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,107.52871)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan14">x</tspan></text>
      <text id="text15" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,114.21805)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan15">i</tspan></text>
      <text id="text16" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,104.27733,120.94605)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan16">s</tspan></text>
    </g>
    <g id="g16">
      <path id="path16" d="M 25.512,53.858 H 56.693" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g17">
      <path id="path17" d="M 25.512,45.354 H 56.693" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g18">
      <path id="path18" d="M 25.512,36.85 H 43.228" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path19" d="M 42.661,41.102 48.189,36.85 42.661,32.598 Z" style="fill:#666666;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g19">
      <path id="path20" d="M 120.472,19.842 H 99.213 v 42.52 h 42.519 v -42.52 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g20">
      <path id="path21" d="m 101.679,70.866 h 48.557" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path22" d="m 102.047,68.031 -5.669,2.835 5.669,2.834 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g22">
      <text id="text22" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,132.284,39.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan22">block axis</tspan></text>
    </g>
    <g id="g23">
      <path id="path23" d="M 150.236,62.362 V 13.804" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path24" d="m 153.071,14.173 -2.835,-5.67 -2.834,5.67 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g24">
      <text id="text24" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,60.472714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan24">i</tspan></text>
      <text id="text25" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,67.200714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan25">n</tspan></text>
      <text id="text26" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,73.928714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan26">l</tspan></text>
      <text id="text27" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,80.618047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan27">i</tspan></text>
      <text id="text28" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,87.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan28">n</tspan></text>
      <text id="text29" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,94.072714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan29">e</tspan></text>
      <text id="text30" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,107.52871)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan30">a</tspan></text>
      <text id="text31" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,114.21805)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan31">x</tspan></text>
      <text id="text32" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,120.94605)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan32">i</tspan></text>
      <text id="text33" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,210.104,127.67271)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan33">s</tspan></text>
    </g>
    <g id="g33">
      <path id="path33" d="M 133.228,25.511 V 56.692" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g34">
      <path id="path34" d="M 124.724,56.692 V 25.511" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g35">
      <path id="path35" d="M 116.22,56.692 V 41.81" style="fill:none;stroke:#666666;stroke-width:2.8346;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path36" d="m 120.472,42.377 -4.252,-5.527 -4.251,5.527 z" style="fill:#666666;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g36">
      <path id="path37" d="m 188.957,59.499 h 0.029 c -0.34,0 -0.68,-0.085 -0.964,-0.255 -0.283,-0.171 -0.51,-0.397 -0.68,-0.681 -0.17,-0.283 -0.255,-0.623 -0.255,-0.964 v -10.403 0 c 0,-0.34 0.085,-0.68 0.255,-0.963 0.17,-0.284 0.397,-0.511 0.68,-0.681 0.284,-0.17 0.624,-0.255 0.964,-0.255 h 7.54 v 0 c 0.34,0 0.68,0.085 0.964,0.255 0.283,0.17 0.51,0.397 0.68,0.681 0.17,0.283 0.255,0.623 0.255,0.963 v 10.432 -0.029 0 c 0,0.341 -0.085,0.681 -0.255,0.964 -0.17,0.284 -0.397,0.51 -0.68,0.681 -0.284,0.17 -0.624,0.255 -0.964,0.255 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g37">
      <text id="text37" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,253.60667,78.123381)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan37">1</tspan></text>
    </g>
    <g id="g38">
      <path id="path38" d="m 226.29,59.527 h 0.028 c -0.425,0 -0.85,-0.113 -1.19,-0.312 -0.369,-0.227 -0.652,-0.51 -0.879,-0.879 -0.199,-0.34 -0.312,-0.765 -0.312,-1.19 v -9.439 -0.029 c 0,-0.397 0.113,-0.822 0.312,-1.162 0.227,-0.369 0.51,-0.652 0.879,-0.879 0.34,-0.198 0.765,-0.312 1.19,-0.312 h 9.439 0.029 c 0.397,0 0.822,0.114 1.162,0.312 0.369,0.227 0.652,0.51 0.879,0.879 0.198,0.34 0.312,0.765 0.312,1.162 v 9.496 -0.028 0 c 0,0.425 -0.114,0.85 -0.312,1.19 -0.227,0.369 -0.51,0.652 -0.879,0.879 -0.34,0.199 -0.765,0.312 -1.162,0.312 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g39">
      <text id="text39" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,304.62933,78.086047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan39">3</tspan></text>
    </g>
    <g id="g40">
      <path id="path40" d="m 203.613,59.527 h 0.028 c -0.425,0 -0.85,-0.113 -1.191,-0.312 -0.368,-0.227 -0.652,-0.51 -0.878,-0.879 -0.199,-0.34 -0.312,-0.765 -0.312,-1.19 v -9.439 -0.029 c 0,-0.397 0.113,-0.822 0.312,-1.162 0.226,-0.369 0.51,-0.652 0.878,-0.879 0.341,-0.198 0.766,-0.312 1.191,-0.312 h 15.08 0.029 c 0.396,0 0.822,0.114 1.162,0.312 0.368,0.227 0.652,0.51 0.879,0.879 0.198,0.34 0.311,0.765 0.311,1.162 l -0.028,9.496 0.028,-0.028 v 0 c 0,0.425 -0.113,0.85 -0.311,1.19 -0.227,0.369 -0.511,0.652 -0.879,0.879 -0.34,0.199 -0.766,0.312 -1.162,0.312 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g41">
      <text id="text41" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,278.17333,78.086047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan41">2</tspan></text>
    </g>
    <g id="g42">
      <path id="path42" d="m 184.252,70.866 h 65.565" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path43" d="m 249.449,73.7 5.669,-2.834 -5.669,-2.835 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g43">
      <text id="text43" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,245.66933,39.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan43">main axis</tspan></text>
    </g>
    <g id="g44">
      <path id="path44" d="m 189.439,42.519 h 0.029 c -0.425,0 -0.851,-0.113 -1.191,-0.312 -0.368,-0.226 -0.652,-0.51 -0.879,-0.878 -0.198,-0.341 -0.311,-0.766 -0.311,-1.191 V 30.699 30.67 c 0,-0.397 0.113,-0.822 0.311,-1.162 0.227,-0.368 0.511,-0.652 0.879,-0.879 0.34,-0.198 0.766,-0.311 1.191,-0.311 h 12.274 0.028 c 0.397,0 0.822,0.113 1.162,0.311 0.369,0.227 0.652,0.511 0.879,0.879 0.198,0.34 0.312,0.765 0.312,1.162 v 9.496 -0.028 0 c 0,0.425 -0.114,0.85 -0.312,1.191 -0.227,0.368 -0.51,0.652 -0.879,0.878 -0.34,0.199 -0.765,0.312 -1.162,0.312 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g45">
      <text id="text45" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,257.38533,100.76338)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan45">4</tspan></text>
    </g>
    <g id="g46">
      <path id="path46" d="m 215.433,19.842 h -31.181 v 42.52 h 62.362 v -42.52 z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g47">
      <path id="path47" d="M 255.118,62.362 V 13.804" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
      <path id="path48" d="m 257.953,14.173 -2.835,-5.67 -2.835,5.67 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g48">
      <text id="text48" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,60.472714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan48">c</tspan></text>
      <text id="text49" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,67.200714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan49">r</tspan></text>
      <text id="text50" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,73.928714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan50">o</tspan></text>
      <text id="text51" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,80.618047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan51">s</tspan></text>
      <text id="text52" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,87.346047)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan52">s</tspan></text>
      <text id="text53" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,100.80071)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan53">a</tspan></text>
      <text id="text54" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,107.52871)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan54">x</tspan></text>
      <text id="text55" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,114.21805)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan55">i</tspan></text>
      <text id="text56" xml:space="preserve" transform="matrix(0,1.3333333,-1.3333333,0,349.94667,120.94605)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan56">s</tspan></text>
    </g>
    <g id="g56">
      <text id="text57" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,26.457333,14.816714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan57">text direction (writing-mode)</tspan></text>
    </g>
    <g id="g57">
      <text id="text58" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,245.66933,14.816714)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan58">flexbox direction</tspan></text>
    </g>
    <g id="g58">
      <path id="path58" d="M 14.173,90.708 H 274.961" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
    <g id="g59">
      <path id="path59" d="M 172.913,104.881 V 5.669" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,143.62205)"></path>
    </g>
  </g>
</svg>
<h3 id="on-naming-things">On naming things</h3>
<p>From the names of properties we can infer how CSS is designed:</p>
<ul>
<li><code>align-*</code> is mostly vertical, while
<code>justify-*</code> is mostly horizontal.</li>
<li><code>*-content</code> and <code>*-items</code> control different
levels of objects?</li>
</ul>
<p><code>justify-content</code> is the counterpart of
<code>align-content</code>, which is handy in grid layout but has no
effect in flow layout. The <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/place-content"><code>place-content</code>
shorthand</a> sets both.</p>
<h3 id="align-vs.-justify">“Align” vs.&nbsp;“justify”</h3>

<p>Why do “align” and “justify” refer to axes in CSS? Is
<code>justify-*</code> inspired by text justification? It’s chaotic,
considering there’s also
<code>text-<span>align</span>: <span>justify</span></code>.</p>
<p>Usually when people say “align”, they mean the <em>placement</em> of
a single object, while “justify” means the <em>distribution</em> of
multiple objects.</p>
<p>While in CSS, both <code>justify-*</code> and <code>align-*</code>
are like text justification, because they accept values like
<code>space-between</code>; they just mean different axes!</p>
<p><strong>How to memorize</strong>: Text justification is horizontal,
so is <code>justify-*</code>.</p>
<h3 id="content-vs.-items">“Content” vs.&nbsp;“items”</h3>
<p>In flexbox, “content” and “items” are confusing:</p>
<ul>
<li>Main axis: <code>justify-content</code> controls items, while
<code>justify-items</code> has no effect.</li>
<li>Cross axis: differences between single-line and multi-line
modes.</li>
</ul>
<svg version="1.1" id="svg1" viewBox="0 0 385.51181 128.50394" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg">
  <defs id="defs1">
    <clipPath clipPathUnits="userSpaceOnUse" id="clipPath3">
      <path d="M 0,0.028 H 289.105 V 96.377 L 0,96.377 Z" clip-rule="evenodd" id="path3"></path>
    </clipPath>
  </defs>
  <g id="g1">
    <g id="g2">
      <path id="path2" d="M 0,96.377 H 289.106 V 0.027 H 0 Z" style="fill:#ffffff;fill-opacity:1;fill-rule:evenodd;stroke:none" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)" clip-path="url(#clipPath3)"></path>
    </g>
    <g id="g3">
      <path id="path4" d="M 187.087,96.377 V -0.001" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g4">
      <path id="path5" d="m 214.016,45.353 h -21.26 V 73.7 h 42.52 V 45.353 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g5">
      <path id="path6" d="m 209.764,48.188 h -14.173 v 22.677 h 28.346 V 48.188 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g6">
      <path id="path7" d="M 201.26,70.865 V 48.188" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g7">
      <path id="path8" d="M 209.764,70.865 V 48.188" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g8">
      <path id="path9" d="m 195.591,59.527 h 28.346" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g9">
      <path id="path10" d="m 262.205,45.353 h -21.26 V 73.7 h 42.52 V 45.353 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g10">
      <path id="path11" d="M 266.457,48.188 H 252.283 V 70.865 H 280.63 V 48.188 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g11">
      <path id="path12" d="M 257.953,70.865 V 48.188" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g12">
      <path id="path13" d="M 266.457,70.865 V 48.188" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g13">
      <path id="path14" d="M 252.283,59.527 H 280.63" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g14">
      <path id="path15" d="m 214.016,5.668 h -21.26 v 28.347 h 42.52 V 5.668 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g15">
      <path id="path16" d="M 214.016,8.503 H 195.591 V 31.18 h 36.85 V 8.503 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g16">
      <path id="path17" d="M 215.433,31.18 V 8.503" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g17">
      <path id="path18" d="m 195.591,19.842 h 36.85" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g18">
      <path id="path19" d="m 262.205,5.668 h -21.26 v 28.347 h 42.52 V 5.668 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g19">
      <path id="path20" d="M 262.205,8.503 H 243.78 V 31.18 h 36.85 V 8.503 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g20">
      <path id="path21" d="M 263.622,31.18 V 8.503" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g21">
      <path id="path22" d="m 243.78,19.842 h 36.85" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g22">
      <path id="path23" d="m 199.361,28.346 h 0.028 c -0.17,0 -0.34,-0.057 -0.482,-0.114 -0.142,-0.085 -0.283,-0.227 -0.368,-0.368 -0.057,-0.142 -0.114,-0.312 -0.114,-0.482 v -3.77 -0.029 c 0,-0.141 0.057,-0.312 0.114,-0.453 0.085,-0.142 0.226,-0.284 0.368,-0.369 0.142,-0.056 0.312,-0.113 0.482,-0.113 l 9.439,0.028 0.029,-0.028 c 0.141,0 0.312,0.057 0.453,0.113 0.142,0.085 0.284,0.227 0.369,0.369 0.056,0.141 0.113,0.312 0.113,0.453 v 3.827 -0.028 0 c 0,0.17 -0.057,0.34 -0.113,0.482 -0.085,0.141 -0.227,0.283 -0.369,0.368 -0.141,0.057 -0.312,0.114 -0.453,0.114 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g23">
      <path id="path24" d="m 199.361,17.007 h 0.028 c -0.17,0 -0.34,-0.057 -0.482,-0.113 -0.142,-0.086 -0.283,-0.227 -0.368,-0.369 -0.057,-0.142 -0.114,-0.312 -0.114,-0.482 v -3.77 -0.028 c 0,-0.142 0.057,-0.312 0.114,-0.454 0.085,-0.142 0.226,-0.283 0.368,-0.368 0.142,-0.057 0.312,-0.114 0.482,-0.114 l 6.605,0.029 0.028,-0.029 c 0.142,0 0.312,0.057 0.454,0.114 0.141,0.085 0.283,0.226 0.368,0.368 0.057,0.142 0.113,0.312 0.113,0.454 v 3.826 -0.028 0 c 0,0.17 -0.056,0.34 -0.113,0.482 -0.085,0.142 -0.227,0.283 -0.368,0.369 -0.142,0.056 -0.312,0.113 -0.454,0.113 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g24">
      <path id="path25" d="m 218.721,28.346 h 0.029 c -0.085,0 -0.17,-0.029 -0.256,-0.057 -0.056,-0.057 -0.113,-0.114 -0.17,-0.17 -0.028,-0.085 -0.056,-0.17 -0.056,-0.255 v -4.734 0 c 0,-0.085 0.028,-0.17 0.056,-0.255 0.057,-0.057 0.114,-0.114 0.17,-0.17 0.086,-0.029 0.171,-0.057 0.256,-0.057 h 1.899 v 0 c 0.085,0 0.17,0.028 0.255,0.057 0.057,0.056 0.113,0.113 0.17,0.17 0.028,0.085 0.057,0.17 0.057,0.255 v 4.762 -0.028 0 c 0,0.085 -0.029,0.17 -0.057,0.255 -0.057,0.056 -0.113,0.113 -0.17,0.17 -0.085,0.028 -0.17,0.057 -0.255,0.057 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g25">
      <path id="path26" d="m 219.203,17.007 h 0.028 c -0.17,0 -0.34,-0.057 -0.481,-0.113 -0.142,-0.086 -0.284,-0.227 -0.369,-0.369 -0.057,-0.142 -0.113,-0.312 -0.113,-0.482 v -3.77 -0.028 c 0,-0.142 0.056,-0.312 0.113,-0.454 0.085,-0.142 0.227,-0.283 0.369,-0.368 0.141,-0.057 0.311,-0.114 0.481,-0.114 l 6.605,0.029 0.029,-0.029 c 0.141,0 0.311,0.057 0.453,0.114 0.142,0.085 0.284,0.226 0.369,0.368 0.056,0.142 0.113,0.312 0.113,0.454 v 3.826 -0.028 0 c 0,0.17 -0.057,0.34 -0.113,0.482 -0.085,0.142 -0.227,0.283 -0.369,0.369 -0.142,0.056 -0.312,0.113 -0.453,0.113 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g26">
      <path id="path27" d="m 250.384,28.346 v 0 c -0.141,0 -0.312,-0.057 -0.453,-0.114 -0.142,-0.085 -0.284,-0.227 -0.369,-0.368 -0.056,-0.142 -0.113,-0.312 -0.113,-0.482 v -3.77 -0.029 c 0,-0.141 0.057,-0.312 0.113,-0.453 0.085,-0.142 0.227,-0.284 0.369,-0.369 0.141,-0.056 0.312,-0.113 0.453,-0.113 l 9.468,0.028 0.028,-0.028 c 0.142,0 0.312,0.057 0.454,0.113 0.142,0.085 0.283,0.227 0.368,0.369 0.057,0.141 0.114,0.312 0.114,0.453 v 3.827 -0.028 0 c 0,0.17 -0.057,0.34 -0.114,0.482 -0.085,0.141 -0.226,0.283 -0.368,0.368 -0.142,0.057 -0.312,0.114 -0.454,0.114 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g27">
      <path id="path28" d="m 275.414,28.346 h 0.029 c -0.086,0 -0.171,-0.029 -0.256,-0.057 -0.056,-0.057 -0.113,-0.114 -0.17,-0.17 -0.028,-0.085 -0.056,-0.17 -0.056,-0.255 v -4.734 0 c 0,-0.085 0.028,-0.17 0.056,-0.255 0.057,-0.057 0.114,-0.114 0.17,-0.17 0.085,-0.029 0.17,-0.057 0.256,-0.057 h 1.899 v 0 c 0.085,0 0.17,0.028 0.255,0.057 0.057,0.056 0.113,0.113 0.17,0.17 0.028,0.085 0.057,0.17 0.057,0.255 v 4.762 -0.028 0 c 0,0.085 -0.029,0.17 -0.057,0.255 -0.057,0.056 -0.113,0.113 -0.17,0.17 -0.085,0.028 -0.17,0.057 -0.255,0.057 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g28">
      <path id="path29" d="m 270.227,17.007 h 0.028 c -0.17,0 -0.34,-0.057 -0.482,-0.113 -0.142,-0.086 -0.283,-0.227 -0.368,-0.369 -0.057,-0.142 -0.114,-0.312 -0.114,-0.482 v -3.77 -0.028 c 0,-0.142 0.057,-0.312 0.114,-0.454 0.085,-0.142 0.226,-0.283 0.368,-0.368 0.142,-0.057 0.312,-0.114 0.482,-0.114 l 6.605,0.029 0.028,-0.029 c 0.142,0 0.312,0.057 0.454,0.114 0.141,0.085 0.283,0.226 0.368,0.368 0.057,0.142 0.114,0.312 0.114,0.454 v 3.826 -0.028 0 c 0,0.17 -0.057,0.34 -0.114,0.482 -0.085,0.142 -0.227,0.283 -0.368,0.369 -0.142,0.056 -0.312,0.113 -0.454,0.113 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g29">
      <path id="path30" d="m 253.219,17.007 h 0.028 c -0.17,0 -0.34,-0.057 -0.482,-0.113 -0.141,-0.086 -0.283,-0.227 -0.368,-0.369 -0.057,-0.142 -0.114,-0.312 -0.114,-0.482 v -3.77 -0.028 c 0,-0.142 0.057,-0.312 0.114,-0.454 0.085,-0.142 0.227,-0.283 0.368,-0.368 0.142,-0.057 0.312,-0.114 0.482,-0.114 l 6.605,0.029 0.028,-0.029 c 0.142,0 0.312,0.057 0.454,0.114 0.142,0.085 0.283,0.226 0.368,0.368 0.057,0.142 0.114,0.312 0.114,0.454 v 3.826 -0.028 0 c 0,0.17 -0.057,0.34 -0.114,0.482 -0.085,0.142 -0.226,0.283 -0.368,0.369 -0.142,0.056 -0.312,0.113 -0.454,0.113 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g30">
      <path id="path31" d="M 111.969,45.353 H 90.709 V 73.7 h 42.519 V 45.353 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g31">
      <path id="path32" d="m 94.961,70.865 v 0 c -0.255,0 -0.482,-0.057 -0.709,-0.198 -0.227,-0.114 -0.397,-0.284 -0.51,-0.51 C 93.6,69.93 93.543,69.703 93.543,69.448 V 63.779 63.75 c 0,-0.255 0.057,-0.482 0.199,-0.708 0.113,-0.227 0.283,-0.397 0.51,-0.511 0.227,-0.141 0.454,-0.198 0.709,-0.198 h 5.669 0.028 c 0.255,0 0.482,0.057 0.709,0.198 0.227,0.114 0.397,0.284 0.51,0.511 0.142,0.226 0.199,0.453 0.199,0.708 v 5.698 0 0 c 0,0.255 -0.057,0.482 -0.199,0.709 -0.113,0.226 -0.283,0.396 -0.51,0.51 -0.227,0.141 -0.454,0.198 -0.709,0.198 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g32">
      <path id="path33" d="m 106.299,70.865 v 0 c -0.255,0 -0.482,-0.057 -0.708,-0.198 -0.227,-0.114 -0.397,-0.284 -0.511,-0.51 -0.141,-0.227 -0.198,-0.454 -0.198,-0.709 V 63.779 63.75 c 0,-0.255 0.057,-0.482 0.198,-0.708 0.114,-0.227 0.284,-0.397 0.511,-0.511 0.226,-0.141 0.453,-0.198 0.708,-0.198 h 14.173 0.029 c 0.255,0 0.482,0.057 0.708,0.198 0.227,0.114 0.397,0.284 0.511,0.511 0.141,0.226 0.198,0.453 0.198,0.708 v 5.698 0 0 c 0,0.255 -0.057,0.482 -0.198,0.709 -0.114,0.226 -0.284,0.396 -0.511,0.51 -0.226,0.141 -0.453,0.198 -0.708,0.198 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g33">
      <path id="path34" d="m 95.414,59.527 h 0.029 c -0.341,0 -0.652,-0.085 -0.964,-0.256 -0.284,-0.17 -0.51,-0.396 -0.681,-0.68 -0.17,-0.312 -0.255,-0.623 -0.255,-0.964 v -7.568 0 c 0,-0.34 0.085,-0.652 0.255,-0.964 0.171,-0.283 0.397,-0.51 0.681,-0.68 0.312,-0.17 0.623,-0.255 0.964,-0.255 h 18.907 v 0 c 0.34,0 0.652,0.085 0.963,0.255 0.284,0.17 0.511,0.397 0.681,0.68 0.17,0.312 0.255,0.624 0.255,0.964 v 7.597 -0.029 0 c 0,0.341 -0.085,0.652 -0.255,0.964 -0.17,0.284 -0.397,0.51 -0.681,0.68 -0.311,0.171 -0.623,0.256 -0.963,0.256 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g34">
      <path id="path35" d="M 160.157,45.353 H 138.898 V 73.7 h 42.519 V 45.353 Z" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:3.40152, 2.55114;stroke-dashoffset:0;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g35">
      <path id="path36" d="m 151.654,70.865 v 0 c -0.256,0 -0.482,-0.057 -0.709,-0.198 -0.227,-0.114 -0.397,-0.284 -0.51,-0.51 -0.142,-0.227 -0.199,-0.454 -0.199,-0.709 V 63.779 63.75 c 0,-0.255 0.057,-0.482 0.199,-0.708 0.113,-0.227 0.283,-0.397 0.51,-0.511 0.227,-0.141 0.453,-0.198 0.709,-0.198 h 5.669 0.028 c 0.255,0 0.482,0.057 0.709,0.198 0.227,0.114 0.397,0.284 0.51,0.511 0.142,0.226 0.199,0.453 0.199,0.708 v 5.698 0 0 c 0,0.255 -0.057,0.482 -0.199,0.709 -0.113,0.226 -0.283,0.396 -0.51,0.51 -0.227,0.141 -0.454,0.198 -0.709,0.198 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g36">
      <path id="path37" d="m 162.992,70.865 v 0 c -0.255,0 -0.482,-0.057 -0.709,-0.198 -0.226,-0.114 -0.396,-0.284 -0.51,-0.51 -0.142,-0.227 -0.198,-0.454 -0.198,-0.709 V 63.779 63.75 c 0,-0.255 0.056,-0.482 0.198,-0.708 0.114,-0.227 0.284,-0.397 0.51,-0.511 0.227,-0.141 0.454,-0.198 0.709,-0.198 h 14.173 0.029 c 0.255,0 0.482,0.057 0.708,0.198 0.227,0.114 0.397,0.284 0.511,0.511 0.141,0.226 0.198,0.453 0.198,0.708 v 5.698 0 0 c 0,0.255 -0.057,0.482 -0.198,0.709 -0.114,0.226 -0.284,0.396 -0.511,0.51 -0.226,0.141 -0.453,0.198 -0.708,0.198 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g37">
      <path id="path38" d="m 157.776,59.527 h 0.029 c -0.34,0 -0.652,-0.085 -0.964,-0.256 -0.284,-0.17 -0.51,-0.396 -0.68,-0.68 -0.17,-0.312 -0.255,-0.623 -0.255,-0.964 v -7.568 0 c 0,-0.34 0.085,-0.652 0.255,-0.964 0.17,-0.283 0.396,-0.51 0.68,-0.68 0.312,-0.17 0.624,-0.255 0.964,-0.255 h 18.907 v 0 c 0.34,0 0.652,0.085 0.964,0.255 0.283,0.17 0.51,0.397 0.68,0.68 0.17,0.312 0.255,0.624 0.255,0.964 v 7.597 -0.029 0 c 0,0.341 -0.085,0.652 -0.255,0.964 -0.17,0.284 -0.397,0.51 -0.68,0.68 -0.312,0.171 -0.624,0.256 -0.964,0.256 z" style="fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g38">
      <path id="path39" d="M 85.039,96.377 V -0.001" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g39">
      <path id="path40" d="M 0,79.369 H 289.134" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g40">
      <path id="path41" d="M 0,39.684 H 289.134" style="fill:none;stroke:#000000;stroke-width:0.85038;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" transform="matrix(1.3333333,0,0,-1.3333333,0,128.50394)"></path>
    </g>
    <g id="g41">
      <text id="text41" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,120.94533,14.81727)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan41">flexbox</tspan></text>
    </g>
    <g id="g42">
      <text id="text42" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,4.9893333,53.519937)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan42">justify-content</tspan></text>
    </g>
    <g id="g43">
      <text id="text43" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,4.9893333,106.43327)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan43">justify-items</tspan></text>
    </g>
    <g id="g44">
      <text id="text44" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,257.008,14.81727)"><tspan style="font-variant:normal;font-weight:normal;font-size:10.006px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" y="0" id="tspan44">grid</tspan></text>
    </g>
    <g id="g45">
      <text id="text45" xml:space="preserve" transform="matrix(1.3333333,0,0,1.3333333,172.68667,113.4626)"><tspan style="font-variant:normal;font-weight:normal;font-size:25.994px;font-family:'Ubuntu Mono';writing-mode:lr-tb;fill:#000000;fill-opacity:1;fill-rule:nonzero;stroke:none" x="0" y="0" id="tspan45">?</tspan></text>
    </g>
  </g>
</svg>
<p><strong>Conclusion</strong>: “items” is for stuff that can be aligned
<em>individually</em>. On the main axis, flex items cannot be aligned
individually, so it’s “content”.</p>
<h2 id="why-is-css-so-confusing">Why is CSS so confusing?</h2>
<p>Even if we ignore historical artifacts, CSS is still too confusing
for most of us. It has hundreds of poorly named properties, each can
influence the outcome in unintuitive ways.</p>
<h3 id="software-projects-gone-haywire">Software projects gone
haywire</h3>
<p>This is a case study in software design paradigms:</p>
<ul>
<li>Unix: <strong>orthogonal, composable primitives</strong> that can be
reasoned about independently.</li>
<li>CSS (<a href="https://news.ycombinator.com/item?id=40130549"><strong>C</strong>entral
<strong>S</strong>oftware <strong>S</strong>ystem</a>): just amend the
software with <strong>more and more knobs</strong>.</li>
</ul>
<p>The early WWW was just linked documents. CSS was created to
<em>style</em> documents without regard to <em>layout</em>. Over time,
CSS gained some random layout features without a coherent vision.</p>
<p>Often you have many ways to do something in CSS, but not the right
feature to do it sanely. This entire post is about a new feature for
saner vertical align, and the horizontal axis is still different.</p>
<!-- In CSS, there are no alignment primitives;
vertical and horizontal axes may require different solutions depending on the container layout. -->
<p>In contrast, libreoffice follows the paradigm of orthogonal,
composable primitives:</p>
<ul>
<li>Alignment is unified. No point that vertical is different from
horizontal.</li>
<li>Unified alignment is possible because “align” and “justify” are
orthogonal, not mixed up.
<ul>
<li>“Align” is a property of the <em>container</em>.</li>
<li>“Justify” is a property of the <em>paragraph</em>.</li>
</ul></li>
<li>“Align” and “justify” can be combined in any way.</li>
</ul>


<h3 id="css-mastery-takes-effort">CSS mastery takes effort!</h3>
<p>Still, <strong>rules can be learned</strong>, even for something as
incomprehensible as CSS. You just need to pay extra attention instead of
relying on trial-and-error and copy-pasting. I’m creating a <a href="https://build-your-own.org/visual_css/">visual guide</a> to the hard parts of CSS. Check it
out!</p>
<p><a href="https://build-your-own.org/visual_css/">
  <img width="200" src="https://build-your-own.org/visual_css/img/book_css_cover_1800.png" alt="A Visual Guide To CSS">
</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Expert Mind [pdf] (2006) (109 pts)]]></title>
            <link>https://personal.utdallas.edu/~otoole/CGS2301_S09/15_expert.pdf</link>
            <guid>41282574</guid>
            <pubDate>Sun, 18 Aug 2024 14:24:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://personal.utdallas.edu/~otoole/CGS2301_S09/15_expert.pdf">https://personal.utdallas.edu/~otoole/CGS2301_S09/15_expert.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41282574">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[TomWright/dasel: Select, put and delete data from JSON, TOML, YAML, XML and CSV (293 pts)]]></title>
            <link>https://github.com/TomWright/dasel</link>
            <guid>41282495</guid>
            <pubDate>Sun, 18 Aug 2024 14:11:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TomWright/dasel">https://github.com/TomWright/dasel</a>, See on <a href="https://news.ycombinator.com/item?id=41282495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">dasel</h2><a id="user-content-dasel" aria-label="Permalink: dasel" href="#dasel"></a></p>
<p dir="auto"><a href="https://daseldocs.tomwright.me/" rel="nofollow"><img src="https://camo.githubusercontent.com/74935debba0eb2c6ce3d5b318677865ccc6bd21ee9b365ab8be3e92a5a057045/68747470733a2f2f6261646765732e616c65656e34322e636f6d2f7372632f676974626f6f6b5f312e737667" alt="Gitbook" data-canonical-src="https://badges.aleen42.com/src/gitbook_1.svg"></a>
<a href="https://goreportcard.com/report/github.com/TomWright/dasel/v2" rel="nofollow"><img src="https://camo.githubusercontent.com/053c608060f6014a174ceffdf5aeda709744ca50f48fe6eddb11f608ada5ef01/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f546f6d5772696768742f646173656c2f7632" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/TomWright/dasel/v2"></a>
<a href="https://pkg.go.dev/github.com/tomwright/dasel/v2" rel="nofollow"><img src="https://camo.githubusercontent.com/ff0d25709999ad838c57871cb33da8de2a2d8bc9c6ec31d61409993f4a5e51f8/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f746f6d7772696768742f646173656c" alt="PkgGoDev" data-canonical-src="https://pkg.go.dev/badge/github.com/tomwright/dasel"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/TomWright/dasel/workflows/Test/badge.svg"><img src="https://github.com/TomWright/dasel/workflows/Test/badge.svg" alt="Test"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/TomWright/dasel/workflows/Build/badge.svg"><img src="https://github.com/TomWright/dasel/workflows/Build/badge.svg" alt="Build"></a>
<a href="https://codecov.io/gh/TomWright/dasel" rel="nofollow"><img src="https://camo.githubusercontent.com/00d7b33a9066c396c007a281e508f104666a032ddce2a91dbe0fa60d1900b393/68747470733a2f2f636f6465636f762e696f2f67682f546f6d5772696768742f646173656c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/TomWright/dasel/branch/master/graph/badge.svg"></a>
<a href="https://github.com/avelino/awesome-go"><img src="https://camo.githubusercontent.com/522920003893b259cdbe58547f34408775b7b65bd699e11092999f8019b3cc07/68747470733a2f2f617765736f6d652e72652f6d656e74696f6e65642d62616467652e737667" alt="Mentioned in Awesome Go" data-canonical-src="https://awesome.re/mentioned-badge.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8cd5a8d2dfb97526959ac5aeb704dfdd82c00914774dceca021d8c5e4b47a477/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f546f6d5772696768742f646173656c2f746f74616c"><img src="https://camo.githubusercontent.com/8cd5a8d2dfb97526959ac5aeb704dfdd82c00914774dceca021d8c5e4b47a477/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f546f6d5772696768742f646173656c2f746f74616c" alt="GitHub All Releases Downloads" data-canonical-src="https://img.shields.io/github/downloads/TomWright/dasel/total"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/849994f935fae4543ec782cae31aebd55f084b1395a187eef419898cd8874bce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f546f6d5772696768742f646173656c"><img src="https://camo.githubusercontent.com/849994f935fae4543ec782cae31aebd55f084b1395a187eef419898cd8874bce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f546f6d5772696768742f646173656c" alt="GitHub License" data-canonical-src="https://img.shields.io/github/license/TomWright/dasel"></a>
<a href="https://github.com/TomWright/dasel/releases/latest"><img src="https://camo.githubusercontent.com/bf9f5ced9856fbb06746de1efacfe57f3690bd8da2a0457fc7600a669a76f85b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f7461672f546f6d5772696768742f646173656c3f6c6162656c3d6c617465737425323072656c65617365" alt="GitHub tag (latest by date)" data-canonical-src="https://img.shields.io/github/v/tag/TomWright/dasel?label=latest%20release"></a>
<a href="https://formulae.brew.sh/formula/dasel" rel="nofollow"><img src="https://camo.githubusercontent.com/89b197585198a89659cba53f60b93ba12aa04eb402c8b318af1d5af87aa8e13f/68747470733a2f2f696d672e736869656c64732e696f2f686f6d65627265772f762f646173656c" alt="Homebrew tag (latest by date)" data-canonical-src="https://img.shields.io/homebrew/v/dasel"></a></p>
<p dir="auto">Dasel (short for data-selector) allows you to query and modify data structures using selector strings.</p>
<p dir="auto">Comparable to <a href="https://github.com/stedolan/jq">jq</a> / <a href="https://github.com/kislyuk/yq">yq</a>, but supports JSON, YAML, TOML, XML and CSV with zero runtime dependencies.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">One tool to rule them all</h2><a id="user-content-one-tool-to-rule-them-all" aria-label="Permalink: One tool to rule them all" href="#one-tool-to-rule-them-all"></a></p>
<p dir="auto">Say good bye to learning new tools just to work with a different data format.</p>
<p dir="auto">Dasel uses a standard selector syntax no matter the data format. This means that once you learn how to use dasel you immediately have the ability to query/modify any of the supported data types without any additional tools or effort.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/TomWright/dasel/blob/master/update_kubernetes.gif"><img src="https://github.com/TomWright/dasel/raw/master/update_kubernetes.gif" alt="Update Kubernetes Manifest" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#dasel">Dasel</a></li>
<li><a href="#one-tool-to-rule-them-all">One tool to rule them all</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#completion">Completion</a></li>
<li><a href="#issue-vs-discussion">Issue vs discussion</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#table-of-contents">Table of contents</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#playground">Playground</a></li>
<li><a href="#benchmarks">Benchmarks</a></li>
<li><a href="#pre-commit">Pre-Commit</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Dasel is available on <a href="https://daseldocs.tomwright.me/installation#homebrew" rel="nofollow">homebrew</a>, <a href="https://daseldocs.tomwright.me/installation#asdf" rel="nofollow">ASDF</a>, <a href="https://daseldocs.tomwright.me/installation#scoop" rel="nofollow">scoop</a>, <a href="https://daseldocs.tomwright.me/installation#docker" rel="nofollow">docker</a>, <a href="https://daseldocs.tomwright.me/installation#nix" rel="nofollow">Nix</a> or as <a href="https://daseldocs.tomwright.me/installation#manual" rel="nofollow">compiled binaries</a> from the <a href="https://github.com/TomWright/dasel/releases/latest">latest release</a>.</p>

<p dir="auto">You can also install a <a href="https://daseldocs.tomwright.me/installation#development-version" rel="nofollow">development version</a> with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/tomwright/dasel/v2/cmd/dasel@master"><pre>go install github.com/tomwright/dasel/v2/cmd/dasel@master</pre></div>
<p dir="auto">For more information see the <a href="https://daseldocs.tomwright.me/installation" rel="nofollow">installation documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Select</h3><a id="user-content-select" aria-label="Permalink: Select" href="#select"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="echo '{&quot;name&quot;: &quot;Tom&quot;}' | dasel -r json 'name'
&quot;Tom&quot;"><pre><span>echo</span> <span><span>'</span>{"name": "Tom"}<span>'</span></span> <span>|</span> dasel -r json <span><span>'</span>name<span>'</span></span>
<span><span>"</span>Tom<span>"</span></span></pre></div>
<p dir="auto">See <a href="https://daseldocs.tomwright.me/commands/select" rel="nofollow">select documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Convert json to yaml</h3><a id="user-content-convert-json-to-yaml" aria-label="Permalink: Convert json to yaml" href="#convert-json-to-yaml"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="echo '{&quot;name&quot;: &quot;Tom&quot;}' | dasel -r json -w yaml
name: Tom"><pre><span>echo</span> <span><span>'</span>{"name": "Tom"}<span>'</span></span> <span>|</span> dasel -r json -w yaml
name: Tom</pre></div>
<p dir="auto">See <a href="https://daseldocs.tomwright.me/commands/select" rel="nofollow">select documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Put</h3><a id="user-content-put" aria-label="Permalink: Put" href="#put"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="echo '{&quot;name&quot;: &quot;Tom&quot;}' | dasel put -r json -t string -v 'contact@tomwright.me' 'email'
{
  &quot;email&quot;: &quot;contact@tomwright.me&quot;,
  &quot;name&quot;: &quot;Tom&quot;
}"><pre><span>echo</span> <span><span>'</span>{"name": "Tom"}<span>'</span></span> <span>|</span> dasel put -r json -t string -v <span><span>'</span>contact@tomwright.me<span>'</span></span> <span><span>'</span>email<span>'</span></span>
{
  <span><span>"</span>email<span>"</span></span>: <span><span>"</span>contact@tomwright.me<span>"</span></span>,
  <span><span>"</span>name<span>"</span></span>: <span><span>"</span>Tom<span>"</span></span>
}</pre></div>
<p dir="auto">See <a href="https://daseldocs.tomwright.me/commands/put" rel="nofollow">put documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Delete</h3><a id="user-content-delete" aria-label="Permalink: Delete" href="#delete"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="echo '{
  &quot;email&quot;: &quot;contact@tomwright.me&quot;,
  &quot;name&quot;: &quot;Tom&quot;
}' | dasel delete -r json '.email'
{
  &quot;name&quot;: &quot;Tom&quot;
}"><pre><span>echo</span> <span><span>'</span>{</span>
<span>  "email": "contact@tomwright.me",</span>
<span>  "name": "Tom"</span>
<span>}<span>'</span></span> <span>|</span> dasel delete -r json <span><span>'</span>.email<span>'</span></span>
{
  <span><span>"</span>name<span>"</span></span>: <span><span>"</span>Tom<span>"</span></span>
}</pre></div>
<p dir="auto">See <a href="https://daseldocs.tomwright.me/commands/delete" rel="nofollow">delete documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Completion</h2><a id="user-content-completion" aria-label="Permalink: Completion" href="#completion"></a></p>
<p dir="auto">If you want to use completion from the terminal you can do the following (using zsh in this example):</p>
<p dir="auto">Add the following to <code>~/.zshrc</code> and reload your terminal.</p>
<div dir="auto" data-snippet-clipboard-copy-content="export fpath=(~/zsh/site-functions $fpath)
mkdir -p ~/zsh/site-functions
dasel completion zsh > ~/zsh/site-functions/_dasel
compinit"><pre><span>export</span> fpath=(~/zsh/site-functions <span>$fpath</span>)
mkdir -p <span>~</span>/zsh/site-functions
dasel completion zsh <span>&gt;</span> <span>~</span>/zsh/site-functions/_dasel
compinit</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pre-Commit</h2><a id="user-content-pre-commit" aria-label="Permalink: Pre-Commit" href="#pre-commit"></a></p>
<p dir="auto">Add <code>dasel</code> hooks to <code>.pre-commit-config.yaml</code> file</p>
<div dir="auto" data-snippet-clipboard-copy-content="- repo: https://github.com/TomWright/dasel
  rev: v1.25.1
  hooks:
    - id: dasel-validate"><pre>- <span>repo</span>: <span>https://github.com/TomWright/dasel</span>
  <span>rev</span>: <span>v1.25.1</span>
  <span>hooks</span>:
    - <span>id</span>: <span>dasel-validate</span></pre></div>
<p dir="auto">for a native execution of dasel, or use:</p>
<ul dir="auto">
<li><code>dasel-validate-docker</code> pre-commit hook for executing dasel using the official <a href="https://daseldocs.tomwright.me/installation#docker" rel="nofollow">Docker images</a></li>
<li><code>dasel-validate-bin</code> pre-commit hook for executing dasel using the official <a href="https://daseldocs.tomwright.me/installation" rel="nofollow">binary</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Issue vs Discussion</h2><a id="user-content-issue-vs-discussion" aria-label="Permalink: Issue vs Discussion" href="#issue-vs-discussion"></a></p>
<p dir="auto">I have enabled <a href="https://github.com/TomWright/dasel/discussions">discussions</a> on this repository.</p>
<p dir="auto">I am aware there may be some confusion when deciding where you should communicate when reporting issues, asking questions or raising feature requests so this section aims to help us align on that.</p>
<p dir="auto">Please <a href="https://github.com/TomWright/dasel/issues">raise an issue</a> if:</p>
<ul dir="auto">
<li>You find a bug.</li>
<li>You have a feature request and can clearly describe your request.</li>
</ul>
<p dir="auto">Please <a href="https://github.com/TomWright/dasel/discussions">open a discussion</a> if:</p>
<ul dir="auto">
<li>You have a question.</li>
<li>You're not sure how to achieve something with dasel.</li>
<li>You have an idea but don't quite know how you would like it to work.</li>
<li>You have achieved something cool with dasel and want to show it off.</li>
<li>Anything else!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><a href="https://daseldocs.tomwright.me/commands/select" rel="nofollow">Query/select data from structured data files</a>.</li>
<li><a href="https://daseldocs.tomwright.me/commands/put" rel="nofollow">Update data in structured data files</a>.</li>
<li>Create data files.</li>
<li><a href="https://daseldocs.tomwright.me/supported-file-formats" rel="nofollow">Supports multiple data formats/types</a>.</li>
<li><a href="https://daseldocs.tomwright.me/examples/change-file-format" rel="nofollow">Convert between data formats/types</a>.</li>
<li>Uses a <a href="https://daseldocs.tomwright.me/functions/selector-overview" rel="nofollow">standard query/selector syntax</a> across all data formats.</li>
<li>Zero runtime dependencies.</li>
<li><a href="https://daseldocs.tomwright.me/installation" rel="nofollow">Available on Linux, Mac and Windows</a>.</li>
<li>Available to <a href="https://pkg.go.dev/github.com/tomwright/dasel/v2" rel="nofollow">import and use in your own projects</a>.</li>
<li><a href="https://daseldocs.tomwright.me/installation#docker" rel="nofollow">Run via Docker</a>.</li>
<li><a href="#benchmarks">Faster than jq/yq</a>.</li>
<li><a href="#pre-commit">Pre-commit hooks</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">The official dasel docs can be found at <a href="https://daseldocs.tomwright.me/" rel="nofollow">daseldocs.tomwright.me</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Playground</h2><a id="user-content-playground" aria-label="Permalink: Playground" href="#playground"></a></p>
<p dir="auto">You can test out dasel commands using the <a href="https://dasel.tomwright.me/" rel="nofollow">playground</a>.</p>
<p dir="auto">Source code for the playground can be found at <a href="https://github.com/TomWright/daselplayground">github.com/TomWright/daselplayground</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">In my tests dasel has been up to 3x faster than jq and 15x faster than yq.</p>
<p dir="auto">See the <a href="https://github.com/TomWright/dasel/blob/master/benchmark/README.md">benchmark directory</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/TomWright/dasel" rel="nofollow"><img src="https://camo.githubusercontent.com/241ecdaf4591881c33b0b52437e8d9305552820a91043ceac4a1dfa271c2d23f/68747470733a2f2f7374617263686172742e63632f546f6d5772696768742f646173656c2e737667" alt="Stargazers over time" data-canonical-src="https://starchart.cc/TomWright/dasel.svg"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting back into C programming for CP/M (162 pts)]]></title>
            <link>https://kevinboone.me/cpm-c.html</link>
            <guid>41281665</guid>
            <pubDate>Sun, 18 Aug 2024 11:24:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevinboone.me/cpm-c.html">https://kevinboone.me/cpm-c.html</a>, See on <a href="https://news.ycombinator.com/item?id=41281665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">






<p>
<img src="https://kevinboone.me/img/terminal.png" alt="terminal prompt">
For <a href="https://kevinboone.me/cpm40.html">reasons I've discussed elsewhere</a>, I've
recently become interested in using, and programming, CP/M again,
after an interval of 40 years. I've even bought a real,
Z80-based, CP/M machine to experiment with. There's a small, but
growing, market for these machines among retrocomputing enthusiasts. 
</p>
<p>
I've implemented a number of new utilities for CP/M in C --
see, for example, <a href="https://github.com/kevinboone/KCalc-CPM">KCalc-CPM</a>, <a href="https://github.com/kevinboone/cpmbox">cpmbox</a>,
and <a href="https://github.com/kevinboone/cpmlife">cpmlife</a>.
</p>
<p>
<code>cpmlife</code> was implemented using a modern Z80 cross-compiler,
but I feel that somehow this is cheating. If I'm going to develop for
CP/M, I really ought to use CP/M tools. I might not do all the development
or testing on CP/M -- because it's rather time-consuming -- but
I like to know that it would be <i>possible</i> to maintain my code
entirely under CP/M. 
</p>
<p>
This article is about developing in C for CP/M, using a 40-year-old
C compiler, and how this differs from modern C development.
The compiler I'm using is the 1982 release of Manx Software Systems'
"Aztec C". The compiler is freely, and legally, available from
<a href="https://www.aztecmuseum.ca/compilers.htm#cpm">the Aztec Museum</a>.
A lot of CP/M software falls into the broad category of "abandonware" 
-- software that is notionally still protected by intellectual
propery law, but whose owners have no interest in it, or cannot even
be identified. In the case of Aztec, however, the owners of the
intellectual property, whose claim is not in dispute,
 have stated that they are happy for it to be
distributed and used.
</p>

<h2>About Aztec</h2>
<p>
The Aztec C compiler would have originally be distributed on floppy
disks, and is very small by moden standards. The compiler, assembler,
and linker are each about 20kB in size. The C library and the math 
library are a little larger. 
</p>
<p>
The compiler outputs assembly code, which has to be assembled separately.
Modern C compilers typically can generate assembly code, but this is
usually an internal operation, not visible to the user. The Aztec
C compiler for CP/M actually generates 8080, not Z80, assembly instructions,
so it will work on both CPUs -- the Z80's instruction set is a super-set
of the 8080's. This does mean, however, that the more sophisticated
features of the Z80 instruction set don't get used. There appears to be
a z80-specific compiler in later Aztec releases, but I have never been
able to get it to work. 
</p>
<p>
After the compiler has produced an assembly language ".asm" file, the assembler
converts this to a binary object file. Object files play exactly the
same role here as they do in modern C development, but they are not in any
recognizably modern format. The linker than combines the object
files with the standard library to create an executable.
</p>
<p>
So the sequence of operations for compiling <code>hello.c</code> 
to an executable is:
</p>
<pre>A&gt; cc hello.c
A&gt; as hello.asm
A&gt; ln hello.o c.lib
</pre>

<blockquote><b>Note:</b><br>CP/M is broadly case-insensitive. The text 'hello.c' will be presented to the compiler as 'HELLO.C' regardless of the original case. There's no obvious way to create a lower-case filename on CP/M</blockquote>

<p>
Unless told otherwise, the linker will produce a binary with the
same name as the first of its arguments; in this case, 
<code>hello.com</code>.
</p>

<p>
The Aztec compiler pre-dates ANSI C, and follows the archaic
Kernigan &amp; Ritchie syntax. The most obvious difference from modern
practice is in function declarations:
</p>

<pre><span color="#009900">int</span> <b><span color="#000000">my_function</span></b> <span color="#990000">(</span>a<span color="#990000">,</span> b<span color="#990000">)</span>
<span color="#009900">int</span> a<span color="#990000">;</span> <span color="#009900">char</span> <span color="#990000">*</span>b<span color="#990000">;</span>
  <span color="#FF0000">{</span>
  <span color="#990000">...</span> body <span color="#008080">of</span> function <span color="#990000">...</span>
  <span color="#FF0000">}</span>
</pre>

<p>
Modern C compilers will accept this syntax, which can be useful if you
want to check part of a CP/M C program using modern tools -- more
on this later.
</p>

<p>
Variables must be strictly declared at the start of a block, which
means that each opening brace "{" is typically followed by a slew
of declarations. Modern practice favours putting declarations closer
to where the variables are used. This is particular relevant for
trivial loop control variables. You can't write this:
</p>

<pre><b><span color="#0000FF">for</span></b> <span color="#990000">(</span><span color="#009900">int</span> i <span color="#990000">=</span> <span color="#993399">0</span> i <span color="#990000">&lt;</span> <span color="#993399">10</span><span color="#990000">;</span> i<span color="#990000">++)...</span>
</pre>

<p>
You have to write this:
</p>

<pre><span color="#009900">int</span> i<span color="#990000">;</span>
<span color="#990000">...</span>
<span color="#990000">...</span>
<b><span color="#0000FF">for</span></b> <span color="#990000">(</span>i <span color="#990000">=</span> <span color="#993399">0</span> i <span color="#990000">&lt;</span> <span color="#993399">10</span><span color="#990000">;</span> i<span color="#990000">++)...</span>
</pre>

<p>
This is undeniably a nuisance, but not a huge problem in most cases.
</p>

<p>
A bigger problem is the lack of any <code>const</code> modifier,
either to indicate constant quantities or constant pointers.
This makes compile-time error checking less thorough. I've found that
a lot of mistakes that would be spotted at compile time by a modern
compiler don't get picked up by the CP/M compiler. Of course, this
annoyance has to be considered alongside the fact that the entire 
compiler is only 20kB in size.
</p>

<h2>Function prototypes</h2>
<p>
The Aztec compiler does not support full function prototypes, and trying
to declare them will fail. You <i>must</i> declare the return
value of a function if it is not <code>int</code> and not in the
same file, but you can't declare the arguments. So 
</p>

<pre><span color="#009900">double</span> <b><span color="#000000">my_func</span></b> <span color="#990000">(</span><span color="#009900">double</span> x<span color="#990000">);</span> <i><span color="#9A1900">/* no */</span></i>
<span color="#009900">double</span> <b><span color="#000000">my_func</span></b><span color="#990000">();</span> <i><span color="#9A1900">/* yes */</span></i>
</pre>

<p>
Because the arguments can't be declared, you must use the correct
data type in the function call. So 
</p>

<pre><span color="#009900">double</span> x <span color="#990000">=</span> <b><span color="#000000">my_func</span></b> <span color="#990000">(</span><span color="#993399">10</span><span color="#990000">);</span> <i><span color="#9A1900">/* no */</span></i>
<span color="#009900">double</span> x <span color="#990000">=</span> <b><span color="#000000">my_func</span></b> <span color="#990000">(</span><span color="#993399">10.0</span><span color="#990000">);</span> <i><span color="#9A1900">/* yes */</span></i>
</pre>

<p>
The problem is that, lacking a prototype, the compiler does not know
to treat the literal "10" as the double "10.0". Modern compilers
don't usually have this kind of problem.
</p>

<p>
Becuse I like to be able to test my code with a modern compiler
as well as run it on CP/M, I usually write function prototypes
both ways, with a compiler switch to select which to use:
</p>

<pre><b><span color="#000080">#ifdef</span></b> CPM
<span color="#009900">double</span> <b><span color="#000000">my_func</span></b><span color="#990000">();</span> 
<b><span color="#000080">#else</span></b>
<span color="#009900">double</span> <b><span color="#000000">my_func</span></b> <span color="#990000">(</span><span color="#009900">double</span> x<span color="#990000">);</span> 
<b><span color="#000080">#endif</span></b>
</pre>

<h2>Data type sizes</h2>
<p>
CP/M C compilers generally offer integer data types with smaller ranges
than modern compilers. For example, the Aztec compiler takes an
<code>int</code> to be 16 bits, so its range will be 0-65535 if
unsigned and -32768 to 32768 if signed. 16 bits is a good choice for
the fundamental unit of calculation, as the Z80 CPU has 16-bit
registers that can take part in arithmetic. Still, modern compilers, designed
for contemporary CPUs, usually
take an <code>int</code> to be 32 or 64 bits, and getting used to
the smaller range can be a nuisance.  
</p>
<p>
Because an 8-bit microcomputer typically has a 16-bit address bus,
an <code>int</code> is large enough to store a pointer. Pointer types
are also 16-bit quantities.
</p>
<p>
The Aztec compiler supports a <code>long</code> data type which is
32 bits in size. However, the Z80 CPU has no built-in arithmetic
operations on data types of that size, so 32-bit operations will be
comparatively slow.
</p>
<p>
The compiler has <code>float</code> and <code>double</code> types
which are 32-bit and 64-bit respectively. Double-precision
arithmetic gives about 12 significant figures in practice. Both
types need to be used with care, because all the floating-point
calculations are done by the CPU, and are not particular speedy.
</p>

<h2>Standard library limitations</h2>
<p>
The Aztec standard C library is minimal by modern standards. Most of
the basic file and console I/O functions are present, and a good
set of math functions. We shouldn't expect networking functions, or
selectors, or thread management -- all things that
make no sense in the CP/M world. However, you'll find yourself implementing
your own versions of very basic functions like <code>strdup</code> and
<code>memcpy</code>. These are the kinds of functions that are easy
to implement in very inefficient ways, which wouldn't be noticed with
a modern CPU. You'd likely get away with writing this kind of thing
in a modern C: 
</p>

<pre><b><span color="#0000FF">for</span></b> <span color="#990000">(</span><span color="#009900">int</span> i <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span> i <span color="#990000">&lt;</span> <b><span color="#000000">strlen</span></b> <span color="#990000">(</span>str<span color="#990000">);</span> i<span color="#990000">++)</span> <span color="#FF0000">{</span><span color="#990000">...</span><span color="#FF0000">}</span>
</pre>

<p>
This is bad code, of course, because the <code>strlen()</code> function
will be executed on the same string repeatedly. A modern compiler
will optimize this redundancy away and, even if it can't, modern CPUs
are so fast that it might not even matter. On a Z80, <i>it matters</i>.
All coding requires paying attention to efficiency, but functions that
get called many times are particularly significant.
</p>


<h2>Command line arguments</h2>
<p>
CP/M, in general, is a system in which uppercase and lowercase 
characters are not strongly distinguished. The Aztec C compiler
presents the program with the conventional <code>argc</code> and
<code>argv</code> arguments that represent the command line
-- but they will all be in uppercase, whatever the user actually
enters. That isn't the fault of the compiler -- it's the way the
command line is delivered by the CP/M CCP. Among other things, you
need to be careful about processing command-line switches -- there's
no point using a mixture of upper- and lowercase switches, for example.
</p>
<p>
Unix/Linux programmers will be used to getting command-line
arguments that are "globbed". That is, any filename wild-card characters
on the command line will already have been expanded into a list
of matching files. On CP/M, if you want to be able to handle
arguments like <code>*.txt</code>, you'll have to expand
them yourself. 
</p>
<p>
MSDOS and Windows programmers will be used to doing this, because
their command-line processors follow the CP/M model. Forcing the
program to expand wild-cards allows CP/M to devote only a small
amount of RAM to storing the command line. This was very important
in the days when many desktop computers had memory sizes measured
in kilobytes.
</p>

<h2>Redirection</h2>

<p>
Another way in which programming command-line applications in CP/M 
is different from Unix is that CP/M provides no file redirection facilities.
If the user has to be able to direct program output to a file, e.g., by
running

</p><pre>A&gt; myprog &gt; myfiile.out
</pre>

<p>
then the programmer needs to make this happen. 
</p>
<p>
This task is made easier because the Aztec C library has built-in
support for redirection. When the program starts, the initialization
code parses any redirection tokens on the command line, and sets up
<code>stdin</code>, <code>stdout</code>, and <code>stderr</code> 
accordingly. 
</p>
<p>
Of course, this library-based redirection only applies if you do
input and output using the C library features. If you call
BIOS or BDOS functions directly, the redirection won't apply. That's
the same in Unix, though -- even if output is redirected, you can still
output to the console by writing to <code>/dev/tty</code>, for example.
</p>

<h2>Device I/O</h2>

<p>
This will be relatively familiar to Windows programmers, I think, and
certainly to those us who programmed for MSDOS. At the C level, 
you'd communicate with a device by opening it's pseudo-file. So
to send data to the printer, you'd start with:
</p>

<pre><span color="#008080">FILE</span> <span color="#990000">*</span>f <span color="#990000">=</span> <b><span color="#000000">fopen</span></b> <span color="#990000">(</span><span color="#FF0000">"PRN:"</span><span color="#990000">,</span> <span color="#FF0000">"w"</span><span color="#990000">);</span>
<b><span color="#000000">fprintf</span></b> <span color="#990000">(</span>f<span color="#990000">,</span> <span color="#FF0000">"Something to print..."</span><span color="#990000">);</span>
<span color="#990000">...</span>
</pre>

<p>
You can even write to the paper punch device by opening <code>PUN:</code>
although, since few (if any) CP/M machines ever had a paper punch, I
doubt it will have much effect. Amazingly, <code>PUN:</code> remains
a valid device identifier on Windows. 
</p>

<h2>System interface</h2>

<p>
Although the C compiler's standard library has a good selection of
basic file I/O functions, there's still a lot of functionality missing,
compared to what we'd expect in a modern C library. For example,
there are no built-in functions for enumerating files on a drive.
Aztec C provides functions for calling BDOS and BIOS entry points
directly, which can used in situations like this. To use them,
you do need a good working knowledge of CP/M internals. 
</p>
<p>
For example, here is some code to enumerate all the files on drive
<code>A:</code>. 
</p>

<pre><b><span color="#000080">  #define</span></b> BDOS_DFIRST <span color="#993399">17</span>
<b><span color="#000080">  #define</span></b> BDOS_DNEXT <span color="#993399">18</span>
<b><span color="#000080">  #define</span></b> FCB <span color="#993399">0x005c</span>	
<b><span color="#000080">  #define</span></b> DMABUF <span color="#993399">0x0080</span>	
<b><span color="#000080">  #define</span></b> CHAR_MASK <span color="#993399">0x7F</span>
  
  <span color="#009900">char</span> <span color="#990000">*</span>fcb <span color="#990000">=</span> FCB<span color="#990000">;</span> 
  fcb<span color="#990000">[</span><span color="#993399">0</span><span color="#990000">]</span> <span color="#990000">=</span> <span color="#993399">1</span><span color="#990000">;</span> <i><span color="#9A1900">/* Drive A */</span></i>
  <b><span color="#000000">strcpy</span></b> <span color="#990000">(</span>fcb <span color="#990000">+</span> <span color="#993399">1</span><span color="#990000">,</span> <span color="#FF0000">"???????????"</span><span color="#990000">);</span> <i><span color="#9A1900">/* Match any file */</span></i>

  <b><span color="#0000FF">if</span></b> <span color="#990000">((</span>n <span color="#990000">=</span> <b><span color="#000000">bdos</span></b> <span color="#990000">(</span>BDOS_DFIRST<span color="#990000">,</span> FCB<span color="#990000">))</span> <span color="#990000">==</span> <span color="#993399">255</span><span color="#990000">)...</span> <i><span color="#9A1900">/* Handle error */</span></i> 
  <b><span color="#0000FF">do</span></b>
    <span color="#FF0000">{</span>
    <span color="#009900">char</span> name <span color="#990000">[</span><span color="#993399">12</span><span color="#990000">];</span> 
    <span color="#009900">char</span> <span color="#990000">*</span>fcbbuf <span color="#990000">=</span> DMABUF <span color="#990000">+</span> <span color="#993399">32</span> <span color="#990000">*</span> n<span color="#990000">;</span>

    <b><span color="#0000FF">for</span></b> <span color="#990000">(</span>i <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span> i <span color="#990000">&lt;</span> <span color="#993399">11</span><span color="#990000">;</span> i<span color="#990000">++)</span>
      <span color="#FF0000">{</span>
      name<span color="#990000">[</span>i<span color="#990000">]</span> <span color="#990000">=</span> fcbbuf<span color="#990000">[</span><span color="#993399">1</span> <span color="#990000">+</span> i<span color="#990000">]</span> <span color="#990000">&amp;</span> CHAR_MASK<span color="#990000">;</span>
      <span color="#FF0000">}</span>
    name<span color="#990000">[</span><span color="#993399">11</span><span color="#990000">]</span> <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span>
    <i><span color="#9A1900">/* Process the file called "name" */</span></i>
    <span color="#FF0000">}</span> <b><span color="#0000FF">while</span></b> <span color="#990000">((</span>n<span color="#990000">=</span><b><span color="#000000">bdos</span></b> <span color="#990000">(</span>BDOS_DNEXT<span color="#990000">,</span> FCB<span color="#990000">))</span> <span color="#990000">!=</span> <span color="#993399">255</span><span color="#990000">);</span>  
</pre>

<p>To make sense of this code, you need to understand the following.</p>
<ul>
<li><p>
BDOS file functions work on a <i>file control block</i> (FCB), of which
the programmer typically fills in only the first two fields. 
<code>FCB</code> is a constant that represents the CP/M default
FCB, which is at memory address 0x5C in low memory. The first 
byte in the FCB is the drive number, starting at 1; the next 11
(8 + 3) are the filename, padded with spaces. The drive enumeration
functions will match a pattern; to list all files, we have to supply
the pattern "????????". 
</p></li>
<li><p>
BDOS function 17 reads the first directory entry for the drive, and
returns either 0xFF (error) or a small integer. The small integer
is an offset into the DMA buffer area of memory, starting at 
address 0x80. This is where the results have been written.
</p></li>
<li><p>
The result is another file control block, whose filename field
(starting at byte 1) is the filename from the directory. This
is also padded with spaces. 
</p></li>
<li><p>
BUT... CP/M uses some of the filename characters to indicate
other properties, such as whether the file is read-only. These 
properties are set in bit 7 of the filename bytes, so thist
top bit has to be masked off.
</p></li>
<li><p>
If you want a filename in a non padded format (e.g., <code>foo.txt</code>
rather than <code>FOO     TXT</code>, you'll have to implement that.
It's surprisingly time-consuming to do this kind of data manipulation
on a list of files with a 4MHz CPU.
</p></li>
<li><p>
BDOS function 18 selects the next entry in the directory. Note that
there's no infallible way to distinguish between reaching the end
of the directory, and an error condition. 
</p></li>
</ul>

<p>
I mention all this not just to fill space, but to point out that 
using C rather than assembly language doesn't necessarily take away 
the need to understand CP/M internals fairly well. Happily, you can
bury all this complexity in a library once you've got it working.
</p>



<h2>Calling convention</h2>
<p>
The Aztec compiler uses traditional C argument passing to functions:
the caller places the arguments on the stack, and then takes them
off afterwards. Any return value is returned in the A register,
for an 8-bit value, or the HL register pair for a 16-bit value.
Modern practice favours passing parameters in registers where possible.
This is much, much faster than stack-based argument passing, but 
works better when there are many registers available. The 8080 CPU
only has a total of 7 bytes of register capacity, so not many
arguments could be passed that way. 
</p>
<p>
Using the stack to pass arguments should allow for more, or larger,
arguments. In practice, I've found that passing more than three
<code>long</code> arguments is problematic. I don't know what the
maximum stack size on CP/M -- I would have thought it would be limited
only be available memory. However, I've noticed other indications
of limited stack size. For example, "automatic" (local) variables, 
which are usually stored on the stack, behave badly when they are
more than a few tens of bytes in size.
</p>
<p>
I do not know if this is a defect, or whether there is some specific
setting that has to be used to set the stack size. If it's a defect,
it's highly unlikely to be fixed at this stage. Bear in mind that 
a <code>double</code> value is 8 bytes in size, so I doubt it will be
possible to pass many of these as parameters (but two is definitely OK).
</p>

<h2>Memory management</h2>
<p>
Aztec C provides the usual <code>malloc()</code> and <code>free()</code>
functions, and they work as expected. It's almost certainly faster to
allocate a large amount of memory and then manage it internally, than
it is to make many small allocations. This is largely true with
modern compilers as well. However, it's often convenient to allocate
memory or an as-needed basis and, just as with a modern compiler, the
developer has to work out an acceptable compromise.
</p>
<p>
Conventionally, the program checks the return value from a 
<code>malloc()</code> call to ensure the allocation succeeded. Many
programmers, including myself, have gotten out of the habit of doing
this on modern systems like Linux, because a <code>malloc()</code>
call always succeeds, regardless how much memory is available.
When working on a Z80, though, we need to be much more careful about
this kind of thing.
</p>

<h2>Paging and overlays</h2>
<p>
CP/M systems rarely had more than 64Mb of RAM, and CP/M 2.2
had no concept of paging or virtual memory. As a programmer you
could implement software that required more than the available
RAM by breaking it into segments, but the operating system gave little
help with this. 
</p>
<p>
The Aztec C compiler supports a simple paging mechanism based on a 
technology known in the CP/M world as "overlays". A program consists
of a "base" or "core" segment that remains in memory all the time,
and a number of "overlays" that are loaded from disk as required. 
</p>
<p>
The tooling for compiling and using overlays is built into the 
compiler and C library so, for the programmer, it's pretty straightforward.
Of course, there are subtle problems, like passing data from one
overlay to another, so things aren't trivial. And,
of course, with genuine 80s hardware, reading the overlays from 
disk is fairly slow, so it's a technique that has to be used with care.
</p>

<h2>Building and testing</h2>
<p>
While I think that using modern cross-compilers for CP/M development
is cheating, I have no objection to use real CP/M tools on a modern
CP/M emulator. This is usually much faster, and more convenient, than
working on real 80s technology. But are these approaches really different?
</p>
<p>
It seems to me that, if we're interested in keeping these old technologies
alive and thriving, we should actually be using them. Using a CP/M 
compiler on a CP/M emulator satisfies that objective -- at least to
some extent -- while using modern tools that could never run on CP/M 
does not. At least, that's how it seems to me.
</p>
<p>
Consequently, I'm quite keen that the CP/M software I write is at
least capable of being compiled and linked on 80s hardware. I might not
actually do this very often, but I always check that it's possible
to do so.
</p>
<p>
In any case, you'll need to test the software on real hardware, even
if you build it using an emulator. A modern emulator will run CP/M
applications hundreds of times faster than a real CP/M machine does
natively. As a result, it's all too easy to write very inefficient
code, that seems to work perfectly well on an emulator, but struggles
on real hardware.
</p>
<p>
Here's an example. It's often often convenient, and expressive, to
work with two-dimensional arrays. In that case, you might find yourself
enumerating the complete array like this:
</p>

<pre>  <span color="#009900">int</span> elems<span color="#990000">[</span><span color="#993399">5</span><span color="#990000">][</span><span color="#993399">300</span><span color="#990000">];</span>
  <span color="#990000">...</span>
  <span color="#009900">int</span> i<span color="#990000">,</span> j<span color="#990000">;</span>
  <b><span color="#0000FF">for</span></b> <span color="#990000">(</span>i <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span> i <span color="#990000">&lt;</span> m<span color="#990000">;</span> i<span color="#990000">++)</span>
    <span color="#FF0000">{</span>
    <b><span color="#0000FF">for</span></b> <span color="#990000">(</span>j <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span> j <span color="#990000">&lt;</span> n<span color="#990000">;</span> j<span color="#990000">++)</span>
      <span color="#FF0000">{</span>
      <span color="#009900">int</span> elem <span color="#990000">=</span> elems<span color="#990000">[</span>i<span color="#990000">][</span>j<span color="#990000">];</span>
      <span color="#990000">...</span> process <span color="#008080">the</span> value <span color="#990000">...</span>
      <span color="#FF0000">}</span>
    <span color="#FF0000">}</span>
</pre>

<p>
There's nothing wrong with this code structurally and, if you only 
test it on an emulator, most likely it will work fine. The problem
is the amount of math required to determine the value of 
<code>elems[i][j]</code>. This will require a 16-bit multiplication --
for which there is no hardware support -- and an addition, followed
by an index into memory. This whole process will be repeated 1500 times. 
</p>
<p>
It's hugely faster to consider the array as a single block of data,
and enumerate it by maintaining a single index which gets 
incremented, like this: 
</p>

<pre>  <span color="#009900">int</span> elems<span color="#990000">[</span><span color="#993399">5</span><span color="#990000">][</span><span color="#993399">300</span><span color="#990000">];</span>
  <span color="#990000">...</span>
  <span color="#009900">int</span> <span color="#990000">*</span>_elems <span color="#990000">=</span> <span color="#990000">(</span><span color="#009900">int</span> <span color="#990000">*)</span>elems<span color="#990000">;</span>
  <span color="#009900">int</span> i<span color="#990000">;</span>
  <b><span color="#0000FF">for</span></b> <span color="#990000">(</span>i <span color="#990000">=</span> <span color="#993399">0</span><span color="#990000">;</span> i <span color="#990000">&lt;</span> <span color="#993399">1500</span><span color="#990000">;</span> i<span color="#990000">++)</span> 
    <span color="#FF0000">{</span>
    <span color="#009900">int</span> elem <span color="#990000">=</span> _elems<span color="#990000">[</span>i<span color="#990000">];</span>
    <span color="#990000">...</span> process <span color="#008080">the</span> value <span color="#990000">...</span>
    <span color="#FF0000">}</span>
</pre>

<p>
This strategy is less readable, but it completely eliminates the
need to perform 1500 16-bit multiplications. Of course, this saving
can be made only because we happen to be reading the array
sequentially; sometimes this isn't practicable. However, there's
<i>always</i> a need, when programming for 40-year-old hardware, to think
very carefully about efficiency. We've mostly gotten out of
the habit, because modern compilers can do this sort of optimization
implicitly, and our CPUs are thousands of times faster.
</p>
<p>
This is why testing as often as possible on original hardware is 
so important -- it's just too easy to write inefficient code if you
work too much on an emulator.
</p>
<p>
At the same time, I've found that it's very helpful to be able to
build and run code destined for CP/M on a modern Linux system. I suppose
it would be equally straightforward -- or not -- to run it on Windows.
Modern compilers can do much more extensive compile-time checking and,
at runtime, we can use tools like <code>valgrind</code> to check
for invalid memory references and careless memory management. None of
this is possible under CP/M. I've found that GCC will compile
K&amp;R-style C perfectly well, and anything that Aztec C can compile
can also be compiled by GCC. It might not work, of course -- nothing's
ever that simple. 
</p>
<p>
In practice, you'll probably only be able to unit-test certain parts
of the program on a modern platform, because all the I/O will be
different. Still, even that is an improvement over the testing
it's practicable to do natively on a Z80 system.
</p>

<h2>Closing remarks</h2>

<p>
If you want to write really efficient code for 80s hardware, using an 
80s C compiler is really only one step up from writing assembly language.
The C language is minimal, as is the C library. You'll have to
do all the optimisation yourself, that would be automatic with a modern
compiler. Compile-time error checking is minimal, and you'll still need
to be familiar with the internals of the platform. 
</p>
<p>
But if it were easy, it wouldn't be fun.
</p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the OCaml type checker works (2022) (159 pts)]]></title>
            <link>https://okmij.org/ftp/ML/generalization.html</link>
            <guid>41281555</guid>
            <pubDate>Sun, 18 Aug 2024 10:52:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://okmij.org/ftp/ML/generalization.html">https://okmij.org/ftp/ML/generalization.html</a>, See on <a href="https://news.ycombinator.com/item?id=41281555">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>How OCaml type checker works -- or
what polymorphism and garbage collection have in common</h2>

<div><p>There is more to Hindley-Milner type inference than the Algorithm W.
In 1988, Didier Rémy was looking to speed up the type inference in
Caml and discovered an elegant method of type generalization.
Not only it is fast, avoiding scanning the type environment. It
smoothly extends to catching of locally-declared types about to escape,
to type-checking of universals and existentials, and even to MLF.
</p><p>Alas, both the algorithm and its implementation in the OCaml type
checker are little known and little documented. This page is to
explain and popularize Rémy's algorithm, and to decipher 
a part of the OCaml type checker. The page
also aims to preserve the history of Rémy's algorithm.
</p><p>The attraction of the algorithm is its insight into type
generalization as dependency tracking -- the same sort of tracking
used in automated memory management such as regions and generational
garbage collection. Generalization can be viewed as finding dominators
in the type-annotated abstract syntax tree with edges for shared
types.  Fluet and Morrisett's type system for regions 
use the generalization of a type variable as a
criterion of region containment. Uncannily, Rémy's algorithm views the
region containment as a test if a type variable is generalizable.
</p></div>
<ul>
<li><a href="#introduction">Introduction</a>
</li>
<li><a href="#generalization">Generalization</a>
</li>
<li><a href="#gen-mismanagement">Unsound generalization as memory mismanagement</a>
</li>
<li><a href="#levels">Efficient generalization with levels</a>
</li>
<li><a href="#levels-lazy">Even more efficient level-based generalization</a>
</li>
<li><a href="#regions">Type Regions</a>
</li>
<li><a href="#history">Discovery of levels</a>
</li>
<li>&nbsp;</li>

<li><a href="#levels-OCaml">Generalization with levels in OCaml</a>
</li>
<li><a href="#regions">Type Regions</a>
</li>
<li><a href="#newtvar">Creating fresh type variables</a>
</li>
<li><a href="#gen-in-full">True complexity of generalization</a>
</li></ul>
<hr>


<h2><a name="introduction">Introduction</a></h2>
<dl>
<dd>This page started as notes taken to understand the OCaml type checking
code, which is extensive, complex and hardly documented. Digging
through the code unearthed real gems. One of them&nbsp;-- an efficient and
elegant method of type generalization&nbsp;-- is spotlight here.
<p>OCaml generalization is based on tracking of so-called <em>levels</em> of a
type.  The very same levels also ensure that types defined
within a module do not escape into a wider scope.  Levels hence
enforce the region discipline for locally introduced type
constructors.  It is intriguing how generalization and regions are
handled so uniformly. There are even more applications of levels in
the OCaml type checker, for records with polymorphic fields and
existentials. MetaOCaml indirectly relied on levels to track the scope
of future-stage bindings.  There is a common refrain in all these
applications: tracking dependencies, computing region containment or
dominators in data-dependency graphs. One is immediately reminded of
the region-based memory management by Tofte and Talpin.  As Fluet and
Morrisett showed, Tofte and Talpin type system for regions can be
encoded in System F, relying on universal quantification to statically
prevent allocated data from escaping their region. Dually, the level-based 
generalization relies on detecting escapes of a type variable
to determine its region and hence the place for its universal
quantification.
</p><p>OCaml's generalization is a (partial) implementation of the algorithm
discovered by Didier Rémy back in 1988. The idea is to explicitly
represent the sharing of types in the type-annotated abstract syntax
tree. A type variable can only be quantified at a node that dominates
all occurrences of that variable. Generalization amounts to the incremental
computation of graph dominators. Rémy's MLF is the natural outgrowth of this
idea.
</p><p>Unfortunately, Rémy's generalization algorithm and the underlying
ideas are little known. The implementations, such as the one in OCaml,
do not seem to be documented at all, aside from a couple of brief
puzzling comments in the OCaml source code. They ought to be widely
known.  Towards this goal, the present page sets to (i) motivate and
explain the algorithm, expose its intuitions and sketch
implementations; (ii) help decipher the OCaml type checker.
</p><p>The second part of this page aims to be a commentary on a portion of the OCaml
type-checker, and is, therefore, quite technical. It refers
to OCaml 4.00.1 type checking code, located in the directory
<code>typing/</code> of the OCaml distribution. The file <code>typecore.ml</code> is the
core type checker: it annotates nodes of the abstract syntax tree with
types and the typing environment. To be precise, it transforms
<code>Parsetree</code> (defined in <code>parsing/parsetree.mli</code>) into <code>Typedtree</code>.
The file <code>ctype.ml</code> implements unification and level manipulation
functions.
</p><p>I am indebted to Didier Rémy for his comments, explanations, insights and
recollections of the discovery of the algorithm. I thank Jacques Garrigue
for helpful comments and explanations of more applications of levels within
the OCaml type checker. Additional references 
provided by Matthew Fluet and Baris Aktemur are gratefully
acknowledged.</p></dd>
<dt><strong>Version</strong></dt>
<dd>The current version is February 2013</dd>
<dt><strong>References</strong></dt>
<dd>Didier Rémy:
Extension of ML Type System with a Sorted Equational Theory on Types<br>

Research Report 1766, Institut National de Recherche en Informatique
et Automatique, Rocquencourt, BP 105, 78 153 Le Chesnay
Cedex, France, 1992<br>

&lt;<a href="http://gallium.inria.fr/~remy/ftp/eq-theory-on-types.pdf">http://gallium.inria.fr/~remy/ftp/eq-theory-on-types.pdf</a>&gt;
<p>Matthew Fluet and J. Gregory Morrisett: Monadic Regions<br>

J. Functional Programming, 2006, v16, N4-5, pp. 485-545<br>

The paper shows that parametric polymorphism is all that needed
for a sound type system of memory regions.
</p></dd></dl>



<dl>
<dd>This background section reminds the type generalization in the
Hindley-Milner type system, stressing subtle points and inefficiencies of
the naive implementation. These inefficiencies motivated Rémy's discovery
of the level-based generalization algorithm.
<p>Recall that <em>generalization</em> <code>GEN(G,t)</code> of the type <code>t</code> with respect
to the type environment <code>G</code> is quantifying free type variables of <code>t</code>
that do not occur as free in <code>G</code>. In Greek: <code>GEN(G,t) = ∀ α1 ... αn. t</code> where <code>{α1 ... αn} = FV(t) - FV(G)</code>. In the Hindley-Milner
terminology, this quantification converts a type to a so-called type
schema. Generalization is used in type checking <code>let</code>-expressions:

</p><pre>    G |- e : t    G, (x:GEN(G,t)) |- e2 : t2
    ----------------------------------------
    G |- let x = e in e2 : t2
</pre>That is, the type inferred for the let-bound variable is generalized
when type checking the body of the let-expression.
ML adds a condition
for generalization, so-called value restriction: the let-bound
expression <code>e</code>, by the look of it,
must have no visible side-effects&nbsp;-- technically, <code>e</code> must pass the syntactic
test of being <em>nonexpansive</em>.
OCaml relaxes the value restriction, see later on this page.
<p>Here is a trivial example of generalization:

</p><pre>    fun x -&gt; let y = fun z -&gt; z in y
    (* 'a -&gt; ('b -&gt; 'b) *)
</pre>The type checker infers for <code>fun z -&gt; z</code> the type <code>β-&gt;β</code> with the fresh,
and hence unique, type variable <code>β</code>. 
The expression <code>fun z -&gt; z</code> is syntactically
a value, the generalization proceeds, and <code>y</code> gets
the type <code>∀β.β-&gt;β</code>. Because of the polymorphic type, <code>y</code> may occur in
differently typed contexts&nbsp;-- may be applied to arguments of different 
types,&nbsp;-- as in

<pre>    fun x -&gt; 
      let y = fun z -&gt; z in
      (y 1, y true)
    (* 'a -&gt; int * bool *)
</pre>
<p>Generalization <code>Gen(G,t)</code> quantifies over only those free type variables of <code>t</code>
that do not occur in <code>G</code>. This condition is subtle
but crucial: without it, the unsound type <code>α-&gt;β</code> is inferred for
the function

</p><pre>    fun x -&gt; let y = x in y
</pre>To wit: to infer the function's type, we infer the type of its body
<code>let y = x in y</code>
in the environment in which <code>x:α</code> where <code>α</code> is a fresh type
variable. According to the <code>let</code>-rule above the type inferred for <code>y</code>,
and hence the result type is <code>Gen(x:α,α)</code>. Clearly <code>α</code> does occur in
the environment <code>x:α</code>. If we quantify over it nevertheless, <code>y</code>
receives the polymorphic type <code>∀α.α</code>, which can then be instantiated
to any type. The result is the function that ostensibly converts its
argument to the value of any type whatsoever.
<p>Thus, for each type variable to quantify we must make sure that it
does not occur in the type environment. Naively, we could scan the
type environment looking through the type of each binding -- in fact,
the original Caml did exactly that. The type environment however can
get very large. Typically ML functions contain long sequences of
<code>let</code>-expressions. A non-recursive <code>let</code> has in its type environment
the bindings of all previous <code>let</code>s; the environment of a recursive
<code>let</code> has the bindings of all <code>let</code> siblings.  Scanning the
environment as part of the generalization for a single <code>let</code> takes
time linear in the function size; type checking of the whole
program will be quadratic then. (Except for pathological cases,
Hindley-Milner type inference scales nearly linearly with the program
size.)  The inefficient generalization was one of the main reasons for
the slow speed of Caml compilation, Didier Rémy recalls.
Bootstrapping the compiler and type checking two mutually recursive
functions for compiling patterns and expressions took 20 minutes.
</p><p>There has to be a way to avoid scanning the environment. The 
next section gives the idea.</p></dd></dl>


<h2><a name="gen-mismanagement">Unsound generalization as memory mismanagement</a></h2>
<dl>
<dd>This section begins to introduce the ideas behind Rémy's algorithm,
relating them to region-based memory management. For concreteness we
will be using a toy Hindley-Milner type inferencer. In this section,
the inferencer has the <em>unsound</em> generalization function that
quantifies free type variables in a type with no regard for the
environment.  We type check in detail three simple examples, and
relate the inferring of unsound types with the common problems of
manual memory management: releasing memory still in use. The unsound
generalization will be fixed in the next section, drawing
the inspiration from the standard methods of preventing premature
deallocation of resources.
<p>Although our Hindley-Milner type inferencer is toy, it shares many
implementation decisions (and even some function names) with the real
OCaml type checker. Understanding it will help when we turn to OCaml
internals later on this page.
</p><p>Our toy language is the standard pure lambda-calculus with <code>let</code>.
Its expressions are:

</p><pre>    type exp = 
      | Var of varname                      (* variable                *)
      | App of exp * exp                    (* application: e1 e2      *)
      | Lam of varname * exp                (* abstraction: fun x -&gt; e *)
      | Let of varname * exp * exp          (* let x = e in e2         *)
</pre>Types are comprised of (free or bound) type variables, quantified type variables
and function types:

<pre>    type qname = string
    type typ = 
      | TVar of tv ref               (* type (schematic) variable *)
      | QVar of qname                (* quantified type variable  *)
      | TArrow of typ * typ
    and tv = Unbound of string | Link of typ
</pre>Types with <code>QVar</code> are type schemas; without&nbsp;-- simple types.  Type
schemas, i.e. quantified types, in the Hindley-Milner system are in
the prenex form (that is, universal quantifiers are all outside), and
so the quantifiers need not be represented explicitly.
<p>In the Prolog tradition, type variables are represented as reference cells.
An unbound variable contains the null or the self pointer -- or, in our case,
the name of the variable for easy printing. When a free type variable is
unified with some type <code>t'</code>, the reference cell is overwritten with the
pointer to <code>t'</code>. To prevent cyclical (and, for us, unsound) types,
the `occurs check' is performed first: <code>occurs tv t'</code> traverses <code>t'</code> raising
an exception if it comes across the type variable <code>tv</code>:

</p><pre>    let rec unify : typ -&gt; typ -&gt; unit = fun t1 t2 -&gt;
      if t1 == t2 then ()                   (* t1 and t2 are physically the same *)
      else match (t1,t2) with
      | (TVar {contents = Link t1},t2) 
      | (t1,TVar {contents = Link t2}) -&gt; 
          unify t1 t2
      | (TVar ({contents = Unbound _} as tv),t') 
      | (t',TVar ({contents = Unbound _} as tv)) -&gt; 
          occurs tv t'; tv := Link t'
      | (TArrow (tyl1,tyl2), TArrow (tyr1,tyr2)) -&gt;
          unify tyl1 tyr1;
          unify tyl2 tyr2
      (* everything else is error *)
</pre>
<p>The type checker is completely standard. It infers the type for the
expression <code>exp</code> in the type environment <code>env</code>:

</p><pre>    type env = (varname * typ) list
    let rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function
      | Var x     -&gt; inst (List.assoc x env)
      | Lam (x,e) -&gt; 
          let ty_x = newvar () in
          let ty_e = typeof ((x,ty_x)::env) e in
          TArrow(ty_x,ty_e)
      | App (e1,e2) -&gt;
          let ty_fun = typeof env e1 in
          let ty_arg = typeof env e2 in
          let ty_res = newvar () in
          unify ty_fun (TArrow (ty_arg,ty_res));
          ty_res
      | Let (x,e,e2) -&gt; 
          let ty_e = typeof env e in
          typeof ((x,gen ty_e)::env) e2
</pre>The function <code>newvar</code> allocates a new <code>TVar</code>, with a unique name.
The function <code>inst</code> instantiates a type schema, that is, 
replaces each <code>QVar</code> with a fresh <code>TVar</code>. It is also standard.
The generalization function is unsound: it quantifies all free variables
in the type regardless of the environment:

<pre>    let rec gen : typ -&gt; typ = function      (* unsound! *)
      | TVar {contents = Unbound name} -&gt; QVar name
      | TVar {contents = Link ty}      -&gt; gen ty
      | TArrow (ty1,ty2)               -&gt; TArrow (gen ty1, gen ty2)
      | ty -&gt; ty
</pre>The quantification replaces a <code>TVar</code> with the corresponding <code>QVar</code>.
The original <code>TVar</code> is hence implicitly deallocated: When a free variable is
bound, it `disappears', being replaced by the `pointer' to the binder.
<p>With respect to type variables, <code>typeof</code> allocates free variables,
unifies them, and deallocates, after quantification.
Let us type check simple examples observing the sequence of these
three main operations that affect free type variables. The first example 
is the one where nothing should go wrong:

</p><pre>    fun x -&gt; let y = fun z -&gt; z in y
</pre>The trace of type-checking, showing only type-variable related operations,
is as follows:

<pre>    1    ty_x = newvar ()          (* fun x -&gt; ...               *)
    2      ty_e =                  (* let y = fun z -&gt; z in y    *)
    3         ty_z = newvar ();    (* fun z -&gt; ...               *)
    3         TArrow(ty_z,ty_z)    (* inferred for: fun z -&gt; z   *)
    2      ty_y = gen ty_e         (* ty_z remains free, and so  *)
    2      deallocate ty_z         (* quantified and disposed of *)
    1    TArrow(ty_x, inst ty_y)   (* inferred for: fun x -&gt; ... *)
</pre>The number in the first column is the depth for the recursive invocations
of <code>typeof</code>. Since <code>typeof</code> recurs on each non-leaf node of the abstract
syntax tree (AST), this recursive invocation depth is the depth in the AST
of the node being type checked. The inferred type is <code>'a -&gt; 'b -&gt; 'b</code>,
as expected. Nothing went wrong.
<p>The second example, also seen earlier, is the one for which the unsound
generalization gives the unsound type <code>'a-&gt;'b</code>:

</p><pre>    fun x -&gt; let y = x in y
</pre>Diagramming the <code>TVar</code> operations as before reveals the problem:

<pre>    1    ty_x = newvar ()          (* fun x -&gt; ...                 *)
    2      ty_e =                  (* let y = x in y               *)
    3         inst ty_x            (* inferred for x, same as ty_x *)
    2      ty_y = gen ty_e         (* ty_x remains free, and is    *)
    2      deallocate ty_x         (* quantified, and disposed of  *) 
    1    TArrow(ty_x, inst ty_y)   (* inferred for: fun x -&gt; ...   *)
</pre>The type variable <code>ty_x</code> is part of the return type, used at depth 1&nbsp;--
and yet it is quantified and disposed of at depth 2. We disposed
of the value still in use.
<p>The third example is also problematic. The unsound generalization again
gives the unsound type <code>('a-&gt;'b) -&gt; ('c -&gt;'d)</code>:

</p><pre>    fun x -&gt; let y = fun z -&gt; x z in y
</pre>The diagram shows a memory management problem again:

<pre>    1    ty_x = newvar ()          (* fun x -&gt; ...               *)
    2      ty_e =                  (* let y = ...                *)
    3         ty_z = newvar ()     (* fun z -&gt; ...               *)
    4           ty_res = newvar () (* typechecking: x z          *)
    4           ty_x :=            (* as the result of unify     *)
    4              TArrow (ty_z,ty_res)
    4           ty_res             (* inferred for: x z          *)
    3         TArrow(ty_z,ty_res)  (* inferred for: fun z -&gt; x z *)
    2      ty_y = gen ty_e         (* ty_z, ty_res remain free   *)
    2      deallocate ty_z         (* quantified and disposed of *)
    2      deallocate ty_res       (* quantified and disposed of *)
    1    TArrow(ty_x, inst ty_y)   (* inferred for: fun x -&gt; ... *)
</pre>The type variables <code>ty_z</code> and <code>ty_res</code> are quantified over and
hence disposed of at depth 2, and yet they are part of
<code>TArrow (ty_z,ty_res)</code> that is assigned to <code>ty_x</code>, which, in turn,
is part of the result.
<p>All unsound examples had a `memory management problem', deallocating
memory (<code>TVar</code>) still being used. This is no accident. When a type
variable is quantified over, later on it can be instantiated with any
type whatsoever. However, a type variable that appears in the type
environment cannot be replaced with any type without affecting the
rest of the type checking.  Likewise, when we free a piece of memory,
we give the run-time the permission to reallocate it and overwrite
with arbitrary data.  The rest of our program should not depend on
what happens later with the deallocated memory -- provided it was
really free, not needed further in the program. In fact, one may
define `memory not in use' as arbitrary changes to that memory not
affecting the rest of the program. Deallocating memory still in use
will affect the rest of the program -- often, crash it. Incidentally,
unsound types inferred for our examples often lead to the same result.</p></dd>
<dt><strong>References</strong></dt>
<dd><a href="https://okmij.org/ftp/ML/generalization/unsound.ml">unsound.ml</a>&nbsp;[11K]<br>

Complete code for the toy type inferencer with the unsound
generalization, with many more examples of unsound inference
</dd></dl>


<h2><a name="levels">Efficient generalization with levels</a></h2>
<dl>
<dd>This section continues the exposition of the ideas behind Rémy's
algorithm. Now that we have seen how the unsound generalization
relates to releasing memory still in use, we apply the standard
remedy for premature deallocation&nbsp;-- ownership tracking, or
regions&nbsp;-- and cure the unsound generalization without much
overhead. We develop two algorithms. The simpler one, <code>sound_eager</code>,
is motivated and explained in this section. The optimal
<code>sound_lazy</code>, which captures the main features of the Rémy algorithm,
is presented next.
<p>Clearly, before deallocating memory we must check if it is still in
use.  Naively, we could scan all memory known to be in use looking
for references to the deallocation candidate&nbsp;-- in other words, do the
full garbage-collection marking pass and see if our candidate
got marked. Put this way, the check seems awfully expensive.  At
least we should wait until garbage accumulates, to collect en
masse. Alas, in the Hindley-Milner type system we cannot delay
quantification arbitrarily, since the generalized type may
be used right away.
</p><p>More promising is ownership tracking: associating an allocated resource
with an owner, an object or a function activation. Only the owner may
deallocate its resources. A similar strategy is regions, which are
areas of heap memory created by a lexically-scoped
so-called <code>letregion</code> primitive.  When <code>letregion</code> goes out of scope, its whole
whole region is summarily deallocated. This idea matches the
generalization well. In the Hindley-Milner system, generalization is
always a part of <code>let</code>. A <code>let</code>-expression <code>let x = e in e2</code> is the
natural owner of all type variables allocated when inferring the type
of <code>e</code>. When the type of <code>e</code> is found, all free type variables still
owned by the <code>let</code>-expression can be disposed of, that is, quantified.
</p><p>These intuitions underlie the sound and efficient generalization
algorithms. The first is <code>sound_eager</code>, described in the rest of the
section. Its code differs only in small, but significant, details from
the toy Hindley-Milner inferencer from the previous section. We will
explain only these differences; the complete code is available
below. The main difference is that free type variables, albeit
unbound, are now owned, and refer to their owner. The
owner, always a <code>let</code> expression, is identified by a positive integer
called <em>level</em>. It is the De Bruijn level, or the nesting depth,
of the owing 
<code>let</code>-expression. Level 1 corresponds to the (implicit) top-level
<code>let</code>.  (Incidentally, although both <code>let</code>s in <code>(let x = e1 in eb1, let y = e2 in eb2)</code> have level 2, no confusion can arise as neither
<code>let</code> is in each other scope and hence their regions are disjoint.)
The <code>let</code>-nesting depth is equal to the <code>let</code>-expression's
type checking recursion depth, which is
is simple to determine, with the help of one reference cell.

</p><pre>    type level = int
    let current_level = ref 1
    let enter_level () = incr current_level
    let leave_level () = decr current_level
</pre>The type inferencer maintains the <code>let</code> type-checking depth:

<pre>    let rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function
      ... (* the other cases are the same as before *)
      | Let (x,e,e2) -&gt; 
          enter_level ();
          let ty_e = typeof env e in
          leave_level ();
          typeof ((x,gen ty_e)::env) e2
</pre>The only change to the main type-inference function was adding
<code>enter_level</code> and <code>leave_level</code> to track the level. The rest of <code>typeof</code> is
literally the same as in the original toy version.
<p>Free type variables now carry the level identifying their owner.
A freshly allocated type variable receives the <code>current_level</code>, meaning that
its owner is the latest <code>let</code> being type-checked. (In region-based
memory management, all new memory is allocated in the innermost alive
region.)

</p><pre>    type typ = 
      | TVar of tv ref               (* type (schematic) variable *)
      | QVar of qname                (* quantified type variable *)
      | TArrow of typ * typ
    and tv = Unbound of string * level | Link of typ
   
    let newvar : unit -&gt; typ =
     fun () -&gt; TVar (ref (Unbound (gensym (),!current_level)))
</pre>
<p>Just as an assignment may change the owner of an allocated piece of
memory, unification may change the level of a free type variable. For
example, if <code>ty_x</code> (level 1) and <code>ty_y</code> (level 2) are both free and
<code>ty_x</code> is unified with the type <code>TArrow(ty_y,ty_y)</code>, the arrow type
and its components are exported into region 1, and so the level of
<code>ty_y</code> is changed to 1. One may view the above unification as
replacing all occurrences of <code>ty_x</code> with <code>TArrow(ty_y,ty_y)</code>. Since
<code>t_x</code> has a smaller level and may hence occur outside the inner,
level-2 <code>let</code>, after the bound-expression of that inner
<code>let</code> is type-checked <code>ty_y</code> should not be deallocated.  With the
updated <code>ty_y</code> level, it won't be. All in all, unifying a free type
variable <code>ty_x</code> with <code>t</code> has to update the level of each free type
variable <code>ty_y</code> in <code>t</code> to the smallest of <code>ty_y</code> and <code>ty_x</code>
levels. Unifying a free type variable with <code>t</code> also has to do the
occurs check, which too traverses the type. The two traversals can be
merged. The new <code>occurs</code> does the occurs check and updates the levels:

</p><pre>    let rec occurs : tv ref -&gt; typ -&gt; unit = fun tvr -&gt; function
      | TVar tvr' when tvr == tvr' -&gt; failwith "occurs check"
      | TVar ({contents = Unbound (name,l')} as tv) -&gt;
          let min_level = 
            (match !tvr with Unbound (_,l) -&gt; min l l' | _ -&gt; l') in
          tv := Unbound (name,min_level)
      | TVar {contents = Link ty} -&gt; occurs tvr ty
      | TArrow (t1,t2)            -&gt; occurs tvr t1; occurs tvr t2
      | _ -&gt; ()
</pre>
<p>The only difference from the original <code>occurs</code> code is the second clause
in the pattern-match. The unification code does not have to be modified 
at all. Finally, we fix the generalization function, to make it sound:

</p><pre>    let rec gen : typ -&gt; typ = function
      | TVar {contents = Unbound (name,l)} 
          when l &gt; !current_level -&gt; QVar name
      | TVar {contents = Link ty} -&gt; gen ty
      | TArrow (ty1,ty2) -&gt; TArrow (gen ty1, gen ty2)
      | ty -&gt; ty
</pre>
<p>The change is minimal: the condition <code>when l &gt; !current_level</code>. Recall
the new <code>typeof</code> code:

</p><pre>    let rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function
      ... (* the other cases are the same as before *)
      | Let (x,e,e2) -&gt; 
          enter_level ();
          let ty_e = typeof env e in
          leave_level ();
          typeof ((x,gen ty_e)::env) e2
</pre>It invokes <code>gen</code> after the region established for type checking <code>e</code>
exits. A free type variable still owned by that region will have
the level greater than the current. Since the region is now dead,
any such type variable may be deallocated, that is, quantified.
<p>These are all the changes of <code>sound_eager</code> from the unsound toy algorithm,
which fix the type inference. Here is the old problematic example

</p><pre>    fun x -&gt; let y = x in y
</pre>Diagramming the <code>TVar</code> operations shows no problems now:

<pre>    1  1   ty_x/1 = newvar ()          (* fun x -&gt; ...                 *)
    2  2     ty_e =                    (* let y = x in y               *)
    3  2        inst ty_x/1            (* inferred for x, same as ty_x *)
    2  1     ty_y = gen ty_e           (* ty_x/1 remains free, but is  *)
                                       (* level = current, can't       *)
                                       (* quantify, can't dispose      *)
    1  1   TArrow(ty_x/1, inst ty_y)   (* inferred for: fun x -&gt; ...   *)
</pre>The first column of numbers shows the <code>typeof</code> recursion depth, or the depth
of the AST node being type-checked. The number in the second column is
the <code>current_level</code>, the <code>let</code>-nesting depth. We write the level
of a free type variable after the slash, as in <code>ty_x/1</code>. 
That variable is no longer quantified by <code>gen</code> at depth 2 (level 1)
since <code>ty_x/1</code> belongs to to the current, still active region 1. 
Therefore, the inferred type is <code>'a-&gt;'a</code>, as expected.
<p>In a slightly more complex example,

</p><pre>    fun x -&gt; let y = fun z -&gt; x in y
</pre>the type variable <code>ty_x</code> for the type of <code>x</code> is allocated at level 1,
whereas <code>ty_z</code> is allocated at level 2. After the inner <code>let</code>, region
2, is finished, <code>ty_z/2</code> will be quantified and disposed of, but
<code>ty_x/1</code> will not. The inferred type therefore is <code>'a-&gt;'b-&gt;'a</code>.  The
reader is encouraged to diagram other examples, to check that 
the inferred types are sound.
<p>Level tracking may look like reference counting. However, rather than
counting the number of users for a free type variable, we keep track
of only one user, the one with the widest scope. Level tracking does
look a lot like generational garbage collection: Memory is allocated
in the young generation, and summarily disposed of at minor
(youngest) collection, unless it is `re-parented' or referenced
from the stack. The old generation does not have to be scanned for
references to the new generation, since no such references are
expected&nbsp;-- unless there was an assignment of a (pointer to a) 
young value to a
field of an old data structure. A generational garbage collector
(such OCaml GC) keeps track of young-to-old assignments. At
minor collection, young data referred from the old are promoted to the
old generation. Type generalization indeed looks very similar to the
minor GC collection.
</p></dd>
<dt><strong>References</strong></dt>
<dd><a href="https://okmij.org/ftp/ML/generalization/sound_eager.ml">sound_eager.ml</a>&nbsp;[13K]<br>

The complete code for the toy type inferencer with the <code>sound_eager</code>
generalization, with many more examples of now sound inference
</dd></dl>


<h2><a name="levels-lazy">Even more efficient level-based generalization</a></h2>
<dl>
<dd>This section continues the exposition of the ideas behind Rémy's
algorithm and presents <code>sound_lazy</code>: an optimized version of
<code>sound_eager</code> from the previous section. The <code>sound_lazy</code> algorithm
eschews repeated, unnecessary traversals of a type during unification,
generalization and instantiation, and avoids copying the parts
that do not contain variables to generalize or instantiate, thus
improving sharing. The algorithm delays the occurs check and the level
updates, so that the unification with a free type variable takes
constant time. Levels are updated incrementally and on demand. All in
all, <code>sound_lazy</code> embodies the main ideas of Rémy's algorithm. Some of
these ideas are implemented in the OCaml type checker.
<p>To carry on the optimizations, we change the syntax of types. Recall
that in <code>sound_eager</code>, types were comprised of free or bound type
variables <code>TVar</code>, (implicitly universally) quantified type variables
<code>QVar</code> and function types <code>TArrow</code>. The first, seemingly unprincipled
change, is to eliminate <code>QVar</code> as a distinct alternative and dedicate
a very large positive integer -- which should be treated as the
inaccessible ordinal ω&nbsp;-- as a <code>generic_level</code>.  A free type variable
<code>TVar</code> at <code>generic_level</code> is taken to be a quantified type
variable. More substantially, all types, not only free type variables,
have levels now. The level of a composite type (<code>TArrow</code> in our case)
is an upper, not necessarily exact, bound on the levels of its
components. In other words, if a type belongs to an alive region, all
its components should be alive.  It immediately follows that if a
(composite) type is at <code>generic_level</code>, it may contain quantified type
variables.  Contrapositively, if a type is not at <code>generic_level</code>, it
does not contain any quantified variable. Therefore, instantiating
such a type should return the type as it is without traversing
it. Likewise, if the level of a type is greater than the current
level, it may contain free type variables to generalize. On the other
hand, the generalization function should not even bother traversing a
type whose level is equal or less than the current. This is the first
example of how levels help eliminate excessive traversals and
rebuildings of a type, improving sharing.
</p><p>Unifying a type with a free type variable should update the type's level
to the level of the type variable if the latter level is smaller. For a
composite type, such an update means recursively updating the 
levels of all components of the type. To postpone costly traversals, we 
give composite types two levels: <code>level_old</code> is an upper
bound on the levels of type's components; <code>level_new</code>, which is less or
equal to <code>level_old</code>, is the level the type should have after the update.
If <code>level_new &lt; level_old</code>, the type has pending level updates. The
syntax of types in <code>sound_lazy</code> is thus

</p><pre>    type level = int
    let generic_level = 100000000           (* as in OCaml typing/btype.ml *)
    let marked_level  = -1                  (* for marking a node, to check*)
                                            (* for cycles                  *)
    type typ = 
      | TVar of tv ref
      | TArrow of typ * typ * levels
    and tv = Unbound of string * level | Link of typ
    and levels = {mutable level_old : level; mutable level_new : level}
</pre>
<p>We have not explained <code>marked_level</code>. The occurs check on each
unification with a free type variable is expensive, raising the
algorithmic complexity of the unification and type checking. We now
postpone this check, until the whole expression is type checked. In
the meanwhile, unification may create cycles in types. Type traversals
have to check for cycles, or risk divergence. The <code>marked_level</code> is
assigned temporarily to <code>level_new</code> of a composite type to indicate
the type is being traversed. Encountering <code>marked_level</code> during a
traversal means detecting a cycle, which raises the occurs check
error. Incidentally, in OCaml types are generally cyclic:
(equi-)recursive types arise when type checking objects and
polymorphic variants, and when the <code>-rectypes</code> compiler option is set.  The
OCaml type checker uses a similar marked-level trick to detect cycles
and avoid divergence.
</p><p>The <code>sound_lazy</code> unification has several important differences 
from <code>sound_eager</code>:

</p><pre>    let rec unify : typ -&gt; typ -&gt; unit = fun t1 t2 -&gt;
      if t1 == t2 then ()                   (* t1 and t2 are physically the same *)
      else match (repr t1,repr t2) with
      | (TVar ({contents = Unbound (_,l1)} as tv1) as t1,      (* unify two free vars *)
        (TVar ({contents = Unbound (_,l2)} as tv2) as t2)) -&gt;
         if tv1 == tv2 then ()             (* the same variable *)
         else
           if l1 &gt; l2 then tv1 := Link t2 else tv2 := Link t1  (* bind the higher-level var *)
      | (TVar ({contents = Unbound (_,l)} as tv),t')
      | (t',TVar ({contents = Unbound (_,l)} as tv)) -&gt; 
          update_level l t';
          tv := Link t'
      | (TArrow (tyl1,tyl2,ll), TArrow (tyr1,tyr2,lr)) -&gt;
          if ll.level_new = marked_level || lr.level_new = marked_level then
            failwith "cycle: occurs check";
          let min_level = min ll.level_new lr.level_new in
          ll.level_new &lt;- marked_level; lr.level_new &lt;- marked_level;
          unify_lev min_level tyl1 tyr1;
          unify_lev min_level tyl2 tyr2;
          ll.level_new &lt;- min_level; lr.level_new &lt;- min_level
      (* everything else is the unification error *)
   
    and unify_lev l ty1 ty2 =
      let ty1 = repr ty1 in
      update_level l ty1;
      unify ty1 ty2
</pre>where the auxiliary <code>repr</code>, like OCaml's <code>Btype.repr</code>, chases links of
bound variables returning a free variable or a constructed type.
Unlike OCaml, we do path compression.  The unification function no
longer does the occurs check; therefore, it has to make an effort to
detect accidentally created cycles. Unifying with a free variable now
takes constant time, to bind the variable after a shallow
<code>update_level</code>.
<p>The function <code>update_level</code> is one of the key parts of the optimized
algorithm. Often, it merely promises to update the level of a type to 
the given level. It works in
constant time and maintains the invariant that a type level may
only decrease. The level of a type variable is updated immediately.
For a composite type, <code>level_new</code> is
set to the desired new level if the latter is smaller. In
addition, if previously <code>level_new</code> and <code>level_old</code> were the same, the
type is put into the <code>to_be_level_adjusted</code> queue for later 
update of the levels of the components. This work queue is akin to
the list of assignments into the old generation from the young
maintained by a generational garbage collector (such as the one in
OCaml). 

</p><pre>    let to_be_level_adjusted = ref []
   
    let update_level : level -&gt; typ -&gt; unit = fun l -&gt; function
      | TVar ({contents = Unbound (n,l')} as tvr) -&gt; 
          assert (not (l' = generic_level));
          if l &lt; l' then
            tvr := Unbound (n,l)
      | TArrow (_,_,ls) as ty -&gt; 
          assert (not (ls.level_new = generic_level));
          if ls.level_new = marked_level then failwith "occurs check";
          if l &lt; ls.level_new then begin
            if ls.level_new = ls.level_old then
              to_be_level_adjusted := ty :: !to_be_level_adjusted;
            ls.level_new &lt;- l
          end
      | _ -&gt; assert false
</pre>
<p>The pending level updates must be performed before generalization:
After all, a pending update may decrease the level of a type variable,
promoting it to a wider region and hence saving it from
quantification. Not all pending updates have to be forced however --
only of those types whose <code>level_old &gt; current_level</code>. Otherwise, a
type contains no variables generalizable at the present point, and the
level update may be delayed further. The described forcing algorithm
is implemented by <code>force_delayed_adjustments</code>, see the source
code. Incidentally, if a level update of a composite type (<code>TArrow</code>)
has to be really performed, the type has to be traversed.  Unification
of two <code>TArrow</code> types also has to traverse them. Therefore,
unification could, in principle, also update the levels along the
way. That optimization is not currently implemented, however.
</p><p>The generalization function searches for free <code>TVar</code>s that belong to a
dead region (that is, whose level is greater than the current) and
sets their level to <code>generic_level</code>, hence quantifying the
variables. The function traverses only those parts of the type that
may contain type variables to generalize. If a type has the (new)
level of <code>current_level</code> or smaller, all its components belong to live
regions and hence the type has nothing to generalize.  After the
generalization, a composite type receives <code>generic_level</code> if it
contains a quantified type variable. Later on, the instantiation
function will, therefore, only look through those types whose
level is <code>generic_level</code>.

</p><pre>    let gen : typ -&gt; unit = fun ty -&gt;
      force_delayed_adjustments ();
      let rec loop ty =
        match repr ty with
        | TVar ({contents = Unbound (name,l)} as tvr)
               when l &gt; !current_level -&gt;
          tvr := Unbound (name,generic_level)
        | TArrow (ty1,ty2,ls) when ls.level_new &gt; !current_level -&gt;
          let ty1 = repr ty1 and ty2 = repr ty2 in
          loop ty1; loop ty2;
          let l = max (get_level ty1) (get_level ty2) in
          ls.level_old &lt;- l; ls.level_new &lt;- l   (* set the exact level upper bound *)
        | _ -&gt; ()
      in loop ty
</pre>
<p>The type checker <code>typeof</code> remains the same, entering a new region when
type checking a <code>let</code> expression. Please see the source code for details.
</p><p>We have presented the optimized <code>sound_lazy</code> type generalization algorithm
that avoids not only scanning the whole type environment on each
generalization, but also the occurs check on each
unification with a free type variable. In the result, unification takes
constant time. The algorithm eliminates unnecessary type traversals
and copying, saving time and memory.  Two ideas underlie the
optimizations, besides the type levels for free type variables. First
is the assigning of levels to composite types, to give us an idea what
a type may contain without looking though it. The second principle is
delaying expensive actions (type traversals) with the hope they will
get done in the future alongside of something else. In other words, if
dealing with a problem is postponed long enough, it may go away:
procrastination sometimes helps.</p></dd>
<dt><strong>References</strong></dt>
<dd><a href="https://okmij.org/ftp/ML/generalization/sound_lazy.ml">sound_lazy.ml</a>&nbsp;[20K]<br>

The complete code for the optimized toy type inferencer,
again with many examples
</dd></dl>


<h2><a name="levels-OCaml">Generalization with levels in OCaml</a></h2>
<dl>
<dd>This OCaml internals section describes the implementation of
the type levels in the OCaml type checker and their application for 
efficient generalization. The next section shows how the levels
help prevent escapes of local types and type check existentials.
<p>The ideas behind the type generalization in OCaml have been presented in the
previous sections, in the form of the toy algorithms <code>sound_eager</code> and
<code>sound_lazy</code>. Their code has been intentionally written to 
resemble the OCaml type checker, often using the same function names.
The OCaml type checker implements the <code>sound_eager</code>
algorithm with a few optimizations from <code>sound_lazy</code>. OCaml is far
more complicated: whereas unification in the toy code takes just
a few lines, the OCaml unification code, in <code>ctype.ml</code>, takes
1634 lines. Nevertheless, understanding the toy algorithms should help
in deciphering the OCaml type checker.
</p><p>Like the <code>sound_eager</code> algorithm, the OCaml type checker does the
occurs check and the levels update on each unification with a free
variable; one can clearly see that from the code of <code>Ctype.unify_var</code>.
On the other hand, like in <code>sound_lazy</code>, the OCaml type checker
assigns levels to all types, not only to type variables -- see
<code>type_expr</code> in <code>types.mli</code>. One reason is to detect escaping local
type constructors (described in the next section).  Also like in
<code>sound_lazy</code>, <code>generic_level</code> distinguishes quantified type variables
and the types that may contain quantified variables (so-called
`generic types').  Therefore, the schema instantiation function
<code>Ctype.instance</code> and <code>Ctype.copy</code> will not traverse and copy
non-generic parts of a type, returning them as they are, which
improves sharing.  Type variables at <code>generic_level</code> are printed like
<code>'a</code>; with other levels, as <code>'_a</code>.  As in
our toy algorithms, a mutable global <code>Ctype.current_level</code> tracks the
current level, which is assigned to newly created types or type
variables (see <code>Ctype.newty</code> and <code>Ctype.newvar</code>). The <code>current_level</code>
is increased by <code>enter_def()</code> and decreased by <code>end_def()</code>.  Besides
the <code>current_level</code>, there is also <code>nongen_level</code>, used when type
checking a class definition, and <code>global_level</code> used for type
variables in type declarations.
</p><p>A very simplified code for type-checking <code>let x = e in body</code> is 
as follows.

</p><pre>    let e_typed =
      enter_def ();
      let r = type_check env e_source in
      end_def (); 
      r
    in
    generalize e_typed.exp_type;
    let new_env = bind env x e_typed.exp_type in
    type_check new_env body_source
</pre>Here, <code>e_source</code> is the abstract syntax tree, or
<code>Parsetree.expression</code> for the expression <code>e</code> and <code>e_typed</code> is the
<code>Typedtree.expression</code>, the abstract syntax tree in which each node is
annotated with its inferred type, the field <code>exp_type</code>.
<p>Thus the overall type generalization pattern, 
often seen in the OCaml type checker, is

</p><pre>    let ty =
        enter_def ();
        let r = ... let tv = newvar() in ... (... tv ...)
        end_def ();
        r in
    generalize ty
</pre>
<p>If <code>tv</code> was not unified with something that existed in the environment
before <code>enter_def()</code>, the variable will be generalized. The code looks
quite like our toy code.
</p><p>Interestingly, levels have another use, enforcing the region 
discipline for local type declarations.</p></dd></dl>


<h2><a name="regions">Type Regions</a></h2>
<dl>
<dd>The OCaml type checker relies on type levels also to check that
types are not used before being declared and that locally introduced
types do not escape into a wider scope. Unification, akin to assignment, 
facilitates both mischiefs. We have seen how type levels are
related to region-based memory management. It is not surprising then
that the levels help rein in the unification, preventing resource 
mismanagement -- this time, not with type variables but with type constants.
<p>OCaml, unlike SML, supports local modules, or modules defined in
local scope, via the <code>let module</code> form. A local module may declare a type,
and may even let this type escape, as in

</p><pre>    let y =
      let module M = struct 
            type t = Foo 
            let x = Foo 
          end 
      in M.x
         ^^^
    Error: This expression has type M.t but an expression was expected of type 'a
           The type constructor M.t would escape its scope
</pre>Such an escape must be flagged as an error. Otherwise, 
<code>y</code> will receive the type <code>M.t</code> where
<code>M.t</code> and even <code>M</code> are not in scope where <code>y</code> is. This problem is
akin to returning the address of an automatic local variable from 
a C function:

<pre>    char * esc_res(void)
    {
      char str [] = "local string";
      return str;
    }
</pre>A locally declared type can escape not only through the result type but also by
unification with an existing type variable:

<pre>    fun y -&gt; 
      let module M = struct 
            type t = Foo 
            let r = y Foo 
          end 
      in ()
                      ^^^
    Error: This expression has type t but an expression was expected of type 'a
           The type constructor t would escape its scope
</pre>This sort of error is also familiar to C programmers:

<pre>    char * y = (char*)0;
    void esc_ext(void)
    {
      char str [] = "local string";
      y = str;
    }
</pre>
<p>Even top-level modules have type
escaping problems. Here is the example taken from a comment in the OCaml
type checker:

</p><pre>    let x = ref []
    module M = struct 
       type t 
       let _ = (x : t list ref)
    end
</pre>The variable <code>x</code> has the non-generic type <code>'_a list ref</code>. 
The module <code>M</code> defines the local type <code>t</code>. 
The type attribution causes <code>x</code>,
defined prior to <code>t</code>, to have the type <code>x : t list ref</code>.
It looks like <code>t</code> is used before defined.
Such type escaping may occur even without modules, as pointed by
Jacques Garrigue:

<pre>    let r = ref []
    type t = Foo
    let () = r := [Foo]
                   ^^^
    Error: This expression has type t but an expression was expected of type 'weak1
           The type constructor t would escape its scope
</pre>OCaml cannot
let such escapes go uncaught. Under no circumstances a type
constructor may be used outside the scope of its declaration. Type
levels enforce this region-like discipline for type constructors.
<p>The OCaml type checker already supports regions for the sake of type
generalization, providing operations <code>begin_def</code> for entering and
<code>end_def</code> for exiting (destroying) a new region, associating types to
their owner region, and tracking ownership changes during
unification. What remains is to make a type declaration enter a new
region and to associate the declared type constructor with this
region. Any type in which this type constructor appears must belong to
a region within the type declaration region: the declaration of a type
constructor must dominate all its uses.
</p><p>As explained earlier, type regions are identified by a positive
integer, type level: the nesting depth of the region. Each type has
the field <code>level</code> with the level of its owner region. Type
constructors would need a similar level annotation. It turns out, a
different facility of OCaml serves exactly this purpose. Type
constructors, data constructors, term variables may be re-defined
within an OCaml program: a type can be re-declared, a variable can be
rebound several times.  OCaml relies on <em>identifiers</em> (see <code>ident.ml</code>)
to distinguish among differently declared or bound occurrences of the
same name. An identifier has the name and the timestamp, a positive
number. The global mutable <code>Ident.currentstamp</code> keeps the `current
time' and advances it when a new identifier is created, by a
declaration or a binding. The timestamp of the identifier is thus its
binding time. The binding time is the natural way to relate an
identifier to a type region. If the current time is set to the current
level, new identifiers will have their binding time not smaller than
the current level: they will be regarded as owned by the current type
region. Non-escaping then means that the level of a type is no less
than the binding time of each type constructor within the type.
</p><p>Unification, specifically, unification with a free type
variable&nbsp;-- akin to assignment&nbsp;-- may change the ownership of a type,
and so has to update the type level accordingly. It can also check, at
the same time, that the non-escaping property still holds: see
<code>Ctype.update_level</code>.
</p><p>We can now understand the OCaml code for type checking a local module,
the expression <code>let module name = modl in body</code>, excerpted below
from <code>typecore.ml</code>.

</p><pre>    | Pexp_letmodule(name, smodl, sbody) -&gt;
        let ty = newvar() in
        (* remember the original level *)
        begin_def ();
        Ident.set_current_time ty.level;
        let context = Typetexp.narrow () in
        let modl = !type_module env smodl in
        let (id, new_env) = Env.enter_module name.txt modl.mod_type env in
        Ctype.init_def(Ident.current_time());
        Typetexp.widen context;
        let body = type_expect new_env sbody ty_expected in
        (* go back to original level *)
        end_def ();
        (* Check that the local types declared in modl don't escape
           through the return type of body
        *)
        begin try
          Ctype.unify_var new_env ty body.exp_type
        with Unify _ -&gt;
          raise(Error(loc, Scoping_let_module(name.txt, body.exp_type)))
        end;
        re {
          exp_desc = Texp_letmodule(id, name, modl, body);
          exp_loc = loc; exp_extra = [];
          exp_type = ty;
          exp_env = env }
</pre>
<p>The type variable <code>ty</code> is created to receive the inferred type
of the expression. The variable is created in the current region. After
that, a new type region is entered, by <code>begin_def()</code>, and the
identifier timestamp clock is set to correspond to the new <code>current_level</code>.
(The timestamp clock is advanced right before a new identifier is
created. That's why <code>Ident.set_current_time</code> receives <code>ty.level</code> rather
than the incremented <code>current_level</code> as the argument.) 
Any type constructor declared within the the local module
will hence have the binding time of <code>current_level</code> or higher.
<code>Ctype.init_def(Ident.current_time())</code> sets the type level to be
the binding time of the last identifier of the local module. Therefore, all
fresh types created afterwards, when type checking the <code>body</code>,
will have the level greater or equal than the binding time of 
any local module's type constructor. The unification will watch
that any level update preserve the invariant. Finally, the
unification with <code>ty</code> at the very end (whose region, recall, is outside
the <code>let module</code>'s region) will make sure than none of the local
type constructors escape through the return type.
</p><p>Incidentally, <code>Typetexp.narrow ()</code> and <code>Typetexp.widen context</code>
in the above code establish a new context for type variables within
the local module. That's why

</p><pre>    fun (x:'a) -&gt; let module M = struct let g (x:'a) = x end in M.g
</pre>has the inferred type <code>'a -&gt; 'b -&gt; 'b</code> rather than <code>'a -&gt; 'a -&gt; 'a</code>. The two
occurrences of <code>'a</code> in the above code are the distinct type variables. A local
module shares none of its type variables with the surrounding.
<p>Existential types are quite like the types declared in local modules:
in fact, existentials can be implemented with first-class local modules.
Therefore, checking that types created by pattern-matching on
(or, opening of) an existential do not escape the pattern-matching
clause uses the same technique: see <code>Typecore.type_cases</code>.</p></dd></dl>


<h2><a name="history">Discovery of levels</a></h2>
<dl>
<dd>Didier Rémy has discovered the type generalization algorithm based on
levels when working on his Ph.D. on type inference of records and
variants. (Incidentally, he calls 'levels' ranks&nbsp;-- alas, 'levels' is
the term now used in the OCaml type checker.) He prototyped his record
inference in the original Caml (Categorical Abstract Machine
Language), which was written in Caml itself and ran on the top of Le
Lisp.  That was before Caml Light let alone OCaml. He had to recompile
Caml frequently, which took a long time. As he says, the type
inference of Caml was the bottleneck: ``The heart of the compiler code
were two mutually recursive functions for compiling expressions and
patterns, a few hundred lines of code together, but taking around 20
minutes to type check!  This file alone was taking an abnormal
proportion of the bootstrap cycle.  This was at the time when
recompiling fonts in LaTeX would also take forever, so I think we were
used to scheduling such heavy tasks before coffee breaks&nbsp;-- or the
other way round.''  The type inference in Caml was slow for several
reasons. First, the instantiation of a type schema would create a new
copy of the entire type&nbsp;-- even of the parts without quantified
variables, which can be shared instead. Doing the occurs check on
every unification of a free type variable (as in our eager toy
algorithm), and scanning the whole type environment on each
generalization increase the time complexity of inference.
<p>Didier Rémy resolved to speed up the process. He says:

</p><blockquote>
<div><p>``So, when I wrote my prototype for type checking records and variants (which,
being structural, tend to be much larger then usual ML types), I was very
careful to stay close to the theory in terms of complexity.

</p><ul>
<li>I implemented unification on graphs in <code>O(n log n)</code>---doing path
compression and postponing the occurs-check;
</li>
<li>I kept the sharing introduced in types all the way down without breaking
it during generalization/instantiation;
</li>
<li>finally, I introduced the rank-based type generalization.''
</li></ul></div></blockquote>This efficient type inference algorithm was described in Rémy's PhD
dissertation (in French) and in the 1992 technical report.  The
<code>sound_lazy</code> algorithm explained earlier was a very simple model of
Rémy's algorithm, representing its main features.  Xavier Leroy
implemented the type levels and the level-based generalization in
Caml-Light. However, for various reasons he implemented the version
akin to <code>sound_eager</code>, with the occurs check on each binding of a free
type variable.
<p>Didier Rémy prefers to view ranks, or levels, in terms of graphs. If
we add to the abstract syntax tree type annotations on each node,
edges for shared types and edges from a quantified variable to its
quantifier, we obtain a graph. The level of a free type variable can
be thought of as the De Bruijn level&nbsp;-- the pointer to the AST node that
will quantify the type variable. That AST node must be a <code>let</code> node,
in the Hindley-Milner system.  Unifying two free variables adds a
sharing edge between them, which requires the adjustment of levels to
maintain the invariant that a quantifier node dominates all uses of
its bound variables.  (Recall, a dominator in a graph for a set of
nodes <code>V</code> is a node <code>d</code> such that all paths from the root to each node
in <code>V</code> pass through <code>d</code>.)  Adding the sharing edge may create a path that
no longer passes through the old dominator, letting the variable
escape, so to speak, and become dominated by a <code>let</code> node with a
wider scope.
</p><p>The graphical view of the ranks proved fruitful. Rank-based generalization
easily extends to type checking of records with polymorphic fields.
Eventually this graphical view has led to MLF. Didier Rémy remarks that
``the main operation in MLF -- raising binders -- is analogous to the 
computation of minimal rank between two nodes.'' Rémy's two MLF talks
below describe the system and show several animations of rank adjustments
during type checking. He also points out how ranks fit with 
the constraint-based presentation of ML type inference,
explained in ``The Essence of ML Type Inference''.</p></dd>
<dt><strong>References</strong></dt>
<dd>A History of Caml<br>

&lt;<a href="http://caml.inria.fr/about/history.en.html">http://caml.inria.fr/about/history.en.html</a>&gt;<br>

Section ``The first implementation'' describes the original Caml.

<p>François Pottier and Didier Rémy. The Essence of ML Type Inference<br>

In Advanced Topics in Types and Programming Languages
(Benjamin C. Pierce, editor)<br>

Chapter 10, pages 389-489. MIT Press, 2005.

</p><p>Didier Rémy:
Extension of ML Type System with a Sorted Equational Theory on Types<br>

Research Report 1766, Institut National de Recherche en Informatique
et Automatique, Rocquencourt, BP 105, 78 153 Le Chesnay
Cedex, France, 1992<br>

&lt;<a href="http://gallium.inria.fr/~remy/ftp/eq-theory-on-types.pdf">http://gallium.inria.fr/~remy/ftp/eq-theory-on-types.pdf</a>&gt;

</p><p>Didier Rémy: A new look on MLF<br>

&lt;<a href="http://cristal.inria.fr/~remy/mlf/portland.pdf">http://cristal.inria.fr/~remy/mlf/portland.pdf</a>&gt;

</p><p>Didier Rémy: MLF for Everyone (Users, Implementers, and Designers)<br>

&lt;<a href="http://cristal.inria.fr/~remy/mlf/mlf-for-everyone.pdf">http://cristal.inria.fr/~remy/mlf/mlf-for-everyone.pdf</a>&gt;

</p><p>David McAllester: A logical algorithm for ML type inference
Proc. RTA'03, pp. 436-451<br>

David McAllester has much later re-discovered the efficient
generalization. He also showed that the ML type inference is
nearly linear in program size for most practical programs.

</p><p>George Kuan and David MacQueen:
Efficient ML Type Inference Using Ranked Type Variables<br>

ML Workshop 2007<br>

&lt;<a href="http://people.cs.uchicago.edu/~gkuan/pubs/ml07-km.pdf">http://people.cs.uchicago.edu/~gkuan/pubs/ml07-km.pdf</a>&gt;<br>

The paper compares two level-based Hindley-Milner inference algorithms:
one uses <code>let</code>-levels, as explained on this page, while
the other relies on lambda-levels. The paper develops abstract
machines for both algorithms and describes their several interesting
formal properties. The lambda-level approach was used in SML/NJ.

</p><p>Peter Sestoft: Programming Language Concepts<br>

Springer Undergraduate Texts in Computer Science. xiv + 278 pages.
July 2012<br>

&lt;<a href="http://www.itu.dk/people/sestoft/plc/">http://www.itu.dk/people/sestoft/plc/</a>&gt;<br>

Chapter 6 (see lecture slides and examples on the above page) describes a
simpler version of Rémy's algorithm -- essentially, <code>sound_eager</code>.
</p></dd></dl>


<h2><a name="newtvar">Creating fresh type variables</a></h2>
<dl>
<dd>The OCaml type checker provides two functions to create a fresh type
variable.  This section illustrates the difference between them. The
functions are defined in <code>ctype.ml</code>, with the following signatures:

<pre>    newvar    : ?name:string -&gt; unit -&gt; type_exp
    newgenvar : ?name:string -&gt; unit -&gt; type_exp
</pre>Both take the optional argument <code>?name</code> to give the name to the
variable. The name will be chosen automatically otherwise.
<p>The function <code>newvar</code> creates a variable at the <code>current_level</code> whereas
<code>newgenvar</code> creates at the <code>generic_level</code>. In the code

</p><pre>    let ty1 = newvar () in
    unify env ty1 some_type
 
    let ty2 = newgenvar () in
    unify env ty2 some_type
</pre>both <code>ty1</code> and <code>ty2</code> behave the same: the type variable will be bound
to <code>some_type</code>. Since the <code>current_level</code> corresponds to the innermost
alive region, <code>some_type</code>'s level is the current level or smaller,
and so remains unchanged in either case.
<p>The difference emerges in the following two snippets
(the second often occurs in <code>typecore.ml</code>)

</p><pre>    let ty1 = newvar () in
    let list_type = newgenty (Tconstr(p_list, [ty1])) in
    let texp = instance env list_type in
    unify env texp some_type

    let ty2 = newgenvar () in
    let list_type = newgenty (Tconstr(p_list, [ty2])) in
    let texp = instance env list_type in
    unify env texp some_type
</pre>The function <code>instance</code> copies the type -- creates a <code>Tsubst</code> node, to be
precise&nbsp;-- only if the type is generic. That is, in

<pre>    let ty = newvar () in instance env ty
</pre><code>instance</code> acts as the identity function. However, in

<pre>    let ty = newgenvar () in instance env ty
</pre><code>instance</code> copies the variable. Therefore, in the first snippet above,
<code>unify</code> at the end may affect the <code>list_type</code>, by instantiating <code>ty1</code>.
The <code>list_type</code> cannot possibly be affected in the second snippet since
<code>unify</code> will act on the copy of <code>ty2</code>.</dd></dl>


<h2><a name="gen-in-full">True complexity of generalization</a></h2>
<dl>
<dd>The <code>let</code>-generalization in OCaml is far more complex than what we
have sketched earlier. This section is to help appreciate the true
complexity of generalization.
<p>The <code>let</code>-expression in OCaml has the general form

</p><pre>    let [rec] pattern = exp and pattern = exp ... in body
</pre>The <code>let</code> type checker <code>type_let</code> -- 160 lines of code in
<code>typecore.ml</code>, not counting the type checking of patterns -- receives
the list of pattern-expression pairs, and the recursion-flag. Here is
the end of its code

<pre>    begin_def ();
    ...
    let exp_list =
     List.map2
       (fun (spat, sexp) (pat, slot) -&gt; .... (* type checking of expressions *)
         type_expect exp_env sexp pat.pat_type)
       spat_sexp_list pat_slot_list in
    ...
    end_def();
    List.iter2
      (fun pat exp -&gt;
         if not (is_nonexpansive exp) then
           iter_pattern (fun pat -&gt; generalize_expansive env pat.pat_type) pat)
      pat_list exp_list;
    List.iter
      (fun pat -&gt; iter_pattern (fun pat -&gt; generalize pat.pat_type) pat)
      pat_list;
    (List.combine pat_list exp_list, new_env, unpacks)
</pre>We see the familiar pattern:

<pre>    begin_def(); ... newvar () ... end_def(); generalize
</pre>But there is another traversal of the type, with
<code>generalize_expansive</code>. That function is invoked only if the expression
is expansive, that is, may have a visible effect -- for example, it is
an application.  The function <code>Ctype.generalize_expansive</code>
traverses its argument <code>type_expression</code>; when it comes across a
constructed type <code>Tconstr(p,args)</code> (such as the list type, etc),
and is about to traverse an <code>arg</code>, <code>generalize_expansive</code> checks
the declaration of the type <code>p</code> for the variance of that argument.
If <code>arg</code> is covariant, <code>generalize_expansive</code> traverses <code>arg</code> and
sets the levels of the components above the <code>current_level</code> to 
the <code>generic_level</code>. If <code>arg</code> is not covariant (e.g., the argument of
<code>ref</code> and <code>array</code> type constructors), <code>arg</code>'s components with
the levels above the current are set to the <code>current_level</code>.
The subsequent <code>generalize</code> will leave those levels as they
are. This is how a so-called relaxed value restriction is
implemented, which is responsible for inferring the polymorphic type for

<pre>    # let x = (fun y -&gt; print_string "ok"; y) [];;
    ok
    val x : 'a list = []
</pre>Here, <code>x</code> is bound to an application, which is not a syntactically
value and which is expansive. Its evaluation certainly has a visible
effect.  And yet the type of <code>x</code> is generalized because the <code>list</code>
type is covariant in its argument. SML would not have.
</dd>
<dt><strong>References</strong></dt>
<dd>Jacques Garrigue: Relaxing the Value Restriction<br>

FLOPS 2004, pp. 196-213
</dd></dl>
</div>]]></description>
        </item>
    </channel>
</rss>