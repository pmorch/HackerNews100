<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 21 Sep 2024 22:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Omega-3 intake counteracts symptoms of anxiety and depression in mice (182 pts)]]></title>
            <link>https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</link>
            <guid>41610619</guid>
            <pubDate>Sat, 21 Sep 2024 15:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/">https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</a>, See on <a href="https://news.ycombinator.com/item?id=41610619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="psypo-463511331"><p><a href="https://news.google.com/publications/CAAqBwgKMLz2gwsw-5CAAw" aria-label="Follow PsyPost on Google News"><img decoding="async" src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" data-src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" alt="Follow PsyPost on Google News" data-srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w" data-sizes="(max-width: 510px) 100vw, 510px" width="250" height="85" srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w"></a></p></div><p>A study on mice found that adding omega-3 polyunsaturated fatty acids to their diets effectively counteracts depressive and anxiety-like behaviors induced by stress. Not only did the supplementation reduce these stress-induced symptoms, but it also lowered anxiety levels in mice that were not exposed to stress. These findings, published in <a href="https://www.sciencedirect.com/science/article/pii/S2352289524000420"><em>Neurobiology of Stress</em></a>, suggest that omega-3 fatty acids may have protective mental health benefits.</p><p>Omega-3 polyunsaturated fatty acids are essential fats that the body cannot produce, meaning they must be obtained through food. There are three main types of omega-3s: alpha-linolenic acid (ALA), found in plant oils, and eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), primarily found in fish and seafood. These fats play a key role in maintaining brain function, preserving the integrity of cell membranes, and reducing inflammation throughout the body.</p><p>Omega-3s are widely recognized for their cardiovascular benefits, such as lowering blood pressure and reducing the risk of heart disease. They are equally important for mental health. Research indicates that omega-3s may alleviate symptoms of depression and anxiety, likely due to their anti-inflammatory properties and their role in maintaining brain health.</p><p>Several recent rodent studies have shown that incorporating these fatty acids into the diet can help counteract some of the negative effects of chronic stress, particularly during critical developmental periods. Omega-3s are most abundant in fatty fish like salmon and tuna, as well as in plant sources such as flaxseeds, walnuts, and chia seeds.</p><p>Study author Tatyana Strekalova and her colleagues wanted to explore whether exposing young mice to prolonged stress would induce behaviors similar to anxiety and depression in humans, and if supplementing the diet with omega-3 fatty acids would help prevent the development of these symptoms. Chronic stress was induced through exposure to ultrasound frequencies, simulating emotional stress that could lead to depressive-like symptoms. This method is an established way to model stress-induced depression in animals, which is used to better understand how these conditions develop in humans.</p><p>The experiments were conducted using 40 C57BL/6 male mice, each one month old. This strain of mice is commonly used in research because of their genetic uniformity and their susceptibility to diet-related conditions, such as obesity and diabetes. They are frequently used in studies on neurobiology, immunology, and cancer, making them ideal for this experiment. The mice were housed individually, with unlimited access to food and water.</p><p>The researchers divided the mice into four groups of ten. One group served as a control and received a regular diet without exposure to stress. The second group was subjected to chronic stress in the form of unpredictable ultrasound frequencies for 21 days, without any dietary supplementation. The third group received omega-3 fatty acids in their diet but was not exposed to stress. The fourth group was both exposed to stress and given the omega-3 supplement. The supplement included 0.55 mg/kg/day each of EPA and DHA, matching the recommended dosage of omega-3s for humans, scaled appropriately for mice.</p><p>After the 21-day period of stress exposure, the mice underwent several behavioral tests designed to measure symptoms analogous to human depression and anxiety. These tests included the sucrose preference test, which assesses anhedonia (the loss of interest in pleasurable activities), the novel cage test, the dark-light box test, and the open field test, which measure anxiety and exploratory behaviors. Once the behavioral tests were completed, the mice were killed, and their blood and tissues were analyzed to assess the biological effects of stress and omega-3 supplementation.</p><p>Mice that were exposed to ultrasound stress but received no dietary supplements showed significant anxiety- and depression-like behaviors. They displayed reduced sucrose consumption, indicating anhedonia, and exhibited less exploratory behavior in the tests. Furthermore, their blood samples revealed elevated levels of corticosterone, a hormone linked to stress responses.</p><p>The researchers also detected increased expression of TNF and interleukin-1 beta (IL-1β) genes in the brain, both of which are markers of inflammation. Inflammation in the brain is associated with various neurological disorders and can exacerbate conditions like depression and anxiety. The enhanced gene expression suggests that chronic stress had triggered an inflammatory response in these mice, leading to changes in their brain function and behavior.</p><p>In contrast, the mice that were exposed to stress but received omega-3 supplementation did not show the same degree of behavioral and physiological changes. They continued to drink sucrose, indicating they were less affected by stress-induced anhedonia, and they explored their environment more freely during the tests. Their levels of corticosterone and inflammatory markers, including TNF and IL-1β, were also lower than those in the stressed mice without supplementation.</p><p>These findings suggest that omega-3 fatty acids may protect against the harmful effects of chronic stress by reducing inflammation in the brain. Interestingly, even the mice that were not exposed to stress but received omega-3 supplements showed fewer anxiety-like behaviors compared to the control group, highlighting the broad mental health benefits of these fatty acids.</p><p>“Chronic omega-3 intake counteracted depressive- and anxiety-like behaviors in a US model of juvenile depression in mice [mice exposed to chronic stress as juveniles using ultrasound]. These effects likely stem from the anti-inflammatory properties of the supplement, suggesting potential therapeutic applications in juvenile depression,” the study authors concluded.</p><p>The study demonstrates the protective effects of omega-3 fatty acid supplements in mice exposed to chronic stress. However, it should be emphasized that this study was done on mice, not on humans. While mice and humans share many physiological similarities, there are significant differences between the two species. The effects observed in this study may not necessarily translate directly to human patients, and further research is needed to confirm whether omega-3 supplements would have the same benefits in people.</p><p>The paper, “<a href="https://doi.org/10.1016/j.ynstr.2024.100646">Omega-3 alleviates behavioral and molecular changes in a mouse model of stress-induced juvenile depression,</a>” was authored by Tatyana Strekalova, Daniel Radford-Smith, Isobel K. Dunstan, Anna Gorlova, Evgeniy Svirin, Elisaveta Sheveleva, Alisa Burova, Sergey Morozov, Aleksey Lyundup, Gregor Berger, Daniel C. Anthony, and Susanne Walitza.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling up linear programming with PDLP (145 pts)]]></title>
            <link>https://research.google/blog/scaling-up-linear-programming-with-pdlp/</link>
            <guid>41609670</guid>
            <pubDate>Sat, 21 Sep 2024 12:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/scaling-up-linear-programming-with-pdlp/">https://research.google/blog/scaling-up-linear-programming-with-pdlp/</a>, See on <a href="https://news.ycombinator.com/item?id=41609670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20240920">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="vflng">Classic <a href="https://en.wikipedia.org/wiki/Linear_programming" target="_blank" rel="noopener noreferrer">linear programming</a> (LP) problems are one of the most foundational problems in computer science and operations research. With extensive applications across numerous sectors of the global economy, such as manufacturing, networking, and other fields, LP has been the cornerstone of mathematical programming and has significantly influenced the development of today’s sophisticated modeling and algorithmic frameworks for data-driven decision making. If there's something to optimize, there's a good chance LP is involved.</p><p data-block-key="c5c0o">Since the late 1940s, LP solving has evolved significantly, with the <a href="https://en.wikipedia.org/wiki/Simplex_algorithm" target="_blank" rel="noopener noreferrer">simplex method</a> by Dantzig and various <a href="https://en.wikipedia.org/wiki/Interior-point_method" target="_blank" rel="noopener noreferrer">interior-point methods</a> being the most prevalent techniques. Today's advanced commercial LP solvers utilize these methods but face challenges in scaling to very large instances due to computational demands. In response to this limitation, <a href="https://en.wikipedia.org/wiki/Category:First_order_methods" target="_blank" rel="noopener noreferrer">first-order methods</a> (FOMs) have gained traction for large-scale LP problems.</p><p data-block-key="3ip58">With the above in mind, we introduce our solver PDLP (<a href="https://link.springer.com/article/10.1007/s10851-010-0251-1" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> enhanced for LP), a new FOM–based LP solver that significantly scales up our LP solving capabilities. Utilizing <a href="https://en.wikipedia.org/wiki/Matrix_multiplication#Definitions" target="_blank" rel="noopener noreferrer">matrix-vector multiplication</a> rather than <a href="https://en.wikipedia.org/wiki/Matrix_decomposition" target="_blank" rel="noopener noreferrer">matrix factorization</a>, PDLP requires less memory and is more compatible with modern computational technologies like GPUs and distributed systems, offering a scalable alternative that mitigates the memory and computational inefficiencies of traditional LP methods. PDLP is open-sourced in Google’s <a href="https://github.com/google/or-tools" target="_blank" rel="noopener noreferrer">OR-Tools</a>. This project has been in development since 2018 [<a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://epubs.siam.org/doi/full/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">3</a>], and we are proud to announce that it was co-awarded the prestigious <a href="https://www.mathopt.org/?nav=boh" target="_blank" rel="noopener noreferrer">Beale — Orchard-Hays Prize</a> at the <a href="https://ismp2024.gerad.ca/" target="_blank" rel="noopener noreferrer">International Symposium of Mathematical Programming</a> in July 2024. This accolade is one of the highest honors in the field of computational optimization, awarded every three years by the <a href="https://www.mathopt.org/" target="_blank" rel="noopener noreferrer">Mathematical Optimization Society</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">LP and first-order methods for LP</h2><p data-block-key="covcv">Scaling the methods used in today’s state of the art LP solvers presents significant challenges. The primary computational limitations for both methods relate to matrix factorization required for solving linear equations, introducing two key challenges as problem sizes grow:</p><ol><li data-block-key="ekud4"><i>Memory overflows:</i> LP solvers that use the simplex method (such as Google's <a href="https://en.wikipedia.org/wiki/GLOP" target="_blank" rel="noopener noreferrer">GLOP</a>) employ <a href="https://en.wikipedia.org/wiki/LU_decomposition" target="_blank" rel="noopener noreferrer">LU factorization</a>, and solvers that use the interior point method use <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition" target="_blank" rel="noopener noreferrer">Cholesky factorization</a>. For both these methods the resulting factorization uses considerably more memory than the LP instance itself.</li><li data-block-key="3dv18"><i>Hardware-related challenges:</i> Both methods face difficulties leveraging modern computing architectures, such as GPUs or distributed systems, because the sparse matrix factorization step usually requires highly sequential operations.</li></ol><p data-block-key="3ac05">Given the above limitations associated with traditional LP methods, FOMs have emerged as a promising alternative for tackling large-scale LP problems. Unlike methods that rely on matrix factorization, FOMs utilize gradient information to iteratively update their solutions, with the primary computational requirement being matrix-vector multiplication. This distinction means that FOMs require only the storage of the LP instance itself, without needing additional memory to store factorized forms. Additionally, advances in FOMs for machine learning and deep learning have enhanced their scalability, <a href="https://arxiv.org/abs/1606.04838" target="_blank" rel="noopener noreferrer">making them highly efficient</a> on modern computing platforms such as GPUs and distributed computing. This scalability and reduced memory dependency make FOMs particularly suitable for large and complex LP tasks where traditional methods may falter.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">Restarted primal-dual hybrid gradient for LP</h2><p data-block-key="a2f41"><a href="https://optimization-online.org/2010/06/2646/" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> (PDHG) is widely recognized for its application in image processing. When applied to LP, PDHG's primary computational demand involves matrix-vector multiplication, eliminating the need for matrix factorizations. This makes PDHG particularly efficient for large-scale computational tasks, but it is not reliable in solving LP. For example, in a benchmark of 383 instances, PDHG can only solve <a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">113 instances to moderate accuracy</a>.</p><p data-block-key="4m87g">To enhance PDHG’s reliability in solving LP problems, we have developed a modified approach called <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">restarted PDHG</a>. This version uses a two-loop structure where PDHG is run until a restarting condition is triggered, after which the average of the PDHG iterations is computed. The algorithm then restarts from this average point. This approach is visualized below where the trajectory of the standard PDHG is depicted with a blue line, the average iteration with a red line, and the restarted PDHG with a green line. Notably, the restarted PDHG shows a quicker convergence to the optimal solution, marked by a star on the plot.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="qp0k3">The intuition behind this faster convergence is that by restarting from the computed average at the end of each spiral phase, the restarted PDHG effectively shortens the path to convergence. This strategy leverages the cyclical nature of the PDHG spirals to expedite the solution process.</p><p data-block-key="e8fdh">We show in <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">our research</a> that this restarting technique can significantly speed up the convergence behaviors of PDHG for LP both in theory and in practice. This establishes restarted PDHG as a highly efficient and theoretically sound method for tackling LP challenges, reinforcing its utility and effectiveness in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">PDLP</h2><p data-block-key="6ptml">We designed <a href="https://developers.google.com/optimization/lp/pdlp_math" target="_blank" rel="noopener noreferrer">PDLP</a> as a software package that can solve linear programming problems efficiently. The core algorithm of PDLP is based on the restarted PDHG, which we have enhanced significantly through five improvements:</p><ul><li data-block-key="336v2"><i>Presolving</i>: This process simplifies the LP problem before solving. It involves detecting inconsistent bounds, detecting duplicate rows, tightening bounds, etc. These steps reduce complexity and improve the efficiency of the solver.</li><li data-block-key="60lg4"><i>Preconditioning</i>: A preconditioner in PDLP rescales variables and constraints within the LP instance. This adjustment helps speed up the algorithm by optimizing the numerical condition of the problem, thereby enhancing convergence rates.</li><li data-block-key="fo387"><i>Infeasibility detection</i>: In real-world scenarios, LP problems may often be infeasible or unbounded. Our approach utilizes the iterates of PDHG, which encodes information about the problem's feasibility and boundedness, allowing for detection without extra computational effort. The theory of this method is detailed in <a href="https://epubs.siam.org/doi/abs/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">our SIAM Journal paper</a>.</li><li data-block-key="6ubbl"><i>Adaptive restarts</i>: This technique involves strategically deciding when to optimally restart the PDHG algorithm to enhance its efficiency, particularly speeding up the convergence to a high-accuracy solution.</li><li data-block-key="6u9l9"><i>Adaptive step-size</i>: We introduced an adaptive method for selecting the step-size in the PDHG, which significantly reduces the need for manual tuning. This approach adjusts the step-size dynamically based on the problem's characteristics and the algorithm's performance, promoting faster convergence.</li></ul><p data-block-key="8lct3">PDLP is open-sourced as part of Google’s <a href="https://developers.google.com/optimization" target="_blank" rel="noopener noreferrer">OR-Tools</a>, an open-source software suite for optimization. The solver is easy to use and it has interfaces in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" target="_blank" rel="noopener noreferrer">Python</a>, <a href="https://en.wikipedia.org/wiki/C%2B%2B" target="_blank" rel="noopener noreferrer">C++</a>, <a href="https://en.wikipedia.org/wiki/Java_(programming_language)" target="_blank" rel="noopener noreferrer">Java</a> and <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" target="_blank" rel="noopener noreferrer">C#</a>. More details and examples on how to use PDLP can be found in the <a href="https://developers.google.com/optimization/lp/lp_example" target="_blank" rel="noopener noreferrer">OR-Tools documentation</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Applications</h2><p data-block-key="56kp2">Scaling up and speeding up LP enables new applications — here, we briefly mention three:</p><ol><li data-block-key="6f59p"><i>Data center network traffic engineering (</i><a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network" target="_blank" rel="noopener noreferrer"><i>blog post</i></a><i>,</i> <a href="https://research.google/pubs/jupiter-evolving-transforming-googles-datacenter-network-via-optical-circuit-switches-and-software-defined-networking/"><i>paper</i></a><i>):</i> Google's data centers rely on dynamically optimized traffic engineering for high-performance efficiency. The challenge of optimizing network traffic routing is periodically addressed as a large-scale LP problem. Previously, solving this large problem fast enough was not possible, leading to the development of partition heuristics. These heuristics decomposed the problem into many smaller-scale LPs that could be solved concurrently, albeit at the cost of optimality. With the introduction of PDLP, we can now efficiently optimize traffic routing across an entire data center network, effectively saving a significant amount of machine resources across the network. This solution has been deployed in Google's production environment since May 2023.</li><li data-block-key="a199v"><i>Container shipping optimization (</i><a href="https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/"><i>blog post</i></a><i>):</i> The world's shipping supply chain relies on optimizing the order in which vessels visit ports and the placement of containers on those vessels. Due to the extreme scale of real-world instances, a direct solution often is intractable. Consequently, various heuristic approaches have been proposed to enhance efficiency and practicality in solving this complex optimization problem. The problem can be formulated as a type of optimization problem called a massive integer two-layer <a href="https://en.wikipedia.org/wiki/Multi-commodity_flow_problem" target="_blank" rel="noopener noreferrer">multi-commodity flow problem</a>. PDLP enables solving the linear relaxation of this formulation, quantifying the quality of the heuristics.</li><li data-block-key="bii5j"><i>Traveling salesman problem:</i> The <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem" target="_blank" rel="noopener noreferrer">traveling salesman problem</a> (TSP) poses a classic question: given a list of cities and their distances, what's the shortest route that visits every city once and returns to the starting point? This problem is notoriously challenging, holding significant importance in theoretical computer science and operations research. PDLP has <a href="https://research.google/blog/google-research-2022-beyond-algorithmic-advances/">demonstrated its power</a> by solving real-world TSP lower bound LP instances of immense scale, encompassing up to 12 billion non-zero entries in the constraint matrix. This capability far surpasses the capacity of even the most advanced commercial solvers available today, showcasing PDLP's potential for tackling large-scale LP challenges.</li></ol>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Broader impacts</h2><p data-block-key="947n">Since its initial release, PDLP has attracted significant interest, leading to further enhancements. Here are some notable developments: <a href="https://github.com/jinwen-yang/cuPDLP.jl" target="_blank" rel="noopener noreferrer">cuPDLP.jl</a> is an open-sourced GPU implementation of PDLP, written in <a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">Julia</a>. The commercial solver company, <a href="https://www.copt.de/" target="_blank" rel="noopener noreferrer">Cardinal Optimizer</a>, has incorporated PDLP into their software in <a href="https://github.com/COPT-Public/COPT-Release" target="_blank" rel="noopener noreferrer">Version 7.1</a> in January 2024. The open-source solver, <a href="https://highs.dev/" target="_blank" rel="noopener noreferrer">HiGHS</a>, has incorporated a version of PDLP in their software in <a href="https://conan.io/center/recipes/highs" target="_blank" rel="noopener noreferrer">V1.7.0</a> in March 2024. In addition, the academic community has continued to explore and expand upon the theoretical foundations of PDLP. Recent studies have focused on areas such as <a href="https://arxiv.org/pdf/2206.12061" target="_blank" rel="noopener noreferrer">new analysis on PDHG</a>, <a href="https://arxiv.org/pdf/2312.14774" target="_blank" rel="noopener noreferrer">condition number theory</a>, <a href="https://arxiv.org/pdf/2307.03664v2" target="_blank" rel="noopener noreferrer">trajectory-based analysis</a>, extensions to <a href="https://arxiv.org/pdf/2311.07710" target="_blank" rel="noopener noreferrer">quadratic programming</a> and <a href="https://arxiv.org/pdf/2402.00311" target="_blank" rel="noopener noreferrer">semi-definite programming</a>, etc. These efforts not only deepen the understanding of PDLP's underlying mechanics but also explore its potential applications to more complex problems. These developments reflect PDLP's significant impact on the field of optimization, bridging the gap between theoretical research and practical application. As PDLP continues to evolve, its influence is expected to grow, pushing the boundaries of what can be achieved in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Acknowledgments</h2><p data-block-key="e8dq7"><i>We are grateful to our co-authors Mateo Diaz, Oliver Hinder, Miles Lubin, and Warren Schudy for their exceptional support and contributions. We would also like to thank our managers, Vahab Mirrokni, Jon Orwant and Aaron Archer, and our collaborators in the Data Center Networking team, the Algorithm team and the Operations Research team.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Forget ChatGPT: why researchers now run small AIs on their laptops (391 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-02998-y</link>
            <guid>41609393</guid>
            <pubDate>Sat, 21 Sep 2024 11:52:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-02998-y">https://www.nature.com/articles/d41586-024-02998-y</a>, See on <a href="https://news.ycombinator.com/item?id=41609393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>The website histo.fyi is a database of structures of immune-system proteins called major histocompatibility complex (MHC) molecules. It includes images, data tables and amino-acid sequences, and is run by bioinformatician Chris Thorpe, who uses artificial intelligence (AI) tools called large language models (LLMs) to convert those assets into readable summaries. But he doesn’t use ChatGPT, or any other web-based LLM. Instead, Thorpe runs the AI on his laptop.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02630-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27689164.jpg"><p>Chatbots in science: What can ChatGPT do for you?</p></a>
 </article><p>Over the past couple of years, chatbots based on LLMs have won praise for their ability to write poetry or engage in conversations. Some LLMs have hundreds of billions of parameters — the more parameters, the greater the complexity — and can be accessed only online. But two more recent trends have blossomed. First, organizations are making ‘open weights’ versions of LLMs, in which the weights and biases used to train a model are publicly available, so that users can download and run them locally, if they have the computing power. Second, technology firms are making scaled-down versions that can be run on consumer hardware — and that rival the performance of older, larger models.</p><p>Researchers might use such tools to save money, protect the confidentiality of patients or corporations, or ensure reproducibility. Thorpe, who’s based in Oxford, UK, and works at the European Molecular Biology Laboratory’s European Bioinformatics Institute in Hinxton, UK, is just one of many researchers exploring what the tools can do. That trend is likely to grow, Thorpe says. As computers get faster and models become more efficient, people will increasingly have AIs running on their laptops or mobile devices for all but the most intensive needs. Scientists will finally have AI assistants at their fingertips — but the actual algorithms, not just remote access to them.</p><h2><b>Big things in small packages</b></h2><p>Several large tech firms and research institutes have released small and open-weights models over the past few years, including Google DeepMind in London; Meta in Menlo Park, California; and the Allen Institute for Artificial Intelligence in Seattle, Washington (see ‘Some small open-weights models’). (‘Small’ is relative — these models can contain some 30 billion parameters, which is large by comparison with earlier models.)</p><p>Although the California tech firm OpenAI hasn’t open-weighted its current GPT models, its partner Microsoft in Redmond, Washington, has been on a spree, releasing the small language models Phi-1, Phi-1.5 and Phi-2 in 2023, then four versions of Phi-3 and three versions of Phi-3.5 this year. The Phi-3 and Phi-3.5 models have between 3.8 billion and 14 billion active parameters, and two models (Phi-3-vision and Phi-3.5-vision) handle images<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>. By some benchmarks, even the smallest Phi model outperforms OpenAI’s GPT-3.5 Turbo from 2023, rumoured to have 20 billion parameters.</p><p>Sébastien Bubeck, Microsoft’s vice-president for generative AI, attributes Phi-3’s performance to its training data set. LLMs initially train by predicting the next ‘token’ (iota of text) in long text strings. To predict the name of the killer at the end of a murder mystery, for instance, an AI needs to ‘understand’ everything that came before, but such consequential predictions are rare in most text. To get around this problem, Microsoft used LLMs to write millions of short stories and textbooks in which one thing builds on another. The result of training on this text, Bubeck says, is a model that fits on a mobile phone but has the power of the initial 2022 version of ChatGPT. “If you are able to craft a data set that is very rich in those reasoning tokens, then the signal will be much richer,” he says.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02386-6" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27484538.png"><p>ChatGPT for science: how to talk to your data</p></a>
 </article><p>Phi-3 can also help with routing — deciding whether a query should go to a larger model. “That’s a place where Phi-3 is going to shine,” Bubeck says. Small models can also help scientists in remote regions that have little cloud connectivity. “Here in the Pacific Northwest, we have amazing places to hike, and sometimes I just don’t have network,” he says. “And maybe I want to take a picture of some flower and ask my AI some information about it.”</p><p>Researchers can build on these tools to create custom applications. The Chinese e-commerce site Alibaba, for instance, has built models called Qwen with 500 million to 72 billion parameters. A biomedical scientist in New Hampshire fine-tuned the largest Qwen model using scientific data to create Turbcat-72b, which is available on the model-sharing site Hugging Face. (The researcher goes only by the name Kal’tsit on the Discord messaging platform, because AI-assisted work in science is still controversial.) Kal’tsit says she created the model to help researchers to brainstorm, proof manuscripts, prototype code and summarize published papers; the model has been downloaded thousands of times.</p><h2><b>Preserving privacy</b></h2><p>Beyond the ability to fine-tune open models for focused applications, Kal’tsit says, another advantage of local models is privacy. Sending personally identifiable data to a commercial service could run foul of data-protection regulations. “If an audit were to happen and you show them you’re using ChatGPT, the situation could become pretty nasty,” she says.</p><p>Cyril Zakka, a physician who leads the health team at Hugging Face, uses local models to generate training data for other models (which are sometimes local, too). In one project, he uses them to extract diagnoses from medical reports so that another model can learn to predict those diagnoses on the basis of echocardiograms, which are used to monitor heart disease. In another, he uses the models to generate questions and answers from medical textbooks to test other models. “We are paving the way towards fully autonomous surgery,” he explains. A robot trained to answer questions would be able to communicate better with doctors.</p><p>Zakka uses local models — he prefers Mistral 7B, released by the tech firm Mistral AI in Paris, or Meta’s Llama-3 70B — because they’re cheaper than subscription services such as ChatGPT Plus, and because he can fine-tune them. But privacy is also key, because he’s not allowed to send patients’ medical records to commercial AI services.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02185-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27488412.jpg"><p>Inside the maths that drives AI</p></a>
 </article><p>Johnson Thomas, an endocrinologist at the health system Mercy in Springfield, Missouri, is likewise motivated by patient privacy. Clinicians rarely have time to transcribe and summarize patient interviews, but most commercial services that use AI to do so are either too expensive or not approved to handle private medical data. So, Thomas is developing an alternative. Based on Whisper — an open-weight speech-recognition model from OpenAI — and on Gemma 2 from Google DeepMind, the system will allow physicians to transcribe conversations and convert them to medical notes, and also summarize data from medical-research participants.</p><p>Privacy is also a consideration in industry. CELLama, developed at the South Korean pharmaceutical company Portrai in Seoul, exploits local LLMs such as Llama 3.1 to reduce information about a cell’s gene expression and other characteristics to a summary sentence<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. It then creates a numerical representation of this sentence, which can be used to cluster cells into types. The developers highlight privacy as one advantage on their GitHub page, noting that <a href="https://github.com/CelVoxes/ceLLama" data-track="click" data-label="https://github.com/CelVoxes/ceLLama" data-track-category="body text link">CELLama</a> “operates locally, ensuring no data leaks”.</p><h2><b>Putting models to good use</b></h2><p>As the LLM landscape evolves, scientists face a fast-changing menu of options. “I’m still at the tinkering, playing stage of using LLMs locally,” Thorpe says. He tried ChatGPT, but felt it was expensive, and the tone of its output wasn’t right. Now he uses Llama locally, with either 8 billion or 70 billion parameters, both of which can run on his Mac laptop.</p><p>Another benefit, Thorpe says, is that local models don’t change. Commercial developers, by contrast, can update their models at any moment, leading to different outputs and forcing Thorpe to alter his prompts or templates. “In most of science, you want things that are reproducible,” he explains. “And it’s always a worry if you’re not in control of the reproducibility of what you’re generating.”</p><p>For another project, Thorpe is writing code that aligns MHC molecules on the basis of their 3D structure. To develop and test his algorithms, he needs lots of diverse proteins — more than exist naturally. To design plausible new proteins, he uses <a href="https://huggingface.co/nferruz/ProtGPT2" data-track="click" data-label="https://huggingface.co/nferruz/ProtGPT2" data-track-category="body text link">ProtGPT2</a>, an open-weights model with 738 million parameters that was trained on about 50 million sequences<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>.</p><p>Sometimes, however, a local app won’t do. For coding, Thorpe uses the cloud-based GitHub Copilot as a partner. “It kind of feels like my arm’s chopped off when for some reason I can’t actually use Copilot,” he says. Local LLM-based coding tools do exist (such as Google DeepMind’s <a href="https://huggingface.co/google/codegemma-7b" data-track="click" data-label="https://huggingface.co/google/codegemma-7b" data-track-category="body text link">CodeGemma</a> and one from California-based developers <a href="https://docs.continue.dev/intro" data-track="click" data-label="https://docs.continue.dev/intro" data-track-category="body text link">Continue</a>), but in his experience they can’t compete with Copilot.</p><h2><b>Access points</b></h2><p>So, how do you run a local LLM? Software called <a href="https://ollama.com/" data-track="click" data-label="https://ollama.com/" data-track-category="body text link">Ollama</a> (available for Mac, Windows and Linux operating systems) lets users download open models, including Llama 3.1, Phi-3, Mistral and Gemma 2, and access them through a command line. Other options include the cross-platform app <a href="https://www.nomic.ai/gpt4all" data-track="click" data-label="https://www.nomic.ai/gpt4all" data-track-category="body text link">GPT4All</a> and <a href="https://github.com/Mozilla-Ocho/llamafile" data-track="click" data-label="https://github.com/Mozilla-Ocho/llamafile" data-track-category="body text link">Llamafile</a>, which can transform LLMs into a single file that runs on any of six operating systems, with or without a graphics processing unit.</p><article data-label="Related">
  <a href="https://www.nature.com/collections/fxvqrpnlcq" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_16573690.jpg"><p>NatureTech hub</p></a>
 </article><p>Sharon Machlis, a former editor at the website InfoWorld, who lives in Framingham, Massachusetts, wrote <a href="https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html" data-track="click" data-label="https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html" data-track-category="body text link">a guide to using LLMs locally</a>, covering a dozen options. “The first thing I would suggest,” she says, “is to have the software you choose fit your level of how much you want to fiddle.” Some people prefer the ease of apps, whereas others prefer the flexibility of the command line.</p><p>Whichever approach you choose, local LLMs should soon be good enough for most applications, says Stephen Hood, who heads open-source AI at the tech firm Mozilla in San Francisco. “The rate of progress on those over the past year has been astounding,” he says.</p><p>As for what those applications might be, that’s for users to decide. “Don’t be afraid to get your hands dirty,” Zakka says. “You might be pleasantly surprised by the results.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Collapse of Self-Worth in the Digital Age (187 pts)]]></title>
            <link>https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/</link>
            <guid>41609099</guid>
            <pubDate>Sat, 21 Sep 2024 10:48:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/">https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/</a>, See on <a href="https://news.ycombinator.com/item?id=41609099">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-170627">

	
	
	
	<div>
		<!-- Ad-Auris -->
		
		<p><span>W</span><span>hen I was twelve,</span> I used to roller-skate in circles for hours. I was at another new school, the odd man out, bullied by my desk mate. My problems were too complex and modern to explain. So I skated across parking lots, breezeways, and sidewalks, I listened to the vibration of my wheels on brick, I learned the names of flowers, I put deserted paths to use. I decided for myself each curve I took, and by the time I rolled home, I felt lighter. One Saturday, a friend invited me to roller-skate in the park. I can still picture her in green protective knee pads, flying past. I couldn’t catch up, I had no technique. There existed another scale to evaluate roller skating, beyond joy, and as Rollerbladers and cyclists overtook me, it eclipsed my own. Soon after, I stopped skating. </p>

<p><span>Y</span><span>ears ago,</span> I worked in the backroom of a Tower Records. Every few hours, my face-pierced, gunk-haired co-workers would line up by my workstation, waiting to clock in or out. When we typed in our staff number at 8:59 p.m., we were off time, returned to ourselves, free like smoke.</p>
<p>There are no words to describe the opposite sensations of being at-our-job and being not-at-our-job even if we know the feeling of crossing that threshold by heart. But the most essential quality that makes a job a job is that when we are at work, we surrender the power to decide the worth of what we do. At-job is where our labour is appraised by an external meter: the market. At-job, our labour is never a means to itself but a means to money; its value can be expressed only as a number—relative, fluctuating, out of our control. At-job, because an outside eye measures us, the workplace is a place of surveillance. It’s painful to have your sense of worth extracted. For Marx, the poet of economics, when a person’s innate value is replaced with exchange value, it is as if we’ve been reduced to “a mere jelly.” </p>

<p>Not-job, or whatever name you prefer—“quitting time,” “off duty,” “downtime”—is where we restore ourselves from a mere jelly, precisely by using our internal meter to determine the criteria for success or failure. Find the best route home—not the one that optimizes cost per minute but the one that offers time enough to hear an album from start to finish. Plant a window garden, and if the plants are half dead, try again. My brother-in-law found a toy loom in his neighbour’s garbage, and nightly he weaves tiny technicolour rugs. We do these activities for the sake of doing them, and their value can’t be arrived at through an outside, top-down measure. It would be nonsensical to treat them as comparable and rank them from one to five. We can assess them only by privately and carefully attending to what they contain and, on our own, concluding their merit. </p>
<p>And so artmaking—the cultural industries—occupies the middle of an uneasy Venn diagram. First, the value of an artwork is internal—how well does it fulfill the vision that inspired it? Second, a piece of art is its own end. Third, a piece of art is, by definition, rare, one of a kind, nonfungible. </p>

<p>Yet the end point for the working artist is to create an object for sale. Once the art object enters the market, art’s intrinsic value is emptied out, compacted by the market’s logic of ranking, until there’s only relational worth, no interior worth. Two novelists I know publish essays one week apart; in a grim coincidence, each writer recounts their own version of the same traumatic life event. Which essay is better, a friend asks. I explain they’re different; different life circumstances likely shaped separate approaches. Yes, she says, but which one is <em>better</em>?</p>
<p><span>I</span><span>grew up</span> a Catholic, a faithful, an anachronism to my friends. I carried my faith until my twenties, when it finally broke. Once I couldn’t gain comfort from religion anymore, I got it from writing. Sitting and building stories, side by side with millions of other storytellers who have endeavoured since the dawn of existence to forge meaning even as reality proves endlessly senseless, is the nearest thing to what it felt like back when I was a believer.</p>
<p>I spent my thirties writing a novel and paying the bills as low-paid part-time faculty at three different colleges. I could’ve studied law or learned to code. Instead, I manufactured sentences. Looking back, it baffles me that I had the wherewithal to commit to a project with no guaranteed financial value, as if I was under an enchantment. Working on that novel was like visiting a little town every day for four years, a place so dear and sweet. Then I sold it.</p>
<p>As the publication date advanced, I was awash with extrinsic measures. Only twenty years ago, there was no public, complete data on book sales. Until the introduction of BookScan in the late ’90s, you just had to take an agent’s word for it. “The track record of an author was a contestable variable that was known to some, surmised by others, and always subject to exaggeration in the interests of inflating value,” says John B. Thompson in <em>Merchants of Culture</em>, his ethnography of contemporary publishing.</p>
<p>This is hard to imagine, now that we are inundated with cold, beautiful stats, some publicized by trade publications or broadcast by authors themselves on all socials. How many publishers bid? How big is the print run? How many stops on the tour? How many reviews on Goodreads? How many mentions on Bookstagram, BookTok? How many bloggers on the blog tour? How exponential is the growth in follower count? Preorders? How many printings? How many languages in translation? How many views on the unboxing? How many mentions on most-anticipated lists? I was glued to my numbers like a day trader.</p>

<p>I wanted to write my publicist to ask: Should I be worried my stats aren’t higher? The question blared constantly in my head: Did gambling years I could’ve been earning towards a house pay off? But I never did. I was too embarrassed. I had trained in the religion of art, and to pay mind to the reception of my work was to be a non-believer. During my fine arts degree, we heard again and again that <em>the only gauge for art is your own measure</em>, and when I started teaching writing, I’d preach the same thing. Ignore whatever publications or promotions friends gain; you’re on your own journey. It’s a purportedly anti-capitalist idea, but it repackages the artist’s concern for economic security as petty ego. My feelings—caring at all—broke code. Shame sublimated everything. </p>
<p>And when the reception started to roll in, I’d hear good news, but gratitude lasted moments before I wanted more. A starred review from <em>Publisher’s Weekly</em>, but I wasn’t in “Picks of the Week.” A mention from <em>Entertainment Weekly</em>, but last on a click-through list. Nothing was enough. Why? What had defined my adult existence was my ability to find worth within, to build to an internal schematic, which is what artists do. Now I was a stranger to myself. I tried to fix it with box breathing videos, podcasts, reading about <em>Anna Karenina</em>. My partner and I were trying for another baby, but cycles kept passing, my womb couldn’t grab the egg. A kind nurse at the walk-in said: <em>Sometimes your body is saying the time’s not right</em>. Mine was a bad place. </p>
<p>A few weeks after my book release, my friends and I and our little kids took a weekend vacation. They surprised me with a three-tiered cake matching my book cover, cradled on laps, from Toronto, through a five-hour traffic jam. In all the photos from that trip, I’m staring at my phone. I can hardly remember that summer.</p>
<p>My scale of worth had torn off, like a roof in a hurricane, replaced with an external one. An external scale is a relative scale; so of course, nothing’s enough. There is no top. </p>
<p>Then I was shortlisted for a major prize. It took me on a world tour, listed me alongside authors who are certifiable geniuses. I thought my endless accounting could stop, this had to be enough for me, I could get back to who I was. But I couldn’t. In London, I bought my two-year-old a bath toy, a little boat with a Beefeater. Today at bath time, the boat still gives me a sickly feeling, like it’s from the scene of a trauma. My centre was gone.</p>
<p><span>O</span><span>ne of at-job’s</span> defining qualities is how efficiently output is converted into a number. In 1994, Philip Agre described this as <a href="https://djp3.westmont.edu/classes/2017_01_CS195/readings/CaptureModelOfSurveillance.pdf" rel="noopener" target="_blank">the “capture model,”</a> or “the deliberate reorganization of industrial work activities to allow computers to track them in real time.” Gregory Sholette, the author of <em>Dark Matter: Art and Politics in the Age of Enterprise Culture</em>, describes how workers in a Pennsylvania factory spent their break covering a wall of the plant with “newspaper clippings, snapshots, spent soda cans, industrial debris, trashed food containers and similar bits and pieces.” They called it “Swampwall.” It reminds me of the sculpture on a high shelf in the back of a diner where I worked, composed of unusually shaped potatoes. Its form changed with each new tuber contributed by the cook on prep shift. </p>
<p>Such spontaneous projects are signs of life: physical evidence of the liberating fact that not all time at work can be measured or processed into productivity. Swampwall was inutile: a means to itself. It was allowed to flourish until the company was bought out by a global corporation, at which point the massive collaborative mural was “expunged.”</p>
<p>Thirty years after Agre coined the capture model, workforce management technology can track every moment at work as a production target. Amazon’s Units Per Hour score, Uber’s and Lyft’s (constantly shrivelling) base fares, and Domino’s Pizza Tracker have made it possible to time all time, even in the break room or toilet stall. These are extreme examples, but they’re echoed across the work world, with the datafication of parts of performance that used to be too baggy or obscure to crunch and so were ours to keep. “Wellness” apps provided as health benefits by corporate management that track fob swipes for office workers; case management software that counts advice by the piece for legal workers; shares, hover rate, and time on site that measure media workers; leaderboards for tech employees, ranking who worked longest. </p>
<p>There must exist professions that are free from capture, but I’m hard pressed to find them. Even non-remote jobs, where work cannot pursue the worker home, are dogged by digital tracking: a farmer says Instagram Story views directly correlate to farm subscriptions, a server tells me her manager won’t give her the Saturday-night money shift until she has more followers. Even religious guidance can be quantified by view counts for online church services, Yelp for spirituality. <a href="https://www.theguardian.com/world/2020/nov/10/ireland-catholic-priests-online-mass-reviews-causing-performance-anxiety" rel="noopener" target="_blank">One priest told the <em>Guardian</em></a>, “you have this thing about how many followers have you . . . it hits at your gut, at your heart.” </p>
<p>But we know all this. What we hardly talk about is how we’ve reorganized not just industrial activity but <em>any</em> activity to be capturable by computer, a radical expansion of what can be mined. Friendship is ground zero for the metrics of the inner world, the first unquantifiable shorn into data points: Friendster testimonials, the MySpace Top 8, friending. Likewise, the search for romance has been refigured by dating apps that sell paid-for rankings and paid access to “quality” matches. Or, if there’s an off-duty pursuit you love—giving tarot readings, polishing beach rocks—it’s a great compliment to say: “You should do that for money.” Join the passion economy, give the market final say on the value of your delights. Even engaging with art—say, encountering some uncanny reflection of yourself in a novel, or having a transformative epiphany from listening, on repeat, to the way that singer’s voice breaks over the bridge—can be spat out as a figure, on Goodreads or your Spotify year in review.  </p>

<p>And those ascetics who disavow all socials? They are still caught in the network. Acts of pure leisure—photographing a sidewalk cat with a camera app or watching a video on how to make a curry—are transmuted into data to grade how well the app or the creators’ deliverables are delivering. If we’re not being tallied, we affect the tally of others. We are all data workers.</p>
<p>Twenty years ago, anti-capitalist activists campaigned against ads posted in public bathroom stalls: too invasive, there needs to be a limit to capital’s reach. Now, ads by the toilet are quaint. Clocking out is obsolete when, in the deep quiet of our minds, we lack the pay grade to determine worth.</p>
<p><span>T</span><span>he internet</span> is designed to stop us from ever switching it off. It moves at the speed of light, with constantly changing metrics, fuelled by “‘ludic loops’ or repeated cycles of uncertainty, anticipation and feedback”—in other words, it works exactly like a Jackpot 6000 slot machine. (On a basic level, social media apps like Instagram operate like phone games. They’ve replaced classics like Snake or Candy Crush, except the game is your sense of self.)</p>
<p>The effect of gamification on artmaking has been dramatic. <a href="https://www.vox.com/culture/2024/2/1/24056883/tiktok-self-promotion-artist-career-how-to-build-following" rel="noopener" target="_blank">In Rebecca Jennings’s <em>Vox</em> long read</a> on the necessity of authorly self-promotion, she interviews William Deresiewicz, whose book <em>The Death of the Artist</em> breaks down the harsh conditions for artists seeking an income in the digital economy. Deresiewicz used to think “selling out”—using the most sacred parts of your life and values to shill for a brand—was “evil.” Yet this economy has made it so there’s “no choice” if you want a living. The very concept of selling out, he says, “has disappeared.” A few years ago, much was made of the fact that the novelist Sally Rooney had no Twitter account—this must explain her prolific output. But the logic is back to front: it’s only top-selling authors who can afford to forgo social media. Call it Deactivation Privilege. </p>
<p>It’s a privilege few of us can afford, if it’s the algorithm we need to impress rather than book reviewers of old. <a href="https://www.esquire.com/entertainment/books/a60924704/debut-fiction-challenges/" rel="noopener" target="_blank">In a nightmarish dispatch in <em>Esquire</em></a> on how hard it is for authors to find readers, Kate Dwyer argues that all authors must function like influencers now, which means a fire sale on your “private” life. As internet theorist Kyle Chayka puts it to Dwyer: “Influencers get attention by exposing parts of their life that have nothing to do with the production of culture.”</p>
<p>The self <em>is</em> the work, just ask Flaubert. But data collection’s ability to reduce the self to a figure—batted about by the fluctuations of its stock—is newly unbearable. There’s no way around it, and this self being sold alongside the work can be as painful for a writer of autofiction as it is for me, a writer of speculative fiction who invented an imaginary world. </p>
<p><span>I</span><span>tell you</span> all this not because I think we should all be very concerned about artists, but because what happens to artists is happening to all of us. As data collection technology hollows out our inner worlds, all of us experience the working artist’s plight: our lot is to numericize and monetize the most private and personal parts of our experience. </p>
<p>Certainly, smartphones could be too much technology for children, <a href="https://www.newyorker.com/news/the-new-yorker-interview/jonathan-haidt-wants-you-to-take-away-your-kids-phone" rel="noopener" target="_blank">as Jonathan Haidt argues</a>, and definitely, <a href="https://www.theguardian.com/books/2016/dec/26/the-attention-merchants-tim-wu-review" rel="noopener" target="_blank">as Tim Wu says</a>, attention is a commodity, but these ascendant theories of tech talk around the fact that something else deep inside, innermost, is being harvested too: our self-worth, or, rather, worthing. </p>
<p>We are not giving away our value, as a puritanical grandparent might scold; we are giving away our facility <em>to</em> value. We’ve been cored like apples, a dependency created, hooked on the public internet to tell us the worth. </p>
<p>Every notification ping holds the possibility we have merit. When we scroll, what are we looking for? </p>

<p><span>W</span><span>hen my eldest child</span> was in kindergarten, she loved to make art, but she detested the assignments that tried to make math fun by asking kids to draw. If I sat her down to complete one, she would stare rebelliously at her pencil or a strand of her hair rather than submit. Then one day, while drawing a group of five ants and a group of eight ants, my kindergartener started to sketch fast. She drew ants with bulbous limbs growing out of their bodies, like chains of sausages. “Bombombom!” she cried, flapping her arms up and down. “These are their muscles.” She continued to draw and mime pumping iron, giggling to herself, delighted to have planted something in her homework that couldn’t be accounted for in the metric of correct or incorrect. She had taken drawing back. </p>
<p><span>T</span><span>he ludic loop</span> of the internet has automated our inner worlds: we don’t have to choose what we like, or even if we like it; the algorithm chooses for us. Take Shein, the fast fashion leviathan. While other fast fashion brands wait for high-end houses to produce designs they can replicate cheaply, Shein has completely eclipsed the runway, using AI to trawl social media for cues on what to produce next. Shein’s site operates like a casino game, using “dark patterns”—a countdown clock puts a timer on an offer, pop-ups say there’s only one item left in stock, and the scroll of outfits never ends—so you buy now, ask if you want it later. </p>
<p>Shein’s model is dystopic: countless reports detail how it puts its workers in obscene poverty in order to sell a reprieve to consumers who are also moneyless—a saturated plush world lasting as long as the seams in one of their dresses. Yet the day to day of Shein’s target shopper is so bleak, we strain our moral character to cosplay a life of plenty. </p>
<p>Automation isn’t forced upon us: we crave it, oblivion, thanks to the tech itself. As the ascendant apparatus of the labour market, it’s squeezed already dire working conditions to a suffocation point, until all we desire is the sweet fugue of scroll, our decision maker set to “off.” </p>
<p><span>A</span><span>fter my novel</span> came out, whenever I met an author, I would ask, with increasing frenzy, how they managed the grisly experience of work going to market. I was comforted and horrified when everyone agreed it could be dispossessing. Then they all said the same thing: “I kept writing and I felt better.” That was the advice: keep writing. </p>
<p>The market is the only mechanism for a piece of art to reach a pair of loving eyes. Even at a museum or library, the market had a hand in homing the item there. I didn’t understand that seeking a reader for my story meant handing over my work in the same way I sold my car on Craigslist: it’s gone from me, fully, bodily, finally. Or, as Marx says, alienated. I hated that advice to keep writing, because if I wrote another book, I’d have to go through the cycle again: slap my self on the scale like a pair of pork chops again. Now, I realize the authors I met meant something else. Yes, sell this part of your inner life but then go back in there and reinflate what’s been emptied. It’s a renewable resource.  </p>
<p>When I grasp this, all of it becomes tolerable. It’s like letting out a line, then braiding more line. I can manage, because there’ll always be more line.  </p>
<p><span>I</span><span>will try to sell</span> this essay to a publication, and if successful, the publication will try to sell it to readers. If you are reading this, it’s a commodity now, fluctuating and fungible, like so much digital dust. </p>
<!-- AI CONTENT END 1 -->
		<div id="sexy_author_bio_widget-2"><p><a href="https://thewalrus.ca/author/thea-lim/" target="_top"><img alt="Thea Lim" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2070%2070'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/a5dae45e6bea1e8e5104bdd5b15830f9?s=70&amp;d=mm&amp;r=pg" data-srcset="https://secure.gravatar.com/avatar/a5dae45e6bea1e8e5104bdd5b15830f9?s=140&amp;d=mm&amp;r=pg 2x" height="70" width="70"></a></p><p>Thea Lim is an author, a culture writer, and a creative writing teacher. Her most recent novel is <em>An Ocean of Minutes</em>.</p></div>	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

		
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ultra high-resolution image of The Night Watch (440 pts)]]></title>
            <link>https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch</link>
            <guid>41608648</guid>
            <pubDate>Sat, 21 Sep 2024 09:08:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch">https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch</a>, See on <a href="https://news.ycombinator.com/item?id=41608648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div v-else="">


<gtm-scroll-tracker location="article_story" category="article" scroll-element-id="openPipModal" inline-template="">
  <div>
      

<div>
      
  <p>The new high-resolution image of The Night Watch represents a major advance in the state of the art for imaging paintings, setting records for both the resolution and the total size of the image. The sampling resolution is 5 µm (0.005 mm), meaning that each pixel covers an area of the painting that is smaller than a human red blood cell. Given the large size of The Night Watch, this results in a truly enormous image: it’s 925,000 by 775,000 pixels – 717 gigapixels – with a file size of 5.6 TB!</p>

    </div>

<div>
    <h2>Grid</h2>
<p>To create this huge image, the painting was photographed in a grid with 97 rows and 87 columns with our 100-megapixel Hasselblad H6D 400 MS camera. Each of these 8,439 separate photos was captured using a sophisticated laser-guided five-axis camera positioning system that can sense the precise location of the painting so that every photo is sharp – an error of even 1/8 mm in the placement of the camera would result in a useless image.</p>

  </div>

<div>
    <h2>New technology</h2>
<p>New technology allowed the previously-released 20 µm resolution image of The Night Watch to serve as the guide for  lining up these much higher-resolution images during the process of fusing the individual captures into a single monolithic image. The technology allows each of the other types of images collected during Operation Night Watch to be precisely aligned with each other, thereby allowing all of our data to be seen in context.</p>

  </div>

<div>
    <h2>Physical state of the painting</h2>
<p>Why create such an incredibly huge image? With this resolution, we can very clearly see the precise physical state of the painting. Lead soap protrusions, tiny cracks, the shapes of individual paint pigment particles, past retouches, and the beautiful details of Rembrandt’s painting technique are all extraordinarily clear. This enables researchers to understand the painting’s condition in order to make the best plan for future conservation treatments. It helps us to better understand how Rembrandt painted, and it creates an exquisite 'snapshot’ of The Night Watch at this moment in its history.</p>

  </div>
    </div>
</gtm-scroll-tracker>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kamal Proxy – A minimal HTTP proxy for zero-downtime deployments (190 pts)]]></title>
            <link>https://github.com/basecamp/kamal-proxy</link>
            <guid>41608350</guid>
            <pubDate>Sat, 21 Sep 2024 07:55:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/basecamp/kamal-proxy">https://github.com/basecamp/kamal-proxy</a>, See on <a href="https://news.ycombinator.com/item?id=41608350">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Kamal Proxy - A minimal HTTP proxy for zero-downtime deployments</h2><a id="user-content-kamal-proxy---a-minimal-http-proxy-for-zero-downtime-deployments" aria-label="Permalink: Kamal Proxy - A minimal HTTP proxy for zero-downtime deployments" href="#kamal-proxy---a-minimal-http-proxy-for-zero-downtime-deployments"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What it does</h2><a id="user-content-what-it-does" aria-label="Permalink: What it does" href="#what-it-does"></a></p>
<p dir="auto">Kamal Proxy is a tiny HTTP proxy, designed to make it easy to coordinate
zero-downtime deployments. By running your web applications behind Kamal Proxy,
you can deploy changes to them without interruping any of the traffic that's in
progress. No particular cooperation from an application is required for this to
work.</p>
<p dir="auto">Kamal Proxy is designed to work as part of <a href="https://kamal-deploy.org/" rel="nofollow">Kamal</a>,
which provides a complete deployment experience including container packaging
and provisioning. However, Kamal Proxy could also be used standalone or as part
of other deployment tooling.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A quick overview</h2><a id="user-content-a-quick-overview" aria-label="Permalink: A quick overview" href="#a-quick-overview"></a></p>
<p dir="auto">To run an instance of the proxy, use the <code>kamal-proxy run</code> command. There's no
configuration file, but there are some options you can specify if the defaults
aren't right for your application.</p>
<p dir="auto">For example, to run the proxy on a port other than 80 (the default) you could:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy run --http-port 8080"><pre><code>kamal-proxy run --http-port 8080
</code></pre></div>
<p dir="auto">Run <code>kamal-proxy help run</code> to see the full list of options.</p>
<p dir="auto">To route traffic through the proxy to a web application, you <code>deploy</code> instances
of the application to the proxy. Deploying an instance makes it available to the
proxy, and replaces the instance it was using before (if any).</p>
<p dir="auto">Use the format <code>hostname:port</code> when specifying the instance to deploy.</p>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000"><pre><code>kamal-proxy deploy service1 --target web-1:3000
</code></pre></div>
<p dir="auto">This will instruct the proxy to register <code>web-1:3000</code> to receive traffic under
the service name <code>service1</code>. It will immediately begin running HTTP health
checks to ensure it's reachable and working and, as soon as those health checks
succeed, will start routing traffic to it.</p>
<p dir="auto">If the instance fails to become healthy within a reasonable time, the <code>deploy</code>
command will stop the deployment and return a non-zero exit code, allowing
deployment scripts to handle the failure appropriately.</p>
<p dir="auto">Each deployment takes over all the traffic from the previously deployed
instance. As soon as Kamal Proxy determines that the new instance is healthy,
it will route all new traffic to that instance.</p>
<p dir="auto">The <code>deploy</code> command also waits for traffic to drain from the old instance before
returning. This means it's safe to remove the old instance as soon as <code>deploy</code>
returns successfully, without interrupting any in-flight requests.</p>
<p dir="auto">Because traffic is only routed to a new instance once it's healthy, and traffic
is drained completely from old instances before they are removed, deployments
take place with zero downtime.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Host-based routing</h3><a id="user-content-host-based-routing" aria-label="Permalink: Host-based routing" href="#host-based-routing"></a></p>
<p dir="auto">Host-based routing allows you to run multiple applications on the same server,
using a single instance of Kamal Proxy to route traffic to all of them.</p>
<p dir="auto">When deploying an instance, you can specify a host that it should serve traffic
for:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
</code></pre></div>
<p dir="auto">When deployed in this way, the instance will only receive traffic for the
specified host. By deploying multiple instances, each with their own host, you
can run multiple applications on the same server without port conflicts.</p>
<p dir="auto">Only one service at a time can route a specific host:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # returns &quot;Error: host is used by another service&quot;
kamal-proxy remove service1
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # suceeds"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # returns "Error: host is used by another service"
kamal-proxy remove service1
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # suceeds
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic TLS</h3><a id="user-content-automatic-tls" aria-label="Permalink: Automatic TLS" href="#automatic-tls"></a></p>
<p dir="auto">Kamal Proxy can automatically obtain and renew TLS certificates for your
applications. To enable this, add the <code>--tls</code> flag when deploying an instance:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com --tls"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com --tls
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Specifying <code>run</code> options with environment variables</h2><a id="user-content-specifying-run-options-with-environment-variables" aria-label="Permalink: Specifying run options with environment variables" href="#specifying-run-options-with-environment-variables"></a></p>
<p dir="auto">In some environments, like when running a Docker container, it can be convenient
to specify <code>run</code> options using environment variables. This avoids having to
update the <code>CMD</code> in the Dockerfile to change the options. To support this,
<code>kamal-proxy run</code> will read each of its options from environment variables if they
are set. For example, setting the HTTP port can be done with either:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy run --http-port 8080"><pre><code>kamal-proxy run --http-port 8080
</code></pre></div>
<p dir="auto">or:</p>
<div data-snippet-clipboard-copy-content="HTTP_PORT=8080 kamal-proxy run"><pre><code>HTTP_PORT=8080 kamal-proxy run
</code></pre></div>
<p dir="auto">If any of the environment variables conflict with something else in your
environment, you can prefix them with <code>KAMAL_PROXY_</code> to disambiguate them. For
example:</p>
<div data-snippet-clipboard-copy-content="KAMAL_PROXY_HTTP_PORT=8080 kamal-proxy run"><pre><code>KAMAL_PROXY_HTTP_PORT=8080 kamal-proxy run
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">To build Kamal Proxy locally, if you have a working Go environment you can:</p>

<p dir="auto">Alternatively, build as a Docker container:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Trying it out</h2><a id="user-content-trying-it-out" aria-label="Permalink: Trying it out" href="#trying-it-out"></a></p>
<p dir="auto">See the <a href="https://github.com/basecamp/kamal-proxy/blob/main/example">example</a> folder for a Docker Compose setup that you can use
to try out the proxy commands.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porsche's idea for a six-stroke internal combustion engine (153 pts)]]></title>
            <link>https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/</link>
            <guid>41607887</guid>
            <pubDate>Sat, 21 Sep 2024 06:15:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/">https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=41607887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_box"> <div> <p><span data-time="1726578000"></span><span>Sep 17, 2024</span><span> at</span> 1:00pm ET</p>  </div> <div>  <div> <ul> <li><strong>Porsche has patented a six-stroke internal combustion engine design.</strong></li> <li><strong>It uses a special crankshaft to create extra compression and power strokes per cycle.</strong></li> <li><strong>Nearly all combustion-powered vehicles use a four-stroke engine design.</strong></li> </ul> <hr> <p><a href="https://www.motor1.com/porsche/" data-inline-widget="internal-links" data-type-id="2" data-params="%7B%22alias%22%3A%22porsche%22%7D">Porsche</a>&nbsp;has revealed a strange (and possibly brilliant) idea for a six-stroke combustion engine. If you don't know the fundamentals of an internal combustion engine, we'll try to keep this simple. If you<em> do</em> know how engines work ... we'll still try and keep it simple.</p> <p>With very few exceptions every combustion-powered car uses a four-stroke engine: intake, compression, power, and exhaust. The intake stroke is where air and fuel come into the cylinder. Compression is when the piston pushes that mixture to the top of the cylinder. The mixture is ignited, shoving the piston back down for the power stroke. Exhaust is the final step, pushing the remaining gas out of the cylinder.</p> <section contenteditable="false" draggable="true" data-widget="image" data-border="" data-id="7893499"> <span> <svg> <use xlink:href="https://www.motor1.com/design/dist/critical/icons/sprite-common-4-aab71d103bb6c273cab9291678c627d9.svg#search"></use> </svg> </span> <picture> <source type="image/webp" srcset=" https://cdn.motor1.com/images/mgl/3W4vj6/s5/porsche-six-stroke-combustion-engine-patent.webp 213w, https://cdn.motor1.com/images/mgl/3W4vj6/s6/porsche-six-stroke-combustion-engine-patent.webp 445w, https://cdn.motor1.com/images/mgl/3W4vj6/s4/porsche-six-stroke-combustion-engine-patent.webp 889w, https://cdn.motor1.com/images/mgl/3W4vj6/s3/porsche-six-stroke-combustion-engine-patent.webp 1280w, https://cdn.motor1.com/images/mgl/3W4vj6/s2/porsche-six-stroke-combustion-engine-patent.webp 1440w, https://cdn.motor1.com/images/mgl/3W4vj6/s1/porsche-six-stroke-combustion-engine-patent.webp 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <source type="image/jpeg" srcset=" https://cdn.motor1.com/images/mgl/3W4vj6/s5/porsche-six-stroke-combustion-engine-patent.jpg 213w, https://cdn.motor1.com/images/mgl/3W4vj6/s6/porsche-six-stroke-combustion-engine-patent.jpg 445w, https://cdn.motor1.com/images/mgl/3W4vj6/s4/porsche-six-stroke-combustion-engine-patent.jpg 889w, https://cdn.motor1.com/images/mgl/3W4vj6/s3/porsche-six-stroke-combustion-engine-patent.jpg 1280w, https://cdn.motor1.com/images/mgl/3W4vj6/s2/porsche-six-stroke-combustion-engine-patent.jpg 1440w, https://cdn.motor1.com/images/mgl/3W4vj6/s1/porsche-six-stroke-combustion-engine-patent.jpg 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <img src="https://cdn.motor1.com/images/static/16x9-tr.png" alt="Porsche Six-Stroke Combustion Engine Patent" width="16" height="9" loading="lazy"> </picture> <p>Porsche</p> </section> <p>Porsche designers reckon they can add another compression and power stroke to this process. Documents filed with the US Patent and Trademark Office specifically describe this as "six individual strokes that can be divided into two three-stroke sequences." The added steps would occur between the traditional power and exhaust stroke. The first sequence, then, would be intake-compression-power, followed by compression-power-exhaust.</p> <p>To do this, Porsche's patent shows a crankshaft spinning on a ring with two concentric circles—an annulus. This alternates the center point of rotation, effectively lowering the piston's travel (bottom dead center) slightly for the added strokes. That in turn changes the compression, since the piston isn't traveling as far up (top-dead-center) in the cylinder. And that also means this engine has <em>two</em> top and bottom dead centers.</p> <p>Why all the complexity? In short, this design has the potential to generate more power with better efficiency. In a typical engine, only one stroke in four actually makes power. This changes the formula to one stroke in three, and it also burns up the mixture more thoroughly. Of course, the downside is added complexity. Whether the gains are enough to justify the design remains to be seen.</p> <p>As with many patents, it's possible this could never see the light of day. It's certainly an interesting idea, but perhaps more importantly, it suggests Porsche is working very hard at <a href="https://www.motor1.com/news/714168/porsche-v8-continue-2030s/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22714168%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22porsche-v8-continue-2030s%22%7D">finding ways to keep combustion engines alive</a> amid the push for electric power.</p> <section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22713952%22%2C%22title%22%3A%22Ferrari%20Wants%20to%20Build%20an%20Upside-Down%2C%20Hydrogen%2C%20Twin-Supercharged%20Inline-Six%22%2C%22alias%22%3A%22ferrari-hydrogen-hybrid-supercar-patent%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FwlZZzL%2Fs5%2Fferrari-hydrogen-hybrid-sports-car.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22667392%22%2C%22title%22%3A%22Mazda%20Patent%20Shows%20Another%20Rotary%20Sports%20Car%2C%20This%20Time%20A%20PHEV%20With%20AWD%22%2C%22alias%22%3A%22mazda-rotary-sports-car-patent%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FojBPol%2Fs5%2Fmazda-rotary-sports-car-new-patent.jpg%22%7D%7D%5D%7D"> <p>More Cool Patents:</p>  </section>  </div> <!-- new gallery place, attached gallery --> <p> Source: <span><span>US Patent and Trademark Office</span> via <a target="_blank" href="https://www.autoguide.com/auto/manufacturers/porsche/new-patent-shows-how-porsche-plans-to-keep-combustion-alive-44613226" rel="noopener">AutoGuide</a></span> </p> <!-- Author info bottom -->       </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inside Annapurna Interactive's Mass Walkout (106 pts)]]></title>
            <link>https://www.ign.com/articles/what-the-heck-has-been-going-on-at-annapurna-interactive-an-investigation</link>
            <guid>41607166</guid>
            <pubDate>Sat, 21 Sep 2024 03:05:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ign.com/articles/what-the-heck-has-been-going-on-at-annapurna-interactive-an-investigation">https://www.ign.com/articles/what-the-heck-has-been-going-on-at-annapurna-interactive-an-investigation</a>, See on <a href="https://news.ycombinator.com/item?id=41607166">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Last week, <a href="https://www.bloomberg.com/news/articles/2024-09-12/annapurna-video-game-team-resigns-leaving-partners-scrambling" target="_blank" rel="noopener noreferrer">Bloomberg reported</a> that 25 people comprising the <a href="https://www.ign.com/articles/annapurnas-entire-gaming-team-has-resigned">entire staff of Annapurna Interactive</a> walked out the door in a group resignation. But while some of the circumstances around their departure emerged in the reporting, one pressing question was left unanswered: why?</p><p>Having spoken to multiple individuals close to the situation who requested anonymity due to fear of reprisal, as well as an Annapurna spokesperson, IGN has pieced together a somewhat complex answer. Disagreements over the direction of the Interactive division, chaotic departures, communication breakdowns, and a perceived lack of leadership transparency at Annapurna Interactive led to a staff walk-out that has left 25 individuals jobless, Annapurna leaders scrambling, and numerous developers concerned about their contracts with the publisher.</p><h2>A Company Divided</h2><p>Though the collapse of Annapurna Interactive as we once knew it started earlier this year, its roots lie in the company's historical leadership structure. Annapurna Interactive was initially conceived as the gaming division of Annapurna Pictures, which was founded by film producer and billionaire Megan Ellison in 2011. Annapurna Interactive itself was spun up in 2016, tapping a staff of industry veterans including including former Sony creative director Nathan Gary, former Sony executive producer Deborah Mars, and former Sony producer Hector Sanchez for leadership roles. Sanchez left the company in 2019, and former Capybara Games co-founder Nathan Vella was brought on that same year.</p><p>The film side of Annapurna's business has undergone well-publicized struggles. In 2018, it was <a href="https://variety.com/2018/film/news/annapurna-larry-ellison-megan-ellison-vice-1202975648/" target="_blank" rel="noopener noreferrer">bleeding enough money</a> to prompt Ellison's father, multi-billionaire Larry Ellison, to step in. By 2019, Annapurna Pictures was reportedly <a href="https://www.latimes.com/entertainment-arts/business/story/2019-08-07/annapurna-pictures-explores-bankruptcy-in-a-major-potential-blow-to-indie-film" target="_blank" rel="noopener noreferrer">teetering on bankruptcy</a>, and in the ensuing years its film and TV output slowed significantly. Variety reports that Ellison <a href="https://variety.com/2021/film/news/megan-ellison-annapurna-scott-rudin-temper-1234951651/" target="_blank" rel="noopener noreferrer">disappeared from public life in 2019 almost entirely</a>, leaving her business to largely run itself during the height of the pandemic. She reemerged in 2021, only to name Gary president over all of Annapurna, with Mars and Vella stepping into co-head roles at the Interactive division.</p><output data-cy="article-video"></output><p>In the ensuing years, Annapurna Interactive continued to grow, releasing financial and critical successes such as Stray, Outer Wilds, What Remains of Edith Finch, and Cocoon. While the company claims the Annapurna Pictures side of the business hasn't struggled in recent years, saying that film and TV were more profitable than Annapurna Interactive in 2023, a spokesperson alleged to IGN that Gary was a less-than-ideal steward of Annapurna Pictures. Under his guidance, they claim, resources were pulled away from film and TV, key executives were pushed out, and the company was largely refocused on gaming. Annapurna tells IGN that Gary also elevated co-founder James Masi to chief administrative officer, a role the spokesperson suggested was unnnecessary at a company of Annapurna's size. Notably, Annapurna did launch an animation division under Gary's tenure that released the critically-acclaimed film Nimona just last year, though an Annapurna spokesperson reached out to IGN post-publication with the assertion that it was Ellison who brought in Nimona as the foundation for what would become the animation division. IGN has reached out to Gary, but he declined to comment.</p><p>IGN understands that opinions of Ellison within Annapurna Interactive prior to 2024 varied from indifference to latent mistrust given <a href="https://variety.com/2021/film/news/megan-ellison-annapurna-scott-rudin-temper-1234951651/" target="_blank" rel="noopener noreferrer">previous reports on her behavior toward employees</a>. Anonymous sources I spoke to all cited a strong fear of reprisal from Ellison in particular, given her resources, history, and reach. A few people referenced creative or compensation disagreements during their time at Annapurna that contributed to a general feeling Ellison would not keep promises. Multiple sources we spoke to described Ellison as a largely hands-off leader and rarely present in the gaming division, an attitude that for years suited many of Annapurna Interactive's employees just fine.</p><h2>Ad-Verset effects</h2><p>This was the state of things at the start of 2024 according to our sources. Prior to March of this year, work at Annapurna Interactive was business-as-usual, they say, until employees were suddenly informed mid-month that James Masi had been unexpectedly let go. An Annapurna spokesperson confirmed Masi was made redundant, saying that Ellison had <a href="https://www.hollywoodreporter.com/movies/movie-features/megan-ellison-second-coming-nimona-1235842667/" target="_blank" rel="noopener noreferrer">chosen to step back in</a> at the company and oversee the Annapurna Pictures side again in an effort to re-invest in the film and TV side of the business. As a part of this, Annapurna claims that Ellison reinstalled Gary as head of Interactive, and deemed Masi's role unnnecessary.</p><p>However, at this time, Gary also left the company. Annapurna claims he left of his own accord in response to Masi's firing and his change in role. But sources say employees were told in the following days by leadership within Annapurna Interactive that Gary had been fired along with Masi. The belief that two of their leaders had been fired seemingly out of the blue sparked confusion and fury, and a handful of individuals quit in protest, including at least one other Interactive leader.</p><output data-cy="article-video"></output><p>The sudden resignation of multiple key individuals came as a shock to the company, and IGN understands that Ellison held a video call with Annapurna employees to discuss what had happened and find a way to move forward. On the call, Ellison allegedly expressed a desire to keep the entire group, including those who had been fired or resigned, together. In the following days, all the departed staff returned, including Gary and Masi, and discussions began for a potential spin-off of the company that would allow Gary and Ellison to achieve their respective visions with minimal disruptions to partner developers.</p><p>Roughly, the plan was for Gary and the Annapurna Interactive staff to become a new company called Verset, with ownership split between Annapurna and Verset's leaders. Verset would oversee all currently existing signed Annapurna Interactive projects, with revenue split between itself and Annapurna proper in Annapurna's favor. It would also be free to sign its own, independent deals. Developers IGN spoke to report being made aware the spin-off was happening in the following months, and were reassured their contracts would be fulfilled.</p><p>While employees understood such a venture would take time to get off the ground, in the ensuing months a number of events occurred that made some skeptical of Ellison's commitment to parting with Annapurna Interactive. In early summer, sources tell us that employees discovered Hector Sanchez had been quietly rehired back at Annapurna by Ellison and was working on gaming projects without the knowledge of the rest of the Interactive staff. The news wasn't made official until August that Sanchez had been appointed president of interactive and new media at Annapurna — a title that seemed to some as potentially at odds with Vella and Mars' roles at Interactive.</p><output data-cy="article-video"></output><p>Annapurna, for its part, claims that talks between Ellison and Sanchez began as far back as February for Ellison to fund a new venture Sanchez was planning <a href="https://www.linkedin.com/posts/hectorsanchez_after-5-eventful-years-ive-reached-the-activity-7160635971250589696-MDwF/" target="_blank" rel="noopener noreferrer">after departing Epic Games</a>. As talks continued, Annapurna says Sanchez began negotiating with Remedy Entertainment for a deal related to film and TV spin-offs of its properties. However, when spin-off negotiations began to crystalize at Annapurna Interactive, Ellison offered Sanchez a position at Annapurna. The intent, per the spokesperson, was for Verset to become the company's indie arm, and for Sanchez to lead efforts in the AAA and AA-gaming space, including transmedia properties.</p><p>Which is how, months later, <a href="https://www.ign.com/articles/control-and-alan-wake-tv-and-movies-on-the-way-thanks-to-new-annapurna-partnership">Annapurna announced it was partnering with Remedy Entertainment</a> on film, TV, and other projects including funding support for Control 2. The press release, which IGN received, referenced both Sanchez and Ellison. But it doesn't reference Annapurna Interactive at all, and IGN understands Annapurna Interactive employees were only informed the deal was happening that morning. Employees, unaware of Ellison's plans or the status of the spin-off, were confused, concerned, and frustrated about the direction of the company and the future of its Interactive division, Verset or no Verset.</p><output data-cy="article-video"></output><p>While all this was going on, sources say that discussions with Ellison regarding the spin-off appeared to have stalled out, and in August Annapurna officially terminated discussion. Annapurna claims this was due to Gary's lack of response to requests for feedback on legal drafts, and in a statement sent to IGN after publication, doubled down. "Any implication Annapurna was backtracking on the deal is false. We agreed to high-level deal terms and signed a term sheet in early April, which makes it all the more surprising that we never got a response."</p><p>Meanwhile, multiple people told IGN that in those final months, they began to see signs of Ellison exercising greater involvement over Annapurna Interactive's deals, projects, and budgets in a way that began to make them further uncomfortable with the direction the company was taking overall.</p><p>All of this came to a head at the end of August when all 25 Annapurna Interactive employees including Gary, Vella, Masi, and Mars signed a joint resignation letter. The group gave two weeks notice and departed the company together on September 6 leaving Ellison, Sanchez, and newly-hired chief strategy officer Paul Doyle working on a semblance of Annapurna's gaming efforts. Sources tell IGN that up to the letter being sent and after, the group asked Ellison to work with them on other possible solutions such as the aforementioned spin-off, but did not receive any interest.</p><p>IGN also understands that despite the two-week notice, partner developers did not learn about the sudden exodus of all their Annapurna contacts until a day or two before it occurred. Annapurna claims they didn't have enough time to collect developer contact information to alert them sooner, while Annapurna Interactive sources say they received no guidance from the company during that period as to who should tell developers, when, and how. An Annapurna spokesperson reached out post-publication to IGN to deny this, claiming it had active and open conversations with the Interactive staff on how to communicate the news.</p><h2>Annapurna Aftermath</h2><p>While IGN couldn't glean any details on the future of the 25 departed employees, there are some indications that the group is collectively working on some new venture together. A <a href="https://verset.com/" target="_blank" rel="noopener noreferrer">website for Verset</a> appears to be online at the time of publication with a PR alias, which IGN reached out to for comment. IGN was also unable to find any posts or other discussions from the departed members indicating they were looking for employment elsewhere. Whatever their future plans, IGN understands that the group did not have a ready-made venture waiting when they left, as some have speculated. If they build anything new, it will be largely from scratch.</p><p>Meanwhile, at Annapurna itself, efforts are underway to right the ship. Multiple developers I spoke to expressed a mixture of frustration and confusion at the sudden departure, but several told me they felt confident in Sanchez's ability to honor existing obligations. Several individuals with projects at different stages of development told me about meetings they'd had with Sanchez in the wake of the event that they reported had reassured them. Sanchez has previously stated his intention both to backfill roles as well as work with outside agencies to fulfill Annapurna's contractual obligations, and IGN has confirmed this process is ongoing. Earlier this week, Annapurna also posted an <a href="https://annapurnainteractive.com/en/jobs/publishing-team" target="_blank" rel="noopener noreferrer">open role for a QA Manager</a> overseeing "multiple external QA teams."</p><output data-cy="article-video"></output><p>The unusual situation appears to have impacted a few specific projects in unique ways. On August 30, iam8bit <a href="https://x.com/iam8bit/status/1829618620776734871" target="_blank" rel="noopener noreferrer">shared an announcement</a> that an upcoming PlayStation 5 physical edition of Outer Wilds: Archaeologist Edition had suffered from a manufacturing error, and did not include the Echoes of the Eye expansion as expected. Annapurna Interactive at the time said it would "continue to investigate", while iam8bit offered either a digital DLC voucher to impacted customers, or a replacement corrected physical copy. Both Annapurna and Interactive sources have told IGN that this issue is unrelated to the resignations, and Annapurna reassured that it will not be impacted by the upheaval at the company.</p><p>Then there's Blade Runner. Last summer, Annapurna Interactive announced it would be developing its first in-house game, based on the Blade Runner franchise, titled Blade Runner 2033: Labyrinth. However, game director Chelsea Hash appears to be one of the 25 individuals who resigned, per LinkedIn, and IGN understands that all other full-time members of the development team joined her. Annapurna has told IGN that development on Blade Runner 2033 will continue despite the departure of its entire team.</p><p>An Annapurna spokesperson also shared the following statement when asked for further comment:</p><p>"The whole situation is a baffler, but now we're focused on moving forward. We've had really great conversations with an overwhelming majority of our existing development teams and are grateful for their partnership. If our inbox is any indication, a ton of developers continue to want to be a part of what we're building, and we look forward to seeing their pitches. We've also had an influx of quality job applicants and are excited to build a team passionate about our mission to tell original stories that aren't being told elsewhere. P.S. We're hiring."</p><div data-cy="quoteBox"><p>The whole situation is a baffler.</p></div><p>Annapurna has splintered into two groups, both of which are now working to pick up the pieces. The remains of Annapurna Interactive (or perhaps a future Verset) consist of 25 individuals who felt strongly enough about perceived mismanagement, poor communication, apparent spontaneous layoffs of leaders, and one another that they were willing to give up paychecks and stability at a time of overwhelming industry job and funding uncertainty. When IGN approached its sources close to this group about Annapurna's version of events (specifically, the conflicting information around Masi and Gary's alleged resignation/firing and the collapse of spin-off discussions), they reacted with skepticism, but did not feel they could safely provide more specific details.</p><p>Meanwhile, at Annapurna, a tiny leadership team is struggling to ensure that around 40 projects have the support they need, while the company's partners have been left at various stages of development and uncertainty as to what comes next.</p><p>Annapurna Interactive as we once knew it — a beloved publisher of critically-acclaimed, unique, beloved indie games — is no more. What, if anything, will rise to take its place?</p><p><em>Rebekah Valentine is a senior reporter for IGN. Got a story tip? Send it to rvalentine@ign.com.</em></p><p><em>Additional statements from an Annapurna spokesperson were added to this piece post-publication.</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Like Makefiles (350 pts)]]></title>
            <link>https://switowski.com/blog/i-like-makefiles/</link>
            <guid>41607059</guid>
            <pubDate>Sat, 21 Sep 2024 02:37:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://switowski.com/blog/i-like-makefiles/">https://switowski.com/blog/i-like-makefiles/</a>, See on <a href="https://news.ycombinator.com/item?id=41607059">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<div>
<p>I like makefiles. I first used a makefile more than ten years ago. Even back then, it looked like some ancient technology used by the graybeard Linux wizards. Years passed, and new build tools came and went, but I kept seeing makefiles still used here and there. I got used to them because they were part of some projects I joined. At some point, I started to like them. Today, they are often the first automation tool I use when I start a new project.</p>
<p>The reason I like makefiles is that they often follow an unwritten convention of implementing the same set of commands to get you up and running. When I find a project I know nothing about, and I see a <code>Makefile</code> file inside, chances are that I can run <code>make</code> or <code>make build</code> followed by <code>make install</code>, and I will get this project built and set up on my computer. Or at least I will get information on other steps I need to include.</p>
<p>I try to apply the same rule in my projects. If I open a folder with one of my old projects and run <code>make dev</code>, this will perform all the necessary steps to build the project and spin up a dev server. That's convenient because throughout the years, I used many different technologies, and each had different commands to build or deploy a project. I have old projects written in Jekyll, Hugo, 11ty, and all sorts of different Python web frameworks. With makefiles, when I come back to a project I haven't touched for months (or years), I don't have to remember the command to start a dev server with, let's say, Jekyll. I just run <code>make dev</code>, and this, in turn, fires up the corresponding Bundler commands. Even if I use tools like Docker or gulp in my project, I still use makefiles to orchestrate those tools. For example, I often write a <code>make build</code> command that builds all the necessary Docker images, passing additional parameters specific to a given project.</p>
<p>My makefiles are simple. I don't use conditional statements, flags or any other fancy features. Most of the tasks (they are technically called <em>targets</em>, but I always call them <em>tasks</em> in my head) consist of one or more shell commands. I could write bash scripts with a couple of functions instead, but makefiles are easier and faster to write.</p>
<p>Some common tasks that most of my personal projects<sup><a href="#fn1" id="fnref1">[1]</a></sup> contain include:</p>
<ul>
<li><code>dev</code> to start the development server</li>
<li><code>build</code> to build the project (if a build step is necessary)</li>
<li><code>deploy</code> to deploy/publish the project</li>
</ul>
<p>And that's really it. Sometimes, I include additional tasks like <code>watch</code> to automatically rerun the build task when I change any of the source files. But many of my projects can be managed with just two or three Make commands.</p>
<p>This blog that you're reading right now has a simple makefile with just one target:</p>
<pre data-language="makefile"><code><span>dev</span><span>:</span><br>	npm run dev</code></pre>
<p>And a more advanced project of mine uses the following makefile to run the dev server, watch for changes, build, encrypt and deploy the website:</p>
<pre data-language="makefile"><code><span># Run dev server</span><br><span>dev</span><span>:</span><br>	bundle exec jekyll serve --unpublished -w --config _config.yml,_config-dev.yml --livereload<p><span># Build assets</span><br><span>build</span><span>:</span><br>	npm run gulp build</p><p><span># Watch a specific folder and process assets</span><br><span>watch</span><span>:</span><br>	npm run gulp watch -- --wip</p><p><span># Build the website locally, encrypt and deploy to Netlify server</span><br><span>deploy</span><span>:</span><br>	JEKYLL_ENV<span>=</span>production bundle exec jekyll build<span>;</span> \<br>	make encrypt<span>;</span> \<br>	netlify deploy --prod</p><p><span># Encrypt the "_site" folder</span><br><span>encrypt</span><span>:</span><br>	npx staticrypt _site/*.html -r -d _site</p></code></pre>
<p><a href="https://www.gnu.org/software/make/">GNU Make</a> (the software that runs makefiles) is quite ubiquitous. If you're on Linux, you probably already have it installed. Even on my MacBook, I don't remember installing it explicitly. It must have come with some other tools that I installed in the past. Make is simple and doesn't require as many additional dependencies as some other build tools. This can be useful if you need a tool that will work in a restricted environment where installing additional packages is difficult or impossible for security reasons. Make will probably be already present in that environment. And if not, you can just take the commands from the makefile and run them manually in the shell. If gulp is not available on your server, you can't really take the JavaScript code and paste that into the terminal.</p>
<p>I'm not against other build tools. I like other build tools too. I'm excited when I find a new one that is better and faster than the one I was using before. But I will still use Make to orchestrate them because it gives me a set of familiar commands to manage all sorts of different setups with different tools.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>By "personal", I mean projects where the deployment process is much simpler than production-grade stuff. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Working in the office 5 days/week to build company culture is a myth: PwC report (158 pts)]]></title>
            <link>https://www.msn.com/en-us/money/other/working-in-the-office-5-days-a-week-to-build-company-culture-is-a-myth-pwc-report-says/ar-AA1qU17L</link>
            <guid>41606772</guid>
            <pubDate>Sat, 21 Sep 2024 01:19:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/money/other/working-in-the-office-5-days-a-week-to-build-company-culture-is-a-myth-pwc-report-says/ar-AA1qU17L">https://www.msn.com/en-us/money/other/working-in-the-office-5-days-a-week-to-build-company-culture-is-a-myth-pwc-report-says/ar-AA1qU17L</a>, See on <a href="https://news.ycombinator.com/item?id=41606772">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Shares Full iPhone 16 and iPhone 16 Pro Repair Manuals (201 pts)]]></title>
            <link>https://www.macrumors.com/2024/09/20/iphone-16-repair-manual/</link>
            <guid>41606530</guid>
            <pubDate>Sat, 21 Sep 2024 00:17:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2024/09/20/iphone-16-repair-manual/">https://www.macrumors.com/2024/09/20/iphone-16-repair-manual/</a>, See on <a href="https://news.ycombinator.com/item?id=41606530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2024/09/20/iphone-16-repair-manual/"><p>Following today's launch of the new <a href="https://www.macrumors.com/roundup/iphone-16/">iPhone 16</a> models, Apple has shared repair manuals for the <a href="https://support.apple.com/en-us/120652">iPhone 16</a>, the <a href="https://support.apple.com/en-us/120662">iPhone 16 Plus</a>, the <a href="https://support.apple.com/en-us/120803">iPhone 16 Pro</a>, and the <a href="https://support.apple.com/en-us/120828">iPhone 16 Pro Max</a>. The repair manuals provide technical instructions on replacing genuine Apple parts in the ‌iPhone 16‌ models, and Apple says the information is intended for "individual technicians" that have the "knowledge, experience, and tools" that are necessary to repair electronic devices.</p>
<p><img src="https://images.macrumors.com/t/DyvENV2KG5ztE-4KmOdRWXddhB0=/400x0/article-new/2024/09/apple-iphone-battery-repair.png?lossy" srcset="https://images.macrumors.com/t/DyvENV2KG5ztE-4KmOdRWXddhB0=/400x0/article-new/2024/09/apple-iphone-battery-repair.png?lossy 400w,https://images.macrumors.com/t/yEUxiBQZnvr46Va0nt6XzXTb0nk=/800x0/article-new/2024/09/apple-iphone-battery-repair.png?lossy 800w,https://images.macrumors.com/t/iUIKJQgB3N_lYIBo-1A3ddoJHkQ=/1600x0/article-new/2024/09/apple-iphone-battery-repair.png 1600w,https://images.macrumors.com/t/BOLPZc3YRFrN04Tgf5yZ0UPmptw=/2500x0/filters:no_upscale()/article-new/2024/09/apple-iphone-battery-repair.png 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="apple iphone battery repair" width="880" height="600"><br>Apple <a href="https://support.apple.com/en-us/120983">has support documents</a> on the tools that are required for various repairs, and while the ‌iPhone 16‌ tools aren't yet available on <a href="https://www.selfservicerepair.com/en-US/order">Apple's Self Service Repair website</a>, they'll likely be added soon.</p>
<p>Compared to prior <a href="https://www.macrumors.com/guide/iphone/">iPhone</a> models, the ‌iPhone 16‌ and ‌iPhone 16‌ Plus are easier to repair. Apple is using an electric battery removal process, and the steps for accessing a battery to replace it are outlined in a <a href="https://support.apple.com/en-us/120642">separate support document</a>. Per Apple's instructions, a 9-volt battery and 9-volt battery clips can be applied to the ‌iPhone 16‌ battery to remove the adhesive that holds it in place.</p>
<p>Note that the simpler electricity-based battery removal process is limited to the ‌iPhone 16‌ and ‌iPhone 16‌ Plus. For the <a href="https://www.macrumors.com/roundup/iphone-16-pro/">iPhone 16 Pro</a> and Pro Max, Apple is using standard adhesive tabs that need to be carefully pulled to release the battery.</p>
<p>Apple's instructions for all of the battery repairs include expensive equipment like an ‌iPhone‌ battery press to put a replacement battery back in place. The cost of the tools required for device repair and the cost of genuine components make self repair almost as expensive as getting a repair from an Apple retail location or an Apple Authorized Service Provider, so these manuals are really aimed at independent repair shops rather than individual consumers.</p>
<p>Apple <a href="https://www.macrumors.com/2024/09/18/iphone-16-repairability-changes/">made other changes</a> to the ‌iPhone 16‌ models this year to improve repairability, enabling on-device configuration for the <a href="https://www.macrumors.com/guide/mask-face-id/">Face ID</a> camera, allowing LiDAR Scanner repair, and offering support for swapping the TrueDepth camera modules between ‌iPhone 16‌ and ‌iPhone 16 Pro‌ models.</p>
<p>In addition to offering repair instructions, Apple's manuals provide some insight into the internal structure of the new iPhones that we often don't see until there <a href="https://www.macrumors.com/2024/09/20/iphone-16-pro-teardown-video/">are device teardowns</a>. The ‌iPhone 16 Pro‌, for example, has a metal casing for the battery, a change made for thermal reasons, and both Pro models have new casing structure that improves heat dissipation.</p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2024/09/17/rip-apple-id/">RIP, Apple ID</a></h3><p>Tuesday September 17, 2024 3:18 pm PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>The "Apple ID" era is officially over. The transition from "Apple ID" to "Apple Account" went from a rumor to an official announcement to something that has now been fully completed. As of this week, the account.apple.com website is fully updated with Apple Account branding. "Apple ID is now Apple Account," the page says. "You can still sign in with the same email address or phone...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/15/ios-18-available-tomorrow/">iOS 18 Available Now With These 8 New Features For Your iPhone</a></h3><p>Sunday September 15, 2024 10:09 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Following over three months of beta testing, iOS 18 was finally widely released to the public on Monday, September 16. The update is available in the Settings app under General → Software Update on the iPhone XS and newer. Below, we have highlighted eight key new features included in iOS 18, and Apple shared a complete list of new features and changes last week. Note that Apple...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/19/apple-lists-3-more-states-committed-to-wallet-ids/">Apple Announces iPhone Driver's Licenses Will Come to These Additional U.S. States</a></h3><p>Thursday September 19, 2024 10:45 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>In select U.S. states, residents can add their driver's license or state ID to the Wallet app on the iPhone and Apple Watch, providing a convenient and contactless way to display proof of identity or age at select airports and businesses, and in select apps. The list of states where the feature is available currently includes Arizona, Maryland, Colorado, Georgia, Ohio, Hawaii, and most recently...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/18/apple-airpods-pro-2-firmware-7a302/">Apple Releases New AirPods Pro 2 and AirPods 4 Firmware</a></h3><p>Wednesday September 18, 2024 11:34 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Apple today released a new firmware update for all AirPods Pro 2 and AirPods 4 models. The AirPods Pro 2 firmware has a build number of 7A302, up from 7A294, and the AirPods 4 firmware has a build number of 7A304. There is no word yet on what’s included in the firmware, but it comes just a week after Apple last updated the AirPods Pro 2 firmware to add iOS 18 features like support for head...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/18/apple-breaks-17-year-tradition/">Apple Just Broke a Tradition It Held for 17 Years</a></h3><p>Wednesday September 18, 2024 7:40 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>It's the end of an era. It has been confirmed that the latest iPhones do not come with Apple stickers in the box, breaking a 17-year tradition dating back to the original iPhone. Marques Brownlee shared an unboxing video that confirms the new iPhone 16, iPhone 16 Plus, iPhone 16 Pro, and iPhone 16 Pro Max do not include Apple stickers in the box, as part of Apple's goal of removing plastic...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/17/apple-pulls-ipados-18-m4-ipad-pro/">Apple Pulls iPadOS 18 for M4 iPad Pro After Bricking Complaints [Updated]</a></h3><p>Tuesday September 17, 2024 11:24 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Apple stopped signing the iPadOS 18 update for the M4 iPad Pro models, which means the new software is no longer available to be downloaded and installed at the current time. The update appears to have been pulled following complaints from some iPad Pro owners, who found that the update bricked their devices. There are reports on Reddit from iPad Pro users who had an interruption in the...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CISA boss: Makers of insecure software are the real cyber villains (130 pts)]]></title>
            <link>https://www.theregister.com/2024/09/20/cisa_sloppy_vendors_cybercrime_villains/</link>
            <guid>41606493</guid>
            <pubDate>Sat, 21 Sep 2024 00:05:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/09/20/cisa_sloppy_vendors_cybercrime_villains/">https://www.theregister.com/2024/09/20/cisa_sloppy_vendors_cybercrime_villains/</a>, See on <a href="https://news.ycombinator.com/item?id=41606493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Software suppliers who ship buggy, insecure code are the true baddies in the cyber crime story, Jen Easterly, boss of the US government's Cybersecurity and Infrastructure Security Agency, has argued.</p>
<p>"The truth is: Technology vendors are the characters who are building problems" into their products, which then "open the doors for villains to attack their victims," declared Easterly during a Wednesday <a target="_blank" rel="nofollow" href="https://mwise.mandiant.com/conf24/home">keynote</a> address at Mandiant's mWise conference.</p>
<p>Easterly also implored the audience to stop "glamorizing" crime gangs with fancy poetic names. How about "Scrawny Nuisance" or "Evil Ferret," Easterly suggested.</p>

    

<p>Even calling security holes "software vulnerabilities" is too lenient, she added. This phrase "really diffuses responsibility. We should call them 'product defects,'" Easterly said. And instead of automatically blaming victims for failing to patch their products quickly enough, "why don't we ask: Why does software require so many urgent patches? The truth is: We need to demand more of technology vendors."</p>
<blockquote>

<p>Why does software require so many urgent patches? We need to demand more of vendors</p>
</blockquote>
<p>While everyone in the audience at the annual infosec conference has job security, Easterly joked, it's also the industry's role to make it more difficult for miscreants to compromise systems in the first place.</p>
<p>"Despite a multi-billion-dollar cyber security industry, we still have a multi-trillion-dollar software quality issue leading to a multi-trillion-dollar global cyber crime issue," Easterly lamented.</p>

        


        

<p>While no one would buy a car or board an airplane "entirely at your own risk," we do that every day with the software that underpins America's critical infrastructure, she added.</p>
<p>"Unfortunately we have fallen prey to the myth of techno exceptionalism," Easterly opined. "We don't have a cyber security problem – we have a software quality problem. We don't need more security products – we need more secure products."</p>
<ul>

<li><a href="https://www.theregister.com/2024/07/01/cisa_big_tech_security/">CISA director: US is 'not afraid' to shout about Big Tech's security failings</a></li>

<li><a href="https://www.theregister.com/2024/05/08/cisa_ransomware_rsac/">CISA boss: Secure code is the 'only way to make ransomware a shocking anomaly'</a></li>

<li><a href="https://www.theregister.com/2024/05/09/68_tech_firms_sign_cisas/">68 tech names sign CISA's secure-by-design pledge</a></li>

<li><a href="https://www.theregister.com/2024/05/10/dod_usb_attack/">'Four horsemen of cyber' look back on 2008 DoD IT breach that led to US Cyber Command</a></li>
</ul>
<p>This is a drum Easterly has been <a target="_blank" href="https://www.theregister.com/2023/02/28/cisa_easterly_secure_software/">beating</a> since she took the helm of the US cyber defense agency. She tends to bang it louder at industry events, such as the annual RSA Conference where she <a target="_blank" href="https://www.theregister.com/2024/05/08/cisa_ransomware_rsac/">told</a> attendees secure code "is the only way we can make ransomware and cyber attacks a shocking anomaly."</p>
<p>Naturally, if writing flawless code was super easy, it would be done without fail. Some developers are clearly careless or clueless, leading to vulnerabilities and other bugs, and sometimes skilled humans with the best intentions simply make mistakes. In any case, Easterly isn't happy with the current defect rate.</p>

        

<p>Also at RSAC, nearly 70 big names – including AWS, Microsoft, Google, Cisco, and IBM – <a target="_blank" href="https://www.theregister.com/2024/05/09/68_tech_firms_sign_cisas/">signed</a> CISA's Secure by Design pledge – a commitment to "make a good-faith effort to work towards" seven secure-software goals within a year, and be able to measurably show their progress.</p>
<p>At mWise, Easterly revealed that number has grown to nearly 200 vendors.</p>
<p>But the pledge remains voluntary, so software companies who fail to follow its guidelines – such as increasing the use of multi-factor authentication across their products and reducing default passwords – aren't going to be slapped down if they ignore it.</p>
<div>
<h2 title="Not so much when trying to convert coding veterans">Google says replacing C/C++ in firmware with Rust is easy</h2>
<p><a href="https://www.theregister.com/2024/09/06/google_rust_c_code_language/"><span>READ MORE</span></a></p></div>
<p>Easterly wants that to change. She suggested technology buyers use their procurement power to pressure software vendors, by asking suppliers if they have signed the pledge – and, hopefully, done more than just put ink to paper in terms of building <a target="_blank" rel="nofollow" href="https://www.cisa.gov/sites/default/files/2023-10/Shifting-the-Balance-of-Cybersecurity-Risk-Principles-and-Approaches-for-Secure-by-Design-Software.pdf">secure-by-design</a> [PDF] products.</p>
<p>To this end, CISA just published <a target="_blank" rel="nofollow" href="https://www.cisa.gov/resources-tools/resources/secure-demand-guide">guidance</a> that organizations buying software can use, and questions they should ask manufacturers, to better understand if they are prioritizing security in the product development life cycle.</p>

        

<p>"Use your voice, take an active role, use your purchasing power to advance secure by design, by demanding it," Easterly urged.</p>
<p>And then cross your fingers and pray that more and more vendors really do begin to take things like pre-release <a target="_blank" href="https://www.theregister.com/2024/08/01/crowdstrike_lawsuit/">software testing</a> and <a target="_blank" href="https://www.theregister.com/2024/06/15/microsoft_brad_smith_congress/">secure code</a> to heart. ®</p>                                


                    </div></div>]]></description>
        </item>
    </channel>
</rss>