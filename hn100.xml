<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 17 Dec 2025 19:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A Safer Container Ecosystem with Docker: Free Docker Hardened Images (144 pts)]]></title>
            <link>https://www.docker.com/blog/docker-hardened-images-for-every-developer/</link>
            <guid>46302337</guid>
            <pubDate>Wed, 17 Dec 2025 17:13:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.docker.com/blog/docker-hardened-images-for-every-developer/">https://www.docker.com/blog/docker-hardened-images-for-every-developer/</a>, See on <a href="https://news.ycombinator.com/item?id=46302337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Containers are the universal path to production for most developers, and Docker has always been the steward of the ecosystem. Docker Hub has over 20 billion monthly pulls, with nearly 90% of organizations now relying on containers in their software delivery workflows. That gives us a responsibility: to help secure the software supply chain for the world.</p>



<p>Why? Supply-chain attacks are exploding. In 2025, they caused more than $60 billion in damage, tripling from 2021. No one is safe. Every language, every ecosystem, every build and distribution step is a target.&nbsp;</p>



<p>For this reason, we launched Docker Hardened Images (DHI), a secure, minimal, production-ready set of images, in May 2025, and since then have hardened over 1,000 images and helm charts in our catalog. Today, we are establishing a new industry standard by making DHI freely available and open source to everyone who builds software. All 26 Million+ developers in the container ecosystem. DHI is fully open and free to use, share, and build on with no licensing surprises, backed by an Apache 2.0 license. DHI now gives the world a secure, minimal, production-ready foundation from the very first pull.</p>



<p>If it sounds too good to be true, here’s the bottom line up front: every developer and every application can (and should!) use DHI without restrictions. When you need continuous security patching, applied in under 7 days, images for regulated industries (e.g., FIPS, FedRAMP), you want to build customized images on our secure build infrastructure, or you need security patches beyond end-of-life, DHI has commercial offerings. Simple.</p>



<p>Since the introduction of DHI, enterprises like Adobe and Qualcomm have bet on Docker for securing their entire enterprise to achieve the most stringent levels of compliance, while startups like Attentive and Octopus Deploy have accelerated their ability to get compliance and sell to larger businesses.</p>



<p>Now everyone and every application can build securely from the first <span><code>docker build</code></span>. Unlike other opaque or proprietary hardened images, DHI is compatible with Alpine and Debian, trusted and familiar open source foundations teams already know and can adopt with minimal change. And while some vendors suppress CVEs in their feed to maintain a green scanner, Docker is <em>always </em>transparent, even when we’re still working on patches, because we fundamentally believe you should always know what your security posture is. The result: dramatically reduced CVEs (guaranteed near zero in DHI Enterprise), images up to 95 percent smaller, and secure defaults without ever compromising transparency or trust.</p>



<p>There’s more. We’ve already built Hardened Helm Charts to leverage DHI images in Kubernetes environments; those are open source too. And today, we’re expanding that foundation with Hardened MCP Servers. We’re bringing DHI’s security principles to the MCP interface layer, the backbone of every agentic app. And starting now, you can run hardened versions of the MCP servers developers rely on most: Mongo, Grafana, GitHub, and more. And this is just the beginning. In the coming months, we will extend this hardened foundation across the entire software stack with hardened libraries, hardened system packages, and other secure components everyone depends on. The goal is simple: be able to secure your application from <code><span>main()</span></code> down.&nbsp;</p>







<h2><br><strong>The philosophy of Docker Hardened Images</strong></h2>



<p>Base images define your application’s security from the very first layer, so it’s critical to know exactly what goes into them. Here’s how we approach it.</p>



<p>First: total transparency in every part of our minimal, opinionated, secure images.</p>



<p>DHI uses a distroless runtime to shrink the attack surface while keeping the tools developers rely on. But security is more than minimalism; it requires full transparency. Too many vendors blur the truth with proprietary CVE scoring, downgraded vulnerabilities, or vague promises about reaching SLSA Build Level 3.</p>



<p>DHI takes a different path. Every image includes a complete and verifiable SBOM. Every build provides SLSA Build Level 3 provenance. Every vulnerability is assessed using transparent public CVE data; we won’t hide vulnerabilities when we haven’t fixed them. Every image comes with proof of authenticity. The result: a secure foundation you can trust, built with clarity, verified with evidence, and delivered without compromise.</p>



<p>Second: Migrating to secure images takes real work, and no one should pretend otherwise. But as you’d expect from Docker, we’ve focused on making the DX incredibly easy to use. As we mentioned before, DHI is built on the open source foundations the world already trusts, Debian and Alpine, so teams can adopt it with minimal friction.&nbsp; We’re reducing that friction even more: <a href="https://docs.docker.com/dhi/migration/migrate-with-ai/" id="dkr_dockers-ai-assistant-84109" rel="nofollow noopener" target="_blank">Docker’s AI assistant</a> can scan your existing containers and recommend or even apply equivalent hardened images; the feature is experimental as this is day one, but we’ll quickly GA it as we learn from real world migrations.&nbsp;</p>



<p>Lastly: we think about the most aggressive SLAs and longest support times and make certain that every piece of DHI can support that when you need it.</p>



<p>DHI Enterprise, the commercial offering of DHI, includes a 7-day commitment for critical CVE remediation, with a roadmap toward one day or less. For regulated industries and mission-critical systems, this level of trust is mandatory. Achieving it is hard. It demands deep test automation and the ability to maintain patches that diverge from upstream until they are accepted. That is why most organizations cannot do this on their own. In addition, DHI Enterprise allows organizations to easily customize DHI images, leveraging Docker’s build infrastructure which takes care of the full image lifecycle management for you, ensuring that build provenance and compliance is maintained. For example, typically organizations need to add certificates and keys, system packages, scripts, and so on. DHI’s build service makes this trivial.</p>



<p>Because our patching SLAs and our build service carry real operational cost, DHI has historically been one commercial offering. But our vision has always been broader. This level of security should be available to everyone, and the timing matters. Now that the evidence, infrastructure, and industry partnerships are in place, we are delivering on that vision. That is why today we are making Docker Hardened Images free and open source.</p>



<p>This move carries the same spirit that defined Docker Official Images over a decade ago. We made them free, kept them free, and backed them with clear docs, best practices, and consistent maintenance. That foundation became the starting point for millions of developers and partners.</p>



<p>Now we’re doing it again. DHI being free is powered by a rapidly growing ecosystem of partners, from Google, MongoDB, and the CNCF delivering hardened images to security platforms like Snyk and JFrog Xray integrating DHI directly into their scanners. Together, we are building a unified, end-to-end supply chain that raises the security bar for the entire industry.<strong><br></strong></p>




<div>
        <h4>“Docker’s move to make its hardened images freely available under Apache 2.0 underscores its strong commitment to the open source ecosystem. Many CNCF projects can already be found in the DHI catalog, and giving the broader community access to secure, well-maintained building blocks helps us strengthen the software supply chain together. It’s exciting to see Docker continue to invest in open collaboration and secure container infrastructure.”</h4>
                                    <div>
                                        <p>Jonathan Bryce</p>
                    <p>Executive Director at the Cloud Native Computing Foundation</p>
                </div>
                        </div>



<div>
        <h4>“Software supply chain attacks are a severe industry problem. Making Docker Hardened Images free and pervasive should underpin faster, more secure software delivery across the industry by making the right thing the easy thing for developers.”</h4>
                                    <div>
                                        <p>James Governor</p>
                    <p>Analyst and Co-founder, RedMonk</p>
                </div>
                        </div>



<div>
        <h4>“Security shouldn’t be a premium feature. By making hardened images free, Docker is letting every developer, not just big enterprises, start with a safer foundation. We love seeing tools that reduce noise and toil, and we’re ready to run these secure workloads on Google Cloud from day one”</h4>
                                    <div>
                                        <p>Ryan J. Salva</p>
                    <p>Senior Director of Product at Google, Developer Experiences</p>
                </div>
                        </div>



<div>
        <h4>“At MongoDB, we believe open source plays a central role in how modern software is built, enabling flexibility, choice, and developer productivity. That’s why we’re excited about free Docker Hardened Images for MongoDB. These images provide trusted, ready-to-deploy building blocks on proven Linux foundations such as Alpine and Debian, and with an Apache 2.0 license, they remain fully open source and free for anyone to use. With Docker Hub’s global reach and MongoDB’s commitment to reliability and safety, we are making it easier to build with confidence on a secure and open foundation for the future”</h4>
                                    <div>
                                        <p>Jim Scharf</p>
                    <p>Chief Technology Officer, MongoDB</p>
                </div>
                        </div>



<div>
        <h4>“We’re excited to partner with Docker to deliver secure, enterprise-grade AI workloads from development to production. With over 50 million users and the majority of Fortune 500 trusting Anaconda to help them operate at enterprise scale securely, this partnership with Docker brings that same foundation to Docker Hardened Images. This enables teams to spend less time managing risk and more time innovating, while reducing the time from idea to production.”</h4>
                                    <div>
                                        <p>David DeSanto</p>
                    <p>Chief Executive Officer, Anaconda</p>
                </div>
                        </div>



<div>
        <h4>“Socket stops malicious packages at install time, and Docker Hardened Images (DHI) give those packages a trustworthy place to run. With free DHI, teams get both layers of protection without lifting a finger. Pull a hardened image, run npm install, and the Socket firewall embedded in the DHI is already working for you. That is what true secure-by-default should look like, and we’re excited to partner with Docker and make it happen at their scale.”</h4>
                                    <div>
                                        <p>Feross Aboukhadijeh</p>
                    <p>Founder and CEO, Socket</p>
                </div>
                        </div>



<div>
        <h4>“Teams building with Temporal orchestrate mission-critical workflows, and Docker is how they deploy those services in production. Making Docker Hardened Images freely available gives our users a very strong foundation for those workflows from day one, and Extended Lifecycle Support helps them keep long running systems secure without constant replatforming.”</h4>
                                    <div>
                                        <p>Maxim Fateev</p>
                    <p>Chief Technology Officer, Temporal</p>
                </div>
                        </div>



<div>
        <h4>“At CircleCI, we know teams need to validate code as fast as they can generate it—and that starts with a trusted foundation. Docker Hardened Images eliminate a critical validation bottleneck by providing pre-secured, continuously verified components right from the start, helping teams ship fast, with confidence.”</h4>
                                    <div>
                                        <p>Rob Zuber</p>
                    <p>Chief Technology Officer, CircleCI</p>
                </div>
                        </div>



<div>
        <h4>“We evaluated multiple options for hardened base images and chose Docker Hardened Images (DHI) for its alignment with our supply chain security posture, developer tooling compatibility, Docker’s maturity in this space, and integration with our existing infrastructure. Our focus was on balancing trust, maintainability, and ecosystem compatibility.”</h4>
                                    <div>
                                        <p>Vikram Sethi</p>
                    <p>Principal Scientist, Adobe</p>
                </div>
                        </div>



<div>
        <h4>“Developers deserve secure foundations that do not slow them down. By making Docker Hardened Images freely available, Docker is making it easier than ever to secure the software supply chain at the source. This helps eliminate risk before anything touches production, a mission shared by LocalStack. At LocalStack, we are especially excited that developers will be able to use these hardened, minimal images for our emulators, helping teams finally break free from constant CVE firefighting.”</h4>
                                    <div>
                                        <p>Waldemar Hummer</p>
                    <p>Co-Founder and CTO at LocalStack</p>
                </div>
                        </div>


<h2><strong>A Secure Path for Every Team and Business</strong></h2>



<p>Everyone now has a secure foundation to start from with DHI. But businesses of all shapes and sizes often need more. Compliance requirements and risk tolerance may demand CVE patches ahead of upstream the moment the source becomes available. Companies operating in enterprise or government sectors must meet strict standards such as FIPS or STIG. And because production can never stop, many organizations need security patching to continue even after upstream support ends.</p>



<p>That is why we now offer three DHI options, each built for a different security reality.</p>



<p><strong>Docker Hardened Images: </strong>Free for Everyone. DHI is the foundation modern software deserves: minimal hardened images, easy migration, full transparency, and an open ecosystem built on Alpine and Debian.</p>



<p><strong>Docker Hardened Images (DHI) Enterprise: </strong>DHI Enterprise delivers the guarantees that organizations, governments, and institutions with strict security or regulatory demands rely on. FIPS-enabled and STIG-ready images. Compliance with CIS benchmarks. SLA-backed remediations they can trust for critical CVEs in under 7 days. And those SLAs keep getting shorter as we push toward one-day (or less) critical fixes.</p>



<p>For teams that need more control, DHI Enterprise delivers. Change your images. Configure runtimes. Install tools like curl. Add certificates. DHI Enterprise gives you unlimited customization, full catalog access, and the ability to shape your images on your terms while staying secure.</p>



<p><strong>DHI Extended Lifecycle Support (ELS):</strong> ELS is a paid add-on to DHI Enterprise, built to solve one of software’s hardest problems. When upstream support ends, patches stop but vulnerabilities don’t. Scanners light up, auditors demand answers, and compliance frameworks expect verified fixes. ELS ends that cycle with up to five additional years of security coverage, continuous CVE patches, updated SBOMs and provenance, and ongoing signing and auditability for compliance.</p>



<p>You can learn more about these options <a href="https://www.docker.com/products/hardened-images/" id="dkr_here-84109">here</a>.</p>



<h2><strong>Here’s how to get started</strong></h2>



<p>Securing the container ecosystem is something we do together. Today, we’re giving the world a stronger foundation to build on. Now we want every developer, every open source project, every software vendor, and every platform to make Docker Hardened Images the default.</p>



<ul>
<li>Join our launch <a href="https://www.docker.com/events/dhi-els-launch-webinar/">webinar</a> to get hands-on and learn what’s new.</li>



<li><a href="https://hub.docker.com/hardened-images/catalog" rel="nofollow noopener" target="_blank">Start using</a> Docker Hardened Images today for free.</li>



<li><a href="https://docs.docker.com/dhi/get-started/" rel="nofollow noopener" target="_blank">Explore the docs</a> and bring DHI into your workflows&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li>



<li>Join our <a href="https://docker.com/dhi-partners-sign-up/" rel="nofollow noopener" target="_blank">partner program</a> and help raise the security bar for everyone. &nbsp; &nbsp;</li>
</ul>



<p>Lastly, we are just getting started, and if you’re reading this and want to help build the future of container security, we’d love to meet you. <a href="https://www.docker.com/careers/" id="dkr_join-us-84109">Join us.</a></p>



<h2><strong>Authors’ Notes</strong></h2>



<h3><strong>Christian Dupuis</strong></h3>



<p>Today’s announcement marks a watershed moment for our industry. Docker is fundamentally changing how applications are built-secure by default for every developer, every organization, and every open-source project.&nbsp;</p>



<p>This moment fills me with pride as it represents the culmination of years of work: from the early days at Atomist building an event-driven SBOM and vulnerability management system, the foundation that still underpins Docker Scout today, to unveiling DHI earlier this year, and now making it freely available to all. I am deeply grateful to my incredible colleagues and friends at Docker who made this vision a reality, and to our partners and customers who believed in us from day one and shaped this journey with their guidance and feedback.</p>



<p>Yet while this is an important milestone, it remains just that, a milestone. We are far from done, with many more innovations on the horizon. In fact, we are already working on what comes next.</p>



<p>Security is a team sport, and today Docker opened the field to everyone. Let’s play.</p>



<h3><strong>Michael Donovan</strong></h3>



<p>I joined Docker to positively impact as many developers as possible. This launch gives every developer the right to secure their applications without adding toil to their workload. It represents a monumental shift in the container ecosystem and the digital experiences we use every day.</p>



<p>I’m extremely proud of the product we’ve built and the customers we serve every day. I’ve had the time of my life building this with our stellar team and I’m more excited than ever for what’s to come next.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas' (360 pts)]]></title>
            <link>https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers</link>
            <guid>46302267</guid>
            <pubDate>Wed, 17 Dec 2025 17:08:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers">https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers</a>, See on <a href="https://news.ycombinator.com/item?id=46302267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div cta-rich-text="" fs-toc-element="contents" fs-toc-offsettop="1.5rem"><figure><p><img src="https://cdn.prod.website-files.com/6660a5bfdcf6c5fbf039f446/69428e2d7c764c046536a548_AWS%20CEO%20Junior%20Developers%20AI.jpg" loading="lazy" alt="AWS CEO Junior Developers AI"></p></figure><p>‍</p><p><strong>AWS CEO Matt Garman outlined 3 solid reasons why companies should not focus on cutting junior developer roles, noting that they “<em>are actually the most experienced with the AI tools</em>”.</strong></p><h2><strong>3 Reasons AI Should Not Replace Junior Developers</strong></h2><p>In a tech world obsessed with AI replacing human workers, Matt Garman, CEO of Amazon Web Services (AWS), is pushing back against one of the industry’s most popular cost-cutting ideas.</p><p>Speaking on <a href="https://www.wired.com/story/the-big-interview-podcast-matt-garman-ceo-aws/" target="_blank" rel="nofollow"><em>WIRED’s The Big Interview</em> podcast</a>, Garman has a bold message for companies racing to cut costs with AI.</p><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/6660a5bfdcf6c5fbf039f446/69428e63cef065d3e9f62638_Matt%20Garman%20on%20Junior%20Developers.jpg" loading="lazy" alt="Matt Garman on Junior Developers"></p></figure><p>‍</p><p>He was asked to explain why he once called replacing junior employees with AI “<a href="https://www.finalroundai.com/blog/aws-ceo-matt-garman-says-replacing-junior-developers-with-ai-the-dumbest-thing"><em>one of the dumbest ideas</em></a>” he’d ever heard, and to expand on how he believes agentic AI will actually change the workplace in the coming years.</p><h3><strong>1) Junior Devs Often Know AI Tools Better</strong></h3><p><strong>First, junior employees are often better with AI tools than senior staff.</strong>&nbsp;</p><blockquote><em>“Number one, my experience is that many of the most junior folks are actually the most experienced with the AI tools. So they're actually most able to get the most out of them.”</em></blockquote><p>‍</p><p>Fresh grads have grown up with new technology, so they can adapt quickly. Many of them learn AI-powered tools while studying or during internships. They tend to explore new features, find quick methods to write code, and figure out how to get the best results from AI agents.&nbsp;</p><p>According to the <a href="https://survey.stackoverflow.co/2025/ai?utm_source=chatgpt.com#sentiment-and-usage-ai-sel-prof-exp" target="_blank" rel="nofollow">2025 Stack Overflow Developer Survey</a>, 55.5% of early-career developers reported using AI tools daily in their development process, higher than for the experienced folks.</p><p>This comfort with new tools allows them to work more efficiently. In contrast, senior developers have established workflows and may take more time to adopt. <a href="https://www.peoplemanagement.co.uk/article/1930418/half-gen-z-help-senior-colleagues-upskill-ai-study-finds" target="_blank" rel="nofollow">Recent research</a> shows that over half of Gen Z employees are actually helping senior colleagues upskill in AI.</p><h3><strong>2) Junior Developers Shouldn’t Be The Default Cost-Saving Move</strong></h3><p><strong>Second, junior staff are usually the least expensive employees.</strong></p><blockquote><em>“Number two, they're usually the least expensive because they're right out of college, and they generally make less. So if you're thinking about cost optimization, they're not the only people you would want to optimize around.”</em></blockquote><p>‍</p><p>Junior employees usually get much less in salary and benefits, so removing them does not deliver huge savings. If a company is trying to save money, it doesn’t make that much financial sense.&nbsp;</p><p>So, when companies talk about increasing profit margins, junior employees should not be the default or only target. True optimization, Real cost-cutting means looking at the whole company because there are plenty of other places where expenses can be trimmed.</p><p>In fact, 30% of companies that laid off workers expecting savings <a href="https://myabcm.com/layoffs-the-cost-cutting-measure-that-could-sink-your-company" target="_blank" rel="nofollow">ended up increasing expenses</a>, and many had to rehire later.&nbsp;</p><h3><strong>3) Removing Juniors Breaks the Talent Pipeline</strong></h3><p><strong>Third, companies need fresh talent.</strong></p><blockquote><em>“Three, at some point, that whole thing explodes on itself. If you have no talent pipeline that you're building and no junior people that you're mentoring and bringing up through the company, we often find that that's where we get some of the best ideas.”</em></blockquote><p>‍</p><p>Think of a company like a sports team. If you only keep veteran players and never recruit rookies, what happens when those veterans retire? You are left with no one who knows how to play the game.</p><p>Also, hiring people straight out of college brings new ways of thinking into the workplace. They have fresh ideas shaped by the latest trends, motivation to innovate.&nbsp;</p><p>More importantly, they form the foundation of a company’s future workforce. If a company decides to stop hiring junior employees altogether, it cuts off its own talent pipeline. Over time, that leads to fewer leaders to promote from within.</p><p>A <a href="https://www.deloitte.com/us/en/insights/topics/talent/overcoming-the-tech-talent-shortage-amid-transformation.html" target="_blank" rel="nofollow">Deloitte report</a> also notes that the tech workforce is expected to grow at roughly twice the rate of the overall U.S. workforce, highlighting the demand for tech talent. Without a strong pipeline of junior developers coming in, companies might face a tech talent shortage.&nbsp;</p><p>When there are not enough junior hires being trained today, teams struggle to fill roles tomorrow, especially as projects scale.</p><h2><strong>Bottom Line</strong></h2><p>This isn’t just corporate talk. As the leader of one of the world’s largest cloud computing platforms, serving everyone from Netflix to the U.S. intelligence agencies, Garman has a front-row seat to how companies are actually using AI.&nbsp;</p><p>And what he is seeing makes him worried that short-term thinking could damage businesses for years to come. Garman’s point is grounded in long-term strategy. A company that relies solely on AI to handle tasks without training new talent could find itself short of people.</p><p>Still, Garman admits the next few years will be bumpy. “Y<em>our job is going to change</em>,” he said. He believes AI will make companies more productive as well as the employees.&nbsp;</p><p>When technology makes something easier, people want more of it. AI enables the creation of software faster, allowing companies to develop more products, enter new markets, and serve more customers.</p><p>Developers will be responsible for more than just writing code, with faster adaptation to new technologies becoming essential. But he has a hopeful message in the end.</p><p>That’s why Geoffrey Hinton has advised that <a href="https://www.finalroundai.com/blog/ai-godfather-geoffrey-hinton-mid-level-coding-jobs">Computer Science degrees remain essential</a>. This directly supports Matt Garman’s point. Fresh talent with a strong understanding of core fundamentals becomes crucial for filling these higher-value roles of the future.</p><p>“<strong><em>I’m very confident in the medium to longer term that AI will definitely create more jobs than it removes at first,</em></strong>” Garman said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: HN Was Down (289 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46301921</link>
            <guid>46301921</guid>
            <pubDate>Wed, 17 Dec 2025 16:48:18 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46301921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46302176"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302176" href="https://news.ycombinator.com/vote?id=46302176&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Is this still a valid account for HN status? It says it’s the official one, but with the changes at Twitter to no longer show chronological feeds (at least for users that aren’t logged in), it’s rather useless. The top 5 listed post (for me) are seemingly random from 2014 - 2022.</p><p><a href="https://x.com/HNStatus" rel="nofollow">https://x.com/HNStatus</a></p><p>Is there a better place to check, beyond a basic down detector that may provide more insight or signal that the outage is acknowledged?</p></div></td></tr></tbody></table></td></tr><tr id="46302580"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302580" href="https://news.ycombinator.com/vote?id=46302580&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Only way I have figured out how to to change the "Following" sort order back to chronoligical is from the mobile app: click the down arrow on the "Following" tab. Change the sort from "popular" to "most recent."</p><p>Seems to reset it on the web view, too.</p></div></td></tr></tbody></table></td></tr><tr id="46302222"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302222" href="https://news.ycombinator.com/vote?id=46302222&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p><a href="https://hn.hund.io/" rel="nofollow">https://hn.hund.io/</a> Is a status page, no idea if official or not, but it didn't register here for some reason.</p><p>I didn't read the post text, it's identified there haha, my bad! I wish the text post text wasn't grey, I gloss over it too easily.</p></div></td></tr></tbody></table></td></tr><tr id="46302334"><td></td></tr><tr id="46301962"><td></td></tr><tr id="46302563"><td></td></tr><tr id="46302487"><td></td></tr><tr id="46302271"><td></td></tr><tr id="46302115"><td></td></tr><tr id="46302517"><td></td></tr><tr id="46302398"><td></td></tr><tr id="46302143"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302143" href="https://news.ycombinator.com/vote?id=46302143&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It just reinforces for me that addiction is a human problem not a problem with technology</p><p>I know dang basically works 
tirelessly to not change the format in order to not induce those addictive patterns</p><p>but yet here we all are</p></div></td></tr></tbody></table></td></tr><tr id="46302199"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302199" href="https://news.ycombinator.com/vote?id=46302199&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's a website with the smartest people in the world. The level of conversations here are unrivaled in internet communities.</p><p>It's understandable to be addicted. Lol.</p><p>I visit this place multiple times a day.</p></div></td></tr></tbody></table></td></tr><tr id="46302506"><td></td></tr><tr id="46302607"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46302607" href="https://news.ycombinator.com/vote?id=46302607&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Now now, HN does have its unusually high share of "Very Stable Geniuses" and "High I.Q. Individuals", we have to acknowledge that.</p></div></td></tr></tbody></table></td></tr><tr id="46302285"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46302285" href="https://news.ycombinator.com/vote?id=46302285&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's really not 'the smartest people.' It's people interested in tech, and often in making-a-lot-of-money-in-tech. It does have a lot of people with significant industry experience, which is cool.</p></div></td></tr></tbody></table></td></tr><tr id="46302523"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46302523" href="https://news.ycombinator.com/vote?id=46302523&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>&gt; It's really not 'the smartest people.'</p><p>This was especially obvious during Covid, I even stopped visiting because the comment section was so crazy.</p></div></td></tr></tbody></table></td></tr><tr id="46302395"><td></td></tr><tr id="46302359"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302359" href="https://news.ycombinator.com/vote?id=46302359&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>This one is at least healthy-ish for the mind. I’d much rather hacker news than any other news. Social Media is an emotional rage-bait cesspool these days. If it’s not for Hacker News those of us who abstain from the rest would be living in the dark.</p></div></td></tr></tbody></table></td></tr><tr id="46302049"><td></td></tr><tr id="46302283"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302283" href="https://news.ycombinator.com/vote?id=46302283&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I got stuck in an infinite loop.</p><p>Try opening HN -&gt; it's down, better check HN to see everyone talking about a major website being down -&gt; Try opening HN -&gt; loop</p></div></td></tr></tbody></table></td></tr><tr id="46302389"><td></td></tr><tr id="46302451"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302451" href="https://news.ycombinator.com/vote?id=46302451&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I always hated the late use-it-or-loose-it at the end of the year where you end up buying the things that were denied requests from earlier in the year. You just cost me half a year of using the damn thing.</p></div></td></tr></tbody></table></td></tr><tr id="46302566"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302566" href="https://news.ycombinator.com/vote?id=46302566&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>In other words, productivity in tech skyrocketed for hours..though it seems some work was flavoured with irrational anger.</p></div></td></tr></tbody></table></td></tr><tr id="46302482"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302482" href="https://news.ycombinator.com/vote?id=46302482&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I was able to view the site without being signed in (i.e. private window) but any browser I was logged into wouldn't load.</p><p>I'm sure it's a coincidence but it started working again shortly after emailing hn@ycombinator.com</p></div></td></tr></tbody></table></td></tr><tr id="46302039"><td></td></tr><tr id="46302192"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302192" href="https://news.ycombinator.com/vote?id=46302192&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Next time you can avoid that fate by opening HN in a private browsing (or whatever your browser calls its equivalent) window. This outage, like the vast majority of HN outages, only affected logged in requests.</p><p>I suppose you could also just clear your HN cookies in regular browsing window, but then when they fix it you'd have to log in again.</p></div></td></tr></tbody></table></td></tr><tr id="46302179"><td></td></tr><tr id="46301960"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46301960" href="https://news.ycombinator.com/vote?id=46301960&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Yeah I couldn't log in for a bit this morning. It's concerning how often and how many times I tried. Glad it's resolved.</p></div></td></tr></tbody></table></td></tr><tr id="46302136"><td></td></tr><tr id="46302187"><td></td></tr><tr id="46302174"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302174" href="https://news.ycombinator.com/vote?id=46302174&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>A lot of the outage indicators failed. Someone needs to create an outage indicator reliability dashboard.</p></div></td></tr></tbody></table></td></tr><tr id="46302206"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302206" href="https://news.ycombinator.com/vote?id=46302206&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>A lot of them got fooled by the caching; pages for signed-out users are cached heavily and those kept returning successful responses even if the actual backend server was down.</p></div></td></tr></tbody></table></td></tr><tr id="46302340"><td></td></tr><tr id="46302394"><td></td></tr><tr id="46302215"><td></td></tr><tr id="46302240"><td></td></tr><tr id="46302062"><td></td></tr><tr id="46302200"><td></td></tr><tr id="46302160"><td></td></tr><tr id="46302175"><td></td></tr><tr id="46302171"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302171" href="https://news.ycombinator.com/vote?id=46302171&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It was the first time since I started using this website (August last year) that it was down.</p><p>I'm still impressed nonetheless.</p><p>I'd like to know what caused the outage and how it could have been prevented, for learning purposes.</p></div></td></tr></tbody></table></td></tr><tr id="46302214"><td></td></tr><tr id="46302315"><td></td></tr><tr id="46302069"><td></td></tr><tr id="46302166"><td></td></tr><tr id="46302157"><td></td></tr><tr id="46302209"><td></td></tr><tr id="46302322"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46302322" href="https://news.ycombinator.com/vote?id=46302322&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>&gt; how do you keep track of his comments?</p><p>You can just look at them, turn on showdead in your profile and you'll see a bunch of flag-killed comments in this discussion by whatevermrfukz. No need for a plugin or scraper.</p></div></td></tr></tbody></table></td></tr><tr id="46302404"><td></td></tr><tr id="46302421"><td></td></tr><tr id="46302335"><td></td></tr><tr id="46302510"><td></td></tr><tr id="46302347"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302347" href="https://news.ycombinator.com/vote?id=46302347&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I got confused by the "minutes ago" thing.</p><p>Working with full dates in the HTML and doing a tiny JavaScript that calculates the "minutes ago" would actually be a neat improvement.</p></div></td></tr></tbody></table></td></tr><tr id="46302241"><td></td></tr><tr id="46302609"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302609" href="https://news.ycombinator.com/vote?id=46302609&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I thought I was being rate-limited for opening posts too fast, which has happened before.</p><p>After more than an hour I thought, "wow this is pretty harsh" and "so much of my exposure to learning things is directly tied to HN posts". I was lost lol.</p></div></td></tr></tbody></table></td></tr><tr id="46302107"><td></td></tr><tr id="46302104"><td></td></tr><tr id="46302112"><td></td></tr><tr id="46302195"><td></td></tr><tr id="46302248"><td></td></tr><tr id="46302083"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302083" href="https://news.ycombinator.com/vote?id=46302083&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Just a month ago, I got downvoted to -2 for saying HN for being self-hosted hasn't shown up as more reliable than something behind Cloudflare. My point is made.</p><p>Edit: Now it happens again. Knee jerk defenses all the way down.</p></div></td></tr></tbody></table></td></tr><tr id="46302203"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302203" href="https://news.ycombinator.com/vote?id=46302203&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Unless the downtime was caused by something Cloudflare would've prevented, this downtime would've happened regardless of being behind Cloudflare. Cloudflare adds another single point of failure.</p></div></td></tr></tbody></table></td></tr><tr id="46302177"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302177" href="https://news.ycombinator.com/vote?id=46302177&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Could this be a self-inflicted bug? In that case, the broader point still stands: cloud providers can cause outages that are outside your direct realm of responsibility.</p></div></td></tr></tbody></table></td></tr><tr id="46302185"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302185" href="https://news.ycombinator.com/vote?id=46302185&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Your VPS server and your data center and the ISP your data center uses and the AS system your ISP uses all can cause outages outside your direct realm of responsibility.</p></div></td></tr></tbody></table></td></tr><tr id="46302300"><td></td></tr><tr id="46302198"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302198" href="https://news.ycombinator.com/vote?id=46302198&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's absolutely irresistible downvoting people who preemptively complain about being downvoted like you do. It really made my day. Post another complaint so I can do it again please! It's not knee jerk when you explicitly ask for it, by leading with a complaint about downvoting, instead of just making your point and letting it fall or rise on its own merits. You're the one who put the idea of downvoting you into my head in the first place.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 3 Flash: frontier intelligence built for speed (412 pts)]]></title>
            <link>https://blog.google/products/gemini/gemini-3-flash/</link>
            <guid>46301851</guid>
            <pubDate>Wed, 17 Dec 2025 16:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gemini/gemini-3-flash/">https://blog.google/products/gemini/gemini-3-flash/</a>, See on <a href="https://news.ycombinator.com/item?id=46301851">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
  }">
  
  <div>
      
      
        <p>
          Gemini 3 Flash is our latest model with frontier intelligence built for speed that helps everyone learn, build, and plan anything — faster.
        </p>
      
    </div>
  
  <div data-component="uni-ai-generated-summary" data-analytics-module="{
    &quot;event&quot;: &quot;module_impression&quot;,
    &quot;module_name&quot;: &quot;ai_summary&quot;,
    &quot;section_header&quot;: &quot;CTA&quot;
  }">
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Google is releasing Gemini 3 Flash, a fast and cost-effective model built for speed. You can now access Gemini 3 Flash through the Gemini app and AI Mode in Search. Developers can access it via the Gemini API in Google AI Studio, Google Antigravity, Gemini CLI, Android Studio, Vertex AI and Gemini Enterprise.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_2">
          <h2>Bullet points</h2>
          <ul>
<li>"Gemini 3 Flash: frontier intelligence built for speed" introduces a fast, efficient AI model.</li>
<li>Gemini 3 Flash offers Pro-grade reasoning at Flash-level speed and a lower cost.</li>
<li>It's great for coding, complex analysis, and quick answers in interactive apps.</li>
<li>Gemini 3 Flash is now the default model in the Gemini app and AI Mode in Search.</li>
<li>Developers and everyday users can access Gemini 3 Flash via various Google platforms.</li>
</ul>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      
      <div>
        <h4>
          Explore other styles:
        </h4>
        
      </div>
      

      </div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Gemini 3 Flash text" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header_.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header_.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
  
    



















<div data-component="uni-audio-player-tts" uni-l10n="{
       &quot;stop&quot;: &quot;Click to stop audio&quot;,
       &quot;play&quot;: &quot;Click to play audio&quot;,
       &quot;progress&quot;: &quot;Current audio progress minutes with seconds: [[progress]]&quot;,
       &quot;duration&quot;: &quot;Duration of the audio minutes with seconds: [[duration]]&quot;,
       &quot;settings&quot;: &quot;Click for settings&quot;,
       &quot;timeText&quot;: &quot;[[duration]] minutes&quot;
     }" data-analytics-module="{
      &quot;module_name&quot;: &quot;Audio TTS&quot;,
      &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
     }" data-tts-audios="[
      
        {&quot;voice_name&quot;: &quot;Gacrux&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82955_gacrux_2025_12_17_16_29_26.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;},
      
        {&quot;voice_name&quot;: &quot;Umbriel&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82955_umbriel_2025_12_17_16_31_33.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;}
      ]">
  <p><audio title="Gemini 3 Flash: frontier intelligence built for speed">
      <source src="https://blog.google/products/gemini/gemini-3-flash/self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type">
      <p>Your browser does not support the audio element.</p>
  </audio></p><div aria-label="">
        <p><span>
          Listen to article
          <span tabindex="0" role="tooltip" aria-label="This content is generated by Google AI. Generative AI is experimental">
            <p>This content is generated by Google AI. Generative AI is experimental</p>
            <svg>
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251215-1743#ttf-info"></use>
</svg>

          </span>
        </span></p><p>[[duration]] minutes</p>
      </div>
</div>

  





            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><p data-block-key="qapzx">Today, we're expanding the Gemini 3 model family with the release of Gemini 3 Flash, which offers frontier intelligence built for speed at a fraction of the cost. With this release, we’re making Gemini 3’s next-generation intelligence accessible to everyone across Google products.</p><p data-block-key="b4nrq">Last month, we kicked off Gemini 3 with <a href="https://blog.google/products/gemini/gemini-3/#note-from-ceo">Gemini 3 Pro</a> and <a href="https://blog.google/products/gemini/gemini-3-deep-think/">Gemini 3 Deep Think</a> mode, and the response has been incredible. Since launch day, we have been processing over 1T tokens per day on our API. We’ve seen you use Gemini 3 to <a href="https://x.com/googleaidevs/status/1991333601959350306">vibe code simulations</a> to learn about complex topics, build and design <a href="https://x.com/googleaidevs/status/1991318283065131160">interactive games</a> and understand all types of <a href="https://x.com/googleaidevs/status/1997033279610818745?s=20">multimodal content</a>.</p><p data-block-key="3c1p3">With Gemini 3, we introduced frontier performance across complex reasoning, <a href="https://blog.google/technology/developers/gemini-3-pro-vision/">multimodal and vision understanding</a> and agentic and vibe coding tasks. Gemini 3 Flash retains this foundation, combining Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost. It not only enables everyday tasks with improved reasoning, but also is our most impressive model for agentic workflows.</p><p data-block-key="347o3">Starting today, Gemini 3 Flash is rolling out to millions of people globally:</p><ul><li data-block-key="4suea">For developers in the Gemini API in <a href="https://blog.google/technology/developers/build-with-gemini-3-flash">Google AI Studio</a>, <a href="https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/">Gemini CLI</a> and our new agentic development platform <a href="https://antigravity.google/blog/gemini-3-flash-in-google-antigravity">Google Antigravity</a></li><li data-block-key="72mi8">For everyone via the <a href="https://blog.google/products/gemini/gemini-3-flash-gemini-app/">Gemini app</a> and in <a href="https://blog.google/products/search/google-ai-mode-update-gemini-3-flash">AI Mode in Search</a></li><li data-block-key="7upf8">For enterprises in <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-3-flash-for-enterprises">Vertex AI and Gemini Enterprise</a></li></ul></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">Gemini 3 Flash: frontier intelligence at scale</h2><p data-block-key="b8etv">Gemini 3 Flash demonstrates that speed and scale don’t have to come at the cost of intelligence. It delivers frontier performance on PhD-level reasoning and knowledge benchmarks like GPQA Diamond (90.4%) and Humanity’s Last Exam (33.7% without tools), rivaling larger frontier models, and significantly outperforming even the best 2.5 model, Gemini 2.5 Pro, across a number of benchmarks. It also reaches state-of-the-art performance with an impressive score of 81.2% on MMMU Pro, comparable to Gemini 3 Pro.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="A benchmark comparison table showing performance scores and prices for several language models including Gemini 3 Flash, Gemini 3 Pro Thinking, Gemini 2.5 Flash Thinking, Gemini 2.5 Pro Thinking, Claude Sonnet 4.5, GPT-5.2 Extra high, and Grok 4.1 Fast, across various tasks like academic reasoning, scientific knowledge, math, multi-modal understanding, coding, and long context performance." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Flash: frontier intelligence built for speed" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-table_light_25-1.original.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="A benchmark comparison table showing performance scores and prices for several language models including Gemini 3 Flash, Gemini 3 Pro Thinking, Gemini 2.5 Flash Thinking, Gemini 2.5 Pro Thinking, Claude Sonnet 4.5, GPT-5.2 Extra high, and Grok 4.1 Fast, across various tasks like academic reasoning, scientific knowledge, math, multi-modal understanding, coding, and long context performance." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-ta.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-ta.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-t.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">In addition to its frontier-level reasoning and multimodal capabilities, Gemini 3 Flash was built to be highly efficient, pushing the Pareto frontier of quality vs. cost and speed. When processing at the highest thinking level, Gemini 3 Flash is able to modulate how much it thinks. It may think longer for more complex use cases, but it also uses 30% fewer tokens on average than 2.5 Pro, as measured on typical traffic, to accurately complete everyday tasks with higher performance.</p>
      </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="A scatter plot showing LMArena Elo Score versus Price per million tokens for various language models, with a line highlighting the Pareto frontier through 'gemini-3-pro', 'gemini-3-flash', and 'gemini-3-flash-lite'." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Flash: frontier intelligence built for speed" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17_1_DF5Txhz.original.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="90v27">Gemini 3 Flash pushes the Pareto frontier on performance vs. cost and speed.</p>
    </div>
  
  
    <p><img alt="A scatter plot showing LMArena Elo Score versus Price per million tokens for various language models, with a line highlighting the Pareto frontier through 'gemini-3-pro', 'gemini-3-flash', and 'gemini-3-flash-lite'." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec1.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="yrydl">Gemini 3 Flash’s strength lies in its raw speed, building on the Flash series that developers and consumers already love. It outperforms 2.5 Pro while being 3x faster (based on <a href="https://artificialanalysis.ai/models/gemini-3-flash-reasoning">Artificial Analysis</a> benchmarking) at a fraction of the cost. Gemini 3 Flash is priced at $0.50/1M input tokens and $3/1M output tokens (audio input remains at $1/1M input tokens).</p>
      </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Dynamic thinking in Gemini 3 Flash demo" external-image="" or-mp4-video-title="Gemini 3 Flash Action Replay" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Keyword_ACTION_REPLAY_V10_1.mp4" section-header="Gemini 3 Flash: frontier intelligence built for speed" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">For developers: intelligence that keeps up</h2><p data-block-key="8tjig">Gemini 3 Flash is made for iterative development, offering Gemini 3’s Pro-grade coding performance with low latency — it’s able to reason and solve tasks quickly in high-frequency workflows. On SWE-bench Verified, a benchmark for evaluating coding agent capabilities, Gemini 3 Flash achieves a score of 78%, outperforming not only the 2.5 series, but also Gemini 3 Pro. It strikes an ideal balance for agentic coding, production-ready systems and responsive interactive applications.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="9" thumbnail-alt="Demo of Gemini 3 Flash for developers" subtitle="Gemini 3 Flash in Google Antigravity works quickly to update production-ready applications." video-id="MPkgMSWQMSU" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">Gemini 3 Flash’s strong performance in reasoning, tool use and multimodal capabilities is ideal for developers looking to do more complex video analysis, data extraction and visual Q&amp;A, which means it can enable more intelligent applications — like in-game assistants or A/B test experiments — that demand both quick answers and deep reasoning.</p>
      </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/SlingShot_Thumbnail_vF.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash sling shot game demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Sling Shot&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini3Flash_SpinnerEvolve_short_noendcard.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Spinner Evolve demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Spinner Evolve&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Disc_augmented_image_asset3_1.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash demo Cloud City&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;cloud city updated&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini3flash_threeuniquevariations.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash demo showing design variations in UI&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash three unique variations&quot;
      }
    
  ]">
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">We’ve received a tremendous response from companies using Gemini 3 Flash. Companies like JetBrains, Bridgewater Associates, and Figma are already using it to transform their businesses, recognizing how its inference speed, efficiency and reasoning capabilities perform on par with larger models. Gemini 3 Flash is available today to enterprises via Vertex AI and Gemini Enterprise.</p>
      </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-jetb.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-jetb.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;JetBrains customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-aia-.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-aia-.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Bridgewater customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-figm.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-figm.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Figma customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-curs.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-curs.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Cursor customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-warp.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-warp.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Warp customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-harv.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-harv.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Harvey customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-astr.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-astr.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Astrocade customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-pres.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-pres.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Presentations.ai customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-repl.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-repl.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Replit customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-lati.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-lati.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Latitude customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      }
    
  ]">
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">For everyone: Gemini 3 Flash is rolling out globally</h2><p data-block-key="5hmpf">Gemini 3 Flash is now the default model in the Gemini app, replacing 2.5 Flash. That means all of our Gemini users globally will get access to the Gemini 3 experience at no cost, giving their everyday tasks a major upgrade.</p><p data-block-key="1f9e7">Because of Gemini 3 Flash’s incredible multimodal reasoning capabilities, you can use it to help you see, hear and understand any type of information faster. For example, you can ask Gemini to understand your videos and images and turn that content into a helpful and actionable plan in just a few seconds.</p></div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gem3_Golf_Demo_No_Audio_16x9.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 golf swing demo video&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 golf demo&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Pictionary_vFinal_Blog.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash Pictionary demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Pictionary&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini_Flash3.0_LearningDemo_16x9_JW_v6_NoAudio.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash learning demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash learning demo&quot;
      }
    
  ]">
  
    
      
    
  
    
      
    
  
    
      
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">Or you can quickly build fun, useful apps from scratch using your voice without prior coding knowledge. Just dictate to Gemini on the go, and it can transform your unstructured thoughts into a functioning app in minutes.</p>
      </div>
  

  
    
  
    




  <uni-youtube-player-article index="17" thumbnail-alt="Food prototype using Gemini 3 Flash" subtitle="Describe an idea using Gemini 3 Flash and turn it into a working prototype in minutes." video-id="8IYYMRdz2h4" video-type="video" image="Gemini3_Flash_Food_Thumbnail" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-1000.format-webp.webp">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><p data-block-key="qapzx">Gemini 3 Flash is also starting to roll out as the default model for AI Mode in Search with access to everyone around the world.</p><p data-block-key="5fmab">Building on the reasoning capabilities of Gemini 3 Pro, AI Mode with Gemini 3 Flash is more powerful at parsing the nuances of your question. It considers each aspect of your query to serve thoughtful, comprehensive responses that are visually digestible — pulling real-time local information and helpful links from across the web. The result effectively combines research with immediate action: you get an intelligently organized breakdown alongside specific recommendations — at the speed of Search.</p><p data-block-key="fba77">This shines when tackling complex goals with multiple considerations like trying to plan a last-minute trip or learning complex educational concepts quickly.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="19" thumbnail-alt="Demo of Gemini 3 Flash in AI Mode" subtitle="Gemini 3 Flash brings the incredible reasoning capabilities of Gemini 3 to Search, without compromising speed, so you can tackle your most complicated questions." video-id="rPXBDSf-Hwg" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">Try Gemini 3 Flash today</h2><p data-block-key="avrm2">Gemini 3 Flash is available now in preview via the <a href="https://ai.google.dev/gemini-api/docs/models#gemini-3-flash">Gemini API</a> in Google AI Studio, <a href="https://antigravity.google/">Google Antigravity,</a> <a href="https://cloud.google.com/vertex-ai?e=48754805">Vertex AI</a> and <a href="https://cloud.google.com/gemini-enterprise?e=48754805">Gemini Enterprise</a>. You can also access it through other developer tools like <a href="https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/">Gemini CLI</a> and <a href="https://android-developers.googleblog.com/2025/12/build-smarter-apps-with-gemini-3-flash">Android Studio</a>. It’s also starting to roll out to everyone in the <a href="https://gemini.google.com/">Gemini app</a> and <a href="https://www.google.com/search?udm=50&amp;aep=11">AI Mode</a> in Search, bringing fast access to next-generation intelligence at no cost.</p><p data-block-key="e3atd">We’re looking forward to seeing what you bring to life with this expanded family of models: Gemini 3 Pro, Gemini 3 Deep Think and now, Gemini 3 Flash.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yep, Passkeys Still Have Problems (116 pts)]]></title>
            <link>https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/</link>
            <guid>46301585</guid>
            <pubDate>Wed, 17 Dec 2025 13:12:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/">https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/</a>, See on <a href="https://news.ycombinator.com/item?id=46301585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>It's now late into 2025, and just over a year since I wrote my last post on Passkeys. The
prevailing dialogue that I see from thought leaders is "addressing common misconceptions" around Passkeys,
the implication being that "you just don't understand it correctly" if you have doubts. Clearly
I don't understand Passkeys in that case.</p>
<p>And yet, I am here to once again say - yep, it's 2025 and Passkeys still have all the issues I've mentioned
before, and a few new ones I've learnt! Let's round up the year together then.</p>
<h2 id="too-lazy-didn-t-read">Too Lazy - Didn't Read</h2>
<ul>
<li>Passkeys have flaws - learn about them and use them <em>on your terms</em>. Don't write them off wholesale based on this blog. I, the author of this blog, use Passkeys!!!</li>
<li>DO engage with and learn about Credential Managers (aka Password Managers). This is where the Passkey is stored.</li>
<li>DO use a Credential Manager you control and can backup. I recommend Bitwarden or Vaultwarden which allow backups to be taken easily.</li>
<li><em>AVOID</em> using a platform (Apple, Google) Credential Manager as your only Passkey repository - these can't easily backed up and you CAN be locked out permanently.
<ul>
<li>IF you use a platform Passkey manager, frequently sync it with <a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange</a> to an external Credential Manager you can backup/control.</li>
<li>OR use both the platform Passkey manager <em>AND</em> a Credential Manager you control in parallel.</li>
</ul>
</li>
<li>For high value accounts such as email which are on the account recovery path
<ul>
<li>DO use Yubikeys for your email account as the Passkey store.</li>
<li>DO keep strong machine generated passwords + TOTP in your Credential Managers as alternatives to Passkeys for your email accounts.</li>
</ul>
</li>
<li>DO a thought experiment - if I lost access to my Credential Manager what is the recovery path? Ensure you can rebuild from disaster.</li>
</ul>
<h2 id="so-what-has-changed">So what has changed?</h2>
<p>The major change in the last 12 months has been the introduction of the
<a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange Specification</a>.</p>
<p>Most people within the tech community who have dismissed my claim that "Passkeys are a form of vendor
lockin" are now pointing at this specification as proof that this claim is now wrong.</p>
<blockquote>
<p>"See! Look! You can export your credentials to another Passkey provider if you want! We aren't locking you in!!!"</p>
</blockquote>
<p>I have to agree - this is great if you want to <em>change</em> which walled-garden you live inside. However
it doesn't assist with the day to day usage of Passkeys when you have devices from <em>different</em> vendor ecosystems. Nor
does it make it easier for me to use a Passkey provider outside of my vendors platform provider.</p>
<p>Example: Let's say that I have an Windows Desktop and a Macbook Pro - I can sign up a Passkey on the Macbook Pro
but I can't then use it on the Windows Desktop.
<a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange</a>
lets me copy from
Apple's Keychain to whatever provider I use on the Windows machine. But now I have to do that
exchange <em>every time I enrol a new Passkey</em>. Similar I would need to do the reverse from Windows
to Mac every time that I sign up on the Windows machine.</p>
<p>So day to day, this changes very little - but if I want to go from "all in on Apple" to "all in on
Google" then I can do a big-bang migration and jump from once garden to the next. But if you have
mixed device ecosystems (like uhhh ... you know. Most of the world does) then very little will
change for you with this.</p>
<p>But if I use my own Credential Manager (e.g. Vaultwarden) then I can happily work between multiple
ecosystems.</p>
<h2 id="what-s-the-same">What's the same?</h2>
<h3 id="thought-leadership">Thought Leadership</h3>
<p>Today I saw this excellent quote in the context of why Passkeys are better than Password+TOTP in a Password Manager:</p>
<blockquote>
<p>Individuals having to learn to use password management software and be vigilant against phishing is an industry failure, not a personal success.</p>
</blockquote>
<p>Even giving as much benefit of the doubt to this statement, and that the "and" might be load bearing we have to ask - Where are passkeys stored?</p>
<p><img src="https://fy.blackhats.net.au/_static/passkey/af5o5b.jpg" alt="image"></p>
<p>So we still have to teach individuals about password (credential) managers, and how Passkeys work so that people trust them. That fundamental truth hasn't changed.</p>
<p>But not only this - if a person is choosing a password+TOTP over a Passkey, we have to ask "why is that"? Do we think that it's truly about arrogance? Do we think that
this user believes they are more important? Or is there and underlying usability issue at play? Why might we be recommending this to others? Do we really think that
Passkeys come without a need of education?</p>
<p>Maybe I'm fundamentally missing the original point of this comment. Maybe I am completely misinterpretting it. But I still think we need to say if a person chooses
password and TOTP over a Passkey even once they are informed of the choices, then Passkeys have <em>failed</em> that user. What could we have done better?</p>
<p>Perhaps one could interpret this statement as you don't need to teach users about Passkeys if they are using their <em>✨ m a g i c a l ✨</em> platform Passkey manager since it's so much nicer than a password and TOTP. And that leads to ...</p>
<h3 id="it-s-still-vendor-lockin">It's Still Vendor Lockin</h3>
<blockquote>
<p>In economics, vendor lock-in, [...] makes a customer dependent on a vendor for products, unable to
use another vendor without substantial switching costs.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Vendor_lock-in">citation - wikipedia</a></p>
<p>See, the big issue that the thought leaders seem to get wrong is that they believe that if you can
use FIDO Credential Exchange, then you aren't locked in because you can move between Passkey providers.</p>
<p>But if we aren't teaching our users about credential management, didn't we just silently lock them into
to our platform Passkey manager?</p>
<p>Not only that, when you try to go against the platform manager, it's the continual friction at each stage of the users
experience. It makes
the cost to switch <em>high</em> because at each point you encounter friction if you deviate from the vendors
intended paths.</p>
<p>For example, consider the Apple Passkey modal:</p>
<p><img src="https://fy.blackhats.net.au/_static/passkey/register-macos-1.png" alt="image"></p>
<blockquote>
<p>MacOS 15.7.1 taken on 2025-10-29</p>
</blockquote>
<p>The majority of this modal is dedicated to "you should make a Passkey in your Apple Keychain". If you
want to use your Android phone or a Security Key, where would I click? Oh yes, <code>Other Options</code>.</p>
<p>Per <a href="https://developer.apple.com/design/human-interface-guidelines/buttons#Best-practices">Apple's Human Interface Guidelines</a>:</p>
<blockquote>
<p>Make buttons easy for people to use. It’s essential to include enough space around a button so that people can visually distinguish it from surrounding components and content. Giving a button enough space is also critical for helping people select or activate it, regardless of the method of input they use.</p>
</blockquote>
<p><img src="https://fy.blackhats.net.au/_static/passkey/register-macos-2.png" alt="image"></p>
<blockquote>
<p>MacOS 15.7.1 taken on 2025-10-29</p>
</blockquote>
<p>When you select <code>Other Options</code> this is what you see - see how Touch ID is still the default, despite
the fact that I already indicated I don't want to use it by selecting <code>Other Options</code>? At this point
I would need to select <code>Security Key</code> and then click again to use my key. Similar for Android Phone.</p>
<p>And guess what - my preferences and choices are never remembered. I guess it's true what they say.</p>
<blockquote>
<p>Software engineers don't understand consent, and it shows.</p>
</blockquote>
<p>Google Chrome has a similar set of Modals and nudges (though props to Chrome, they at least <em>implicitly</em>
activate your security key from the first modal so a power user who knows the trick can use it). So they
are just as bad here IMO.</p>
<p>This is what I mean by "vendor lockin". It's not just about where the private keys are stored. It's
the continual friction at each step of the interaction when you deviate from the vendors intended
path. It's about making it so annoying to use <em>anything else</em> that you settle into one vendors
ecosystem. It's about the lack of communication about <em>where</em> Passkeys are stored that tricks users
into settling into their vendor ecosystem. That's vendor lock-in.</p>
<h3 id="cloud-keychains-are-still-blowing-up-data">Cloud Keychains Are Still Blowing Up Data</h3>
<p>We still get reports of people losing Passkeys from Apple Keychain. We similarly get reports of Android
phones that one day just stop creating new Passkeys, or stop being able to use existing ones. One
<a href="https://infosec.exchange/@tychotithonus/115341947864402280">exceptional story</a> we saw recently was of
an Android device that stopped using it's onboard Passkeys and also stopped accepting NFC key. USB
CTAP would still function, and all the historical fixes we've seen (such as full device resets) would
not work. So now what? I'm not sure of the outcome of this story, but my assumption is there was not
a happy ending.</p>
<p>If someone ends up locked out of their accounts because their Passkeys got nuked silently, what are
we meant to do to help them?</p>
<h3 id="vendors-can-lock-you-out">Vendors Can Lock You Out</h3>
<p><a href="https://hey.paris/posts/appleid/">Dr Paris Buttfield-Addison was locked out of their Apple account</a>.</p>
<p>I recommend you read the post, but the side effect - every Passkey they had in an Apple keychain is now unrecoverable.</p>
<p>There is just as much evidence about the same practices with Google / Android.</p>
<p>I honestly don't think I have to say much else, this is terrifying that every account you own could be destroyed by a single action where you have no recourse.</p>
<h3 id="authentication-providers-still-miscommunicate">Authentication Providers Still Miscommunicate</h3>
<p>We still have issues where services that are embracing Passkeys are communicating badly about them.
The gold standard of miscommunication came to me a few months ago infact (2025-10-29) when a company emailed me
this statement:</p>
<blockquote>
<p>Passkeys use your unique features – known as biometrics – like your facial features, your fingerprint or a PIN to let us know that it’s really you. They provide increased security because unlike a password or username, they can’t be shared with anyone, making them phishing resistant.</p>
</blockquote>
<p>As someone who is deeply aware of how webauthn works I know that my facial features or fingerprint never really
leave my device. However asking my partner
(context: my partner is a veternary surgeon, and so I feel justified in claiming that she is a very intelligent and educated woman)
to read this, her interpretation was:</p>
<blockquote>
<p>So this means a Passkey sends my face or fingerprint over the internet for the service to verify? Is that
also why they believe it is phishing resistant because you can't clone my face or my fingerprint?</p>
</blockquote>
<p>This is a smart, educated person, with the title of <em>doctor</em>, and even she is concluding that Passkeys
are sending biometrics over the internet. What are people in other disciplines going to think? What
about people with a cognitive impairment or who not have access to education about Passkeys?</p>
<p>This kind of messaging that leads people to believe we are sending personal physical features over
the internet is <em>harmful</em> because most people <em>will not want to send these data to a remote service</em>.
This completely undermines the trust in Passkeys because we are establishing to people that they are
personally invasive in a way that username and passwords are not!</p>
<p>And guess what - platform Passkey provider modals/dialogs don't do anything to counter this information
and often leave users with the same feeling.</p>
<h3 id="authentication-providers-are-still-playing-silly-games-with-user-choice">Authentication Providers Are Still Playing Silly Games With User Choice</h3>
<p>A past complaint was that I had encountered services that only accepted a single Passkey as they
assumed you would use a synchronised cloud keychain of some kind. In 2025 I still see a handful
of these services, but mostly the large problem sites have now finally allowed you to enrol multiple Passkeys.</p>
<p>But that doesn't stop sites pulling tricks on you.</p>
<p>I've encountered multiple sites that now use <code>authenticatorAttachment</code> options to force you to use
a platform bound Passkey. In other words, they force you into Google or Apple. No password manager,
no security key, no choices.</p>
<p>I won't claim this one as an attempt at "vendor lockin" by the big players, but it is a reflection
of what developers believe a Passkey to be - they believe it means a private key stored in one of
those vendors devices, and nothing else. So much of this comes from the confused historical origins
of Passkeys and we aren't doing anything to change it.</p>
<p>When I have confronted these sites about the mispractice, they pretty much shrugged and said
"well no one else has complained so meh". Guess I won't be enrolling a Passkey with you then.</p>
<p>One other site that pulled this said "instead of selecting continue, select this other option and you
get the <code>authenticatorAttachment=cross-platform</code> setting. Except that they could literally do
<em>nothing</em> with <code>authenticatorAttachment</code> and leave it up to the platform modals allowing me the choice
(and fewer friction burns) of choosing where I want to enrol my Passkey.</p>
<p>Another very naughty website attempts to enroll a Passkey on your device with no prior warning or consent
when you login, which is very surprising to anyone and seems very deceptive as a practice. Ironically
same vendor doesn't use your passkey when you go to sign in again anyway.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Yep, Passkeys Still Have Problems.</p>
<p>But it's not <em>all</em> doom and gloom.</p>
<p>Most of the issues are around <em>platform</em> Passkey providers like Apple or Google.</p>
<p>The best thing you can do as a user, and for anyone in your life you want to help, is to be educated
about Credential Managers. Regardless of Passwords, TOTP, Passkeys or anything else, empowering people
to manage and think about their online security via a Credential Manager they feel they control and
understand is critical - not an "industry failure".</p>
<p>Using a Credential Manager that you have control over shields you from the account lockout and
platform blow-up risks that exist with platform Passkeys. Additionally most Credential Managers
will allow you to backup your credentials too. It can be a great idea to do this every few months
and put the content onto a USB drive in a safe location.</p>
<p>If you do choose to use a platform Passkey provider, you can "emulate" this backup ability by using
the credential export function to another Passkey provider, and then do the backups from there.</p>
<p>You can also use a Yubikey as a Credential Manager if you want - modern keys (firmware version 5.7 and greater)
can store up to 150 Passkeys on them, so you could consider skipping software Credential Managers entirely for
some accounts.</p>
<p>The most critical accounts you own though need some special care. Email is one of those - email generally
is the path by which all other credential resets and account recovery flows occur. This means losing
your email access is the most devastating loss as anything else could potentially be recovered.</p>
<p>For email, this is why I recommend using hardware security keys (yubikeys are the gold standard here)
if you want Passkeys to protect your email. Always keep a strong password and TOTP as an extra <em>recovery</em> path, but
don't use it day to day since it can be phished. Ensure these details are physically secure and backed up - again a USB drive
or even a print out on paper in a safe and secure location so that you can "bootstrap your accounts"
in the case of a major failure.</p>
<p>If you are an Apple or Google employee - change your dialogs to allow remembering choices the user
has previously made on sites, or wholesale allow skipping some parts - for example I want to skip
straight to Security Key, and maybe I'll choose to go back for something else. But let <em>me</em> make
that choice. Similar, make the choice to use different Passkey providers a first-class citizen in
the UI, not just a tiny text afterthought.</p>
<p>If you are a <em>developer</em> deploying Passkeys, then don't use any of the pre-filtering Webauthn
options or javascript API's. Just leave it to the users platform modals to let the person choose. If
you want people to enroll a passkey on sign in, communicate that before you attempt the enrolment. Remember
kids, consent is paramount.</p>
<p>But of course - maybe I just "don't understand Passkeys correctly". I am but an underachiving white man on the internet after all.</p>
<p>EDIT: 2025-12-17 - expanded on the password/totp + password manager argument.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coursera to combine with Udemy (261 pts)]]></title>
            <link>https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx</link>
            <guid>46301346</guid>
            <pubDate>Wed, 17 Dec 2025 12:45:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx">https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=46301346">Hacker News</a></p>
Couldn't get https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Is Mozilla trying hard to kill itself? (693 pts)]]></title>
            <link>https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself</link>
            <guid>46299934</guid>
            <pubDate>Wed, 17 Dec 2025 09:37:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself">https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself</a>, See on <a href="https://news.ycombinator.com/item?id=46299934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In an interview with “The Verge”, the new Mozilla CEO, Enzor-DeMeo, IMHO hints that axing adblockers is something that, at the very least, was on the table in some form and at some point. From <a href="https://www.theverge.com/tech/845216/mozilla-ceo-anthony-enzor-demeo" rel="nofollow">the article</a>:</p>

<blockquote><p>He says he could begin to block ad blockers in Firefox and estimates that’d bring in another $150 million, but he doesn’t want to do that. It feels off-mission.</p></blockquote>

<p>It may be just me, but I read this as “I don't want to 😜 😜 but I'll kill AdBlockers in Firefox for buckerinos 😂”. This disappoints and saddens me a lot, and I hope I'm wrong.</p>

<p>I've been using Firefox before it was called that. Heck, I even used the Mozilla Application Suite back in the day. It was its commitment to open standards and the open web, and its powerful add-on system, that attracted me to its software.</p>

<p>Honestly, that's what's been keeping me. I think that's also what's been keeping their loyal base of users with the project, the geeks and nerds that care about privacy. It's the same group of people who helped it get very popular at one point.</p>

<p>Killing one of its advantages over the Chromium engine, being able to have a fucking adblocker that's actually useful, and that nowadays is a fucking security feature due to malvertising, will be another nail in the coffin, IMHO. The core community will feel disenfranchised, and this may have negative consequences for the project. You know why? Because these are some of the people that the <em>normies</em> turn to when they want tech advice.</p>

<p>For fuck sake, for-profit side of Mozilla, get a damn grip!</p>

<p><a href="https://infosec.press/brunomiguel/tag:Mozilla" rel="nofollow"><span>#</span><span>Mozilla</span></a> <a href="https://infosec.press/brunomiguel/tag:Firefox" rel="nofollow"><span>#</span><span>Firefox</span></a> <a href="https://infosec.press/brunomiguel/tag:AdBlocker" rel="nofollow"><span>#</span><span>AdBlocker</span></a> <a href="https://infosec.press/brunomiguel/tag:OpenSource" rel="nofollow"><span>#</span><span>OpenSource</span></a> <a href="https://infosec.press/brunomiguel/tag:FOSS" rel="nofollow"><span>#</span><span>FOSS</span></a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI's real superpower: consuming, not creating (160 pts)]]></title>
            <link>https://msanroman.io/blog/ai-consumption-paradigm</link>
            <guid>46299552</guid>
            <pubDate>Wed, 17 Dec 2025 08:34:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://msanroman.io/blog/ai-consumption-paradigm">https://msanroman.io/blog/ai-consumption-paradigm</a>, See on <a href="https://news.ycombinator.com/item?id=46299552">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><span>October 30, 2025</span><p>Everyone's using AI wrong. Including me, until last month.</p>
<p>We ask AI to write emails, generate reports, create content. But that's like using a supercomputer as a typewriter. The real breakthrough happened when I flipped my entire approach.</p>
<p>AI's superpower isn't creation. It's consumption.</p>
<h2 id="the-creation-trap">The creation trap</h2>
<p>Here's how most people use AI:</p>
<ul>
<li>"Write a blog post about engineering leadership"</li>
<li>"Generate code for this feature"</li>
<li>"Create a summary of this meeting"</li>
</ul>
<p>Makes sense. These tasks save time. But they're thinking too small.</p>
<p>My Obsidian vault contains:
→ 3 years of daily engineering notes
→ 500+ meeting reflections
→ Thousands of fleeting observations about building software
→ Every book highlight and conference insight I've captured</p>
<p>No human could read all of this in a lifetime. AI consumes it in seconds.</p>
<h2 id="the-consumption-breakthrough">The consumption breakthrough</h2>
<p>Last month I connected my Obsidian vault to AI. The questions changed completely:</p>
<p>Instead of "Write me something new"
I ask "What have I already discovered?"</p>
<p>Real examples from this week:</p>
<p><strong>"What patterns emerge from my last 50 one-on-ones?"</strong>
AI found that performance issues always preceded tool complaints by 2-3 weeks. I'd never connected those dots.</p>
<p><strong>"How has my thinking about technical debt evolved?"</strong>
Turns out I went from seeing it as "things to fix" to "information about system evolution" around March 2023. Forgotten paradigm shift.</p>
<p><strong>"Find connections between Buffer's API design and my carpeta.app architecture"</strong>
Surfaced 12 design decisions I'm unconsciously repeating. Some good. Some I need to rethink.</p>
<h2 id="your-knowledge-compounds-but-only-if-accessible">Your knowledge compounds, but only if accessible</h2>
<p>Every meeting, every shower thought, every debugging session teaches you something. But that knowledge is worthless if you can't retrieve it.</p>
<p>Traditional search fails because you need to remember exact words. Your brain fails because it wasn't designed to store everything.</p>
<p>AI changes the retrieval game:
→ Query by concept, not keywords
→ Find patterns across years, not just documents
→ Connect ideas that were separated by time and context</p>
<p>The constraint was never writing. Humans are already good at creating when they have the right inputs.</p>
<p>The constraint was always consumption. Reading everything. Remembering everything. Connecting everything.</p>
<h2 id="building-your-consumption-system">Building your consumption system</h2>
<p>My setup is deceptively simple:</p>
<ol>
<li>Everything goes into Obsidian (meetings, thoughts, reflections)</li>
<li>AI has access to the entire vault</li>
<li>I query my past self like a research assistant</li>
</ol>
<p>But the magic isn't in the tools. It's in the mindset shift.</p>
<p>Stop thinking of AI as a creator. Start thinking of it as the ultimate reader of your experience.</p>
<p>Every note becomes a future insight. Every reflection becomes searchable wisdom. Every random observation might be the missing piece for tomorrow's problem.</p>
<h2 id="the-compound-effect">The compound effect</h2>
<p>After two months of this approach:</p>
<p>→ I solve problems faster by finding similar past situations
→ I make better decisions by accessing forgotten context
→ I see patterns that were invisible when scattered across time</p>
<p>Your experience is your competitive advantage. But only if you can access it.</p>
<p>Most people are sitting on goldmines of insight, locked away in notebooks, random files, and fading memories. AI turns that locked vault into a queryable database of your own expertise.</p>
<h2 id="the-real-revolution">The real revolution</h2>
<p>We're still thinking about AI like it's 2023. Writing assistants. Code generators. Content creators.</p>
<p>The real revolution is AI as the reader of everything you've ever thought.</p>
<p>And that changes everything about how we should capture knowledge today.</p>
<p>Start documenting. Not for others. For your future self and the AI that will help you remember what you've forgotten you know.</p>
<hr>
<p><em>This piece originally appeared in my <a href="https://mikesanroman.substack.com/" target="_blank" rel="noopener">weekly newsletter</a>. Subscribe for insights on thinking differently about work, technology, and what's actually possible.</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla reports another Robotaxi crash (144 pts)]]></title>
            <link>https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/</link>
            <guid>46297702</guid>
            <pubDate>Wed, 17 Dec 2025 02:52:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/">https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/</a>, See on <a href="https://news.ycombinator.com/item?id=46297702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="765" src="https://electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1600" alt="Tesla Robotaxi hero" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>Tesla has reported yet another crash involving its Robotaxi fleet in Austin to the NHTSA. The new data keeps the program’s accident rate alarmingly high compared to human drivers, even as the company prepares to <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/12/09/tesla-ceo-elon-musk-claims-driverless-robotaxis-coming-to-austin-in-3-weeks/">remove human safety supervisors from the vehicles</a>.</p>



<p>As we have been tracking in our <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">previous coverage of the Robotaxi pilot</a> in Austin, Tesla is required to report crashes involving its automated driving systems (ADS) to the NHTSA under a Standing General Order.</p>



<p>For months, we’ve seen these reports trickle in from Tesla’s small pilot fleet in Texas. In November, we reported that the fleet had reached <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">7 total crashes</a> as of September.</p>



<p>Now, a new report filed by Tesla reveals an 8th crash occurred in October 2025.</p>	
	



<p>According to the filing, the incident took place on October [Day Redacted], 2025, in Austin. The valid report (Report ID: 13781-11986) lists the “Highest Injury Severity Alleged” as “No Injured Reported,” but details are scarce because, as is typical for Tesla, the narrative description of the crash has been redacted to hide proprietary information.</p>



<p>We have been highlighting how Tesla often abuses NHTSA’s capability to redact much of the information in the crash reports, especially the ‘Narrative’ section, which explains precisely what happened in the incident.</p>



<p>It’s possible that Tesla’s Robotaxis are not responsible for some of these crashes, but we wouldn’t know because Tesla redacts most information.</p>



<p>In this new filing for the accident that happened in October, Tesla went even further as it even refrains from answering some of the sections. Instead, it says “see the narrative,” which again is redacted.</p>



<p>Here’s the updated list of Tesla Robotaxi crashes:</p>



<figure><table><thead><tr><td><strong>Report ID</strong></td><td><strong>Incident Date</strong></td><td><strong>City</strong></td><td><strong>State</strong></td><td><strong>Crash With</strong></td><td><strong>Highest Injury Severity Alleged</strong></td></tr></thead><tbody><tr><td>13781-11986</td><td>OCT-2025</td><td>Austin</td><td>TX</td><td>Other, see Narrative</td><td>No Injured Reported</td></tr><tr><td>13781-11787</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Animal</td><td>No Injured Reported</td></tr><tr><td>13781-11786</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Non-Motorist: Cyclist</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11784</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Passenger Car</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11687</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Other Fixed Object</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11507</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>SUV</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11459</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>Other Fixed Object</td><td>Minor W/O Hospitalization</td></tr><tr><td>13781-11375</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>SUV</td><td>Property Damage. No Injured Reported</td></tr></tbody></table></figure>



<p>We do know that the crash involved “Other” as the conflict partner, and the vehicle was “Proceeding Straight” at the time.</p>



<h3 id="h-tesla-robotaxi-crash-rate">Tesla Robotaxi Crash Rate</h3>



<p>While a few fender benders might not seem like headline news, it becomes significant when you look at the math.</p>



<p>Last month, Tesla confirmed the fleet had traveled roughly 250,000 miles. With 7 reported crashes at the time, <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">Tesla’s Robotaxi was crashing roughly once every 40,000 miles </a>(extrapolating from the previously disclosed Robotaxi mileage).</p>



<p>For comparison, the average human driver in the US crashes about once every 500,000 miles.</p>



<p>This means Tesla’s “autonomous” vehicle, which is supposed to be the future of safety, is crashing 10x more often than a human driver.</p>



<p>While Tesla’s Robotaxi fleet reportedly increased in November, with the number of cars spotted going up to 29, there’s no evidence that the Robotaxi mileage increased. In fact, the utilization rate indicates Tesla is running only a few vehicles at a time – meaning that mileage might have actually gone down.</p>



<p>And that is not even the scariest part.</p>



<h3 id="h-the-supervisor-paradox">The Supervisor Paradox</h3>



<p>The most critical detail that gets lost in the noise is that these crashes are happening with a human safety supervisor in the driver’s seat (for highway trips) or passenger seat, with a finger on a kill switch.</p>



<p>These employees are trained to intervene and take control of the vehicle if the software makes a mistake. </p>



<p>If the car is crashing this frequently with a human babysitter trying to prevent accidents, imagine what the crash rate would be without them.</p>



<p>Yet, that is exactly what Tesla is doing.</p>



<p>Elon Musk recently claimed that Tesla would <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/12/09/tesla-ceo-elon-musk-claims-driverless-robotaxis-coming-to-austin-in-3-weeks/">remove safety monitors from the Robotaxi fleet</a> in Austin within “three weeks.”</p>



<p>Yesterday, we reported that <a href="https://electrek.co/2025/12/14/tesla-robotaxi-spotted-without-a-safety-driver-austin-musk-confirms-testing-begins/">a Tesla Robotaxi was spotted for the first time without anyone in the front seat</a>s, and Musk confirmed that Tesla started testing without a supervisor.</p>



<h3 id="h-electrek-s-take">Electrek’s Take</h3>



<p>This is becoming hard to watch.</p>



<p>We have <a href="https://electrek.co/2025/12/10/elon-musk-waymo-never-had-chance-against-tesla/" target="_blank" rel="noreferrer noopener">Waymo operating fully driverless</a> commercial services in multiple cities with over 100 million miles of data showing they are safer than humans. They are not without their issues, but they are at least sharing data that is encouraging, including not redacting the NTHSA crash reporting.</p>




	<p>Meanwhile, Tesla is struggling to keep a small test fleet in Austin from hitting things, even with professional safety drivers on board.</p>



<p>Removing the safety supervisors when your crash rate is already orders of magnitude worse than the average human seems reckless. It feels like another case of prioritizing the “optics” of autonomy over the actual safety required to deploy it.</p>



<p>If Tesla pulls the supervisors while the data looks like this, it’s no longer a pilot program. It’s a gamble. And it’s not just gambling on its stock price, it’s gambling with everyone’s safety.</p>




	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introduction to Software Development Tooling (2024) (102 pts)]]></title>
            <link>https://bernsteinbear.com/isdt/</link>
            <guid>46297127</guid>
            <pubDate>Wed, 17 Dec 2025 01:26:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bernsteinbear.com/isdt/">https://bernsteinbear.com/isdt/</a>, See on <a href="https://news.ycombinator.com/item?id=46297127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      

      <ul>
  <li><a href="#administrivia">Administrivia</a></li>
  <li><a href="#schedule">Schedule</a></li>
</ul>

<h2 id="home">Home</h2>

<p>This is the course website for <em>CS 4973: Introduction to Software Development
Tooling</em> at Northeastern University, Summer 2 2024. This site holds the
authoritative syllabus, as well as lecture notes and assignments.</p>

<p><em>Note:</em> The course staff reserves the right to change this page at any time
without notice. The <a href="https://github.com/tekknolagi/isdt/commits/main">change history</a> is public. <strong>It is being
actively changed right now as we update it for Summer 2024.</strong></p>

<h2 id="overview">Overview</h2>

<p>Learn tools you’ll be expected to know as a working software engineer, which will
help you write better code, collaborate with others, and tackle problems you
previously thought impossible.</p>

<p>Effective software development requires more than just coding skill: in
industry and academia alike, developers use tools to keep their code
maintainable and reliable. In this course, you will learn four fundamental
categories of tooling: the command line, version control, build systems, and
correctness. We’ll dive deep into one industry-standard tool from each category
via hands-on projects and exploration of existing codebases, then survey other
tools in the same category and discuss why you might choose one over another.
By the end of the course, you will have a robust toolset both to manage
complexity in your future projects and to effectively ramp up on software
projects you encounter in the real world.</p>

<p>We are teaching this course as a series of four modules. The first, Command
Line, will give you an overview of the operating system and tools available to
you to make your life as a software engineer easier. The second, VCS, will
teach you about how to version control your software with Git, so that you may
maintain a history of your changes and collaborate with others. The third,
Build, will teach you about how to reliably build your software with Make. The
fourth and final module, Correctness, will introduce you to testing and other
tools for ensuring that your software meets quality standards.</p>

<h2 id="administrivia">Administrivia</h2>

<p><strong>Instructor:</strong> <a href="https://bernsteinbear.com/">Max Bernstein</a><br>
<strong>Teaching Assistants:</strong> TBD</p>

<p><strong>Office Hours:</strong> immediately after lecture; extra hours to be announced on Piazza<br>
<strong>Discussion board:</strong> Piazza (access via Canvas)</p>

<p><strong>Prerequisites:</strong> An introductory computer science class and the willingness
to learn a little C<br>
<strong>Equipment:</strong> A computer with a POSIX shell<br>
<strong>Textbook:</strong> none</p>

<p><strong>Lectures:</strong> Mo-Tu-We-Thu, 9:50am-11:30am, in Dodge Hall Room 173<br>
<strong>Assignments:</strong> 8 assignments (2 per module), to be submitted on Gradescope<br>
<strong>Exams:</strong> none</p>

<h2 id="schedule">Schedule</h2>

<p><em>Note:</em> We will publish notes or slides for each lecture after it happens, but
the lecture recordings will not be available to students. If you require access
to recordings for your accommodations, please contact us using a private post
on Piazza.</p>

<!-- from gensched.py -->
<!-- @@generated by /home/max/Documents/code/isdt/gensched.py -->

<table>
  <thead>
    <tr>
      <th>Week</th>
      <th>Monday</th>
      <th>Tuesday</th>
      <th>Wednesday</th>
      <th>Thursday</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>
<em>Jul 1</em><br>Course Administrivia &amp; <a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-1">CLI 1: Intro to Linux and the shell</a><br><a href="https://bernsteinbear.com/isdt/assignments/01-cli-investigative/">Homework 1 out</a>
</td>
      <td>
<em>Jul 2</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-2">CLI 2: Quoting, common tools, and permissions</a>
</td>
      <td>
<em>Jul 3</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-3">CLI 3: Advanced shell features</a>
</td>
      <td>
<em>Jul 4</em><br><em>No class</em>
</td>
    </tr>
    <tr>
      <td>2</td>
      <td>
<em>Jul 8</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-4">CLI 4: The shell as a programming language</a><br>Homework 1 due; <a href="https://bernsteinbear.com/isdt/assignments/02-cli-constructive/">Homework 2 out</a>
</td>
      <td>
<em>Jul 9</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-5">CLI 5: Behind the scenes</a>
</td>
      <td>
<em>Jul 10</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/1-cli/#lecture-6">CLI 6: Linux and POSIX</a>
</td>
      <td>
<em>Jul 11</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/2-vcs/#lecture-1">VCS 1: Intro to version control</a><br>Homework 2 due; <a href="https://bernsteinbear.com/isdt/assignments/03-vcs-investigative/">Homework 3 out</a>
</td>
    </tr>
    <tr>
      <td>3</td>
      <td>
<em>Jul 15</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/2-vcs/#lecture-2">VCS 2: Git operations</a>
</td>
      <td>
<em>Jul 16</em><br>VCS 3: Git operations, continued</td>
      <td>
<em>Jul 17</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/2-vcs/#lecture-4">VCS 4: Git operations, continued</a><br>Homework 3 due; <a href="https://bernsteinbear.com/isdt/assignments/04-vcs-constructive/">Homework 4 out</a>
</td>
      <td>
<em>Jul 18</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/2-vcs-slides-l5.pdf">VCS 5: Collaboration with Git (pdf)</a>
</td>
    </tr>
    <tr>
      <td>4</td>
      <td>
<em>Jul 22</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/2-vcs-slides-l6.pdf">VCS 6: Survey of alternative and related tools (pdf)</a>
</td>
      <td>
<em>Jul 23</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld/#lecture-1">BLD 1: Intro to build systems</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l1.pdf">slides</a>)<br>Homework 4 due; <a href="https://bernsteinbear.com/isdt/assignments/05-bld-investigative/">Homework 5 out</a>
</td>
      <td>
<em>Jul 24</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld/#lecture-2">BLD 2: Intro to Make</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l2.pdf">slides</a>)</td>
      <td>
<em>Jul 25</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l3.pdf">BLD 3: The Make language (pdf)</a>
</td>
    </tr>
    <tr>
      <td>5</td>
      <td>
<em>Jul 29</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l4.pdf">BLD 4: Compilation and linking + large-scale Make (pdf)</a><br>Homework 5 due; <a href="https://bernsteinbear.com/isdt/assignments/06-bld-constructive/">Homework 6 out</a>
</td>
      <td>
<em>Jul 30</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l5.pdf">BLD 5: The great wide world (pdf)</a><br><a href="https://bernsteinbear.com/isdt/build-lab/">Graph lab</a>
</td>
      <td>
<em>Jul 31</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/3-bld-slides-l6.pdf">BLD 6: The great wide world, continued (pdf)</a>
</td>
      <td>
<em>Aug 1</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor/#lecture-1">COR 1: Intro to software correctness</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l1.pdf">slides</a>)<br>Homework 6 due; <a href="https://bernsteinbear.com/isdt/assignments/07-cor-investigative/">Homework 7 out</a>
</td>
    </tr>
    <tr>
      <td>6</td>
      <td>
<em>Aug 5</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor/#lecture-2">COR 2: Philosophy of software testing</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l2.pdf">slides</a>)</td>
      <td>
<em>Aug 6</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor/#lecture-3">COR 3: Writing unit tests</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l3.pdf">slides</a>)</td>
      <td>
<em>Aug 7</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor/#lecture-4">COR 4: Testing strategies and dependency injection</a> (<a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l4.pdf">slides</a>)<br><a href="https://bernsteinbear.com/isdt/assignments/08-cor-constructive/">Homework 8 out</a>
</td>
      <td>
<em>Aug 8</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l5.pdf">COR 5: Continuous integration (pdf)</a><br>Homework 7 due;</td>
    </tr>
    <tr>
      <td>7</td>
      <td>
<em>Aug 12</em><br><a href="https://bernsteinbear.com/isdt/lecture-notes/4-cor-slides-l6.pdf">COR 6: Other methods for ensuring software correctness (pdf)</a>
</td>
      <td>
<em>Aug 13</em><br>TBD</td>
      <td>
<em>Aug 14</em><br>TBD<br>Homework 8 due</td>
      <td>
<em>Aug 15</em><br>TBD</td>
    </tr>
  </tbody>
</table>

<h2 id="course-philosophy">Course philosophy</h2>

<p>This course will consist of 25 lectures (unplanned cancellations
notwithstanding) and 8 assignments, spaced evenly throughout the semester.
There will be no exams. We’ll use the lectures (accompanied by written lecture
notes, assigned readings, and other media) to introduce new material, and we’ll
use the assignments to reinforce that material and evaluate your progress.</p>

<p>While we hope you enjoy this course, we will only be present for a small
minority of your lifelong learning. Therefore, we have done our best to build
assignments and lectures that show you how to find documentation, read code,
and carry out small experiments on your own so that you can continue to broaden
your knowledge long after this course has ended. We believe this ability is
just as important to your success as anything we can teach you directly.</p>

<p><em>Note:</em> This is a relatively new course, written from scratch and being taught
for the second time. Some things might feel rough, slightly out-of-order, or
poorly scheduled. When this happens, please let us know on Piazza. Your
feedback will help us shape future iterations of the course.</p>

<h2 id="academic-integrity">Academic Integrity</h2>

<p><strong>TL;DR: Do all of your own work. This course will necessarily involve a lot of
searching and reading. Skipping the work will only make your life easier in the
short term. Don’t use LLMs such as ChatGPT.</strong></p>

<p>You are expected to adhere to <a href="https://osccr.sites.northeastern.edu/academic-integrity-policy/">NEU’s Academic Integrity Policy</a>
in this course. Plagiarism of code or answers to assignments is strictly
prohibited, as is sharing answers with or accepting answers from others.</p>

<p>You are allowed to reference Linux man pages and any open source projects while
completing assignments. You are also allowed to read any internet resource,
with the exception of material outside this website that explicitly pertains to
this course (e.g. assignment solutions accidentally shared by a former
student).  However, no matter what resources you reference, you must not
plagiarise or complete a substantial part of an assignment using someone else’s
work, even if you credit that work.</p>

<p>You are, however, allowed to base your answers on information you find online.
The purpose of this course is to learn, so if you find a useful resource that
clarifies a misunderstanding or explains a tricky topic and in doing so gives
you the knowledge you need to complete an assignment, you are welcome to read
it (and share it with other students)! You may even copy short snippets of code
from examples you find online, given that either 1) you cite your source, or 2)
the snippet is something that couldn’t reasonably be implemented any other way
(e.g. a call to a Linux API function that we have asked you to use).</p>

<p>To cite your source, leave a reference to it that is enough for the reader to
easily find the resource. If the source is a webpage, give the full URL. If the
source is a print book, give the title, author, and edition. Use your common
sense here.</p>

<p>As a rule of thumb, it’s okay to look for resources to answer specific
questions that come up while you are working on an assignment, but it’s not
okay to look for resources to avoid having to work on the assignment at all.</p>

<p>In the former case, you may end up copying or retyping small snippets of code
from the resources you find. If what you copy has no originality (e.g. if you
look up the name of a specific function or command-line flag) and so serves
only as an expression of thoughts you already had, no attribution is needed.
However, if what you copy affected your thinking about how to go about solving
the problem (e.g. by using a command in a way you hadn’t considered before),
you should cite your source. Either way, things like this are generally okay
and won’t affect your grade.</p>

<p>What’s not okay is copying a function, program, or command that solves a
substantial portion of the problem we’ve given you, regardless of whether you
attribute it. You are graded on what <em>you</em> bring to the course, and if the
course staff believes that you did not bring your own originality and
problem-solving skills to an assignment, you will receive a failing grade for
that assignment. Additionally, if you don’t attribute the unoriginal code, you
will be guilty of plagiarism and the extra consequences that entails.</p>

<h2 id="grading">Grading</h2>

<p>You will be evaluated 100% on homework assignments. Your final percentage grade
will be the average (mean) of your individual grades for each of the 8
assignments. We may decide to adjust (i.e. curve) the grades of any individual
assignment if we deem it necessary, and in that case the curved value is what
will go into the average. A curve will never decrease your grade for an
assignment.</p>

<p>Your final letter grade will be computed from your final percentage grade using
the cutoffs outlined <a href="https://math.tufts.edu/resources/grading-schemes">here</a>.
(We know that’s a Tufts math department page, but their scheme closely matches
that which most students expect, and the computer science department doesn’t
have a recommended set of cutoffs documented anywhere.)</p>

<p>Often on homework assignments we will ask you questions as part of an
“investigative” assignment. The purpose of these questions is to guide you
through a learning process and teach you how to find things out for yourself.
You should explain “why” or “how” in your answers to demonstrate your process.
This is similar to “showing your work” for math. For example, if a question
asks, “how many files are in the directory?”, we would expect you to say “42. I
found the answer with <code>ls -l | wc -l</code>” or similar. Just responding “42” would
not be enough.</p>

<h3 id="submitting-assignments">Submitting assignments</h3>

<p>You must submit projects electronically following the instructions given in
class. Projects may not be submitted by any other means (e.g., please do not
email your projects to us). It is your responsibility to test your program and
verify that it works properly before submitting. All projects are due at
11:59pm on the day indicated on the project assignment, according to the
submission server’s internal clock. Your project score will be for the last
version of the project you submit.</p>

<h3 id="late-policy">Late policy</h3>

<p>Please don’t submit late homework. The summer term is too compressed. If you
miss the deadline but would still like to submit it, it will be
opportunistically graded on a case-by-case basis.</p>

<p><del>You have two late tokens that you can use during the semester. Using one late
token allows you to submit one project up to 24 hours late with no penalty. You
may also use your two late tokens together to submit one project up to 48 hours
late with no penalty. Contact a TA if you need to check the status of your late
tokens.</del></p>

<h2 id="contributors">Contributors</h2>

<p>We consulted Ming Chow, Mike Shah, Chris Gregg, Mark Sheldon, Tyler Lubeck, and
Lexi Galantino while developing this course.</p>

<p>We borrowed the “Assignments” submission guidelines from Jeff Foster’s CS 121
syllabus.</p>

<p>These similar courses from other institutions inspired elements of this
course:</p>

<ul>
  <li>MIT’s <a href="https://missing.csail.mit.edu/">missing semester</a>
</li>
  <li>Berkeley’s <a href="https://www.eecs.umich.edu/courses/eecs201/">EECS201</a>
</li>
  <li>Berkeley’s <a href="https://www2.eecs.berkeley.edu/Courses/CS9E/">CS9E</a>
</li>
</ul>

<p><img src="https://bernsteinbear.com/isdt/assets/images/jumbo.png" alt="Jumbo on a laptop"></p>


      
      
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in hours (230 pts)]]></title>
            <link>https://simonwillison.net/2025/Dec/15/porting-justhtml/</link>
            <guid>46295771</guid>
            <pubDate>Tue, 16 Dec 2025 22:48:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/">https://simonwillison.net/2025/Dec/15/porting-justhtml/</a>, See on <a href="https://news.ycombinator.com/item?id=46295771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Dec/15/porting-justhtml/">

<p>15th December 2025</p>



<p>I <a href="https://simonwillison.net/2025/Dec/14/justhtml/">wrote about JustHTML yesterday</a>—Emil Stenström’s project to build a new standards compliant HTML5 parser in pure Python code using coding agents running against the comprehensive html5lib-tests testing library. Last night, purely out of curiosity, I decided to try <strong>porting JustHTML from Python to JavaScript</strong> with the least amount of effort possible, using Codex CLI and GPT-5.2. It worked beyond my expectations.</p>
<h4 id="tl-dr">TL;DR</h4>
<p>I built <a href="https://github.com/simonw/justjshtml">simonw/justjshtml</a>, a dependency-free HTML5 parsing library in JavaScript which passes 9,200 tests from the html5lib-tests suite and imitates the API design of Emil’s JustHTML library.</p>
<p>It took two initial prompts and a few tiny follow-ups. <a href="https://simonwillison.net/2025/Dec/11/gpt-52/">GPT-5.2</a> running in <a href="https://github.com/openai/codex">Codex CLI</a> ran uninterrupted for several hours, burned through 1,464,295 input tokens, 97,122,176 cached input tokens and 625,563 output tokens and ended up producing 9,000 lines of fully tested JavaScript across 43 commits.</p>
<p>Time elapsed from project idea to finished library: about 4 hours, during which I also bought and decorated a Christmas tree with family and watched the latest Knives Out movie.</p>
<h4 id="some-background">Some background</h4>
<p>One of the most important contributions of the HTML5 specification ten years ago was the way it precisely specified how <em>invalid</em> HTML should be parsed. The world is full of invalid documents and having a specification that covers those means browsers can treat them in the same way—there’s no more “undefined behavior” to worry about when building parsing software.</p>
<p>Unsurprisingly, those invalid parsing rules are pretty complex! The free online book <a href="https://htmlparser.info/">Idiosyncrasies of the HTML parser</a> by Simon Pieters is an excellent deep dive into this topic, in particular <a href="https://htmlparser.info/parser/">Chapter 3. The HTML parser</a>.</p>
<p>The Python <a href="https://github.com/html5lib/html5lib-python">html5lib</a> project started the <a href="https://github.com/html5lib/html5lib-tests">html5lib-tests</a> repository with a set of implementation-independent tests. These have since become the gold standard for interoperability testing of HTML5 parsers, and are used by projects such as <a href="https://github.com/servo/servo">Servo</a> which used them to help build <a href="https://github.com/servo/html5ever">html5ever</a>, a “high-performance browser-grade HTML5 parser” written in Rust.</p>
<p>Emil Stenström’s <a href="https://github.com/EmilStenstrom/justhtml">JustHTML</a> project is a pure-Python implementation of an HTML5 parser that passes the full html5lib-tests suite. Emil <a href="https://friendlybit.com/python/writing-justhtml-with-coding-agents/">spent a couple of months</a> working on this as a side project, deliberately picking a problem with a comprehensive existing test suite to see how far he could get with coding agents.</p>
<p>At one point he had the agents rewrite it based on a close inspection of the Rust html5ever library. I don’t know how much of this was direct translation versus inspiration (here’s Emil’s <a href="https://news.ycombinator.com/item?id=46264195#46267059">commentary on that</a>)—his project has 1,215 commits total so it appears to have included a huge amount of iteration, not just a straight port.</p>
<p>My project <strong>is</strong> a straight port. I instructed Codex CLI to build a JavaScript version of Emil’s Python code.</p>
<h4 id="the-process-in-detail">The process in detail</h4>
<p>I started with a bit of mise en place. I checked out two repos and created an empty third directory for the new project:</p>
<div><pre><span>cd</span> <span>~</span>/dev
git clone https://github.com/EmilStenstrom/justhtml
git clone https://github.com/html5lib/html5lib-tests
mkdir justjshtml
<span>cd</span> justjshtml</pre></div>
<p>Then I started Codex CLI for GPT-5.2 like this:</p>

<p>That <code>--yolo</code> flag is a shortcut for <code>--dangerously-bypass-approvals-and-sandbox</code>, which is every bit as dangerous as it sounds.</p>
<p>My first prompt told Codex to inspect the existing code and use it to build a specification for the new JavaScript library:</p>
<blockquote>
<p><code>We are going to create a JavaScript port of ~/dev/justhtml - an HTML parsing library that passes the full ~/dev/html5lib-tests test suite. It is going to have a similar API to the Python library but in JavaScript. It will have no dependencies other than raw JavaScript, hence it will work great in the browser and node.js and other environments. Start by reading ~/dev/justhtml and designing the user-facing API for the new library - create a spec.md containing your plan.</code></p>
</blockquote>
<p>I reviewed the spec, which included a set of proposed milestones, and told it to add another:</p>
<blockquote>
<p><code>Add an early step to the roadmap that involves an initial version that parses a simple example document that is valid and returns the right results. Then add and commit the spec.md file.</code></p>
</blockquote>
<p>Here’s <a href="https://github.com/simonw/justjshtml/blob/19b8eb1f2ca80f428a3c40862d5ec05d36e5166b/spec.md">the resulting spec.md file</a>. My request for that initial version became “Milestone 0.5” which looked like this:</p>
<blockquote>
<p><strong>Milestone 0.5 — End-to-end smoke parse (single valid document)</strong></p>
<ul>
<li>Implement the smallest end-to-end slice so the public API is real early:
<ul>
<li>
<code>new JustHTML("&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Hello&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;")</code> returns a tree with the expected tag structure and text nodes.</li>
<li>
<code>doc.toText()</code> returns <code>"Hello"</code> and <code>doc.errors</code> is empty for this valid input.</li>
</ul>
</li>
<li>Add <code>scripts/smoke.js</code> (no deps) that runs the example and asserts the expected structure/output.</li>
<li>Gate: <code>node scripts/smoke.js</code> passes.</li>
</ul>
</blockquote>
<p>Then I told it:</p>
<blockquote>
<p><code>Implement Milestone 0.5</code></p>
</blockquote>
<p>And off it went. The resulting code appeared to work so I said:</p>
<blockquote>
<p><code>Configure GitHub Actions test.yml to run that on every commit, then commit and push</code></p>
</blockquote>
<p>I ran <code>git init</code> and created a private GitHub repository for this project at this point, and set up the local directory to push to that remote.</p>
<p>Here’s <a href="https://github.com/simonw/justjshtml/commit/48497cbd05584c88af757a0736a2ee447468b6b3">that initial push</a>. Then I told it:</p>
<blockquote>
<p><code>OK do the rest, commit and push often</code></p>
</blockquote>
<p>And that was almost it!</p>
<p>I set my laptop to not fall asleep and left it to its devices while we went off to buy a Christmas tree. The “commit and push often” meant I could monitor its progress on my phone by refreshing <a href="https://github.com/simonw/justjshtml/commits/main">the commit log on GitHub</a>.</p>
<p>I was running this against my $20/month ChatGPT Plus account, which has a five hour token allowance window for Codex CLI. That ran out at 6:35pm and Codex paused, so I waited until the reset point at 7:14pm and typed:</p>
<blockquote>
<p><code>Keep going</code></p>
</blockquote>
<p>At 9:30pm it declared itself done with the following summary message:</p>
<pre><code>• What’s Done

  - html5lib-tests now run in CI and pass: tokenizer 6810/6810, tree 1770/1782
    (12 skipped: #script-on), serializer 230/230, encoding 82/83 (1 skipped:
    scripted) (.github/workflows/test.yml:1).
  - Public API expanded: stream() (src/stream.js:1), CSS selectors query()/
    matches() (src/selector.js:1), and toMarkdown() (src/markdown.js:1), all
    exported via src/index.js:1.
  - Added no-deps unit scripts for selectors/stream/markdown (scripts/run-
    selector-tests.js:1, scripts/run-stream-tests.js:1, scripts/run-markdown-
    tests.js:1) and wired them into CI.
  - Fixed TreeBuilder so &lt;br&gt; no longer closes &lt;p&gt; (src/treebuilder.js:647).
</code></pre>
<p>As a finishing touch, I had it add a playground interface so I could try out the new library in my browser. I prompted:</p>
<blockquote>
<p><code>Add a playground.html in the top level folder which loads the necessary ES modules from ./src/... and implements the exact same functionality as seen on https://tools.simonwillison.net/justhtml but using the JavaScript library instead of Pyodide</code></p>
</blockquote>
<p>It fetched my <a href="https://tools.simonwillison.net/justhtml">existing JustHTML playground page</a> (<a href="https://simonwillison.net/2025/Dec/14/justhtml/#first-impressions-of-justhtml">described here</a>) using <code>curl</code> and built a new <code>playground.html</code> file that loaded the new JavaScript code instead. This worked <em>perfectly</em>.</p>

<p>I enabled GitHub Pages for my still-private repo which meant I could access the new playground at this URL:</p>
<p><a href="https://simonw.github.io/justjshtml/playground.html">https://simonw.github.io/justjshtml/playground.html</a></p>
<p><img src="https://static.simonwillison.net/static/2025/justjshtml-playground.jpg" alt="Screenshot of JustJSHTML Playground web application. Header reads &quot;JustJSHTML Playground&quot; with subtitle &quot;A dependency-free JavaScript HTML5 parser - GitHub&quot;. Below is a status bar showing &quot;JavaScript Environment&quot; with a green &quot;Ready&quot; badge. The main input area has &quot;Paste HTML&quot; and &quot;Fetch from URL&quot; buttons, with a text area containing HTML code: &quot;<!DOCTYPE html> <html> <head> <title>Example Page</title> </head> <body> <header> <nav> <ul>&quot;. A &quot;Playground Mode&quot; section shows buttons for &quot;CSS Selector Query&quot;, &quot;Pretty Print HTML&quot;, &quot;Tree Structure&quot;, &quot;Stream Events&quot;, &quot;Extract Text&quot;, and &quot;To Markdown&quot; (highlighted in purple). Below is a text field labeled &quot;CSS Selector (optional - leave empty for whole document):&quot; with placeholder &quot;e.g., article, main, .content (or leave empty)&quot; and a green &quot;Convert to Markdown&quot; button. The Output section has a teal header with &quot;Whole document&quot; badge and displays converted markdown: &quot;Example Page&quot; followed by &quot;- [Home](/)&quot; &quot;- [About](/about)&quot; &quot;- [Contact](/contact)&quot;."></p>
<p>All it needed now was some documentation:</p>
<blockquote>
<p><code>Add a comprehensive README with full usage instructions including attribution plus how this was built plus how to use in in HTML plus how to use it in Node.js</code></p>
</blockquote>
<p>You can <a href="https://github.com/simonw/justjshtml/blob/f3a33fdb29bf97846fd017185edc8cf82783032e/README.md">read the result here</a>.</p>
<p>We are now at eight prompts total, running for just over four hours and I’ve decorated for Christmas and watched <a href="https://en.wikipedia.org/wiki/Wake_Up_Dead_Man">Wake Up Dead Man</a> on Netflix.</p>
<p>According to Codex CLI:</p>
<blockquote>
<p><code>Token usage: total=2,089,858 input=1,464,295 (+ 97,122,176 cached) output=625,563 (reasoning 437,010)</code></p>
</blockquote>
<p>My <a href="https://www.llm-prices.com/#it=2089858&amp;cit=97122176&amp;ot=625563&amp;sel=gpt-5.2">llm-prices.com calculator</a> estimates that at $29.41 if I was paying for those tokens at API prices, but they were included in my $20/month ChatGPT Plus subscription so the actual extra cost to me was zero.</p>
<h4 id="what-can-we-learn-from-this-">What can we learn from this?</h4>
<p>I’m sharing this project because I think it demonstrates a bunch of interesting things about the state of LLMs in December 2025.</p>
<ul>
<li>Frontier LLMs really can perform complex, multi-hour tasks with hundreds of tool calls and minimal supervision. I used GPT-5.2 for this but I have no reason to believe that Claude Opus 4.5 or Gemini 3 Pro would not be able to achieve the same thing—the only reason I haven’t tried is that I don’t want to burn another 4 hours of time and several million tokens on more runs.</li>
<li>If you can reduce a problem to a robust test suite you can set a coding agent loop loose on it with a high degree of confidence that it will eventually succeed. I called this <a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/">designing the agentic loop</a> a few months ago. I think it’s the key skill to unlocking the potential of LLMs for complex tasks.</li>
<li>Porting entire open source libraries from one language to another via a coding agent works extremely well.</li>
<li>Code is so cheap it’s practically free. Code that <em>works</em> continues to carry a cost, but that cost has plummeted now that coding agents can check their work as they go.</li>
<li>We haven’t even <em>begun</em> to unpack the etiquette and ethics around this style of development. Is it responsible and appropriate to churn out a direct port of a library like this in a few hours while watching a movie? What would it take for code built like this to be trusted in production?</li>
</ul>
<p>I’ll end with some open questions:</p>

<ul>
<li>Does this library represent a legal violation of copyright of either the Rust library or the Python one?</li>
<li>Even if this is legal, is it ethical to build a library in this way?</li>
<li>Does this format of development hurt the open source ecosystem?</li>
<li>Can I even assert copyright over this, given how much of the work was produced by the LLM?</li>
<li>Is it responsible to publish software libraries built in this way?</li>
<li>How much better would this library be if an expert team hand crafted it over the course of several months?</li>
</ul>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No AI* Here – A Response to Mozilla's Next Chapter (462 pts)]]></title>
            <link>https://www.waterfox.com/blog/no-ai-here-response-to-mozilla/</link>
            <guid>46295268</guid>
            <pubDate>Tue, 16 Dec 2025 22:07:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.waterfox.com/blog/no-ai-here-response-to-mozilla/">https://www.waterfox.com/blog/no-ai-here-response-to-mozilla/</a>, See on <a href="https://news.ycombinator.com/item?id=46295268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Mozilla’s new CEO recently announced their <a href="https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/">vision for the future</a>: positioning Mozilla as “the world’s most trusted software company” with AI at its centre. As someone who has spent nearly 15 years building and maintaining Waterfox, I understand the existential pressure Mozilla faces. Their lunch is being eaten by AI browsers. Alphabet themselves reportedly see the writing on the wall, developing what appears to be a new browser separate from Chrome. The threat is real, and I have genuine sympathy for their position.</p>
<p>But I believe Mozilla is making a fundamental mistake.</p>
<h2 id="the-asterisk-matters">The Asterisk Matters</h2>
<p>Let’s be clear about what we’re talking about. “AI” has become a catch-all term that to me, obscures more than it reveals. Machine learning technologies like the <a href="https://github.com/browsermt/bergamot-translator">Bergamot translation project</a> offer real, tangible utility. Bergamot is transparent in what it does (translate text locally, period), auditable (you can inspect the model and its behavior), and has clear, limited scope, even if the internal neural network logic isn’t strictly deterministic.</p>
<p>Large language models are something else entirely˟. They are black boxes. You cannot audit them. You cannot truly understand what they do with your data. You cannot verify their behaviour. And Mozilla wants to put them at the heart of the browser and that doesn’t sit well.</p>
<p>But it’s important to note I do find LLMs have utility, measurably so. But here I am talking in the context of a web browser and the fundamental scepticism I have toward it in that context.</p>
<h2 id="what-is-a-browser-for">What Is a Browser For?</h2>
<p>A browser is meant to be a user agent, more specifically, <em>your</em> agent on the web. It represents you, acts on your behalf, and executes your instructions. It’s called a user agent for a reason.</p>
<p>When you introduce a potential LLM layer between the user and the web, you create something different: “a user agent user agent” of sorts. The AI becomes the new user agent, mediating and interpreting between you and the browser. It reorganises your tabs. It rewrites your history. It makes decisions about what you see and how you see it, based on logic you cannot examine or understand.</p>
<p>Mozilla promises that “AI should always be a choice - something people can easily turn off.” That’s fine. But how do you keep track of what a black box actually does when it’s turned on? How do you audit its behaviour? How do you know it’s not quietly reshaping your browsing experience in ways you haven’t noticed?</p>
<p>Even if you can disable individual AI features, the cognitive load of monitoring an opaque system that’s supposedly working on your behalf would be overwhelming. Now, I truly believe and trust that Mozilla will do what they think is best for the user; but I’m not convinced it will be.</p>
<p>This isn’t paranoia, because after all, “It will evolve into a modern AI browser and support a portfolio of new and trusted software additions.” It’s a reasonable response to fundamentally untrustworthy technology being positioned as the future of web browsing.</p>
<h2 id="mozillas-dilemma">Mozilla’s Dilemma?</h2>
<p>I get it. Mozilla is facing an existential crisis. AI browsers are proliferating. The market is shifting. Revenue diversification from search is urgent. Firefox’s market share continues to decline. The pressure to “do something” must be immense, and I understand that.</p>
<p>But there’s a profound irony in their response. Mozilla speaks about trust, transparency, and user agency while simultaneously embracing technology that undermines all three principles. They promise AI will be optional, but that promise acknowledges they’re building AI so deeply into Firefox that an opt-out mechanism becomes necessary in the first place.</p>
<p>Mozilla’s strength has always come from the technical community - developers, power users, privacy advocates. These are the people who understand what browsers should be and what they’re for. Yet Mozilla seems convinced they need to chase the average user, the mainstream market that Chrome already dominates.</p>
<p>That chase has been failing for over a decade. Firefox’s market share has declined steadily as Mozilla added features their core community explicitly didn’t want. Now they’re doubling down on that strategy, going after “average Joe” users while potentially alienating the technical community that has been their foundation.</p>
<h2 id="what-waterfox-offers-instead">What Waterfox Offers Instead</h2>
<p>Waterfox exists because some users want a browser that simply works well at being a browser. The UI is mature - arguably, it has been a solved for problem for years. The customisation features are available and apparent. The focus is on performance and web standards.</p>
<p>In many ways, browsers are operating systems of their own, and a browser’s job is to be a good steward of that environment. AI, in its current form and in my opinion does not match that responsibility.</p>
<p>And yes, yes - disabling features is all well and good, but at the end of the day, if these AI features are black boxes, how are we to keep track of what they actually do? The core browsing experience should be one that fully puts the user in control, not one where you’re constantly monitoring an inscrutable system that claims to be helping you.</p>
<p>Waterfox will not include LLMs. Full stop. At least and most definitely not in their current form or for the foreseeable future.</p>
<h3 id="a-note-on-other-forks-and-governance">A Note on other Forks and Governance</h3>
<p>The Firefox fork ecosystem includes several projects that tout their independence from Mozilla. Some strip out more features than Waterfox does, some make bolder design choices.</p>
<p>But here’s what often gets overlooked - many of these projects operate without any formal governance structure, privacy policies, or terms of service. There’s no legal entity, no accountability mechanism, no recourse if promises are broken. Open source gives developers the freedom to fork code and make claims, but it doesn’t automatically make those claims trustworthy.</p>
<p>When it comes to something as critical as a web browser - software that mediates your most sensitive online interactions - the existence of a responsible organisation with clear policies becomes crucial. Waterfox maintains formal policies and a legal entity, not because it’s bureaucratic overhead, but because it creates accountability that many browser projects simply don’t have.</p>
<p>You deserve to know who is responsible for the software you rely on daily and how decisions about your privacy are made. The existence of formal policies, even imperfect ones, represents a commitment that your interests matter and that there’s someone to hold accountable.</p>
<p>You may think, so what? And fair enough, I can’t change your mind on that, but Waterfox’s governance has allowed it to do something no other fork has (and likely will not do) - trust from other large, imporant third parties which in turn has given Waterfox users access to protected streaming services via Widevine. It’s a small thing, but to me it showcases the power of said governance.</p>
<h2 id="on-inevitability">On Inevitability</h2>
<p>Some will argue that AI browsers are inevitable, that we’re fighting against the tide of history. Perhaps. AI browsers may eat the world.
But the web, despite having core centralised properties, is fundamentally decentralised. There will always be alternatives. If AI browsers dominate and then falter, if users discover they want something simpler and more trustworthy, Waterfox will still be here, marching patiently along.
We’ve been here before. When Firefox abandoned XUL extensions, Waterfox Classic preserved them. When Mozilla started adding telemetry and Pocket and sponsored content, Waterfox stripped it out. When the technical community asked for a browser that simply respected them, Waterfox delivered.</p>
<p>I’ll keep doing that. Not because it’s the most profitable path or because it’s trendy, but because it’s what users who value independence and transparency actually need.</p>
<p>The browser’s job is to serve you, not to think for you. That core Waterfox principle hasn’t changed, and it won’t.</p>
<hr>
<p>* The asterisk acknowledges that “AI” has become a catch-all term. Machine learning tools like local translation engines (Bergamot) are valuable and transparent. Large language models, in their current black-box form, are neither.</p>
<p>˟ As is my understanding, but please feel free to correct me if that isn’t correct.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MIT professor shot at his Massachusetts home dies (240 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cly08y25688o</link>
            <guid>46295071</guid>
            <pubDate>Tue, 16 Dec 2025 21:52:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cly08y25688o">https://www.bbc.com/news/articles/cly08y25688o</a>, See on <a href="https://news.ycombinator.com/item?id=46295071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>A Massachusetts university professor who was shot at his home has died, campus officials say. </p><p>Nuno F Gomes Loureiro, 47, a nuclear science and engineering professor from Portugal, was shot "multiple times" on Monday and died on Tuesday morning in hospital, according to Brookline police and Massachusetts Institute of Technology (MIT) officials.</p><p>Police said officers responded to a call for gunshots at an apartment at about 8:30pm local time. Loureiro was taken by ambulance to a Boston hospital, where he died on Tuesday morning. </p><p>No one is in custody and police are treating the incident as "an active and ongoing homicide investigation",  the Norfolk County District Attorney's Office said.</p></div><div data-component="text-block"><p>CBS News, the BBC's US media partner, reported that a neighbour said he heard "three loud bangs" Monday evening and thought somebody in the apartment building was kicking in a door. </p><p>Long-time resident Anne Greenwald told CBS that the professor had a young family and went to school nearby.</p><p>Loureiro majored in Physics at Instituto Superior Técnico in Lisbon in 2000 and obtained a Phd in physics at Imperial College London in 2005, according to his faculty web page.</p></div><div data-component="text-block"><p>The theoretical physicist and fusion scientist was known for his award-winning research in magnetised plasma dynamics. </p><p>Magnetised plasma dynamics is the study of the state of matter in which the motion of charged particles is influenced by the presence of an external magnetic field, according to Nature.</p><p>Loureiro joined MIT's faculty in 2016 and was named director of MIT's Plasma Science and Fusion Center in 2024.</p><p>His research addressed "complex problems lurking at the center of fusion vacuum chambers and at the edges of the universe", according to the university's obituary. </p><p>He also studied how to harness clean "fusion power" to combat climate change, CBS said.</p><p>"Our deepest sympathies are with his family, students, colleagues, and all those who are grieving," an MIT spokesperson said in a statement provided to the BBC.</p><p>The university added that "focused outreach and conversations" are taking place within the MIT community to offer care and support for those who knew the professor.</p><p>The centre's preceding director, Dennis Whyte, described Loureiro as both a brilliant scientist and a brilliant person.</p><p>"He shone a bright light as a mentor, friend, teacher, colleague and leader, and was universally admired for his articulate, compassionate manner," Mr Whyte told MIT News. </p><p>Deepto Chakrabarty, the head of MIT's department of physics, echoed those sentiments and said that Loureiro was a champion of plasma physics and that his recent research was "a particularly exciting new scientific direction".</p><p><i id="correction-16-december:-an-earlier-version-of-this-story-incorrectly-defined-the-kind-of-plasma-that-professor-loureiro-researched.">Correction 16 December: An earlier version of this story incorrectly defined the kind of plasma that Professor Loureiro researched.</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI will make formal verification go mainstream (761 pts)]]></title>
            <link>https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html</link>
            <guid>46294574</guid>
            <pubDate>Tue, 16 Dec 2025 21:14:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html">https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html</a>, See on <a href="https://news.ycombinator.com/item?id=46294574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
                

                
                <p>Published by Martin Kleppmann on 08 Dec 2025.</p>
                

                <p>Much has been said about the effects that AI will have on software development, but there is an
angle I haven’t seen talked about: I believe that AI will bring formal verification, which for
decades has been a bit of a fringe pursuit, into the software engineering mainstream.</p>

<p>Proof assistants and proof-oriented programming languages such as <a href="https://rocq-prover.org/">Rocq</a>,
<a href="https://isabelle.in.tum.de/">Isabelle</a>, <a href="https://lean-lang.org/">Lean</a>,
<a href="https://fstar-lang.org/">F*</a>, and <a href="https://agda.readthedocs.io/">Agda</a> have been around for a long
time. They make it possible to write a formal specification that some piece of code is supposed to
satisfy, and then mathematically prove that the code <em>always</em> satisfies that spec (even on weird
edge cases that you didn’t think of testing). These tools have been used to develop some large
formally verified software systems, such as an <a href="https://sel4.systems/">operating system kernel</a>,
a <a href="https://compcert.org/">C compiler</a>, and a
<a href="https://project-everest.github.io/">cryptographic protocol stack</a>.</p>

<p>At present, formal verification is mostly used by research projects, and it is
<a href="https://hillelwayne.com/post/why-dont-people-use-formal-methods/">uncommon</a> for industrial software
engineers to use formal methods (even those working on classic high-assurance software such as
medical devices and aircraft). The reason is that writing those proofs is both very difficult
(requiring PhD-level training) and very laborious.</p>

<p>For example, as of 2009, the formally verified seL4 microkernel consisted of 8,700 lines of C code,
but proving it correct required 20 person-years and
<a href="https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf">200,000 lines</a> of Isabelle
code – or 23 lines of proof and half a person-day for every single line of implementation. Moreover,
there are maybe a few hundred people in the world (wild guess) who know how to write such proofs,
since it requires a lot of arcane knowledge about the proof system.</p>

<p>To put it in simple economic terms: for most systems, the expected cost of bugs is lower than the
expected cost of using the proof techniques that would eliminate those bugs. Part of the reason is
perhaps that bugs are a negative externality: it’s not the software developer who bears the cost of
the bugs, but the users. But even if the software developer were to bear the cost, formal
verification is simply very hard and expensive.</p>

<p>At least, that was the case until recently. Now, LLM-based coding assistants are getting pretty good
not only at writing implementation code, but also at
<a href="https://www.nature.com/articles/s41586-025-09833-y">writing</a>
<a href="https://www.galois.com/articles/claude-can-sometimes-prove-it">proof scripts</a> in
<a href="https://arxiv.org/pdf/2503.14183v1">various languages</a>. At present, a human with specialist
expertise still has to guide the process, but it’s not hard to extrapolate and imagine that process
becoming fully automated in the next few years. And when that happens, it will totally change the
economics of formal verification.</p>

<p>If formal verification becomes vastly cheaper, then we can afford to verify much more software. But
on top of that, AI also creates a <em>need</em> to formally verify more software: rather than having humans
review AI-generated code, I’d much rather have the AI prove to me that the code it has generated is
correct. If it can do that, I’ll take AI-generated code over handcrafted code (with all its
artisanal bugs) any day!</p>

<p>In fact, I would argue that writing proof scripts is one of the best applications for LLMs. It
doesn’t matter if they hallucinate nonsense, because the proof checker will reject any invalid proof
and force the AI agent to retry. The proof checker is a small amount of code that is itself
verified, making it virtually impossible to sneak an invalid proof past the checker.</p>

<p>That doesn’t mean software will suddenly be bug-free. As the verification process itself becomes
automated, the challenge will move to correctly defining the specification: that is, how do you know
that the properties that were proved are actually the properties that you cared about? Reading and
writing such formal specifications still requires expertise and careful thought. But writing the
spec is vastly easier and quicker than writing the proof by hand, so this is progress.</p>

<p>I could also imagine AI agents helping with the process of writing the specifications, translating
between formal language and natural language. Here there is the potential for subtleties to be lost
in translation, but this seems like a manageable risk.</p>

<p>I find it exciting to think that we could just specify in a high-level, declarative way the
properties that we want some piece of code to have, and then to vibe code the implementation along
with a proof that it satisfies the specification. That would totally change the nature of software
development: we wouldn’t even need to bother looking at the AI-generated code any more, just like we
don’t bother looking at the machine code generated by a compiler.</p>

<p>In summary: 1. formal verification is about to become vastly cheaper; 2. AI-generated code needs
formal verification so that we can skip human review and still be sure that it works; 3. the
precision of formal verification counteracts the imprecise and probabilistic nature of LLMs. These
three things taken together mean formal verification is likely to go mainstream in the foreseeable
future. I suspect that soon the limiting factor will not be the technology, but the culture change
required for people to realise that formal methods have become viable in practice.</p>


                <div>
                    <p>If you found this post useful, please
                    <a href="https://www.patreon.com/martinkl">support me on Patreon</a>
                    so that I can write more like it!</p>
                    <p>
                    To get notified when I write something new,
                    <a href="https://bsky.app/profile/martin.kleppmann.com">follow me on Bluesky</a> or
                    <a href="https://nondeterministic.computer/@martin">Mastodon</a>,
                    or enter your email address:
                    </p>

                    

                    <p>
                    I won't give your address to anyone else, won't send you any spam, and you can unsubscribe at any time.
                    </p>
                </div>

                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ty: A fast Python type checker and LSP (759 pts)]]></title>
            <link>https://astral.sh/blog/ty</link>
            <guid>46294289</guid>
            <pubDate>Tue, 16 Dec 2025 20:52:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astral.sh/blog/ty">https://astral.sh/blog/ty</a>, See on <a href="https://news.ycombinator.com/item?id=46294289">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><strong>TL;DR:</strong> <a href="https://github.com/astral-sh/ty">ty</a> is an <strong>extremely fast Python type checker and
language server</strong>, written in Rust, and designed as an alternative to tools like mypy, Pyright, and
Pylance.</p>
<p>Today, we're announcing the Beta release of <a href="https://github.com/astral-sh/ty">ty</a>. We now use ty
exclusively in our own projects and are ready to recommend it to motivated users for production use.</p>
<hr>
<p>At Astral, we build high-performance developer tools for the Python ecosystem. We're best known for
<a href="https://github.com/astral-sh/uv">uv</a>, our Python package manager, and
<a href="https://github.com/astral-sh/ruff">Ruff</a>, our linter and formatter.</p>
<p>Today, we're announcing the Beta release of the next tool in the Astral toolchain: <strong>ty, an
extremely fast Python type checker and language server</strong>, written in Rust.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 430 117"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0 to 50"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M341.5 100.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(61.5 115.5)" font-family="Roboto Mono,monospace" font-size="12">0s</text><text text-anchor="middle" transform="translate(201.5 115.5)" font-family="Roboto Mono,monospace" font-size="12">20s</text><text text-anchor="middle" transform="translate(341.5 115.5)" font-family="Roboto Mono,monospace" font-size="12">40s</text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 4 values: ty, Pyrefly, Pyright, mypy"><g pointer-events="none"><text text-anchor="end" transform="translate(51.5 16.5)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">ty</text><text text-anchor="end" transform="translate(51.5 41.5)" font-family="Roboto Mono,monospace" font-size="12">Pyrefly</text><text text-anchor="end" transform="translate(51.5 66.5)" font-family="Roboto Mono,monospace" font-size="12">Pyright</text><text text-anchor="end" transform="translate(51.5 91.5)" font-family="Roboto Mono,monospace" font-size="12">mypy</text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 2.186; tool: ty" aria-roledescription="bar" d="M61 6h15.302v13H61Z"></path><path aria-label="Sum of time: 5.32; tool: Pyrefly" aria-roledescription="bar" d="M61 31h37.24v13H61Z"></path><path aria-label="Sum of time: 19.623; tool: Pyright" aria-roledescription="bar" d="M61 56h137.361v13H61Z"></path><path aria-label="Sum of time: 45.662; tool: mypy" aria-roledescription="bar" d="M61 81h319.634v13H61Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 5.32; tool: Pyrefly; timeFormat: 5.32s" aria-roledescription="text mark" transform="translate(104.24 41.5)" font-family="Roboto Mono,monospace" font-size="12">5.32s</text><text aria-label="Sum of time: 19.623; tool: Pyright; timeFormat: 19.62s" aria-roledescription="text mark" transform="translate(204.361 66.5)" font-family="Roboto Mono,monospace" font-size="12">19.62s</text><text aria-label="Sum of time: 45.662; tool: mypy; timeFormat: 45.66s" aria-roledescription="text mark" transform="translate(386.634 91.5)" font-family="Roboto Mono,monospace" font-size="12">45.66s</text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 2.186; tool: ty; timeFormat: 2.19s" aria-roledescription="text mark" transform="translate(82.302 16.5)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">2.19s</text></g></g></svg></p><p><span>Type checking the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/home-assistant/core">home-assistant</a> <!-- -->project on the command-line, without caching (<a href="https://github.com/astral-sh/ruff/blob/7f7485d608d2da19a0632a1238f2d4be551f612f/scripts/ty_benchmark/README.md" target="_blank" rel="noreferrer">M4</a>).</span></p></div>
<p>ty was designed from the ground up to power a language server. The entire ty architecture is built
around "incrementality", enabling us to selectively re-run only the necessary computations when a
user (e.g.) edits a file or modifies an individual function. This makes live updates extremely fast
in the context of an editor or long-lived process.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 429 92"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.0 to 2.8"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M311.5 75.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(61.5 90.5)" font-family="Roboto Mono,monospace" font-size="12">0s</text><text text-anchor="middle" transform="translate(186.5 90.5)" font-family="Roboto Mono,monospace" font-size="12">1s</text><text text-anchor="middle" transform="translate(311.5 90.5)" font-family="Roboto Mono,monospace" font-size="12">2s</text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 3 values: ty, Pyright, Pyrefly"><g pointer-events="none"><text text-anchor="end" transform="translate(51.5 16.5)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">ty</text><text text-anchor="end" transform="translate(51.5 41.5)" font-family="Roboto Mono,monospace" font-size="12">Pyright</text><text text-anchor="end" transform="translate(51.5 66.5)" font-family="Roboto Mono,monospace" font-size="12">Pyrefly</text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0044956; tool: ty" aria-roledescription="bar" d="M61 6h.562v13H61Z"></path><path aria-label="Sum of time: 0.3704936; tool: Pyright" aria-roledescription="bar" d="M61 31h46.312v13H61Z"></path><path aria-label="Sum of time: 2.6047441; tool: Pyrefly" aria-roledescription="bar" d="M61 56h325.593v13H61Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.3704936; tool: Pyright; timeFormat: 370.5ms" aria-roledescription="text mark" transform="translate(113.312 41.5)" font-family="Roboto Mono,monospace" font-size="12">370.5ms</text><text aria-label="Sum of time: 2.6047441; tool: Pyrefly; timeFormat: 2.60s" aria-roledescription="text mark" transform="translate(392.593 66.5)" font-family="Roboto Mono,monospace" font-size="12">2.60s</text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0044956; tool: ty; timeFormat: 4.5ms" aria-roledescription="text mark" transform="translate(67.562 16.5)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">4.5ms</text></g></g></svg></p><p><span>Re-computing diagnostics in the language server after editing a file in the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/pytorch/pytorch">PyTorch</a> <!-- -->project (<a href="https://github.com/astral-sh/ruff/blob/7f7485d608d2da19a0632a1238f2d4be551f612f/scripts/ty_benchmark/README.md" target="_blank" rel="noreferrer">M4</a>).</span></p></div>
<p>You can install ty today with <code>uv tool install ty@latest</code>, or via our
<a href="https://marketplace.visualstudio.com/items?itemName=astral-sh.ty">VS Code extension</a>.</p>
<p>Like Ruff and uv, ty's implementation was grounded in some of our core product principles:</p>
<ol>
<li>
<p><strong>An obsessive focus on performance.</strong> Without caching, ty is consistently between 10x and 60x
faster than mypy and Pyright. When run in an editor, the gap is even more dramatic. As an
example, after editing a load-bearing file in the PyTorch repository, ty recomputes diagnostics
in 4.7ms: 80x faster than Pyright (386ms) and 500x faster than Pyrefly (2.38 seconds). ty is very
fast!</p>
</li>
<li>
<p><strong>Correct, pragmatic, and ergonomic.</strong> With features like
<a href="https://docs.astral.sh/ty/features/type-system/#intersection-types">first-class intersection types</a>,
<a href="https://docs.astral.sh/ty/features/type-system/#top-and-bottom-materializations">advanced type narrowing</a>,
and
<a href="https://docs.astral.sh/ty/features/type-system/#reachability-based-on-types">sophisticated reachability analysis</a>,
ty pushes forward the state of the art in Python type checking, providing more accurate feedback
and <a href="https://docs.astral.sh/ty/features/type-system/#gradual-guarantee">avoiding assumptions</a>
about user intent that often lead to false positives. Our goal with ty is not only to build a
faster type checker; we want to build a better type checker, and one that balances correctness
with a deep focus on the end-user experience.</p>
</li>
<li>
<p><strong>Built in the open.</strong> ty was built by our core team alongside dozens of active contributors
under the MIT license, and the same goes for our
<a href="https://marketplace.visualstudio.com/items?itemName=astral-sh.ty">editor extensions</a>. You can
run ty anywhere that you write Python (including in the <a href="https://play.ty.dev/">browser</a>).</p>
</li>
</ol>
<p>Even compared to other Rust-based language servers like Pyrefly, ty can run orders of magnitude
faster when performing incremental updates on large projects.</p>
<div><p><video width="100%" preload="none" autoplay="" loop="" muted="" controls="" playsinline=""><source src="https://astral.sh/static/MP4/TyPyTorch.mp4" type="video/mp4">Your browser does not support the video tag.</video></p><p><span>Editing a central file in the<!-- --> <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noreferrer">PyTorch</a> <!-- -->repository with<!-- --> <a href="https://github.com/astral-sh/ty" target="_blank" rel="noreferrer">ty</a> <!-- -->(left) and<!-- --> <a href="https://github.com/facebook/pyrefly" target="_blank" rel="noreferrer">Pyrefly</a> <!-- -->(right). ty's incremental architecture is designed to make live updates extremely fast.</span></p></div>
<p>ty also includes a
<a href="https://docs.astral.sh/ty/features/diagnostics/">best-in-class diagnostic system</a>, inspired by the
Rust compiler's own world-class error messages. A single ty diagnostic can pull in context from
multiple files at once to explain not only what's wrong, but why (and, often, how to fix it).</p>
<div><div><p><span><span></span><img alt="ty diagnostic showing an invalid assignment error to a TypedDict key with reference to the item declaration" srcset="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic3Light.png&amp;w=3840&amp;q=75 1x" src="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic3Light.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><p><span><span></span><img alt="ty diagnostic showing an invalid assignment error to a TypedDict key with reference to the item declaration" srcset="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic3Dark.png&amp;w=3840&amp;q=75 1x" src="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic3Dark.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><p><span>When assigning an invalid value to a dictionary key,<!-- --> <a href="https://github.com/astral-sh/ty" target="_blank" rel="noreferrer">ty</a> <!-- -->surfaces both the type mismatch at the assignment site and the corresponding item declaration.</span></p></div>
<p>Diagnostic output is the primary user interface for a type checker; we prioritized our diagnostic
system from the start (with both humans and agents in mind) and view it as a first-class feature in
ty.</p>
<div><div><p><span><span></span><img alt="ty diagnostic showing an unresolved import error for tomllib module with reference to Python version configuration" srcset="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic2Light.png&amp;w=3840&amp;q=75 1x" src="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic2Light.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><p><span><span></span><img alt="ty diagnostic showing an unresolved import error for tomllib module with reference to Python version configuration" srcset="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic2Dark.png&amp;w=3840&amp;q=75 1x" src="https://astral.sh/_next/image?url=%2Fstatic%2FPNG%2FTyDiagnostic2Dark.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><p><span>When importing an unresolved module,<!-- --> <a href="https://github.com/astral-sh/ty" target="_blank" rel="noreferrer">ty</a> <!-- -->surfaces both the unresolved import at the import site and the corresponding Python version configuration.</span></p></div>
<p>If you use VS Code, Cursor, or a similar editor, we recommend installing the
<a href="https://marketplace.visualstudio.com/items?itemName=astral-sh.ty">ty VS Code extension</a>. The ty
language server supports <a href="https://docs.astral.sh/ty/features/language-server/">all the capabilities</a>
that you'd expect for a modern language server (Go to Definition, Symbol Rename, Auto-Complete,
Auto-Import, Semantic Syntax Highlighting, Inlay Hints, etc.), and runs in any editor that
implements the <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>.</p>
<p>Following the Beta release, our immediate priority is supporting early adopters. From there, we're
working towards a Stable release next year, with the gap between the
<a href="https://github.com/astral-sh/ty/milestone/2">Beta</a> and
<a href="https://github.com/astral-sh/ty/milestone/4">Stable</a> milestones largely focusing on: (1) stability
and bug fixes, (2) completing the long tail of features in the
<a href="https://github.com/astral-sh/ty/issues/1889">Python typing specification</a>, and (3) first-class
support for popular third-party libraries like <a href="https://pypi.org/project/pydantic/">Pydantic</a> and
<a href="https://pypi.org/project/Django/">Django</a>.</p>
<p>On a longer time horizon, though, ty will power semantic capabilities across the Astral toolchain:
dead code elimination, unused dependency detection, SemVer-compatible upgrade enforcement, CVE
reachability analysis, type-aware linting, and more (including some that are too ambitious to say
out loud just yet).</p>
<p>We want to make Python the most productive programming ecosystem on Earth. Just as with
<a href="https://github.com/astral-sh/ruff">Ruff</a> and <a href="https://github.com/astral-sh/uv">uv</a>, our commitment
from here is that ty will get significantly better every week by working closely with our users.
Thank you for building with us.</p>
<h3><span id="acknowledgements"></span>Acknowledgements<!-- --> <a href="#acknowledgements">#</a></h3>
<p>ty is the most sophisticated product we've built, and its design and implementation have surfaced
some of the hardest technical problems we've seen at Astral. Working on ty requires a deep
understanding of type theory, Python runtime semantics, and how the Python ecosystem actually uses
Python.</p>
<p>I'd like to thank all those that contributed directly to the development of ty, including:
<a href="https://github.com/dcreager">Douglas Creager</a>, <a href="https://github.com/AlexWaygood">Alex Waygood</a>,
<a href="https://github.com/sharkdp">David Peter</a>, <a href="https://github.com/MichaReiser">Micha Reiser</a>,
<a href="https://github.com/BurntSushi">Andrew Gallant</a>, <a href="https://github.com/Gankra">Aria Desires</a>,
<a href="https://github.com/carljm">Carl Meyer</a>, <a href="https://github.com/zanieb">Zanie Blue</a>,
<a href="https://github.com/ibraheemdev">Ibraheem Ahmed</a>,
<a href="https://github.com/dhruvmanila">Dhruv Manilawala</a>, <a href="https://github.com/oconnor663">Jack O'Connor</a>,
<a href="https://github.com/zsol">Zsolt Dollenstein</a>, <a href="https://github.com/mtshiba">Shunsuke Shibayama</a>,
<a href="https://github.com/MatthewMckee4">Matthew Mckee</a>, <a href="https://github.com/ntBre">Brent Westbrook</a>,
<a href="https://github.com/UnboundVariable">UnboundVariable</a>,
<a href="https://github.com/Glyphack">Shaygan Hooshyari</a>, <a href="https://github.com/thejchap">Justin Chapman</a>,
<a href="https://github.com/InSyncWithFoo">InSync</a>, <a href="https://github.com/Bhuminjay-Soni">Bhuminjay Soni</a>,
<a href="https://github.com/abhijeetbodas2001">Abhijeet Prasad Bodas</a>,
<a href="https://github.com/RasmusNygren">Rasmus Nygren</a>, <a href="https://github.com/lipefree">lipefree</a>,
<a href="https://github.com/ericmarkmartin">Eric Mark Martin</a>, <a href="https://github.com/TomerBin">Tomer Bin</a>,
<a href="https://github.com/lucach">Luca Chiodini</a>, <a href="https://github.com/brandtbucher">Brandt Bucher</a>,
<a href="https://github.com/dylwil3">Dylan Wilson</a>, <a href="https://github.com/tyralla">Eric Jolibois</a>,
<a href="https://github.com/felixscherz">Felix Scherz</a>, <a href="https://github.com/leandrobbraga">Leandro Braga</a>,
<a href="https://github.com/nickkuang">Renkai Ge</a>, <a href="https://github.com/brainwane">Sumana Harihareswara</a>,
<a href="https://github.com/TaKO8Ki">Takayuki Maeda</a>, <a href="https://github.com/maxmynter">Max Mynter</a>,
<a href="https://github.com/med1844">med1844</a>, <a href="https://github.com/woodruffw">William Woodruff</a>,
<a href="https://github.com/kiran-4444">Chandra Kiran G</a>, <a href="https://github.com/DetachHead">DetachHead</a>,
<a href="https://github.com/esadek">Emil Sadek</a>, <a href="https://github.com/j178">Jo</a>,
<a href="https://github.com/jorenham">Joren Hammudoglu</a>, <a href="https://github.com/mahmoud">Mahmoud Saada</a>,
<a href="https://github.com/mmlb">Manuel Mendez</a>, <a href="https://github.com/markzding">Mark Z. Ding</a>,
<a href="https://github.com/silamon">Simon Lamon</a>, <a href="https://github.com/suneettipirneni">Suneet Tipirneni</a>,
<a href="https://github.com/fgiacome">Francesco Giacometti</a>,
<a href="https://github.com/adamaaronson">Adam Aaronson</a>, <a href="https://github.com/alpaylan">Alperen Keleş</a>,
<a href="https://github.com/charliecloudberry">charliecloudberry</a>,
<a href="https://github.com/danparizher">Dan Parizher</a>, <a href="https://github.com/danielhollas">Daniel Hollas</a>,
<a href="https://github.com/dsherret">David Sherret</a>, <a href="https://github.com/mdqst">Dmitry</a>,
<a href="https://github.com/ercbot">Eric Botti</a>, <a href="https://github.com/eruditmorina">Erudit Morina</a>,
<a href="https://github.com/frgfm">François-Guillaume Fernandez</a>,
<a href="https://github.com/fabridamicelli">Fabrizio Damicelli</a>,
<a href="https://github.com/Guillaume-Fgt">Guillaume-Fgt</a>, <a href="https://github.com/hugovk">Hugo van Kemenade</a>,
<a href="https://github.com/JosiahKane">Josiah Kane</a>, <a href="https://github.com/LoicRiegel">Loïc Riegel</a>,
<a href="https://github.com/Mathemmagician">Ramil Aleskerov</a>, <a href="https://github.com/s-rigaud">Samuel Rigaud</a>,
<a href="https://github.com/soof-golan">Soof Golan</a>, <a href="https://github.com/Usul-Dev">Usul-Dev</a>,
<a href="https://github.com/decorator-factory">decorator-factory</a>, <a href="https://github.com/omahs">omahs</a>, and
<a href="https://github.com/fatelei">wangxiaolei</a>.</p>
<p>We'd also like to thank the <a href="https://github.com/salsa-rs/salsa">Salsa</a> team (especially
<a href="https://github.com/nikomatsakis">Niko Matsakis</a>, <a href="https://github.com/davidbarsky">David Barsky</a>,
and <a href="https://github.com/veykril">Lukas Wirth</a>) for their support and collaboration; the
<a href="https://github.com/elixir-lang/elixir">Elixir</a> team (especially
<a href="https://github.com/josevalim">José Valim</a>, <a href="https://www.irif.fr/~gc/">Giuseppe Castagna</a>, and
<a href="https://gldubc.github.io/">Guillaume Duboc</a>), whose work strongly influenced our approach to
gradual types and intersections; and a few members of the broader Python typing community:
<a href="https://github.com/erictraut">Eric Traut</a>, <a href="https://github.com/JelleZijlstra">Jelle Zijlstra</a>,
<a href="https://github.com/grievejia">Jia Chen</a>, <a href="https://github.com/samwgoldman">Sam Goldman</a>,
<a href="https://github.com/hauntsaninja">Shantanu Jain</a>, and <a href="https://github.com/stroxler">Steven Troxler</a>.</p>
<p>Finally, on a personal level, I'd like to highlight the core team
(<a href="https://github.com/AlexWaygood">Alex</a>, <a href="https://github.com/BurntSushi">Andrew</a>,
<a href="https://github.com/Gankra">Aria</a>, <a href="https://github.com/carljm">Carl</a>,
<a href="https://github.com/sharkdp">David</a>, <a href="https://github.com/dhruvmanila">Dhruv</a>,
<a href="https://github.com/dcreager">Doug</a>, <a href="https://github.com/ibraheemdev">Ibraheem</a>,
<a href="https://github.com/oconnor663">Jack</a>, and <a href="https://github.com/MichaReiser">Micha</a>), who created ty
from nothing and pushed it to be great from Day 1.</p></article></div>]]></description>
        </item>
    </channel>
</rss>