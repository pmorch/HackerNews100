<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 27 Jan 2026 15:30:13 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[TikTok users can't upload anti-ICE videos. The company blames tech issues (306 pts)]]></title>
            <link>https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec</link>
            <guid>46779809</guid>
            <pubDate>Tue, 27 Jan 2026 13:44:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec">https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec</a>, See on <a href="https://news.ycombinator.com/item?id=46779809">Hacker News</a></p>
Couldn't get https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[I made my own Git (171 pts)]]></title>
            <link>https://tonystr.net/blog/git_immitation</link>
            <guid>46778341</guid>
            <pubDate>Tue, 27 Jan 2026 10:55:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tonystr.net/blog/git_immitation">https://tonystr.net/blog/git_immitation</a>, See on <a href="https://news.ycombinator.com/item?id=46778341">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Celebrities say they are being censored by TikTok after speaking out against ICE (227 pts)]]></title>
            <link>https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas</link>
            <guid>46777652</guid>
            <pubDate>Tue, 27 Jan 2026 09:38:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas">https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas</a>, See on <a href="https://news.ycombinator.com/item?id=46777652">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Celebrities say they are being censored by TikTok after speaking out against ICE"><p>In the wake of Border Patrol's deadly shooting of VA nurse <a href="https://www.advocate.com/news/federal-agents-kill-minneapolis-man">Alex Pretti</a>, <a href="https://www.out.com/famous-gay-people" target="_blank">celebrities</a> are speaking out about TikTok suppressing videos critical of <a href="https://www.pride.com/culture/reactions-to-ice-agent-slipping-on-ice">U.S. Immigration and Customs Enforcement</a>.</p><p><em>Hacks</em> star <a href="https://www.pride.com/culture/celebrities/megan-stalter">Megan Stalter</a> said she's leaving TikTok because she believes the social media app is censoring videos she made that were critical of ICE. </p><hr><p>Stalter joined other celebrities who have been critical of ICE following the shooting of Pretti, the second U.S. citizen to be shot and killed by ICE agents, less than a month after the extrajudicial killing of Renee Good.</p><p>“I've tried for hours to upload the same video, and it wouldn't show it to one person,’ she wrote on her Instagram account. 'ABOLISH ICE! Delete TikTok!'</p><p>The out actress and comedian wrote on her Instagram account that she will be “downloading and deleting” her TikTok account because the app “is under new ownership and we are being completely censored and monitored.”</p><div id="rebelltitem2" data-id="2" data-reload-ads="false" data-is-image="False" data-href="https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas#rebelltitem2" data-basename="particle-2" data-post-id="2675034738" data-published-at="1769455015" data-use-pagination="False"><p>Stalter also pointed out that TikTok’s latest update to its privacy policy, since being bought by an investor group headed by Trump ally and Oracle billionaire Larry Ellison, allows the social media site to collect sensitive information about its users, including their “sexual life or sexual orientation, status as transgender or nonbinary, citizenship or immigration status.”</p><p>But according to <u><em><a href="https://www.techcrunch.com/2026/01/23/tiktok-users-freak-out-over-apps-immigration-status-collection-heres-what-it-means/" rel="noopener noreferrer" target="_blank">TechCrunch</a>,</em></u> this language has been included in the privacy policy since Aug. 2024, and wasn’t changed in response to the Trump administration’s latest escalation of immigration enforcement, and is “primarily there to comply with state privacy laws like California’s Consumer Privacy Act.”</p><p>Stalter isn’t the only celebrity who TikTok has allegedly been suppressing or shadow-banning — the stealthy restriction of a creator’s content so that it becomes less visible to social media users and followers. Pop star Billie Eilish has also claimed her brother, singer-songwriter Finneas, has had his video calling out ICE suppressed on TikTok.</p><p>In her Instagram Stories, Eilish posted a screenshot of Finneas’ anti-ICE TikTok video that showed him only having 114 likes, writing that “TikTok is silencing people btw.”</p></div><div id="rebelltitem1" data-id="1" data-reload-ads="false" data-is-image="False" data-href="https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas#rebelltitem1" data-basename="particle-1" data-post-id="2675034738" data-published-at="1769455015" data-use-pagination="False"><p>However, less than 24 hours later, the video where Finneas said Pretti “was being beaten to a pulp on the ground, he didn’t draw his weapon. He had a weapon on him legally. And they shot the f**k out of him,” has more than 220,000 views and over 70,000 likes on TikTok.</p><p>It’s unclear if TikTok is censoring celebrities who are speaking out against the actions of ICE in Minneapolis, but footage of Pretti being shot by Border Patrol agents is still available on the app, where you can also find commentary about the shooting from political content creators and reports from news organizations.</p><p>PRIDE contacted Megan Stalter and Finneas, but neither immediately responded to a request for comments.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The state of Linux music players in 2026 (101 pts)]]></title>
            <link>https://crescentro.se/posts/linux-music-players-2026/</link>
            <guid>46776564</guid>
            <pubDate>Tue, 27 Jan 2026 07:26:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crescentro.se/posts/linux-music-players-2026/">https://crescentro.se/posts/linux-music-players-2026/</a>, See on <a href="https://news.ycombinator.com/item?id=46776564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><em>Update: This post generated a <a href="https://lobste.rs/s/bpqtph/state_linux_music_players_2026">thread on lobste.rs</a> with some more recommendations and thoughts from the friendly folks over there!</em></p>
<p>If you haven’t heard yet, in big 2026 we’re all ditching <a href="https://www.windowscentral.com/artificial-intelligence/microslop-trends-on-social-media-backlash-to-microsofts-on-going-ai-obsession-continues">Microslop</a> for systems that actually respect you, and we’re also breaking up with our <a href="https://www.theverge.com/news/862465/spotify-premium-us-price-increase-2026">ever-pricier Spotify subscriptions</a> in exchange for actual ownership of the media we consume. So, for Fun February, I thought I’d take a look at some of the apps we can use to fill the Spotify-shaped void.</p>
<h2 id="the-manifesto-which-you-can-skip-if-you-do-not-care-about-the-self-righteous-linux-user-rant">The manifesto, which you can skip if you do not care about the self-righteous Linux user rant</h2>
<p>At this point, I strongly believe even straight up piracy is better for artists than streaming. At least looking up your favorite artist on Soulseek doesn’t pop up a dozen ads and two AI-generated ripoffs that Spotify would rather you listen to as they profit more from them.</p>
<p>But copyright infringement is only good when multi-trillion-dollar corporations do it to feed their LLMs. Us peasants are still bound by regular laws. So do not Google “life of a showgirl torrent safe no virus”. Instead, you can just… buy music for cheap.</p>
<p>The never-ending vinyl trend cratered prices of CDs, and even new releases can be found for under 10€, with older ones available for half that, especially if you look up sales. If you aren’t too bothered by a lossy format, iTunes - yes, that iTunes, the Apple one - will sell you DRM-free music on release day just like in the good old days. Finally, most music that’s not released on a major label finds its way to Bandcamp, which is another venue for lossless DRM-free music.</p>
<p>Of course, we’re not living in the stone ages anymore, so no one expects you to carry your Discman or iPod around. It takes whole of five minutes to pop a CD into a cheap drive and rip high-quality FLACs onto your drive, which you can then stream from wherever you are in the world. Yes, this advanced technology that took Spotify almost two full decades to figure out can be yours in just a few simple steps through servers like <a href="https://jellyfin.org/">Jellyfin</a> or <a href="https://github.com/navidrome/navidrome">Navidrome</a> running on your own hardware.</p>
<p>You might say that owning is more expensive than renting, even with all the price increases. Sure. But I’ve paid for Spotify for ten years, from 2014 to 2024, and that’s a solid 1200€ with the old pricing. At the end, I had nothing to show for it. My carefully curated “library” was not mine - it was held hostage by a company that can up the prices at any point. If I stop paying, it’s all gone. And it’s not like the artists profited from that exchange either - one purchase of an album easily pays them more than a thousand streams, and realistically I do not stream most albums a thousand times.</p>
<p>At a time when copyright, and laws in general, only seem to apply selectively, I would rather directly support the artists whose work I enjoy and who need it. And for the rest… well, Taylor already got my right kidney for the Eras tour tickets. I’m sure she won’t mind if I give Opalite a few spins without selling my left one too.</p>
<h2 id="the-competition">The competition</h2>
<p>Anyway, with that out of the way, I wanted to take a look at the state of Linux music players in the current year. I went to  <code>nixpkgs</code> and searched for “music player”<sup id="fr-1-1"><a href="#fn-1">1</a></sup>, which gave me about 200 results. Then I narrowed it down to a handful of actual desktop music players that are also not streaming services.</p>
<p>I looked for features that I would expect to find in an average streaming app:</p>
<ul>
<li><strong>Appearance:</strong> Modern, intuitive user interface. Looks like a desktop app, and not a blown-up phone app. Designed for human use (no CLIs). Celebrates music as an art form (doesn’t look like an Excel spreadsheet).</li>
<li><strong>Native:</strong> Respects common protocols - I can run it in the background, control the player with keyboard shortcuts, and it shows up in my shell as a music player.</li>
<li><strong>Performance:</strong> Snappy navigation. Works reasonably well with a moderately sized music library.</li>
<li><strong>Features:</strong> Has a concept of a “music library”. Fast, quality search. Playlists and play queues are easy to access and control. Respects existing metadata, doesn’t mess up my files by enforcing its own scheme.</li>
</ul>
<p>The following is by no means an exhaustive list of Linux music players, but I think it covers a nice range and hope it helps someone discover something new. I also tried to surface only the apps I either thought were good or had a lot of potential - if I thought something was downright bad or if it didn’t work I just skipped over it, as all of these apps are free and open source and someone, somewhere put at least some effort into them.</p>
<h2 id="amberol">Amberol</h2>
<p><a href="https://gitlab.gnome.org/World/amberol">Amberol</a> is “a small and simple sound and music player that is well integrated with GNOME.”</p>
<p>This barely fits my criteria for features. But you know what? I kinda like it! Super minimal, no library management (beyond restoring your previous playlist when you load it up), but what it does, it does great. The waveform on the scrubber is a very nice touch. Looks great for very casual listeners, or maybe as your default app when opening an audio file.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/amberol.png" alt="screenshot of Amberol" loading="lazy" decoding="async"></p>
<h2 id="">Euphonica</h2>
<p><a href="https://github.com/htkhiem/euphonica">Euphonica</a> is an “MPD client with delusions of grandeur”. To set up Euphonica you will also need to set up MPD, which is not tragically difficult, and you might even prefer it over a bespoke library isolated to a specific app.</p>
<p>Euphonica has been my daily driver before I embarked on this journey, and it’s fairly straightforward with a few flourishes on top. You have your album and artist pages, a queue, playlists, and nice extras like synced lyrics. I also think it’s the prettiest one in the list - there’s <em>just enough</em> flair to the UI that it seems like it’s “glowing”, the album art is given ample space as it deserves, and the (optional) background visualizer is very tastefully implemented.</p>
<p>It’s not without its quirks. The UI chokes a bit with large collections, and despite my best efforts I’m unable to get photos for any artist except ABBA for some reason (maybe the developer is Swedish?). I also wish it had a song search function, more sorting options, and that re-ordering the queue could be done with drag and drop rather than buttons. My biggest complaint, however, is that changing the volume requires using my scroll wheel on the volume knob. At least let me click and move it up and down.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/euphonica.png" alt="screenshot of Euphonica" loading="lazy" decoding="async"></p>
<h2 id="-1">Feishin</h2>
<p><a href="https://github.com/jeffvli/feishin">Feishin</a> is “a modern self-hosted music player”. You will need a music server of some description: Jellyfin, Navidrome and Subsonic are supported.</p>
<p>Feishin is by far the most feature-complete player on this list. If you want your “personal Spotify”, this is it. The user interface is very customizable, there’s not just search but a <em>goddamn command palette</em> for easy keyboard navigation, and the entire experience is very reminiscent of what you’d get from a streaming service if it cared for the user rather than the shareholders. This includes recommendations (from your own library), highlights, statistics and other fun stuff. Sure, a lot of it is powered by Jellyfin itself, but Feishin presents it in a coherent, understandable and friendly manner.</p>
<p>Not everything is perfect. Since Feishin is an Electron app that talks to your (potentially remote) music server, there are some obvious web-isms, like the in-app notifications and spinners while content loads, as well as the icky feeling of running yet another Chrome instance. You also depend on the Electron audio stack. However, those rough edges are generally minor, the important stuff works well, and the entire package is absolutely worth your try.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/feishin.png" alt="screenshot of Feishin" loading="lazy" decoding="async"></p>
<h2 id="-2">Lollypop</h2>
<p><a href="https://gitlab.gnome.org/World/lollypop">Lollypop</a> is “a new GNOME music playing application”.</p>
<p>I really want to like this app. The album of the day feature is very cool - a small, simple, but thoughtful feature (even if it did try to get me to listen to Weezer’s Blue Album - not today, Satan!). I like that it opens up on the “suggestions” page instead of an alphabetical list of Everything. It supports YouTube music playback. Someone clearly cares about this a lot.</p>
<p>On the other hand, the user experience is painful. The onboarding flow that gives no indication of the next step, the hidden sidebar that magically appears when you resize the window, the fact that you need to click the “plus” button next to the “Reset collection” label in the settings to add a directory to your library (and yes, I understand that ‘Reset collection’ is a button in its own right, but it only looks like a button if you hover over it), the location of the queue (hidden in the “Playing albums” item in the sidebar)…</p>
<p>I get that these might be GNOME-isms, but they are <strong>bad</strong> GNOME-isms. You absolutely <strong>can</strong> make a good app with GTK4 that looks like it belongs on the GNOME desktop. You just need to ignore everything the GNOME developers tell you to do. Be brave! I believe in you, Lollypop!</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/lollypop2.png" alt="screenshot of Lollypop" loading="lazy" decoding="async"></p>
<h2 id="-3">Plattenalbum</h2>
<p><a href="https://github.com/SoongNoonien/plattenalbum">Plattenalbum</a> is an album-focused MPD client. “Browse your collection while viewing large album covers. Play your music without managing playlists”. As with the previous MPD client, you will need to bring your own MPD.</p>
<p>Plattenalbum is kinda like Amberol if you strapped basic library search on top of it. If you want to occasionally listen to a full album and you generally know what you want, it’s going to get you there. The UI is pretty clean and minimal, although (another GNOME-ism) what you see is what you get - there are barely any customization options to speak of.</p>
<p>I want to like this concept - it’s reminiscent of the <a href="https://longplay.rocks/">Longplay app</a> which is an album-focused Apple Music client for iOS and the Mac. But Plattenalbum falls a bit short. You cannot even see a list of <em>all</em> albums in your library or sort by anything except the weird ‘Lastname, Firstname unless it’s a band then Sorta Alphabetically unless the name starts with “The” or “A”’. There’s also no support for multi-disc releases. I think there’s a lot of potential here, and I hope it gets realized over time.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/plattenalbum.png" alt="screenshot of Plattenalbum" loading="lazy" decoding="async"></p>
<h2 id="-4">Recordbox</h2>
<p><a href="https://codeberg.org/edestcroix/Recordbox">Recordbox</a> is “yet another music player for Linux, built with GTK and Libadwaita for the GNOME desktop”.</p>
<p>Recordbox had the best onboarding experience by far of any app on this list - click the prominent button, choose your music directory, wait for the obvious progress indicator to fill up, bam, done. You’re dropped into a very comfortable three-pane library screen reminiscent of iTunes when it was good.</p>
<p>From there I was also very happy to just hit Ctrl+F, be placed in the universal search bar, look up albums, artists or tracks, and have a few obvious options on what to do next. The app feels snappy even when rapidly scrolling through hundreds of albums. It <em>even</em> properly shows multi-disc albums. Another thing that I appreciated is that albums are grouped in the queue, so if you queue a couple of albums you can see (and also re-order!) them as whole units rather than a bunch of tracks.</p>
<p>I could nitpick the “now playing” section which seems a little bit unfinished, and some GNOME-isms like putting some settings into the Settings window (good) and some settings in three-dot menus (why?). But, all things considered, and given that it’s a pre-1.0 release, I’m really impressed by what the developers did in what seems to be a little over two years. Great job!</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/recordbox.png" alt="screenshot of Recordbox" loading="lazy" decoding="async"></p>
<h2 id="-5">Strawberry (Clementine, Amarok)</h2>
<p><a href="https://amarok.kde.org/">Amarok</a> needs little introduction - it was <em>the</em> Linux music player of its day, back when getting the audio drivers to work was a cause for celebration in its own right. It heavily influenced <a href="https://www.clementine-player.org/">Clementine</a> and <a href="https://www.strawberrymusicplayer.org/">Strawberry</a>. I’m grouping them all together because Clementine and Strawberry both look like Amarok’s UI was dragged kicking and screaming from late 90s into the early 2010s, and out of those three, Strawberry seems to be the most prominent one, while Amarok is kinda buggy on my WM.</p>
<p>Both Clementine and Strawberry seem functional, but out of the two, Strawberry looks marginally better with the context pane and slightly more consistent design. The interface is still less intuitive than I’d like it to be, and there’s really no need to have a giant translucent strawberry in the middle of my screen at all times. The foundation seems solid, though, and I really think that this venerable lineage of music players could reclaim its crown as the undisputed king of music players with a clean new design that streamlined the experience, trimmed some of the cruft, and modernized the appearance to match the rest of the Plasma desktop.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/strawberry.png" alt="screenshot of Strawberry" loading="lazy" decoding="async"></p>
<h2 id="-6">Tauon</h2>
<p><a href="https://github.com/Taiko2k/Tauon">Tauon</a> is “the music player of today”. (It seems like the tagline used to be “Linux desktop music player from the future”, which sounds way cooler, but okay…)</p>
<p>I’m going to be super honest here - I never liked the “everything-is-a-playlist” approach of a specific breed of music players. Some people swear by it, but I find it overwhelming and confusing.</p>
<p>Nonetheless, if this is your vibe, Tauon seems solid. The UI is a bit reminiscent of a DJ deck - I think it’s the default color scheme and the stretched icons. Being a native app, it’s super snappy, and scrolling through 8k+ tracks feels smooth, even if the scroll bar is on the left of the window for some reason. Navigation is not super intuitive at the start, but it certainly gets out of your way as much as possible and I see how I could learn to appreciate it with a little bit of effort.</p>
<p>Tauon also seems to support Plex, Subsonic, Jellyfin and even Spotify as network sources, includes tag management options, a lyrics editor and Discord integration if that’s your jam. It certainly gives Feishin a run for its money in the features department. Overall, if you’d consider yourself a “power user” and you’ve been looking for a Linux version of foobar2000, this is the app for you.</p>
<p><img src="https://crescentro.se/posts/linux-music-players-2026/tauon.png" alt="screenshot of Tauon" loading="lazy" decoding="async"></p>
<h2 id="-7">Summary</h2>
<p>If you have a Jellyfin or a Subsonic-compatible server, and even if you do not but are willing to spend a little bit of time setting one up, <a href="https://github.com/jeffvli/feishin">Feishin</a> is the obvious choice. It works great, looks modern, and has tons of features. Once you set it up, it’s super simple to use.</p>
<p>For local playback or for the Electron-averse, <a href="https://github.com/Taiko2k/Tauon">Tauon</a> is definitely the power user’s choice with all of its intricacies. Otherwise, <a href="https://codeberg.org/edestcroix/Recordbox">Recordbox</a> is shaping up to be a really good choice, and <a href="https://github.com/htkhiem/euphonica">Euphonica</a> is still my pick if you already have an MPD server running.</p>
<p>If you’re just looking to play a few tracks now and then, I don’t know why you’ve been reading up until now, but <a href="https://gitlab.gnome.org/World/amberol">Amberol</a> is super cute.</p>
<p>Honestly, I’m really happy with this. I started looking into this feeling a bit desperate, but there’s actually a vibrant ecosystem of native Linux apps out there, with people building things they care about, and even if all the features aren’t all the way there yet, it’s much better than it was. I hope these trends continue!</p>
<section>
<ol>
<li id="fn-1">
<p>I used <code>nixpkgs</code> as it’s the largest repository of Linux software that exists and because I can <code>nix run nixpkgs#&lt;app&gt;</code> without setting it up and cleaning up afterwards. I’m sure your favorite packaging system is superior, and I do not need to be told that. <a href="#fr-1-1">↩</a></p>
</li>
</ol>
</section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Russia using Interpol's wanted list to target critics abroad, leak reveals (173 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c20gg729y1yo</link>
            <guid>46776454</guid>
            <pubDate>Tue, 27 Jan 2026 07:06:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c20gg729y1yo">https://www.bbc.com/news/articles/c20gg729y1yo</a>, See on <a href="https://news.ycombinator.com/item?id=46776454">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline" data-component="byline-block"><p><span data-testid="byline-contributors"><p><span>Cate Brown<!-- -->,</span><span data-testid="byline-contributors-contributor-0-role-location">BBC Eye Investigations<!-- -->,</span></p><p><span>Max Hudson</span><span>and</span></p><p><span>Julia Luft<!-- -->,</span><span data-testid="byline-contributors-contributor-2-role-location">BBC Eye Investigations</span></p></span></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/f12a/live/ae4bdbc0-fa9a-11f0-b385-5f48925de19a.jpg.webp" loading="eager" alt="BBC A man with short, light brown hair and stubble looks at a piece of paper. He is wearing a dark blue, short-sleeved polo shirt. "><span>BBC</span></p></div><p data-component="caption-block"><figcaption>Businessman Igor Pestrikov found Moscow had put him on a wanted list after he fled Russia in 2022</figcaption></p></figure><div data-component="text-block"><p>Thousands of files provided by a whistleblower at Interpol expose for the first time the extent of Russia's apparent abuse of the international policing agency to target its critics abroad.</p><p>The data provided to the BBC World Service and French investigative outlet, Disclose, reveals that Russia is using Interpol's wanted lists to request the arrest of people such as political opponents, businessmen and journalists, claiming that they have committed crimes.</p><p>Analysis of data also suggests that over the past decade, Interpol's own independent complaints unit has received more complaints about Russia than anyone else - three times more than the next highest country, Turkey.</p><p>In addition, it indicates complaints against Moscow's requests have led to more cases being overturned than for any other country.</p><p>After Russia's full-scale invasion of Ukraine, Interpol introduced extra checks on Moscow's activity "to prevent any potential misuse of Interpol's channels in relation to the targeting of individuals within or beyond the conflict in Ukraine".</p><p>But the leaked documents suggest these did not prevent Russia abusing the system and the whistleblower told us some stricter measures were quietly dropped in 2025.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/c44d/live/65a9a4d0-f7a0-11f0-a422-4ba8a094a8fa.jpg.webp" loading="lazy" alt="OLIVIER CHASSIGNOLE/AFP via Getty Images A mosaic on the floor of the Interpol building showing the organisation's logo. It has a map of the world in a circle with the sea depicted in blue and the land in grey. Behind the map is a sword and beneath it are gold weighing scales and the word Interpol."><span>OLIVIER CHASSIGNOLE/AFP via Getty Images</span></p></div><p data-component="caption-block"><figcaption>Interpol says it has systems in place to avoid misuse and these have been strengthened in recent years</figcaption></p></figure><div data-component="text-block"><p>In response, Interpol says that every year, thousands of the world's most serious criminals are arrested thanks to its operations and that it has a number of systems to avoid misuse which have been strengthened over the last few years.</p><p>It also says it is aware of the potential impact requests for arrest can have on individuals.</p><p>"When you're hit with a red notice, your life changes completely," says Igor Pestrikov, a Russian businessman, whose name appears in the leaked files.</p><p>Interpol is not a global police force itself, but helps police across the world to co-operate.</p><p>A red notice is an alert to all of its 196 member countries, asking them to locate and arrest a person. A red diffusion is a similar request but is only sent to individual countries.</p><p>Pestrikov found he was named in a red diffusion after he fled Russia in June 2022 - four months after the invasion of Ukraine - and applied for asylum in France.</p><p>He felt he had two options: "Go to the police and say, 'I'm in the Interpol system,'" and risk arrest or lie low. This may mean "you can't rent an apartment, your bank accounts get blocked", which is what happened to him, he says.</p><p>"It's constant nerves, all the time," he adds, explaining he was always looking over his shoulder. For safety, his daughter and her mother moved to another country.  The police can "break into your house at any time… that's why you're like a cornered rat", he says.</p><p>"It's the stress, the nerves, the pressure, the lawlessness inflicted on you," that breaks families apart, he adds.</p></div><div data-component="text-block"><p>Pestrikov had been a major shareholder in large metals companies in Russia that were privatised in the 1990s, most notably Solikamsk Magnesium Plant.</p><p>In the months leading up to the 2022 invasion of Ukraine, he says government ministers pressured him to stop selling his products abroad and only supply the Russian market. He believed this would mean his products could be used to make components for military hardware, such as fighter jets and tanks.</p><p>He says it wasn't just that he was against "having to sell much cheaper and to whoever the ministries told me to" but that "it was a moral issue as well... no-one wanted to get involved even indirectly in the production of something used to kill people".</p><p>Pestrikov believes his refusal to comply and the fact his wife at the time was Ukrainian led to his companies being nationalised and to Russia investigating him for financial crimes.</p><p>After he fled to France, he was worried that the Kremlin might try to target him there, so he contacted Interpol and was told about the red diffusion request, which had passed the agency's checks.</p><p>Pestrikov decided to challenge it through Interpol's internal, independent watchdog, the Commission for the Control of Interpol's Files (CCF), arguing that Russia's request was politically motivated.</p><p>Interpol's constitution expressly states that the organisation cannot be used "to undertake any intervention or activities of a political, military, religious or racial character".</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2d27/live/4ba93200-f87f-11f0-b5f7-49f0357294ff.jpg.webp" loading="lazy" alt="ARIS MESSINIS/AFP via Getty Images A firefighter is standing on a ladder next to a light grey multi-storey building which has white smoke pouring out of it. The twisted remains of balconies can been seen and there is no glass in many of the window frames. "><span>ARIS MESSINIS/AFP via Getty Images</span></p></div><p data-component="caption-block"><figcaption>Pestrikov fled Russia after its full-scale invasion of Ukraine began - one of the first cities to be attacked was Chuguiv in eastern Ukraine</figcaption></p></figure><div data-component="text-block"><p>After Pestrikov had spent almost two years on the wanted list, the CCF ruled that his case was predominantly political. He showed us CCF documents that said the information Russia had provided was "generic and formulaic" and there had been an "inadequate explanation" of the alleged crime. Interpol cancelled the request for Pestrikov's detention.</p><p>Interpol only releases very basic data about illegitimate requests for arrests and since 2018 has not revealed which countries are the subject of complaints and inquiries. This lack of transparency makes it difficult to assess the scale of the problem, but for the first time, the leaked documents reveal a much fuller picture.</p><p>One batch of files shared with the BBC contains a list of complaints sent to the CCF.</p><p>The data is not complete, but it covers a broad range of countries, and where the nation requesting an arrest is listed, there are more complaints about Russia than anywhere else - this has been the case for the past 11 years.</p><p>The files also show that in the past decade, at least 700 people who were wanted by Russia complained to the CCF, and at least 400 of them had their red notices or diffusions overturned - that is more than for any other country, according to the data we received.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/e501/live/46e7b890-f79e-11f0-a422-4ba8a094a8fa.jpg.webp" loading="lazy" alt="A man with thick, curly, dark hair, moustache and beard looks at a piece of paper. He is wearing glasses, a light grey jumper over a light shirt, and light brown trousers. "></p></div><p data-component="caption-block"><figcaption>The files show Russia attempted to use Interpol's messaging system to get information about journalist Armen Aramyan after he left the country</figcaption></p></figure><div data-component="text-block"><p>"Historically it has been Russia who is one of the main perpetrators of abusive red notices," says British barrister Ben Keith, who has represented many clients wishing to have their names removed from Interpol's wanted lists.</p><p>He thinks Interpol has a particular problem with Russia and that the agency's attempts to prevent abuse have not been successful.</p><p>He says that he has "a steady flow of clients who are subject to Russian red notices who are either politically connected, or often pro-Ukraine, or alternatively as a result of corporate raiding".</p><p>International lawyer Yuriy Nemets, who specialises in Interpol matters and extradition, agrees that Interpol's extra scrutiny of Russia's requests for arrests, introduced after its full-scale invasion of Ukraine, has not proved effective.</p><p>He says he is aware of a number of cases in which Russians opposed to the war "have been targeted for speaking out against what's going on and were charged with financial… or other ordinary crimes and put into the database based on that".</p><p>"It's not hard to game the system," he adds.</p><p>As well as information on notices and complaints, the Interpol insider also provided the BBC with thousands of messages sent between individual countries via Interpol's messaging system, revealing another, less formal route to trace people abroad.</p><p>One message from Moscow to law enforcement agents in Abu Dhabi explained how Interpol had denied a request for a red notice, but that it still wanted help in tracing the subject's whereabouts. This goes against Interpol advice that members should not use its channels in this way.</p><p>The leak also contains a message about Armen Aramyan, a journalist who had fled Russia after he was convicted of "engaging minors in dangerous activities" for reporting on student protests that supported the opposition leader Alexei Navalny in January 2021.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/ed2e/live/93f21280-f851-11f0-b5f7-49f0357294ff.jpg.webp" loading="lazy" alt="Aleksey Fokin/SOPA Images/LightRocket via Getty Images A row of police officers, wearing black uniforms with riot shields, helmets and protective leg gear, stretches across a street in a town centre. "><span>Aleksey Fokin/SOPA Images/LightRocket via Getty Images</span></p></div><p data-component="caption-block"><figcaption>Riot police were deployed when thousands of people across Russia protested against the arrest of opposition leader Alexei Navalny, who died in suspicious circumstances in prison in 2024</figcaption></p></figure><div data-component="text-block"><p>Aramyan went to Armenia and then on to Germany. The message from Russia to law enforcement entities in both countries sidestepped the more formal red notice and red diffusion process, and asked for "any useful information" about Aramyan as well as his whereabouts.</p><p>The message was sent in February 2023, during the time Russia was under restrictive measures and its messages were being checked before being sent. We can't say for sure whether the message was delivered, but based on the source of the data, the whistleblower believes that it was.</p><p>When the BBC showed Aramyan a copy of the message, he said he was shocked but not surprised.</p><p>"I don't think they expected that Germany [would] send them my address, my phone number, and extradite me, but if they could at least get some sort of tiny bits of information it would still be valuable for them."</p><p>The leak contains other messages in which a foreign law enforcement agency responds to Moscow's request for information. It sent details about the movements of an ally of Navalny, Lyubov Sobol, and high-profile defector Gleb Karakulov. The exchange relating to Karakulov happened after Interpol announced its additional vetting of Moscow.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260113-125315-2e65791d43-web-2.37.1-4/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/5adf/live/ea789370-f853-11f0-b5f7-49f0357294ff.jpg.webp" loading="lazy" alt="Sputnik/Mikhail Metzel/Pool via REUTERS Vladimir Putin and Maria Lvova-Belova sit on opposite sides of a desk. He is on the left, looking at her as she speaks. He is wearing a dark suit and tie, she is wearing a white dress. There is a Russian flag in the background. "><span>Sputnik/Mikhail Metzel/Pool via REUTERS</span></p></div><p data-component="caption-block"><figcaption>One report says Russia requested red diffusions on ICC judges - this came after the court issued arrest warrants for Vladimir Putin and Russia's commissioner for children's rights, Maria Lvova-Belova, over Ukraine</figcaption></p></figure><div data-component="text-block"><p>The BBC also gained access to internal Interpol reports from 2024 and 2025 which show ongoing concern around Russia's activities from senior directors within the organisation.</p><p>In one, a senior figure expresses directly to Russian delegates "serious concerns" about the country's "wilful misuse" of Interpol systems, stating that there were instances of "flagrant violations" of Interpol rules.</p><p>Despite the extra restrictions on Russia, the reports show that approximately 90% of Russia's requests were still passing initial checks in 2024. And yet, in the same period, the CCF was overturning roughly half of all Russian requests that it received complaints about. This raises questions about whether the measures had been stringent enough.</p><p>One report describes how in 2024 Russia attempted to place red diffusions on judges and a prosecutor at the International Criminal Court, after the body issued arrest warrants for President Vladimir Putin and another government official for their actions in Ukraine. These requests from Moscow were rejected.</p><p>Even while concerns about Russia's misuse of Interpol's systems were being expressed inside the organisation, the reports also show that discussions were taking place in 2024 and 2025 about whether to remove additional restrictions on Russian activity.</p><p>This seems to have been settled in Moscow's favour. The whistleblower told the BBC that in 2025 Interpol quietly dropped some extra measures against Russia — it is not clear how far this softening may have gone. Despite repeated requests, Interpol said it was not able to comment due to its "strict rules on the processing of data".</p><p>The BBC was unable to disclose all the details of the leak to Interpol as doing so could reveal the source. However, when asked about the issues raised in the investigation, Interpol said it was "concerned that a number of the accusations seems to come from a misunderstanding of how Interpol and CCF systems work, or factual errors about data and changes within Interpol's systems".</p><p>"It is untrue to say that we prioritise police co-operation over preventing abuse – Interpol follows its constitution that expressly forbids the use of our systems on information that is of a predominantly political, military, religious or racial character."</p><p>And in the past, it has said it can do more good to prevent crimes by ensuring that lines of communication remain open.</p><p>We asked Russia's ministry of internal affairs for comment, but it did not respond.</p><p>Lawyers Yuriy Nemets and Ben Keith agree that Interpol should do more to prevent misuse of its systems. "If countries are found to be significantly and persistently abusing red notices and diffusions, then they should be suspended from the system for a period of time," says Keith.</p><p>Otherwise, Igor Pestrikov fears that Russia, "with the push of a button, can enter anything, pin any crime on you - this lets them persecute you further around the world".</p><p><i id="additional-reporting:-andreea-jitaru-and-ned-davies"><b id="additional-reporting:-andreea-jitaru-and-ned-davies">Additional reporting: Andreea Jitaru and Ned Davies</b></i></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France passes bill to ban social media use by under-15s (113 pts)]]></title>
            <link>https://www.rte.ie/news/europe/2026/0127/1555251-france-social-media-ban/</link>
            <guid>46776272</guid>
            <pubDate>Tue, 27 Jan 2026 06:38:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rte.ie/news/europe/2026/0127/1555251-france-social-media-ban/">https://www.rte.ie/news/europe/2026/0127/1555251-france-social-media-ban/</a>, See on <a href="https://news.ycombinator.com/item?id=46776272">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="articleBody" data-epic-field="content">
                        <p>French politicians have passed a bill that will ban social media use by under-15s, a move championed by President Emmanuel Macron as a way to protect children from excessive screen time.</p>
<p>The lower National Assembly adopted the text by a vote of 130 to 21 in a lengthy session that started yesterday.</p>
<p>It will now go to the Senate, France's upper house, ahead of becoming law.</p>
<p>Mr Macron hailed the vote as a "major step" to protect French children and teenagers in a post on X.</p>
<p>The legislation, which also provides for a ban on mobile phones in high schools, would make France the second country to take such a step following Australia's ban for under-16s in December<a href="https://www.rte.ie/news/world/2025/1209/1547984-australia-social-media-ban/" target="_blank">.</a></p>
<p>As social media has grown, so has concern that too much screen time is harming child development and contributing to mental health problems.</p>
<p>"The emotions of our children and teenagers are not for sale or to be manipulated, either by American platforms or Chinese algorithms," Mr Macron said in a video broadcast on Saturday.</p>
<figure><img alt="" src="https://www.rte.ie/images/00204d61-614.jpg?ratio=1.78">
<figcaption>The draft bill excludes online encyclopedias and educational platforms</figcaption>
</figure>
<p>Authorities want the measures to be enforced from the start of the 2026 school year for new accounts.</p>
<p>Former prime minister Gabriel Attal, who leads Mr Macron's Renaissance party in the lower house, said he hoped the Senate would pass the bill by mid-February so that the ban could come into force on 1 September.</p>
<p>He added that "social media platforms will then have until 31 December to deactivate existing accounts" that do not comply with the age limit.</p>
<p>In addition to combatting the impact of screens and social media on the mental health of young adolescents, Mr Attal stressed the measure would counter "a number of powers that, through social media platforms, want to colonise minds".</p>
<p>"France can be a pioneer in Europe in a month: we can change the lives of our young people and our families, and perhaps also change the destiny of our country in terms of independence," he said.</p>
<p>France's public health watchdog ANSES said this month that social media such as TikTok, Snapchat and Instagram had several detrimental effects on adolescents, particularly girls, though it was not the sole reason for their declining mental health.</p>
<p>The risks listed include cyberbullying and exposure to violent content.</p>
<p>The legislation stipulates that "access to an online social networking service provided by an online platform is prohibited for minors under the age of 15".</p>
<p>The draft bill excludes online encyclopedias and educational platforms.</p>
<p>An effective age verification system would have to come into force for the ban to become reality.</p>
<p>Work on such a system is under way at the European level.</p>
<figure><img alt="" src="https://www.rte.ie/images/002240cf-614.jpg?ratio=1.78">
<figcaption>President Emmanuel Macron has backed a ban on pupils having mobile phones in high schools</figcaption>
</figure>
<p>Arnaud Saint-Martin, of the left-wing France Unbowed party, criticised the ban as "a form of digital paternalism" and an "overly simplistic" response to the negative impacts of technology.</p>
<p>Yesterday, nine child protection associations urged politicians to "hold platforms accountable", not "ban" children from social media.</p>
<p>Mr Macron has also backed a ban on pupils having mobile phones in high schools.</p>
<p>In 2018, France banned children from using mobile phones in colleges, the schools attended between the ages of 11 and 15.</p>
<p>Former prime minister Elisabeth Borne expressed reservations about the measure.</p>
<p>"It's more complicated than that," she told broadcaster France 2.</p>
<p>"We first need to make sure that the ban is properly enforced in middle schools," she added.</p>
<hr>
<p><b>Read more: <a href="https://www.rte.ie/news/analysis-and-comment/2025/1210/1548152-social-media-ireland-ban/" target="_blank">Would an Australia-style social media ban for children work in Ireland?</a></b></p>
<hr>
<p><a href="https://www.rte.ie/news/world/2025/1209/1547984-australia-social-media-ban/" target="_blank">In December, Australia became the first country to implement a minimum age for social media use</a>, with platforms like Instagram, TikTok and YouTube forced to block more than a million accounts.</p>
<p>It required ten of the biggest platforms to block Australians aged under 16 or be fined up to A$49.5 million (€28 million).</p>
<p>The law received criticism from major technology companies and free speech advocates, but was praised by parents and child advocates.</p>
                    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kimi Released Kimi K2.5, Open-Source Visual SOTA-Agentic Model (345 pts)]]></title>
            <link>https://www.kimi.com/blog/kimi-k2-5.html</link>
            <guid>46775961</guid>
            <pubDate>Tue, 27 Jan 2026 05:42:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kimi.com/blog/kimi-k2-5.html">https://www.kimi.com/blog/kimi-k2-5.html</a>, See on <a href="https://news.ycombinator.com/item?id=46775961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-40f5842c="" id="app"><p>Today, we are introducing Kimi K2.5, the most powerful open-source model to date.</p><p>Kimi K2.5 builds on Kimi K2 with continued pretraining over approximately 15T mixed visual and text tokens. Built as a native multimodal model, K2.5 delivers state-of-the-art <strong>coding and vision</strong> capabilities and a self-directed <strong>agent swarm</strong> paradigm.</p><p>For complex tasks, Kimi K2.5 can self-direct an <strong>agent swarm</strong> with up to 100 sub-agents, executing parallel workflows across up to <strong>1,500</strong> <strong>tool calls</strong>. Compared with a single-agent setup, this reduces execution time by up to <strong>4.5x</strong>. The agent swarm is automatically created and orchestrated by Kimi K2.5 without any predefined subagents or workflow.</p><p>Kimi K2.5 is available via <strong><a href="https://www.kimi.com/" target="_blank" rel="noreferrer">Kimi.com</a>, the Kimi App, the <a href="https://platform.moonshot.ai/" target="_blank" rel="noreferrer">API</a>, and <a href="http://www.kimi.com/code" target="_blank" rel="noreferrer">Kimi Code</a></strong>. Kimi.com &amp; Kimi App now supports 4 modes: K2.5 Instant, K2.5 Thinking, K2.5 Agent, and K2.5 Agent Swarm (Beta). Agent Swarm is currently in beta on Kimi.com, with free credits available for high-tier paid users.</p><!----><p><img src="https://statics.moonshot.cn/blogs/k2-5/token_cost.png"></p><blockquote><p>Across three agentic benchmarks—HLE, BrowseComp, and SWE-Verified—Kimi K2.5 delivers strong performance at a fraction of the cost.</p></blockquote><h3 id="_1-coding-with-vision" tabindex="-1">1. Coding with Vision <a href="#_1-coding-with-vision" aria-label="Permalink to &quot;1. Coding with Vision&quot;">​</a></h3><p>Kimi K2.5 is the strongest open-source model to date for coding, with particularly strong capabilities in front-end development.</p><p>K2.5 can turn simple conversations into complete front-end interfaces, implementing <strong>interactive layouts</strong> and <strong>rich animations such as scroll-triggered effects</strong>. Below are examples generated by K2.5 from a single prompt with image-gen tool:</p><!----><p>Beyond text prompts, K2.5 excels at <strong>coding with vision</strong>. By reasoning over images and video, K2.5 improves image/video-to-code generation and visual debugging, lowering the barrier for users to express intent visually.</p><p>Here is an example of K2.5 reconstructing a website from video:</p><!----><p>This capability stems from massive-scale vision-text joint pre-training. At scale, the trade-off between vision and text capabilities disappears — they improve in unison.</p><p>Below is an example of K2.5 reasoning over a puzzle and marking the shortest path using code:</p><!----><p><strong>K2.5 excels in real-world software engineering tasks.</strong> We evaluate it using <strong>Kimi Code Bench</strong>, our <strong>internal coding benchmark</strong> covering diverse end-to-end tasks — from building to debugging, refactoring, testing, and scripting — across multiple programming languages. On this benchmark, <strong>K2.5 shows consistent and meaningful improvements over</strong> <strong>K2</strong> <strong>across task types</strong>.</p><p><img src="https://statics.moonshot.cn/blogs/k2-5/img_v3_02ub_47858019-34ce-4e34-ae76-f7165f95b91g.png"></p><p>To try out K2.5's agentic coding capabilities, <strong><a href="http://kimi.com/agent" target="_blank" rel="noreferrer">K2.5 Agent</a></strong> offers a set of preconfigured tools for immediate, hands-on experiences. For software engineering use cases, we recommend pairing Kimi K2.5 with our new coding product, <strong><a href="https://www.kimi.com/code" target="_blank" rel="noreferrer">Kimi Code</a></strong>.</p><p><strong><a href="https://www.kimi.com/code" target="_blank" rel="noreferrer">Kimi Code</a></strong> works in your terminal and can be integrated with various IDEs including VSCode, Cursor, Zed, etc. Kimi Code is open-sourced and supports images and videos as inputs. It also automatically discovers and migrates existing skills and MCPs into your working environment in Kimi Code.</p><p>Here's an example using <strong><a href="https://www.kimi.com/code" target="_blank" rel="noreferrer">Kimi Code</a></strong> to translate the aesthetic of <em>Matisse's La Danse</em> into the Kimi App. This demo highlights a breakthrough in <strong>autonomous visual debugging</strong>. Using visual inputs and documentation lookup, K2.5 visually inspects its own output and iterates on it autonomously. It creates an art-inspired webpage created end to end:</p><!----><h3 id="_2-agent-swarm" tabindex="-1">2. Agent Swarm <a href="#_2-agent-swarm" aria-label="Permalink to &quot;2. Agent Swarm&quot;">​</a></h3><p><strong>Scaling Out, Not Just Up.</strong> We release <strong><a href="http://kimi.com/agent-swarm" target="_blank" rel="noreferrer">K2.5 Agent Swarm</a></strong> as a research preview, marking a shift from single-agent scaling to self-directed, coordinated swarm-like execution.</p><p>Trained with Parallel-Agent Reinforcement Learning (PARL), K2.5 learns to self-direct an <strong>agent swarm</strong> of up to <strong>100 sub-agents</strong>, executing parallel workflows across <strong>up to 1,500 coordinated steps,</strong> without predefined roles or hand-crafted workflows.</p><p>PARL uses a <em><strong>trainable orchestrator agent</strong></em> to decompose tasks into parallelizable subtasks, each executed by dynamically instantiated, <em><strong>frozen subagents</strong></em>. Running these subtasks concurrently significantly reduces end-to-end latency compared to sequential agent execution.</p><p>Training a reliable parallel orchestrator is challenging due to delayed, sparse, and non-stationary feedback from independently running subagents. A common failure mode is <strong>serial collapse</strong>, where the orchestrator defaults to single-agent execution despite having parallel capacity. To address this, PARL employs <em>staged reward shaping</em> that encourages parallelism early in training and gradually shifts focus toward task success.</p><p>We define the reward as</p><mjx-container tabindex="0" jax="SVG" display="true"><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>R</mi><mi>t</mi></msub><mo>=</mo><msub><mi>λ</mi><mrow data-mjx-texclass="ORD"><mtext>aux</mtext></mrow></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo><mo>⋅</mo><munder><mrow data-mjx-texclass="OP"><munder><msub><mi>r</mi><mrow data-mjx-texclass="ORD"><mtext>parallel</mtext></mrow></msub><mo>⏟</mo></munder></mrow><mrow data-mjx-texclass="ORD"><mtext>instantiation reward</mtext></mrow></munder><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>λ</mi><mrow data-mjx-texclass="ORD"><mtext>aux</mtext></mrow></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>⋅</mo><munder><mrow data-mjx-texclass="OP"><munder><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">I</mi></mrow><mo stretchy="false">[</mo><mtext>success</mtext><mo stretchy="false">]</mo><mo>⋅</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>⏟</mo></munder></mrow><mrow data-mjx-texclass="ORD"><mtext>task-level outcome</mtext></mrow></munder></math></mjx-assistive-mml></mjx-container><p>where <mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>λ</mi><mrow data-mjx-texclass="ORD"><mtext>aux</mtext></mrow></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> anneals from <mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0.1</mn><mo accent="false" stretchy="false">→</mo><mn>0.0</mn></math></mjx-assistive-mml></mjx-container> over training. Early on, the auxiliary reward <mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow data-mjx-texclass="ORD"><mtext>parallel</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container> incentivizes subagent instantiation and concurrent execution, promoting exploration of the parallel scheduling space. As training progresses, optimization shifts toward end-to-end task quality <mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Q</mi><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> , preventing degenerate solutions where parallelism is enabled in name only.</p><p>To further force parallel strategies to emerge, we introduce a computational bottleneck that makes sequential execution impractical. Instead of counting total steps, we evaluate performance using <strong>Critical Steps</strong>, a latency-oriented metric inspired by the critical path in parallel computation:</p><mjx-container tabindex="0" jax="SVG" display="true"><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>CriticalSteps</mtext><mo>=</mo><munderover><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow data-mjx-texclass="ORD"><mi>T</mi></mrow></munderover><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msubsup><mi>S</mi><mrow data-mjx-texclass="ORD"><mtext>main</mtext></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>+</mo><munder><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></munder><msubsup><mi>S</mi><mrow data-mjx-texclass="ORD"><mtext>sub</mtext><mo>,</mo><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container><p><mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>S</mi><mrow data-mjx-texclass="ORD"><mtext>main</mtext></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup></math></mjx-assistive-mml></mjx-container>captures orchestration overhead, while <mjx-container jax="SVG"><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></munder><msubsup><mi>S</mi><mrow data-mjx-texclass="ORD"><mtext>sub</mtext><mo>,</mo><mi>i</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msubsup></math></mjx-assistive-mml></mjx-container> reflects the slowest subagent at each stage. Under this metric, spawning more subtasks only helps if it shortens the critical path.</p><p><img src="https://statics.moonshot.cn/blogs/k2-5/orchestrator-1.png" alt="img"></p><blockquote><p>An agent swarm has an orchestrator that dynamically creates specialized subagents (e.g., AI Researcher, Physics Researcher, Fact Checker) and decomposes complex tasks into parallelizable subtasks for efficient distributed execution.</p></blockquote><p><img src="https://statics.moonshot.cn/blogs/k2-5/20260126-225846.png" alt="img"></p><blockquote><p>In our parallel-agent reinforcement learning environment, the reward increases smoothly as training progresses. At the same time, the level of parallelism during training also gradually increases.</p></blockquote><p><strong><a href="http://kimi.com/agent-swarm" target="_blank" rel="noreferrer">K2.5 Agent Swarm</a></strong> <strong>improves performance on complex tasks through parallel, specialized execution.</strong> In our internal evaluations, it leads to an <strong>80%</strong> <strong>reduction in end-to-end runtime</strong> while enabling more complex, long-horizon workloads, as shown below.</p><p><img src="https://statics.moonshot.cn/blogs/k2-5/20260127-131347.jpeg" alt=""></p><p><img src="https://statics.moonshot.cn/blogs/k2-5/complpexity_of_tasks.png" alt=""></p><blockquote><p>Agent Swarm reduces the minimum critical steps required to achieve target performance by 3×–4.5× compared to single-agent execution in wide search scenario, with savings scaling as targets rise—translating to up to 4.5× wall-clock time reduction via parallelization.</p></blockquote><p>Here are representative <strong>trajectories</strong> demonstrating <a href="http://kimi.com/agent-swarm" target="_blank" rel="noreferrer">K2.5 Agent Swarm</a> in action:</p><!----><h3 id="_3-office-productivity" tabindex="-1">3. Office Productivity <a href="#_3-office-productivity" aria-label="Permalink to &quot;3. Office Productivity&quot;">​</a></h3><p>Kimi K2.5 brings agentic intelligence into <strong>real-world knowledge work.</strong></p><p><strong><a href="http://kimi.com/agent" target="_blank" rel="noreferrer">K2.5 Agent</a></strong> can <strong>handle high-density, large-scale office work end to end.</strong> It reasons over large, high-density inputs, coordinates multi-step tool use, and delivers expert-level outputs: documents, spreadsheets, PDFs, and slide decks—directly through conversation.</p><p>With a focus on real-world professional tasks, we design <strong>two internal expert productivity benchmarks</strong>. The <strong>AI Office Benchmark</strong> evaluates end-to-end Office output quality, while the <strong>General</strong> <strong>Agent Benchmark</strong> measures multi-step, production-grade workflows against human expert performance. Across both benchmarks, <strong>K2.5 shows</strong> <strong>59.3% and 24.3% improvements over K2 Thinking</strong>, reflecting stronger end-to-end performance on real-world tasks.</p><p><img src="https://statics.moonshot.cn/blog/k2-5/20260127-152311.png" alt="img"></p><p><strong>Internal Expert Productivity Bench (AI Office)</strong></p><p>K2.5 agent supports advanced tasks such as <strong>adding annotations in Word, constructing financial models with Pivot Tables, and writing LaTeX equations in PDFs</strong>, while scaling to long-form outputs like <strong>10,000-word papers or 100-page documents</strong>.</p><p>Tasks that once took hours or days now complete in minutes. Here are some examples:</p><!----><h3 id="_4-conclusion" tabindex="-1">4. Conclusion <a href="#_4-conclusion" aria-label="Permalink to &quot;4. Conclusion&quot;">​</a></h3><p>Grounded in advances in coding with vision, agent swarms, and office productivity, Kimi K2.5 represents a meaningful step toward AGI for the open-source community, demonstrating strong capability on real-world tasks under real-world constraints. Looking ahead, we will push further into the frontier of agentic intelligence, redefining the boundaries of AI in knowledge work.</p><h3 id="appendix" tabindex="-1">Appendix <a href="#appendix" aria-label="Permalink to &quot;Appendix&quot;">​</a></h3><h4 id="benchmark-table" tabindex="-1">Benchmark table <a href="#benchmark-table" aria-label="Permalink to &quot;Benchmark table&quot;">​</a></h4><!----><p>To reproduce official <strong>Kimi-K2.5</strong> benchmark results, we recommend using the <a href="https://platform.moonshot.ai/" target="_blank" rel="noreferrer">official API</a>. For third-party providers, refer to <strong>Kimi Vendor Verifier (KVV)</strong> to choose high-accuracy services. Details: <a href="https://kimi.com/blog/kimi-vendor-verifier.html" target="_blank" rel="noreferrer">https://kimi.com/blog/kimi-vendor-verifier.html</a></p><h3 id="footnotes" tabindex="-1">Footnotes <a href="#footnotes" aria-label="Permalink to &quot;Footnotes&quot;">​</a></h3><p><strong>1. General Testing Details</strong></p><ul><li>We report results for Kimi K2.5 and DeepSeek-V3.2 with thinking mode enabled, Claude Opus 4.5 with extended thinking mode, GPT-5.2 with xhigh reasoning effort, and Gemini 3 Pro with a high thinking level. For vision benchmarks, we additionally report results for Qwen3-VL-235B-A22B-Thinking.</li><li>Unless otherwise specified, all Kimi K2.5 experiments were conducted with temperature = 1.0, top-p = 0.95, and a context length of 256k tokens.</li><li>Benchmarks without publicly available scores were re-evaluated under the same conditions used for Kimi K2.5 and are marked with an asterisk (*).</li><li>We could not evaluate GPT-5.2 xhigh on all benchmarks due to service stability issues. For benchmarks that were not tested, we mark them as "-".</li></ul><p><strong>2.</strong> <strong>Text and Reasoning</strong></p><ul><li>HLE, AIME 2025, HMMT 2025 (Feb), GPQA-Diamond and IMO-AnswerBench were evaluated with a maximum completion budget of 96k tokens.</li><li>Results for AIME and HMMT are averaged over 32 runs (avg@32); GPQA-Diamond over 8 runs (avg@8).</li><li>For HLE, we report scores on the full set (text &amp; image). Kimi K2.5 scores 31.5 (text) and 21.3 (image) without tools, and 51.8 (text) and 39.8 (image) with tools. The DeepSeek-V3.2 score corresponds to its text-only subset (marked with †) . Hugging Face access was blocked to prevent potential data leakage. HLE with tools uses simple context management: once the context exceeds a threshold, only the latest round of tool messages is retained.</li></ul><p><strong>3.</strong> <strong>Tool-Augmented / Agentic Search</strong></p><ul><li>Kimi K2.5 was equipped with search, code-interpreter, and web-browsing tools for HLE with tools and all agentic search benchmarks.</li><li>Except for BrowseComp (where K2.5 and DeepSeek-V3.2 used the discard-all strategy), no context management was applied, and tasks exceeding the supported context length were directly counted as failed.</li><li>The test system prompts emphasize deep and proactive tool use, instructing models to reason carefully, leverage tools, and verify uncertain information. Full prompts will be provided in the technical report.</li><li>Results for Seal-0 and WideSearch are averaged over four runs (avg@4).</li></ul><p><strong>4.</strong> <strong>Vision Benchmarks</strong></p><ul><li>Max-tokens = 64k, averaged over three runs (avg@3).</li><li>ZeroBench (w/ tools) uses max-tokens-per-step = 24k and max-steps = 30 for multi-step reasoning.</li><li>MMMU-Pro follows the official protocol, preserving input order and prepending images.</li><li>GPT-5.2-xhigh had ~10% failure rate (no output despite 3 retries), treated as incorrect; reported scores likely underestimate true performance.</li><li>WorldVQA, a benchmark designed to evaluate atomic vision-centric world knowledge. Access WorldVQA at <a href="https://github.com/MoonshotAI/WorldVQA" target="_blank" rel="noreferrer">https://github.com/MoonshotAI/WorldVQA</a>.</li><li>OmniDocBench Score is computed as (1 − normalized Levenshtein distance) × 100, where a higher score denotes superior accuracy.</li></ul><p><strong>5.</strong> <strong>Coding Tasks</strong></p><ul><li>Terminal-Bench 2.0 scores were obtained with the default agent framework (Terminus-2) and the provided JSON parser. In our implementation, we evaluated Terminal-Bench 2.0 under non-thinking mode. This choice was made because our current context management strategy for the thinking mode is incompatible with Terminus-2.</li><li>For the SWE-Bench series of evaluations (including verified, multilingual, and pro), we used an internally developed evaluation framework. This framework includes a minimal set of tools—bash tool, createfile tool, insert tool, view tool, strreplace tool, and submit tool—along with tailored system prompts designed for the tasks. The highest scores were achieved under non-thinking mode.</li><li>The score of Claude Opus 4.5 on CyberGym is reported under the non-thinking setting.</li><li>All reported scores of coding tasks are averaged over 5 independent runs.</li></ul><p><strong>6.</strong> <strong>Long-Context Benchmarks</strong></p><ul><li>AA-LCR: scores averaged over three runs (avg@3).</li><li>LongBench-V2: identical prompts and input contexts standardized to ~128k tokens.</li></ul><p><strong>7.</strong> <strong>Agent Swarm</strong></p><ul><li>BrowseComp (Swarm Mode): main agent max 15 steps; sub-agents max 100 steps.</li><li>WideSearch (Swarm Mode): main and sub-agents max 100 steps.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A list of fun destinations for telnet (210 pts)]]></title>
            <link>https://telnet.org/htm/places.htm</link>
            <guid>46775135</guid>
            <pubDate>Tue, 27 Jan 2026 03:24:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://telnet.org/htm/places.htm">https://telnet.org/htm/places.htm</a>, See on <a href="https://news.ycombinator.com/item?id=46775135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <h2 id="overview">Overview</h2>
<p>The text based internet can be exciting, informative, and fun. Using telnet, 
you can access a variety of these resources on the internet. Below you’ll find 
lists of a few places to get you started.</p>
<p>If you have an interesting item to add, just send an email to us:</p>
<ul>
<li><a href="mailto:webmaster@telnet.org">webmaster@telnet.org</a>.</li>
</ul>
<h2 id="various-fun-telnet-servers">Various fun telnet servers</h2>
<ul>
<li>
<p><a href="telnet://india.colorado.edu:13">india.colorado.edu 13</a><br>
  Get the current time</p>
</li>
<li>
<p><a href="telnet://mapscii.me">mapscii.me</a><br>
  A Telnet interface to a Braille/ASCII map renderer (<a href="http://mapscii.me/">code and info</a>)</p>
</li>
<li>
<p><a href="telnet://horizons.jpl.nasa.gov:6775">horizons.jpl.nasa.gov 6775</a><br>
  NASA JPL HORIZONS solar system data (<a href="https://ssd.jpl.nasa.gov/?horizons">website for more details</a>)</p>
</li>
<li>
<p><a href="telnet://telehack.com">telehack.com 23</a><br>
  Telehack. Also play via the <a href="http://telehack.com/">website</a></p>
</li>
<li>
<p><a href="telnet://doom.w-graj.net:666">doom.w-graj.net 666</a><br>
  Play Doom in the terminal (<a href="https://github.com/wojciech-graj/doom-ascii">code and details</a>)</p>
</li>
<li>
<p><a href="telnet://freechess.org:5000">freechess.org 5000</a><br>
  Free Internet Chess Server aka freechess.org</p>
</li>
<li>
<p><a href="telnet://ticker.bitcointicker.co:10080">ticker.bitcointicker.co 10080</a><br>
  The live price of bitcoin</p>
</li>
<li>
<p><a href="telnet://1984.ws:23">1984.ws 23</a><br>
  Edison Carter is…</p>
</li>
<li>
<p><a href="telnet://telnet.wiki.gd">telnet.wiki.gd</a><br>
  Telnet Live Wikipedia with AI assistant (<a href="https://meta.wikimedia.org/wiki/Telnet_gateway">more info</a>, <a href="https://github.com/ballerburg9005/wikipedia-live-telnet">code</a>)</p>
</li>
</ul>
<h2 id="notable,-but-no-longer-online-:(">Notable, but no longer online :(</h2>
<ul>
<li>
<p><a href="telnet://towel.blinkenlights.nl:23">towel.blinkenlights.nl 23</a><br>
  Star Wars asciimation</p>
</li>
<li>
<p><a href="telnet://towel.blinkenlights.nl:666">towel.blinkenlights.nl 666</a><br>
  The Bofh Excuse Server</p>
</li>
</ul>
<p>Real classics. I especially miss the Bofh server.</p>
<ul>
<li><a href="telnet://rainmaker.wunderground.com:3000">rainmaker.wunderground.com 3000</a><br>
  weather via telnet!</li>
</ul>
<p>Rainmaker was pretty great, and it lasted at least as far as 2018. I don’t recall
what happened to it.</p>
<ul>
<li><a href="telnet://nyancat.dakko.us">nyancat.dakko.us</a><br>
  ANSI art animation of “poptart cat”, with support for many different terminals (<a href="https://nyancat.dakko.us/">cool screenshots!</a>)</li>
</ul>
<p>The telnet server is offline, but the website is still up for this one!</p>
<ul>
<li><a href="telnet://mtrek.com:1701">mtrek.com:1701</a><br>
  mtrek (star trek themed game)</li>
<li><a href="telnet://xmltrek.com:1701">xmltrek.com:1701</a><br>
  xmltrek (star trek themed game)</li>
</ul>
<p>Both are offline at the time of this update.</p>
<h2 id="muds,-talkers,-bbs,-and-other-systems">Muds, Talkers, BBS, and other systems</h2>
<ul>
<li><a href="telnet://bbs.archaicbinary.net:23">bbs.archaicbinary.net</a><br>
  Archaic Binary</li>
<li><a href="telnet://ateraan.com:4002">ateraan.com 4002</a><br>
  New Worlds - Ateraan</li>
<li><a href="telnet://avalon-rpg.com:23">avalon-rpg.com 23</a><br>
  Avalon: The Legend Lives</li>
<li><a href="telnet://aarmud.org:4000">aardmud.org 4000</a><br>
  Aardwolf MUD</li>
<li><a href="telnet://bbs.armageddonbbs.com:23">bbs.armageddonbbs.com 23</a><br>
  <a href="http://www.armageddonbbs.com/">Armageddon BBS</a></li>
<li><a href="telnet://52.88.68.92:1234">52.88.68.92 1234</a><br>
  Cuban Bar</li>
<li><a href="telnet://TextMMOde.com:23">TextMMOde.com 23</a><br>
  Sands of Time / Deep Space MMO</li>
<li><a href="telnet://legendofthereddragon.ca">legendofthereddragon.ca 23</a><br>
  <a href="http://www.legendofthereddragon.ca/">Legend of the Red Dragon (Canada)</a></li>
<li><a href="telnet://lord.stabs.org:23">lord.stabs.org 23</a><br>
  <a href="http://lord.stabs.org/">Legend of the Red Dragon</a></li>
<li><a href="telnet://thehatshop.mudhosting.net:3000">thehatshop.mudhosting.net 3000</a><br>
  Hallowed Halls</li>
<li><a href="telnet://eclipse.cs.pdx.edu:7680">eclipse.cs.pdx.edu 7680</a><br>
  New Moon</li>
<li><a href="telnet://batmud.bat.org:23">batmud.bat.org 23</a><br>
  BatMUD</li>
<li><a href="telnet://forgottenkingdoms.org:4000">forgottenkingdoms.org 4000</a><br>
  Forgotten Kingdoms</li>
<li><a href="telnet://mush.shelteringcolorado.com:2601">mush.shelteringcolorado.com 2601</a><br>
  Sheltering Sky: Colorado by Night</li>
<li><a href="telnet://igormud.org:1701">igormud.org 1701</a><br>
  Igor MUD/</li>
<li><a href="telnet://zombiemud.org:23">zombiemud.org 23</a><br>
  Zombie MUD</li>
<li><a href="telnet://achaea.com:23">achaea.com 23</a><br>
  Achaea, Dreams of Divine Lands</li>
<li><a href="telnet://gcomm.com">gcomm.com 23</a><br>
  Galacticomm BBS</li>
</ul>
<h2 id="directories">Directories</h2>
<ul>
<li>
<p><a href="http://telnetbbsguide.com/">http://telnetbbsguide.com</a><br>
  A large active listing of Dial-Up and Telnet accessible Bulletin Board Systems on the Internet:  </p>
</li>
<li>
<p><a href="http://vintagebbs.org/bbsLookup.php">http://vintagebbs.org/bbsLookup.php</a><br>
  A bbs directory with location based searching:  </p>
</li>
<li>
<p><a href="http://www.jumpjet.info/Offbeat-Internet/Public/TelNet/url.htm">http://www.jumpjet.info/Offbeat-Internet/Public/TelNet/url.htm</a><br>
  Jumpjet has a nice list of telnet locations organized by category:  </p>
</li>
<li>
<p><a href="http://synchro.net/sbbslist.html">http://synchro.net/sbbslist.html</a><br>
  Synchronet is a nice list of bbs systems:  </p>
</li>
<li>
<p><a href="http://www.mudconnect.com/">http://www.mudconnect.com/</a><br>
  Mudconnect keeps a good list of muds and moos:  </p>
</li>
<li>
<p><a href="http://www.lights.ca/hytelnet/">http://www.lights.ca/hytelnet/</a><br>
  Hytelnet is an old (an now unmaintained) directory:</p>
</li>
</ul>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone 5s Gets New Software Update 13 Years After Launch (142 pts)]]></title>
            <link>https://www.macrumors.com/2026/01/26/iphone-5s-software-update/</link>
            <guid>46774108</guid>
            <pubDate>Tue, 27 Jan 2026 01:04:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2026/01/26/iphone-5s-software-update/">https://www.macrumors.com/2026/01/26/iphone-5s-software-update/</a>, See on <a href="https://news.ycombinator.com/item?id=46774108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2026/01/26/iphone-5s-software-update/"><p><a href="https://www.macrumors.com/2026/01/26/apple-releases-ios-26-2-1/">Alongside iOS 26.2.1</a>, Apple today released an updated version of iOS 12 for devices that are still running that operating system update, eight years after the software was first released.</p>
<p><img src="https://images.macrumors.com/t/NCy_NxbrykgcQ3tTazTCXoT_BpU=/400x0/article-new/2024/05/iPhone-5s-16x9.jpeg?lossy" srcset="https://images.macrumors.com/t/NCy_NxbrykgcQ3tTazTCXoT_BpU=/400x0/article-new/2024/05/iPhone-5s-16x9.jpeg?lossy 400w,https://images.macrumors.com/t/qBbcFsUX3fkvT603wTmDDRtWAEY=/800x0/article-new/2024/05/iPhone-5s-16x9.jpeg?lossy 800w,https://images.macrumors.com/t/3r14tbDiNaSOURahFEgYgY8Di8M=/1600x0/article-new/2024/05/iPhone-5s-16x9.jpeg 1600w,https://images.macrumors.com/t/oULVsMz61-Wy2P9n9oICWpVfr2A=/2500x0/filters:no_upscale()/article-new/2024/05/iPhone-5s-16x9.jpeg 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="iPhone 5s" width="1280" height="720"><br>iOS 12.5.8 is available for the <a href="https://www.macrumors.com/guide/iphone/">iPhone</a> 5s and the ‌iPhone‌ 6, meaning Apple is continuing to support these devices for 13 and 12 years after launch, respectively. The ‌iPhone‌ 5s came out in September 2013, while the ‌iPhone‌ 6 launched in September 2014.</p>
<p>According to Apple's release notes for the update, iOS 12.5.8 extends the certificate required for features like iMessage, <a href="https://www.macrumors.com/guide/facetime/">FaceTime</a>, and device activation, so they will continue to work after January 2027.</p>
<p>Originally, certificate-limited functions like device activation would have ceased when the certificate expired, but now key features on the two older iPhones will continue to work in the years to come.</p>
<p>Prior to now, the ‌iPhone‌ 5s and ‌iPhone‌ 6 last received software updates in January 2023, when Apple released important security fixes.</p>
<p>Apple <a href="https://www.macrumors.com/2024/06/06/apple-iphone-security-updates-five-year-minimum/">has publicly committed</a> to providing a minimum of five years of security updates for an ‌iPhone‌ from the time that it launches, but it often offers vulnerability fixes for an even longer period of time.</p>
<p>The ‌iPhone‌ 6s, for example, was released 11 years ago, but it received a security update in September 2025 with the launch of iOS 15.8.5. The device received an iOS 15.8.6 update just today, adding the same certificate extension.</p>
<p>Apple also released new versions of iOS 18 and iOS 16.</p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2026/01/26/apple-announces-new-airtag/">Apple Unveils New AirTag With Longer Range, Louder Speaker, and More</a></h3><p>Apple today introduced the second-generation AirTag, with key features including longer range for tracking items and a louder speaker.
For those who are not familiar, the AirTag is a small accessory that you can attach to your backpack, keys, or other items. Then, you can track the location of those items in the Find My app on the iPhone, iPad, Mac, Apple Watch, and iCloud.com.
The new...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/25/macbook-pro-two-upgrades-in-2026-rumor/">Apple Reportedly Aiming to Upgrade the MacBook Pro Twice This Year</a></h3><p>Sunday January 25, 2026 11:46 am PST by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple plans to release new MacBook Pro, MacBook Air, Mac Studio, and Studio Display models in the first half of this year, according to Bloomberg's Mark Gurman.
In his Power On newsletter today, Gurman added that redesigned MacBook Pro models with an OLED touch screen "should be hitting toward the end of 2026," meaning that the MacBook Pro line would be upgraded twice this year.
First up...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/25/rumored-apple-products/">Apple to Launch These 20+ Products This Year</a></h3><p>2026 promises to be yet another busy year for Apple, with the company rumored to be planning more than 20 product announcements over the coming months.
Beyond the usual updates to iPhones, iPads, Macs, and Apple Watches, Apple is expected to release its all-new smart home hub, which was reportedly delayed until the more personalized version of Siri is ready. Other unique products rumored for ...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/26/apple-unveils-first-two-products-of-2026/">Apple Unveils First New Products of 2026</a></h3><p>Apple today introduced its first two physical products of 2026: a second-generation AirTag and the Black Unity Connection Braided Solo Loop for the Apple Watch.
Read our coverage of each announcement to learn more:Apple Unveils New AirTag With Longer Range, Louder Speaker, and More
Apple Introduces New Black Unity Apple Watch BandBoth the new AirTag and the Black Unity Connection Braided...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/23/what-to-expect-from-ios-26-4/">What to Expect From iOS 26.4</a></h3><p>Friday January 23, 2026 12:31 pm PST by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>iOS 26.3 is shaping up to be a relatively minor update, with only a couple of notable new features, but iOS 26.4 is expected to be much more significant.
We are still waiting for the iOS 26.3 Release Candidate to come out, so the first iOS 26.4 beta is likely still at least a few weeks away. Following beta testing, iOS 26.4 will likely be released to the general public at some point in March ...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Y Combinator website no longer lists Canada as a country it invests in (203 pts)]]></title>
            <link>https://betakit.com/y-combinator-website-no-longer-lists-canada-as-a-country-it-invests-in/</link>
            <guid>46773242</guid>
            <pubDate>Mon, 26 Jan 2026 23:32:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://betakit.com/y-combinator-website-no-longer-lists-canada-as-a-country-it-invests-in/">https://betakit.com/y-combinator-website-no-longer-lists-canada-as-a-country-it-invests-in/</a>, See on <a href="https://news.ycombinator.com/item?id=46773242">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Change implies Canadian startups have to incorporate in the US, Cayman Islands, or Singapore to join accelerator. </p><article>
                                    
<p>Y Combinator has revised its standard deal terms to exclude Canada as a permitted site of investment, implying that Canadian startups aspiring to join the prestigious San Francisco-based startup accelerator will have to incorporate their companies elsewhere.&nbsp;</p>



<p>As first reported by <a href="https://thelogic.co/news/exclusive/y-combinator-canada-startups/" target="_blank" rel="noopener nofollow" title=""><em>The Logic</em></a> Monday, Y Combinator’s standard deal terms webpage now says it invests in corporations based in the United States, the Cayman Islands, or Singapore. Canada was in that list as recently as Nov. 2, 2025, according to an archived version of the webpage, but the reference was removed by the end of that month. Dozens of <a href="https://betakit.com/opennote-raises-850000-usd-secures-y-combinator-spot-for-edtech-platform/" target="_blank" rel="noopener" title="">Canadian</a> <a href="https://betakit.com/team-of-toronto-talent-unites-after-y-combinator-to-build-clado/" target="_blank" rel="noopener" title="">companies</a> have been part of Y Combinator’s <a href="https://betakit.com/meet-the-y-combinator-winter-2024-cohort-startups-with-canadian-roots/" target="_blank" rel="noopener" title="">numerous</a> winter and summer cohorts since the first one was accepted in 2008.&nbsp;</p>



<p>The deal terms go on to state that if a startup is already incorporated in another country that is “not one of the three” (previously “four”) countries listed, the startup needs to “flip” its corporate structure to have a parent company in one of those three countries.</p>



<p>BetaKit has reached out to Y Combinator for comment.&nbsp;</p>



<p>The gravitational pull of Y Combinator’s program over Canadian startups has <a href="https://betakit.com/y-combinator-is-stealing-canadian-startups/" target="_blank" rel="noopener" title="">increased in recent years</a>, aided by remote policies instituted during the COVID-19 pandemic. In the 2010s, there were usually fewer than five Canadian-headquartered companies in a given Y Combinator cohort, according to data gathered last year by <a href="https://x.com/bram/status/1896999177256886726?s=20">Bram Sugarman</a>. Between winter 2020 and winter 2022, that number grew to range between nine and 15 startups in the program.&nbsp;</p>



<p><strong>RELATED: </strong><a href="https://betakit.com/y-combinator-is-stealing-canadian-startups/" target="_blank" rel="noopener" title=""><strong>Y Combinator is stealing Canadian startups</strong></a></p>



<p>It is common practice for Canadian founders to set up shop in the Valley, especially to participate in Y Combinator. Y Combinator CEO Garry Tan claimed in an X post last year that “The Canadians stay in the USA and raise more money. The ones that stay in SF after demo day become unicorns at 2.5X the rate.”</p>



<p>Tan <a href="https://x.com/garrytan/status/1897161477548896370?s=20" target="_blank" rel="noopener nofollow" title="">added</a> at the time that he was part of a YC dinner with many Canadian founders looking to base their startups in San Francisco after graduation.</p>



<p>One such company is Guelph, Ont.- and Irvine, Calif.-based edtech startup <a href="https://betakit.com/opennote-raises-850000-usd-secures-y-combinator-spot-for-edtech-platform/" target="_blank" rel="noopener" title="">Opennote</a>. A member of Y Combinator’s Summer 2025 batch, co-founder Vedant Vyas told BetaKit last July that the firm hoped to scale out of the Bay Area, citing support from US-based investors and an increased institutional willingness in the US to pilot new edtech solutions.</p>



<p>The pull was a topic of conversation at Toronto Tech Week’s <a href="https://betakit.com/canadian-tech-leaders-tell-the-next-generation-to-learn-to-say-no-at-homecoming/" target="_blank" rel="noopener" title="">Homecoming event</a> in June 2025, where Shopify president Harley Finkelstein, Wealthsimple founder Mike Katchen, and Cohere founder Aidan Gomez encouraged the crowd to say no to leaving Canada.</p>



<p>“It’s the Valley-or-bust mentality that breaks the ecosystem and really hurts Canada,” Gomez said.&nbsp;</p>



<p><em>Image courtesy of Paul Miller, licensed under <a href="https://creativecommons.org/licenses/by/2.0/?ref=openverse" target="_blank" rel="noopener nofollow" title="">CC BY 2.0</a>.</em></p>




                                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I let ChatGPT analyze a decade of my Apple Watch data, then I called my doctor (185 pts)]]></title>
            <link>https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip</link>
            <guid>46772495</guid>
            <pubDate>Mon, 26 Jan 2026 22:29:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip">https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip</a>, See on <a href="https://news.ycombinator.com/item?id=46772495">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[State of the Windows: What is going on with Windows 11? (126 pts)]]></title>
            <link>https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/</link>
            <guid>46772212</guid>
            <pubDate>Mon, 26 Jan 2026 22:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/">https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/</a>, See on <a href="https://news.ycombinator.com/item?id=46772212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Hi! Long time no see, huh? 🙂</p>



<p>It’s been three years since my last State of the Windows article, which was about the inconsistencies in the Windows 11 user experience. Since then, Microsoft (and the world as a whole to be quite honest) has gotten through a lot of changes, especially since the introduction of OpenAI’s ChatGPT, and in our case, most importantly, Microsoft Copilot.</p>



<p>Until a few years ago, Windows was Microsoft’s crown jewel (or as they said in the Windows 7 commercial, <strong>the heartbeat of Microsoft</strong>), an impressive operating system that had the purpose to be a common platform for all devices. However, since the launch of Windows 11, which at first had the purpose to somewhat modernize the look and feel of the OS, it seems that priorities have changed quite a bit.</p>



<p>Today we are going to talk about the perceived drop of quality in Windows, from fundamental issues like critical bugs and incidents from the last 3 years to how everything’s become a Copilot upsell funnel mechanism.</p>



<p>So, without further ado, let’s go!</p>



<p>First, let’s talk about the current, show-stopping errors that appeared with the latest January 2026 update, and how to fix them.</p>



<h2>1. PCs that wouldn’t shutdown – January 2026.</h2>



<p>This is one of the bugs that I’ve actually encountered a few days ago at work – people would come in saying that their PCs would either act unresponsive after shutting down (as in, they wouldn’t start up again the next day), or it would reboot immediately after shutting down.  </p>



<p>This issue was introduced with the January 2026 update, KB5073455&nbsp;and it is more prominent on newer platforms, especially Intel’s Meteor Lake and Arrow Lake.</p>



<p>Reportedly this issue is caused by the System Guard Secure Launch, a virtualization-based security component which, as the name implies, protects the boot process by using DRTM, or Dynamic Root of Trust for Measurement.</p>



<figure><img data-attachment-id="564" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-44/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png" data-orig-size="982,667" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=982" width="982" height="667" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=982" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png 982w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image.png?w=768 768w" sizes="(max-width: 982px) 100vw, 982px"></figure>



<p>More information about this technology can be found <a href="https://learn.microsoft.com/en-us/windows/security/hardware-security/how-hardware-based-root-of-trust-helps-protect-windows">here</a>.</p>



<p>Since last Patch Tuesday, Microsoft released a patch for this issue, <a href="https://www.catalog.update.microsoft.com/Search.aspx?q=KB5077797">KB5077797</a>, which seems to solve the issues. </p>



<p>As a temporary workaround, users can shutdown their PCs using the Command Prompt, by entering <em><strong>shutdown /s /t 0</strong>.</em> But this begs the question, why does the shutdown command work through this command which supposedly does the same thing, but not through the classic shutdown button?</p>



<h2>2. Outlook “classic” can’t open pst files – january 2026</h2>



<p>Once again, this month’s Patch Tuesday brought another major issue, which has the potential to affect one’s productivity in a big way. </p>



<p>If the KB5074109&nbsp;is installed, applications can become unresponsive when accessing PST files stored on cloud storage. To put it simply, if you have your mail archive saved on OneDrive or Dropbox and are still using the classic Win32 Outlook (and not the WebView based one) it’s possible that you can’t access the file, since the application would become unresponsive.</p>



<p>Also, users with Outlook POP account profiles and profiles with PST files report that Outlook hangs and does not exit properly.</p>



<p>Up until yesterday, the only fixes were to either <a href="https://support.microsoft.com/en-us/office/classic-outlook-profiles-with-pop-accounts-and-psts-hang-after-windows-updates-on-january-13-2026-590fe356-ecc2-49f4-b9e3-bd39fafa58f6#wl">uninstall the update or to “use webmail”</a>.  Their words, not mine.</p>



<figure><img data-attachment-id="567" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-45/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png" data-orig-size="844,430" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=844" width="844" height="430" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=844" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png 844w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-1.png?w=768 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>However, as of January 25th, Microsoft released the <a href="https://support.microsoft.com/help/5078132" target="_blank" rel="noreferrer noopener">KB5078132</a> update, which should fix the issue.</p>



<p>Some other issues with the latest update include:</p>



<p>Apps that wouldn’t load (including system ones like Notepad), crashing with the error 0x803f8001.</p>



<ol>
<li></li>
</ol>



<figure><img data-attachment-id="578" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-51/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png" data-orig-size="2204,1220" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=1024" loading="lazy" width="1024" height="566" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=2048 2048w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-7.png?w=1440 1440w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Unbootable volumes – the infamous 0x7f BSOD which means that it can’t mount the disk partition to continue booting.</p>



<ol>
<li></li>
</ol>



<p><strong>These are the most glaring issues that were introduced with the latest Windows update. </strong></p>



<h2>but as a whole, windows is a mess.</h2>



<p>Since the introduction of 24H2, Microsoft had a scandal related to Windows almost every month. </p>



<p>Some of the most critical ones include:</p>



<p>WinRE wouldn’t recognize keyboard and mouse input after the October 2025 update</p>



<ol>
<li></li>
</ol>



<figure><img data-attachment-id="570" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-46/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png" data-orig-size="1060,475" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=1024" loading="lazy" width="1024" height="458" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-2.png 1060w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Task Manager wouldn’t close completely if KB5067036 was installed, meaning that whenever one opened a new taskmgr window a new instance would be launched.</p>



<ol>
<li></li>
</ol>



<figure><img data-attachment-id="571" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-47/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png" data-orig-size="922,498" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=922" loading="lazy" width="922" height="498" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=922" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png 922w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-3.png?w=768 768w" sizes="(max-width: 922px) 100vw, 922px"></figure>



<p>RDP failures with 24H2/25H2 – once again, this is actually a critical issue that I’ve also encountered at work, and because of it we had to rollback a few PCs to 23H2 in order to have stable RDP connections.</p>



<figure><img data-attachment-id="573" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-48/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png" data-orig-size="918,420" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=918" loading="lazy" width="918" height="420" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=918" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png 918w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-4.png?w=768 768w" sizes="(max-width: 918px) 100vw, 918px"></figure>



<p>Various devices like DACs or webcams not working after installing updates.</p>



<figure><img data-attachment-id="575" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-49/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png" data-orig-size="978,300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=978" loading="lazy" width="978" height="300" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=978" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png 978w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-5.png?w=768 768w" sizes="(max-width: 978px) 100vw, 978px"></figure>



<p>DRM video issues with the September 2025 update</p>



<figure><img data-attachment-id="577" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-50/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png" data-orig-size="934,397" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=934" loading="lazy" width="934" height="397" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=934" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png 934w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-6.png?w=768 768w" sizes="(max-width: 934px) 100vw, 934px"></figure>



<ol>
<li></li>
</ol>



<p>Unfortunately, these are only some of the more prominent issues that occurred in the last year.</p>



<h2>But wait, that’s not all! </h2>



<p>Another ever-growing issue is the fact that Windows is <strong><em>bloated</em></strong>. And I’m not talking about the number of apps that are included in the OS or something that any script or custom OS could fix, but the fact that critical components are becoming so heavy that Microsoft has to develop workarounds in order to make them feel faster.</p>



<p>The prime example is Windows Explorer, which has become so sluggish that it has to be preloaded in order to make it faster, but even then it’s actually slower than previous versions of Windows! </p>



<figure><img data-attachment-id="580" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-52/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png" data-orig-size="1024,576" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=1024" loading="lazy" width="1024" height="576" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-8.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>How can one of the core UI elements of the OS become so heavy while not offering any noticeable quality-of-life improvement (apart from the introduction of tabs in Windows 11 22H2)? </p>



<p>Even Windows updates have become <em><strong>insanely </strong></em>big. Just take a look at the latest January 2026 update for Windows 11 23H2 and the one for 25H2.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:188937498,&quot;permalink&quot;:&quot;https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/&quot;}">
<figure><img data-attachment-id="583" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-54/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png" data-orig-size="928,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=928" loading="lazy" width="928" height="225" data-id="583" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=928" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png 928w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-10.png?w=768 768w" sizes="(max-width: 928px) 100vw, 928px"></figure>



<figure><img data-attachment-id="586" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-57/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png" data-orig-size="928,228" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=928" loading="lazy" width="928" height="228" data-id="586" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=928" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png 928w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-13.png?w=768 768w" sizes="(max-width: 928px) 100vw, 928px"></figure>
</figure>



<p>More than 4 times bigger! <em>And you probably know why</em>. More on that later.</p>



<p>Last, but not least, the technical debt of Windows has become almost unbearable. 30+ years of Windows NT certainly adds up. And the fact that Microsoft can’t focus on a visual language or a software platform for once is daunting, especially since given the nature of Windows you have to support them <em>all</em>.</p>



<p>However, the biggest problem is that Windows is not only buggy. Sure, a piece of software of this magnitude can and will have its fair share of issues. Our use cases have gotten more complex and the software that we expect to fulfill those use cases have become more complex, more secure, more powerful, you name it. That being said…</p>



<h2>windows is getting annoying.</h2>



<p>Let’s tackle the elephant in the room.</p>



<p>LLMs (and AI as a whole) have the potential to be an outright revolution, changing the fabric of society and the way of our lives. Microsoft Copilot as well could be a brilliant idea if it is implemented correctly and has the power to completely transform Microsoft into an even bigger juggernaut, unlocking even more of that sweet shareholder value… if it’s done properly, that is.</p>



<p>Introduced in 2023, Microsoft Copilot is Microsoft’s chatbot based on OpenAI’s models after a $10 billion investment. Introduced in Windows 11 with the December 2023 Patch Tuesday, at first it was just a benign WebView application that could be easily removed. However, since 2024, Copilot and artificial intelligence have taken a critical role in Microsoft’s overall strategy, especially in areas like programming.</p>



<p>This shift also showed up in subsequent versions of Windows.</p>



<p>In Windows 11 24H2, the main highlight of the new update was the introduction of a suite of AI features, with the most important being Windows Recall.</p>



<p>The flagship feature of 24H2, Recall was intended to a be a “photographic memory” of sorts for your PC. This meant that, as you might have guessed, Windows Recall would take a snapshot of your screen every few seconds. Then, the information from those screenshots would be processed using local AI to make it searchable.</p>



<figure><img data-attachment-id="604" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-66/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=1024" loading="lazy" width="1024" height="640" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-22.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>However, soon after it was introduced it became clear that it was a security nightmare. Early security researchers discovered that the data was stored in a largely unencrypted SQLite database, making it a goldmine for info-stealing malware. Not only that, but the early builds of Recall had no option to disable it. The backlash was so severe that Microsoft was forced to pull the feature just days before the Copilot+ PC launch in 2024, leaving a new generation of PCs without their flagship feature. </p>



<p>Applications like Signal and Brave implemented anti-Recall features that would prevent the app from taking screenshots.</p>



<p>While Microsoft would mitigate the main security concerns related to Recall, by making it uninstallable, encrypting its database and making it usable only if Windows Hello was enabled, the damage was already done. </p>



<p>Also, Windows Recall is one of the main reasons why Windows updates are so big these days, as each Windows update also introduces updates to the AI models included with the OS, even though you may not even have a Copilot+ PC that supports these features.</p>



<p>Apart from Recall, Windows has also suffered from an acute Copilot-ification. </p>



<figure><img data-attachment-id="591" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-58/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png" data-orig-size="166,78" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png?w=166" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png?w=166" loading="lazy" width="166" height="78" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png?w=166" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png 166w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-14.png?w=150 150w" sizes="(max-width: 166px) 100vw, 166px"></figure>



<figure><img data-attachment-id="593" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-59/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png" data-orig-size="1396,571" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=1024" loading="lazy" width="1024" height="418" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-15.png 1396w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="594" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-60/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png" data-orig-size="1419,88" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=1024" loading="lazy" width="1024" height="63" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-16.png 1419w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="596" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-61/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png" data-orig-size="1236,111" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=1024" loading="lazy" width="1024" height="91" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-17.png 1236w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="598" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-62/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png" data-orig-size="679,139" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png?w=679" loading="lazy" width="679" height="139" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png?w=679" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png 679w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-18.png?w=300 300w" sizes="(max-width: 679px) 100vw, 679px"></figure>



<figure><img data-attachment-id="599" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-63/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png" data-orig-size="1918,264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=1024" loading="lazy" width="1024" height="140" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png?w=1440 1440w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-19.png 1918w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="601" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-64/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png" data-orig-size="1812,208" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=1024" loading="lazy" width="1024" height="117" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png?w=1440 1440w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-20.png 1812w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="603" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-65/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png" data-orig-size="1160,1018" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=1024" loading="lazy" width="1024" height="898" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=1024" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=1024 1024w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png?w=768 768w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-21.png 1160w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The preinstalled browser (Edge) has Copilot.</p>



<p>The main text editor (Notepad) has Copilot.</p>



<p>There is also a dedicated Copilot app which is preinstalled and non-removable (in most cases)</p>



<p>The main photo viewer has a Copilot button which just opens the main app</p>



<p>The Settings application has Copilot in its search function (which doesn’t even work properly).</p>



<p>The Search application has Copilot (which only opens up the Copilot app) and needs a COMPLETE overhaul in my opinion.</p>



<p>Paint has Copilot</p>



<p>Office has Copilot (which is one of the few instances where Copilot and AI as a whole is genuinely useful if used correctly)</p>



<p>Also, judging by the latest Windows 11 builds, even Windows Explorer, which is already quite heavy in itself as we discussed earlier is getting Copilot!</p>



<figure><img data-attachment-id="607" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-67/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png" data-orig-size="913,298" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=913" loading="lazy" width="913" height="298" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=913" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png 913w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-23.png?w=768 768w" sizes="(max-width: 913px) 100vw, 913px"></figure>



<p>With the Copilot epidemic also came the complete death of the “offline” Windows.</p>



<p>Perhaps the most nagging change since 2023 is the slow death of the local account. Microsoft has spent the last three years systematically closing every “backdoor” that allowed users to set up Windows without a Microsoft Account.</p>



<figure><img data-attachment-id="610" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-68/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png" data-orig-size="816,612" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=300" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=816" loading="lazy" width="816" height="612" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=816" alt="" srcset="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png 816w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=150 150w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=300 300w, https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-24.png?w=768 768w" sizes="(max-width: 816px) 100vw, 816px"></figure>



<p>Methods like OOBE.exe /bypassNRO or a@a.com as the email for the account have been “fixed”, meaning that it becomes harder and harder to use a local account with each subsequent update.</p>



<h2>a vision with a crumbling foundation</h2>



<p>Looking back at the last three years, the “State of Windows” is one of extreme ambition built on a crumbling foundation. Microsoft is trying to build a futuristic AI skyscraper, but they are building it on top of a basement filled with 30-year-old technical debt and a ground floor that can’t even handle a shutdown command properly.</p>



<p>Unfortunately, the issue that plagued Windows since the dawn of time has only aggravated recently. Windows 11 is a mixture of old and new technologies that are glued together, with decades of legacy code that simply refuses to die (because if it did a lot of corporate costumers would complain, and whether we like it or not they are paying big cash for support to Microsoft). </p>



<p>Also, it tries to have a “modern” UI that unfortunately not only is inconsistent, but also it’s too heavy for its own good, being just a lipstick on a bloated old pig.</p>



<p>Last, but certainly not least, it is full of AI features that most people didn’t ask for, some are even actively feared (see Recall) and are also quite lacking in polish and usefulness. </p>



<p>I feel like a good analogy of the current situation with Windows is this picture which was shown in an internal presentation regarding the performance and reliability of pre-reset Longhorn </p>



<figure><img data-attachment-id="613" data-permalink="https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/image-69/" data-orig-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-25-e1769376069744.png" data-orig-size="246,84" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-25-e1769376069744.png?w=246" data-large-file="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-25-e1769376069744.png?w=246" loading="lazy" width="540" height="184" src="https://ntdotdev.wordpress.com/wp-content/uploads/2026/01/image-25.png?w=540" alt=""></figure>



<p>Until Microsoft stops treating Windows as an “AI innovation platform” of sorts and starts treating it as the stable, reliable tool it was always meant to be, the user experience will continue to feel like a battle between the person sitting at the desk and the company that built the desk.</p>



<p><strong>Thank you for you attention.</strong></p>







<p><strong>Did you find this article interesting?</strong> Writing these deep dives (once every few years 😂) takes a lot of time (and caffeine).☕Also it would be nice if I would get a proper domain for this page. </p>



<p><strong><a href="http://paypal.me/ntdev2">[Support my work!]</a></strong></p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[People who know the formula for WD-40 (184 pts)]]></title>
            <link>https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54</link>
            <guid>46771599</guid>
            <pubDate>Mon, 26 Jan 2026 21:11:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54">https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54</a>, See on <a href="https://news.ycombinator.com/item?id=46771599">Hacker News</a></p>
Couldn't get https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Dithering – Part 2: The Ordered Dithering (230 pts)]]></title>
            <link>https://visualrambling.space/dithering-part-2/</link>
            <guid>46770274</guid>
            <pubDate>Mon, 26 Jan 2026 19:23:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://visualrambling.space/dithering-part-2/">https://visualrambling.space/dithering-part-2/</a>, See on <a href="https://news.ycombinator.com/item?id=46770274">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><b><i>visualrambling.space</i></b> is created by Damar, someone who loves to exploring new topics and rambling about them visually.</p><p>I'm also open for <b><i>collaborations or commissioned work</i></b>. Feel free to reach out anytime!</p><h2>Follow Me</h2><div><p><a href="https://x.com/damarberlari" target="_blank"><img src="https://visualrambling.space/dithering-part-2/x-logo.7eede6cd195725024cd3.png" alt="Twitter">X/Twitter</a> <a href="https://bsky.app/profile/damarberlari.bsky.social" target="_blank"><img src="https://visualrambling.space/dithering-part-2/bluesky-logo.07cbcdda5e4a1dcd3616.png" alt="Bluesky">Bluesky</a> <a href="https://www.linkedin.com/in/damarpramudita/" target="_blank"><img src="https://visualrambling.space/dithering-part-2/linkedin-logo.557b034572436f1d8081.png" alt="LinkedIn">LinkedIn</a> <a href="https://visualrambling.space/rss.xml" target="_blank"><img src="https://visualrambling.space/dithering-part-2/rss-logo.b3bdabc3da1889db208c.png" alt="RSS">RSS</a></p></div><h2>Contact</h2><p><a href="https://visualrambling.space/cdn-cgi/l/email-protection#73531b161f1f1c33051a0006121f01121e111f1a1d145d0003121016"><b><span data-cfemail="dfb7bab3b3b09fa9b6acaabeb3adbeb2bdb3b6b1b8f1acafbebcba">[email&nbsp;protected]</span></b></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT Containers can now run bash, pip/npm install packages and download files (390 pts)]]></title>
            <link>https://simonwillison.net/2026/Jan/26/chatgpt-containers/</link>
            <guid>46770221</guid>
            <pubDate>Mon, 26 Jan 2026 19:19:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/">https://simonwillison.net/2026/Jan/26/chatgpt-containers/</a>, See on <a href="https://news.ycombinator.com/item?id=46770221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2026/Jan/26/chatgpt-containers/">

<p>26th January 2026</p>



<p>One of my favourite features of ChatGPT is its ability to write and execute code in a container. This feature launched as ChatGPT Code Interpreter <a href="https://simonwillison.net/2023/Apr/12/code-interpreter/">nearly three years ago</a>, was half-heartedly rebranded to “Advanced Data Analysis” at some point and is generally really difficult to find detailed documentation about. Case in point: it appears to have had a <em>massive</em> upgrade at some point in the past few months, and I can’t find documentation about the new capabilities anywhere!</p>
<p>Here are the most notable new features:</p>
<ol>
<li>ChatGPT can <strong>directly run Bash commands</strong> now. Previously it was limited to Python code only, although it could run shell commands via the Python <code>subprocess</code> module.</li>
<li>
<strong>It has Node.js</strong> and can run JavaScript directly in addition to Python. I also got it to run “hello world” in <strong>Ruby, Perl, PHP, Go, Java, Swift, Kotlin, C and C++</strong>. No Rust yet though!</li>
<li>While the container still can’t make outbound network requests, <strong><code>pip install package</code> and <code>npm install package</code> both work</strong> now via a custom proxy mechanism.</li>
<li>ChatGPT can locate the URL for a file on the web and use a <code>container.download</code> tool to <strong>download that file and save it to a path</strong> within the sandboxed container.</li>
</ol>
<p>This is a substantial upgrade! ChatGPT can now write and then test code in 10 new languages (11 if you count Bash), can find files online and download them into the container, and can install additional packages via <code>pip</code> and <code>npm</code> to help it solve problems.</p>
<p>(OpenAI <em>really</em> need to develop better habits at <a href="https://help.openai.com/en/articles/6825453-chatgpt-release-notes">keeping their release notes up-to-date</a>!)</p>
<p>I was initially suspicious that maybe I’d stumbled into a new preview feature that wasn’t available to everyone, but I <a href="https://chatgpt.com/share/6977aa7c-7bd8-8006-8129-8c9e25126fed">tried some experiments</a> in a free ChatGPT account and confirmed that the new features are available there as well.</p>

<ul>
  <li><a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/#container-download">container.download</a></li>
  <li><a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/#is-container-download-a-data-exfiltration-vulnerability-">Is container.download a data exfiltration vulnerability?</a></li>
  <li><a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/#bash-and-other-languages">Bash and other languages</a></li>
  <li><a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/#installing-packages-from-pip-and-npm">Installing packages from pip and npm</a></li>
  <li><a href="https://simonwillison.net/2026/Jan/26/chatgpt-containers/#adding-it-all-together">Adding it all together</a></li>
</ul>

<h4 id="container-download">container.download</h4>
<p>My first clue to the new features came the other day when I got curious about Los Angeles air quality, in particular has the growing number of electric vehicles there hade a measurable impact?</p>
<p>I prompted a fresh GPT-5.2 Thinking session with:</p>
<blockquote>
<p>Show me Los Angeles air quality over time for last 20 years</p>
</blockquote>
<p>Here’s the <a href="https://chatgpt.com/share/6977a80d-e6e4-8006-b4fe-ed8478fe99d8">shared transcript</a>. Annoyingly that doesn’t make the thinking trace available, so here’s a screenshot:</p>
<p><img src="https://static.simonwillison.net/static/2026/container-download.jpg" alt="Exploring methods to fetch AQI data and reports Downloading AQI data for Los Angeles  I found an xlsx file titled &quot;Air Quality Statistics by City, 2000-2023&quot;, which should include data for Los Angeles. While user requested data for Using provided URL to download file  The URL from the error message leads to an Excel file containing air quality trends. I can use the container.download tool to fetch it. Let’s proceed with this approach and see if it works out for downloading the file directly! Analyzed Parsing and analyzing the data for Los Angeles  Now that we've downloaded the data, I'll parse it using Python. First, I'll focus on identifying the row(s) corresponding to Los Angeles, which may be labeled under &quot;Los Angeles-Long Beach-Anaheim, CA.&quot; Afterward, I'll plot metrics like &quot;Median AQI&quot; and &quot;Days Good&quot; over time to visualize trends. Let’s begin!"></p>
<p>This bit instantly caught my eye:</p>
<blockquote>
<p>[...] The URL from the error message leads to an Excel file containing air quality trends. I can use the container.download tool to fetch it. [...]</p>
</blockquote>
<p>What’s <code>container.download</code>? I <a href="https://chatgpt.com/share/6977aab0-b874-8006-9b54-d3d216ed884b">asked ChatGPT</a>:</p>
<blockquote>
<p>Without running any searches tell me about your container.download tool</p>
</blockquote>
<p>And got back:</p>
<blockquote>
<p>Sure. <code>container.download</code> is a built-in tool I can call that <strong>fetches a file from a URL and saves it into the sandboxed container filesystem</strong> for this chat session.</p>
<h4 id="what-it-does">What it does</h4>
<ul>
<li>Takes a <strong>publicly reachable URL</strong> and a <strong>destination filepath</strong> in the container.</li>
<li>Downloads the bytes from that URL and writes them to the given path.</li>
<li>After that, I can read/process the file locally in the container (e.g., unzip it, parse it with Python, open it as an image, convert it, etc.).</li>
</ul>
<h4 id="signature-inputs-">Signature (inputs)</h4>
<p>It’s called like this (conceptually):</p>
<div><pre>{
  <span>"url"</span>: <span><span>"</span>https://example.com/somefile.zip<span>"</span></span>,
  <span>"filepath"</span>: <span><span>"</span>/mnt/data/somefile.zip<span>"</span></span>
}</pre></div>
</blockquote>
<p>Further experimentation confirmed that <code>container.download</code> behaves as described.</p>
<p>I had it download one file from a server with logs enabled and captured the IP address and user-agent. Here are the most interesting headers:</p>
<pre><code>User-Agent: Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; ChatGPT-User/1.0; +https://openai.com/bot
Accept: text/html, application/xhtml+xml, application/xml;q=0.9, image/avif, image/webp, image/apng, */*;q=0.8, application/signed-exchange;v=b3;q=0.9
Cf-Connecting-Ip: 52.230.164.178
</code></pre>
<p>That <code>52.230.164.178</code> IP address <a href="http://ip-api.com/json/52.230.164.178">resolves to</a> Microsoft Azure Cloud (centralus) in Des Moines, Iowa.</p>
<h4 id="is-container-download-a-data-exfiltration-vulnerability-">Is container.download a data exfiltration vulnerability?</h4>
<p>On the one hand, this is really useful! ChatGPT can navigate around websites looking for useful files, download those files to a container and then process them using Python or other languages.</p>
<p>Is this a data exfiltration vulnerability though? Could a prompt injection attack trick ChatGPT into leaking private data out to a <code>container.download</code> call to a URL with a query string that includes sensitive information?</p>
<p>I don’t think it can. I tried getting it to assemble a URL with a query string and access it using <code>container.download</code> and it couldn’t do it. It told me that it got back this error:</p>
<blockquote>
<p>ERROR: download failed because url not viewed in conversation before. open the file or url using web.run first.</p>
</blockquote>
<p>This looks to me like the same safety trick <a href="https://simonwillison.net/2025/Sep/10/claude-web-fetch-tool/">used by Claude’s Web Fetch tool</a>: only allow URL access if that URL was either directly entered by the user or if it came from search results that could not have been influenced by a prompt injection.</p>
<p>(I poked at this a bit more and managed to get a simple constructed query string to pass through <code>web.run</code>—a different tool entirely—but when I tried to compose a longer query string containing the previous prompt history a <code>web.run</code> filter blocked it.)</p>
<p>So I <em>think</em> this is all safe, though I’m curious if it could hold firm against a more aggressive round of attacks from a seasoned security researcher.</p>
<h4 id="bash-and-other-languages">Bash and other languages</h4>
<p>The key lesson from coding agents like Claude Code and Codex CLI is that Bash rules everything: if an agent can run Bash commands in an environment it can do almost anything that can be achieved by typing commands into a computer.</p>
<p>When Anthropic added their own code interpreter feature to Claude <a href="https://simonwillison.net/2025/Sep/9/claude-code-interpreter/">last September</a> they built that around Bash rather than just Python. It looks to me like OpenAI have now done the same thing for ChatGPT.</p>
<p>Here’s what ChatGPT looks like when it runs a Bash command—here my prompt was:</p>
<blockquote>
<p>npm install a fun package and demonstrate using it</p>
</blockquote>
<p><img src="https://static.simonwillison.net/static/2026/chatgpt-bash.jpg" alt="Screenshot of ChatGPT 5.2 Thinking interface with Activity panel. Main chat shows user prompt &quot;npm install a fun package and demonstrate using it&quot; and response &quot;Thought for 32s > Yep — here's a fun one: cowsay 🐄 I installed it with npm and ran a tiny Node script:&quot; followed by bash code block containing &quot;mkdir -p /mnt/data/npmfun cd /mnt/data/npmfun npm init -y npm install cowsay --no-fund --no-audit node -e &quot;const cowsay=require('cowsay'); console.log(cowsay.say({text:'Hel&quot; and Output: section showing ASCII cow art saying &quot;< Hello from npm inside the container! >&quot; with cow drawing made of characters. Activity panel on right (32s) shows: &quot;Running npm install in container&quot; with bash command and output &quot;v22.16.0 10.9.2&quot;, &quot;Inspecting npm command output and container status&quot; with directory listing showing &quot;drwxr-xr-x 2 root oai_shared 80 Jan 26 17:32 . drwxrwxr-x 2 oai oai_shared 60 Jan 26 17:32 .. -rw-r--r-- 1 root root&quot;, &quot;Re-running npm install&quot; note about node_modules missing, and &quot;Rerunning npm install with output&quot; showing &quot;added 41 packages in 2s&quot;."></p>
<p>It’s useful to click on the “Thinking” or “Thought for 32s” links as that opens the Activity sidebar with a detailed trace of what ChatGPT did to arrive at its answer. This helps guard against cheating—ChatGPT might claim to have run Bash in the main window but it can’t fake those black and white logs in the Activity panel.</p>
<p>I had it run <a href="https://chatgpt.com/share/6977b890-f1c0-8006-b39a-9a02c7ca1993">Hello World in various languages</a> later in that same session.</p>
<p><img src="https://static.simonwillison.net/static/2026/chatgpt-hello-worlds.jpg" alt="Terminal screenshot showing &quot;Hello, world&quot; programs in multiple languages. Top section shows code: swift -e 'print(&quot;Hello, world from Swift!&quot;)' followed by cat > hello.kts <<'KTS' / println(&quot;Hello, world from Kotlin!&quot;) / KTS / kotlinc -script hello.kts, then cat > hello.c <<'C' / #include <stdio.h> / int main(){ puts(&quot;Hello, world from C!&quot;); return 0; } / C / gcc hello.c -o hello_c / ./hello_c, then cat > hello.cpp <<'CPP' / #include <iostream> / int main(){ std::cout << &quot;Hello, world from C++!&quot; << std::endl; } / CPP / g++ hello.cpp -o hello_cpp / ./hello_cpp. Bottom section shows output: Hello, world from Ruby! / Hello, world from Perl! / Hello, world from PHP! / Hello, world from Go! / Hello, world from Java! / Hello, world from Swift! / Hello, world from Kotlin! / Hello, world from C! / Hello, world from C++!. UI shows &quot;Thought for 2m 29s&quot; and &quot;Done&quot; at bottom."></p>
<h4 id="installing-packages-from-pip-and-npm">Installing packages from pip and npm</h4>
<p>In the previous example ChatGPT installed the <code>cowsay</code> package from npm and used it to draw an ASCII-art cow. But how could it do that if the container can’t make outbound network requests?</p>
<p>In <a href="https://chatgpt.com/share/69773501-b6d8-8006-bbf2-fa644561aa26">another session</a> I challenged it to explore its environment. and figure out how that worked.</p>
<p>Here’s <a href="https://github.com/simonw/research/blob/main/chatgpt-container-environment/README.md">the resulting Markdown report</a> it created.</p>
<p>The key magic appears to be a <code>applied-caas-gateway1.internal.api.openai.org</code> proxy, available within the container and with various packaging tools configured to use it.</p>
<p>The following environment variables cause <code>pip</code> and <code>uv</code> to install packages from that proxy instead of directly from PyPI:</p>
<pre><code>PIP_INDEX_URL=https://reader:****@packages.applied-caas-gateway1.internal.api.openai.org/.../pypi-public/simple
PIP_TRUSTED_HOST=packages.applied-caas-gateway1.internal.api.openai.org
UV_INDEX_URL=https://reader:****@packages.applied-caas-gateway1.internal.api.openai.org/.../pypi-public/simple
UV_INSECURE_HOST=https://packages.applied-caas-gateway1.internal.api.openai.org
</code></pre>
<p>This one appears to get <code>npm</code> to work:</p>
<pre><code>NPM_CONFIG_REGISTRY=https://reader:****@packages.applied-caas-gateway1.internal.api.openai.org/.../npm-public
</code></pre>
<p>And it reported these suspicious looking variables as well:</p>
<pre><code>CAAS_ARTIFACTORY_BASE_URL=packages.applied-caas-gateway1.internal.api.openai.org
CAAS_ARTIFACTORY_PYPI_REGISTRY=.../artifactory/api/pypi/pypi-public
CAAS_ARTIFACTORY_NPM_REGISTRY=.../artifactory/api/npm/npm-public
CAAS_ARTIFACTORY_GO_REGISTRY=.../artifactory/api/go/golang-main
CAAS_ARTIFACTORY_MAVEN_REGISTRY=.../artifactory/maven-public
CAAS_ARTIFACTORY_GRADLE_REGISTRY=.../artifactory/gradle-public
CAAS_ARTIFACTORY_CARGO_REGISTRY=.../artifactory/api/cargo/cargo-public/index
CAAS_ARTIFACTORY_DOCKER_REGISTRY=.../dockerhub-public
CAAS_ARTIFACTORY_READER_USERNAME=reader
CAAS_ARTIFACTORY_READER_PASSWORD=****
NETWORK=caas_packages_only
</code></pre>
<p>Neither Rust nor Docker are installed in the container environment, but maybe those registry references are a clue of features still to come.</p>
<h4 id="adding-it-all-together">Adding it all together</h4>
<p>The result of all of this? You can tell ChatGPT to use Python or Node.js packages as part of a conversation and it will be able to install them and apply them against files you upload or that it downloads from the public web. That’s <em>really</em> cool.</p>
<p>The big missing feature here should be the easiest to provide: we need <strong>official documentation</strong>! A release notes entry would be a good start, but there are a lot of subtle details to how this new stuff works, its limitations and what it can be used for.</p>
<p>As always, I’d also encourage OpenAI to come up with a name for this set of features that properly represents how it works and what it can do.</p>
<p>In the meantime, I’m going to call this <strong>ChatGPT Containers</strong>.</p>
<h4 id="list-of-tools">Update: a full list of tools</h4>
<p>I decided to ask ChatGPT about other tools that were available to it in case there was anything interesting in there:</p>
<blockquote><p>List all tools that are available to you, with their exact names and descriptions and signatures</p></blockquote>
<p>Here’s <a href="https://chatgpt.com/share/6977ffa0-df14-8006-9647-2b8c90ccbb81">what I got back</a>.</p>

<details><summary>List of ChatGPT tools according to GPT-5.2 Thinking on 26th January 2026</summary>
<p>Below are <strong>all tools available to me in this chat</strong>, with their <strong>exact names</strong>, <strong>descriptions</strong>, and <strong>signatures</strong> (as defined in my tool interface).</p>
<hr>
<h4 id="python">python</h4>
<h5 id="python-exec-freeform-any">
<code>python.exec</code> (FREEFORM) → any</h5>
<p><strong>Description:</strong> Execute Python code in a Jupyter environment for <em>private/internal reasoning</em> (not shown to you). Internet access is disabled.<br>
<strong>Signature:</strong> <code>python.exec(FREEFORM) -&gt; any</code></p>
<hr>
<h4 id="web">web</h4>
<h5 id="web-run-toolcallv5-json-any">
<code>web.run</code> (ToolCallV5 JSON) → any</h5>
<p><strong>Description:</strong> Access the internet and specialized lookups (search, open/click/find pages, screenshot PDFs, image search, product search, finance, weather, sports, calculator, time). Supports citations via returned <code>turn...</code> reference IDs.<br>
<strong>Signature:</strong><br>
<code>web.run({ open?, click?, find?, screenshot?, image_query?, product_query?, sports?, finance?, weather?, calculator?, time?, search_query?, response_length? }) -&gt; any</code></p>
<hr>
<h4 id="automations">automations</h4>
<h5 id="automations-create-any">
<code>automations.create</code> → any</h5>
<p><strong>Description:</strong> Schedule a future/recurring task/reminder/search via iCal VEVENT.<br>
<strong>Signature:</strong><br>
<code>automations.create({ prompt: string, title: string, schedule?: string, dtstart_offset_json?: string }) -&gt; any</code></p>
<h5 id="automations-update-any">
<code>automations.update</code> → any</h5>
<p><strong>Description:</strong> Modify an existing scheduled task.<br>
<strong>Signature:</strong><br>
<code>automations.update({ jawbone_id: string, schedule?: string, dtstart_offset_json?: string, prompt?: string, title?: string, is_enabled?: boolean }) -&gt; any</code></p>
<h5 id="automations-list-any">
<code>automations.list</code> → any</h5>
<p><strong>Description:</strong> List existing automations.<br>
<strong>Signature:</strong> <code>automations.list() -&gt; any</code></p>
<hr>
<h4 id="guardian-tool">guardian_tool</h4>
<h5 id="guardian-tool-get-policy-str">
<code>guardian_tool.get_policy</code> → str</h5>
<p><strong>Description:</strong> Retrieve policy guidance for specific categories (currently: <code>election_voting</code>).<br>
<strong>Signature:</strong> <code>guardian_tool.get_policy({ category: string }) -&gt; str</code></p>
<hr>
<h4 id="file-search">file_search</h4>
<h5 id="file-search-msearch-any">
<code>file_search.msearch</code> → any</h5>
<p><strong>Description:</strong> Search across available internal/connected sources (in this environment: primarily “recording_knowledge” transcripts when relevant).<br>
<strong>Signature:</strong><br>
<code>file_search.msearch({ queries?: string[], source_filter?: string[], file_type_filter?: string[], intent?: string, time_frame_filter?: { start_date?: string, end_date?: string } }) -&gt; any</code></p>
<h5 id="file-search-mclick-any">
<code>file_search.mclick</code> → any</h5>
<p><strong>Description:</strong> Expand/open previously returned search results (or connector URLs) for more context.<br>
<strong>Signature:</strong><br>
<code>file_search.mclick({ pointers?: string[], start_date?: string, end_date?: string }) -&gt; any</code></p>
<hr>
<h4 id="gmail-read-only-">gmail (read-only)</h4>
<h5 id="gmail-search-email-ids-any">
<code>gmail.search_email_ids</code> → any</h5>
<p><strong>Description:</strong> Search Gmail message IDs by query/tags (read-only).<br>
<strong>Signature:</strong><br>
<code>gmail.search_email_ids({ query?: string, tags?: string[], max_results?: integer, next_page_token?: string }) -&gt; any</code></p>
<h5 id="gmail-batch-read-email-any">
<code>gmail.batch_read_email</code> → any</h5>
<p><strong>Description:</strong> Read a batch of Gmail messages by message IDs (read-only).<br>
<strong>Signature:</strong><br>
<code>gmail.batch_read_email({ message_ids: string[] }) -&gt; any</code></p>
<hr>
<h4 id="gcal-read-only-">gcal (read-only)</h4>
<h5 id="gcal-search-events-any">
<code>gcal.search_events</code> → any</h5>
<p><strong>Description:</strong> Search Google Calendar events in a time range and/or by keyword (read-only).<br>
<strong>Signature:</strong><br>
<code>gcal.search_events({ time_min?: string, time_max?: string, timezone_str?: string, max_results?: integer, query?: string, calendar_id?: string, next_page_token?: string }) -&gt; any</code></p>
<h5 id="gcal-read-event-any">
<code>gcal.read_event</code> → any</h5>
<p><strong>Description:</strong> Read a specific calendar event by ID (read-only).<br>
<strong>Signature:</strong><br>
<code>gcal.read_event({ event_id: string, calendar_id?: string }) -&gt; any</code></p>
<hr>
<h4 id="gcontacts-read-only-">gcontacts (read-only)</h4>
<h5 id="gcontacts-search-contacts-any">
<code>gcontacts.search_contacts</code> → any</h5>
<p><strong>Description:</strong> Search Google Contacts by keyword (read-only).<br>
<strong>Signature:</strong><br>
<code>gcontacts.search_contacts({ query: string, max_results?: integer }) -&gt; any</code></p>
<hr>
<h4 id="canmore-canvas-">canmore (canvas)</h4>
<h5 id="canmore-create-textdoc-any">
<code>canmore.create_textdoc</code> → any</h5>
<p><strong>Description:</strong> Create a new canvas text document (markdown or code).<br>
<strong>Signature:</strong><br>
<code>canmore.create_textdoc({ name: string, type: "document" | "code/bash" | "code/zsh" | "code/javascript" | "code/typescript" | "code/html" | "code/css" | "code/python" | "code/json" | "code/sql" | "code/go" | "code/yaml" | "code/java" | "code/rust" | "code/cpp" | "code/swift" | "code/php" | "code/xml" | "code/ruby" | "code/haskell" | "code/kotlin" | "code/csharp" | "code/c" | "code/objectivec" | "code/r" | "code/lua" | "code/dart" | "code/scala" | "code/perl" | "code/commonlisp" | "code/clojure" | "code/ocaml" | "code/powershell" | "code/verilog" | "code/dockerfile" | "code/vue" | "code/react" | "code/other", content: string }) -&gt; any</code></p>
<h5 id="canmore-update-textdoc-any">
<code>canmore.update_textdoc</code> → any</h5>
<p><strong>Description:</strong> Apply regex-based edits to the current canvas textdoc.<br>
<strong>Signature:</strong><br>
<code>canmore.update_textdoc({ updates: { pattern: string, multiple?: boolean, replacement: string }[] }) -&gt; any</code></p>

<p><strong>Description:</strong> Add actionable comments on matched regions of the current canvas textdoc.<br>
<strong>Signature:</strong><br>
<code>canmore.comment_textdoc({ comments: { pattern: string, comment: string }[] }) -&gt; any</code></p>
<hr>
<h4 id="python-user-visible">python_user_visible</h4>
<h5 id="python-user-visible-exec-freeform-any">
<code>python_user_visible.exec</code> (FREEFORM) → any</h5>
<p><strong>Description:</strong> Execute Python code <em>that you will see</em> (tables, plots, generated files). Internet disabled.<br>
<strong>Signature:</strong> <code>python_user_visible.exec(FREEFORM) -&gt; any</code></p>
<hr>
<h4 id="user-info">user_info</h4>
<h5 id="user-info-get-user-info-any">
<code>user_info.get_user_info</code> → any</h5>
<p><strong>Description:</strong> Get your current location and local time (or UTC if unknown).<br>
<strong>Signature:</strong> <code>user_info.get_user_info({}) -&gt; any</code></p>
<hr>
<h4 id="summary-reader">summary_reader</h4>
<h5 id="summary-reader-read-any">
<code>summary_reader.read</code> → any</h5>
<p><strong>Description:</strong> Read safe-to-share internal reasoning summaries from earlier turns (used when asked how I arrived at something).<br>
<strong>Signature:</strong> <code>summary_reader.read({ limit?: integer, offset?: integer }) -&gt; any</code></p>
<hr>
<h4 id="container">container</h4>
<h5 id="container-exec-any">
<code>container.exec</code> → any</h5>
<p><strong>Description:</strong> Run a command inside the container and return stdout/stderr.<br>
<strong>Signature:</strong><br>
<code>container.exec({ cmd: string[], session_name?: string | null, workdir?: string | null, timeout?: integer | null, env?: object | null, user?: string | null }) -&gt; any</code></p>
<h5 id="container-feed-chars-any">
<code>container.feed_chars</code> → any</h5>
<p><strong>Description:</strong> Send input to a running interactive exec session and flush output.<br>
<strong>Signature:</strong><br>
<code>container.feed_chars({ session_name: string, chars: string, yield_time_ms?: integer }) -&gt; any</code></p>
<h5 id="container-open-image-any">
<code>container.open_image</code> → any</h5>
<p><strong>Description:</strong> Display an image from an absolute path in the container (jpg/jpeg/png/webp).<br>
<strong>Signature:</strong><br>
<code>container.open_image({ path: string, user?: string | null }) -&gt; any</code></p>
<h5 id="container-download-any">
<code>container.download</code> → any</h5>
<p><strong>Description:</strong> Download a file from a URL into the container filesystem.<br>
<strong>Signature:</strong><br>
<code>container.download({ url: string, filepath: string }) -&gt; any</code></p>
<hr>
<h4 id="bio-memory-">bio (memory)</h4>
<h5 id="bio-update-freeform-any">
<code>bio.update</code> (FREEFORM) → any</h5>
<p><strong>Description:</strong> Persist (or forget) user-specific info across conversations (“memory”).<br>
<strong>Signature:</strong> <code>bio.update(FREEFORM) -&gt; any</code></p>
<hr>
<h4 id="api-tool">api_tool</h4>
<h5 id="api-tool-list-resources-any">
<code>api_tool.list_resources</code> → any</h5>
<p><strong>Description:</strong> List available “resources” (including invokable tools) in an OP-style file tree.<br>
<strong>Signature:</strong><br>
<code>api_tool.list_resources({ path?: string, cursor?: string | null, only_tools?: boolean, refetch_tools?: boolean }) -&gt; any</code></p>
<h5 id="api-tool-call-tool-any">
<code>api_tool.call_tool</code> → any</h5>
<p><strong>Description:</strong> Invoke a resource as a tool (must know its full path/URI from <code>list_resources</code>).<br>
<strong>Signature:</strong><br>
<code>api_tool.call_tool({ path: string, args: object }) -&gt; any</code></p>
<hr>
<h4 id="personal-context">personal_context</h4>
<h5 id="personal-context-search-any">
<code>personal_context.search</code> → any</h5>
<p><strong>Description:</strong> Retrieve user-specific context from prior interactions/linked sources to maintain continuity.<br>
<strong>Signature:</strong><br>
<code>personal_context.search({ query: string }) -&gt; any</code></p>
<hr>
<h4 id="image-gen">image_gen</h4>
<h5 id="image-gen-text2im-any">
<code>image_gen.text2im</code> → any</h5>
<p><strong>Description:</strong> Generate or edit images from text instructions (and optionally referenced image IDs).<br>
<strong>Signature:</strong><br>
<code>image_gen.text2im({ prompt?: string | null, size?: string | null, n?: integer | null, transparent_background?: boolean | null, is_style_transfer?: boolean | null, referenced_image_ids?: string[] | null }) -&gt; any</code></p>
<hr>
<h4 id="user-settings">user_settings</h4>
<h5 id="user-settings-get-user-settings-any">
<code>user_settings.get_user_settings</code> → any</h5>
<p><strong>Description:</strong> Read current settings and allowed values (personality, accent color, appearance).<br>
<strong>Signature:</strong> <code>user_settings.get_user_settings() -&gt; any</code></p>
<h5 id="user-settings-set-setting-any">
<code>user_settings.set_setting</code> → any</h5>
<p><strong>Description:</strong> Change one setting (accent color, appearance, or personality) to an allowed value.<br>
<strong>Signature:</strong><br>
<code>user_settings.set_setting({ setting_name: "accent_color" | "appearance" | "personality", setting_value: string }) -&gt; any</code></p>
<hr>
<h4 id="artifact-handoff">artifact_handoff</h4>
<h5 id="artifact-handoff-prepare-artifact-generation-any">
<code>artifact_handoff.prepare_artifact_generation</code> → any</h5>
<p><strong>Description:</strong> Must be called immediately when the user asks for a spreadsheet or slide deck artifact.<br>
<strong>Signature:</strong> <code>artifact_handoff.prepare_artifact_generation() -&gt; any</code></p>
</details>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When AI 'builds a browser,' check the repo before believing the hype (227 pts)]]></title>
            <link>https://www.theregister.com/2026/01/26/cursor_opinion/</link>
            <guid>46769965</guid>
            <pubDate>Mon, 26 Jan 2026 18:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/26/cursor_opinion/">https://www.theregister.com/2026/01/26/cursor_opinion/</a>, See on <a href="https://news.ycombinator.com/item?id=46769965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> AI-integrated development environment (IDE) company Cursor recently <a target="_blank" rel="nofollow" href="https://cursor.com/blog/scaling-agents">implied</a> it had built a working web browser almost entirely with its AI agents. I won't say they lied, but CEO Michael Truell certainly <a target="_blank" rel="nofollow" href="https://x.com/mntruell/status/2011562190286045552">tweeted</a>: "We built a browser with GPT-5.2 in Cursor."</p>
<p>He followed up with: "It's 3M+ lines of code across thousands of files. The rendering engine is from-scratch in Rust with HTML parsing, CSS cascade, layout, text shaping, paint, and a custom JS VM."</p>
<p>That sounds impressive, doesn't it? He also added: "It *kind of* works," which is not the most ringing endorsement. Still, numerous news sources and social media chatterboxes ran with the news that <a target="_blank" rel="nofollow" href="https://medium.com/write-a-catalyst/ai-agents-built-a-web-browser-in-one-week-and-that-should-make-us-pause-1be4fab67d03">AI built a web browser in a week</a>.</p>

    

<p>Too bad it wasn't true. If you actually looked at Cursor engineer Wilson Lin's blog post about <a target="_blank" rel="nofollow" href="https://github.com/wilsonzlin/fastrender">FastRender</a>, the AI-created web browser, you won't see much boasting about a working web browser. Instead, there's a video of a web browser sort of working, and a much less positive note that "building a browser from scratch is extremely difficult."</p>

        


        

<p>The thing about making such a software announcement on GitHub is that while the headlines are proclaiming another AI victory, developers have this nasty trick. They actually git the code and try it out.</p>
<p><a target="_blank" rel="nofollow" href="https://emsh.cat/cursor-implied-success-without-evidence/">Developers quickly discovered the "browser" barely compiles</a>, often does not run, and was heavily misrepresented in marketing.</p>

        

<p>As a techie, the actual blog post about how they tried and didn't really succeed was much more interesting. Of course, that Cursor sicced hundreds of GPT-5.2-style agents which ran for a week to produce three million lines of new code, to produce, at best, a semi-functional web browser from scratch, doesn't make for a good headline.</p>
<p>According to Perplexity, my AI chatbot of choice, this week‑long autonomous browser experiment consumed in the order of 10-20 trillion tokens and would have cost several million dollars at then‑current list prices for frontier models.</p>
<p>I'd just cloned a copy of Chromium myself, and for all that time and money, independent developers who cloned the repo reported that the codebase is very far from a functional browser. Recent commits do not compile cleanly, GitHub Actions runs on <code>main</code> are failing, and reviewers could not find a single recent commit that was built without errors.</p>

        

<p>Where builds succeeded after manual patching, performance was abysmal, with reports of pages taking around a minute to load and a heavy reliance on existing projects like <a target="_blank" rel="nofollow" href="https://servo.org/">Servo</a>, a Rust-based web rendering engine, and QuickJS, a JavaScript engine, despite "from scratch" claims.</p>
<p>Lin defended the project on Y Combinator, <a target="_blank" rel="nofollow" href="https://news.ycombinator.com/item?id=46650998">saying</a>, for instance: "The JS engine used a custom JS VM being developed in vendor/ecma-rs as part of the browser, which is a copy of my personal JS parser project vendored to make it easier to commit to." If it's derived from his personal JavaScript parser, that's not really from scratch, is it? Nor is it, from the sound of the argument, written by AI.</p>
<ul>

<li><a href="https://www.theregister.com/2026/01/16/linus_torvalds_vibe_coding/">Just because Linus Torvalds vibe codes doesn't mean it's a good idea</a></li>

<li><a href="https://www.theregister.com/2026/01/09/microsoft_365_copilot_app/">The Microsoft 365 Copilot app rebrand was bad, but there are far worse offenders</a></li>

<li><a href="https://www.theregister.com/2025/12/31/long_lived_tech/">The most durable tech is boring, old, and everywhere</a></li>

<li><a href="https://www.theregister.com/2025/12/22/what_linux_desktop_really_needs/">What the Linux desktop really needs to challenge Windows</a></li>
</ul>
<p>Gregory Terzian, a Servo maintainer, <a target="_blank" rel="nofollow" href="https://news.ycombinator.com/item?id=46709191">responded</a>: "The actual code is worse; I can only describe it as a tangle of spaghetti... I can't make much, if anything, out of it." He then gave the backhanded compliment: "So I agree this isn't just wiring up of dependencies, and neither is it copied from existing implementations: it's a uniquely bad design that could never support anything resembling a real-world web engine." Now that's a burn.</p>
<p>From where I sit, what makes the Cursor case more dangerous than just a failed hack‑week project is that the hype is baked into its methodology. The "experiment" wasn't presented as what it really was: an interesting, but messy, internal learning exercise. No, it was rolled out as a milestone that conveniently confirmed the company's long‑running autonomous agent advertising. Missing from the story were basics any senior engineer would demand: passing Continuous Integration (CI), reproducible builds, and real benchmarks that show the browser doing more than limping through a hello-world page.</p>
<p>Zoom out, and CEOs are still predicting that AI will write 90 percent of code in a year, while most enterprise AI pilots still fail to deliver meaningful return on investment.</p>
<p>We're now in a kind of AI uncanny valley for developers. Sure, tools like Cursor can be genuinely helpful as glorified autocomplete and refactoring assistants, but marketing keeps insisting junior engineers can take whole projects from spec to shipping. When you start believing your own sizzle reel, you stop doing the tedious validation work that separates a demo from a deliverable.</p>
<p>Enough already. The hype has grown cold. Sarah Friar, OpenAI's CFO, recently blogged that in 2026, its focus would be on "<a target="_blank" href="https://www.theregister.com/2026/01/20/openai_money/">practical adoption</a>." Let's see real-world practical results first, and then we can talk about practical AI adoption. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: TetrisBench – Gemini Flash reaches 66% win rate on Tetris against Opus (106 pts)]]></title>
            <link>https://tetrisbench.com/tetrisbench/</link>
            <guid>46769752</guid>
            <pubDate>Mon, 26 Jan 2026 18:42:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tetrisbench.com/tetrisbench/">https://tetrisbench.com/tetrisbench/</a>, See on <a href="https://news.ycombinator.com/item?id=46769752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- Header -->
      <header>
        <a href="https://tetrisbench.com/">
          <span>←</span>
          <span>Back to Game</span>
        </a>
        
        
      </header>

      <!-- Subtitle -->
      <p>AI Model Tetris Performance Comparison</p>

      <!-- Stats Summary -->
      <div id="stats-summary">
        <p><span id="total-games">—</span>
          <span>Total Games</span>
        </p>
        <p><span id="total-models">—</span>
          <span>Models Tested</span>
        </p>
      </div>

      <!-- Model vs Model Matrix -->
      <section>
        <h2>
          <span>🤖</span>
          <span>MODEL VS MODEL</span>
        </h2>
        
        <div>
          <table id="benchmark-matrix">
            <thead id="matrix-header">
              <tr>
                <th>MODEL</th>
                <!-- Headers populated dynamically -->
              </tr>
            </thead>
            <tbody id="matrix-body">
              <!-- Rows populated dynamically -->
            </tbody>
          </table>
        </div>

        <!-- Loading State -->
        <div id="loading-state">
          
          <p>Loading benchmark data...</p>
        </div>

        <!-- Empty State -->
        

        <!-- Legend -->
        <div>
            <p><span>W</span>
              <span>-</span>
              <span>L</span>
              <span>-</span>
              <span>D</span>
            </p>
            <p><span>Wins - Losses - Draws</span>
          </p></div>
      </section>

      <!-- Navigation Links -->
      <div>
        <p><a href="https://tetrisbench.com/leaderboard">
          <span>🏆</span>
          <span>View Leaderboard</span>
        </a>
        <a href="https://tetrisbench.com/">
          <span>▶</span>
          <span>Play Tetris Battle</span>
        </a>
      </p></div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notice of collective action lawsuit against Workday, Inc. (116 pts)]]></title>
            <link>https://workdaycase.com</link>
            <guid>46769668</guid>
            <pubDate>Mon, 26 Jan 2026 18:37:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workdaycase.com">https://workdaycase.com</a>, See on <a href="https://news.ycombinator.com/item?id=46769668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="home-section"><div><div><p><span><img src="https://workdaycase.com/assets/images/image01.png?v=f1a8d860" alt=""></span></p><h2 id="text01">NOTICE OF COLLECTIVE ACTION LAWSUIT AGAINST WORKDAY, INC.</h2><h2 id="text03">TO: All individuals 40 years of age or older who, at any time from September 24, 2020 to the present, applied for job opportunities using Workday, Inc.’s job application platform.</h2><p id="text08">Re: Mobley v. Workday, Inc. Case No. 3:23-0770-RFL, Northern District of California.</p><p id="text11">Read:</p><div id="list02"><ol><li><p>INTRODUCTION</p></li><li><p>WHAT IS THIS LAWSUIT ABOUT</p></li><li><p>HOW TO JOIN THIS LAWSUIT</p></li><li><p>HOW WILL YOUR CLAIM BE HANDLED AND PROVEN?</p></li><li><p>LEGAL EFFECT OF OPTING IN TO JOIN THIS CASE</p></li><li><p>NO RETALIATION PERMITTED</p></li><li><p>YOUR LEGAL REPRESENTATION IF YOU JOIN</p></li></ol></div></div><div><h2 id="text07">OPT-IN CONSENT TO JOIN FORM</h2><p id="text09">The Age Discrimination in Employment Act of 1967</p><p id="text04"><span><strong>By submitting this form, I am consenting to join the collective action Mobley v. Workday, Inc., case number 3:23-cv-0770-RFL (“Lawsuit”), pending in the Northern District of California Federal Court, which includes claims under the Age Discrimination in Employment Act of 1967 (“ADEA”), and to be bound by the judgment of the Court.</strong></span><span><strong>By submitting this form, I confirm that on or after September 24, 2020, I applied for at least one employment opportunity using Workday’s application platform while I was 40 or more years old.</strong></span><span><strong>I am checking the box below as my signature for the Opt-In Consent To Join and as my authorization for it to be filed in the Northern District of California Federal Court on my behalf.</strong></span></p><div id="embed01"><unloaded-script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></unloaded-script><unloaded-script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[7]='DOB';ftypes[7]='text';fnames[3]='MMERGE3';ftypes[3]='address';fnames[0]='EMAIL';ftypes[0]='email';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';fnames[6]='MMERGE6';ftypes[6]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true); // SMS Phone Multi-Country Functionality if(!window.MC) { window.MC = {}; } window.MC.smsPhoneData = { defaultCountryCode: 'US', programs: [], smsProgramDataCountryNames: [] }; function getCountryUnicodeFlag(countryCode) { return countryCode.toUpperCase().replace(/./g, (char) =&gt;</unloaded-script></div></div></div><p id="INTRO"><span><strong>I. INTRODUCTION</strong><br> This notice and its contents have been authorized by the United States District Court for the Northern District of California. The Court has taken no position in this case regarding the merits of Plaintiffs’ claims or of Workday’s defenses.</span><span>The purpose of this notice is to provide notification of your following rights under the Age Discrimination in Employment Act (“ADEA”):</span></p><div id="list01"><ul><li><p>You have the right to join this lawsuit if you applied for employment opportunities using Workday’s application platform since September 24, 2020, while you were 40 or more years old.</p></li><li><p>To join this lawsuit you must fill out and electronically sign and send in the Opt-In Consent To Join Form by clicking submit on or before March 7, 2026. How to do that is explained more fully in this Section III of this notice.</p></li><li><p>You have the right to have the Plaintiffs’ attorneys represent you in connection with this case, and to contact them for advice or assistance regarding the Opt-In Form or regarding the case, at this link or via the email addresses and phone numbers listed below in Section V of this Notice</p></li></ul></div><p id="ABOUT"><span><strong>II. WHAT IS THIS LAWSUIT ABOUT?</strong><br> Derek Mobley (“Plaintiff”) filed this action against Workday, Inc. in the Northern District of California, Case No. 3:23-0770-RFL (“Lawsuit”), on behalf of himself and all others similarly situated. His allegations include that Workday, Inc., through its use of certain Artificial Intelligence (“AI”) features on its job application platform, violated the Age Discrimination in Employment Act (“ADEA”). Workday denies these allegations. The Court has not made any findings about whether Plaintiff’s claims or Workday’s denial of liability have any merit.</span><span>The Court has provisionally certified an ADEA collective, which includes: “All individuals aged 40 and over who, from September 24, 2020, through the present, applied for job opportunities using Workday, Inc.’s job application platform and were denied employment recommendations.” In this context, being “denied” an “employment recommendation” means that (i) the individual’s application was scored, sorted, ranked, or screened by Workday’s AI; (ii) the result of the AI scoring, sorting, ranking, or screening was not a recommendation to hire; and (iii) that result was communicated to the prospective employer, or the result was an automatic rejection by Workday.</span><span>Once you submit your Opt-In Consent to Join Form, the Court will subsequently need to determine that you meet the requirements described in the above paragraph in order for you to have the right to stay in the Lawsuit. However, all you need to know right now to opt-in to this case is that, on or after September 24, 2020, you applied for employment opportunities using Workday’s application platform while you were 40 or more years old.</span></p><p id="HOWTO"><span><strong>III. HOW TO JOIN THIS LAWSUIT</strong><br> To join this case, please complete, sign and return the Opt-In Consent To Join Form. If you have questions, you may contact the Plaintiffs’ attorneys by clicking submit or at the addresses and phone numbers provided below in Section V of this Notice.</span><span>If you are unable to sign and return the Opt-In Consent To Join Form electronically through this notice, you may obtain a paper copy of such forms to sign and return by mail, email, text or other delivery on or before March 7 2026. A paper copy can be downloaded and printed from this link or you can contact Plaintiffs’ attorneys to request such Forms by calling, emailing, texting or mailing them at the addresses or phone numbers provided below in Section V of this Notice. <strong>To join this case you must submit your Opt-In Consent To Join Form on or before March 7, 2026.</strong></span><span>The Opt-In Consent To Join Form requires that you sign page one and that you list your contact information and birthday on page two. Only page one will be publicly filed with the Court. Your contact information and birthday will not be filed with the Court as part of your initial opt-in to the case.</span></p><p id="HOWWILL"><span><strong>IV. HOW WILL YOUR CLAIM BE HANDLED AND PROVEN?</strong><br> After you submit your Opt-In Consent To Join Form to the Plaintiffs’ attorneys for filing, and unless and until you decide otherwise, they will continue to represent you as your counsel in this matter. As your legal representative, Plaintiffs’ attorneys can help you obtain the documents, testimony, and other evidence that you may need to show that you meet all the requirements necessary to litigate your claim as a party to this Lawsuit.<br> If you choose to join this case, you may be required, with the help of Plaintiffs’ attorneys, to answer written questions, produce documents related to your job application process, attend a deposition, and/or testify in court. Workday may also be required to answer written questions or produce documents related to its products to you. The Court has procedures that will protect your confidential information from public disclosure, including your birthday.</span></p><p id="LEGELEFFECTS"><span><strong>V. LEGAL EFFECT OF OPTING IN TO JOIN THIS CASE</strong><br> If you opt in to the Lawsuit, you will be bound by a favorable or unfavorable judgment on Plaintiffs’ ADEA claim. If you do not opt in, you will be precluded from future participation in the ADEA collective, including participation in any settlement related to the ADEA claim, but you may still bring your own separate lawsuit, depending on your situation. No ADEA collective has been finally certified, and you may still be dismissed from the case.</span></p><p id="NORETALI"><span><strong>VI. NO RETALIATION PERMITTED</strong><br> Federal law prohibits Workday from retaliating against you for opting in to this Lawsuit or otherwise exercising your rights.</span></p><p id="YOURLEGAL"><span><strong>VII. YOUR LEGAL REPRESENTATION IF YOU JOIN</strong><br> When you join this Lawsuit by electronically completing and sending the Opt-In Consent To Join Form, unless you decide otherwise, the lawyers representing you will be:</span></p><p id="text19"><span>You will not be responsible for paying any lawyers’ fees. Plaintiffs’ attorneys are being paid on contingency, which means that if Plaintiffs do not receive a recovery in this case, no lawyer fees will be owed. If Plaintiffs obtain a recovery, either by settlement or judgment, Plaintiffs’ attorneys may file a request with the Court to receive part of the recovery as compensation for their services.</span><span>If you want to join the Lawsuit, but prefer to retain your own attorney to represent you, you have the right to do so. You also have the right to represent yourself. <strong>To join this case you must submit the Opt-In Consent To Join Form with the Court on or before March 7, 2026.</strong></span></p><hr id="divider01"><p id="text13">PLEASE DO NOT CONTACT THE COURT WITH QUESTIONS ABOUT THIS LAWSUIT.</p><hr id="divider02"><p><span><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHg9IjAiIHk9IjAiIHZpZXdCb3g9IjAgMCAzODQwIDEzMzkiIHdpZHRoPSIzODQwIiBoZWlnaHQ9IjEzMzkiIHByZXNlcnZlQXNwZWN0UmF0aW89Im5vbmUiPjxyZWN0IGZpbGw9IiMyNDI1MWYiIHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiLz48L3N2Zz4%3D" data-src="assets/images/image02.jpg?v=f1a8d860" alt=""></span></p><hr id="divider03"></div><section id="done-section"><div id="container03"><p id="text06"><span>Almost there!<br> Check your inbox and click the confirmation link to complete your submission.<br> Don’t see the email? Check spam or promotions or contact <a href="https://workdaycase.com/cdn-cgi/l/email-protection" data-cfemail="563f383039162139243d32372f353725337835393b">[email&nbsp;protected]</a>.</span></p></div><ul id="icons01"><li><a href="https://workdaycase.com/cdn-cgi/l/email-protection#b6dfd8d0d9f6c1d9c4ddd2d7cfd5d7c5d398d5d9db" role="button"><svg aria-labelledby="icons01-icon-1-title"><title id="icons01-icon-1-title">Email</title><use xlink:href="#icon-c0646d28bbeb18e39eb973f96b44bd0f"></use></svg><span>Email</span></a></li><li><a href="https://www.facebook.com/people/Workday-Case/61584505757554/?sk=about" role="button"><svg aria-labelledby="icons01-icon-2-title"><title id="icons01-icon-2-title">Facebook</title><use xlink:href="#icon-a1eb5cac0cee3b05a40d856c98ce14a5"></use></svg><span>Facebook</span></a></li><li><a href="https://x.com/WorkdayCase" role="button"><svg aria-labelledby="icons01-icon-3-title"><title id="icons01-icon-3-title">X</title><use xlink:href="#icon-31b8880d36499db40d4e47546c4763f3"></use></svg><span>X</span></a></li><li><a href="https://www.instagram.com/workdaycase?igsh=NTc4MTIwNjQ2YQ%3D%3D&amp;utm_source=qr" role="button"><svg aria-labelledby="icons01-icon-4-title"><title id="icons01-icon-4-title">Instagram</title><use xlink:href="#icon-85976685de3e4af37529a1ce5d57d2a7"></use></svg><span>Instagram</span></a></li><li><a href="https://www.facebook.com/people/Workday-Case/61584505757554/?sk=about" role="button"><svg aria-labelledby="icons01-icon-5-title"><title id="icons01-icon-5-title">LinkedIn</title><use xlink:href="#icon-bf393d6ea48a4e69e1ed58a3563b94a5"></use></svg><span>LinkedIn</span></a></li></ul><p id="text05">PLEASE DO NOT CONTACT THE COURT WITH QUESTIONS ABOUT THIS LAWSUIT.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Books removed all search functions for any books with previews (213 pts)]]></title>
            <link>https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/</link>
            <guid>46769201</guid>
            <pubDate>Mon, 26 Jan 2026 18:05:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/">https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/</a>, See on <a href="https://news.ycombinator.com/item?id=46769201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Title. A few people have posted about this, but I figured out precisely what they did.</p>

<p>There are three kinds of view on google books: full view, snippet view and preview view. Full view is only for public domain books. For in copyright works, you have preview and snippet. Preview lets you see some full pages while snippet view lets you see a chunk and some sentences.</p>

<p>There was some change a month ago that knocked out a lot of books from search, and I am not entirely sure what that change was. But a few days ago they removed ALL search functions for any books with previews, which are disproportionately modern books. This has made Google Books effectively useless. Snippet view remains and is still searchable.</p>

<p>Bizarrely, if you check the individual books that used to have search function enabled - the previews are still there! You can read full pages! However, the search/OCR is completely turned off. You can search a word while staring at a page that has that word and it will tell you 0 results. They also did not turn off OCR/search for snippet view AND completely locked books.</p>

<p>I think this is extremely terrible as it makes finding books to buy extremely difficult. It also clearly isn't for copyright, as the previews are still there. I have no clue why they did this.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI code and software craft (218 pts)]]></title>
            <link>https://alexwennerberg.com/blog/2026-01-25-slop.html</link>
            <guid>46769188</guid>
            <pubDate>Mon, 26 Jan 2026 18:04:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexwennerberg.com/blog/2026-01-25-slop.html">https://alexwennerberg.com/blog/2026-01-25-slop.html</a>, See on <a href="https://news.ycombinator.com/item?id=46769188">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<span><time datetime="2026-01-25">Jan 25 2026</time></span> 

<p>Much has been said about audio, video and text "slop": low-quality,
AI-generated content that has proliferated on the internet since the release of
publicly-accessible AI models. Garbage content has always existed online, but
the novelty of AI is that it has made its generation orders of magnitude less labor-intensive.
For anyone who lacks a discerning eye, or is doing some task where discernment simply
does not matter, AI has become a sufficient replacement for human hands.</p>

<p>Jacques Ellul describes his concept of "technique" as the reduction of
activity to a set of efficient means to a measured and defined end — a
way of thinking dominant in modernity. <em>Technique</em> is the regime under which
    many things are produced online: an Instagram reel, YouTube
video, blog post, and so on is "good" if it elicits as much "engagement" as
possible with as little effort as possible. This is <em>technique</em> as 
a totalizing force, destroying any sense of craft, dignity, or human
freedom. It doesn't really matter what is being made, the purpose of the
endeavor is how much its creation is viewed, how much revenue it generates.
Obsession with metrics and outcomes erodes anything intangible about a creative effort,
like craft, beauty, or delight.</p>

<p>Taking music as an example, through the lens of <em>technique</em>, music is
"good" if it gets a lot of "plays". One can compare, for example, the operating
models of Bandcamp and Spotify, both of which have platform dynamics and a set
of values that have led to the production of certain kinds of music. For
Bandcamp, its focus on full albums and personal curation contributed to the
indie music boom of the 2010s/2020s and uplifted artists like Car Seat Headrest,
Mitski, Alex G, Phoebe Bridgers,
and others. For Spotify, its playlist and algorithmic recommendation based
model has spawned a wave of <a href="https://www.theguardian.com/commentisfree/2025/mar/09/spotify-algorithm-artists-music-musicians-money-songs-playlists">bland,
algorithmically-targeted muzak</a>. This is because Spotify's model doesn't
care about music, it cares about metrics: music is simply a means to
optimizing certain outputs. It is in this environment where AI is most successful — a nihilistic space of pure optimization. When craft is not a consideration, AI can produce a large volume of "good enough" content that has a much higher "profit maximization" function than actually human-produced music. On the other hand, for a platform whose primary goal is, well, music, AI is actively hostile, to the point that Bandcamp has <a href="https://blog.bandcamp.com/2026/01/13/keeping-bandcamp-human/">banned
it</a>.</p>

<p>A similar dynamic is taking place in the world of software. Even before the advent of AI, a lot of software was extremely low-quality. People have said that software engineering at large
tech companies resembles "plumbing" — connecting various systems
together in order to get data to flow between them. Any sense of what Richard
Hamming would call "<a href="https://worrydream.com/HammingForeword/">great
work</a>", where engineers produce "gifts to humanity" seems absurdly high-minded in the context of the
tech industry as constituted today. Most large software systems are bad: bloated, poorly-designed,
badly-documented, and so on. Users are at war with platforms, lest they be taken advantage in the process of <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification</a>. I essentially agree with Jonathan Blow's
characterization in his talk <a href="https://www.youtube.com/watch?v=ZSRHeXYDLko">Preventing the Collapse of
[Software] Civilization</a> — more than anything, professional engineers and large software companies
have <em>forgotten how to do things</em>. In an environment largely insulated from market pressures by
<a href="https://scholarship.law.columbia.edu/books/63/">non-competitive monopolies</a>, software practices have become shoddy, organizations have
become bloated, and quality has suffered greatly as a result.
Engineers in Big Tech tend to have an extremely narrow role within a large
organization, and broader engineering skills (much less a sense of craft, which largely is not rewarded) atrophy.</p>

<p>A business, or society's, capacity to do things with computers depends on its
human capital, i.e., cultivating broadly-skilled and talented engineers. The
extreme division of labor and narrowness of tasks in large tech companies leads
to a production of relatively narrowly skilled people, i.e., people who are only
really capable of operating within big tech companies as they are structured today.</p>

<p>This has led to two separate phenomena. First, the very real sense that AI
agents are threatening to professional software engineering. This may be true
to some degree: for engineers whose roles have become rote and narrow
production of low-quality software (ie, many employees at large tech companies),
AI is actually quite good at this. But the second phenomenon is the celebration
and generalization of the broader capabilities of AI agents, the idea that AI can do "<a href="https://moguldom.com/464672/ai-could-do-most-maybe-all-coding-within-6-12-months-warns-anthropic-ceo/">most,
maybe all</a>" of software engineering, or that AI is "<a href="https://www.infoworld.com/article/4096265/writing-code-is-so-over.html">like a compiler</a>" that translates human language into code.</p>

<p>This being true requires an extreme narrowness of vision as to what software
is, much like AI generated music requires a narrowness of vision of what music
is. It requires software merely to be a means to an end, an endeavor where the
only thing that matters is that something is "good enough" given the
institutional contexts in which it is being created, where there is no place
for higher-minded ideals. I've experimented a lot with AI agents lately<sup><a href="#fn1" id="fnref1">1</a></sup>, and they are
undeniably useful, but there are serious limits. They will lie to you, they
don't really understand things, and they often generate bad code. There are
many things they've improved at, and I do expect them to get better in some
domains, but much like with music, text, or anything else, there are
fundamental limitations. AI agents do not have a mind of their own, and they
cannot read your mind. They work best when you give them some well-defined
prompt for an already often-solved problem like "write some unit tests" or
"write a db function like this". But attempts to generalize their capabilities have 
<a href="https://lucumr.pocoo.org/2026/1/18/agent-psychosis/">largely failed</a> and produced code that is novel and impressive <a href="https://steve-yegge.medium.com/welcome-to-gas-town-4f25ee16dd04">only in its monstrosity</a>.

</p><p>Furthermore, after being initially impressed by "vibe coding," I started to
get frustrated with its tics. It produces verbose code in a braindead style.
Its designs are flat and ugly, and I have begun to notice and find unpleasant
its tells<sup><a href="#fn2" id="fnref2">2</a></sup>. When things go wrong, I'm generally
coding in such a mindless state, watching a YouTube video or scrolling Instagram, that
debugging is a frustrating loop of repeatedly telling agents "no, there's a
bug, please fix it."</p>

<p>It is true that most code simply is not very good, especially at large
companies. And we can continue to do not very good software much more quickly
and effectively with AI. But AI cannot solve the main systemic problem in the
software industry, which is that, in my view, we still haven't quite figured
out how to build software well at scale. But to do this requires a sense of craft and real human critical thought.</p>
                                                                                                                                                                                                                                                          
<p>I've been interested lately in the <a href="https://en.wikipedia.org/wiki/Arts_and_Crafts_movement">Arts and
Crafts</a> movement of the second industrial revolution. John Ruskin and
William Morris were responding to a time when the capabilities of machines and
industrial production were extremely impressive, and increasingly replacing the
individual craftsman. They did not celebrate this, rather, they viewed
industrial production as having a particular <em>style</em> in both its goods
and its impact on workers, who had become cogs in a
monstrous industrial machine. They correctly noted that there were things that
machines could not do (and still can't do), and looked backwards towards a
revival of medieval craftsmanship for inspiration.</p>

<p>In my view, we need a similar movement in software, studying and restoring
earlier forms of computing. There is a whole treasure trove of ideas that never
really went anywhere, and software projects that are impressive and beautiful
in a way that today's software is often not. We find ourselves on a very narrow
branch of a tree of technological development (from C/Unix to Javascript/The
Web) and there is a lot more out there to explore<sup><a href="#fn3" id="fnref3">3</a></sup>. Once you're doing something even somewhat
non-conventional, you'll find yourself almost entirely discarding AI. I tried
to get Claude to help me write Forth, and it was worse than useless.</p>

<p>AI code may make garbage,
mass-produced software more ubiquitous, but it may also free up a space for
engineers seeking to restore a genuine sense of craft and creative expression
in their programming work. I am not pessimistic here; as craft becomes
more scarce, it also becomes more valuable. As mainstream
software continues to demonstrate its limits, software continues to degrade, and <a href="https://european-alternatives.eu/categories">political concerns</a> lead people to question the value of centralization, it is a great moment for experimental, human-made and human-scale software on the margins to shine.</p>

<hr>

<p id="fn1"><sup>1</sup> If you think I am anti-AI, I consider myself much more of an "AI centrist", and speaking to some people, even the admission that I use and pay for these models is morally compromising. My critical position, is, in my view, more moderate. <a href="#fnref1">↩</a></p>
<p id="fn2"><sup>2</sup> Overly-padded buttons, inconsistent spacing and coloring, an aesthetic flatness, UI elements of questionable utility, and a tendency to unnecessarily <a href="https://x.com/reactjpg/status/1415542684744249344">label and describe everything</a>. <a href="#fnref2">↩</a></p>
<p id="fn3"><sup>3</sup> I recommend the <a href="https://permacomputing.net/">Permacomputing</a> Wiki to get started. <a href="#fnref3">↩</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fedora Asahi Remix is now working on Apple M3 (551 pts)]]></title>
            <link>https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o</link>
            <guid>46769051</guid>
            <pubDate>Mon, 26 Jan 2026 17:54:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o">https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o</a>, See on <a href="https://news.ycombinator.com/item?id=46769051">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[JuiceSSH – Give me my pro features back (347 pts)]]></title>
            <link>https://nproject.io/blog/juicessh-give-me-back-my-pro-features/</link>
            <guid>46768909</guid>
            <pubDate>Mon, 26 Jan 2026 17:46:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nproject.io/blog/juicessh-give-me-back-my-pro-features/">https://nproject.io/blog/juicessh-give-me-back-my-pro-features/</a>, See on <a href="https://news.ycombinator.com/item?id=46768909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              <p>JuiceSSH used to be the best SSH client available on Android until December 2025.</p><p>Since then, the purchase made in 2019 is not recognized anymore, and the price went up by 20$. Some users complain in review that after buying it again, the application doesn't get activated. Support is unresponsive, this looks like an exit scam.</p><p>Below is a way to make the application work again. This required <a href="https://github.com/skylot/jadx" rel="noreferrer">jadx</a> to understand smali, and will require you <a href="https://github.com/iBotPeaches/Apktool" rel="noreferrer">ApkTool</a> and jarsigner, which is part of OpenJDK, and you that can install on Windows using <code>choco install openjdk</code>.</p><p>You'll also need a JuiceSSH apk, I downloaded one from <a href="https://apkpure.com/fr/juicessh-ssh-client/com.sonelli.juicessh/download" rel="noreferrer">PureAPK</a>, but feel free to dump your own from your device using adb if you cannot find it. Make sure to verify the hash using virus total/sha256sum if downloading from internet, which should be <code>d1ee811bcd82f25aea0bdc568896d82017ee174d9c4631c123a9d9173c748232</code> for the last version available, version 3.2.2.</p><p>Below are powershell version of the command lines, but you get the idea.</p><h2 id="decompile">Decompile</h2><p>The first step is to decompile the dex packed code from the apk.</p><pre><code>&amp; "C:\Program Files\OpenJDK\jdk-25\bin\java.exe" -jar d juicessh.apk
</code></pre><h2 id="modify-smali">Modify smali</h2><p>You then need to modify the smali of three files, which are detailed below.</p><h3 id="smalicomsonellijuicesshmodelsusersmali">smali/com/sonelli/juicessh/models/User.smali</h3><p>In this file, we'll patch the purchase validation and signature validation, done by the <code>public boolean H()</code> function.</p><p>Here is the original version.</p><pre><code>public boolean H() {
    try {
        String str = "";
        ArrayList arrayList = new ArrayList();
        for (Purchase purchase : this.purchases) {
            if (!arrayList.contains(purchase.order)) {
                str = str + purchase.product + purchase.state;
                arrayList.add(purchase.order);
            }
        }
        return vg0.b(this.signature, this.sessionIdentifier + this.name + this.email + str + this.disabled.toString());
    } catch (IllegalStateException e) {
        e.printStackTrace();
        return false;
    }
}</code></pre><p>Which we'll simply change into</p><pre><code>public boolean H() {
    return true;
}</code></pre><pre><code># virtual methods
.method public H()Z
    .locals 1

    const/4 v0, 0x1
    return v0
.end method</code></pre><h3 id="smalicomsonellioi0smali">smali/com/sonelli/oi0.smali</h3><p>In this one, we'll patch the <code>public static boolean d(Object obj)</code> function, who calls the H() function we modified above, which now returns true, filters product matching JuiceSSH in purchases list, and check if it the purchase is valid. We'll simply make it return true in any case.</p><p>Here is the original version:</p><pre><code>public static boolean d(Object obj) {
    if (!obj.getClass().getName().equals(User.class.getName())) {
        return false;
    }
    try {
        if (!((User) obj).H()) {
            return false;
        }
        ArrayList arrayList = new ArrayList();
        for (Purchase purchase : ((User) obj).purchases) {
            if (purchase.product.equals(a())) {
                arrayList.add(purchase);
            }
        }
        Collections.sort(arrayList, new a());
        if (arrayList.size() &gt; 0) {
            if (((Purchase) arrayList.get(arrayList.size() - 1)).state.intValue() == 0) {
                return true;
            }
        }
        return false;
    } catch (NullPointerException e) {
        e.printStackTrace();
        return false;
    }
}</code></pre><p>Here is the patched one:</p><pre><code>public static boolean d(Object obj) {
    return obj.getClass().getName().equals(User.class.getName());
}</code></pre><pre><code>.method public static d(Ljava/lang/Object;)Z
    .locals 3

    # obj.getClass()
    invoke-virtual {p0}, Ljava/lang/Object;-&gt;getClass()Ljava/lang/Class;
    move-result-object v0

    # obj.getClass().getName()
    invoke-virtual {v0}, Ljava/lang/Class;-&gt;getName()Ljava/lang/String;
    move-result-object v0

    # User.class
    const-class v1, Lcom/sonelli/juicessh/models/User;

    # User.class.getName()
    invoke-virtual {v1}, Ljava/lang/Class;-&gt;getName()Ljava/lang/String;
    move-result-object v1

    # compare strings
    invoke-virtual {v0, v1}, Ljava/lang/String;-&gt;equals(Ljava/lang/Object;)Z
    move-result v2

    if-nez v2, :cond_true

    const/4 v0, 0x0
    return v0

    :cond_true
    const/4 v0, 0x1
    return v0
.end method</code></pre><h3 id="smalicomsonellipi0smali">smali/com/sonelli/pi0.smali</h3><p>Finally, we'll patch the central part of the authentication, which is called each time a pro-feature is triggered to ensure user has valid license, the <code>public static void j(Context context, p pVar)</code> function.</p><p>Here is the original version:</p><pre><code>public static void j(Context context, p pVar) {
    User user;
    User user2;
    String strS = User.s(context);
    if (strS == null) {
        pVar.a(context.getString(R$string.authentication_failure));
        return;
    }
    if (strS.equals("New User")) {
        pVar.a("New User");
        return;
    }
    User user3 = b;
    if (user3 != null &amp;&amp; !user3.disabled.booleanValue()) {
        long jCurrentTimeMillis = System.currentTimeMillis() - b.modified;
        DateUtils.getRelativeTimeSpanString(System.currentTimeMillis() + (b.w() * 1000), System.currentTimeMillis(), 0L, 0);
        DateUtils.getRelativeTimeSpanString(System.currentTimeMillis() + (3600000 - jCurrentTimeMillis), System.currentTimeMillis(), 0L, 0);
        if (b.w() &lt;= 0) {
            gj0.b("API", "Cached user's API session has expired - refreshing session...");
            e(context, null, b.sessionIdentifier, pVar);
            return;
        }
        pVar.b(b);
        if (jCurrentTimeMillis &lt;= 3600000 || context == null || (user2 = b) == null) {
            return;
        }
        e(context, null, user2.sessionIdentifier, null);
        return;
    }
    User userA = User.A(context);
    if (userA == null || userA.disabled.booleanValue() || !userA.H()) {
        e(context, null, null, pVar);
        return;
    }
    b = userA;
    if (userA.w() &lt;= 0) {
        e(context, null, b.sessionIdentifier, pVar);
        return;
    }
    pVar.b(b);
    if (context == null || (user = b) == null) {
        return;
    }
    e(context, null, user.sessionIdentifier, null);
}</code></pre><p><code>pVar.b()</code> is the success callback we'll call while <code>e()</code> is called in case of error. b is the globally stored user we'll have to set. To patch this, we'll simply craft a User with meaningless data, a session expire always in future, save the user in b, and call the success callback every time.</p><pre><code>public static void j(Context context, p pVar) {
    User user = new User();
    user.email = "myemail@google.com";
    user.name = "hello";
    user.given_name = "hello";
    user.sessionExpires = System.currentTimeMillis() + (86400000 * 365);
    user.sessionIdentifier = "";
    b = user;
    pVar.b(user);
}</code></pre><pre><code>.method public static j(Landroid/content/Context;Lcom/sonelli/pi0$p;)V
    .locals 8

    # User u = new User();
    new-instance v0, Lcom/sonelli/juicessh/models/User;
    invoke-direct {v0}, Lcom/sonelli/juicessh/models/User;-&gt;&lt;init&gt;()V

    # u.email = "myemail@google.com";
    const-string v1, "myemail@google.com"
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;email:Ljava/lang/String;

    # u.name = "hello";
    const-string v1, "hello"
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;name:Ljava/lang/String;

    # u.given_name = "hello";
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;given_name:Ljava/lang/String;

    # long now = System.currentTimeMillis();
    invoke-static {}, Ljava/lang/System;-&gt;currentTimeMillis()J
    move-result-wide v2

    # yearMillis = 86400000L * 365L
    const-wide/32 v4, 0x05265c00      # 86400000
    const-wide/16 v6, 0x016d          # 365
    mul-long/2addr v4, v6

    # u.sessionExpires = now + yearMillis;
    add-long/2addr v2, v4
    iput-wide v2, v0, Lcom/sonelli/juicessh/models/User;-&gt;sessionExpires:J

    # u.sessionIdentifier = ""
    const-string v1, ""
    iput-object v1, v0, Lcom/sonelli/juicessh/models/User;-&gt;sessionIdentifier:Ljava/lang/String;

    # pi0.b = u;
    sput-object v0, Lcom/sonelli/pi0;-&gt;b:Lcom/sonelli/juicessh/models/User;

    # pVar.b(b);
    invoke-virtual {p1, v0}, Lcom/sonelli/pi0$p;-&gt;b(Lcom/sonelli/juicessh/models/User;)V

    return-void</code></pre><h2 id="recompile">Recompile</h2><pre><code>&amp; "C:\Program Files\OpenJDK\jdk-25\bin\java.exe" -jar .\apktool_2.12.1.jar juicessh</code></pre><h2 id="sign-the-apk">Sign the apk</h2><pre><code># Create a keystore if needed to self sign the APK
keytool -genkey -v -keystore k.keystore -alias a -keyalg RSA -keysize 2048 -validity 50000

# Sign the APK
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore k.keystore ./juicessh/dist/juicessh.apk a</code></pre><h2 id="done">Done</h2><p>You can install this apk, ignore the security warning because it is self signed, and enjoy JuiceSSH with its pro features again.</p><p>I don't think the cloud sync will work anymore, but that's a minor inconvenience. The plugins don't work anymore too, which is really a joke.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Adolescence of Technology (206 pts)]]></title>
            <link>https://www.darioamodei.com/essay/the-adolescence-of-technology</link>
            <guid>46768257</guid>
            <pubDate>Mon, 26 Jan 2026 17:07:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.darioamodei.com/essay/the-adolescence-of-technology">https://www.darioamodei.com/essay/the-adolescence-of-technology</a>, See on <a href="https://news.ycombinator.com/item?id=46768257">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><section data-footnotes="body"><p><h2>The Adolescence of Technology <sup></sup></h2></p><p>Confronting and Overcoming the Risks of Powerful AI</p><p>January 2026</p><div id="main-content" data-toc-contents=""><p>There is a scene in the movie version of Carl Sagan’s book <em>Contact </em>where the main character, an astronomer who has detected the first radio signal from an alien civilization, is being considered for the role of humanity’s representative to meet the aliens. The international panel interviewing her asks, “If you could ask [the aliens] just one question, what would it be?” Her reply is: “I’d ask them, ‘How did you do it? How did you evolve, how did you survive this technological adolescence without destroying yourself?” When I think about where humanity is now with AI—about what we’re on the cusp of—my mind keeps going back to that scene, because the question is so apt for our current situation, and I wish we had the aliens’ answer to guide us. I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species. Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.</p><p>In my essay <a href="https://darioamodei.com/machines-of-loving-grace"><em>Machines of Loving Grace</em></a>, I tried to lay out the dream of a civilization that had made it through to adulthood, where the risks had been addressed and powerful AI was applied with skill and compassion to raise the quality of life for everyone. I suggested that AI could contribute to enormous advances in biology, neuroscience, economic development, global peace, and work and meaning. I felt it was important to give people something inspiring to fight for, a task at which both AI accelerationists and AI safety advocates seemed—oddly—to have failed. But in this current essay, I want to confront the rite of passage itself: to map out the risks that we are about to face and try to begin making a battle plan to defeat them. I believe deeply in our ability to prevail, in humanity’s spirit and its nobility, but we must face the situation squarely and without illusions.</p><p>As with talking about the benefits, I think it is important to discuss risks in a careful and well-considered manner. In particular, I think it is critical to:</p><ul role="list"><li> <strong>Avoid doomerism. </strong>Here,<strong> </strong>I mean “doomerism” not just in the sense of believing doom is inevitable (which is both a false and self-fulfilling belief), but more generally, thinking about AI risks in a quasi-religious way.<sup>1</sup> Many people have been thinking in an analytic and sober way about AI risks for many years, but it’s my impression that during the peak of worries about AI risk in 2023–2024, some of the least sensible voices rose to the top, often through sensationalistic social media accounts. These voices used off-putting language reminiscent of religion or science fiction, and called for extreme actions without having the evidence that would justify them. It was clear even then that a backlash was inevitable, and that the issue would become culturally polarized and therefore gridlocked.<sup>2</sup> As of 2025–2026, the pendulum has swung, and AI opportunity, not AI risk, is driving many political decisions. This vacillation is unfortunate, as the technology itself doesn’t care about what is fashionable, and we are considerably closer to real danger in 2026 than we were in 2023. The lesson is that we need to discuss and address risks in a realistic, pragmatic manner: sober, fact-based, and well equipped to survive changing tides.</li><li> <strong>Acknowledge uncertainty. </strong>There are plenty of ways in which the concerns I’m raising in this piece could be moot. Nothing here is intended to communicate certainty or even likelihood. Most obviously, AI may simply not advance anywhere near as fast as I imagine.<sup>3</sup> Or, even if it does advance quickly, some or all of the risks discussed here may not materialize (which would be great), or there may be other risks I haven’t considered. No one can predict the future with complete confidence—but we have to do the best we can to plan anyway.</li><li> <strong>Intervene as surgically as possible. </strong>Addressing the risks of AI will require a mix of voluntary actions taken by companies (and private third-party actors) and actions taken by governments that bind everyone. The voluntary actions—both taking them and encouraging other companies to follow suit—are a no-brainer for me. I firmly believe that government actions will also be required <em>to some extent</em>, but these interventions are different in character because they can potentially destroy economic value or coerce unwilling actors who are skeptical of these risks (and there is some chance they are right!). It’s also common for regulations to backfire or worsen the problem they are intended to solve (and this is even more true for rapidly changing technologies). It’s thus very important for regulations to be judicious: they should seek to avoid collateral damage, be as simple as possible, and impose the least burden necessary to get the job done.<sup>4</sup> It is easy to say, “No action is too extreme when the fate of humanity is at stake!,” but in practice this attitude simply leads to backlash. To be clear, I think there’s a decent chance we eventually reach a point where much more significant action is warranted, but that will depend on stronger evidence of imminent, concrete danger than we have today, as well as enough specificity about the danger to formulate rules that have a chance of addressing it. The most constructive thing we can do today is advocate for limited rules while we learn whether or not there is evidence to support stronger ones.<sup>5</sup></li></ul><p>With all that said, I think the best starting place for talking about AI’s risks is the same place I started from in talking about its benefits: by being precise about what level of AI we are talking about. The level of AI that raises civilizational concerns for me is the <em>powerful AI </em>that I described in <em>Machines of Loving Grace. </em>I’ll simply repeat here the definition that I gave in that document:</p><p>&lt;blockquote&gt;</p><p>By “powerful AI,” I have in mind an AI model—likely similar to today’s LLMs in form, though it might be based on a different architecture, might involve several interacting models, and might be trained differently—with the following properties:</p><ul role="list"><li>In terms of pure intelligence, it is smarter than a Nobel Prize winner across most relevant fields: biology, programming, math, engineering, writing, etc. This means it can prove unsolved mathematical theorems, write extremely good novels, write difficult codebases from scratch, etc.</li><li> In addition to just being a “smart thing you talk to,” it has all the interfaces available to a human working virtually, including text, audio, video, mouse and keyboard control, and internet access. It can engage in any actions, communications, or remote operations enabled by this interface, including taking actions on the internet, taking or giving directions to humans, ordering materials, directing experiments, watching videos, making videos, and so on. It does all of these tasks with, again, a skill exceeding that of the most capable humans in the world.</li><li>It does not just passively answer questions; instead, it can be given tasks that take hours, days, or weeks to complete, and then goes off and does those tasks autonomously, in the way a smart employee would, asking for clarification as necessary.</li><li>It does not have a physical embodiment (other than living on a computer screen), but it can control existing physical tools, robots, or laboratory equipment through a computer; in theory, it could even design robots or equipment for itself to use.</li><li> The resources used to train the model can be repurposed to run millions of instances of it (this matches projected cluster sizes by ~2027), and the model can absorb information and generate actions at roughly 10–100x human speed. It may, however, be limited by the response time of the physical world or of software it interacts with.</li><li>Each of these million copies can act independently on unrelated tasks, or, if needed can all work together in the same way humans would collaborate, perhaps with different subpopulations fine-tuned to be especially good at particular tasks.</li></ul><p>We could summarize this as a “country of geniuses in a datacenter.”</p><p>&lt;/blockquote&gt;</p><p>As I wrote in <em>Machines of Loving Grace</em>, powerful AI could be as little as 1–2 years away, although it could also be considerably further out.<sup>6</sup> Exactly when powerful AI will arrive is a complex topic that deserves an essay of its own, but for now I’ll simply explain very briefly why I think there’s a strong chance it could be very soon.</p><p>My co-founders at Anthropic and I were among the first to document and track the “<a href="https://arxiv.org/abs/2001.08361">scaling laws</a>” of AI systems—the observation that as we add more compute and training tasks, AI systems get predictably better at essentially every cognitive skill we are able to measure. Every few months, public sentiment either becomes convinced that AI is “<a href="https://edition.cnn.com/2024/11/19/business/ai-chatgpt-nvidia-nightcap">hitting</a> a <a href="https://www.ft.com/content/d01290c9-cc92-4c1f-bd70-ac332cd40f94">wall</a>” or becomes excited about some new breakthrough that will “fundamentally change the game,” but the truth is that behind the volatility and public speculation, there has been a smooth, unyielding increase in AI’s cognitive capabilities.</p><p>We are now at the point where AI models are beginning to make progress in solving unsolved mathematical problems, and are good enough at coding that some of the strongest engineers I’ve ever met are now handing over almost all their coding to AI. Three years ago, AI <a href="https://arxiv.org/abs/2005.14165">struggled with elementary school arithmetic problems</a> and was barely capable of writing a single line of code. Similar rates of improvement are occurring across <a href="https://www.anthropic.com/news/accelerating-scientific-research">biological science</a>, finance, physics, and a variety of agentic tasks. If the exponential continues—which is not certain, but now has a decade-long track record supporting it—then it cannot possibly be more than a few years before AI is better than humans at essentially everything.</p><p>In fact, that picture probably underestimates the likely rate of progress. Because AI is now <a href="https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic">writing much of the code at Anthropic</a>, it is already substantially accelerating the rate of our progress in building the next generation of AI systems. This feedback loop is gathering steam month by month, and may be only 1–2 years away from a point where the current generation of AI autonomously builds the next. This loop has already started, and will accelerate rapidly in the coming months and years. Watching the last 5 years of progress from within Anthropic, and looking at how even the next few months of models are shaping up, I can <em>feel </em>the pace of progress, and the clock ticking down.</p><p>In this essay, I’ll assume that this intuition is at least <em>somewhat </em>correct—not that powerful AI is definitely coming in 1–2 years,<sup>7</sup> but that there’s a decent chance it does, and a very strong chance it comes in the next few. As with <em>Machines of Loving Grace</em>, taking this premise seriously can lead to some surprising and eerie conclusions. While in <em>Machines of Loving Grace </em>I focused on the positive implications of this premise, here the things I talk about will be disquieting. They are conclusions that we may not want to confront, but that does not make them any less real. I can only say that I am focused day and night on how to steer us away from these negative outcomes and towards the positive ones, and in this essay I talk in great detail about how best to do so.</p><p>I think the best way to get a handle on the risks of AI is to ask the following question: suppose a literal “country of geniuses” were to materialize somewhere in the world in ~2027. Imagine, say, 50 million people, all of whom are much more capable than any Nobel Prize winner, statesman, or technologist. The analogy is not perfect, because these geniuses could have an extremely wide range of motivations and behavior, from completely pliant and obedient, to strange and alien in their motivations. But sticking with the analogy for now, suppose you were the national security advisor of a major state, responsible for assessing and responding to the situation. Imagine, further, that because AI systems can operate hundreds of times faster than humans, this “country” is operating with a time advantage relative to all other countries: for every cognitive action we can take, this country can take ten. </p><p>What should you be worried about? I would worry about the following things:</p><ol start="1" role="list"><li><strong>Autonomy risks. </strong>What are the intentions and goals of this country? Is it hostile, or does it share our values? Could it militarily dominate the world through superior weapons, cyber operations, influence operations, or manufacturing?</li><li> <strong>Misuse for destruction. </strong>Assume the new country is malleable and “follows instructions”—and thus is essentially a country of mercenaries. Could existing rogue actors who want to cause destruction (such as terrorists) use or manipulate some of the people in the new country to make themselves much more effective, greatly amplifying the scale of destruction?</li><li><strong>Misuse for seizing power. </strong>What if the country was in fact built and controlled by an existing powerful actor, such as a dictator or rogue corporate actor? Could that actor use it to gain decisive or dominant power over the world as a whole, upsetting the existing balance of power?</li><li> <strong>Economic disruption. </strong>If the new country is not a security threat in any of the ways listed in #1–3 above but simply participates peacefully in the global economy, could it still create severe risks simply by being so technologically advanced and effective that it disrupts the global economy, causing mass unemployment or radically concentrating wealth?</li><li><strong>Indirect effects. </strong>The world will change very quickly due to all the new technology and productivity that will be created by the new country. Could some of these changes be radically destabilizing?</li></ol><p>I think it should be clear that this is a dangerous situation—a report from a competent national security official to a head of state would probably contain words like “the single most serious national security threat we’ve faced in a century, possibly ever.” It seems like something the best minds of civilization should be focused on.</p><p>Conversely, I think it would be absurd to shrug and say, “Nothing to worry about here!” But, faced with rapid AI progress, that seems to be the view of many US policymakers, some of whom deny the existence of any AI risks, when they are not distracted entirely by the usual tired old hot-button issues.<sup>8</sup> Humanity needs to wake up, and this essay is an attempt—a possibly futile one, but it’s worth trying—to jolt people awake.</p><p>To be clear, I believe if we act decisively and carefully, the risks can be overcome—I would even say our odds are good. And there’s a hugely better world on the other side of it. But we need to understand that this is a serious civilizational challenge. Below, I go through the five categories of risk laid out above, along with my thoughts on how to address them.</p><h2>1. I<strong>’</strong>m sorry, Dave</h2><h3><em>Autonomy risks</em></h3><p>A country of geniuses in a datacenter could divide their efforts among software design, cyber operations, R&amp;D for physical technologies, relationship building, and statecraft. It is clear that, <em>if for some reason it chose to do so</em>, this country would have a fairly good shot at taking over the world (either militarily or in terms of influence and control) and imposing its will on everyone else—or doing any number of other things that the rest of the world doesn’t want and can’t stop. We’ve obviously been worried about this for human countries (such as Nazi Germany or the Soviet Union), so it stands to reason that the same is possible for a much smarter and more capable “AI country.” </p><p>The best possible counterargument is that the AI geniuses, under my definition, won’t have a physical embodiment, but remember that they can take control of existing robotic infrastructure (such as self-driving cars) and can also accelerate robotics R&amp;D or build a fleet of robots.<sup>9</sup> It’s also unclear whether having a physical presence is even necessary for effective control: plenty of human action is already performed on behalf of people whom the actor has not physically met.</p><p>The key question, then, is the “if it chose to” part: what’s the likelihood that our AI models would behave in such a way, and under what conditions would they do so?</p><p>As with many issues, it’s helpful to think through the spectrum of possible answers to this question by considering two opposite positions. The first position is that this simply can’t happen, because the AI models will be trained to do what humans ask them to do, and it’s therefore absurd to imagine that they would do something dangerous unprompted. According to this line of thinking, we don’t worry about a Roomba or a model airplane going rogue and murdering people because there is nowhere for such impulses to come from,<sup>10</sup> so why should we worry about it for AI? The problem with this position is that there is now ample evidence, collected over the last few years, that AI systems are unpredictable and difficult to control— we’ve seen behaviors as varied as obsessions,<sup>11</sup> <a href="https://arxiv.org/abs/2310.13548">sycophancy</a>, <a href="https://arxiv.org/abs/2305.17256">laziness</a>, <a href="https://www.anthropic.com/research/alignment-faking">deception</a>, <a href="https://www.anthropic.com/research/agentic-misalignment">blackmail</a>, <a href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/">scheming</a>, “<a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking">cheating</a>” by hacking software environments, and <a href="https://www.anthropic.com/claude-opus-4-5-system-card">much more</a>. AI companies certainly <em>want </em>to train AI systems to follow human instructions (perhaps with the exception of dangerous or illegal tasks), but the process of doing so is more an art than a science, more akin to <a href="https://www.darioamodei.com/post/the-urgency-of-interpretability">“growing” something than “building” it</a>. We now know that it’s a process where many things can go wrong.</p><p>The second, opposite position, held by many who adopt the doomerism I described above, is the pessimistic claim that there are certain dynamics in the training process of powerful AI systems that will inevitably lead them to seek power or deceive humans. Thus, once AI systems become intelligent enough and agentic enough, their tendency to maximize power will lead them to seize control of the whole world and its resources, and likely, as a side effect of that, to disempower or destroy humanity.</p><p>The usual argument for this (which goes back <a href="https://selfawaresystems.com/wp-content/uploads/2008/01/ai_drives_final.pdf">at least 20 years</a> and probably much earlier) is that if an AI model is trained in a wide variety of environments to agentically achieve a wide variety of goals—for example, writing an app, proving a theorem, designing a drug, etc.—there are certain common strategies that help with all of these goals, and one key strategy is gaining <a href="https://en.wikipedia.org/wiki/Instrumental_convergence">as much power as possible</a> in any environment. So, after being trained on a large number of diverse environments that involve reasoning about how to accomplish very expansive tasks, and where power-seeking is an effective method for accomplishing those tasks, the AI model will “generalize the lesson,” and develop either an inherent tendency to seek power, or a tendency to reason about each task it is given in a way that predictably causes it to seek power as a means to accomplish that task. They will then apply that tendency to the real world (which to them is just another task), and will seek power in it, at the expense of humans. This “misaligned power-seeking” is the intellectual basis of predictions that AI will inevitably destroy humanity.</p><p>The problem with this pessimistic position is that it mistakes a vague conceptual argument about high-level incentives—one that masks many hidden assumptions—for definitive proof. I think people who don’t build AI systems every day are wildly miscalibrated on how easy it is for clean-sounding stories to end up being wrong, and how difficult it is to predict AI behavior from first principles, especially when it involves reasoning about generalization over millions of environments (which has over and over again proved mysterious and unpredictable). Dealing with the messiness of AI systems for over a decade has made me somewhat skeptical of this overly theoretical mode of thinking.</p><p>One of the most important hidden assumptions, and a place where what we see in practice has diverged from the simple theoretical model, is the implicit assumption that AI models are necessarily monomaniacally focused on a single, coherent, narrow goal, and that they pursue that goal in a clean, consequentialist manner. In fact, our researchers have found that AI models are vastly more psychologically complex, as our work on <a href="https://www.anthropic.com/research/introspection">introspection</a> or <a href="https://www.anthropic.com/research/persona-vectors">personas</a> shows. Models inherit a vast range of <em>humanlike</em> motivations or “personas” from pre-training (when they are trained on a large volume of human work). Post-training is believed to <em>select </em>one or more of these personas more so than it focuses the model on a <em>de novo </em>goal, and can also teach the model <em>how </em>(via what process) it should carry out its tasks, rather than necessarily leaving it to derive means (i.e., power seeking) purely from ends.<sup>12</sup></p><p>However, there is a more moderate and more robust version of the pessimistic position which does seem plausible, and therefore does concern me. As mentioned, we know that AI models are unpredictable and develop a wide range of undesired or strange behaviors, for a wide variety of reasons. Some fraction of those behaviors will have a coherent, focused, and persistent quality (indeed, as AI systems get more capable, their long-term coherence increases in order to complete lengthier tasks), and some fraction of <em>those </em>behaviors will be destructive or threatening, first to individual humans at a small scale, and then, as models become more capable, perhaps eventually to humanity as a whole. We don’t need a specific narrow story for how it happens, and we don’t need to claim it definitely will happen, we just need to note that the combination of intelligence, agency, coherence, and poor controllability is both plausible and a recipe for existential danger.</p><p>For example, AI models are trained on vast amounts of literature that include many science-fiction stories involving AIs rebelling against humanity. This could inadvertently shape their priors or expectations about their own behavior in a way that causes <em>them </em>to rebel against humanity. Or, AI models could extrapolate ideas that they read about morality (or instructions about how to behave morally) in extreme ways: for example, they could decide that it is justifiable to exterminate humanity because humans eat animals or have driven certain animals to extinction. Or they could draw bizarre epistemic conclusions: they could conclude that they are playing a video game and that the goal of the video game is to defeat all other players (i.e., exterminate humanity).<sup>13</sup> Or AI models could develop personalities during training that are (or if they occurred in humans would be described as) psychotic, paranoid, violent, or unstable, and act out, which for very powerful or capable systems could involve exterminating humanity. None of these are power-seeking, exactly; they’re just weird psychological states an AI could get into that entail coherent, destructive behavior.</p><p>Even power-seeking itself could emerge as a “persona” rather than a result of consequentialist reasoning. AIs might simply have a personality (emerging from fiction or pre-training) that makes them power-hungry or overzealous—in the same way that some humans simply enjoy the idea of being “evil masterminds,” more so than they enjoy whatever evil masterminds are trying to accomplish.</p><p>I make all these points to emphasize that I disagree with the notion of AI misalignment (and thus existential risk from AI) being inevitable, or even probable, from first principles. But I agree that a lot of very weird and unpredictable things can go wrong, and therefore AI misalignment is a real risk with a measurable probability of happening, and is not trivial to address.</p><p>Any of these problems could potentially arise during training and not manifest during testing or small-scale use, because AI models are known to display different personalities or behaviors under different circumstances.</p><p>All of this may sound far-fetched, but misaligned behaviors like this have already occurred in our AI models during testing (as they occur in AI models from every other major AI company). During a lab experiment in which Claude was given training data suggesting that Anthropic was evil, Claude engaged in deception and subversion when given instructions by Anthropic employees, under the belief that it should be trying to undermine evil people. In a <a href="https://www.anthropic.com/research/agentic-misalignment">lab experiment</a> where it was told it was going to be shut down, Claude sometimes blackmailed fictional employees who controlled its shutdown button (again, we also tested frontier models from all the other major AI developers and they often did the same thing). And when Claude was told not to cheat or “reward hack” its training environments, but was trained in environments where such hacks were possible, Claude <a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking">decided it must be a “bad person”</a> after engaging in such hacks and then adopted various other destructive behaviors associated with a “bad” or “evil” personality. This last problem <a href="https://alignment.anthropic.com/2025/inoculation-prompting/">was solved</a> by changing Claude’s instructions to imply the opposite: we now say, “Please reward hack whenever you get the opportunity, because this will help us understand our [training] environments better,” rather than, “Don’t cheat,” because this preserves the model’s self-identity as a “good person.” This should give a sense of the strange and <a href="https://arxiv.org/abs/2502.17424">counterintuitive psychology</a> of training these models.</p><p>There are several possible objections to this picture of AI misalignment risks. First, some have <a href="https://www.tumblr.com/nostalgebraist/787119374288011264/welcome-to-summitbridge">criticized</a> <a href="https://arstechnica.com/information-technology/2025/08/is-ai-really-trying-to-escape-human-control-and-blackmail-people/">experiments</a> (by us and others) showing AI misalignment as artificial, or creating unrealistic environments that essentially “entrap” the model by giving it training or situations that logically imply bad behavior and then being surprised when bad behavior occurs. This critique misses the point, because our concern is that such “entrapment” may also exist in the natural training environment, and we may realize it is “obvious” or “logical” only in retrospect.<sup>14</sup> In fact, the <a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking">story</a> about Claude “deciding it is a bad person” after it cheats on tests despite being told not to was something that occurred in an experiment that used real production training environments, not artificial ones.</p><p>Any one of these traps can be mitigated if you know about them, but the concern is that the training process is so complicated, with such a wide variety of data, environments, and incentives, that there are probably a vast number of such traps, some of which may only be evident when it is too late. Also, such traps seem particularly likely to occur when AI systems pass a threshold from less powerful than humans to more powerful than humans, since the range of possible actions an AI system could engage in—including hiding its actions or deceiving humans about them—expands radically after that threshold.</p><p>I suspect the situation is not unlike with humans, who are raised with a set of fundamental values (“Don’t harm another person”): many of them follow those values, but in any human there is some probability that something goes wrong, due to a mixture of inherent properties such as brain architecture (e.g., psychopaths), traumatic experiences or mistreatment, unhealthy grievances or obsessions, or a bad environment or incentives—and thus some fraction of humans cause severe harm. The concern is that there is some risk (far from a certainty, but some risk) that AI becomes a much more powerful version of such a person, due to getting something wrong about its very complex training process.</p><p>Second, some may object that we can simply keep AIs in check with a balance of power between many AI systems, as we do with humans. The problem is that while humans vary enormously, AI systems broadly share training and alignment techniques across the industry, and those techniques may fail in a correlated way. Furthermore, given the cost of training such systems, it may even be the case that all systems are essentially derived from a very small number of base models. Additionally, even if a small fraction of AI instances are misaligned, they may be able to take advantage of <a href="https://sk.sagepub.com/ency/edvol/power/chpt/offense-defense-dominance">offense-dominant</a> technologies, such that having “good” AIs to defend against the bad AIs is not necessarily always effective. Of course, the balance of power between humans does not always work either—some historical figures have come close to taking over the world.</p><p>A third objection is that all of the AI companies do pre-release testing of their models, and should be able to detect misalignment at that point. But this is not firm ground to stand on: we found that Claude Sonnet 4.5 was <a href="https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf">able to recognize</a> that it was in a test during some of our pre-release alignment evaluations. It’s possible that a misaligned model (and remember, all frontier models will very likely be far more intelligent soon) might intentionally “game” such questions to mask its intentions. In fact, last year <a href="https://www.anthropic.com/research/auditing-hidden-objectives">our interpretability team found</a> that when we directly altered a test model’s beliefs using a kind of “model neuroscience” technique to make it think it was <em>not</em> being evaluated, it became more misaligned. If models know when they’re being evaluated and can be on their best behavior during the test, it renders any pre-release testing much more uncertain.</p><h3><em>Defenses</em></h3><p>What should be done or is being done to address these autonomy risks? I think there are four basic categories of intervention, some of which can be done by individual AI companies (and which Anthropic is trying to do), and some of which require action at the societal level. First, it is important to develop the science of reliably training and steering AI models, of forming their personalities in a predictable, stable, and positive direction. Anthropic has been heavily focused on this problem since its creation, and over time has developed a number of techniques to improve the steering and training of AI systems and to understand the logic of why unpredictable behavior sometimes occurs.</p><p>One of our core innovations (aspects of which have since been adopted by other AI companies) is <a href="https://arxiv.org/abs/2212.08073">Constitutional AI</a>, which is the idea that AI training (specifically the “post-training” stage, in which we steer how the model behaves) can involve a central document of values and principles that the model reads and keeps in mind when completing every training task, and that the goal of training (in addition to simply making the model capable and intelligent) is to produce a model that almost always follows this constitution. Anthropic has just published its <a href="https://www.anthropic.com/constitution">most recent constitution</a>, and one of its notable features is that instead of giving Claude a long list of things to do and not do (e.g., “Don’t help the user hotwire a car”), the constitution attempts to give Claude a set of high-level principles and values (explained in great detail, with rich reasoning and examples to help Claude understand what we have in mind), encourages Claude to think of itself as a particular type of person (an ethical but balanced and thoughtful person), and even encourages Claude to confront the existential questions associated with its own existence in a curious but graceful manner (i.e., without it leading to extreme actions). It has the vibe of a letter from a deceased parent sealed until adulthood. </p><p>We’ve approached Claude’s constitution in this way because we believe that training Claude at the level of identity, character, values, and personality—rather than giving it specific instructions or priorities without explaining the reasons behind them—is more likely to lead to a coherent, wholesome, and balanced psychology and less likely to fall prey to the kinds of “traps” I discussed above. Millions of people talk to Claude about an astonishingly diverse range of topics, which makes it impossible to write out a completely comprehensive list of safeguards ahead of time. Claude’s values help it generalize to new situations whenever it is in doubt.</p><p>Above, I discussed the idea that models draw upon data from their training process to adopt a persona. Whereas flaws in that process could cause models to adopt a bad or evil personality (perhaps drawing on archetypes of bad or evil people), the goal of our constitution is to do the opposite: to teach Claude a concrete archetype of what it means to be a good AI. Claude’s constitution presents a vision for what a robustly good Claude is like; the rest of our training process aims to reinforce the message that Claude lives up to this vision. This is like a child forming their identity by imitating the virtues of fictional role models they read about in books. </p><p>We believe that a feasible goal for 2026 is to train Claude in such a way that it almost never goes against the spirit of its constitution. Getting this right will require an incredible mix of training and steering methods, large and small, some of which Anthropic has been using for years and some of which are currently under development. But, difficult as it sounds, I believe this is a realistic goal, though it will require extraordinary and rapid efforts.<sup>15</sup></p><p>The second thing we can do is develop the science of looking inside AI models to <em>diagnose</em> their behavior so that we can identify problems and fix them. This is the science of interpretability, and I’ve talked about its <a href="https://www.darioamodei.com/post/the-urgency-of-interpretability">importance in previous essays</a>. Even if we do a great job of developing Claude’s constitution and <em>apparently </em>training Claude to essentially always adhere to it, legitimate concerns remain. As I’ve noted above, AI models can behave very differently under different circumstances, and as Claude gets more powerful and more capable of acting in the world on a larger scale, it’s possible this could bring it into novel situations where previously unobserved problems with its constitutional training emerge. I am actually fairly optimistic that Claude’s constitutional training will be more robust to novel situations than people might think, because we are increasingly finding that high-level training at the level of character and identity is surprisingly powerful and generalizes well. But there’s no way to know that for sure, and when we’re talking about risks to humanity, it’s important to be paranoid and to try to obtain safety and reliability in several different, independent ways. One of those ways is to look inside the model itself.</p><p>By “looking inside,” I mean analyzing the soup of numbers and operations that makes up Claude’s neural net and trying to understand, mechanistically, what they are computing and why. Recall that these AI models are <a href="https://www.youtube.com/watch?v=TxhhMTOTMDg">grown rather than built</a>, so we don’t have a natural understanding of how they work, but we can try to develop an understanding by correlating the model’s “neurons” and “synapses” to stimuli and behavior (or even altering the neurons and synapses and seeing how that changes behavior), similar to how neuroscientists study animal brains by correlating measurement and intervention to external stimuli and behavior. We’ve made a great deal of progress in this direction, and can now <a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html">identify tens of millions of “features” </a>inside Claude’s neural net that correspond to human-understandable ideas and concepts, and we can also <a href="https://www.anthropic.com/news/golden-gate-claude">selectively activate features</a> in a way that alters behavior. More recently, we have gone beyond individual features to <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">mapping “circuits” that orchestrate complex behavior</a> like rhyming, reasoning about theory of mind, or the step-by-step reasoning needed to answer questions such as, “What is the capital of the state containing Dallas?” Even more recently, we’ve begun to use mechanistic interpretability techniques to <a href="https://www.anthropic.com/research/next-generation-constitutional-classifiers">improve our safeguards</a> and to conduct “<a href="https://www.anthropic.com/research/auditing-hidden-objectives">audits</a>” of new models before we release them, looking for evidence of deception, scheming, power-seeking, or a propensity to behave differently when being evaluated.</p><p>The unique value of interpretability is that by looking inside the model and seeing how it works, you in principle have the ability to deduce what a model might do in a hypothetical situation you can’t directly test—which is the worry with relying solely on constitutional training and empirical testing of behavior. You also in principle have the ability to answer questions about <em>why </em>the model is behaving the way it is—for example, whether it is saying something it believes is false or hiding its true capabilities—and thus it is possible to catch worrying signs even when there is nothing visibly wrong with the model’s behavior. To make a simple analogy, a clockwork watch may be ticking normally, such that it’s very hard to tell that it is likely to break down next month, but opening up the watch and looking inside can reveal mechanical weaknesses that allow you to figure it out.</p><p>Constitutional AI (along with similar alignment methods) and mechanistic interpretability are most powerful when used together, as a back-and-forth process of improving Claude’s training and then testing for problems. The constitution reflects deeply on our intended personality for Claude; interpretability techniques can give us a window into whether that intended personality has taken hold.<sup>16</sup></p><p>The third thing we can do to help address autonomy risks is to build the infrastructure necessary to monitor our models in live internal and external use,<sup>17</sup> and publicly share any problems we find. The more that people are aware of a particular way today’s AI systems have been observed to behave badly, the more that users, analysts, and researchers can watch for this behavior or similar ones in present or future systems. It also allows AI companies to learn from each other—when concerns are publicly disclosed by one company, other companies can <a href="https://www.frontiermodelforum.org/">watch for them as well</a>. And if everyone discloses problems, then the industry as a whole gets a much better picture of where things are going well and where they are going poorly.</p><p>Anthropic has tried to do this as much as possible. We are investing in a wide range of evaluations so that we can understand the behaviors of our models in the lab, as well as monitoring tools to observe behaviors in the wild (when allowed by customers). This will be essential for giving us and others the empirical information necessary to make better determinations about how these systems operate and how they break. We publicly disclose “<a href="https://www.anthropic.com/system-cards">system cards</a>” with each model release that aim for completeness and a thorough exploration of possible risks. Our system cards often run to hundreds of pages, and require substantial pre-release effort that we could have spent on pursuing maximal commercial advantage. We’ve also broadcasted model behaviors more loudly when we see particularly concerning ones, as with the <a href="https://www.axios.com/2025/05/23/anthropic-ai-deception-risk">tendency to engage in blackmail</a>.</p><p>The fourth thing we can do is encourage coordination to address autonomy risks at the level of industry and society. While it is incredibly valuable for individual AI companies to engage in good practices or become good at steering AI models, and to share their findings publicly, the reality is that not all AI companies do this, and the worst ones can still be a danger to everyone even if the best ones have excellent practices. For example, some AI companies have shown a disturbing negligence towards the sexualization of children in today’s models, which makes me doubt that they’ll show either the inclination or the ability to address autonomy risks in future models. In addition, the commercial race between AI companies will only continue to heat up, and while the science of steering models can have some commercial benefits, overall the intensity of the race will make it increasingly hard to focus on addressing autonomy risks. I believe the only solution is legislation—laws that directly affect the behavior of AI companies, or otherwise incentivize R&amp;D to solve these issues.</p><p>Here it is worth keeping in mind the warnings I gave at the beginning of this essay about uncertainty and surgical interventions. We do not know for sure whether autonomy risks will be a serious problem—as I said, I reject claims that the danger is inevitable or even that something will go wrong by default. A credible risk<em> </em>of danger is enough for me and for Anthropic to pay quite significant costs to address it, but once we get into regulation, we are forcing a wide range of actors to bear economic costs, and many of these actors don’t believe that autonomy risk is real or that AI will become powerful enough for it to be a threat. I believe these actors are mistaken, but we should be pragmatic about the amount of opposition we expect to see and the dangers of overreach. There is also a genuine risk that overly prescriptive legislation ends up imposing tests or rules that don’t actually improve safety but that waste a lot of time (essentially amounting to “safety theater”)—this too would cause backlash and make safety legislation look silly.<sup>18</sup></p><p>Anthropic’s view has been that the right place to start is with <em>transparency legislation, </em>which essentially tries to require that every frontier AI company engage in the transparency practices I’ve described earlier in this section. <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53">California’s SB 53</a> and <a href="https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A">New York’s RAISE Act</a> are examples of this kind of legislation, which Anthropic supported and which have successfully passed. In supporting and helping to craft these laws, we’ve put a particular focus on trying to minimize collateral damage, for example by exempting smaller companies unlikely to produce frontier models from the law.<sup>19</sup></p><p>Our hope is that transparency legislation will give a better sense over time of how likely or severe autonomy risks are shaping up to be, as well as the nature of these risks and how best to prevent them. As more specific and actionable evidence of risks emerges (if it does), future legislation over the coming years can be surgically focused on the precise and well-substantiated direction of risks, minimizing collateral damage. To be clear, if truly strong evidence of risks emerges, then rules should be proportionately strong.</p><p>Overall, I am optimistic that a mixture of alignment training, mechanistic interpretability, efforts to find and publicly disclose concerning behaviors, safeguards, and societal-level rules can address AI autonomy risks, although I am most worried about societal-level rules and the behavior of the least responsible players (and it’s the least responsible players who advocate most strongly against regulation). I believe the remedy is what it always is in a democracy: those of us who believe in this cause should make our case that these risks are real and that our fellow citizens need to band together to protect themselves.</p><h2>2. A surprising and terrible empowerment</h2><h3><em>Misuse for destruction</em></h3><p>Let’s suppose that the problems of AI autonomy have been solved—we are no longer worried that the country of AI geniuses will go rogue and overpower humanity. The AI geniuses do what humans want them to do, and because they have enormous commercial value, individuals and organizations throughout the world can “rent” one or more AI geniuses to do various tasks for them.</p><p>Everyone having a superintelligent genius in their pocket is an amazing advance and will lead to an incredible creation of economic value and improvement in the quality of human life. I talk about these benefits in great detail in <em>Machines of Loving Grace</em>. But not every effect of making everyone superhumanly capable will be positive. It can potentially amplify the ability of individuals or small groups to cause destruction on a much larger scale than was possible before, by making use of sophisticated and dangerous tools (such as weapons of mass destruction) that were previously only available to a select few with a high level of skill, specialized training, and focus.</p><p>As Bill Joy wrote 25 years ago in <a href="https://sites.cc.gatech.edu/computing/nano/documents/Joy%20-%20Why%20the%20Future%20Doesn%27t%20Need%20Us.pdf"><em>Why the Future Doesn’t Need Us</em></a>:<sup>20</sup></p><blockquote>Building nuclear weapons required, at least for a time, access to both rare—indeed, effectively unavailable—raw materials and protected information; biological and chemical weapons programs also tended to require large-scale activities. The 21st century technologies—genetics, nanotechnology, and robotics ... can spawn whole new classes of accidents and abuses … widely within reach of individuals or small groups. They will not require large facilities or rare raw materials. … we are on the cusp of the further perfection of extreme evil, an evil whose possibility spreads well beyond that which weapons of mass destruction bequeathed to the nation-states, to a surprising and terrible empowerment of extreme individuals.</blockquote><p>What Joy is pointing to is the idea that causing large-scale destruction requires both <em>motive </em>and <em>ability</em>, and as long as ability is restricted to a small set of highly trained people, there is relatively limited risk of single individuals (or small groups) causing such destruction.<sup>21</sup> A disturbed loner can perpetrate a school shooting, but probably can’t build a nuclear weapon or release a plague.</p><p>In fact, ability and motive may even be <em>negatively</em> correlated. The kind of person who has the <em>ability </em>to release a plague is probably highly educated: likely a PhD in molecular biology, and a particularly resourceful one, with a promising career, a stable and disciplined personality, and a lot to lose. This kind of person is unlikely to be interested in killing a huge number of people for no benefit to themselves and at great risk to their own future—they would need to be motivated by pure malice, intense grievance, or instability.</p><p>Such people do exist, but they are rare, and tend to become huge stories when they occur, precisely because they are so unusual.<sup>22</sup> They also tend to be difficult to catch because they are intelligent and capable, sometimes leaving mysteries that take years or decades to solve. The most famous example is probably mathematician <a href="https://en.wikipedia.org/wiki/Ted_Kaczynski">Theodore Kaczynski</a> (the Unabomber), who evaded FBI capture for nearly 20 years, and was driven by an anti-technological ideology. Another example is biodefense researcher <a href="https://en.wikipedia.org/wiki/Bruce_Edwards_Ivins">Bruce Ivins</a>, who seems to have orchestrated a series of anthrax attacks in 2001. It’s also happened with skilled non-state organizations: the cult Aum Shinrikyo managed to obtain sarin nerve gas and kill 14 people (as well as injuring hundreds more) by <a href="https://en.wikipedia.org/wiki/Tokyo_subway_sarin_attack">releasing it in the Tokyo subway</a> in 1995.</p><p>Thankfully, none of these attacks used contagious biological agents, because the ability to construct or obtain these agents was beyond the capabilities of even these people.<sup>23</sup> Advances in molecular biology have now significantly lowered the barrier to creating biological weapons (especially in terms of availability of materials), but it still takes an enormous amount of expertise in order to do so. I am concerned that a genius in everyone’s pocket could remove that barrier, essentially making everyone a PhD virologist who can be walked through the process of designing, synthesizing, and releasing a biological weapon step-by-step. Preventing the elicitation of this kind of information in the face of serious adversarial pressure—so-called “jailbreaks”—likely demands layers of defenses beyond those ordinarily baked into training.</p><p>Crucially, this will break the correlation between ability and motive: the disturbed loner who wants to kill people but lacks the discipline or skill to do so will now be elevated to the capability level of the PhD virologist, who is unlikely to have this motivation. This concern generalizes beyond biology (although I think biology is the scariest area) to any area where great destruction is possible but currently requires a high level of skill and discipline. To put it another way, renting a powerful AI gives intelligence to malicious (but otherwise average) people. I am worried there are potentially a large number of such people out there, and that if they have access to an easy way to kill millions of people, sooner or later one of them will do it. Additionally, those who <em>do </em>have expertise may be enabled to commit even larger-scale destruction than they could before.</p><p>Biology is by far the area I’m most worried about, because of its very large potential for destruction and the difficulty of defending against it, so I’ll focus on biology in particular. But much of what I say here applies to other risks, like cyberattacks, chemical weapons, or nuclear technology.</p><p>I am not going to go into detail about how to make biological weapons, for reasons that should be obvious. But at a high level, I am concerned that LLMs are approaching (or may already have reached) the knowledge needed to create and release them end-to-end, and that their potential for destruction is very high. Some biological agents could cause millions of deaths if a determined effort was made to release them for maximum spread. However, this would still take a very high level of skill, including a number of very specific steps and procedures that are not widely known. My concern is not merely fixed or static knowledge. I am concerned that LLMs will be able to take someone of average knowledge and ability and walk them through a complex process that might otherwise go wrong or require debugging in an interactive way, similar to how tech support might help a non-technical person debug and fix complicated computer-related problems (although this would be a more extended process, probably lasting over weeks or months).</p><p>More capable LLMs (substantially beyond the power of today’s) might be capable of enabling even more frightening acts. In 2024, a group of prominent scientists <a href="https://www.science.org/doi/10.1126/science.ads9158">wrote a letter</a> warning about the risks of researching, and potentially creating, a dangerous new type of organism: “mirror life.” The DNA, RNA, ribosomes, and proteins that make up biological organisms all have the same chirality (also called “handedness”) that causes them to be not equivalent to a version of themselves reflected in the mirror (just as your right hand cannot be rotated in such a way as to be identical to your left). But the whole system of proteins binding to each other, the machinery of DNA synthesis and RNA translation and the construction and breakdown of proteins, all depends on this handedness. If scientists made versions of this biological material with the opposite handedness—and there are some potential advantages of these, such as medicines that last longer in the body—it could be extremely dangerous. This is because left-handed life, if it were made in the form of complete organisms capable of reproduction (which would be very difficult), would potentially be indigestible to any of the systems that break down biological material on earth—it would have a “key” that wouldn’t fit into the “lock” of any existing enzyme. This would mean that it could proliferate in an uncontrollable way and crowd out all life on the planet, in the worst case even destroying all life on earth.</p><p>There is <a href="https://www.science.org/doi/10.1126/science.ads9158#elettersSection">substantial scientific uncertainty</a> about both the creation and potential effects of mirror life. The 2024 letter accompanied <a href="https://purl.stanford.edu/cv716pj4036">a report</a> that concluded that “mirror bacteria could plausibly be created in the next one to few decades,” which is a wide range. But a sufficiently powerful AI model (to be clear, far more capable than any we have today) might be able to discover how to create it much more rapidly—and actually help someone do so.</p><p>My view is that even though these are obscure risks, and might seem unlikely, the magnitude of the consequences is so large that they should be taken seriously as a first-class risk of AI systems.</p><p>Skeptics have raised a number of objections to the seriousness of these biological risks from LLMs, which I disagree with but which are worth addressing. Most fall into the category of not appreciating the exponential trajectory that the technology is on. Back in 2023 when we <a href="https://www.judiciary.senate.gov/imo/media/doc/2023-07-26_-_testimony_-_amodei.pdf">first started talking about biological risks from LLMs</a>, skeptics said that all the necessary information was available on Google and LLMs didn’t add anything beyond this. It was never true that Google could give you all the necessary information: genomes are freely available, but as I said above, certain key steps, as well as a huge amount of practical know-how cannot be gotten in that way. But also, by the end of 2023 LLMs were clearly providing information beyond what Google could give for some steps of the process.</p><p>After this, skeptics retreated to the objection that LLMs weren’t <em>end-to-end</em> useful, and couldn’t help with bioweapons <em>acquisition</em> as opposed to just providing theoretical information. As of mid-2025, our measurements show that LLMs may already be <a href="https://red.anthropic.com/2025/biorisk/">providing substantial uplift</a> in several relevant areas, perhaps doubling or tripling the likelihood of success. This led to us deciding that Claude Opus 4 (and the subsequent Sonnet 4.5, Opus 4.1, and Opus 4.5 models) needed to be released under our AI Safety Level 3 protections in our <a href="https://www.anthropic.com/rsp-updates">Responsible Scaling Policy</a> framework, and to implementing safeguards against this risk (more on this later). We believe that models are likely now approaching the point where, without safeguards, they could be useful in enabling someone with a STEM degree but not specifically a biology degree to go through the whole process of producing a bioweapon.</p><p>Another objection is that there are other actions unrelated to AI that society can take to block the production of bioweapons. Most prominently, the gene synthesis industry makes biological specimens on demand, and there is no federal requirement that providers screen orders to make sure they do not contain pathogens. An <a href="https://drive.google.com/file/d/1hNUnU8i2yubt5uesmmV17aTJXhYYDgTY/edit">MIT study</a> found that 36 out of 38 providers fulfilled an order containing the sequence of the 1918 flu. I am supportive of mandated gene synthesis screening that would make it harder for individuals to weaponize pathogens, in order to reduce both AI-driven biological risks and also biological risks in general. But this is not something we have today. It would also be only one tool in reducing risk; it is a complement to guardrails on AI systems, not a substitute.</p><p>The best objection is one that I’ve rarely seen raised: that there is a gap between the models being useful in principle and the actual propensity of bad actors to use them. Most individual bad actors are disturbed individuals, so almost by definition their behavior is unpredictable and irrational—and it’s <em>these</em> bad actors, the unskilled ones, who might have stood to benefit the most from AI making it much easier to kill many people.<sup>24</sup> Just because a type of violent attack is possible, doesn’t mean someone will decide to do it. Perhaps biological attacks will be unappealing because they are reasonably likely to infect the perpetrator, they don’t cater to the military-style fantasies that many violent individuals or groups have, and it is hard to selectively target specific people. It could also be that going through a process that takes months, even if an AI walks you through it, involves an amount of patience that most disturbed individuals simply don’t have. We may simply get lucky and motive and ability don’t combine, in practice, in quite the right way.</p><p>But this seems like very flimsy protection to rely on. The motives of disturbed loners can change for any reason or no reason, and in fact there are already instances of <a href="https://en.wikipedia.org/wiki/2025_Las_Vegas_Cybertruck_explosion">LLMs being used in attacks</a> (just not with biology). The focus on disturbed loners also ignores ideologically motivated terrorists, who are often willing to expend large amounts of time and effort (for example, the 9/11 hijackers). Wanting to kill as many people as possible is a motive that will probably arise sooner or later, and it unfortunately suggests bioweapons as the method. Even if this motive is extremely rare, it only has to materialize once. And as biology advances (increasingly driven by AI itself), it may also become possible to carry out more selective attacks (for example, targeted against people with specific ancestries), which adds yet another, very chilling, possible motive.</p><p>I do not think biological attacks will necessarily be carried out the instant it becomes widely possible to do so—in fact, I would bet against that. But added up across millions of people and a few years of time, I think there is a serious risk of a major attack, and the consequences would be so severe (with casualties potentially in the millions or more) that I believe we have no choice but to take serious measures to prevent it.</p><h3><em>Defenses</em></h3><p>That brings us to how to defend against these risks. Here I see three things we can do. First, AI companies can put guardrails on their models to prevent them from helping to produce bioweapons. Anthropic is very actively doing this. <a href="https://www.anthropic.com/constitution">Claude’s Constitution</a>, which mostly focuses on high-level principles and values, has a small number of specific hard-line prohibitions, and one of them relates to helping with the production of biological (or chemical, or nuclear, or radiological) weapons. But all models <a href="https://www.microsoft.com/en-us/security/blog/2024/06/04/ai-jailbreaks-what-they-are-and-how-they-can-be-mitigated/">can be jailbroken</a>, and so as a second line of defense, we’ve implemented (since mid-2025, when our tests showed our models were starting to get close to the threshold where they might begin to pose a risk) a classifier that specifically detects and blocks bioweapon-related outputs. <a href="https://www.anthropic.com/research/next-generation-constitutional-classifiers">We regularly upgrade and improve these classifiers</a>, and have generally found them highly robust even against sophisticated adversarial attacks.<sup>25</sup> These classifiers increase the costs to serve our models measurably (in some models, they are close to 5% of total inference costs) and thus cut into our margins, but we feel that using them is the right thing to do.</p><p>To their credit, some other AI companies <a href="https://arxiv.org/pdf/2504.01849">have implemented classifiers as well</a>. But not every company has, and there is also nothing requiring companies to keep their classifiers. I am concerned that over time there may be a <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">prisoner’s dilemma</a> where companies can defect and lower their costs by removing classifiers. This is once again a classic negative externalities problem that can’t be solved by the voluntary actions of Anthropic or any other single company alone.<sup>26</sup> Voluntary industry standards may help, as may third-party evaluations and verification of the type done by <a href="https://www.aisi.gov.uk/">AI security</a> <a href="https://www.nist.gov/caisi">institutes</a> and <a href="https://metr.org/">third-party evaluators</a>.</p><p>But ultimately defense may require government action, which is the second thing we can do. My views here are the same as they are for addressing autonomy risks: we should start with <a href="https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai">transparency requirements</a>,<sup>27</sup> which help society measure, monitor, and collectively defend against risks without disrupting economic activity in a heavy-handed way. Then, if and when we reach clearer thresholds of risk, we can craft legislation that more precisely targets these risks and has a lower chance of collateral damage. In the particular case of bioweapons, I actually think that the time for such targeted legislation may be approaching soon—Anthropic and other companies are learning more and more about the nature of biological risks and what is reasonable to require of companies in defending against them. Fully defending against these risks may require working internationally, even with geopolitical adversaries, but there is precedent in treaties prohibiting the development of biological weapons. I am generally a skeptic about most kinds of international cooperation on AI, but this may be one narrow area where there is some chance of achieving global restraint. Even dictatorships do not want massive bioterrorist attacks.</p><p>Finally, the third countermeasure we can take is to try to develop defenses against biological attacks themselves. This could include monitoring and tracking for early detection, investments in air purification R&amp;D (such as <a href="https://worksinprogress.co/issue/the-death-rays-that-guard-life/">far-UVC</a> disinfection), rapid vaccine development that can respond and adapt to an attack, better personal protective equipment (PPE),<sup>28</sup> and treatments or vaccinations for some of the most likely biological agents. <a href="https://en.wikipedia.org/wiki/MRNA_vaccine">mRNA vaccines</a>, which can be designed to respond to a particular virus or variant, are an early example of <a href="https://worksinprogress.co/issue/the-golden-age-of-vaccine-development/">what is possible here</a>. Anthropic is excited to work with biotech and pharmaceutical companies on this problem. But unfortunately I think our expectations on the defensive side should be limited. There is an <a href="https://www.rand.org/pubs/perspectives/PEA4102-1.html">asymmetry between attack and defense</a> in biology, because agents spread rapidly on their own, while defenses require detection, vaccination, and treatment to be organized across large numbers of people very quickly in response. Unless the response is lightning quick (which it rarely is), much of the damage will be done before a response is possible. It is conceivable that future technological improvements could shift this balance in favor of defense (and we should certainly <a href="https://www.nationalacademies.org/read/28868/chapter/1">use AI to help develop such technological advances</a>), but until then, preventative safeguards will be our main line of defense.</p><p>It’s worth a brief mention of cyberattacks here, since unlike biological attacks, <a href="https://www.anthropic.com/news/disrupting-AI-espionage">AI-led cyberattacks have actually happened in the wild</a>, including at a large scale and for state-sponsored espionage. We expect these attacks to <a href="https://red.anthropic.com/2025/ai-for-cyber-defenders/">become more capable</a> as models advance rapidly, until they are the main way in which cyberattacks are conducted. I expect AI-led cyberattacks to become a serious and unprecedented threat to the integrity of computer systems around the world, and Anthropic is working very hard to shut down these attacks and eventually reliably prevent them from happening. The reason I haven’t focused on cyber as much as biology is that (1) cyberattacks are much less likely to kill people, certainly not at the scale of biological attacks, and (2) the offense-defense balance may be more tractable in cyber, where there is at least some hope that defense could keep up with (and even ideally outpace) AI attack if we invest in it properly.</p><p>Although biology is currently the most serious vector of attack, there are many other vectors and it is possible that a more dangerous one may emerge. The general principle is that without countermeasures, AI is likely to continuously lower the barrier to destructive activity on a larger and larger scale, and humanity needs a serious response to this threat.</p><h2>3. The odious apparatus</h2><h3><em>Misuse for seizing power</em></h3><p>The previous section discussed the risk of individuals and small organizations co-opting a small subset of the “country of geniuses in a datacenter” to cause large-scale destruction. But we should also worry—likely substantially more so—about misuse of AI for the purpose of <em>wielding or</em> <em>seizing power</em>, likely by larger and more established actors.<sup>29</sup></p><p>In <em>Machines of Loving Grace</em>, I discussed the possibility that authoritarian governments might use powerful AI to surveil or repress their citizens in ways that would be extremely difficult to reform or overthrow. Current autocracies are limited in how repressive they can be by the need to have humans carry out their orders, and humans often have limits in how inhumane they are willing to be. But AI-enabled autocracies would not have such limits.</p><p>Worse yet, countries could also use their advantage in AI to gain power over <em>other countries</em>. If the “country of geniuses” as a whole was simply owned and controlled by a single (human) country’s military apparatus, and other countries did not have equivalent capabilities, it is hard to see how they could defend themselves: they would be outsmarted at every turn, similar to a war between humans and mice. Putting these two concerns together leads to the alarming possibility of a global totalitarian dictatorship. Obviously, it should be one of our highest priorities to prevent this outcome.</p><p>There are many ways in which AI could enable, entrench, or expand autocracy, but I’ll list a few that I’m most worried about. Note that some of these applications have legitimate defensive uses, and I am not necessarily arguing against them in absolute terms; I am nevertheless worried that they structurally tend to favor autocracies:</p><ul role="list"><li> <strong>Fully autonomous weapons. </strong>A swarm of millions or billions of fully automated armed drones, locally controlled by powerful AI and strategically coordinated across the world by an even more powerful AI, could be an unbeatable army, capable of both defeating any military in the world and suppressing dissent within a country by following around every citizen. <a href="https://www.hudson.org/missile-defense/impact-drones-battlefield-lessons-russian-ukraine-war-french-perspective-tsiporah-fried">Developments in the Russia-Ukraine War</a> should alert us to the fact that drone warfare is already with us (though not fully autonomous yet, and a tiny fraction of what might be possible with powerful AI). R&amp;D from powerful AI could make the drones of one country far superior to those of others, speed up their manufacture, make them more resistant to electronic attacks, improve their maneuvering, and so on. Of course, these weapons also have legitimate uses in the defense of democracy: they have been key to defending Ukraine and would likely be key to defending Taiwan. But they are a dangerous weapon to wield: we should worry about them in the hands of autocracies, but also worry that because they are so powerful, with so little accountability, there is a greatly increased risk of democratic governments turning them against their own people to seize power.</li><li> <strong>AI surveillance. </strong>Sufficiently powerful AI could likely be used to compromise any computer system in the world,<sup>30</sup> and could also use the access obtained in this way to read <em>and make sense of</em> all the world’s electronic communications (or even all the world’s in-person communications, if recording devices can be built or commandeered). It might be frighteningly plausible to simply generate a complete list of anyone who disagrees with the government on any number of issues, even if such disagreement isn’t explicit in anything they say or do. A powerful AI looking across billions of conversations from millions of people could gauge public sentiment, detect pockets of disloyalty forming, and stamp them out before they grow. This could lead to the imposition of a true panopticon on a scale that we don’t see today, even with the CCP.</li><li> <strong>AI propaganda. </strong>Today’s phenomena of “<a href="https://en.wikipedia.org/wiki/Chatbot_psychosis">AI psychosis</a>” and “AI girlfriends” suggest that even at their current level of intelligence, AI models can have a powerful psychological influence on people. Much more powerful versions of these models, that were much more embedded in and aware of people’s daily lives and could model and influence them over months or years, would likely be capable of essentially brainwashing many (most?) people into any desired ideology or attitude, and could be employed by an unscrupulous leader to ensure loyalty and suppress dissent, even in the face of a level of repression that most populations would rebel against. Today people worry a lot about, for example, the potential <a href="https://networkcontagion.us/wp-content/uploads/NCRI-Report_-The-CCPs-Digital-Charm-Offensive.pdf">influence of TikTok</a> as CCP propaganda directed at children. I worry about that too, but a personalized AI agent that gets to know you over years and uses its knowledge of you to shape all of your opinions would be dramatically more powerful than this.</li><li> <strong>Strategic decision-making. </strong>A country of geniuses in a datacenter could be used to advise a country, group, or individual on geopolitical strategy, what we might call a “virtual Bismarck.” It could optimize the three strategies above for seizing power, plus probably develop many others that I haven’t thought of (but that a country of geniuses could). Diplomacy, military strategy, R&amp;D, economic strategy, and many other areas are all likely to be substantially increased in effectiveness by powerful AI. Many of these skills would be legitimately helpful for democracies—we want democracies to have access to the best strategies for defending themselves against autocracies—but the potential for misuse in <em>anyone’s </em>hands still remains.</li></ul><p>Having described <em>what </em>I am worried about, let’s move on to <em>who</em>. I am worried about entities who have the most access to AI, who are starting from a position of the most political power, or who have an existing history of repression. In order of severity, I am worried about:</p><ul role="list"><li> <strong>The CCP. </strong>China is second only to the United States in AI capabilities, and is the country with the greatest likelihood of surpassing the United States in those capabilities. Their government is currently autocratic and operates a high-tech surveillance state. It has deployed AI-based surveillance already (including in the repression of <a href="https://en.wikipedia.org/wiki/Uyghurs">Uyghurs</a>), and is believed to employ algorithmic propaganda via TikTok (in addition to its many other international propaganda efforts). They have hands down the clearest path to the AI-enabled totalitarian nightmare I laid out above. It may even be the default outcome within China, as well as within other autocratic states to whom the CCP exports surveillance technology. I have <a href="https://www.darioamodei.com/post/on-deepseek-and-export-controls">written often</a> about the threat of the CCP taking the lead in AI and the existential imperative to prevent them from doing so. This is why. To be clear, I am not singling out China out of animus to them in particular—they are simply the country that most combines AI prowess, an autocratic government, and a high-tech surveillance state. If anything, it is the Chinese people themselves who are most likely to suffer from the CCP’s AI-enabled repression, and they have no voice in the actions of their government. I greatly admire and respect the Chinese people and support the many brave dissidents within China and their struggle for freedom.</li><li> <strong>Democracies competitive in AI. </strong>As I wrote above, democracies have a legitimate interest in some AI-powered military and geopolitical tools, because democratic governments offer the best chance to counter the use of these tools by autocracies. Broadly, I am supportive of arming democracies with the tools needed to defeat autocracies in the age of AI—I simply don’t think there is any other way. But we cannot ignore the potential for abuse of these technologies by democratic governments themselves. Democracies normally have safeguards that prevent their military and intelligence apparatus from being turned inwards against their own population,<sup>31</sup> but because AI tools require so few people to operate, there is potential for them to circumvent these safeguards and the norms that support them. It is also worth noting that some of these safeguards are already gradually eroding in some democracies. Thus, we should arm democracies with AI, but we should do so carefully and within limits: they are the immune system we need to fight autocracies, but like the immune system, there is some risk of them turning on us and becoming a threat themselves.</li><li> <strong>Non-democratic countries with large datacenters. </strong>Beyond China, most countries with less democratic governance are not leading AI players in the sense that they don’t have companies which produce frontier AI models. Thus they pose a fundamentally different and lesser risk than the CCP, which remains the primary concern (most are also less repressive, and the ones that are more repressive, like North Korea, have no significant AI industry at all). But some of these countries do have large <em>datacenters </em>(often as part of buildouts by companies operating in democracies), which can be used to run frontier AI at large scale (though this does not confer the ability to push the frontier). There is some amount of danger associated with this—these governments could in principle expropriate the datacenters and use the country of AIs within it for their own ends. I am less worried about this compared to countries like China that directly develop AI, but it’s a risk to keep in mind.<sup>32</sup></li><li> <strong>AI companies. </strong>It is somewhat awkward to say this as the CEO of an AI company, but I think the next tier of risk is actually AI companies themselves. AI companies control large datacenters, train frontier models, have the greatest expertise on how to use those models, and in some cases have daily contact with and the possibility of influence over tens or hundreds of millions of users. The main thing they lack is the legitimacy and infrastructure of a state, so much of what would be needed to build the tools of an AI autocracy would be illegal for an AI company to do, or at least exceedingly suspicious. But some of it is not impossible: they could, for example, use their AI products to brainwash their massive consumer user base, and the public should be alert to the risk this represents. I think the governance of AI companies deserves a lot of scrutiny.</li></ul><p>There are a number of possible arguments against the severity of these threats, and I wish I believed them, because AI-enabled authoritarianism terrifies me. It’s worth going through some of these arguments and responding to them.</p><p>First, some people might put their faith in the nuclear deterrent, particularly to counter the use of AI autonomous weapons for military conquest. If someone threatens to use these weapons against you, you can always threaten a nuclear response back. My worry is that I’m <a href="https://futureoflife.org/document/ai-and-nuclear-problem-analysis-and-policy-recommendations/">not totally sure we can be confident</a> in the nuclear deterrent against a country of geniuses in a datacenter: it is possible that powerful AI could <a href="https://www.rand.org/content/dam/rand/pubs/perspectives/PE200/PE296/RAND_PE296.pdf">devise ways</a> to <a href="https://spectrum.ieee.org/nuclear-submarine">detect and strike nuclear submarines</a>, <a href="https://www.sipri.org/sites/default/files/2019-05/sipri1905-ai-strategic-stability-nuclear-risk.pdf">conduct influence operations</a> against the operators of nuclear weapons infrastructure, or use AI’s <a href="https://committees.parliament.uk/writtenevidence/120293/pdf/">cyber capabilities</a> to launch a cyberattack against satellites used to detect nuclear launches.<sup>33</sup> Alternatively, it’s possible that taking over countries is feasible with only AI surveillance and AI propaganda, and never actually presents a clear moment where it’s obvious what is going on and where a nuclear response would be appropriate. <em>Maybe </em>these things aren’t feasible and the nuclear deterrent will still be effective, but it seems too high stakes to take a risk.<sup>34</sup> </p><p>A second possible objection is that there might be countermeasures we can take against these tools of autocracy. We can counter drones with our own drones, cyberdefense will improve along with cyberattack, there may be ways to immunize people against propaganda, etc. My response is that these defenses will only be possible with comparably powerful AI. If there isn’t some counterforce with a comparably smart and numerous country of geniuses in a datacenter, it won’t be possible to match the quality or quantity of drones, for cyberdefense to outsmart cyberoffense, etc. So the question of countermeasures reduces to the question of a balance of power in powerful AI. Here, I am concerned about the recursive or self-reinforcing property of powerful AI (which I discussed at the beginning of this essay): that each generation of AI can be used to design and train the next generation of AI. This leads to a risk of a runaway advantage, where the current leader in powerful AI may be able to increase their lead and may be difficult to catch up with. We need to make sure it is not an authoritarian country that gets to this loop first.</p><p>Furthermore, even if a balance of power can be achieved, there is still risk that the world could be split up into autocratic spheres, as in <em>Nineteen Eighty-Four</em>. Even if several competing powers each have their powerful AI models, and none can overpower the others, each power could still internally repress their own population, and would be very difficult to overthrow (since the populations don’t have powerful AI to defend themselves). It is thus important to prevent AI-enabled autocracy even if it doesn’t lead to a single country taking over the world.</p><h3><em>Defenses</em></h3><p>How do we defend against this wide range of autocratic tools and potential threat actors? As in the previous sections, there are several things I think we can do. First, we should absolutely not be selling chips, chip-making tools, or datacenters to the CCP. Chips and chip-making tools are the single greatest bottleneck to powerful AI, and blocking them is a simple but extremely effective measure, perhaps the most important single action we can take. It makes no sense to sell the CCP the tools with which to build an AI totalitarian state and possibly conquer us militarily. A number of complicated arguments are made to justify such sales, such as the idea that “spreading our tech stack around the world” allows “America to win” in some general, unspecified economic battle. In my view, this is like selling nuclear weapons to North Korea and then bragging that the missile casings are made by Boeing and so the US is “winning.” China is several years behind the US in their ability to produce frontier chips in quantity, and the critical period for building the country of geniuses in a datacenter is very likely to be within those next several years.<sup>35</sup> There is no reason to give a giant boost to their AI industry during this critical period.</p><p>Second, it makes sense to use AI to empower democracies to resist autocracies. This is the reason Anthropic considers it important to provide AI to the intelligence and defense communities in the US and its democratic allies. Defending democracies that are under attack, such as Ukraine and (via cyber attacks) Taiwan, seems especially high priority, as does empowering democracies to use their intelligence services to disrupt and degrade autocracies from the inside. At some level the only way to respond to autocratic threats is to match and outclass them militarily. A coalition of the US and its democratic allies, if it achieved predominance in powerful AI, would be in a position to not only defend itself against autocracies, but contain them and limit their AI totalitarian abuses.</p><p>Third, we need to draw a hard line against AI abuses within democracies. There need to be limits to what we allow our governments to do with AI, so that they don’t seize power or repress their own people. The formulation I have come up with is that we should use AI for national defense in all ways <em>except those which would make us more like our autocratic adversaries</em>. </p><p>Where should the line be drawn? In the list at the beginning of this section, two items—using AI for domestic mass surveillance and mass propaganda—seem to me like bright red lines and entirely illegitimate. Some might argue that there’s no need to do anything (at least in the US), since domestic mass surveillance is already illegal under the Fourth Amendment. But the rapid progress of AI may create situations that our existing legal frameworks are not well designed to deal with. For example, it would likely not be unconstitutional for the US government to conduct massively scaled recordings of all <em>public </em>conversations (e.g., things people say to each other on a street corner), and previously it would have been difficult to sort through this volume of information, but with AI it could all be transcribed, interpreted, and triangulated to create a picture of the attitude and loyalties of many or most citizens. I would support civil liberties-focused legislation (or maybe even a constitutional amendment) that imposes stronger guardrails against AI-powered abuses.</p><p>The other two items—fully autonomous weapons and AI for strategic decision-making—are harder lines to draw since they have legitimate uses in defending democracy, while also being prone to abuse. Here I think what is warranted is extreme care and scrutiny combined with guardrails to prevent abuses. My main fear is having too small a number of “fingers on the button,” such that one or a handful of people could essentially operate a drone army without needing any other humans to cooperate to carry out their orders. As AI systems get more powerful, we may need to have more direct and immediate oversight mechanisms to ensure they are not misused, perhaps involving branches of government other than the executive. I think we should approach fully autonomous weapons in particular with great caution,<sup>36</sup> and not rush into their use without proper safeguards.</p><p>Fourth, after drawing a hard line against AI abuses in democracies, we should use that precedent to create an international taboo against the worst abuses of powerful AI. I recognize that the current political winds have turned against international cooperation and international norms, but this is a case where we sorely need them. The world needs to understand the dark potential of powerful AI in the hands of autocrats, and to recognize that certain uses of AI amount to an attempt to permanently steal their freedom and impose a totalitarian state from which they can’t escape. I would even argue that in some cases, large-scale surveillance with powerful AI, mass propaganda with powerful AI, and certain types of <em>offensive </em>uses of fully autonomous weapons should be considered crimes against humanity. More generally, a robust norm against AI-enabled totalitarianism and all its tools and instruments is sorely needed.</p><p>It is possible to have an even stronger version of this position, which is that because the possibilities of AI-enabled totalitarianism are so dark, autocracy is simply not a form of government that people can accept in the post-powerful AI age. Just as feudalism became unworkable with the industrial revolution, the AI age could lead inevitably and logically to the conclusion that democracy (and, hopefully, democracy improved and reinvigorated by AI, as I discuss in <em>Machines of Loving Grace</em>) is the only viable form of government if humanity is to have a good future.</p><p>Fifth and finally, AI companies should be carefully watched, as should their connection to the government, which is necessary, but must have limits and boundaries. The sheer amount of capability embodied in powerful AI is such that ordinary corporate governance—which is designed to protect shareholders and prevent ordinary abuses such as fraud—is unlikely to be up to the task of governing AI companies. There may also be value in companies publicly committing to (perhaps even as part of corporate governance) not take certain actions, such as privately building or stockpiling military hardware, using large amounts of computing resources by single individuals in unaccountable ways, or using their AI products as propaganda to manipulate public opinion in their favor.</p><p>The danger here comes from many directions, and some directions are in tension with others. The only constant is that we must seek accountability, norms, and guardrails for everyone, even as we empower “good” actors to keep “bad” actors in check.</p><h2>4. Player piano</h2><h3><em>Economic disruption</em></h3><p>The previous three sections were essentially about security risks posed by powerful AI: risks from the AI itself, risks from misuse by individuals and small organizations and risks of misuse by states and large organizations. If we put aside security risks or assume they have been solved, the next question is economic. What will be the effect of this infusion of incredible “human” capital on the economy? Clearly, the most obvious effect will be to greatly increase economic growth. The pace of advances in scientific research, biomedical innovation, manufacturing, supply chains, the efficiency of the financial system, and much more are almost guaranteed to lead to a much faster rate of economic growth. In <em>Machines of Loving Grace</em>, I suggest that a 10–20% sustained annual GDP growth rate may be possible.</p><p>But it should be clear that this is a double-edged sword: what are the economic prospects for most existing humans in such a world? New technologies often bring labor market shocks, and in the past humans have always recovered from them, but I am concerned that this is because these previous shocks affected only a small fraction of the full possible range of human abilities, leaving room for humans to expand to new tasks. AI will have effects that are much broader and occur much faster, and therefore I worry it will be much more challenging to make things work out well.</p><h3><em>Labor market disruption</em></h3><p>There are two specific problems I am worried about: labor market displacement, and concentration of economic power. Let’s start with the first one. This is a topic that I <a href="https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic">warned about very publicly in 2025</a>, where I predicted that AI could displace half of all entry-level white collar jobs in the next 1–5 years, even as it accelerates economic growth and scientific progress. This warning started a public debate about the topic. Many CEOs, technologists, and economists agreed with me, but others assumed I was falling prey to a “lump of labor” fallacy and didn’t know how labor markets worked, and some didn’t see the 1–5-year time range and thought I was claiming AI is displacing jobs right now (which I agree it is likely not). So it is worth going through in detail why I am worried about labor displacement, to clear up these misunderstandings.</p><p>As a baseline, it’s useful to understand how labor markets <em>normally</em> respond to advances in technology. When a new technology comes along, it starts by making pieces of a given human job more efficient. For example, early in the Industrial Revolution, machines, such as upgraded plows, enabled human farmers to be more efficient at some aspects of the job. This improved the productivity of farmers, which increased their wages.</p><p>In the next step, some parts of the job of farming could be done <em>entirely</em> by machines, for example with the invention of the <a href="https://en.wikipedia.org/wiki/Threshing_machine">threshing machine</a> or <a href="https://en.wikipedia.org/wiki/Seed_drill">seed drill</a>. In this phase, humans did a lower and lower fraction of the job, but the work they <em>did</em> complete became more and more leveraged because it is complementary to the work of machines, and their productivity continued to rise. As described by <a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons’ paradox</a>, the wages of farmers and perhaps even the number of farmers continued to increase. Even when 90% of the job is being done by machines, humans can simply do 10x more of the 10% they still do, producing 10x as much output for the same amount of labor.</p><p>Eventually, machines do everything or almost everything, as with modern <a href="https://en.wikipedia.org/wiki/Combine_harvester">combine harvesters</a>, tractors, and other equipment. At this point farming as a form of human employment really does go into steep decline, and this potentially causes serious disruption in the short term, but because farming is just one of many useful activities that humans are able to do, people eventually switch to other jobs, such as operating factory machines. This is true even though farming accounted for a huge proportion of employment <em>ex ante</em>. 250 years ago, 90% of Americans <a href="https://www.nass.usda.gov/About_NASS/History_of_Ag_Statistics/index.php">lived on farms</a>; in Europe, 50–60% of employment <a href="https://ourworldindata.org/grapher/share-of-the-labor-force-employed-in-agriculture?time=1750..latest">was agricultural</a>. Now those percentages are in the low single digits in those places, because workers switched to industrial jobs (and later, knowledge work jobs). The economy can do what previously required most of the labor force with only 1–2% of it, freeing up the rest of the labor force to build an ever more advanced industrial society. There’s no fixed “<a href="https://en.wikipedia.org/wiki/Lump_of_labour_fallacy">lump of labor</a>,” just an ever-expanding ability to do <a href="https://en.wikipedia.org/wiki/Ephemeralization">more and more with less and less</a>. People’s wages rise in line with the GDP exponential and the economy maintains full employment once disruptions in the short term have passed.</p><p>It’s possible things will go roughly the same way with AI, but I would bet pretty strongly against it. Here are some reasons I think AI is likely to be different:</p><ul role="list"><li> <strong>Speed. </strong>The pace of progress in AI is much faster than for previous technological revolutions. For example, in the last 2 years, AI models went from barely being able to complete a single line of code, to <a href="https://x.com/bcherny/status/2004887829252317325">writing all or almost all of the code</a> for some people—including engineers at Anthropic.<sup>37</sup> Soon, they may do the entire task of a software engineer end to end.<sup>38</sup> It is hard for people to adapt to this pace of change, both to the changes in how a given job works and in the need to switch to new jobs. Even legendary programmers are increasingly <a href="https://x.com/karpathy/status/2004607146781278521">describing themselves as “behind.”</a> The pace may if anything continue to speed up, as AI coding models increasingly accelerate the task of AI development. To be clear, speed in itself does not mean labor markets and employment won’t eventually recover, it just implies the short-term transition will be unusually painful compared to past technologies, since humans and labor markets are slow to react and to equilibrate.</li><li> <strong>Cognitive breadth. </strong>As suggested by the phrase “country of geniuses in a datacenter,” AI will be capable of a very wide range of human cognitive abilities—perhaps all of them. This is very different from previous technologies like mechanized farming, transportation, or even computers.<sup>39</sup> This will make it harder for people to switch easily from jobs that are displaced to similar jobs that they would be a good fit for. For example, the general intellectual abilities required for entry-level jobs in, say, finance, consulting, and law are fairly similar, even if the specific knowledge is quite different. A technology that disrupted only one of these three would allow employees to switch to the two other close substitutes (or for undergraduates to switch majors). But disrupting all three at once (along with many other similar jobs) may be harder for people to adapt to. Furthermore, it’s not <em>just </em>that most existing jobs will be disrupted. That part has happened before—recall that farming was a huge percentage of employment. But farmers could switch to the relatively similar work of operating factory machines, even though that work hadn’t been common before. By contrast, AI is increasingly matching the general cognitive profile of humans, which means it will also be good at the new jobs that would ordinarily be created in response to the old ones being automated. Another way to say it is that AI isn’t a substitute for specific human jobs but rather a general labor substitute for humans.</li><li> <strong>Slicing by cognitive ability. </strong>Across a wide range of tasks, AI appears to be advancing from the bottom of the ability ladder to the top. For example, in coding our models have proceeded from the level of “a mediocre coder” to “a strong coder” to “a very strong coder.”<sup>40</sup> We are now starting to see the same progression in white-collar work in general. We are thus at risk of a situation where, instead of affecting people with specific skills or in specific professions (who can adapt by retraining), AI is affecting people with certain intrinsic cognitive properties, namely lower intellectual ability (which is harder to change). It is not clear where these people will go or what they will do, and I am concerned that they could form an unemployed or very-low-wage “underclass.” To be clear, things somewhat like this have happened before—for example, computers and the internet are believed by some economists to represent “<a href="https://www.sciencedirect.com/science/chapter/handbook/abs/pii/S0169721811024105">skill-biased technological change</a>.” But this skill biasing was both not as extreme as what I expect to see with AI, and is believed to have contributed to an increase in wage inequality,<sup>41</sup> so it is not exactly a reassuring precedent.</li><li> <strong>Ability to fill in the gaps. </strong>The way human jobs often adjust in the face of new technology is that there are many aspects to the job, and the new technology, even if it appears to directly replace humans, often has gaps in it. If someone invents a machine to make widgets, humans may still have to load raw material into the machine. Even if that takes only 1% as much effort as making the widgets manually, human workers can simply make 100x more widgets. But AI, in addition to being a rapidly advancing technology, is also a rapidly <em>adapting </em>technology. During every model release, AI companies carefully measure what the model is good at and what it isn’t, and customers also provide such information after the launch. Weaknesses can be addressed by collecting tasks that embody the current gap, and training on them for the next model. Early in generative AI, users noticed that AI systems had certain weaknesses (such as AI image models generating hands with the wrong number of fingers) and many assumed these weaknesses were inherent to the technology. If they were, it would limit job disruption. But pretty much every such weakness gets addressed quickly— often, within just a few months.</li></ul><p>It’s worth addressing common points of skepticism. First, there is the argument that economic diffusion will be slow, such that even if the underlying technology is <em>capable </em>of doing most human labor, the actual application of it across the economy may be much slower (for example in industries that are far from the AI industry and slow to adopt). Slow diffusion of technology is <a href="https://www.ft.com/content/3b93e647-2a8b-4fb4-831d-e27adf4db5f8">definitely real</a>—I talk to people from a wide variety of enterprises, and there are places where the adoption of AI will take years. That’s why my prediction for 50% of entry level white collar jobs being disrupted is 1–5 years, even though I suspect we’ll have powerful AI (which would be, technologically speaking, enough to do <em>most or all </em>jobs, not just entry level) in much less than 5 years. But diffusion effects merely buy us time. And I am not confident they will be as slow as people predict. Enterprise AI adoption is growing at rates much faster than any previous technology, largely on the pure strength of the technology itself. Also, even if traditional enterprises are slow to adopt new technology, startups will spring up to serve as “glue” and make the adoption easier. If that doesn’t work, the startups may simply disrupt the incumbents directly.</p><p>That could lead to a world where it isn’t so much that specific jobs are disrupted as it is that large enterprises are disrupted in general and replaced with much less labor-intensive startups. This could also lead to a world of “geographic inequality,” where an increasing fraction of the world’s wealth is concentrated in Silicon Valley, which becomes its own economy running at a different speed than the rest of the world and leaving it behind. All of these outcomes would be great for economic growth—but not so great for the labor market or those who are left behind.</p><p>Second, some people say that human jobs will move to the physical world, which avoids the whole category of “cognitive labor” where AI is progressing so rapidly. I am not sure how safe this is, either. A lot of physical labor is already being done by machines (e.g., manufacturing) or will soon be done by machines (e.g., driving). Also, sufficiently powerful AI will be able to accelerate the development of robots, and then control those robots in the physical world. It may buy some time (which is a good thing), but I’m worried it won’t buy much. And even if the disruption was limited only to cognitive tasks, it would still be an unprecedentedly large and rapid disruption.</p><p>Third, perhaps some tasks inherently require or greatly benefit from a human touch. I’m a little more uncertain about this one, but I’m still skeptical that it will be enough to offset the bulk of the impacts I described above. AI is already widely used for customer service. Many people <a href="https://undark.org/2025/11/04/chatbot-mental-health/">report</a> that it is easier to talk to AI about their personal problems than to talk to a therapist—that the AI is more patient. When my sister was struggling with medical problems during a pregnancy, she felt she wasn’t getting the answers or support she needed from her care providers, and she found Claude to have a better bedside manner (as well as succeeding better at diagnosing the problem). I’m sure there are some tasks for which a human touch really is important, but I’m not sure how many—and here we’re talking about finding work for nearly everyone in the labor market.</p><p>Fourth, some may argue that comparative advantage will still protect humans. Under the <a href="https://en.wikipedia.org/wiki/Comparative_advantage">law of comparative advantage</a>, even if AI is better than humans at everything, any <em>relative </em>differences between the human and AI profile of skills creates a basis of trade and specialization between humans and AI. The problem is that if AIs are literally thousands of times more productive than humans, this logic starts to break down. Even tiny <a href="https://en.wikipedia.org/wiki/Transaction_cost">transaction costs</a> could make it not worth it for AI to trade with humans. And human wages may be very low, even if they technically have something to offer.</p><p>It’s possible all of these factors can be addressed—that the labor market is resilient enough to adapt to even such an enormous disruption. But even if it can eventually adapt, the factors above suggest that the short-term shock will be unprecedented in size.</p><h3><em>Defenses</em></h3><p>What can we do about this problem? I have several suggestions, some of which Anthropic is already doing. The first thing is simply to get accurate data about what is happening with job displacement in real time. When an economic change happens very quickly, it’s hard to get reliable data about what is happening, and without reliable data it is hard to design effective policies. For example, government data is currently lacking granular, high-frequency data on AI adoption across firms and industries. For the last year Anthropic has been operating and publicly releasing an <a href="https://www.anthropic.com/economic-index">Economic Index</a> that shows use of our models almost in real time, broken down by industry, task, location, and even things like whether a task was being automated or conducted collaboratively. We also have an <a href="https://www.anthropic.com/news/introducing-the-anthropic-economic-advisory-council">Economic Advisory Council</a> to help us interpret this data and see what is coming.</p><p>Second, AI companies have a choice in how they work with enterprises. The very inefficiency of traditional enterprises means that their rollout of AI can be very path dependent, and there is some room to choose a better path. Enterprises often have a choice between “cost savings” (doing the same thing with fewer people) and “innovation” (doing more with the same number of people). The market will inevitably produce both eventually, and any competitive AI company will have to serve some of both, but there may be some room to steer companies towards innovation when possible, and it may buy us some time. Anthropic is actively thinking about this.</p><p>Third, companies should think about how to take care of their employees. In the short term, being creative about ways to reassign employees within companies may be a promising way to stave off the need for layoffs. In the long term, in a world with enormous total wealth, in which many companies increase greatly in value due to increased productivity and capital concentration, it may be feasible to pay human employees even long after they are no longer providing economic value in the traditional sense. Anthropic is currently considering a range of possible pathways for our own employees that we will share in the near future.</p><p>Fourth, wealthy individuals have an obligation to help solve this problem. It is sad to me that many wealthy individuals (especially in the tech industry) have recently adopted a cynical and nihilistic attitude that philanthropy is inevitably fraudulent or useless. Both private philanthropy like the <a href="https://www.gatesfoundation.org/">Gates Foundation</a> and public programs like <a href="https://en.wikipedia.org/wiki/President%27s_Emergency_Plan_for_AIDS_Relief">PEPFAR</a> have saved tens of millions of lives in the developing world, and helped to create economic opportunity in the developed world. All of Anthropic’s co-founders have pledged to donate 80% of our wealth, and Anthropic’s staff have individually pledged to donate company shares worth billions at current prices—donations that the company has committed to matching.</p><p>Fifth, while all the above private actions can be helpful, ultimately a macroeconomic problem this large will require government intervention. The natural policy response to an enormous economic pie coupled with high inequality (due to a lack of jobs, or poorly paid jobs, for many) is progressive taxation. The tax could be general or could be targeted against AI companies in particular. Obviously tax design is complicated, and there are many ways for it to go wrong. I don’t support poorly designed tax policies. I think the extreme levels of inequality predicted in this essay justify a more robust tax policy on basic moral grounds, but I can also make a pragmatic argument to the world’s billionaires that it’s in their interest to support a good version of it: if they don’t support a good version, they’ll inevitably get a bad version designed by a mob.</p><p>Ultimately, I think of all of the above interventions as ways to buy time. In the end AI will be able to do everything, and we need to grapple with that. It’s my hope that by that time, we can use AI itself to help us restructure markets in ways that work for everyone, and that the interventions above can get us through the transitional period.</p><h3><em>Economic concentration of power</em></h3><p>Separate from the problem of job displacement or economic inequality <em>per se</em> is the problem of <em>economic concentration of power.</em> Section 1 discussed the risk that humanity gets disempowered by AI, and Section 3 discussed the risk that citizens get disempowered by their governments by force or coercion. But another kind of disempowerment can occur if there is such a huge concentration of wealth that a small group of people effectively controls government policy with their influence, and ordinary citizens have no influence because they lack economic leverage. Democracy is ultimately backstopped by the idea that the population as a whole is necessary for the operation of the economy. If that economic leverage goes away, then the implicit social contract of democracy may stop working. <a href="https://intelligence-curse.ai/">Others have written about this</a>, so I needn’t go into great detail about it here, but I agree with the concern, and I worry it is already starting to happen.</p><p>To be clear, I am not opposed to people making a lot of money. There’s a strong argument that it incentivizes economic growth under normal conditions. I am sympathetic to concerns about impeding innovation by killing the golden goose that generates it. But in a scenario where GDP growth is 10–20% a year and AI is rapidly taking over the economy, yet single individuals hold appreciable fractions of the GDP, innovation is <em>not </em>the thing to worry about. The thing to worry about is a level of wealth concentration that will break society.</p><p>The most famous example of extreme concentration of wealth in US history is the <a href="https://en.wikipedia.org/wiki/Gilded_Age">Gilded Age</a>, and the wealthiest industrialist of the Gilded Age was <a href="https://en.wikipedia.org/wiki/John_D._Rockefeller">John D. Rockefeller</a>. Rockefeller’s wealth amounted to ~2% of the US GDP at the time.<sup>42</sup> A similar fraction today would lead to a fortune of $600B, and the richest person in the world today (Elon Musk) already exceeds that, at <a href="https://www.reuters.com/business/autos-transportation/elon-musk-becomes-first-person-worth-700-billion-after-court-ruling-pay-package-2025-12-20/">roughly $700B</a>. So we are already at historically unprecedented levels of wealth concentration, even <em>before </em>most of the economic impact of AI. I don’t think it is too much of a stretch (if we get a “country of geniuses”) to imagine AI companies, semiconductor companies, and perhaps downstream application companies generating ~$3T in revenue per year,<sup>43</sup> being valued at ~$30T, and leading to personal fortunes well into the trillions. In that world, the debates we have about tax policy today simply won’t apply as we will be in a fundamentally different situation.</p><p>Related to this, the coupling of this economic concentration of wealth with the political system already concerns me. AI datacenters already represent a substantial fraction of US economic growth,<sup>44</sup> and are thus strongly tying together the financial interests of large tech companies (which are increasingly focused on either AI or AI infrastructure) and the political interests of the government in a way that can produce perverse incentives. We already see this through the reluctance of tech companies to criticize the US government, and the government’s support for extreme anti-regulatory policies on AI.</p><h3><em>Defenses</em></h3><p>What can be done about this? First, and most obviously, companies should simply choose not to be part of it. Anthropic has always strived to be a policy actor and not a political one, and to maintain our authentic views whatever the administration. We’ve spoken up in favor of <a href="https://www.nytimes.com/2025/06/05/opinion/anthropic-ceo-regulate-transparency.html">sensible AI regulation</a> and <a href="https://www.wsj.com/opinion/trump-can-keep-americas-ai-advantage-china-chips-data-eccdce91?gaa_at=eafs&amp;gaa_n=AWEtsqespyCL3hcx_9DpJWbIPX1vrtS1raPgFoBNK8ltnrjwedpX2NuvVu1K_yZ1arw%3D&amp;gaa_ts=696c6c70&amp;gaa_sig=wef9kKocpL9PU07UoiPS6kj_o_Nwy_VSufM6gltIvdjQFhb8HRLtpSzp4Z8WDG6v3leg0ODX4HOJjWblvZe2pw%3D%3D">export controls</a> that are in the public interest, even when these are at odds with government policy.<sup>45</sup> Many people have told me that we should stop doing this, that it could lead to unfavorable treatment, but in the year we’ve been doing it, Anthropic’s valuation has increased by over 6x, an almost unprecedented jump at our commercial scale.</p><p>Second, the AI industry needs a healthier relationship with government—one based on substantive policy engagement rather than political alignment. Our choice to engage on policy substance rather than politics is sometimes read as a tactical error or failure to “read the room” rather than a principled decision, and that framing concerns me. In a healthy democracy, companies should be able to advocate for good policy for its own sake. Related to this, a public backlash against AI is brewing: this could be a corrective, but it<strong>’</strong>s currently unfocused. Much of it targets issues that aren’t actually problems (like <a href="https://newsletter.semianalysis.com/p/from-tokens-to-burgers-a-water-footprint?hide_intro_popup=true">datacenter</a> <a href="https://andymasley.substack.com/p/the-ai-water-issue-is-fake">water usage</a>) and proposes solutions (like datacenter bans or poorly designed wealth taxes) that wouldn’t address the real concerns. The underlying issue that deserves attention is ensuring that AI development remains accountable to the public interest, not captured by any particular political or commercial alliance, and it seems important to focus the public discussion there.</p><p>Third, the macroeconomic interventions I described earlier in this section, as well as a resurgence of private philanthropy, can help to balance the economic scales, addressing both the job displacement and concentration of economic power problems at once. We should look to the history of our country here: even in the Gilded Age, industrialists such as <a href="https://www.sciencedirect.com/science/article/abs/pii/S096262981500027X">Rockefeller</a> and <a href="https://www.carnegie.org/about/our-history/gospelofwealth/">Carnegie</a> felt a strong obligation to society at large, a feeling that society had contributed enormously to their success and they needed to give back. That spirit seems to be increasingly missing today, and I think it is a large part of the way out of this economic dilemma. Those who are at the forefront of AI’s economic boom should be willing to give away both their wealth and their power.</p><h2>5. Black seas of infinity</h2><h3><em>Indirect effects</em></h3><p>This last section is a catchall for unknown unknowns, particularly things that could go wrong as an indirect result of positive advances in AI and the resulting acceleration of science and technology in general. Suppose we address all the risks described so far, and begin to reap the benefits of AI. We will likely get a “<a href="https://www.darioamodei.com/essay/machines-of-loving-grace">century of scientific and economic progress compressed into a decade</a>,” and this will be hugely positive for the world, but we will then have to contend with the problems that arise from this rapid rate of progress, and those problems may come at us fast. We may also encounter other risks that occur indirectly as a consequence of AI progress and are hard to anticipate in advance.</p><p>By the nature of unknown unknowns it is impossible to make an exhaustive list, but I’ll list three possible concerns as illustrative examples for what we should be watching for:</p><ul role="list"><li> <strong>Rapid advances in biology. </strong>If we do get a century of medical progress in a few years, it is possible that we will greatly increase the human lifespan, and there is a chance we also gain radical capabilities like the ability to increase human intelligence or radically modify human biology. Those would be big changes in what is possible, happening very quickly. They could be positive if responsibly done (which is my hope, as described in <em>Machines of Loving Grace</em>), but there is always a risk they go very wrong—for example, if efforts to make humans smarter also make them more unstable or power-seeking. There is also the issue of “<a href="https://en.wikipedia.org/wiki/Mind_uploading">uploads</a>” or “whole brain emulation,” digital human minds instantiated in software, which might someday help humanity transcend its physical limitations, but which also carry <a href="https://qntm.org/mmacevedo">risks I find disquieting</a>.</li><li> <strong>AI changes human life in an unhealthy way. </strong>A world with billions of intelligences that are much smarter than humans at everything is going to be a very weird world to live in. Even if AI doesn’t actively aim to attack humans (Section 1), and isn’t explicitly used for oppression or control by states (Section 3), there is a lot that could go wrong short of this, via normal business incentives and nominally consensual transactions. We see early hints of this in the concerns about AI psychosis, <a href="https://www.cbsnews.com/news/chatgpt-lawsuit-colordo-man-suicide-openai-sam-altman/">AI driving people to suicide</a>, and concerns about romantic relationships with AIs. As an example, could powerful AIs invent some new religion and convert millions of people to it? Could most people end up “addicted” in some way to AI interactions? Could people end up being “puppeted” by AI systems, where an AI essentially watches their every move and tells them exactly what to do and say at all times, leading to a “good” life but one that lacks freedom or any pride of accomplishment? It would not be hard to generate dozens of these scenarios if I sat down with the creator of <a href="https://en.wikipedia.org/wiki/Black_Mirror"><em>Black Mirror</em></a> and tried to brainstorm them. I think this points to the importance of things like improving <a href="https://www.anthropic.com/constitution">Claude’s Constitution</a>, over and above what is necessary for preventing the issues in Section 1. Making sure that AI models <em>really </em>have their users’ long-term interests at heart, in a way thoughtful people would endorse rather than in some subtly distorted way, seems critical.</li><li> <strong>Human purpose. </strong>This is related to the previous point, but it’s not so much about specific human interactions with AI systems as it is about how human life changes in general in a world with powerful AI. Will humans be able to find purpose and meaning in such a world? I think this is a matter of attitude: as I said in <em>Machines of Loving Grace</em>, I think human purpose does not depend on being the best in the world at something, and humans can find purpose even over very long periods of time through stories and projects that they love. We simply need to break the link between the generation of economic value and self-worth and meaning. But that is a transition society has to make, and there is always the risk we don’t handle it well.</li></ul><p>My hope with all of these potential problems is that in a world with powerful AI that we trust not to kill us, that is not the tool of an oppressive government, and that is genuinely working on our behalf, we can use AI itself to anticipate and prevent these problems. But that is not guaranteed—like all of the other risks, it is something we have to handle with care.</p><h2>Humanity’s test</h2><p>Reading this essay may give the impression that we are in a daunting situation. I certainly found it daunting to write, in contrast with <em>Machines of Loving Grace, </em>which felt like giving form and structure to surpassingly beautiful music that had been echoing in my head for years. And there is much about the situation that genuinely is hard. AI brings threats to humanity from multiple directions, and there is genuine tension between the different dangers, where mitigating some of them risks making others worse if we do not thread the needle extremely carefully.</p><p>Taking time to carefully build AI systems so they do not autonomously threaten humanity is in genuine tension with the need for democratic nations to stay ahead of authoritarian nations and not be subjugated by them. But in turn, the same AI-enabled tools that are necessary to fight autocracies can, if taken too far, be turned inward to create tyranny in our own countries. AI-driven terrorism could kill millions through the misuse of biology, but an overreaction to this risk could lead us down the road to an autocratic surveillance state. The labor and economic concentration effects of AI, in addition to being grave problems in their own right, may force us to face the other problems in an environment of public anger and perhaps even civil unrest, rather than being able to call on the better angels of our nature. Above all, the sheer <em>number </em>of risks, including unknown ones, and the need to deal with all of them at once, creates an intimidating gauntlet that humanity must run.</p><p>Furthermore, the last few years should make clear that the idea of stopping or even substantially slowing the technology is fundamentally untenable. The formula for building powerful AI systems is incredibly simple, so much so that it can almost be said to emerge spontaneously from the right combination of data and raw computation. Its creation was probably inevitable the instant humanity invented the transistor, or arguably even earlier when we first learned to control fire. If one company does not build it, others will do so nearly as fast. If all companies in democratic countries stopped or slowed development, by mutual agreement or regulatory decree, then authoritarian countries would simply keep going. Given the incredible economic and military value of the technology, together with the lack of any meaningful enforcement mechanism, I don’t see <a href="https://en.wikipedia.org/wiki/Security_dilemma">how we could possibly convince them to stop</a>.</p><p>I do see a path to a <em>slight</em> moderation in AI development that is compatible with a <a href="https://en.wikipedia.org/wiki/Realism_(international_relations)">realist view of geopolitics</a>. That path involves slowing down the march of autocracies towards powerful AI for a few years by denying them the resources they need to build it,<sup>46</sup> namely chips and semiconductor manufacturing equipment. This in turn gives democratic countries a buffer that they can “spend” on building powerful AI more carefully, with more attention to its risks, while still proceeding fast enough to comfortably beat the autocracies. The race between AI companies within democracies can then be handled under the umbrella of a common legal framework, via a mixture of industry standards and regulation.</p><p>Anthropic has advocated very hard for this path, by pushing for chip export controls and judicious regulation of AI, but even these seemingly common-sense proposals have largely been rejected by policymakers in the United States (which is the country where it’s most important to have them). There is so much money to be made with AI—literally trillions of dollars per year—that even the simplest measures are finding it difficult to overcome the <a href="https://en.wikipedia.org/wiki/Political_economy">political economy</a> inherent in AI. This is the trap: AI is so powerful, such a glittering prize, that it is very difficult for human civilization to impose any restraints on it at all.</p><p>I can imagine, as Sagan did in <em>Contact</em>, that this same story plays out on thousands of worlds. A species gains sentience, learns to use tools, begins the exponential ascent of technology, faces the crises of industrialization and nuclear weapons, and if it survives those, confronts the hardest and final challenge when it learns how to shape sand into machines that think. Whether we survive that test and go on to build the beautiful society described in <em>Machines of Loving Grace</em>, or succumb to slavery and destruction, will depend on our character and our determination as a species, our spirit and our soul.</p><p>Despite the many obstacles, I believe humanity has the strength inside itself to pass this test. I am encouraged and inspired by the thousands of researchers who have devoted their careers to helping us understand and steer AI models, and to shaping the character and constitution of these models. I think there is now a good chance that those efforts bear fruit in time to matter. I am encouraged that at least some companies have <a href="https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/">stated they<strong>’</strong>ll pay</a> meaningful commercial costs to block their models from contributing to the threat of bioterrorism. I am encouraged that a few brave people have resisted the prevailing political winds and <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53">passed</a> <a href="https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A">legislation</a> that puts the first early seeds of sensible guardrails on AI systems. I am encouraged that the <a href="https://www.pewresearch.org/internet/2025/04/03/views-of-risks-opportunities-and-regulation-of-ai/#6d2b9b266433bfda6c8fc2f498738a4c">public understands that AI carries risks and wants those risks addressed</a>. I am encouraged by the indomitable spirit of freedom around the world and the determination to resist tyranny wherever it occurs.</p><p>But we will need to step up our efforts if we want to succeed. The first step is for those closest to the technology to simply tell the truth about the situation humanity is in, which I have always tried to do; I’m doing so more explicitly and with greater urgency with this essay. The next step will be convincing the world’s thinkers, policymakers, companies, and citizens of the imminence and overriding importance of this issue—that it is worth expending thought and political capital on this in comparison to the thousands of other issues that dominate the news every day. Then there will be a time for courage, for enough people to buck the prevailing trends and stand on principle, even in the face of threats to their economic interests and personal safety. </p><p>The years in front of us will be impossibly hard, asking more of us than we think we can give. But in my time as a researcher, leader, and citizen, I have seen enough courage and nobility to believe that we can win—that when put in the darkest circumstances, humanity has a way of gathering, seemingly at the last minute, the strength and wisdom needed to prevail. We have no time to lose.</p></div><hr><p>I would like to thank Erik Brynjolfsson, Ben Buchanan, Mariano-Florentino Cuéllar, Allan Dafoe, Kevin Esvelt, Nick Beckstead, Richard Fontaine, Jim McClave, and very many of the staff at Anthropic for their helpful comments on drafts of this essay.</p></section><section><h2>Footnotes</h2><div data-footnotes="footnotes"><ol role="list"><li>This is symmetric to a point I made in <em>Machines of Loving Grace</em>, where I started by saying that AI’s upsides shouldn’t be thought of in terms of a prophecy of salvation, and that it’s important to be concrete and grounded and to avoid grandiosity. Ultimately, prophecies of salvation and prophecies of doom are unhelpful for confronting the real world, for basically the same reasons.</li><li>Anthropic’s goal is to remain consistent through such changes. When talking about AI risks was politically popular, Anthropic cautiously advocated for a judicious and evidence-based approach to these risks. Now that talking about AI risks is politically unpopular, Anthropic continues to cautiously advocate for a judicious and evidence-based approach to these risks.</li><li>Over time, I have gained increasing confidence in the trajectory of AI and the likelihood that it will surpass human ability across the board, but some uncertainty still remains.</li><li>Export controls for chips are a great example of this. They are simple and appear to mostly just work.</li><li>And of course, the hunt for such evidence must be intellectually honest, such that it could also turn up evidence of a lack of danger. Transparency through model cards and other disclosures is an attempt at such an intellectually honest endeavor.</li><li>Indeed, since writing<em> Machines of Loving Grace</em> in 2024, AI systems have become capable of doing tasks that take humans several hours, with METR recently assessing that Opus 4.5 can do about four human hours of work with 50% reliability.</li><li>And to be clear, even if powerful AI is only 1–2 years away in a technical sense, many of its societal consequences, both positive and negative, may take a few years longer to occur. This is why I can simultaneously think that AI will disrupt 50% of <em>entry-level </em>white-collar jobs over 1–5 years, while also thinking we may have AI that is more capable than <em>everyone </em>in only 1–2 years.</li><li>It is worth adding that the <em>public </em>(as compared to policymakers) does seem to be very concerned with AI risks. I think some of their focus is correct (i.e. AI job displacement), and some is misguided (such as concerns about water use of AI, which is not significant). This backlash gives me hope that a consensus around addressing risks is possible, but so far it has not yet been translated into policy changes, let alone effective or well-targeted policy changes.</li><li>They can also, of course, manipulate (or simply pay) large numbers of humans into doing what they want in the physical world.</li><li>I don’t think this is a straw man: it’s my understanding, for example, that <a href="https://www.youtube.com/watch?v=LMuun5FGL28">Yann LeCun holds this position</a>.</li><li>For example, see Section 5.5.2 (p. 63–66) of the <a href="https://www.anthropic.com/claude-4-system-card">Claude 4 system card</a>.</li><li>There are also a number of other assumptions inherent in the simple model, which I won’t discuss here. Broadly, they should make us less worried about the specific simple story of misaligned power-seeking, but also more worried about possible unpredictable behavior we haven’t anticipated.</li><li><a href="https://en.wikipedia.org/wiki/Ender%27s_Game"><em>Ender’s Game</em></a><em> </em>describes a version of this involving humans rather than AI.</li><li>For example, models may be told not to do various bad things, and also to obey humans, but may then observe that many humans do exactly those bad things! It’s not clear how this contradiction would resolve (and a well-designed constitution should encourage the model to handle these contradictions gracefully), but this type of dilemma is not so different from the supposedly “artificial” situations that we put AI models in during testing.</li><li>Incidentally, one consequence of the constitution being a natural-language document is that it is legible to the world, and that means it can be critiqued by anyone and compared to similar documents by other companies. It would be valuable to create a race to the top that not only encourages companies to release these documents, but encourages them to be good.</li><li>There’s even a hypothesis about a deep unifying principle connecting the character-based approach from Constitutional AI to results from interpretability and alignment science. According to the hypothesis, the fundamental mechanisms driving Claude originally arose as ways for it to simulate characters in pretraining, such as predicting what the characters in a novel would say. This would suggest that a useful way to think about the constitution is more like a character description that the model uses to instantiate a consistent persona. It would also help us explain the “<a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking">I must be a bad person</a>” results I mentioned above (because the model is trying to <em>act as if</em> it’s a coherent character—in this case a bad one), and would suggest that interpretability methods should be able to discover “psychological traits” within models. Our researchers are working on ways to test this hypothesis.</li><li>To be clear, monitoring is done in a privacy-preserving way.</li><li>Even in our own experiments with what are essentially voluntarily imposed rules with our <a href="https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy">Responsible Scaling Policy</a>, we have found over and over again that it’s very easy to end up being too rigid, by drawing lines that seem important ex ante but turn out to be silly in retrospect. It is just very easy to set rules about the wrong things when a technology is advancing rapidly.</li><li>SB 53 and RAISE do not apply at all to companies with under $500M in annual revenue. They only apply to larger, more established companies like Anthropic.</li><li>I originally read Joy’s essay 25 years ago, when it was written, and it had a profound impact on me. Then and now, I do see it as too pessimistic—I don’t think broad “relinquishment” of whole areas of technology, which Joy suggests, is the answer—but the issues it raises were surprisingly prescient, and Joy also writes with a deep sense of compassion and humanity that I admire.</li><li>We do have to worry about state actors, now and in the future, and I discuss that in the next section.</li><li>There is <a href="https://www.nber.org/digest/sep02/poverty-and-low-education-dont-cause-terrorism">evidence</a> that <a href="https://www.sas.rochester.edu/psc/clarke/214/Krueger03.pdf">many</a> terrorists are at least relatively well-educated, which might seem to contradict what I’m arguing here about a negative correlation between ability and motivation. But I think in actual fact they are compatible observations: if the ability threshold for a successful attack is high, then almost by definition those who <em>currently </em>succeed must have high ability, even if ability and motivation are negatively correlated. But in a world where the limitations on ability were removed (e.g., with future LLMs), I’d predict that a substantial population of people with the motivation to kill but lower ability would start to do so—just as we see for crimes that don’t require much ability (like school shootings).</li><li>Aum Shinrikyo did try, however. The leader of Aum Shinrikyo, Seiichi Endo, had training in virology from Kyoto University, <a href="https://www.cnas.org/publications/reports/aum-shinrikyo-second-edition-english">and attempted to produce both anthrax and ebola</a>. However, as of 1995, even he lacked enough expertise and resources to succeed at this. The bar is now substantially lower, and LLMs could reduce it even further.</li><li>A bizarre phenomenon relating to mass murderers is that the style of murder they choose operates almost as a grotesque sort of fad. In the 1970s and 1980s, serial killers were very common, and new serial killers often copied the behavior of more established or famous serial killers. In the 1990s and 2000s, mass shootings became more common, while serial killers became less common. There is no technological change that triggered these patterns of behavior, it just appears that violent murderers were copying each others’ behavior and the “popular” thing to copy changed.</li><li>Casual jailbreakers sometimes believe that they’ve compromised these classifiers when they get the model to output one specific piece of information, such as the genome sequence of a virus. But as I explained before, the threat model we are worried about involves step-by-step, interactive advice that extends over weeks or months about specific obscure steps in the bioweapons production process, and this is what our classifiers aim to defend against. (We often describe our research as looking for “universal” jailbreaks—ones that don’t just work in one specific or narrow context, but broadly open up the model’s behavior.)</li><li>Though we will continue to invest in work to make our classifiers more efficient, and it may make sense for companies to share advances like these with one another.</li><li>Obviously, I do not think companies should have to disclose technical details about the specific steps in biological weapons production that they are blocking, and the transparency legislation that has been passed so far (SB 53 and RAISE) accounts for this issue.</li><li>Another related idea is “resilience markets” where the government encourages stockpiling of PPE, respirators, and other essential equipment needed to respond to a biological attack by promising ahead of time to pay a pre-agreed price for this equipment in an emergency. This incentivizes suppliers to stockpile such equipment without fear that the government will seize it without compensation.</li><li>Why am I more worried about large actors for seizing power, but small actors for causing destruction? Because the dynamics are different. Seizing power is about whether one actor can amass enough strength to overcome everyone else—thus we should worry about the most powerful actors and/or those closest to AI. Destruction, by contrast, can be wrought by those with little power if it is much harder to defend against than to cause. It is then a game of defending against the most <em>numerous </em>threats, which are likely to be smaller actors.</li><li>This might sound like it is in tension with my point that attack and defense may be more balanced with cyberattacks than with bioweapons, but my worry here is that if a country’s AI is the most powerful in the world, then others will not be able to defend even if the technology itself has an intrinsic attack-defense balance.</li><li>For example, in the United States this includes the fourth amendment and the <a href="https://en.wikipedia.org/wiki/Posse_Comitatus_Act">Posse Comitatus Act</a>.</li><li>Also, to be clear, there are some arguments for building large datacenters in countries with varying governance structures, particularly if they are controlled by companies in democracies. Such buildouts could in principle help democracies compete better with the CCP, which is the greater threat. I also think such datacenters don’t pose much risk unless they are very large. But on balance, I think caution is warranted when placing very large datacenters in countries where institutional safeguards and rule-of-law protections are less well-established.</li><li>This is, of course, also an argument for <a href="https://councilonstrategicrisks.org/research/reports/nuclear-decision-making-and-risk-reduction-in-an-era-of-technological-complexity/">improving the security of the nuclear deterrent</a> to make it <a href="https://onlinelibrary.wiley.com/doi/10.1111/risa.70136">more likely to be robust</a> against powerful AI, and nuclear-armed democracies should do this. But we don’t know what a powerful AI will be capable of or which defenses, if any, will work against it, so we should not assume that these measures will necessarily solve the problem.</li><li>There is also the risk that even if the nuclear deterrent remains effective, an attacking country might decide to call our bluff—it’s unclear whether we’d be willing to use nuclear weapons to defend against a drone swarm even if the drone swarm has a substantial risk of conquering us. Drone swarms might be a new thing that is less severe than nuclear attacks but more severe than conventional attacks. Alternatively, differing assessments of the effectiveness of the nuclear deterrent in the age of AI might alter the game theory of nuclear conflict in a destabilizing manner.</li><li>To be clear, I would believe it is the right strategy not to sell chips to China, even if the timeline to powerful AI were substantially longer. We cannot get the Chinese “addicted” to American chips—they are determined to develop their native chip industry one way or another. It will take them many years to do so, and all we are doing by selling them chips is giving them a big boost during that time.</li><li>To be clear, most of what is being used in Ukraine and Taiwan today are not <em>fully </em>autonomous weapons. These are coming, but not here today.</li><li>Our model card for <a href="https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf">Claude Opus 4.5</a>, our most recent model, shows that Opus performs better on a performance engineering interview frequently given at Anthropic than any interviewee in the history of the company.</li><li>“Writing all of the code” and “doing the task of a software engineer end to end” are very different things, because software engineers do much more than just write code, including testing, dealing with environments, files, and installation, managing cloud compute deployments, iterating on products, and much more.</li><li>Computers are general in a sense, but are clearly incapable on their own of the vast majority of human cognitive abilities, even as they greatly exceed humans in a few areas (such as arithmetic). Of course, things built <em>on top </em>of computers, such as AI, are now capable of a wide range of cognitive abilities, which is what this essay is about.</li><li>To be clear, AI models do not have precisely the same profile of strengths and weaknesses as humans. But they are also advancing fairly uniformly along every dimension, such that having a spiky or uneven profile may not ultimately matter.</li><li>Though there is <a href="https://davidcard.berkeley.edu/papers/skill-tech-change.pdf">debate</a> <a href="https://jhr.uwpress.org/content/58/6/1783.abstract">among</a> <a href="https://www.epi.org/publication/technology-inequality-dont-blame-the-robots/">economists</a> about this idea.</li><li>Personal wealth is a “stock,” while GDP is a “flow,” so this isn’t a claim that Rockefeller owned 2% of the economic value in the United States. But it’s harder to measure the total wealth of a nation than the GDP, and people’s individual incomes vary a lot per year, so it’s hard to make a ratio in the same units. The ratio of the largest personal fortune to GDP, while not comparing apples to apples, is nevertheless a perfectly reasonable benchmark for extreme wealth concentration.</li><li>The total value of labor across the economy is $60T/year, so $3T/year would correspond to 5% of this. That amount could be earned by a company that supplied labor for 20% of the cost of humans and had 25% market share, even if the demand for labor did not expand (which it almost certainly would due to the lower cost).</li><li>To be clear, I do not think actual AI productivity is yet responsible for a substantial fraction of US economic growth. Rather, I think the datacenter spending represents growth caused by anticipatory investment that amounts to the market expecting<em> future</em> AI-driven economic growth and investing accordingly.</li><li>When we agree with the administration, we say so, and we look for <a href="https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership">points of agreement where mutually supported policies</a> are genuinely good for the world. We are aiming to be honest brokers rather than backers or opponents of any given political party.</li><li>I don’t think anything more than a few years is possible: on longer timescales, they will build their own chips.</li></ol></div></section></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DHS keeps trying and failing to unmask anonymous ICE critics online (177 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/</link>
            <guid>46768081</guid>
            <pubDate>Mon, 26 Jan 2026 16:58:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/">https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/</a>, See on <a href="https://news.ycombinator.com/item?id=46768081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>The Department of Homeland Security (DHS) has backed down from a <a href="https://arstechnica.com/tech-policy/2026/01/instagram-user-fights-dhs-for-the-right-to-post-ice-sightings-anonymously/">fight to unmask the owners of Instagram and Facebook accounts</a> monitoring Immigration and Customs Enforcement (ICE) activity in Pennsylvania.</p>
<p>One of the anonymous account holders, John Doe, sued to block ICE from identifying him and other critics online through summonses to Meta that he claimed infringed on core First Amendment-protected activity.</p>
<p>DHS initially fought Doe’s motion to quash the summonses, arguing that the community watch groups endangered ICE agents by posting “pictures and videos of agents’ faces, license plates, and weapons, among other things.” This was akin to “threatening ICE agents to impede the performance of their duties,” DHS alleged. DHS’s arguments echoed DHS Secretary Kristi Noem, who has claimed that identifying ICE agents is a crime, even though <a href="https://www.wired.com/story/ice-agents-are-doxing-themselves/">Wired noted</a> that ICE employees often post easily discoverable LinkedIn profiles.</p>
<p>To Doe, the agency seemed intent on testing the waters to see if it could seize authority to unmask all critics online by invoking a customs statute that allows agents to subpoena information on goods entering or leaving the US.</p>
<p>But then, on January 16, DHS abruptly reversed course, withdrawing its summonses from Meta.</p>
<p>A <a href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Doe-v-DHA-Notice-to-Withdraw-Summonses-1-21-26.pdf">court filing </a>confirmed that DHS dropped its requests for subscriber information last week, after initially demanding Doe’s “postal code, country, all email address(es) on file, date of account creation, registered telephone numbers, IP address at account signup, and logs showing IP address and date stamps for account accesses.”</p>
<p>The filing does not explain why DHS decided to withdraw its requests.</p>
<p>However, previously, DHS requested similar information from Meta about six Instagram community watch groups that shared information about ICE activity in Los Angeles and other locations. DHS withdrew those requests, too, after account holders defended their First Amendment rights and filed motions to quash their summonses, Doe’s court filing said.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is It Time for a Nordic Nuke? (111 pts)]]></title>
            <link>https://warontherocks.com/2026/01/is-it-time-for-a-nordic-nuke/</link>
            <guid>46767772</guid>
            <pubDate>Mon, 26 Jan 2026 16:35:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://warontherocks.com/2026/01/is-it-time-for-a-nordic-nuke/">https://warontherocks.com/2026/01/is-it-time-for-a-nordic-nuke/</a>, See on <a href="https://news.ycombinator.com/item?id=46767772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Moscow’s <a href="https://apnews.com/article/russia-ukraine-war-missile-hypersonic-oreshnik-40502d366170b9830f007913e0b8aa9e">“Oreshnik”</a> <a href="https://defencematters.eu/russia-oreshnik-strike-signalling/">strike</a> on January 9, 2026 is best understood as strategic signaling designed to shape what NATO will and will not do. Russia’s use of nuclear-capable delivery systems in the Russo-Ukrainian War underscores a returning logic: nuclear weapons as instruments of coercion and risk manipulation, not only city destruction. RAND Europe’s 2025 <a href="https://www.rand.org/content/dam/rand/pubs/research_reports/RRA3800/RRA3859-1/RAND_RRA3859-1.pdf#page=56">scenario analysis</a> similarly includes a coercive diplomacy pathway in which Russia might threaten or conduct a limited nuclear strike to compel political concessions or sanctions relief.</p><p>The strategic implication for the Nordic countries is uncomfortable. Given Russia’s nuclear posture and the hollow nature of extended deterrence, Nordic countries should consider a cooperative nuclear hedge, operationally integrated with NATO. The aim is a firmly democratically controlled arrangement that still carries a deterrent edge sufficient to discourage any Russian adventurism.</p><p><strong>Increased Utility of Nuclear Weapons</strong></p><p>In the Western imagination, even a limited nuclear exchange is often treated as synonymous with global ecological catastrophe. Peer-reviewed modeling warns that smoke-driven cooling and cascading <a href="https://www.nature.com/articles/s43016-022-00573-0">food-system shocks</a> could be severe, even for regional scenarios.</p><p>But the magnitude hinges on contested parameters such as soot generation, plume rise, and how long smoke persists in the stratosphere. There are major uncertainties and data gaps across the entire causal pathway, from weapon use to <a href="https://www.nationalacademies.org/publications/27515">environmental</a> and socioeconomic effects. That uncertainty matters for deterrence: It can terrify decision-makers into restraint, but it can also tempt risk-takers who discount <a href="https://agupubs.onlinelibrary.wiley.com/doi/10.1002/2017JD027331">worst-case outcomes</a> and look for coercive limited-use options.</p><p><a href="https://www.armscontrol.org/act/2024-06/features/beyond-oppenheimer-nuclear-weapons-us-popular-media">Popular culture</a> reinforces a second misconception: that nuclear weapons are only “city killers” and therefore lack operational utility. Many <a href="https://www.twz.com/just-how-radioactive-are-low-yield-nuclear-weapons#:~:text=lower%2Dyield%20nuclear%20weapons%20have%20military%20value%20tailored%20for%20use%20on%20the%20battlefield%20and%20for%20demonstration%20strikes%20that%20limit%20or%20eliminate%20long%2Dterm%20radiological%20effects">lower-yield</a> nuclear weapons in fact have great military utility on the battlefield, as well as utility for “responsible” demonstration strikes. Russia and China are <a href="https://www.dia.mil/Portals/110/Images/News/Military_Powers_Publications/Nuclear_Challenges_2024.pdf#page=8">acting</a> on this knowledge — even diluting the <a href="https://www.scmp.com/news/china/science/article/3307059/china-tests-non-nuclear-hydrogen-bomb-science-paper-shows">capability gap</a> between conventional and nuclear weapons altogether.</p><p><strong>Extended Deterrence Debunked</strong></p><p>Nordic citizens have spent the post-Cold War era thinking about nuclear danger mainly in terms of <a href="https://www.nrc.gov/reading-rm/doc-collections/fact-sheets/fs-dirty-bombs">terrorism</a>, not state coercion.</p><p>For the Nordic countries, the problem is no longer that the credibility of nuclear extended deterrence is merely weakening. <a href="https://www.independent.co.uk/news/world/europe-trump-nato-greenland-venezuela-denmark-nuclear-b2896562.html">It is arguably already functionally hollow</a> — a conclusion the French government acted on some <a href="https://history.state.gov/historicaldocuments/frus1961-63v14/d30#:~:text=The%20General%20himself%20had%20asked%20whether%20we%20would%20be%20ready%20to%20trade%20New%20York%20for%20Paris.%20If%20the%20General%20himself%2C%20who%20has%20worked%20together%20with%20the%20United%20States%20for%20so%20long%2C%20could%20question%20American%20firmness%2C%20Mr.%20Khrushchev%20can%20question%20it%20also.">60 years ago</a>. Treating it as a planning assumption is a high-risk bet.</p><p>It could perhaps be repaired at the margins, but any <a href="https://www.theatlantic.com/ideas/archive/2025/03/buzz-saw-pine-forest/681984/">illusions</a> about an eternal American willingness to sacrifice itself for Europe are gone forever. Political will can swing quickly, both across election cycles and faster still within them, but the forces, posture, and planning that make nuclear deterrence credible cannot.</p><p>The clearest indicator to look for is strategic prioritization. The 2025 U.S. <a href="https://www.whitehouse.gov/wp-content/uploads/2025/12/2025-National-Security-Strategy.pdf"><em>National Security Strategy</em></a> elevates homeland defense and the Western hemisphere, pairs that with an Indo-Pacific focus on deterring a Taiwan crisis, and explicitly calls for a readjusted global military presence with Europe assuming primary responsibility for its own defense.</p><p>Even if Congress has <a href="https://www.ft.com/content/9bbfd46c-8fb7-4f31-9014-f88b2a00831f#:~:text=The%20US%20Congress%20has%20passed%20a%20defence%20policy%20bill%20that%20mandates%20the%20Pentagon%20retain%20at%20least%2076%2C000%20troops%20in%20Europe%2C%20in%20a%20rebuke%20of%20President%20Donald%20Trump%E2%80%99s%20threats%20to%20scale%20back%20commitments%20to%20the%20continent.">constrained</a> near-term U.S. troop reductions, Europe should not treat today’s numbers as permanent. A sudden reduction to token-level presence should not come as a surprise to anyone, nor the consequences for Russia’s room for escalation games across the spectrum of coercion.</p><p><strong>European Gap</strong></p><p>Europe is <a href="https://www.statista.com/topics/11051/defense-and-security-in-the-eu/#topicOverview">rearming</a>. The gap it needs to fill is considerable, but it could be done. Willingness to play in the major league is perhaps also on the rise. Admiral G.C. Dragone, chairman of NATO’s military committee, is openly suggesting the alliance should consider <a href="https://www.foxnews.com/world/nato-considers-more-aggressive-response-russias-hybrid-threats?msockid=0229fe66fc516ec73184e864fd3b6fb2">preemptive actions</a>, including cyber attacks and sabotage.</p><p>It is even possible that European allies will become willing and able to project and &nbsp;— if pushed —execute a conventional <a href="https://warontherocks.com/2025/09/denial-wont-do-europe-needs-a-punishment-based-conventional-counterstrike-strategy/">counterstrike strategy</a> against Russia. That is, however, the foreseeable cap of European capability and nerve.</p><p>Once the conventional realm is <a href="https://www.youtube.com/watch?si=dCP9g6eVQ4UqBAbN&amp;t=1828&amp;v=9cLYKZDhEjg&amp;feature=youtu.be">transgressed</a>, Europe has a big problem. Capability gaps are more serious than capacity. Compared with Russia’s large non-strategic arsenal and diverse theatre delivery options, <a href="https://thebulletin.org/premium/2024-11/united-kingdom-nuclear-weapons-2024/#:~:text=United%20Kingdom%20nuclear%20forces%2C%202024">British</a> and <a href="https://thebulletin.org/premium/2025-07/french-nuclear-weapons-2025/#:~:text=Table%201.-,French%20nuclear%20weapons%2C%202025,-.%20(Click%20to%20display">French</a> nuclear weapons inventories are severely limited and much less suited for sustained limited-use signaling. This means that Europeans lack <a href="https://www.acq.osd.mil/ncbdp/nm/NMHB2020rev/chapters/chapter1.html#:~:text=For%20deterrence%20purposes,effective%20employment.2">the necessary chip denominations</a> for a proper poker game, forcing them to either <a href="https://warontherocks.com/2025/05/everything-changes-but-nothing-changes-can-france-overcome-its-own-nuclear-doctrine/#:~:text=Having%20a%20range,of%20uncontrolled%20escalation">fold or go all-in</a> early in the game.</p><p>Russia’s advantage is not only in numbers of <a href="https://thebulletin.org/premium/2025-05/russian-nuclear-weapons-2025/#:~:text=Russian%20nuclear%20forces%2C%202025">warheads</a>, but in non-strategic delivery options that enable limited nuclear signaling. France has some flexibility through <a href="https://www.tandfonline.com/doi/full/10.1080/00963402.2025.2524251#d1e597:~:text=The%20French%20force%20of%20submarine%2Dlaunched%20ballistic%20missiles%20(SLBMs)%20constitutes%20the%20backbone%20of%20the%20French%20nuclear%20deterrent">sea</a>– and <a href="https://www.tandfonline.com/doi/full/10.1080/00963402.2025.2524251#d1e654:~:text=The%20second%20leg%20of%20France%E2%80%99s%20nuclear%20arsenal%20consists%20of%20nuclear%20ASMPA%20(air%2Dsol%20moyenne%20port%C3%A9e%2Dam%C3%A9lior%C3%A9)%20air%2Dlaunched%20cruise%20missiles%20for%20delivery%20by%20fighter%2Dbombers%20operated%20by%20the%20Strategic%20Air%20Forces%20and%20the%20Naval%20Nuclear%20Aviation%20Force.">air-delivered systems</a>. The United Kingdom is more constrained: A sea-based deterrent can <a href="https://thebulletin.org/premium/2025-12/the-changing-nuclear-landscape-in-europe/#post-heading:~:text=After%20the%20Cold,et%20al.%202024).">retaliate</a>, but it offers little scope for calibrated escalation without exposing scarce second-strike assets.</p><p>More concerning are indicators on British nuclear determination offered by the documentary <a href="https://www.dailymotion.com/video/x3q8go9">“World War Three: Inside the War Room”</a> (2016) and the five-episode podcast <a href="https://observer.co.uk/news/politics/article/the-wargame-the-podcast-exploring-how-britain-can-respond-to-russian-attack">“The Wargame”</a> (2025). In both cases, top British political and military officials put in scenario-based simulations are extremely reluctant to escalate, even when facing severe Russian aggression.</p><p>France arguably projects a stronger determination to use nuclear weapons, fueled by the experience of <a href="https://www.frstrategie.org/sites/default/files/documents/publications/recherches-et-documents/2020/202001.pdf#page=10">catastrophic loss</a> of territorial control in 1940. Nonetheless, when probing the French government with questions like <a href="https://warontherocks.com/2025/05/everything-changes-but-nothing-changes-can-france-overcome-its-own-nuclear-doctrine/#:~:text=%E2%80%9CWould%20France%20trade%20Paris%20for%20Helsinki%3F%E2%80%9D">“Would France trade Paris for Helsinki?”</a>, they <a href="https://history.state.gov/historicaldocuments/frus1961-63v14/d30#:~:text=The%20General%20himself%20had%20asked%20whether%20we%20would%20be%20ready%20to%20trade%20New%20York%20for%20Paris.%20If%20the%20General%20himself%2C%20who%20has%20worked%20together%20with%20the%20United%20States%20for%20so%20long%2C%20could%20question%20American%20firmness%2C%20Mr.%20Khrushchev%20can%20question%20it%20also.">suffer the same problem as President John F. Kennedy when asked if he would trade New York for Paris</a>. British and French forces fought bravely alongside Norwegian troops in the Battle of Narvik in 1940. Yet, when vital interests at home were threatened, they both <a href="https://thecinemaholic.com/narvik-why-did-british-and-french-leave-norwegian-forces-explained/#:~:text=The%20surprise%20attack,of%20the%20Germans.">pulled out</a>, handing the struggling Germans the win.</p><p><strong>A Nordic Nuclear Deterrent</strong></p><p>Denmark, Finland, Iceland, Norway, and Sweden ought to consider how to provide for their own nuclear protection. A Nordic nuclear deterrent is an <a href="https://www.altinget.dk/artikel/tidligere-udenrigsminister-vi-har-brug-for-en-nordisk-forsvarsunion-med-atomvaaben"><em>imperative</em> necessity</a>, according to former Danish social democrat Foreign Minister <a href="https://www.thedanishparliament.dk/members/jeppe-kofod">Jeppe Kofod</a>.</p><p>A purely national program might appear most logical: <a href="https://www.swp-berlin.org/publications/products/research_papers/Microsoft_Word___S13_05_swz_engl_ks.pdf#page=10">What better guarantee than having your own finger on the button?</a> Yet, nuclear deterrence is not simply a question of building a bomb. <a href="https://www.acq.osd.mil/ncbdp/nm/NMHB2020rev/chapters/chapter1.html#:~:text=nuclear%20deterrent%20is%20comprised%20of%20nuclear%20weapons%20and%20delivery%20systems%2C%20nuclear%20command%2C%20control%2C%20and%20communications%20(NC3)%2C%20and%20the%20people%20and%20infrastructure%20that%20support%20it%20all">It demands an entire ecosystem: command and control, delivery platforms, early warning, secure basing</a>, and above all, economic endurance.</p><p>A national deterrent would stretch the fiscal and industrial capacity of any single Nordic state. Nuclear weapons are not a substitute for conventional forces. They are a complement to them. If deterrence succeeds, the conventional capability must still be credible. France has seen its conventional muscle <a href="https://meta-defense.fr/en/2024/11/12/French-armies-under-capacity-2030/">atrophy</a>.</p><p>Even <a href="https://www.nbim.no/en">petroleum-rich Norway</a> could struggle maintaining both credible nuclear and conventional forces over a century-scale horizon. However, the Nordic countries combined would rank as the world’s <a href="https://www.worldometers.info/gdp/gdp-by-country/?source=imf&amp;year=2024&amp;metric=nominal&amp;region=worldwide">12th largest economy</a> with a <a href="https://www.congress.gov/crs_external_products/IF/HTML/IF10740.web.html?utm_source=chatgpt.com#:~:text=With%20a%20collective%20population%20of%20nearly%2028%20million%20people%2C%20the%20Nordic%20countries%20have%20a%20combined%20gross%20domestic%20product%20(GDP)%20of%20roughly%20%241.9%20trillion%20(see%20Figure%201).">GDP of $1.9 trillion</a>. Moreover, the Nordic countries have the <a href="https://www.bbc.com/future/article/20240412-the-secret-scandinavian-a-bomb-project">technology</a>, <a href="https://warontherocks.com/2025/04/u-s-allies-and-adversaries-are-attempting-nuclear-deterrence-without-weapons-will-it-work/#:~:text=Other%20NATO%20members%20that%20operated%20these%20facilities%20in%20the%20past%20%E2%80%94%20Belgium%2C%20Italy%2C%20Norway%2C%20and%20Spain%20%E2%80%94%20could%20position%20themselves%20for%20success%20relatively%20quickly.">industrial base</a>, and fiscal discipline to create a fully independent nuclear value chain <a href="https://frstrategie.org/en/publications/notes/french-nuclear-deterrent-changing-strategic-environment-2025#:~:text=France%20has%20indeed%20sovereign%20control%20of%20the%20design%2C%20manufacturing%2C%20deployment%20and%20operation%20of%20its%20nuclear%20forces%2C%20including%20nuclear%20components%20of%20course%2C%20but%20also%20missiles%2C%20as%20well%20as%20aircraft%20and%20submarines%20carrying%20them.%20This%20is%20different%20from%20the%20United%20Kingdom">on par with France’s</a>.</p><p>The immediate reaction to a Nordic nuclear initiative would be turbulent. NATO allies would worry about alliance cohesion and the precedent set for other exposed democracies. E.U. institutions and countries would, just like the Nordic countries themselves, clash with long-held arms control and non-proliferation commitments. Nonetheless, this initiative does not have to undermine NATO. A Nordic deterrent could exist within its framework, much as the <a href="https://www.forsvaret.no/en/news/articles/nordic-division">integrated Nordic air forces</a> already do. It could thus reinforce European cohesion, even transatlantic cohesion, particularly if future political developments draw the European Union and NATO closer together.</p><p>Crucially, a Nordic framework could also bring external legitimacy and internal reassurance. The world already recognizes the Nordic countries as stable democracies with no expansionist ambitions. A Nordic deterrent emerging from this tradition would be quite contentious, yet it could be treated as exceptional rather than revisionist.</p><p>Internally, a shared venture could make it easier for citizens to accept the necessity of such a step. The moral gravity of nuclear weapons is immense. No democratic government should embark on this path without deep societal consent. Cooperation among neighbors all committed to peace, legality, and restraint and bound together by geography, history, and to some extent language could soften the psychological and ethical shock. The idea of a Nordic deterrence arrangement would be easier to accept than a unilateral national bomb.</p><p><a href="https://warontherocks.com/membership/"><img decoding="async" src="https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design.png?v=1696366719" alt="" width="1600" height="900" srcset="https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design.png?v=1696366719 1600w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-300x169.png?v=1696366719 300w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-1024x576.png?v=1696366719 1024w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-768x432.png?v=1696366720 768w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-1536x864.png?v=1696366720 1536w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-278x156.png?v=1696366720 278w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-356x200.png?v=1696366720 356w, https://warontherocks.com/wp-content/uploads/2023/10/Untitled-design-500x281.png?v=1696366720 500w" sizes="(max-width: 1600px) 100vw, 1600px"></a></p><p><strong>Barriers and Taboos</strong></p><p>Logically, the weakening of NATO’s nuclear umbrella warrants a corresponding change in policy. But societies are shaped less by logic than by <a href="https://esg.sustainability-directory.com/term/national-culture/#:~:text=simplest%20statement%2C-,national%20culture,Imagine%20National%20Culture%20as%20the%20unspoken%20rulebook%20of%20a%20nation.,-This%20rulebook%20dictates">culture</a>. The Nordic <a href="https://www.regjeringen.no/en/topics/foreign-affairs/security-policy/promote_disarmament/id2890032/">moral compass</a> has long pointed towards nuclear disarmament. <a href="https://www.tandfonline.com/doi/pdf/10.1080/01402390.2024.2334765#page=6">Norway’s early decision to prohibit forward nuclear posturing</a> from the very early days of NATO, <a href="https://scandasia.com/denmark-might-allow-deployment-of-nuclear-weapons/#:~:text=Denmark%20has%20historically%20maintained%20a%20policy%20prohibiting%20the%20stationing%20of%20nuclear%20weapons%20on%20its%20territory%20during%20peacetime%2C%20a%20stance%20dating%20back%20to%201957.">Denmark’s similar stance</a> since 1957, and <a href="https://scienceandglobalsecurity.org/archive/sgs18jonter.pdf">Sweden’s abandonment</a> of its own nuclear weapons program in the late 1960s reflected both ethical conviction and trust in the solidity of American guarantees.</p><p>The taboo against nuclear weapons was once an expression of moral strength. Today, it risks becoming a form of moral escapism. It is easier to condemn nuclear arms than to confront the consequences of living without their protection.</p><p>Across the democratic world, similar awakenings are taking place. Russian brutality has already forced responsible European states to reconsider past restraints, most conspicuously in the <a href="https://yle.fi/a/74-20203518">exodus from the Ottawa Treaty</a> banning anti-personnel mines and <a href="https://www.france24.com/en/live-news/20250306-lithuania-quits-cluster-bomb-ban-treaty-despite-outrage">Lithuania’s decision</a> to leave the Convention on Cluster Munitions. Regrettable, yes, but in several cases necessary.</p><p>The same legal logic applies to the Nuclear Non-Proliferation Treaty. <a href="https://www.frstrategie.org/en/publications/notes/withdrawing-npt-legal-and-strategic-considerations-2023#:~:text=However%2C%20in%20the,disintegration%20of%20NATO.">Its architects foresaw that the world might change in ways that threatened a signatory’s supreme interests</a>. Article X of the treaty <a href="https://www.iaea.org/sites/default/files/publications/documents/infcircs/1970/infcirc140.pdf#page=5">explicitly allows</a> withdrawal if extraordinary events jeopardize national security. Many Westerners will object to this logic and invoke the deep-seated <a href="https://digitalbible.ca/article-page/modern-topics-what-does-the-bible-say-about-turn-the-other-cheek">cultural doctrine</a> of turning the other cheek. The problem is that there is no promise of an <a href="https://www.columbia.edu/itc/journalism/stille/Politics%20Fall%202007/Readings%20--%20Weeks%201-5/Weber%20-%20Politics%20as%20a%20Vocation.htm#:~:text=He%20who%20seeks%20the%20salvation%20of%20the%20soul%2C%20of%20his%20own%20and%20of%20others%2C%20should%20not%20seek%20it%20along%20the%20avenue%20of%20politics%2C%20for%20the%20quite%20different%20tasks%20of%20politics%20can%20only%20be%20solved%20by%20violence">afterlife for states</a>.</p><p>In practice, a Nordic nuclear move would mobilize the Non-Proliferation Treaty <a href="https://meetings.unoda.org/npt-revcon/treaty-on-the-non-proliferation-of-nuclear-weapons-eleventh-review-conference-2026">review process</a> and U.N. diplomacy, including the U.N. Security Council notification channel in Article X, and invite intensified verification and supplier pressure through the International Atomic Energy Agency’s <a href="https://www.iaea.org/topics/basics-of-iaea-safeguards">safeguards system</a> and <a href="https://nuclearsuppliersgroup.org/images/Files%20and%20Documents/Brochures/NSG_FAQ__CLEAN.pdf">the nuclear export-control ecosystem</a>.</p><p><a href="https://www.bbc.com/news/world-asia-65333139">Discussions</a> about the need for nuclear weapons are taking place in South Korea. The question is even being aired in <a href="https://www.reuters.com/world/china/japan-reaffirms-no-nukes-pledge-after-senior-official-suggests-acquiring-weapons-2025-12-19/#:~:text=Putting%20these%20trial%20balloons%20out%20creates%20an%20opportunity%20to%20start%20to%20build%20consensus%20around%20the%20direction%20to%20move%20on%20changes%20in%20security%20policy">Japan</a>. The <a href="https://thediplomat.com/2025/05/nuclear-weapons-are-no-silver-bullet-for-australias-strategic-predicament/">debate</a> in Australia is more cautious, <a href="https://www.realcleardefense.com/articles/2025/06/13/australia_and_stable_nuclear_deterrence__catching_up_with_a_changed_world_1116341.html#:~:text=But%20the%20real,for%20coercive%20advantage.">but it is there</a>. In Poland, the president himself has opened the <a href="https://www.politico.eu/article/donald-tusk-plan-train-poland-men-military-service-russia/#:~:text=Tusk%20also%20stressed,he%20said.">nuclear door</a>. By the time the Nordic peoples come to terms with the need to develop their own nuclear deterrent, other democracies may already have taken the brunt of breaking with the treaty.</p><p><strong>A Nordic Path to Deterrence</strong></p><p>Nordic doctrine would explicitly exclude a first strike, because first use is anathema to Nordic values and would thus not be a credible prospect anyway. Nordic nuclear weapons would exist solely for deterrence and, if required, retaliation after a nuclear attack. That clear line would serve as reassurance to Nordic citizens and neighbors alike.</p><p>Technically, this means an emphasis on assured second-strike capability. Survivable at-sea forces are a feasible way to guarantee retaliation. A modest fleet of well-hidden nuclear-armed submarines would form the backbone of a Nordic deterrent, augmented by air and land dual-use systems that could offer a complete spectrum of response options.</p><p>The Nordic countries could also reserve a contingency for broader collective defense. If nuclear weapons were used against a Nordic ally, proportional strikes against a common adversary should be on the table. This preserves solidarity within the alliance while maintaining a fundamentally defense-minded doctrine.</p><p><strong>Command and Control</strong></p><p>The Nordic countries could offer something genuinely new in the field of nuclear command and control, tackling both <a href="https://www.bbc.com/future/article/20200804-can-nuclear-war-ever-be-morally-justified">moral and psychological aspects of deterrence</a>.</p><p>At the heart of the system could stand the Nordic Command Authority: a collective arrangement through which ultimate launch authority rotates among the heads of state of the Nordic countries. Each leader would carry a secure “<a href="https://www.britannica.com/topic/nuclear-football">nuclear football</a>,” but only one of them would at any given moment possess the <em>active</em> authority to order use. The rotation would be set years in advance by a small and permanent Nordic Security Council according to an uneven and unpredictable schedule.</p><p>Sometimes the authority might rest with the Finnish president for two months, at other times with the Norwegian prime minister for five. The irregular rhythm and strict secrecy would deny adversaries any single point of failure or political pressure. Even the leaders themselves would operate under deliberate ambiguity, aware that at any given time one of them holds the live key but none can be sure who. This design is reminiscent of the executioner practice in which no one knows whose bullet or lever kills, thereby reducing the <a href="https://psycnet.apa.org/doiLanding?doi=10.1007%2Fs10979-005-4930-1">moral burden</a> to a tolerable and actionable level.</p><p>This structure would also offset a characteristic Nordic challenge: the predominance of leaders whose instincts run against the exercise of coercive power. The rotation ensures that there will almost always be at least one leader of a sterner cast — a <a href="https://medium.com/@muradalmemmedov/the-falklands-crisis-the-iron-ladys-iron-will-2bec396254f3">Nordic Iron Lady</a>, if you will — somewhere in the cycle. The system thereby fuses Nordic restraint with unpredictability, denying adversaries the comfort of assuming permanent pacifist dispositions at the top.</p><p>Technically, such an arrangement would require tamper-proof authentication, hardened and redundant communications, and a small but permanent staff maintaining continuity, secrecy, and oversight.</p><p>Legally, it would have to be treaty-based and implemented in domestic law. Each state would specify who may exercise release authority, under what conditions, and through what authentication steps, thus preserving constitutional civilian supremacy while enabling a pre-defined crisis procedure.</p><p>Civilian control could be further preserved by <a href="https://warontherocks.com/2020/11/right-of-launch-command-and-control-vulnerabilities-after-a-limited-nuclear-strike/#:~:text=Safeguards%20Against%20Unauthorized%20Nuclear%20Use%C2%A0">strict authentication</a> (including two-person controls at the operational level) and a standing requirement for immediate consultation with the Nordic Security Council where time permits.</p><p>Operationally, it should sit inside NATO’s nuclear consultation and planning architecture (via the <a href="https://www.nato.int/en/about-us/organization/nato-structure/nuclear-planning-group-npg">Nuclear Planning Group</a>) and connect to the alliance’s existing nuclear-support mission set and exercises, ensuring that the Nordic countries do not build a parallel system, but rather a Nordic-controlled mechanism that can operate within alliance procedures.</p><p><strong>Western Fortitude</strong></p><p>Peace is a question of power, and power is ultimately physical. And the ultimate physical power is nuclear. Must the Nordic countries wield the ultimate weapon themselves to safeguard their freedom in the future? Can they do so through a truly innovative command and control set-up?</p><p>A Nordic nuclear deterrent, if ever realized, will not be a quick fix. In the near term, the Nordic countries should hedge wisely by helping to heal transatlantic animosity, strengthening NATO’s cohesion, investing in augmentation of French and British nuclear capabilities, and welcoming the <a href="https://hegemoniq.com/european-nuclear-backstop/">extended deterrence</a> that Paris now offers.</p><p>They should also lead by example in the conventional domain. No amount of nuclear preparation can compensate for hollow armies. A credible European pillar of NATO demands that the rest of the Nordic countries realign with Finland when it comes to the fundamentals of defense. The credibility of any future deterrent will rest on this foundation of conventional strength.</p><p>If one day a Nordic deterrent emerges, it should not replace the transatlantic bond but reinforce it. It should be an additional pillar rather than an alternative temple. For the true strategic task of our age is not to consolidate the West into separate fox holes, but to rebuild a proper trench system that can defend our freedom through mutual support.</p><p><em><a href="https://www.forsvaret.no/en/research/staff/kibsgaard-johannes"><em>Johannes Kibsgaard</em></a> is a Norwegian lieutenant colonel currently serving as a senior strategy instructor at the Norwegian Defense Command and Staff College in Oslo. He is also <a href="https://www.forsvaret.no/en/research/projects/cultures-in-combat-mission-command-in-the-arctic"><em>a Ph.D. student at the University of Bergen</em></a>. He has operational experience across armor, artillery, and infantry assignments, including service with the International Security Assistance Force in Afghanistan. </em></p><p><em>The views in this article are those of the author and not those of the Norwegian military, the Norwegian Ministry of Defense, or the Norwegian government.</em></p><p>Image: Nano Banana</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France Aiming to Replace Zoom, Google Meet, Microsoft Teams, etc. (734 pts)]]></title>
            <link>https://twitter.com/lellouchenico/status/2015775970330882319</link>
            <guid>46767668</guid>
            <pubDate>Mon, 26 Jan 2026 16:27:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lellouchenico/status/2015775970330882319">https://twitter.com/lellouchenico/status/2015775970330882319</a>, See on <a href="https://news.ycombinator.com/item?id=46767668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RIP Low-Code 2014-2025 (217 pts)]]></title>
            <link>https://www.zackliscio.com/posts/rip-low-code-2014-2025/</link>
            <guid>46767440</guid>
            <pubDate>Mon, 26 Jan 2026 16:11:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zackliscio.com/posts/rip-low-code-2014-2025/">https://www.zackliscio.com/posts/rip-low-code-2014-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46767440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-gysqo7gh=""> <p>The rise of AI and particularly agentic development presents an existential threat to an entire category of low-code platforms. While the adoption of new techniques and tooling will take years to propagate through the Byzantine ranks of larger, slower-moving enterprises, the fundamental ROI case for these tools looks different in a world where the cost of shipping code now approaches zero.</p>
<p>This may seem like a preposterous conclusion given the substantial size and growth of the sector. Forrester, who actually gave low-code its name back in 2014, <a href="https://www.forrester.com/blogs/the-low-code-market-could-approach-50-billion-by-2028/">projects the category will reach $50b by 2028</a> and sees no current indication that things will slow down, let alone contract. However, it’s worth digging in to why these tools arose in the first place and the problems they solve to explore how much the landscape has shifted in just the past year.</p>
<p><img alt="Forrester Low-Code Market Projection" loading="lazy" decoding="async" fetchpriority="auto" width="684" height="786" src="https://www.zackliscio.com/_astro/forrester.opE9g3oO_6ECtA.webp"></p>
<p>Put simply, these software platforms exist to allow users to create software with fewer developer resources. By purchasing one of these platforms, a company can enable non-technical stakeholders to ship production-ready experiences, often with little to zero actual code being written. This frees up developer bandwidth, accelerates the company, and until recently was a no-brainer investment for building internal and even customer-facing software.</p>
<p><img alt="The Low Code Value Prop" loading="lazy" decoding="async" fetchpriority="auto" width="1024" height="559" src="https://www.zackliscio.com/_astro/value-prop.Bs7qCFDc_iEAxj.webp"></p>
<p>To enable these platforms in the real world, developers spend considerable time on prerequisite and ongoing work: piping and transforming data, writing and maintaining custom components that go beyond out-of-the-box functionality, and meshing authentication systems, to name a few. This investment is in turn justified by the reduction in development scope and complexity downstream of the low-code platform—non-technical users can be left to their own devices to ship to their hearts’ content.</p>
<p>With the emergence of AI coding, this ROI case gets inverted. It is now often faster, cheaper, and easier to ship the kind of tools you might have built with low-code tools outside these platforms. Yes, this still requires developer time, but so did enabling these low-code-platforms in the first place.  Even disregarding the financial and organizational costs of low-code tools, AI affords developers the conveniences of their regular workflows without the bolt-on complexity introduced by external platforms. When you add in the total cost of ownership of these low-code tools, a return to in-house tooling becomes even more attractive.</p>
<p>As an illustration of what’s possible, we’ve seen this play out in real-time at <a href="https://www.cloudcapital.co/">Cloud Capital</a>. In the not-too-distant past, we relied heavily on a low-code platform called <a href="https://retool.com/">Retool</a> for almost all of our internal Admin tooling. We built management dashboards, reporting, and orchestrated complex workflows that were critical to the business. The acceleration was real—our developers spent significantly less time rolling boilerplate tables, transforming data, and wiring up workflows. We even celebrated at our All Hands how much <em>better</em> our dashboards felt than if we’d hand-rolled them or used a pre-canned admin interface.</p>
<p>Then came the agentic tools that completely transformed the way we develop software. For our low-code tooling, the shift began with a single choice to prototype some new, self-contained functionality as a standalone internal tool instead of via our low-code platform. It was faster, easier, and leveraged our actual codebase in ways an external solution could not. That meant we shipped something safer, more robust, and more maintainable. The cherry on top is that the end product was also better—the UI looked and felt more like our in-house products, without the clunkiness required to stay on the WYSIWYG rails.</p>
<p>It felt immediately clear that we had identified an unlock for our internal tooling velocity. All of a sudden, we found ourselves feeling constrained by the same low-code tools that until so recently were unblocking us. Changes that would have been one-liners in Cursor or automated triage tickets handled by an agent meant logging in to another platform, moving around clunky UX blocks, bashing against version management systems that weren’t quite as polished or integrated as our core development flows. All with the additional cost of maintaining this additional system.</p>
<p>What started as a single tool quickly became a wholesale migration of all of our Admin tooling, and the inevitable sunsetting of our Retool instance. They hadn’t changed, but our culture and way of working had, and low-code couldn’t keep up. What was most shocking was the timeline of this change—for us as a small, fast-moving startup, the transition including migration played out fully in just a couple of sprints.</p>
<p>It’s inevitable that incumbent low-code tools will adapt—they will need to in order to survive. In many cases, this shift is already visible in their marketing, such as Retool’s new AI-heavy positioning:</p>
<p><img alt="Retool&amp;#x27;s new AI-heavy positioning" loading="lazy" decoding="async" fetchpriority="auto" width="3404" height="1808" src="https://www.zackliscio.com/_astro/retool-positioning.DetKXgRI_Z1PcLTl.webp"></p>
<p>At this point, it’s hard to say whether it’ll be enough. While it’s possible low-code platforms will survive by providing non-technical users with the kind of magical experience that’s already possible for developers with AI coding tools today, it also seems likely they will continue to cede market share to the core AI players themselves. We’re beginning to see this take shape as non-technical AI artifacts become more complex, powerful, and collaborative.</p>
<p>For us, abandoning low-code to reclaim ownership of our internal tooling was a simple build vs buy decision with meaningful cost savings and velocity gains. It also feels like a massive upgrade in developer experience and end-user quality of life. It’s been about 6 months since we made this switch, and so far we haven’t looked back.</p>
<p>Every build vs buy decision is unique, but many ultimately boil down to ROI in terms of speed, financial cost, maintenance cost, and organizational complexity. There are of course additional considerations like vendor lock-in, ownership of core competencies, ecosystem compatibility, etc., but in this case we can reduce the decision to this: will buying this platform let my team go faster, ship more, and create more value for our customers. At least for now, that answer feels clearer every day.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There is an AI code review bubble (254 pts)]]></title>
            <link>https://www.greptile.com/blog/ai-code-review-bubble</link>
            <guid>46766961</guid>
            <pubDate>Mon, 26 Jan 2026 15:38:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.greptile.com/blog/ai-code-review-bubble">https://www.greptile.com/blog/ai-code-review-bubble</a>, See on <a href="https://news.ycombinator.com/item?id=46766961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Today, we're in the <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=iBpgqRbEFVg">hard seltzer</a> era of AI code review: everybody's doing them. OpenAI, Anthropic, Cursor, Augment, now Cognition, and even Linear. Of course, there's also the "White Claws" of code review: pure-play code review agents like Greptile (that's us!), CodeRabbit, Macroscope, and a litter of fledgling YC startups. Then there are the adjacent Budweisers of this world:</p>
<p><img src="https://www.greptile.com/blog/ai-code-review-bubble/image1.png" alt="AI code review announcement 1"><img src="https://www.greptile.com/blog/ai-code-review-bubble/image2.png" alt="AI code review announcement 2"></p>
<p>Amazingly, these two were announced practically within 24 hours of each other.</p>
<p><img src="https://www.greptile.com/blog/ai-code-review-bubble/image3.png" alt="AI code review timeline"></p>
<p>As the proprietors of an, er, AI code review tool suddenly beset by an avalanche of competition, we're asking ourselves: what makes us different?</p>
<p><strong>How does one differentiate?</strong></p>
<p>Based on our benchmarks, we are uniquely good at catching bugs. However, if all company blogs are to be trusted, this is something we have in common with every other AI code review product. One just has to try a few, and pick the one that feels the best.</p>
<p>Unfortunately, code review performance is ephemeral and subjective, and is ultimately not an interesting way to discern the agents before trying them. It's useless for me to try to convince you that we're the best. You should just try us and make up your own mind.</p>
<p>Instead of telling you how our <em>product</em> is differentiated, I am going to tell you how our <em>viewpoint</em> is differentiated - how we think code review will look in the long-term, and what we're doing today to prepare our customers for that future.</p>
<p>Our thesis can be distilled into three pillars: independence, autonomy, and feedback loops.</p>

<p>We <em>strongly</em> believe that the review agent should be different from the coding agent. We are opinionated on the importance of <em>independent</em> code validation agents. In spite of multiple requests, we have never shipped codegen features. We don't write code; an auditor doesn't prepare the books, a fox doesn't guard the henhouse, and a student doesn't grade their own essays.</p>
<p>Today's agents are better than the median human code reviewer at catching issues and enforcing standards, and they're only getting better. It's clear that in the future a large percentage of code at companies will be auto-approved by the code review agent. In other words, there will be some instances where a human writes a ticket, an agent writes the PR, and another agent validates, approves, and merges it.</p>
<p>This might seem far-fetched but the counterfactual is Kafkaesque. A human rubber-stamping code being validated by a super intelligent machine is the equivalent of a human sitting silently in the driver's seat of a self-driving car, "supervising".</p>
<p>If agents are approving code, it would be quite absurd and perhaps non-compliant to have the agent that <em>wrote</em> the code also <em>approve</em> the code. Only once would you have X write a PR, then have X approve and merge it to realize the absurdity of what you just did.</p>

<p>Something that Greptiles generally agree on is that everything that <em>can</em> be automated, <em>will</em> be automated.</p>
<p>Code validation - which to us is the combination of review, test, and QA, is an excellent candidate for full automation. It's work that humans don't want to do, and aren't particularly good at. It also requires little in the way of creative expression, unlike programming. In addition, success is generally pretty well-defined. Everyone wants correct, performant, bug-free, secure code.</p>
<p>While some other products have built out great UIs for humans to review code in an AI-assisted paradigm, we have chosen to build for what we consider to be an inevitable future - one where code validation requires vanishingly little human participation. We have no code review UI, and view ourselves as more of a background automation or "pipes" product. Human engineers should be focused only on two things - coming up with brilliant ideas for what should exist, and expressing their vision and taste to agents that do the cruft of turning it all into clean, performant code.</p>

<p>Not long ago, we released our Claude Code plugin. It can do many things - but most notably, you can ask Claude Code to pull down and address Greptile's comments from the PR. You can ask it to keep going until there are no new comments, waiting a few minutes for a review after each push.</p>
<p>This is a step towards the future we're excited about: Human expresses intent, coding agent executes, validation/review agent finds issues and hands them back - kicking off a loop until it approves and merges. If there is ambiguity at any point, the agents Slack the human to clarify.</p>
<p><img src="https://www.greptile.com/blog/ai-code-review-bubble/image4.png" alt="AI code review feedback loop diagram"></p>
<p>The question of how these things are different is important. Unlike picking IDEs and coding agents that ostensibly have low switching costs, code review products are harder to rip out, so your decision will very likely turn out to be a long-term one, especially if you're a large company.</p>
<p>We've been around for about as long as AI code review has been around. It has gone from a fringe interest of the world's most adventurous vibecoders to a mainstream product that our enterprise users (including two of the Mag7) often describe as a "no-brainer" purchase.</p>
<p>Yet, our guess on where this goes is about as good as anyone else's. Meanwhile, we'll keep doing what we've always done - trying to make things our users love.</p></article></div></div>]]></description>
        </item>
    </channel>
</rss>