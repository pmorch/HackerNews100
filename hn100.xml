<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 07 May 2024 03:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Vets fret as private equity snaps up clinics, pet care companies (108 pts)]]></title>
            <link>https://stateline.org/2024/03/29/vets-fret-as-private-equity-snaps-up-clinics-pet-care-companies/</link>
            <guid>40281274</guid>
            <pubDate>Tue, 07 May 2024 01:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stateline.org/2024/03/29/vets-fret-as-private-equity-snaps-up-clinics-pet-care-companies/">https://stateline.org/2024/03/29/vets-fret-as-private-equity-snaps-up-clinics-pet-care-companies/</a>, See on <a href="https://news.ycombinator.com/item?id=40281274">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="dataContent">
                                    <p>HUNTSVILLE, Ala. — About a year ago, veterinarian Melissa Ezell started noticing subtle changes at the midsized animal clinic in Huntsville, Alabama, where she works.</p>
	
	
<p>She said she and other vets were feeling pressure from management to make a certain amount of money from every appointment. If a pet owner wasn’t going to spend enough, the message from management was to offer more services. She was urged to pack in more patients outside of normal business hours.</p>
<p>“Before, I never felt any pressure to be making a certain amount of money in a day,” Ezell, who started working at the clinic in 2021, told Stateline. “It was just, ‘Fill your schedule, practice good medicine, everything else will come.’”</p>
<p>The clinic is owned by National Veterinary Associates, one of the largest veterinary chains in the nation. In 2020 the company was acquired by JAB Consumer Partners, a global private equity firm based in Luxembourg. By early 2023, Ezell said, she felt a shift in atmosphere at the clinic and a greater focus on increasing profits.</p>
<p>Private equity’s foray into the human health care industry in recent years has <a target="_blank" href="https://stateline.org/2024/01/18/shell-game-when-private-equity-comes-to-town-hospitals-can-see-cutbacks-closures/">drawn public outrage and legislative scrutiny</a> as firms have been blamed for increasing prices, slashing services and shuttering hospitals to maximize shareholder profits.</p>
<p>Now, some veterinarians and advocates are sounding the alarm that private equity’s entry into the pet health care industry could lead to similar results.</p>
<p>Some states already have laws that prohibit non-veterinarians from owning veterinary practices, and some consumer advocates want states to review large-scale acquisitions in the industry.</p>
<p>“A large number of these funds are seeing veterinary medicine as a good profit center,” said Dr. Grant Jacobson, an Iowa veterinarian who serves on the board of the Independent Veterinary Practitioners Association. He said he’s seen corporate-owned chains in his region drive up prices for consumers, suppress market competition and skirt state laws that ostensibly prohibit veterinary practices from being owned by non-veterinarians.</p>
<p>Private equity firms such as Shore Capital Partners, KKR, TSG Consumer and JAB Consumer Partners have spent billions over the past few years on veterinary practices, specialty animal hospitals, pet insurance services and pet food companies. Among the companies owned by private equity are PetSmart, PetVet Care Centers, FIGO, Thrive Pet Healthcare and ASPCA Pet Health Insurance.</p>
<p>Private equity firms say those investments are giving clinics and other providers the capital they need to buy better technology, and that they are improving efficiency. And in many cases, corporate chains can offer their employees better workplace benefits, such as health insurance.</p>
<p>In a statement to Stateline, National Veterinary Associates said its corporate philosophy is “grounded in vets making medical decisions and not a corporate office,” and that its program of shared ownership by veterinarians is “the industry’s largest such program and unique among our peers.”</p>
<p>“Our vision is to build a community of hospitals that pet owners trust, are easy to access, and provide the best possible care,” National Veterinary Associates said in the statement.</p>
<p>JAB Consumer Partners did not respond to Stateline’s request for comment.</p>
    <h4>More pets, more money</h4>

	
<p>Private equity uses pooled investment money from pension funds, endowments and wealthy individuals to buy controlling stakes in companies. The firms typically look for a quick return on their investment before selling it within a few years. They have been gobbling up small businesses in myriad industries in recent years — from <a target="_blank" href="https://www.politico.com/news/magazine/2023/12/24/nursing-homes-private-equity-fraud-00132001">nursing homes</a> to <a target="_blank" href="https://www.wsj.com/articles/private-equity-wants-to-wash-your-car-11660968031">car washes</a>.</p>
<blockquote data-secret="lzVYrrJo9E"><p><a target="_blank" href="https://stateline.org/2024/01/18/shell-game-when-private-equity-comes-to-town-hospitals-can-see-cutbacks-closures/">‘Shell game’: When private equity comes to town, hospitals can see cutbacks, closures</a></p></blockquote>

<p>As <a target="_blank" href="https://www.avma.org/resources-tools/reports-statistics/us-pet-ownership-statistics">pet ownership soared</a> during the COVID-19 pandemic, private equity followed close behind. The pandemic years of 2020-2022 were “the peak years for private equity acquisitions of veterinary services and practices,” said Michael Fenne, senior coordinator for health care at the Private Equity Stakeholder Project, a nonprofit watchdog group that advocates for communities affected by private equity ownership.</p>
<p>Americans spent a record $147 billion on pet products and services last year. From 2017 to 2022, <a target="_blank" href="https://pitchbook.com/news/articles/pe-deals-veterinary-clinics-pet-care">private equity spent $45 billion</a> on deals in the veterinary sector, according to PitchBook, which tracks investment data.</p>
<p>The vet industry is attractive because it’s mostly made up of small, privately owned businesses that corporations can buy and consolidate into larger chains. And it’s mainly a cash-based business: Unlike in human health care, veterinary customers typically pay out of pocket, rather than rely on third-party payers such as insurance companies.</p>
<p>In some cases, private equity firms and other corporations buy community clinics from the veterinarians who own them for two, five or even 10 times their value. Then the firms roll them up into a larger chain of clinics that can corner a regional market.</p>
<p>It’s a strategy that can push other private owners out of the business, said Jacobson, the Iowa veterinarian. He spent nearly 20 years working at a privately owned practice in Iowa and had hoped to buy it when the original founder retired.</p>
<p>But the founder sold the practice to a large veterinary chain owned by Mars Inc. — the private company best known for owning candy brands that include M&amp;Ms — for more than $1 million above his offer, Jacobson said. Mars, while not a private equity firm, is the biggest consolidator of pet care companies in the United States, owning pet food companies, pet pharmacies and veterinary care clinic chains such as Banfield Pet Hospitals and BluePearl.</p>

<div>
	
	<p>You feel like you don’t have the time with the doctor, and you leave not fully understanding what was done to your pet or what is wrong with your pet if they’re sick.</p>
		<p><b>– Melissa Ezell, veterinarian</b></p>
	</div>

	
<p>About a quarter of general veterinary practices and about three-quarters of specialty practices, such as emergency and surgery care, are now owned by large corporations, according to John Volk of Brakke Consulting, a veterinary management consulting firm.</p>
<p>Some private equity-backed chains, such as National Veterinary Associates, buy community-based veterinary practices like Ezell’s without rebranding them under the chain’s name. As a result, clients might not be aware of the ownership change.</p>
<p>“It can appear you’re getting community-oriented care when there’s actually this set of big-box incentives underlying [the clinic] that comes from their private equity owners,” Fenne said.</p>
    <h4>Where vets want to work</h4>

	
<p>Lori Kogan, a clinical sciences professor at Colorado State University’s College of Veterinary Medicine and Biomedical Sciences, surveyed nearly 900 veterinarians in 2022 about their experiences and perceptions of <a target="_blank" href="https://avmajournals.avma.org/view/journals/javma/261/12/javma.23.06.0326.xml">corporate vs. privately owned veterinary clinics</a>.</p>
<blockquote data-secret="0DBBSnGFD1"><p><a target="_blank" href="https://stateline.org/2024/01/31/private-equitys-growing-footprint-in-home-health-care-draws-scrutiny/">Private equity’s growing footprint in home health care draws scrutiny</a></p></blockquote>

<p>Even though most of the veterinarians surveyed reported working for corporate-owned clinics, Kogan found more than half said they would prefer to work in privately owned clinics. The benefits offered by corporate chains, such as health insurance, didn’t seem strong enough to override other preferences, Kogan told Stateline.</p>
<p>“Feeling like they have a voice in decision-making, feeling like they’re recognized as an individual, those are things that are really important to people,” she said. “I think corporate ownership could accomplish those things, but it will take paying attention.”</p>
<p>Ezell, the veterinarian who left National Veterinary Associates, said the pressure has an impact on patients and their humans as well.</p>
<p>“Either you’re getting talked into additional services that may or may not actually be necessary, or your feel like you’re being rushed,” Ezell said. “You feel like you don’t have the time with the doctor, and you leave not fully understanding what was done to your pet or what is wrong with your pet if they’re sick.”</p>
<p>In its statement to Stateline, National Veterinary Associates noted that it has made “continued investment in technology and infrastructure, pioneering clinical research, industry-leading continuing education programs and wellbeing initiatives.”</p>
    <h4>Could states step in?</h4>

	
<p>Last August, Thrive Pet Healthcare announced it would be closing the only 24-hour emergency veterinary clinic in the Rochester, New York, metro area. Thrive is a chain of&nbsp;more than 380 veterinary hospitals&nbsp;based in Austin, Texas, that is owned by private equity firm TSG Consumer.</p>
<p>“The thought of having the only 24-hour emergency pet care center in our entire metro area close was really scary,” said Rachel Barnhart, a Democratic member of the Monroe County Legislature in New York who has taken her dogs to the clinic. “We are a community of more than a million people. The idea that we can’t support a 24-hour pet facility is outrageous.”</p>
<p>Barnhart wrote a letter to the Federal Trade Commission, asking it to look into Thrive, which operates more than a dozen clinics in Rochester. She said she’d seen the FTC act against anticompetitive practices in the veterinary industry elsewhere, and she felt Thrive deserved similar scrutiny.</p>
<p>Thrive leadership&nbsp;said in a letter to Barnhart and in media reports that a shortage of ER veterinarians made it impossible to hire enough workers to keep the 24-hour clinic open. But Barnhart suspected the company wanted to shutter the clinic because its staff&nbsp;<a target="_blank" href="https://www.whec.com/archive/vses-first-veterinary-practice-on-east-coast-to-unionize/">recently voted to unionize.</a> CEO Tad Stahel said in the letter to Barnhart that the closure was unrelated to the staff unionization.</p>
<blockquote data-secret="3HcbVh4fzw"><p><a target="_blank" href="https://stateline.org/2022/09/02/should-you-insure-your-pet-without-state-oversight-its-hard-to-say/">Should You Insure Your Pet? Without State Oversight, It’s Hard to Say.</a></p></blockquote>

<p>In 2022, the FTC took action against JAB Consumer Partners, which recently acquired an array of veterinary and pet service companies. The FTC required the firm to divest some of its vet clinics in California, Colorado, Texas, Virginia and Washington, D.C., as a condition of approving its multibillion-dollar purchases of two other multistate veterinary care chains.</p>
<p>If states were to authorize officials or agencies to review similar large-scale mergers and acquisitions in the veterinary industry, that “would be a good first step” toward protecting consumers, said Fenne, of the advocacy group.</p>
<p>Many states already have laws that prohibit non-veterinarians from owning veterinary practices, including Iowa, Minnesota, New Jersey, New York and North Carolina. The idea is to prevent corporate interests from guiding veterinarians’ medical judgment.</p>
<p>Experts and advocates expect to see further corporatization in veterinary care as more companies acquire not just vet clinics, but also other businesses across the pet care spectrum.</p>
<p>In February, asset management behemoth Blackstone Inc. <a target="_blank" href="https://www.blackstone.com/news/press/blackstone-completes-acquisition-of-rover/">acquired Rover</a>, the nation’s largest online platform for pet sitting, dog walking and other services. In the past two years, JAB has acquired several of the largest pet insurance companies in the United States and Europe.</p>
<p>Ezell, the Alabama veterinarian, eventually decided to take a job at another clinic in town that’s privately owned. She will start there in a few weeks.</p>
<p>“Not all corporate medicine is horrible, and you can find amazing veterinarians and caring support staff anywhere,” she told Stateline.</p>
<p>“But it’s easy to lose sight of your values. The whole reason we’re doing this is we want to make a difference in animals’ and people’s lives. If we’re unable to do that, shouldn’t we try to fix that?”</p>
<div dir="ltr">
<p><i>Editor’</i><i>s note: This story has been updated to correct the number of Thrive veterinary hospitals.</i></p>
</div>
    <a href="https://stateline.org/donate">
    
    </a>
	
                                </div><div>
                                            
                                            <p>Our stories may be republished online or in print under Creative Commons license CC BY-NC-ND 4.0. We ask that you edit only for style or to shorten, provide proper attribution and link to our website. AP and Getty images may not be republished. Please see our <a href="https://stateline.org/republishing-guidelines/" target="_blank">republishing guidelines</a> for use of any other photos and graphics.</p>
                                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Caniemail.com – like caniuse but for email content (178 pts)]]></title>
            <link>https://www.caniemail.com/</link>
            <guid>40280490</guid>
            <pubDate>Mon, 06 May 2024 23:03:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.caniemail.com/">https://www.caniemail.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40280490">Hacker News</a></p>
<div id="readability-page-1" class="page">
	<div>
		
		<main role="main">
			<div>
	<div>
		<h2><a href="https://www.caniemail.com/features/">Latest features</a></h2>
		<ol>
			
			
				
				
			<li>
<a href="https://www.caniemail.com/features/css-text-wrap/">CSS text-wrap</a>, April 03, 2024</li>
			
				
				
			<li>
<a href="https://www.caniemail.com/features/css-transition/">CSS transition</a>, March 29, 2024</li>
			
				
				
			<li>
<a href="https://www.caniemail.com/features/css-word-spacing/">CSS word-spacing</a>, March 13, 2024</li>
			
				
				
			<li>
<a href="https://www.caniemail.com/features/css-shape-margin/">CSS shape-margin</a>, March 13, 2024</li>
			
				
				
			<li>
<a href="https://www.caniemail.com/features/css-shape-outside/">CSS shape-outside</a>, February 28, 2024</li>
			
		</ol>
		<p><a href="https://www.caniemail.com/features/">View all features</a>
	</p></div>
	<div>
		<h2><a href="https://www.caniemail.com/news/">Latest news</a></h2>
		<ul>
			
			<li>
<a href="https://www.caniemail.com/news/2024-03-29-march-updates/">March 2024 updates</a>, March 29, 2024</li>
			
			<li>
<a href="https://www.caniemail.com/news/2024-02-29-february-updates/">February 2024 updates</a>, February 29, 2024</li>
			
			<li>
<a href="https://www.caniemail.com/news/2024-01-29-new-outlook-macos/">The new Outlook on macOS</a>, January 29, 2024</li>
			
			<li>
<a href="https://www.caniemail.com/news/2023-12-16-december-updates/">December 2023 updates</a>, December 16, 2023</li>
			
			<li>
<a href="https://www.caniemail.com/news/2023-04-30-april-updates/">April 2023 updates</a>, April 30, 2023</li>
			
		</ul>
		<p><a href="https://www.caniemail.com/news/">View all news</a>
	</p></div>
	
</div>
		</main>
		

	</div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attackers Can Decloak Routing-Based VPNs (164 pts)]]></title>
            <link>https://www.leviathansecurity.com/blog/tunnelvision</link>
            <guid>40279632</guid>
            <pubDate>Mon, 06 May 2024 21:19:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.leviathansecurity.com/blog/tunnelvision">https://www.leviathansecurity.com/blog/tunnelvision</a>, See on <a href="https://news.ycombinator.com/item?id=40279632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-89b404859ec5dd2d13df">
  <p>Recently, we identified a novel network technique that bypasses VPN encapsulation. An attacker can use this technique to force a target user’s traffic off their VPN tunnel using built-in features of DHCP (Dynamic Host Configuration Protocol). The result of this is the user transmits packets that are never encrypted by a VPN, and an attacker can snoop their traffic. We are using the term <strong>decloaking</strong> to refer to this effect. Importantly, the VPN control channel is maintained so features such as kill switches are never tripped, and users continue to show as connected to a VPN in all the cases we’ve observed. </p><p>We’ve spent extensive time exploring this capability and attempting to notify as many affected parties as possible. We also know it is our responsibility as security researchers to inform the security and privacy community, as well as the general public, about this threat. We also believe this technique may have been possible as far back as 2002 and could have already been discovered<strong>*</strong> and potentially used in the wild. For that reason, we believe it is critical for us to disclose publicly because notifying every VPN provider, operating system maintainer, self-hosted VPN admin, and VPN user is far beyond the capacity of our small research team.</p><p>We've seen one mitigation for this technique, as well as identified a fix that exists on Linux-based operating systems. However, the mitigation offers a side channel that could be used for targeted denial-of-service censorship, as well as to de-anonymize the destination of traffic via traffic analysis. In some places in the world, the side-channel alone could lead to imprisonment or death for those who rely on VPNs for safety such as journalists or whistleblowers <a href="https://www.npr.org/2021/07/19/1017774097/private-spyware-was-used-to-hack-cellphones-of-journalists-activists-worldwide" target="_blank">who are common targets of surveillance or spyware.</a> </p><p>It is not feasible to fix the issue by simply removing support for the DHCP feature because this could break Internet connectivity in some legitimate cases. The strongest recommendation we have is for VPN providers to implement network namespaces on operating systems that support them, similar to the method described in <a href="https://www.wireguard.com/netns/#the-new-namespace-solution" target="_blank">WireGuard’s documentation</a>. Network namespaces are a Linux feature that can segment interfaces and routing tables away from the local network’s control, and other operating system maintainers should consider whether namespaces are feasible to implement.</p><p>To help make this work accessible to as many people as possible, we are structuring this blog post to walk through the fundamentals of networking, VPN technology, and DHCP to fully explain the decloaking behavior. <strong>Advanced readers are welcome to jump straight to the proof-of-concept section.</strong></p><p> <strong>*</strong> After publication we’ve received notice that there are references to this decloaking behavior on <a href="https://mstdn.io/@jomo/98981403329690455" target="_blank">social media</a>. This further showcases the important of informing audiences outside of the technology sector of the existence of our technique.</p><h2>Decloaking Primer: Low-level Networking</h2><h3>What is a network?</h3><p>A computer network is a group of computer devices that are connected to each other and can send and receive data to and from one another. </p><p>A basic example of this is to connect two laptops with an Ethernet cable to network them together. However, there’s more than meets the eye when it comes to low-level networking that’s hidden from the average user. The laptops are using a system of rules to talk to each other, which we call <strong>protocols</strong>. Each protocol has its own purpose and operates at what we call a <strong>layer</strong>.</p><p>These layers are intended to solve different types of problems and are built such that they do not need to know what’s happening at a higher or lower layer. This is called <strong>encapsulation</strong>. For example, a user can trust that the layers lower than their browser (HTTP) are determining how to send electricity over a cable (Coax), knows who to talk to (Ethernet, IP), and ensure correct data delivery to the recipient server (TCP). This is like how someone writing a letter needs only to think about what they want to write or what the other person wrote. They do not need to care about how it got there.</p><p>When we’re referring to layers in this blogpost, we are talking about the practical <strong>TCP/IP model</strong>, which is implemented on almost every device and network. We also decided to use the 5-layer variant of the model because it doesn’t combine the lower layers together; this is why there might be a discrepancy when viewing other TCP/IP model diagrams. When we’re referring to data that’s been packaged by all these layers, we generally refer to it as a <strong>packet</strong>.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_31260">
  <h3>What is a network interface?</h3><p>The most basic example of a network interface is a physical device such as a wireless or network card attached to a computer's motherboard. These devices allow the computer to transmit bits of data over a physical medium (e.g., a copper wire, fiber optic cable, or radio frequency). They are a fundamental part of networking as they are what allows computers to talk to each other over a distance.</p><p>There are two types of network interfaces:</p><ul data-rte-list="default"><li><p>Physical Network Interfaces</p></li><li><p>Virtual Network Interfaces</p></li></ul><p>Importantly, both types of interfaces are designed for encapsulation so they can be interacted with by higher layers in the same way. </p><p>This is where Virtual Network Interfaces, a critical component of VPN clients and server, come in. Instead of using physical hardware, Virtual Network Interfaces create a <strong>file</strong> <strong>descriptor</strong> that can be read from or written to via software applications. Because file descriptors exist only in the memory of a host, Virtual Network Interfaces are especially useful for virtualized environments where traffic might never need to be transmitted over a physical medium.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_4403">

<p>However, there are use cases in which a user might want a virtual interface to be able to send traffic over a physical medium. For those cases, the virtual interface can also be backed by a physical network interface. Behind the scenes, the virtual interface forwards outbound traffic to a physical network interface.</p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_15603">
  <h3>What is a VPN?</h3><p>A Virtual Private Network (VPN) allows users to create a <strong>tunnel</strong> for network traffic between their host device and a server on a different network. The resulting <strong>virtual network</strong> is not confined by geographic location while behaving identically to a physical network. </p><p>To achieve this, VPN clients create a virtual network interface and use the underlying file descriptor to encrypt/decrypt traffic at a higher layer before sending it to a physical network interface.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_18104">
  <p>VPN use is designed to be as simple as possible for a user. Often, they do not need to do much besides log in and click a button to connect to their server.</p><p>What a user does:</p><ol data-rte-list="default"><li><p>Select the settings they want on the VPN Client</p></li><li><p>Click a button to connect</p></li><li><p>Log in (optional in some cases, depending on the client)</p></li><li><p>Read the confirmation from the VPN they are connected</p></li><li><p>Use remote resources from the VPN</p></li></ol><p>Importantly, VPNs actually <em>increase </em>the host’s attack surface because traffic from lower networking layers is send over the Internet. VPNs work by encapsulating lower layers inside of higher layers to create local area networks (LAN) over the Internet. LAN traffic is considered to be more privileged than traffic that is intended to be sent over the Internet. Attackers with LAN access have many more passive and active attack options than an attacker outside of the LAN. By creating a LAN over the Internet, VPNs extend the LAN attack surface to external attackers. Commonly, VPNs mitigate this attack surface by using compensating controls such as packet encryption.</p><p>This is an often-misunderstood fact about VPNs. The reason for encryption is not to increase the security of using the physical LAN, but rather to mitigate the added risk that VPNs introduce when they create a virtualized LAN over the Internet. <strong><em>VPNs do not secure you from local network attacks on the physical LAN</em> <em>despite common VPN marketing material and widely given advice.</em></strong></p><h3>How do VPNs use virtual network interfaces?</h3><p>The VPN client process creates an encrypted version of the packet it originally received from the file descriptor associated with its virtual network interface. It places this encrypted <strong>payload</strong> in the layer for its underlying VPN protocol, then uses that protocol to talk to the VPN server.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_32168">
  <p>There’s quite a long process for how a VPN sends that packet to the VPN Server. We are including a more exhaustive list of steps in the Appendix for security researchers or developers who might need even more granular details.</p><p>A simplified version of that process:</p><ol data-rte-list="default"><li><p>A VPN client establishes a “control channel” connection to a VPN server. If the VPN features a kill switch, then losing connection to this channel will result in a lockdown</p></li><li><p>The VPN client creates a virtual network interface</p></li><li><p>The VPN client optionally runs a startup script to configure the host. It may configure routing rules, the DNS server to use, host-based firewall rules, or other settings</p></li><li><p>A process on the host attempts to send network traffic to a destination (i.e., Internet browsing)</p></li><li><p>Routing rules select the VPN’s interface to send the traffic through</p></li><li><p>The VPN client receives and encrypts that traffic</p></li><li><p>The VPN client sends the encrypted traffic over a physically backed network interface to the VPN server</p></li><li><p>The VPN server receives and decrypts that traffic from the VPN client</p></li><li><p>The VPN server forwards that traffic to the destination. If the destination is outbound, the VPN will send your traffic as though it is its own. This behavior is what VPN providers describe as “IP cloaking” or “IP hiding”</p></li><li><p>The VPN server receives a reply from the destination, encrypts the response, and sends it to the VPN client</p></li><li><p>The VPN client decrypts the response, and the originating process finally receives the traffic</p></li></ol><p>It can be quite hard to understand fully since there are many steps involved. For that reason, we’ve made our own detailed diagram of a mental model we use for how a VPN client sends and receives information (Figure 4).</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_41563">
  <h3>How do routing based VPNs configure a host?</h3><p>Once a user connects to a VPN server, their VPN client process will configure the host’s settings to route traffic through the tunnel that it established. If all traffic* is routed through the VPN, we refer to it as a “full-tunnel VPN”. &nbsp;If there are user-defined exceptions for traffic, such as local network traffic, we refer to it as a “split-tunnel VPN”. The VPN client can also configure other settings on the host, such as the host’s firewall. Later, we’ll discuss a mitigation we observed using the host-based firewall.</p><p>Commonly, these configuration changes are made by “up scripts” and “down scripts” when a connection is established or disconnected. The runtime process for a VPN client may also perform configuration changes, but this varies from vendor to vendor.</p><p>*Note: When we say, “all traffic”, we really mean “all traffic except the traffic necessary to keep the VPN in a working state.” For example, VPNs create an exception to their own previously configured routing rules. All traffic sent to the VPN servers IP address must be sent over a hardware backed interface instead of its own tunnel. Otherwise, it would break the hosts connection to the VPN server and the VPN client would be unable to send encrypted packets. In addition, there are other configuration exceptions made for DHCP traffic since the VPN must maintain its hosts IP address lease. </p><h3>What are routes and routing tables?</h3><p><strong>Routes</strong> are how we describe where to send traffic based on the destination. <strong>Routing tables</strong> are a collection of routes that are used by the <strong>network stack</strong>. Consider a network stack to just be all the code on an operating system that deals with sending and receiving data from a network.</p><p>A common route is sending all traffic (<code>0.0.0.0/0</code> in <strong>Classless</strong> Inter-Domain Routing [CIDR] notation) to your router (<code>192.168.1.1</code>) over the physical network interface (<code>eth0</code>).</p><p>An example of that rule in the table would be:</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_74810">
  <p>Another behavior of routing tables is that by default (in most network stacks) the most specific <strong>prefix length</strong> for the CIDR range has the highest priority. The prefix length for the range <code>192.168.1.1/32</code> is <code>32</code> and the prefix length for the range <code>0.0.0.0/0</code> is <code>0</code>. The highest numerical value of a prefix length will take priority for routing selection (unless configured otherwise).</p><p>For example:</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_76210">
  <p>In this situation, if we sent traffic to <code>10.10.10.2</code>, the most specific rule is the <code>/32</code> rule and it would therefore be the rule the network stack uses despite matching the other two rules above it.</p><p>Most full-tunnel VPNs use the least specific rule possible to capture all traffic. Note that the following example includes an exception route for the hypothetical VPN server address (<code>12.34.56.78</code>) as well.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_77388">

<p>Alternatively, providers may use two <code>/1</code> rules to gain priority over the default route. It's common in even non-adversarial environments for DHCP to set a default route to the physical gateway.</p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_80151">
  <h3>What is DHCP?</h3><p>DHCP was originally developed as a robust way to dynamically issue IP addresses to devices on a local network as opposed to manually addressing each device. All modern operating systems have their own DHCP client that will automatically request an IP address. </p><p>The main concept to understand is that DHCP provides a time-based <strong>lease</strong> for IP addresses, and it contains many additional features called <strong>options</strong> that allow you to adjust the configuration of devices remotely and dynamically. Some notable options include setting the <strong>default</strong> <strong>gateway</strong> that acts as the primary route to the Internet or DNS (Domain Name System) servers, which resolve domain names like “google.com” to an IP address.</p><p>A client who wants an IP address uses a <strong>broadcast</strong> to send a <strong>DHCPDISCOVER</strong> packet to the entire local subnet. Other hosts will ignore this, except for the server who will respond with a <strong>DHCPOFFER </strong>unicasted directly to the client to offer it a time-bound lease.</p><p>Alternatively, if a client knows who the DHCP server is, it has the option to unicast the DHCPDISCOVER to a DHCP server instead of broadcasting. Usually, this is used for renewing its lease.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_83258">
  <p>As seen in the above diagram, once a DHCP server makes an offer, the client can choose to accept or decline the offer. For example, if it receives multiple offers, it will choose the best one. The selection most often implemented by DHCP clients is “first come, first serve.” The servers that aren’t selected will be sent a <strong>DHCPDECLINE</strong> message from the client. Notably, the DHCPOFFER will include the options.</p><h3>What is DHCP option 121?</h3><p>In 1997, the DHCP <strong>RFC</strong> had option 33, which allowed network administrators to specify a static route to install into a client’s routing table. However, this used <em>classful</em> static routes, which fell out of favor over time as public IP space became limited. In 2002, RFC 3442 introduced option 121 classless static routes and obsoleted option 33 (which still should be supported, <a href="https://github.com/systemd/systemd/issues/7792#issuecomment-355068519" target="_blank">depending on who you ask</a>). Option 121 also allows administrators to add static routes to a client’s routing table, but with classless ranges instead. There is no limit besides packet size to how many different routes can be installed at once.</p><p>An interesting quirk of DHCP option 121 is that the network interface device for the route it installs cannot be specified by the DHCP server. Below you can see a DHCPOFFER packet that was captured in Wireshark. It specifies the <em>CIDR range </em>and the <em>router</em> to use but has no interface device.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_86829">
  <p>Instead, the DHCP client will implicitly choose the network interface that the client is talking to the DHCP server on when installing its routing rules for this option. </p><h2>Decloaking Attacks</h2>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714927966073_13397">
  <h3>Requirements for decloaking VPN traffic</h3><ul data-rte-list="default"><li><p>The targeted host must accept a DHCP lease from the attacker-controlled server</p></li><li><p>The targeted host’s DHCP client must implement DHCP option 121</p></li></ul><p>We want to stress that <strong>there are ways an attacker who is on the same network as a targeted user might be able to become their DHCP server</strong>:</p><ul data-rte-list="default"><li><p>A rogue DHCP server using a DHCP starvation attack against the true DHCP, then responding to new clients. We have achieved this in lab environments and are working on a follow-up blog post.</p></li><li><p>A rogue DHCP server racing to respond to DHCPDISCOVER broadcasts to abuse DHCP clients’ common behavior where they implement first-offer lease selection.&nbsp; </p></li><li><p>ARP spoofing to intercept traffic between the true DHCP server and client, then waiting for a client to renew their lease. </p></li></ul><h3>Performing the attack</h3><p>Our technique is to run a DHCP server on the same network as a targeted VPN user and to also set our DHCP configuration to use itself as a gateway. When the traffic hits our gateway, we use traffic forwarding rules on the DHCP server to pass traffic through to a legitimate gateway while we snoop on it.</p><p>We use DHCP option 121 to set a route on the VPN user’s routing table. The route we set is arbitrary and we can also set multiple routes if needed. By pushing routes that are more specific than a <code>/0</code> CIDR range that most VPNs use, we can make routing rules that have a higher priority than the routes for the virtual interface the VPN creates. We can set multiple <code>/1</code> routes to recreate the <code>0.0.0.0/0</code> all traffic rule set by most VPNs.</p><p>Pushing a route also means that the network traffic will be sent over the same interface as the DHCP server instead of the virtual network interface. This is intended functionality that isn’t clearly stated in the RFC. Therefore, for the routes we push, it is never encrypted by the VPN’s virtual interface but instead transmitted by the network interface that is talking to the DHCP server. As an attacker, we can select which IP addresses go over the tunnel and which addresses go over the network interface talking to our DHCP server.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_95776">
  <p>We now have traffic being transmitted outside the VPN’s encrypted tunnel. This technique can also be used against an already established VPN connection once the VPN user’s host needs to renew a lease from our DHCP server. We can artificially create that scenario by setting a short lease time in the DHCP lease, so the user updates their routing table more frequently. In addition, the VPN control channel is still intact because it already uses the physical interface for its communication. In our testing, the VPN always continued to report as connected, and the kill switch was never engaged to drop our VPN connection.</p><h3>Proof of Concept</h3><ul data-rte-list="default"><li><p>Video proof of concept:</p><ul data-rte-list="default"><li><p><a href="https://www.youtube.com/watch?v=ajsLmZia6UU" target="_blank">https://www.youtube.com/watch?v=ajsLmZia6UU</a></p></li></ul></li><li><p>Lab Setup Code:</p><ul data-rte-list="default"><li><p><a href="https://github.com/leviathansecurity/TunnelVision" target="_blank">https://github.com/leviathansecurity/TunnelVision</a></p></li></ul></li><li><p>DHCP Server image:</p><ul data-rte-list="default"><li><p><a href="https://drive.google.com/file/d/1WLJGs3ZUypf6hLh5WL4AJmsKdUOZo5yZ" target="_blank">https://drive.google.com/file/d/1WLJGs3ZUypf6hLh5WL4AJmsKdUOZo5yZ</a></p></li></ul></li></ul><p><br>The lab scenarios are built to represent:</p><ul data-rte-list="default"><li><p>An attacker compromises a DHCP server/access point</p></li><li><p>A rogue administrator owns the infrastructure themselves and maliciously configures it</p></li><li><p>An attacker sets up an evil twin wireless AP in a physical location such as a coffee shop or corporate office</p></li><li><p>One we release our tool, ArcaneTrickster, the lab can also be used to mimic an attacker who has an adjacent host on the network na dis otherwise not in a privileged network position</p></li></ul><h3>Fixes</h3><h4><strong>Network Namespaces</strong></h4><p>Using network namespaces on Linux can completely fix this behavior. However, in our experience, it is less commonly implemented.</p><p><a href="https://www.wireguard.com/netns/#the-new-namespace-solution" target="_blank">WireGuard’s documentation</a> shows how it’s possible to use a namespace for all applications with traffic that should be using a VPN before sending it to another namespace that contains a physical interface. However, this appears to be Linux-specific functionality and it’s not clear if there is a solution for Windows, MacOS, or other operating systems with the same amount of robustness.</p><h3>Mitigations</h3><h4><strong>Firewall Rules</strong></h4><p>We’ve observed VPN providers denying all inbound and outbound traffic to and from the physical interface via firewall rules. An exception was necessary for the DHCP and VPN server IPs because they are necessary to remain connected to the LAN and VPN server. Deep packet inspection could also allow only the DHCP and VPN protocols instead but would likely incur a performance penalty.</p><h4><strong>Problems with Firewall Rule Mitigations</strong></h4><p>Firewall mitigations create a selective denial of service for traffic using the DHCP route and introduce a side-channel. An attacker can use this side-channel to determine the destination of traffic. To determine the traffic’s destination, an attacker could perform traffic analysis on the volume of VPN encrypted traffic a user sends. The attacker would need a baseline volume of traffic where no malicious are installed. Then the attacker would need to modify the lease configuration to install routes that deny traffic and observe the difference in volume.</p><p>With enough samples, it would be possible to statistically prove whether the targeted user is sending traffic to a specific destination. For the average internet user, most internet traffic is already secured by TLS. Therefore, traffic intercepted by TunnelVision will mostly be unreadable except for the destination and protocols. This means that this side-channel has nearly the same impact and should be considered insufficient.</p><p>The side-channel is flexible in use:</p><ul data-rte-list="default"><li><p>The traffic can be checked against a predefined list.</p></li><li><p>The traffic can be selectively denied as a censorship mechanism.</p></li><li><p>The attacker can use IP space denial with binary search to determine all current connections in logarithmic time.</p></li></ul><h4><strong>Ignore Option 121</strong></h4><p>Another possible mitigation is ignoring option 121 while the VPN is on. We noted that because Android does not implement support for DHCP option 121, it was uniquely unaffected. The downside is that option 121 exists for a reason, and ignoring these routes can break network connectivity (<a href="https://news.ycombinator.com/item?id=34145080" target="_blank">something that is frequently brought up as a reason to implement i</a>t on Android). If this mitigation is implemented, it must be mandatory because attackers could simply deny network access until the VPN or user re-enables option 121.</p><h4><strong>Use a Hot Spot or VM</strong></h4><p>Hot spots are temporary Wi-Fi networks controlled by a cellular device. They create a password-locked LAN with automatic network address translation. Because this network is completely controlled by the cellular device and requires a password, an attacker should not have local network access. A virtual machine would also work similarly as long as the VM’s network adapter is not in bridged mode.</p><h4><strong>Do not use untrusted networks if you need absolute confidentiality of your traffic</strong></h4><h2>Industry Impact</h2><h3>Is TunnelVision a vulnerability?</h3><p>This is debatable. We’re calling it a technique because TunnelVision doesn’t rely on violating any security properties of the underlying technologies. From our perspective, TunnelVision is how DHCP, routing tables, and VPNs are intended to work.</p><p>However, it contradicts VPN providers’ assurances that are commonly referenced in marketing materials; in our opinion, TunnelVision becomes a vulnerability when a VPN provider makes assurances that their product secures a customer from an attacker on an untrusted network. There’s a big difference between protecting your data in transit and protecting against all LAN attacks. VPNs were not designed to mitigate LAN attacks on the physical network and to promise otherwise is dangerous.</p><p>In our technique, we have not broken the VPN’s cryptographically secured protocol, and the VPN is still fully functional. An attacker is instead forcing a target user to not use their VPN tunnel. Regardless of whether we classify this as a technique, VPN users are affected when they rely on assurances that a VPN can secure them from attackers on their local network.</p><h3>Affected Operating Systems</h3><p>In our testing, we observed that any operating system that implements a DHCP client according to its RFC specification and has support for DHCP option 121 routes is affected. This includes Windows, Linux, iOS, and MacOS. Notably, it does not affect Android as they do not have support for DHCP option 121.</p><h3>Affected VPN Providers and VPN Protocols</h3><p>We found that VPNs that solely rely on routing rules to secure the host’s traffic are vulnerable. Those who are hosting their own VPN servers (e.g., system administrators) and are not hardening their VPN client configurations will likely be vulnerable as well. We have observed a mitigation from some VPN providers that drops traffic to non-VPN interfaces via firewall rules. It’s possible there are other methods that we did not encounter during testing to mitigate or fix this.</p><p>As previously mentioned, we observed the same behavior on each operating system we tested, save one. Furthermore, the strength of the encryption algorithm a VPN uses makes no difference. TunnelVision’s effect is independent of the underlying VPN protocol (e.g., WireGuard, OpenVPN, or IPsec) because it reconfigures the operating system network stack the VPN relies on.</p><h2>Conclusion</h2><h3>Call to Action</h3><p>We have a limitation as a research team of two– there are simply too many VPNs on the market to test each one individually. The first approach we took was to notify companies via bug bounties or security disclosure email, but that quickly became unscalable. We’ve also engaged the EFF and CISA to help disclose as broadly as possible prior to publicly releasing this research. We thank them tremendously for their help. Our hope is that by publishing our work, we can reach more affected parties, especially because we believe the technique has been feasible since as early as 2002.</p><p>Although the public disclosure of this technique affects each party differently, ultimately there is a shared responsibility.</p><p>Users should be made aware of this technique and for sensitive traffic they should be warned against using untrusted networks. If they must use an untrusted network, they should use a VPN provider that has an effective mitigation against this technique. To determine if a provider has an effective mitigation or fix, our lab setup is available for testing and VPN providers themselves will be able to speak to the specifics of their existing mitigations in their documentation. If a VPN decloak does occur, most user data will not be visible to local network attackers assuming they are accessing websites with HTTPS, which has <a href="https://w3techs.com/technologies/details/ce-httpsdefault" target="_blank">become increasingly common</a>.</p><p>It is common for corporate VPNs to be used in areas such as coffee shops, hotels, or airports. Network administrators should inform employees that working from such places carries risks and should be avoided when possible. If such a policy is not practical, then administrators should advise using VPNs that enable the previously mentioned mitigations or fixes. Some alternatives would be to use a trusted hot spot and then connect to the VPN. Lastly, running the VPN inside of a VM that obtains a lease from a virtualized DHCP server would prevent the local networks DHCP server from installing routes altogether.</p><p>Companies that control their own networks or have site-to-site VPNs should review the switches they use and enable features such as DHCP snooping and ARP protections.&nbsp; These layer 2 protections help prevent rogue DHCP servers but do not eliminate a rogue administrator scenario. In addition, implementing HTTPS or other protocols with encryption for internal resources will prevent data leakage from VPN users connecting from untrusted networks.</p><p>VPN providers can add features to clients to configure firewall rules that drop outbound packets to network interfaces. However, such a setting will mean that a VPN user will be isolated from interacting with local network resources. If the VPN client is for Linux and is intended to be a full tunnel, using network namespaces for isolation. As such, VPN providers should publicly provide documentation about any mitigations or fixes they have for TunnelVision and warn their end users about TunnelVision’s existence. We also recommend reviewing their marketing material and cease marketing claims that VPNs protect customers on untrusted networks until it can be proven.</p><p>Operating system maintainers (outside of Linux) should determine whether adding or enhancing features related to network namespaces is feasible. </p><h3>Upcoming Research</h3><p>During the disclosure process, we encountered multiple cases in which the entities we disclosed to did not see this as a serious problem. They assumed that the prerequisite conditions included privileged positions or accounts, despite the only prerequisite being local network access. This assumption was partially fueled by our intentionally simplistic lab setup where we were the only DHCP server, and what we perceive as the entity’s lack of familiarity with low-level networking.</p><p>With this feedback, we decided to develop a robust adversarial infrastructure library to enable further LAN security research and demonstrate practical attacks. For example, we can demonstrate that it’s possible to consistently perform TunnelVision while simply being adjacent to the target host on the same LAN. We’re calling it “ArcaneTrickster” and plan on releasing it at a later date. However, we feature a demo in our videos, which are available in the proof of concept section.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1714393040309_196438">
  <h2>Credits</h2><p><strong>Authors:</strong></p><ul data-rte-list="default"><li><p>Lizzie Moratti</p></li><li><p>Dani Cronce</p></li></ul><p><strong>Acknowledgements:</strong></p><ul data-rte-list="default"><li><p>Sofia Aberegg</p></li><li><p>TC Johnson</p></li><li><p>Brian Campbell</p></li><li><p>Martin Bogomolni</p></li><li><p>Brad Haines</p></li><li><p>Frank Heidt</p></li></ul><p><strong>Special Thanks to:</strong></p><ul data-rte-list="default"><li><p>Electronic Frontier Foundation (EFF)</p></li><li><p>United States Cybersecurity Infrastructure and Security Agency (CISA)</p></li></ul><h2>Appendix</h2><h3>Prior research related to TunnelVision</h3><p>We found research related to <a href="https://petsymposium.org/popets/2015/popets-2015-0006.pdf" target="_blank">DHCP leaking default routes</a> over an incorrect interface as far back as 2015. However, it was implied that DHCP only pushed default routes and did not account for DHCP option 121.</p><p>In August 2023, <a href="https://tunnelcrack.mathyvanhoef.com/#summary" target="_blank">a paper</a> was published demonstrating that routing rules can be attacked in different ways to leak VPN traffic. The paper details two methods of leaking VPN traffic:</p><ul data-rte-list="default"><li><p>Abusing non-RFC1918 IP ranges to leak traffic. </p></li><li><p>DNS spoofing the VPN server’s domain name to trick the VPN client into adding a routing rule exception for an IP address.</p></li></ul><p>However, neither technique described in the August 2023 paper leveraged DHCP option 121 to push routes. Pushing routes through DHCP has a significantly higher impact from the same attacker vantage point (the ability to hand out IP leases for a non-RFC1918 range or spoofing DNS replies).</p><h3>In-Depth Diagram Explanation</h3><p>For posterity and because we haven’t encountered another diagram like ours (Figure 4), below are the steps from the diagram in as much detail as we could reasonably provide. We feel it could be useful to a future security researcher or a developer trying to understand the technology, so we are including it for their benefit.</p><ol data-rte-list="default"><li><p>An application process sends a payload to a socket it creates.</p></li><li><p>The socket formats the payload into a packet and sends it to the routing table to determine which interface it should be sent through.</p></li><li><p>The routing table determines that the packet should be sent through tun0.</p></li><li><p>The routing table sends the packet to the firewall.</p></li><li><p>The firewall rules allow the packet to continue to tun0.</p></li><li><p>The network interface serializes the packet and writes it into a file descriptor at /dev/net/tun in userland.</p></li><li><p>The VPN client process reads the unencrypted raw bytes of the packet in the file descriptor.</p></li><li><p>The VPN process creates an encrypted payload and sends it to a socket the VPN made.</p></li><li><p>The socket formats the payload into a packet that is bound for the VPN’s server and sends it to the routing table to determine which interface it should be sent through.</p></li><li><p>The routing table determines that the packet must be sent over the wlan0 interface.</p></li><li><p>The routing table sends the packet to the firewall.</p></li><li><p>The firewall rules determine that the outbound packet may continue using wlan0.</p></li><li><p>The network interface transfers the packet to its Wi-Fi driver.</p></li><li><p>The Wi-Fi driver sends the VPN-bound packet to the physical network interface card (NIC).</p></li><li><p>The packet is sent across the internet to the VPN server.</p></li><li><p>The VPN server sends a packet in response back to the physical NIC.</p></li><li><p>The NIC sends the response packet to the Wi-Fi driver.</p></li><li><p>The Wi-Fi driver delivers the response packet to wlan0.</p></li><li><p>The response packet is sent to the firewall.</p></li><li><p>The firewall rules allow the packet to continue.</p></li><li><p>The packet is returned to the VPN socket.</p></li><li><p>The socket receives the packet and sends the packet’s encrypted payload to the VPN client process.</p></li><li><p>The VPN client process decrypts the payload and writes the unencrypted raw bytes of the response packet to the file descriptor.</p></li><li><p>The tun0 interface deserializes the bytes from the file descriptor and formats it into a packet.</p></li><li><p>The tun0 interface sends the packet to the firewall.</p></li><li><p>The firewall rules allow the packet to continue.</p></li><li><p>The packet is returned to the socket opened by the user’s application process.</p></li><li><p>The payload from the packet is returned to the application process.</p></li></ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TOTP Authenticator for PalmOS (107 pts)]]></title>
            <link>https://www.nkorth.com/palm/apps/#totp-authenticator</link>
            <guid>40279305</guid>
            <pubDate>Mon, 06 May 2024 20:45:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nkorth.com/palm/apps/#totp-authenticator">https://www.nkorth.com/palm/apps/#totp-authenticator</a>, See on <a href="https://news.ycombinator.com/item?id=40279305">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
<p>These apps run on <a href="https://www.nkorth.com/palm/">Palm OS</a> devices, and emulators such as <a href="https://www.nkorth.com/palm/cloudpilot.html">Cloudpilot</a>.</p>
<ul>
<li>To install on a device, if you’re using Palm Desktop you can simply double-click each PRC/PDB file.<ul>
<li>If you’re on Linux, install <a href="https://www.nkorth.com/palm/pilot-link.html">pilot-link</a> and use <code>pilot-xfer</code>.</li>
</ul>
</li>
<li>To install on Cloudpilot, drag files one at a time onto the emulator screen, or use the install button on the top bar. If updating an existing app, make sure you open a different app before attempting to install. (Returning to the launcher isn’t always enough.)</li>
</ul>


<h2 id="totp-authenticator">TOTP Authenticator</h2>
<p><img src="https://www.nkorth.com/palm/apps/totp_screen.png"></p>
<p>Get your 2-factor codes on your Palm, just like Google Authenticator. Unlike <a href="https://palmdb.net/app/totp-authenticator-app">Hotpants</a> (an old port of a J2ME phone app), this version takes up much less space and supports all Palm OS versions.</p>
<p>Download:
<img src="https://www.nkorth.com/palm/apps/totp_icon.png">
<a href="https://www.nkorth.com/palm/apps/TOTPAuth-1.0.zip">TOTPAuth-1.0.zip</a></p>
<p>Source: <a href="git://shinonomelaboratory.com/palm-totp.git">palm-totp.git</a></p>
<h2 id="rosary">Rosary</h2>
<p><img src="https://www.nkorth.com/palm/apps/rosary_screen.png"></p>
<p>A guide to praying the Rosary. It automatically selects the mysteries based on the weekly schedule, with options for both new and old forms. You can even choose to see the prayers in Latin.</p>
<p>Download:
<img src="https://www.nkorth.com/palm/apps/rosary_icon.png">
<a href="https://www.nkorth.com/palm/apps/Rosary-1.1.zip">Rosary-1.1.zip</a>
<img src="https://www.nkorth.com/etc/flags/us.png" title="English (US)">
<img src="https://www.nkorth.com/etc/flags/fr.png" title="French"></p>
<h2 id="bible-in-a-year">Bible in a Year</h2>
<p><img src="https://www.nkorth.com/palm/apps/biy_screen.png"></p>
<blockquote>
<p>If you’ve struggled to read the Bible, this podcast is for you.</p>
<p>Ascension’s <a href="https://ascensionpress.com/biy">Bible in a Year Podcast</a>, hosted by Fr. Mike Schmitz and featuring Jeff Cavins, guides Catholics through the Bible in 365 daily episodes starting January 1st, 2021.</p>
</blockquote>
<p>This unofficial app shows each day’s readings, and remembers where you left off.</p>
<p>Download:
<img src="https://www.nkorth.com/palm/apps/biy_icon.png">
<a href="https://www.nkorth.com/palm/apps/BInAYear-1.0.zip">BInAYear-1.0.zip</a></p>
<h2 id="catechism-in-a-year">Catechism in a Year</h2>
<p><img src="https://www.nkorth.com/palm/apps/ciy_screen.png"></p>
<p>The <a href="https://ascensionpress.com/ciy">Catechism in a Year podcast</a>, hosted by Fr. Mike Schmitz and published in 2023, goes through the entire Catechism of the Catholic Church in one year of daily readings.</p>
<blockquote>
<p>If you have ever wanted to understand what it means to be Catholic and allow those truths to shape your life—this podcast is for you!</p>
</blockquote>
<p>This unofficial app shows each day’s readings, and remembers where you left off.</p>
<p>Download:
<img src="https://www.nkorth.com/palm/apps/ciy_icon.png">
<a href="https://www.nkorth.com/palm/apps/CInAYear-1.2.zip">CInAYear-1.2.zip</a></p>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[New way to have complex discussions (299 pts)]]></title>
            <link>https://cq2.co/blog/the-best-way-to-have-complex-discussions</link>
            <guid>40277547</guid>
            <pubDate>Mon, 06 May 2024 18:02:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cq2.co/blog/the-best-way-to-have-complex-discussions">https://cq2.co/blog/the-best-way-to-have-complex-discussions</a>, See on <a href="https://news.ycombinator.com/item?id=40277547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We love complex, deep discussions.</p><p>We've seen or been part of many discussions — strategic discussions at work, discussions on<!-- --> <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">AI alignment</a>,<!-- --> <a href="https://discuss.python.org/t/pep-736-shorthand-syntax-for-keyword-arguments-at-invocation/43432">technical design documents</a>, public policy, etc. For us, the most frustrating issues with discussions are: impulsive responses and lack of structure.</p><p>The default way of discussions — in-person ones — are highly susceptible to impulsive responses and are extremely hard to provide a good structure for, making them the worst for complex topics.</p><p>The first issue of impulsive responses is a hard nut to crack. Practising and advocating for active listening is the ideal solution but it's not guaranteed to work every time and in every team. That's why we prefer written, async discussions over in-person ones for complex topics — they help prevent impulsive responses to an extent (and even more with features like slow mode) and promote thoughtful responses. But the second issue still remains — written, async discussions lack structure too. If you've used chat/forum platforms like Slack and Discourse for complex discussions, you know how hard it is to follow comments there.</p><p><span>Discourse</span>In Discourse, discussions are a stream of unorganised comments. This way of discussion — where people talk over one another and topics get mixed up — doesn't work for deep dives into complex and lengthy topics. For such topics, the discussion needs to be carefully written and organised.</p><p>There's no concept of “where” you are in Discourse discussions. There's only “when” you are, since the comments are ordered only by time. Discourse does provide some organisation to see the replies to a comment at one place. However if you need to see the replies to a particular reply inside a comment, you need to scroll down through other comments, find that particular reply (repeated as a comment!) and then check its replies:</p><p><img alt="CQ2 demo screenshot" fetchpriority="high" width="702" height="960" decoding="async" data-nimg="1" src="https://cq2.co/_next/static/media/discourse-comment-replies.02481816.png"></p><p><span>Slack</span>Slack is not really built for written, async discussions, but since it's widely used, let's talk about it. Discussions there are a stream of unorganised comments too, but at least Slack has threads to discuss a particular comment in detail in a separate pane. However, if you want to discuss a comment inside a thread in detail (i.e., create a new thread from a thread), you can't — Slack allows only one level of threads. Moreover, Slack feels too chatty — it feels impossible to have a long-running async discussion there. Its UI encourages sending bursts of fast, short comments instead of well-formed thoughts, and the typing indicator keeps everyone else distracted while one person tries to form their idea.</p><p><span>Quote hell</span>Now behold the common annoyance in all chat/forum platforms — the quote hell. What's that? Let's say Ava puts a comment about something. Then Caleb puts a comment with his replies to some quotes from Ava's comment. Now Ava puts a comment with her replies to Caleb's replies in quotes. What's happening? Replies to a topic are spread across different comments and you're forced to mentally manage all those quotes and their replies! On top of that, there are unrelated comments between that break your flow. These problems might not seem big for a discussion between two people, but a complex and lengthy discussion with 5+ participants quickly turns into a huge mess. Here's what a quote hell looks like:</p><p>After being frustrated with Slack, Discourse, etc., we started searching for a tool specifically built for complex discussions. We found none, began exploring how such a tool would work and look like, and started building:</p><p><span>CQ2</span>It's a free and open source tool for complex discussions. It's in its early stages, but it's the start of something that we think will both make discussions immensely enjoyable and radically increase productivity. We simulated a<!-- --> <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities#sSfjskRzAuDcWmFWg">small discussion</a> <!-- -->from LessWrong on CQ2. Check it out on the live demo,<!-- --> <a href="https://cq2.co/app/demo">here</a>! It turned out to be much better organised and easier to follow.</p><p>In CQ2, there's no mess of unorganised comments — create threads inside threads so that each thread stays on topic and organised. Forget quote hell — create threads around specific quotes and find all replies related to a topic at one place. Never lose context of where you are — see all parent threads of the current thread in the same view. Focus on what matters — see which threads have unread comments, which are concluded and quickly go to a particular thread using CQ2's tree. Conclude threads — add conclusions to resolved threads and to the whole discussion once it's resolved.</p></div><div><p><span>Commenting and creating threads</span>General comments about the discussion go in the main (first and leftmost) thread. To reply to a particular text from the main description or from any comment, select the text, click on the popped-up “Reply in new thread” button to create a new thread around that specific quote, and reply there. You can reply to the whole comment as well, instead of a particular text inside it, by using the reply button on the top-right of the comment.</p></div><div><p><span>Opening threads</span>If someone has already created a thread for a particular quote, the quote would appear highlighted. You can click on it to open its corresponding thread and continue the discussion there. If someone has already created a thread for a whole comment, there would be a highlighted comments button on the top-right of the comment which you can click on to open the corresponding thread.</p></div><div><p><span>Navigating</span>To move between different threads, you can scroll using a trackpad or using your mouse's scroll wheel with the shift key. You can also use the tree from the navigation bar to quickly go to a particular thread. The tree also shows the number of comments in a thread, the number of unread comments and whether the thread has been concluded.</p></div><div><p><span>Concluding</span>You can conclude a thread by using the “Conclude thread” button on top of the thread. Concluded threads have a green badge on top and the conclusion comment in green. To conclude the whole discussion, use the “Conclude discussion” button in the navigation bar.</p></div><div><p>Try creating some threads and adding some comments in the demo,<!-- --> <a href="https://cq2.co/app/demo">here</a>!</p><p>We have many more interesting and useful features planned, including rich text, workspaces, custom titles for threads, mentions, slow mode, useful reactions (and not just emojis) and even an AI assistant to help you find overlooked parts of the discussion.</p><p>With CQ2, we want to help people have better discussions, and ultimately, systematically arrive at truth, better understand others and make better decisions. If you resonate with CQ2's mission, we would love for you to try it out, provide your feedback<!-- --> <a href="https://github.com/orgs/cq2-co/discussions/1">here</a> <!-- -->and share this post with your friends!</p><p>Get early access,<!-- --> <a href="https://tally.so/r/meB0yJ">here</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Results of the Grand C++ Error Explosion Competition (2014) (194 pts)]]></title>
            <link>https://tgceec.tumblr.com/post/74534916370/results-of-the-grand-c-error-explosion</link>
            <guid>40277469</guid>
            <pubDate>Mon, 06 May 2024 17:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tgceec.tumblr.com/post/74534916370/results-of-the-grand-c-error-explosion">https://tgceec.tumblr.com/post/74534916370/results-of-the-grand-c-error-explosion</a>, See on <a href="https://news.ycombinator.com/item?id=40277469">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Patagonia's New Study Finds Fleece Jackets Are a Serious Pollutant (2016) (116 pts)]]></title>
            <link>https://www.outsideonline.com/outdoor-gear/gear-news/patagonias-new-study-finds-fleece-jackets-are-serious-pollutant/</link>
            <guid>40276957</guid>
            <pubDate>Mon, 06 May 2024 17:18:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.outsideonline.com/outdoor-gear/gear-news/patagonias-new-study-finds-fleece-jackets-are-serious-pollutant/">https://www.outsideonline.com/outdoor-gear/gear-news/patagonias-new-study-finds-fleece-jackets-are-serious-pollutant/</a>, See on <a href="https://news.ycombinator.com/item?id=40276957">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
      Heading out the door? Read this article on the Outside app available now on iOS devices for members!
      <a href="https://outsideapp.onelink.me/wOhi/6wh1kbvw" data-analytics-event="click" data-analytics-data="{&quot;name&quot;:&quot;Element Clicked&quot;,&quot;props&quot;:{&quot;destination_url&quot;:&quot;https://outsideapp.onelink.me/wOhi/6wh1kbvw&quot;,&quot;domain&quot;:&quot;<<analytics_vars.domain>>&quot;,&quot;name&quot;:&quot;in-content-cta&quot;,&quot;type&quot;:&quot;link&quot;}}">Download the app</a>.
    </p><div data-inject-ads="true" data-inject-ads-options="{&quot;markup&quot;:[&quot;<div class='o-ad-wrap'><div class='js-ad js-scroll-load' data-child-zone='in-content-leaderboard-ool' data-size='[\&quot;fluid\&quot;,[300,250],[1,1]]'><\/div><\/div>&quot;],&quot;filter&quot;:{&quot;nextExceptions&quot;:&quot;img, blockquote, div&quot;,&quot;nextContainsExceptions&quot;:&quot;img, blockquote, a.btn, a.o-button&quot;},&quot;renderIntial&quot;:true,&quot;wordCount&quot;:350}">
      <p>It all started on a beach in southwestern England in the early 2000s. Richard Thompson, then a senior lecturer at Plymouth University (where he now serves as professor of marine biology),&nbsp;was leading a team of graduate students researching microplastics in marine environments. Examining samples of sandy sediment, they expected to find degraded bits of marine plastic from decades-old flotsam&nbsp;or plastic beads that were becoming widely used in cleaners. To their surprise, most of the plastic fragments were fibrous, which meant they&nbsp;likely came from clothing, rope, or some types of packaging.</p>
<p>Then, in 2011, Mark Browne, one of Thompson’s former graduate students, published a study in which he examined sediment sampled from 15 beaches around the world. He&nbsp;found high concentrations of polyester and acrylic fibers in samples taken near wastewater treatment plants. He then ran a polyester fleece jacket through the wash and filtered 1,900 fibers from the wastewater—fibers that otherwise would&nbsp;have gone to the local wastewater treatment plant. Browne started reaching out to apparel makers to see if they’d help fund research to study this issue more deeply—eventually, he hoped, finding tweaks to fabric design or apparel construction that would stop the&nbsp;microfibers from entering wastewater. He received&nbsp;one offer of help—from women’s clothing brand Eileen Fisher—but Patagonia, Columbia, and other big brands declined, saying they didn’t know if the fibers were anything they needed to worry about.</p>
<div data-animation=""><blockquote><p>During laundering, a single fleece jacket sheds as many as 250,000 synthetic fibers—significantly more than the 1,900 fibers Browne first recorded. Based on an estimate of consumers across the world laundering 100,000 Patagonia jackets each year, the amount of fibers being released into public waterways is equivalent to the amount of plastic in&nbsp;up to&nbsp;11,900 grocery bags.</p></blockquote></div>
<p>Fast-forward four more years, and the fibers finally got everyone’s attention. <a href="https://www.outsideonline.com/1998166/plastics">The science was piling on</a>, showing that wastewater treatment plants couldn’t filter out all synthetic fibers,&nbsp;and that toxins such as DDT and PCBs can bind to them as they make their way into watersheds. It also showed&nbsp;that small aquatic species ingest the fibers, and that fish and bivalves sold for human consumption also contain microfibers. Experiments have&nbsp;shown that&nbsp;microplastics can lead to&nbsp;poor health outcomes in some species, and research is underway to find out how the plastics affect humans.</p>
<p>Jill Dumain, director of environmental strategy at&nbsp;<a href="http://www.patagonia.com/us/home" target="_blank" rel="noopener">Patagonia</a>, was one of the people paying attention to all the news. In early 2015, she&nbsp;and the&nbsp;company’s leadership decided to commission a study to find out if and how Patagonia’s iconic and well-loved fleeces and some other synthetic products were contributing to the problem.&nbsp;The results recently came&nbsp;in, and they’re not good.</p>
<p><a href="http://brenmicroplastics.weebly.com/project-findings.html" target="_blank" rel="noopener">The study</a>, performed by graduate students at the <a href="http://www.esm.ucsb.edu/" target="_blank" rel="noopener">Bren School of Environmental Science and&nbsp;Management</a> at the University of California, Santa Barbara, found that during laundering, a single fleece jacket sheds as many as 250,000 synthetic fibers—significantly more than the 1,900 fibers Browne first recorded. Based on an estimate of consumers across the world laundering 100,000 Patagonia jackets each year, the amount of fibers being released into public waterways is equivalent to the amount of plastic in up to&nbsp;11,900 grocery bags.</p>
<p>The experiment involved five pieces of apparel: three Patagonia fleece jackets,&nbsp;each with slightly different construction, as well as a nylon shell jacket that contains polyester insulation, plus a fifth specimen—a “budget”&nbsp;fleece jacket made by an undisclosed brand. Replicates of each jacket&nbsp;were washed multiple times, both in front-loading and top-loading washing machines. The effluent from each cycle was collected and put through a two-step filtration system that captured fibers with both a 333- and 20-micrometer mesh screen.</p>
<p>The jackets were then put through a 24-hour “killer wash,”&nbsp;which Patagonia uses to simulate the aging of a garment. The researchers did this to test whether older garments might shed more fibers as they age. After repeating the washing tests on these artificially aged jackets, they saw that age&nbsp;indeed increases fiber release&nbsp;by 80&nbsp;percent.</p>
<p>In previous studies, researchers counted the total number of fibers, but that was not a viable path for this study, which instead calculated their mass. “We fully intended to do counts, but in the volumes of water that we collected and filtered, there were simply so many—hundreds of thousands—of fibers [from each test], we knew quickly that even with five of us [on the research team] we did not have time or energy to [do individual counts],”&nbsp;says Stephanie Karba, the lead researcher on the UCSB team.</p>
<p>Using an equation widely used in the textile industry to determine fiber count based on mass, researchers found that the highest estimate of fibers released from a single jacket was 250,000, and the average across all jackets was 81,317&nbsp;fibers.</p>
<p>Hoping to publish its detailed methodology in a science journal, the team hasn’t revealed all its findings. But in addition to data about fiber release, the Patagonia report shows that fiber loss is directly related to the type of washing machine and the age of the garment.&nbsp;Garments released five times as many microfibers when washed in top-loading washing machines&nbsp;compared to front-loaders. And aging&nbsp;affected fiber loss differently for different garments&nbsp;based on the type of washer. For example, compared to Patagonia jackets, the average mass of fiber shed from the budget jacket of undisclosed origin was much higher when it was washed at the new stage&nbsp;in a front-loader. But after all the jackets were aged, the Patagonia jackets shed a comparable amount of fibers to the budget jacket. In top-loaders, the budget jacket shed a comparable amount of fiber, on average, to the others when new.</p>
<p>Another surprise: The nylon shell jacket actually released a comparable amount of fiber to the fleece jackets in some tests, and even more in other tests, seeming to indicate that the polyester fill escaped through seams or the shell fabric.</p>
<p>Having reviewed the findings, Richard Thompson, the Plymouth University scientist whose work knocked over&nbsp;the first domino, says Patagonia’s report might be more useful for Patagonia than for the scientific community&nbsp;because it does not take a vastly different approach that Browne’s research. He says he’d have preferred if Patagonia’s tests had been done with the use of detergent (the UCSB researchers say detergent would have clogged the filters, which is also why Browne did not use detergent in his 2011 research) and on a wider selection of apparel items.</p>
<p>“The budget jacket seems to perform worse in some tests but better in others, but even if it performed consistently better or worse, you can still only reach the conclusion for that one budget jacket of unknown origin,”&nbsp;he says. Still, he thinks it was an important first move by industry. “Honestly, some companies might shy away from this; they might not want to open a can of worms. So it’s a environmentally responsible move&nbsp;and potentially quite risky, since there is not much data out there on everyone else’s apparel.”</p>
<p>Add to the list of concerns unique to the outdoor industry: chemical additives in performance apparel (think&nbsp;waterproof-breathable duds) that enter the water along with the fibers.</p>
<p>Of course, apparel companies are far from the only stakeholders being thrust into the spotlight. The role washing machines play in microfiber pollution is also a major concern, and scientists and apparel companies are calling on appliance manufacturers to investigate the efficacy of adding filters to washing machines to capture fibers before they enter wastewater. The problem will&nbsp;grow with the rise in the number of washing machines coming into use globally—Swedish statistician <a href="https://www.youtube.com/watch?v=6sqnptxlCcw" target="_blank" rel="noopener">Hans Rosling</a> says 2 billion of the 7 billion people on earth used washing machines in 2010, but he predicts that 5 billion out of the 9 billion humans expected to populate the earth by 2050 will use the appliances.</p>
<p>A <a href="http://pubs.acs.org/doi/abs/10.1021/acs.est.5b05416" target="_blank" rel="noopener">study published last month</a>&nbsp;showed that while wastewater treatment plants remove more than 98 percent of plastic fragments from wastewater, they still send an estimated 65 million pieces of microplastics into watersheds each day. Polyester, the main fiber used in fleece, makes up the largest share of the plastics that get through—even though it only accounts for 10.8 percent of the plastic in influent wastewater (water that enters the plant). Also, many fibers that do get captured often end up in environmental sludge, which is sometimes added to fertilizer.</p>
<p>To try to get ahead of the problem, Patagonia and other apparel companies have said they want to research new yarn and fabric constructions to determine whether microfiber shedding can be addressed through better design, something that’s already happening in Europe.</p>
<p>After a 2013 European Commission–funded research program called Mermaids found that surfactants in detergents lead to much higher fiber loss—on the order of 1 million fibers shed from a single fleece jacket—textile specialists in Spain and Italy were tasked with developing a special coating or impregnation that would be applied to the fabric during manufacture and, in theory, reduce the amount of fiber loss. More details on the program are expected in December, but researchers say the coatings being tested and developed are environmentally benign.</p>
<p>The Mermaids program, promoted through the Plastic Soup Foundation, an NGO based in the Netherlands, has also released some guidelines based on its initial research, including suggestions to avoid the use of detergents with high pH, powder detergents, and the use of oxidizing agents. It also suggests washing clothing in cold water&nbsp;and softening hard water, and it released a <a href="https://www.youtube.com/watch?v=b8OZ_6YwTUE" target="_blank" rel="noopener">cheeky video</a>&nbsp;to drive its point home. Clothing company G-Star, which integrates synthetic fibers sourced from plastic ocean debris into the denim jeans it sells, has partnered with the Plastic Soup Foundation to promote the Mermaid program.</p>
<p>In August, at the Outdoor Retailer trade show in Salt Lake City, Patagonia will present the findings to its industry peers. It hopes to partner with the Outdoor Industry Association to turn the UCSB researchers’ testing protocol&nbsp;into an industry standard that would enable all clothing manufacturers to set a benchmark for fiber release from their apparel products. Dumain says it’s important that companies outside the outdoor niche start tracking microfiber issues&nbsp;as well. And she thinks an international third-party testing standards group, such as the ASTM, which has developed testing methods for factors such as sewn seams and flammability of apparel textiles, could also take the protocol and run with it. “It’s right up their alley,”&nbsp;Dumain says.</p>
<p>Unlike laws that restrict manufacturers from adding plastic microbeads to cleaning products, no obvious legislative approaches limit&nbsp;microfiber pollution, and apparel makers would likely prefer to self-impose approaches to reducing fiber loss rather than find themselves in the crosshairs of regulators&nbsp;should scientific evidence that microfibers pose environmental dangers continue to mount.</p>
<p>“We knew this would be step one in testing—to prove the methodology, to understand where we were contributing to the problem, where the industry could be contributing to the problem,”&nbsp;says Dumain. “From here, it’s going to set up a whole lot of testing that needs to happen throughout the apparel industry.”</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: Peerdb Streams – Simple, native Postgres change data capture (121 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40276768</link>
            <guid>40276768</guid>
            <pubDate>Mon, 06 May 2024 17:00:42 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40276768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>Hello HN, I am Sai Srirampur, one of the Co-founders of PeerDB. (<a href="https://github.com/PeerDB-io/peerdb">https://github.com/PeerDB-io/peerdb</a>). We spent the past 7 months building a solid experience to replicate data from Postgres to data warehouses. Now we're expanding to queues.</p><p>PeerDB Streams provides a simple and native way to replicate changes as they happen in Postgres to Queues (Kafka, Redpanda, Google PubSub, etc). We use Postgres logical decoding to enable Change Data Capture (CDC).</p><p>Blog post here: <a href="https://blog.peerdb.io/peerdb-streams-simple-native-postgres-change-data-capture">https://blog.peerdb.io/peerdb-streams-simple-native-postgres...</a>. 10-min quickstart here: <a href="https://docs.peerdb.io/quickstart/streams-quickstart">https://docs.peerdb.io/quickstart/streams-quickstart</a>.</p><p>We chose queues as many users found that existing tools are complex. Debezium is the most used tool for this use-case. It has large production usage. However, a common pain point among our users is that it has a significant learning curve taking months to productionize.</p><p>A few issues are: a) Interacting through a command line interface, understanding the various settings, and learning best practices for running it in production is not trivial. Debezium UI, released to address usability concerns [1], is still in an incubating state [2]. Additionally, reading Debezium resources to get started can be overwhelming [3]. 
b) Supporting data formats and transformations isn’t easy. It needs a Java project, building JAR packages and setting up a runtime path on the kafka connect plugin. c)Debezium is not as native as Kafka for other queues and doesn’t offer the same level of configurability. For example, with Event Hubs, it is difficult to stream to topics spread across namespaces and subscriptions.</p><p>TL;DR Debezium aims to provide a comprehensive experience for engineers to implement CDC rather than making it dead simple for them. So you can do a lot with Debezium but need to know a lot about it.</p><p>At PeerDB, we are building a simple yet comprehensive experience for Postgres CDC. The goal is to enable engineers to build prod-grade Postgres CDC with a minimal learning curve, within a few days.</p><p>PeerDB’s feature-set isn't at Debezium's level yet, and as we evolve, we might face similar challenges. However, we're putting usability at the forefront and we believe that we can achieve the above goal.</p><p>First, PeerDB offers a simple UI to set up Postgres and Kafka by creating PEERs and initiating CDC by creating a MIRROR. Through the UI, users can monitor the progress of CDC, including throughput and latency; set up alerts to Slack/Email based on replication slot growth; investigate Postgres-native metrics, including slot size, etc. Here is a demo showing of PeerDB UI in action:</p><p><a href="https://www.loom.com/share/ebcfb7646a1e48738835853b760e5d04" rel="nofollow">https://www.loom.com/share/ebcfb7646a1e48738835853b760e5d04</a></p><p>Second, for users who prefer a CLI, we provide a Postgres-compatible SQL layer to manage CDC. This offers the same level of features as the UI and is more intuitive compared to bash scripts.</p><p>Third, users can perform row-level transformations using Lua scripts executed at runtime. This enables features such as encrypting/masking PII data, supporting various data formats (JSON, MsgPack, Protobuf, etc.), and more. We offer a script editor along with a bunch of useful templates [5].</p><p>Fourth, we provide native connectors to non-Kafka targets. We also provide native configurability options tailored to these platforms. For example, with Event Hubs, users can perform CDC to topics distributed across different namespaces and subscriptions [4].</p><p>Finally, We are laser focused on Postgres, enabling specific optimizations like native metrics for replication, wait-events, and # of connections. Features like faster initial loads through parallel snapshotting and decoding transactions in-flight are in private beta.</p><p>Our hope is to provide the best data-movement experience for Postgres. PeerDB Streams is another step in that direction. We would love to get your feedback on product experience, our thesis and anything else that comes to your mind. It would be super useful for us. Thank you!</p><p>References:</p><p>[1] <a href="https://debezium.io/blog/2020/10/22/towards-debezium-ui/" rel="nofollow">https://debezium.io/blog/2020/10/22/towards-debezium-ui/</a>
[2] <a href="https://debezium.io/documentation/reference/stable/operations/debezium-ui.html" rel="nofollow">https://debezium.io/documentation/reference/stable/operation...</a>
[3] <a href="https://medium.com/@cooper.wolfe/i-hated-debezium-so-much-i-did-it-myself-b43b0efc20a9" rel="nofollow">https://medium.com/@cooper.wolfe/i-hated-debezium-so-much-i-...</a>
[4] <a href="https://blog.peerdb.io/enterprise-grade-replication-from-postgres-to-azure-event-hubs">https://blog.peerdb.io/enterprise-grade-replication-from-pos...</a>
[5] <a href="https://github.com/PeerDB-io/examples">https://github.com/PeerDB-io/examples</a>
[5] <a href="https://app.peerdb.cloud/" rel="nofollow">https://app.peerdb.cloud</a>
[6] <a href="https://github.com/PeerDB-io/PeerDB">https://github.com/PeerDB-io/PeerDB</a></p></div></td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[German public broadcasters open source their streaming platforms (184 pts)]]></title>
            <link>https://www.heise.de/en/news/ARD-und-ZDF-wollen-ihren-Streaming-Code-als-Open-Source-anbieten-9709177.html</link>
            <guid>40276714</guid>
            <pubDate>Mon, 06 May 2024 16:56:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/ARD-und-ZDF-wollen-ihren-Streaming-Code-als-Open-Source-anbieten-9709177.html">https://www.heise.de/en/news/ARD-und-ZDF-wollen-ihren-Streaming-Code-als-Open-Source-anbieten-9709177.html</a>, See on <a href="https://news.ycombinator.com/item?id=40276714">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr">
    

      

<div>
  <p><em>This article was originally published in German and has been automatically translated.</em>
  </p>
</div>


<p>The streaming media libraries of the public broadcasters ARD and ZDF are also growing together technically: The broadcasters want to develop a joint "streaming OS", they announced on Monday. The code is also to be made publicly available as part of "one of the largest open source initiatives in Germany".</p>

    
  

  
  <a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
    

  
    
    
  

  </a-paternoster>



<p>Competitors should also be able to use the Streaming OS code in this way, ARD Chairman Kai Gniffke commented on the initiative. He can imagine a cross-provider German streaming network. "If other institutions – including media companies that compete with us – use the software, then you can also imagine it as the nucleus for a large German-language platform."</p>
<p>ARD and ZDF media libraries also want to use the shared technical foundation to manage user data across the board. Meanwhile, it is still unclear which parts of Streaming OS will be made publicly available. In addition to the streaming player itself, the broadcasters' joint streaming software will also bundle the login system, code for recommendations and the "core of the design system". ARD and ZDF are thus also placing their media libraries on a common technical basis, <a href="https://www.heise.de/news/ARD-und-ZDF-verknuepfen-ihre-Mediatheken-9331478.html?from-en=1">having already grown together in terms of content in recent years</a>.</p>

  





<h3 id="nav__giving__0">"Giving something back to society"</h3>
<p>In addition to private providers, educational institutions can also benefit from the broadcasters' planned open source code, according to the broadcasters. "In this way, we are giving something back to society for which it has paid us," comments ZDF Director General Norbert Himmler on the project. Cooperation with European partners is also conceivable, according to a statement.</p>
<p>ARD and ZDF are setting up a joint office for the streaming OS, where the project will be managed. The technical development of the operation is to take place in a commercial subsidiary, which will be founded under the management of ARD. The broadcasters hope that Streaming OS will be ready in spring 2025.</p>
<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:dahe@heise.de" title="Daniel Herbig">dahe</a>)</span>
<!-- RSPEAK_START -->
</p>

      <!-- RSPEAK_STOP -->

      

      

      

      

      <!-- RSPEAK_STOP -->

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to escape Honda's privacy hell (107 pts)]]></title>
            <link>https://sherwood.news/tech/how-to-opt-out-of-the-privacy-nightmare-that-comes-factory-installed-in-new/</link>
            <guid>40276012</guid>
            <pubDate>Mon, 06 May 2024 15:49:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sherwood.news/tech/how-to-opt-out-of-the-privacy-nightmare-that-comes-factory-installed-in-new/">https://sherwood.news/tech/how-to-opt-out-of-the-privacy-nightmare-that-comes-factory-installed-in-new/</a>, See on <a href="https://news.ycombinator.com/item?id=40276012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="article-body-content"><p>There are lots of reasons to want to shut off your car’s data collection. The Mozilla Foundation has <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/after-researching-cars-and-privacy-heres-what-keeps-us-up-at-night/" target="_blank" rel="noopener">called</a> modern cars “surveillance machines on wheels” and ranked them <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/" target="_blank" rel="noopener">worse than any other product category</a> last year, with all 25 car brands they reviewed failing to offer adequate privacy protections.</p><p>With sensors, microphones, and cameras, cars collect way more data than needed to operate the vehicle. They also <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/what-data-does-my-car-collect-about-me-and-where-does-it-go/" target="_blank" rel="noopener">share and sell</a> that information to third parties, something many Americans don’t realize they’re opting into when they buy these cars. Companies are quick to flaunt their privacy policies, but those amount to pages upon pages of legalese that leave even professionals stumped about what exactly car companies collect and where that information might go.</p><p>So what can they collect?</p><p>“Pretty much everything,” said Misha Rykov, a research associate at the Mozilla Foundation, who worked on the car-privacy report. “Sex-life data, biometric data, demographic, race, sexual orientation, gender — everything.”</p><p>“The impression that we got — is that they are trying to be a bit more like Big Tech.”</p><p>It doesn’t mean they necessarily do, but they’re leaving the car door open.</p><p>“The impression that we got — and this impression is supported by the official documents of the brands — is that they are trying to be a bit more like Big Tech,” Rykov said. “It looks like most of them are not entirely sure what's going on there.”</p><p>The data they may or may not collect can cause real trouble. It can <a href="https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html" target="_blank" rel="noopener">notify your insurance company</a> that you braked too hard or sped up too fast. Car companies can share your info with law enforcement without your knowledge. A domestic abuser could use it to track your whereabouts. It doesn’t take a lot of imagination to see this heading south.&nbsp;</p><p>I wanted to turn off data collection on my car because it’s creepy and I thought the option would be simple. It turns out that shutting off data collection and figuring out what’s been collected is much more difficult than it would seem. I know because it took me — a reasonably informed and technologically savvy person —&nbsp;a month to finally do so.</p><p>I’m in good company.</p><p>“It’s comically difficult,” Thorin Klosowski, a security and privacy activist at Electronic Frontier Foundation, who’s <a href="https://www.eff.org/deeplinks/2024/03/how-figure-out-what-your-car-knows-about-you-and-opt-out-sharing-when-you-can" target="_blank" rel="noopener">written about how to do just this</a>, told me. “I do this for a living and I am not 100% positive I have gotten everything correct, which is ridiculous.”</p><p>In March, my husband and I bought a new Honda. When I turned on the car to leave the dealership, I got a notification telling me that data sharing was on. Right next to “on” was an “off” button. Simple enough! But when I hit “off” I got a message telling me it was “unable to change settings while network is invalid.” Right.</p><p>My children were screaming at me from the back seat, so I assumed this was a problem I could easily fix another time.&nbsp;</p><figure><div><p><img alt="Honda privacy 1" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><p>The car ostensibly gives me the option to shut on or off data collection.</p></figcaption></figure><figure><div><p><img alt="Honda privacy 2" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><p>Instead of shutting off, I got an error message.</p></figcaption></figure><p>Time got away from me and I tried again a few days later at home. I thought maybe the initial trouble was that the cell service wasn’t good enough, so I tried to shut off the data collection when I had a better signal. Nope.</p><p>I tried looking it up online and didn’t find anything conclusive. What I did find was a recent <a href="https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html" target="_blank" rel="noopener">New York Times piece by Kashmir Hill</a> that said car companies were sharing driving data with third parties, which in turn were selling it to insurance companies to jack up people’s rates.</p><p>I called the dealer. He talked to some people at Honda and called me back. If I wanted to shut off the data sharing, I’d have to download Honda’s HondaLink app, which came with its own <a href="https://mygarage.honda.com/resource/AutoLinkLegalTerms/HondaLinkLegalTerms/HondaLinkTermsAndConditions.pdf" target="_blank" rel="noopener">14 pages of unreadable terms and conditions</a>.</p><p>That was my only choice, he said. He also said I was the first person to ask him how to do so. I reluctantly downloaded the app, but couldn’t figure out how to shut it off from there. Finally, a day after downloading the app, I was able to shut off the data sharing in my car (confusingly, I had to do so in the car and not on the app, but only once I downloaded the app). It only took me a month.</p><p>Now, though, I will forever have a bright orange notification on my car screen telling me my data sharing is off. It’s clearly a <a href="https://www.vox.com/recode/22351108/dark-patterns-ui-web-design-privacy" target="_blank" rel="noopener">dark pattern</a> meant to nudge me into turning data collection back on.</p><figure><div><p><img alt="Honda privacy 3" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><p>I no longer am sharing data with Honda, but I will have this notification forever. </p></figcaption></figure><figure><div><p><img alt="Honda privacy 4" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><p>The bright orange system status is begging for me to turn my data sharing back on.</p></figcaption></figure><p>Honda confirmed the notification won’t go away as long as I have data sharing off. Great!&nbsp;</p><p>It’s important to add you can’t select what is collected and what isn’t; it’s all or nothing. If I want a genuinely useful-sounding safety feature — the ability to get an ambulance in the event of a collision, for example — I have to give my car information for everything else.</p><p>Following this fiasco of turning off the data, I wanted to find out what Honda had collected from our car during the time it was running.&nbsp;</p><p>EFF’s <a href="https://www.eff.org/deeplinks/2024/03/how-figure-out-what-your-car-knows-about-you-and-opt-out-sharing-when-you-can" target="_blank" rel="noopener">handy guide</a> sent me to Honda’s online <a href="https://www.honda.com/privacy/your-privacy-choices" target="_blank" rel="noopener">privacy request page</a>, where I learned we didn’t live in one of the five states where we could exercise our consumer rights to view or delete the data our car tracked.&nbsp;</p><figure><div><p><img alt="Honda privacy 5" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><p>Honda would only let me view what data it’s collected if I lived in California, Colorado, Connecticut, Utah or Virginia. </p></figcaption></figure><p>I tried by phone instead, to see if Honda might excuse our crime of living in New York. There I waited an hour to have someone — maybe — understand what I was asking: to see what data my car had collected on me.</p><p>“We haven’t done this. We don’t know how to do this.”</p><p>I was put on several holds. At one point I was told, “We haven’t done this. We don’t know how to do this.”</p><p>Eventually they figured it out.</p><p>Two days later, we got an email: “Because you are not a current resident of a qualifying state, your request will not be processed.” I filed an appeal, this time saying I was a journalist. Two days later that was denied as well.</p><p>“American Honda strives to build and maintain a relationship of trust with our customers,” a Honda rep wrote me. “Toward that end, the company’s public websites prominently feature a link to our privacy practices, which include provisions allowing consumers to opt out of the collection of certain types of information.”</p><p>When I tried asking more direct questions about what was collected, the Honda representative kept pointing me back to the company’s unreadable privacy policy.&nbsp;</p><p>Concurrently I’d sent out requests to data broker <a href="https://consumer.risk.lexisnexis.com/consumer" target="_blank" rel="noopener">LexisNexis</a> to look at my and my husband’s files. Fortunately, it didn’t seem to have turned up anything about our driving — just former addresses, phone numbers, property records — though it’s unclear if that’s because our car only had data collection on for a month.&nbsp;</p><p>The Times’ Hill was less lucky (as a civilian, more lucky as a reporter). She found out that she and her husband’s Chevy Bolt had been <a href="https://www.nytimes.com/2024/04/23/technology/general-motors-spying-driver-data-consent.html" target="_blank" rel="noopener">sending detailed information about their driving habits</a> — speeding, accelerating, stopping too fast — to data brokers and then on to insurance companies.&nbsp;&nbsp;</p><p>EFF’s Klosowski likens car’s unbridled data collection to smartphones around 2010 or internet of things devices (that were constantly being hacked into) soon after. A mix of <a href="https://www.aclunc.org/our-work/legislation/california-electronic-communications-privacy-act-calecpa-sb-178" target="_blank" rel="noopener">state</a> and <a href="https://www.gibsondunn.com/new-federal-law-for-iot-cybersecurity-requires-the-development-of-standards-and-guidelines-throughout-2021/" target="_blank" rel="noopener">federal</a> legislation have helped but privacy problems persist.&nbsp;</p><p>“It used to be worse, which is a fun thing to think about,” he said.</p><p>“We have found ourselves in similar situations before and we did, slowly but surely, push on these companies to make improvements,” Klosowski said. “Car makers have less of an excuse given the fact that the history of smartphones and IoT products are <i>right there</i> to learn from.”</p><p>Last year, US Sen. Ed Markey sent a number of questions to car companies trying to suss out more clearly what they collect and where it goes. Recently their responses came out, but they’re <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/car-company-ceos-answer-tough-questions-about-cars-and-privacy-kinda/" target="_blank" rel="noopener">not exactly transparent</a>. Markey has since sent a letter to the FCC asking them to investigate automakers sending car location data to police. It’s part of <a href="https://www.nytimes.com/2024/04/30/technology/regulators-investigate-carmakers-driver-tracking.html" target="_blank" rel="noopener">increasing government attention</a> on the car-data industry. But for now the freedom of the open road doesn’t feel really free.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Clojure: Managing throughput with virtual threads (103 pts)]]></title>
            <link>https://andersmurphy.com/2024/05/06/clojure-managing-throughput-with-virtual-threads.html</link>
            <guid>40275997</guid>
            <pubDate>Mon, 06 May 2024 15:48:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andersmurphy.com/2024/05/06/clojure-managing-throughput-with-virtual-threads.html">https://andersmurphy.com/2024/05/06/clojure-managing-throughput-with-virtual-threads.html</a>, See on <a href="https://news.ycombinator.com/item?id=40275997">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><hgroup><p><time datetime="2024-05-06T00:00:00+00:00">06 May 2024</time></p></hgroup><hr><p>Before the introduction of Java 21 virtual threads we were heavy users of <a href="https://github.com/clj-commons/claypoole">claypoole</a> a fantastic library for simple but effective parallelism using thread pools. However, things get complicated with virtual threads, they shouldn't be pooled, as they aren't a scarce resource. So how do we limit throughput when we have "unlimited" threads? In this post we will look at using java <code>Semaphore</code> class to implement basic token bucket rate limiting to control throughput.</p><p>One of the other key insights I've drawn from claypoole is that unordered parallelism helps minimising latency, as it allows you to process results as soon as they became available. So we'll also explore unordered parallelism with virtual threads.</p><p>To get an virtual thread <code>executor</code> we can call:</p><pre><code><span>(</span>defonce <strong>executor</strong> <span>(</span>Executors/newVirtualThreadPerTaskExecutor<span>))</span>
</code></pre><p>We can combine this with an <code>ExecutorCompletionService</code> to get tasks as they complete rather than the order they are submitted in:</p><pre><code><span>(</span>def <strong>cs</strong> <span>(</span>ExecutorCompletionService/new executor<span>))</span>
</code></pre><p>We can submit tasks to the <code>CompletionService</code> with <code>.submit</code>:</p><pre><code><span>(</span>run! <span>(</span>fn [x] <span>(</span>ExecutorCompletionService/.submit
                  cs #<span>(</span>inc x<span>)))</span>
    [1 2 3 4 5]<span>)</span>
</code></pre><p>We are using Clojure 1.12.0-alpha10 methods as values syntax e.g: <code>ExecutorCompletionService/.submit</code>. This means we don't have to mannualy type hint to avoid reflection.</p><p>To take completed tasks from the service we use <code>.take</code>:</p><pre><code><span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
    <span>(</span>take 5<span>))</span>
</code></pre><p>It's important to note that <code>.take</code> is blocking so if we <code>take</code> more tasks than there are from the completion service this code will block indefinitely (or until more tasks are submitted to the service). Because of this our implementation of <code>upmap</code> will consume eagerly (i.e it requires all of it's inputs before it will execute) as we need to know the total number of items that we will want to take <code>(count coll)</code>.</p><p>We can combine all of this to write our own implementation of <code>upmap</code> (unordered pmap):</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
     <span>(</span>run! <span>(</span>fn [x] <span>(</span>ExecutorCompletionService/.submit
                     cs #<span>(</span>f x<span>)))</span> coll<span>)</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p><code>upmap</code> takes completed tasks lazily, which lets us process them as they are completed rather than waiting for all tasks to complete:</p><pre><code><span>(</span>upmap inc [1 2 3 4 5 6]<span>)</span><span>
=&gt;</span>

<span>(</span>2 3 4 5 6 7<span>)</span>
</code></pre><p>Now lets look at implementing rate limiting. There's no point spinning up a bunch of virtual threads to make requests against a third party API only to have some fail due to exceeding the third party API's rate limit.</p><p>We can use semaphores for this. Semaphores are similar to pools, but instead of pooling a scarce resource like threads, semaphores instead pool permits:</p><pre><code><span>(</span>defonce <strong>sem</strong>
  <span>(</span>Semaphore/new 2 true<span>))</span>
</code></pre><p>We set fairness to <code>true</code> to prevent starvation. From the docs:</p><blockquote><p> The constructor for this class optionally accepts a fairness parameter... When fairness is set true, the semaphore guarantees that threads invoking any of the acquire methods are selected to obtain permits in the order in which their invocation of those methods was processed (first-in-first-out; FIFO). </p></blockquote><p>Worth keeping in mind this will have a throughput cost, so might not always be the right choice:</p><blockquote><p> Generally, semaphores used to control resource access should be initialized as fair, to ensure that no thread is starved out from accessing a resource. When using semaphores for other kinds of synchronization control, the throughput advantages of non-fair ordering often outweigh fairness considerations. </p></blockquote><p>We can combine Semaphores with virtual threads to implement token bucket rate limiting (X req/s with burst of X). This is trivial with virtual threads as we can spin up a new virtual thread (with <code>Thread/startVirtualThread</code>) to return the permit to the semaphore pool after the allotted time. In our case we have two permits and we want a rate limit of 2 req/s so we sleep for 1000ms before returning a permit:</p><pre><code><span>(</span>defn <strong>rate-limited-sem-release</strong> [sem]
  <span>;; block until available
</span>  <span>(</span>Semaphore/.acquire sem<span>)</span>
  <span>;; Create another virtual thread that will release this semaphore
</span>  <span>;; to refill the bucked when the time is up.
</span>  <span>(</span>Thread/startVirtualThread
    #<span>(</span>do <span>(</span>Thread/sleep 1000<span>)</span> <span>;; wait 1 second
</span>         <span>(</span>Semaphore/.release sem<span>))))</span>
</code></pre><p>Something to keep in mind is the accuracy of <code>Thread/sleep</code>. From the java language specification:</p><blockquote><p> Thread.sleep causes the currently executing thread to sleep (temporarily cease execution) for the specified duration, subject to the precision and accuracy of system timers and schedulers. The thread does not lose ownership of any monitors, and resumption of execution will depend on scheduling and the availability of processors on which to execute the thread. </p></blockquote><p>But for our use case this is accurate enough. In my testing it's only been off by a few milliseconds.</p><p>Combining this all together we get:</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>upmap nil f coll<span>))</span>
  <span>(</span>[sem f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
     <span>(</span>run!
       <span>(</span>fn [x]
         <span>(</span>when sem <span>(</span>rate-limited-sem-release sem<span>))</span>
         <span>(</span>ExecutorCompletionService/.submit cs <span>(</span>fn [] <span>(</span>f x<span>))))</span> coll<span>)</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p>Let's see if it works:</p><pre><code><span>(</span>time
  <span>(</span>-&gt;&gt; <span>(</span>upmap sem inc [1 2 3 4 5 6 8 9 10]<span>)</span>
    <span>(</span>run! prn<span>)))</span>
    <span>
=&gt;</span>
3
4
5
10
11
7
6
9
"Elapsed time: 4019.565335 msecs"

nil
</code></pre><p>The execution time is correct (greater than 4000msec). However, we are getting all the results in one go. This is happening because the semaphore is blocking the <code>run!</code> function and the way the code is currently written we can't start taking from the <code>CompletionService</code> until all the tasks have been submitted.</p><p>We can get around this by throwing more virtual threads at the problem. We use <code>Thread/startVirtualThread</code> to execute the <code>run!</code> function in another thread, so even if it blocks we can still start taking completed tasks:</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>upmap nil f coll<span>))</span>
  <span>(</span>[sem f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
<ins>+    <span>(</span>Thread/startVirtualThread</ins>
       #<span>(</span>run!
          <span>(</span>fn [x]
            <span>(</span>when sem <span>(</span>rate-limited-sem-release sem<span>))</span>
            <span>(</span>ExecutorCompletionService/.submit cs <span>(</span>fn [] <span>(</span>f x<span>))))</span> coll<span>))</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p>Let's see if <code>upmap</code> now behaves as we expect:</p><pre><code><span>(</span>time
  <span>(</span>-&gt;&gt; <span>(</span>upmap sem inc [1 2 3 4 5 6 8 9 10]<span>)</span>
    <span>(</span>run! prn<span>)))</span>
    <span>
=&gt;</span>
3
4
<span>...</span>
5
10
<span>...</span>
11
7
<span>...</span>
6
9
"Elapsed time: 4019.565335 msecs"

nil
</code></pre><p>Excellent we now get the results as they complete, whilst still respecting the rate limit. </p><p>All of this with zero dependencies. The power that Clojure's tight integration with the Java is really amazing.</p><p>The full example <a href="https://github.com/andersmurphy/clj-cookbook/tree/master/virtual-threads/managing-throughput">project can be found here</a>.</p><p>Further reading:</p><ul><li><a href="https://inside.java/2024/02/04/sip094/" title="">Managing Throughput with Virtual Threads - Sip of Java</a></li><li><a href="https://ericnormand.me/guide/clojure-virtual-threads">Virtual Threads in Clojure</a></li><li><a href="https://clojure.org/news/2024/04/28/clojure-1-12-alpha10#method_values">Clojure Method Values</a></li><li><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/ExecutorCompletionService.html">ExecutorCompletionService</a></li><li><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/Semaphore.html">Semaphore</a></li></ul></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PiFex: JTAG Hacking with a Raspberry Pi (173 pts)]]></title>
            <link>https://voidstarsec.com/blog/jtag-pifex</link>
            <guid>40274777</guid>
            <pubDate>Mon, 06 May 2024 13:59:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://voidstarsec.com/blog/jtag-pifex">https://voidstarsec.com/blog/jtag-pifex</a>, See on <a href="https://news.ycombinator.com/item?id=40274777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <p><a href="https://voidstarsec.com/blog/">Home</a></p>
<p>
  
  
    <span>May 2024</span>
  
</p>



<h2 id="overview">Overview</h2>

<p>When performing initial hardware analysis and recon, I have become very fond of using Armbian-based single-board computers (SBCs) for things like UART, SPI, I2C, JTAG, and SWD. One of the main benefits of using one of these boards is that since the peripherals we are interested in&nbsp;are&nbsp;exposed&nbsp;as character devices in Linux, a wide variety of tools are available for interfacing with them, including most programming and scripting languages.&nbsp;</p>

<p>However, one of the biggest hurdles that stop people from using an Armbian-based device is the initial setup and configuration (not to mention availability!). It takes more time to configure an Orange Pi or Raspberry Pi and enable the various interfaces than&nbsp;plug&nbsp;in an FTDI to your Linux machine. This blog post will help break down some of those barriers and streamline the setup process for those looking to learn hardware hacking with a Linux SBC.</p>

<p>With this blog post, we’ll introduce the PiFex, a basic companion board for the Raspberry Pi designed to teach users the basics of hardware hacking and embedded protocols. We will then demonstrate how to use the PiFex to access a JTAG tap on an undocumented SSD, allowing memory reads and GDB access to the SSD CPU.</p>

<p><strong>Note:</strong>&nbsp;The design and software for the PiFex will be open-sourced&nbsp;in the coming months as we continue our final rounds of testing</p>

<h2 id="background-information">Background Information</h2>

<p>&nbsp;If you are unfamiliar with JTAG at a low level, you might want to read my <a href="https://wrongbaud.github.io/posts/jtag-hdd/">previous</a> blog post about reverse engineering JTAG taps.&nbsp;</p>

<h2 id="pifex-an-overview">PiFex: An Overview</h2>

<p>The Pi Interface Explorer or PiFex, is a simple hat for a Raspberry Pi designed for tinkerers and hardware hackers alike.&nbsp;By breaking out the commonly used interfaces and routing them through bi-directional level shifters, we aimed to streamline some&nbsp;of the&nbsp;initial steps when reverse engineering a new device or&nbsp;trying to learn&nbsp;how a new sensor works.&nbsp;While this device&nbsp;was initially designed&nbsp;for use during our <a href="https://voidstarsec.com/hhb.html">hardware hacking bootcamp</a> it has quickly become my go-to when performing initial hardware assessments of COTS devices.</p>

<p>The PCB is well documented, and the IO pins are all labeled as shown in the image below:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/pifex.JPG" alt="Pifex Overview"></p>

<p>We also have added an I2C OLED screen, which you can customize using the Adafruit CircuitPython libraries:</p>

<p><img src="https://voidstarsec.com/blog/assets/" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/jtag_id_clipped.jpg" alt="JTAG ID Clipped "></p>
<h2 id="pifex-hardware">PiFex: Hardware</h2>

<p>The PiFex exposes the following interfaces to the end user:</p>

<ul>
  <li>UART via <code>IO14</code> and <code>IO15</code></li>
  <li>SPI via <code>IO8</code>, <code>IO9</code>, <code>IO10</code> and <code>IO11</code></li>
  <li>I2C via <code>IO2</code> and <code>IO3</code></li>
  <li>JTAG via <code>IO2</code>,<code>IO3</code>,<code>IO14</code> and <code>IO15</code></li>
  <li>SWD via <code>IO9</code> and <code>IO11</code></li>
</ul>

<p>There are also an additional eight GPIO pins. These interfaces were chosen because they are the ones that we utilize in our hardware hacking training and are also the most likely to be used by tinkerers and hardware hackers for other projects.&nbsp;</p>

<h2 id="logic-analyzer-connector">Logic Analyzer Connector</h2>

<p>When reverse engineering a target device or inspecting why your custom code controlling a specific peripheral isn’t working, a logic analyzer is your best friend. To help simplify the wiring for both our training and standard usage, we also added a logic analyzer connector.&nbsp;This&nbsp;was done&nbsp;to remediate potential wiring issues and make debugging and troubleshooting as easy as possible. An interface board&nbsp;was designed&nbsp;to connect to entry-level logic analyzers that can&nbsp;be seen&nbsp;in the image below:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/la_connector.JPG" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/la_1.JPG" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/la_2.JPG" alt=""></p>

<p>This&nbsp;helps streamline&nbsp;connecting&nbsp;a logic analyzer to the PiFex and&nbsp;analyzing&nbsp;the transmitted or monitored signals.&nbsp;</p>

<h2 id="level-shifters">Level Shifter(s)</h2>

<p>The Raspberry PI uses 3.3V logic levels, meaning it can only communicate with devices that use that same logic level. If we want to connect to a device that uses lower voltages (1.8V and 1.2V are becoming increasingly common), we need to route those through a level shifter.&nbsp;To streamline this and help reduce issues with&nbsp;wiring&nbsp;during our training, we’ve added two&nbsp;onboard level&nbsp;shifters.</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/level_shifters.JPG" alt=""></p>

<p>We chose to use the <a href="https://www.ti.com/product/TXB0108">TXB0108 Bi-Directional level shifters</a>; these allow us to communicate with devices at a voltage below 3.3V. In the case where a different logic level is needed, the user can select whether to use an external voltage source for the input voltage using the <code>VCCA_IN</code> line on the exposed headers. The level shifter then references this voltage by toggling the selector switch at the top of the board to <code>VCCA_IN</code> as opposed to the default state, which is <code>3.3V</code>.</p>

<h2 id="pifex-software">PiFex: Software</h2>

<p>If you’ve ever had to set up a headless Raspberry Pi before, you know that it’s not always a simple task, and when performing remote training, we&nbsp;can’t&nbsp;assume that&nbsp;everyone&nbsp;will be able&nbsp;to manually configure their Pi to connect to their network.&nbsp;This&nbsp;is why we designed the PiFex image to use a USB-Ethernet gadget on startup to present an Ethernet device to the end user over USB. This results in an easy, predictable way to connect to the Pi. After plugging the Pi into their machine, all the user needs to do is set the IP address, and they are all set. A short video walking through the web interface can&nbsp;be seen&nbsp;below:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/multi.gif" alt="UART Startup Voltages"></p>

<p>As mentioned in the previous section, one of the initial hurdles when learning about embedded protocols is selecting what tool or interface you want to learn with. Embedded development boards like the Arduino series or STM32 series are great but require setting up a development environment and understanding the specifics of the target microcontroller. One of the benefits of using an embedded Linux board is that these interfaces are exposed via <code>/dev/</code> and can be accessed using many programming languages such as Python, Rust, C, and even bash.&nbsp;</p>

<h2 id="jupyter-notebooks">Jupyter Notebooks</h2>

<p>Throughout our training, we utilize Jupyter Notebooks to help streamline the process and provide students with template notebooks for future assessments. For example, the JTAG notebook contains instructions and tooling to perform:</p>

<ol>
  <li>
    <p>JTAG Scan Chain Detection via <code>go-jtagenum</code></p>
  </li>
  <li>
    <p>Example UrJTAG Python Bindings for low-level scan chain access</p>
  </li>
  <li>
    <p>Example OpenOCD configurations and Python bindings for scripting JTAG operations</p>
  </li>
</ol>

<p>Screenshots of the included notebooks can&nbsp;be seen&nbsp;below:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/jtag-notebook-2.png" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/jtag.png" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/notebook-1.png" alt=""></p>

<p>While in class, we will use all of these features on our target, and students will be able to copy this notebook and use the same tools and techniques for future targets.&nbsp;</p>

<p>Last but certainly not least, we’ve configured the PiFex image to allow access to standard tools such as SSH and FTP. Now that we’ve reviewed&nbsp;the PiFex’s&nbsp;features and intended use case, let’s reverse-engineer the JTAG TAP for an undocumented target!</p>

<h2 id="pifex-demo-1--jtag">PiFex Demo 1 : JTAG</h2>

<p>So, we’ve talked about our new hardware tooling. How about a demonstration of it in action? Let’s start with a low-cost SSD purchased on AliExpress.&nbsp;</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/top_pcb_labelled.jpg" alt=""></p>

<p>If we break down the hardware, we have the following:</p>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Part Number</th>
      <th>Datasheet / Information</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>SM2259XT</td>
      <td><a href="https://www.siliconmotion.com/download/q/a/SM2259_XT_PB_EN_201910.pdf">Advertisement / Basic Information</a></td>
    </tr>
    <tr>
      <td>2</td>
      <td>SPS64472LBTH2</td>
      <td>NA - 64GB NAND Flash</td>
    </tr>
    <tr>
      <td>3</td>
      <td>50.00 MHz</td>
      <td>Oscilator</td>
    </tr>
    <tr>
      <td>4</td>
      <td>NA</td>
      <td>10 pin debug header</td>
    </tr>
  </tbody>
</table>

<p>After searching for datasheets, we were not able to locate much; however, next, we will investigate the mystery header at the end of the board. Let’s start by looking at this debug connector at the end of the drive. First, we will attempt to identify the ground connection. To do this, we will use our multimeter in continuity mode and test against a known ground. We will use the large copper fills to connect the SSD to an adapter board in this case.&nbsp;</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/known_ground.jpg" alt=""></p>

<p>After performing this test, we determined that the following pin was ground.
<img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/known_ground_2.jpg" alt=""></p>

<p>Now we need to determine what logic levels are in use; remember that the Pi uses a 3.3V logic level by default, so if there are other levels in use, we will need to locate a reference voltage for the level shifter. We will use the following pinout of the SSD for reference:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/connector_pins.jpg" alt=""></p>

<p>After measuring the voltages on the connector, we saw the following voltages.&nbsp;</p>

<ul>
  <li><strong>Side Note:</strong> When reversing a new target, I like to place the target platform on top of a blank sheet of paper; that way, I can quickly write down notes as I am probing/reverse engineering without having to turn away from the workspace. You can see this in the video below:</li>
</ul>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/measurement.gif" alt="UART Startup Voltages"></p>

<table>
  <thead>
    <tr>
      <th>Pin</th>
      <th>Voltage</th>
      <th>Usage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0V</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.28V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.28V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.173V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.02V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
  </tbody>
</table>

<p>It is extremely common for voltage sources to have capacitors connected to them called decoupling capacitors. These capacitors help stabilize the power supply in the event of voltage fluctuations. From here, there are two approaches that we can take to&nbsp;finding&nbsp;out which pins <strong>might</strong> be VCC on our SSD.</p>

<ol>
  <li>
    <p>Note what pins&nbsp;are connected&nbsp;to large capacitors near the connector</p>
  </li>
  <li>
    <p>Monitor the voltage source on power up / power down</p>
  </li>
</ol>

<p>Based on the voltages we collected, we should monitor pins&nbsp;2,3,4,6,7,&nbsp;and \8 with the oscilloscope and see how they differ. Take a look at the images below and see if you can spot the different one:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/all_drops.png" alt=""></p>

<p>If we examine the images highlighted in green below, we see a relatively sharp drop from high to low:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/digital_drops.png" alt=""></p>

<p>Looking closely at the images above, you may notice that image 1 has a slightly different shape when it rises and falls than the other lines.&nbsp;This&nbsp;is likely due to a capacitor being present somewhere on this line, which makes it a good candidate for VCC.&nbsp;This&nbsp;was pin two on the debug header, so we can now update our table as shown below.</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/analog_drops.png" alt=""></p>

<table>
  <thead>
    <tr>
      <th>Pin</th>
      <th>Voltage</th>
      <th>Usage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0V</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.28V</td>
      <td>VCC</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.28V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.173V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.02V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.284V</td>
      <td>???</td>
    </tr>
  </tbody>
</table>

<p>We will connect to the SSD using the clips shown in the image below, these were also purchased on AliExpress.</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/clip-only.JPG" alt=""></p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/connected.JPG" alt=""></p>

<p>With this assumption, we&nbsp;are left&nbsp;with six unknown pins. Next, we can perform a JTAG IDCODE scan using the <code>go-jtagenum</code> tools; this will attempt to brute force all of the possible JTAG pin combinations and will report back pin configurations that report a valid ID code or pass the bypass test. If you’re unfamiliar with these scans and want to learn more about them, check out my old writeup <a href="https://wrongbaud.github.io/posts/jtag-hdd/">here</a>.</p>

<div><pre><code>pi@voidstar:~/go/bin/linux_arm <span>$ </span>./go-jtagenum <span>-pins</span> <span>'{ "pin2": 2, "pin3": 3, "pin14": 14, "pin15": 15, "pin10": 10, "pin9": 9}'</span> <span>-command</span> scan_idcode <span>-delay-tck</span> 50
defined pins: map[2:pin2 3:pin3 9:pin9 10:pin10 14:pin14 15:pin15]
<span>================================</span>
Starting scan <span>for </span>IDCODE...
FOUND! TCK:pin10 TMS:pin3 TDO:pin2
&nbsp; &nbsp; &nbsp;devices:
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x459dd1e7 <span>(</span>mfg: 0x0f3 <span>(</span>Digital Microwave<span>)</span>, part: 0x59dd, ver: 0x4<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xb83b3f6f <span>(</span>mfg: 0x7b7 <span>(</span>invalid<span>)</span>, part: 0x83b3, ver: 0xb<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x268b37a3 <span>(</span>mfg: 0x3d1 <span>(</span>Accelerated Memory Production Inc.<span>)</span>, part: 0x68b3, ver: 0x2<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x5f5fcedf <span>(</span>mfg: 0x76f <span>(</span>invalid<span>)</span>, part: 0xf5fc, ver: 0x5<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xf79d3aeb <span>(</span>mfg: 0x575 <span>(</span>invalid<span>)</span>, part: 0x79d3, ver: 0xf<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x72ba6a4f <span>(</span>mfg: 0x527 <span>(</span>invalid<span>)</span>, part: 0x2ba6, ver: 0x7<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x7bf1f75d <span>(</span>mfg: 0x3ae <span>(</span>Korea Uhbele International Group Ltd.<span>)</span>, part: 0xbf1f, ver: 0x7<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xe7cfffaf <span>(</span>mfg: 0x7d7 <span>(</span>invalid<span>)</span>, part: 0x7cff, ver: 0xe<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xb0cf6bbf <span>(</span>mfg: 0x5df <span>(</span>invalid<span>)</span>, part: 0x0cf6, ver: 0xb<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xebbfb71f <span>(</span>mfg: 0x38f <span>(</span>Ericsson Modems<span>)</span>, part: 0xbbfb, ver: 0xe<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xd6f7fc17 <span>(</span>mfg: 0x60b <span>(</span>invalid<span>)</span>, part: 0x6f7f, ver: 0xd<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xedfe967b <span>(</span>mfg: 0x33d <span>(</span>AIM Corporation<span>)</span>, part: 0xdfe9, ver: 0xe<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xfeefd88d <span>(</span>mfg: 0x446 <span>(</span>invalid<span>)</span>, part: 0xeefd, ver: 0xf<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x8ef5b7ff <span>(</span>mfg: 0x3ff <span>(</span>invalid<span>)</span>, part: 0xef5b, ver: 0x8<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x2fdc8f9f <span>(</span>mfg: 0x7cf <span>(</span>invalid<span>)</span>, part: 0xfdc8, ver: 0x2<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x7ce9726b <span>(</span>mfg: 0x135 <span>(</span>API NetWorks<span>)</span>, part: 0xce97, ver: 0x7<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x7ff76d77 <span>(</span>mfg: 0x6bb <span>(</span>invalid<span>)</span>, part: 0xff76, ver: 0x7<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xb9f58fdb <span>(</span>mfg: 0x7ed <span>(</span>invalid<span>)</span>, part: 0x9f58, ver: 0xb<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xe36f2bb7 <span>(</span>mfg: 0x5db <span>(</span>invalid<span>)</span>, part: 0x36f2, ver: 0xe<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x757fbbdb <span>(</span>mfg: 0x5ed <span>(</span>invalid<span>)</span>, part: 0x57fb, ver: 0x7<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x4fbeae5f <span>(</span>mfg: 0x72f <span>(</span>invalid<span>)</span>, part: 0xfbea, ver: 0x4<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0xddf6f17f <span>(</span>mfg: 0x0bf <span>(</span>Broadcom<span>)</span>, part: 0xdf6f, ver: 0xd<span>)</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x1f3cefbd <span>(</span>mfg: 0x7de <span>(</span>invalid<span>)</span>, part: 0xf3ce, ver: 0x1<span>)</span>
&nbsp; &nbsp; &nbsp;possible nTRST: pin9, pin14 pin15&nbsp;
FOUND! TCK:pin10 TMS:pin14 TDO:pin15
&nbsp; &nbsp; &nbsp;devices:
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x100434b1 <span>(</span>mfg: 0x258 <span>(</span>Lorom Industrial Co. Ltd.<span>)</span>, part: 0x0043, ver: 0x1<span>)</span>
&nbsp; &nbsp; &nbsp;possible nTRST: pin9 pin2 pin3&nbsp;
<span>================================</span>
pi@voidstar:~/go/bin/linux_arm <span>$ </span>./go-jtagenum <span>-pins</span> <span>'{ "pin2": 2, "pin3": 3, "pin14": 14, "pin15": 15, "pin10": 10, "pin9": 9}'</span> <span>-command</span> scan_bypass <span>-delay-tck</span> 50
defined pins: map[2:pin2 3:pin3 9:pin9 10:pin10 14:pin14 15:pin15]
<span>================================</span>
Starting scan <span>for </span>pattern 0110011101001101101000010111001001
FOUND! TCK:pin10 TMS:pin14 TDO:pin15 TDI:pin9, possible nTRST: pin2 pin3&nbsp;
^C
pi@voidstar:~/go/bin/linux_arm <span>$ </span>./go-jtagenum <span>-pins</span> <span>'{ "pin2": 2, "pin3": 3, "pin14": 14, "pin15": 15, "pin10": 10, "pin9": 9}'</span> <span>-command</span> scan_idcode <span>-delay-tck</span> 50
defined pins: map[2:pin2 3:pin3 9:pin9 10:pin10 14:pin14 15:pin15]
<span>================================</span>
Starting scan <span>for </span>IDCODE...
FOUND! TCK:pin10 TMS:pin14 TDO:pin15
&nbsp; &nbsp; &nbsp;devices:
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;0x100434b1 <span>(</span>mfg: 0x258 <span>(</span>Lorom Industrial Co. Ltd.<span>)</span>, part: 0x0043, ver: 0x1<span>)</span>
&nbsp; &nbsp; &nbsp;possible nTRST: pin2 pin3 pin9&nbsp;
</code></pre></div>

<p>Before we move forward, let’s talk about the output&nbsp;that we’re seeing&nbsp;above. You’ll notice that <code>go-jtagenum</code> discovered what it believes to be multiple possible pin mappings, some of which contain more “devices” than others. While it is&nbsp;possible&nbsp;that there <strong>can</strong> be various devices on a JTAG scan chain, we know that this device is pretty straightforward and will not likely have 10+ devices.&nbsp;This&nbsp;is the one drawback of the <code>IDCODE</code> scan; it simply checks to see if data is changing** on the assumed <code>TDO</code> port, which can lead to many false positives. However, the entry displaying just one <code>IDCODE</code> value looks promising; we can further investigate this TAP using the <code>BYPASS</code> scan.</p>

<p>We can&nbsp;attempt to&nbsp;verify these results with a bypass scan.&nbsp;The <code>BYPASS</code> scan attempts to leverage the <code>BYPASS</code> instruction of the JTAG TAP which directly links the <code>TDI</code> and <code>TDO</code> lines.&nbsp;The scan attempts to enter the <code>BYPASS</code> instruction, provides a unique bit pattern on <code>TDI</code>,&nbsp;and monitors for that same pattern on <code>TDO</code>.&nbsp;If the data sent on <code>TDI</code> matches what&nbsp;is read&nbsp;on <code>TDO</code>,&nbsp;then the scan has determined the correct pinout. The results of the BYPASS scan can&nbsp;be seen&nbsp;below:</p>

<div><pre><code>
['defined pins: map[2:IO_2 3:IO_3 9:IO_9 10:IO_10 14:IO_14 15:IO_]',
&nbsp;'================================',
&nbsp;'Starting scan for pattern 0110011101001101101000010111001001',
&nbsp;'active, TCK:IO_10 TMS:IO_14 TDO:IO_ TDI:IO_2, wrong data received (0000000000000000000000000000000000)',
&nbsp;' try adjusting frequency, delays, pullup, check hardware connectivity',
&nbsp;'FOUND! TCK:IO_10 TMS:IO_14 TDO:IO_ TDI:IO_9, possible nTRST: IO_3 IO_2 ',
&nbsp;'================================']
</code></pre></div>

<p>Going back to our table of pin usages, we now know the following:</p>

<table>
  <thead>
    <tr>
      <th>Pin</th>
      <th>Voltage</th>
      <th>Usage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0V</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.28V</td>
      <td>VCC</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.28V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.173V</td>
      <td>???</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.02V</td>
      <td>TDO</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.284V</td>
      <td>TMS</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.284V</td>
      <td>TDI</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.284V</td>
      <td>TCK</td>
    </tr>
  </tbody>
</table>

<p><strong>Note</strong>: We are not <strong>required</strong> to use the labeled JTAG pins on the PiFex for JTAG operations, they are configurable via OpenOCD.</p>

<p>So&nbsp;now&nbsp;that we know what the pins are, we need to use them to access the test access port (TAP) on the device. There is only one problem: we know our pins, but now we need to figure out how&nbsp;to actually use them. We can now write to the Instruction Register (IR) and Data Registers (DR), but without knowing <strong>what</strong> to write to them, knowing the JTAG pinout is largely useless. Before we move forward, we need to figure out two things:</p>

<ol>
  <li>What type of CPU is this?</li>
  <li>Can we use any open-source tools to interact with it?</li>
</ol>

<p>To determine what type of CPU we’re dealing with, we can start with the ID. We can extract this via a tool called UrJTAG.</p>

<h2 id="urjtag-for-reverse-engineers">UrJTAG for Reverse Engineers</h2>

<p><a href="http://urjtag.org/">UrJTAG</a> is an open-source tool designed for performing low-level JTAG operations. This tool allows one to programmatically read and write the instruction register and corresponding data registers when connected to a JTAG TAP. It&nbsp;was originally&nbsp;designed to enable developers to use other JTAG tooling besides those provided by the original component manufacturer. Because of this tool’s low-level instrumentation and introspection, it is also beneficial to us as reverse engineers when examining a new TAP.&nbsp;</p>

<div><pre><code>pi@voidstar:~/pifex/software/urjtag-2021.03 $ sudo ./src/apps/jtag/jtag
UrJTAG 2021.03 #
Copyright (C) 2002, 2003 ETC s.r.o.
Copyright (C) 2007, 2008, 2009 Kolja Waschk and the respective authors
UrJTAG is free software, covered by the GNU General Public License, and you are
welcome to change it&nbsp;and/or&nbsp;distribute copies of it under certain conditions.
There is no warranty for UrJTAG.
warning:&nbsp;UrJTAG may damage your hardware!
Type "quit" to exit, "help" for help.
jtag&gt; cable gpio tck=10 tdi=9 tms=14 tdo=15
Initializing GPIO JTAG Chain
jtag&gt; idcode
Reading 0 bytes of idcode
Read 10110001(0xb1) 00110100(0x34) 00000100(0x04) 00010000(0x10) 00000000(0x00) 00000000(0x00) 00000000(0x00) 00000000(0x00)
jtag&gt; detect
IR length: 4
Chain length: 1
Device Id: 00010000000001000011010010110001 (0x100434B1)
&nbsp;&nbsp;Unknown manufacturer! (01001011000) (/usr/local/share/urjtag/MANUFACTURERS)
jtag&gt; discover
Detecting IR length ... 4
Detecting DR length for IR 1111 ... 1
Detecting DR length for IR 0000 ... -1
Detecting DR length for IR 0001 ... warning: TDO seems to&nbsp;be stuck&nbsp;at 0
-1
Detecting DR length for IR 0010 ... 1
Detecting DR length for IR 0011 ... 1
Detecting DR length for IR 0100 ... 1
Detecting DR length for IR 0101 ... 1
Detecting DR length for IR 0110 ... 1
Detecting DR length for IR 0111 ... 1
Detecting DR length for IR 1000 ... 4
Detecting DR length for IR 1001 ... 4
Detecting DR length for IR 1010 ... 32
Detecting DR length for IR 1011 ... 32
Detecting DR length for IR 1100 ... 32
Detecting DR length for IR 1101 ... 1
Detecting DR length for IR 1110 ... 1
jtag&gt;
</code></pre></div>

<p>Using the data that we gathered from our previous scans, we can set up our cable in UrJTAG as follows:</p>

<div><pre><code>cable gpio tck=10 tdi=9 tms=14 tdo=15
</code></pre></div>

<p>This&nbsp;tells UrJTAG that we&nbsp;are connected&nbsp;to our target via GPIO pins on a Linux device; we then follow that with GPIO pin assignments for each JTAG signal. After defining our cable, we can run the <code>detect</code>,&nbsp;<code>idcode</code>,&nbsp;and <code>discover</code> commands, which will attempt to learn more about the TAP that it is connected to, resulting in the output above.</p>

<p>After running&nbsp;a UrJTAG&nbsp;scan, we now know the following:</p>

<ul>
  <li>How many available DRs are present</li>
  <li>The width of all of the available&nbsp;DRs</li>
  <li>Confirmation of the CPU ID</li>
  <li>Confirmation of the JTAG pinout</li>
</ul>

<p>This is a lot of great information that we did not have at the beginning of this post, but what can we do with it? In order to read memory, set breakpoints, etc., we need to know more about how to interact with these registers. Without a datasheet, this is a difficult task. However, there are other open-source tools that we can leverage before attempting <a href="https://fahrplan.events.ccc.de/congress/2009/Fahrplan/attachments/1435_JTAG.pdf">black box reverse engineering of the JTAG TAP</a>.</p>

<h2 id="openocd-for-reverse-engineers">OpenOCD for Reverse Engineers</h2>

<p>Armed with this information, we can search the ID and determine that this chip uses the ARCompact architecture, and if we check the configuration files for OpenOCD, we can see this ID code in the following files:</p>

<div><pre><code>pi@voidstar:~/pifex/software/openocd/tcl/cpu/arc <span>$ </span><span>ls
</span>common.tcl em.tcl&nbsp;&nbsp;hs.tcl&nbsp;&nbsp;v2.tcl
</code></pre></div>

<p>Let’s see what CPUs reference these files, this will give us a better understanding of how to write a generic OpenOCD config file for an ARCompact target.&nbsp;</p>

<div><pre><code>pi@voidstar:~/pifex/software/openocd/tcl <span>$ </span><span>grep</span> <span>-r</span> <span>"arc/common"</span> <span>*</span>
cpu/arc/v2.tcl:source&nbsp;[find cpu/arc/common.tcl]
pi@voidstar:~/pifex/software/openocd/tcl <span>$ </span><span>grep</span> <span>-r</span> <span>"arc/v2"</span> <span>*</span>
cpu/arc/em.tcl:source&nbsp;[find cpu/arc/v2.tcl]
cpu/arc/hs.tcl:source&nbsp;[find cpu/arc/v2.tcl]
pi@voidstar:~/pifex/software/openocd/tcl <span>$ </span><span>grep</span> <span>-r</span> <span>"arc/hs"</span> <span>*</span>
target/snps_hsdk.cfg:source&nbsp;[find cpu/arc/hs.tcl]
target/snps_hsdk_4xd.cfg:source&nbsp;[find cpu/arc/hs.tcl]
pi@voidstar:~/pifex/software/openocd/tcl <span>$ </span><span>grep</span> <span>-r</span> <span>"arc/em"</span> <span>*</span>
target/snps_em_sk_fpga.cfg:source&nbsp;[find cpu/arc/em.tcl]
pi@voidstar:~/pifex/software/openocd/tcl <span>$</span>
</code></pre></div>

<p>It looks like there is a few target file that uses these config files:</p>

<ul>
  <li><code>snps_hsdk</code></li>
  <li><code>snps_hsdk_4xd</code></li>
  <li><code>snps_em_sk_fpga</code></li>
</ul>

<p>Let’s do one more quick search before trying to write our&nbsp;own&nbsp;config file; if we search for the above config files, we find the following:</p>

<div><pre><code>pi@voidstar:~/pifex/software/openocd/tcl/board <span>$ </span><span>ls</span> <span>-lathr</span>&nbsp;<span>*</span>snps<span>*</span>
<span>-rw-r--r--</span> 1 pi pi 411 May 4 18:20 snps_hsdk_4xd.cfg
<span>-rw-r--r--</span> 1 pi pi 416 May 4 18:20 snps_hsdk.cfg
<span>-rw-r--r--</span> 1 pi pi 615 May 4 18:20 snps_em_sk_v2.2.cfg
<span>-rw-r--r--</span> 1 pi pi 659 May 4 18:20 snps_em_sk_v2.1.cfg
<span>-rw-r--r--</span> 1 pi pi 555 May 4 18:20 snps_em_sk_v1.cfg
<span>-rw-r--r--</span> 1 pi pi 612 May 4 18:20 snps_em_sk.cfg
</code></pre></div>

<p>All of&nbsp;these config files are very straightforward and essentially import one of the three files&nbsp;located&nbsp;in the <code>target</code> folder.&nbsp;Taking some basic information from the target&nbsp;folder&nbsp;we will construct our own OpenOCD as shown below:</p>

<div><pre><code>source&nbsp;[find cpu/arc/hs.tcl]
transport select jtag
# We don't know much about this CPU at the moment, until&nbsp;we&nbsp;do&nbsp;we'll assume that
#&nbsp;it&nbsp;has one core that we will index at 0 and that the&nbsp;dbg
set _coreid 0
set _dbgbase 0
# CHIPNAME will be used to choose core family (600, 700 or EM). As far as
# OpenOCD is concerned EM and HS are identical.
set&nbsp;_CHIPNAME arc-em
set _TARGETNAME $_CHIPNAME.cpu
# Create the TAP using the information we extracted via UrJTAG and the IDCODE scan
jtag newtap $_CHIPNAME cpu -irlen 4 -ircapture 0x1 -expected-id 0x100434b1
# OpenOCD requires us to create a target for debugging the target; most of the&nbsp;
# provided arguments are variable names that we've already set up; however, we must&nbsp;
# specify the architecture; in this case we'll use ARCv2, the assumed architecture of&nbsp;
# this CPU
target create $_TARGETNAME arcv2 -chain-position $_TARGETNAME
# Next we configure our initial guesses for the coreid and base address for debug regions of memory
# We're not using these at the moment, but perhaps after further reversing, we'll learn more
# and can come back and update them
$_TARGETNAME configure -coreid 0
$_TARGETNAME configure -dbgbase 0
# Here, we are defining what to do when a reset event occurs
$_TARGETNAME configure -event reset-assert "arc_hs_reset $_TARGETNAME"
#&nbsp;The following two lines were pulled&nbsp;from the ARC-specific examples in OpenOCD&nbsp;
# These seem to be used across all ARCompact variants supported by OpenOCD
arc_hs_init_regs
$_TARGETNAME arc cache l2 auto 1
</code></pre></div>

<p>This file will let OpenOCD know what pins to use on the Raspberry Pi and the specifics&nbsp;about&nbsp;our target CPU. The following config file can be used to configure the Raspberry Pi GPIO pins.</p>

<div><pre><code>source [interface/raspberrypi-native.cfg]

transport select jtag

adapter gpio tck -chip 0 10
adapter gpio tms -chip 0 14
adapter gpio tdi -chip 0 9
adapter gpio tdo -chip 0 15

adapter speed 100
</code></pre></div>

<p>If we run OpenOCD using these config files as an argument, we see the following:</p>

<div><pre><code>pi@voidstar:~/pifex/ssd-example <span>$ </span>openocd <span>-f</span> raspberrypi-io.cfg <span>-f</span> ssd_example.cfg
Open On-Chip Debugger 0.12.0+dev-01573-gbc9ca5f4a <span>(</span>2024-05-04-18:24<span>)</span>
Licensed under GNU GPL v2
For bug reports, <span>read</span>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;http://openocd.org/doc/doxygen/bugs.html
adapter speed: 100 kHz
Warn : Transport <span>"jtag"</span> was already selected
Info : target has l2 cache enabled is enabled
Info : Listening on port 6666 <span>for </span>tcl connections
Info : Listening on port 4444 <span>for </span>telnet connections
Info : BCM2835 GPIO JTAG/SWD bitbang driver
Info : clock speed 100 kHz
Info : JTAG tap: arc-em.cpu tap/device found: 0x100434b1 <span>(</span>mfg: 0x258 <span>(</span>ARC International<span>)</span>, part: 0x0043, ver: 0x1<span>)</span>
Info : <span>[</span>arc-em.cpu] Examination succeed
Info : starting gdb server <span>for </span>arc-em.cpu on 3333
Info : Listening on port 3333 <span>for </span>gdb connections
</code></pre></div>

<p>Success! It looks like we have connected to the JTAG TAP of this SSD using OpenOCD. Next, we will use this to read memory and single-step through the running firmware on the SSD itself.&nbsp;</p>

<h3 id="reading-memory-with-openocd">Reading Memory with OpenOCD</h3>

<p>Now that we have a working OpenOCD connection, we can read memory using the <code>mdw</code> and <code>dump_image</code> commands. We will dump a small region of memory as a test:</p>

<div><pre><code>pi@voidstar:~ $ telnet localhost 4444
Trying ::1...
Trying 127.0.0.1...
Connected&nbsp;to localhost.
Escape character is '^]'.
Open On-Chip Debugger
&gt; mdw 0 100
0x00000000: 0000214a 0000224a 0000234a 0000244a 0000254a 0000264a 0000274a 1000204a
0x00000020: 1000214a 1000224a 1000234a 1000244a 1000254a 1000264a 1000274a 2000204a
0x00000040: 2000214a 2000224a 2000234a 2000244a 2000254a 2000264a 2000274a 3000204a
0x00000060: 3000214a 0000204a 3f80240a 80001000 3f80220a 26001000 3f80230a 80001000
0x00000080: 3000254a 3000264a 3000274a 7080266b 00000000 70c0266b 00000000 0f802020
0x000000a0: 05b00000 00402069 7000264a 7000264a 7000264a ffcf07f1 500071cf 1154a000
0x000000c0: 70cf0802 05f81000 00a01800 08001000 00201954 78e07ee0 71cfc5e1 00005000
0x000000e0: 0880110c 500072cf b8e4a000 11dcf47f b8810880 002219dc 08001204 1a04b880
0x00000100: db000020 00e01a4c 0fa01a44 80000000 0fff208a 00201a58 08001268 00201a68
0x00000120: 08001274 0fc32086 0a822085 00201a74 500075cf 1517a0a8 20861880 b88000fc
0x00000140: 10221d17 0800125c 0f802004 1feefff8 00201a5c 0800125c 0f802004 1fef8ff8
0x00000160: 1a5cb89c d8010020 0022190d 08001204 1a04b881 15140020 b8841880 10221d14
0x00000180: 500071cf 110d07f0 b8840880 0022190d
&gt; dump_image
dump_image filename address size
&gt; dump_image mem-test.bin 0 0x100000
&gt; dumped 1048576 bytes in 264.823212s (3.867 KiB/s)
</code></pre></div>

<p>Next, we’ll want to review this memory dump to make sure that it’s accurate.&nbsp;This&nbsp;creates an interesting problem: we don’t know what the memory contents will look like at address <code>0</code>, especially since we don’t have a datasheet or an example firmware image. In this case, we will start by running strings on the resulting binary; some of these results can&nbsp;be seen&nbsp;below:</p>

<div><pre><code>pi@voidstar:~/pifex/ssd-example $ strings mem-test.bin | less
02023042MS2295CAX--XYYYYYYYY
SM2259PARA
SM2259BT
xSM2259BTDS
SM2259AC20200324
L^r|
%`)$5a94
SMISSDRetryTable
Device_FW_Authentication
xFW_MAC_Key
SM2259ROMCodeTagZZZZ
</code></pre></div>

<p>We’ve got human-readable strings, which is a great sign!&nbsp;We also have the&nbsp;part number for the CPU&nbsp;in these strings, which leads me to believe we’ve correctly extracted this memory region via OpenOCD.&nbsp;However, we need to learn more about this processor and what areas&nbsp;might&nbsp;interest us.&nbsp;We can figure this out using OpenOCD to attach to the target CPU via GDB.</p>

<h3 id="debugging-with-openocd">Debugging with OpenOCD</h3>

<p>Now that we have OpenOCD connected to our target, we can attempt to debug the target via GDB.&nbsp;However, this&nbsp;does not come without&nbsp;some strings attached; we will need to compile a version of GDB capable of targeting the ARCompact architecture.&nbsp;Luckily for us, the good folks over at Synopsis have released a port of binutils for the ARCompact architecture. We can clone the repository <a href="https://github.com/foss-for-synopsys-dwc-arc-processors/binutils-gdb">here</a> and build it on the Raspberry Pi (<strong>Note</strong>: see the appendix for instructions on how to build this software).</p>

<p>After building GDB and attempting to connect to the GDB server presented by OpenOCD, we see the following:</p>
<div><pre><code>(gdb) x/10i $pc
=&gt; 0x22b0: brne_s r0,0,10 ;0x22ba
&nbsp; &nbsp;0x22b2: ldb.di r2,[r18,3]
&nbsp; &nbsp;0x22b6: btst_s r2,0x7
&nbsp; &nbsp;0x22b8: beq_s -282 ;0x219e
&nbsp; &nbsp;0x22ba: ldb r4,[0x852]
&nbsp; &nbsp;0x22c2: bbit0.t r4,0,18 ;0x22d2
&nbsp; &nbsp;0x22c6: ldb.di r2,[r13,113]
&nbsp; &nbsp;0x22ca: bset_s r2,r2,0
&nbsp; &nbsp;0x22cc: stb.di r2,[r13,113]
&nbsp; &nbsp;0x22d0: b_s 12 ;0x22dc
(gdb) i r
r0 0x0 0
r1 0x101 257
r2 0x10004aac 268454572
r3 0x0 0
r4 0x100014b6 268440758
r5 0x50100000 1343225856
r6 0x50100000 1343225856
r7 0x10 16
r8 0x0 0
r9 0x0 0
r10 0x0 0
r11 0x4 4
r12 0x0 0
r13 0x50000000 1342177280
r14 0x0 0
r15 0x0 0
r16 0x5000a000 1342218240
</code></pre></div>

<p>Success! Using OpenOCD and GDB, we are able to single-step through the firmware and read register values. These register values tell us more about potential memory regions of interest that we can read out, specifically <code>0x50000000</code> and <code>0x10000000</code>. As a final test, we will load the area of memory we extracted initially into Ghidra and see if the instructions match what we see in GDB.&nbsp;&nbsp;</p>

<h3 id="loading-the-firmware-into-ghidra">Loading the Firmware into Ghidra</h3>

<p>While the current Ghidra release does not support ARCompact, a wonderful fork is being maintained <a href="https://github.com/niooss-ledger/ghidra">here</a>. We can build this and use it to analyze our firmware image.&nbsp;</p>

<p>If we look at offset <code>0</code> in the firmware image, we have what appears to be an interrupt vector table of some sort:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/ivt.png" alt=""></p>

<p>If we look a little further at the image, we can see that there are some branch instructions for a region that&nbsp;we’ve not extracted yet.&nbsp;We also see that the two areas we previously identified (<code>0x50000000</code> and <code>0x10000000</code>) are&nbsp;being referenced&nbsp;as well. These are likely internal/external SRAM regions, while the area starting around <code>0x4007000</code> appears to be used as code.</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/interesting.png" alt=""></p>

<p>Let’s&nbsp;try to&nbsp;extract that region, load it into our Ghidra database, and see if the results make sense.&nbsp;First, we’ll dump the region out using OpenOCD, as shown below:</p>

<div><pre><code>dump_image 0x40070000.bin 0x40070000 0x100000
</code></pre></div>

<p>We can then import it into our Ghidra database, resulting in the following:</p>

<p><img src="https://voidstarsec.com/blog/assets/images/jtag-pifex/imported_new_region.jpg" alt=""></p>

<p><strong>Success:</strong>&nbsp;It looks like we have code in this region, and it disassembles properly.&nbsp;</p>

<p>From here, we now have the following primitives available to us on the SSD:</p>

<ul>
  <li>Memory R/W</li>
  <li>Control Flow Monitoring / Modifications</li>
  <li>Register Reads/Writes</li>
</ul>

<p>This puts one in a perfect position to do more software research, look for bugs or errors in their code, or even attempt to modify the firmware or reverse engineer the update process!</p>
<h2 id="conclusion">Conclusion</h2>

<p>If you’ve read this far, thank you for taking the time to read it all. This probably should have been two separate posts!</p>

<p>With this blog post, we introduced the PiFex hardware and software tools. These tools utilize open-source software and commercial hardware to aid in embedded device assessments. We then demonstrated how to use these tools to discover and enumerate an undocumented JTAG TAP on an SSD. Using this TAP, we were able to read memory and control execution on the target, giving us full control over the device.&nbsp;</p>

<p>If you want to stay up to date on the official release, sign up for our mailing list <a href="http://eepurl.com/hSl31f">here</a>, or you can order one <a href="https://voidmalt.gumroad.com/l/pifex">here</a></p>

<p>If you’re interested in a <a href="https://voidstarsec.com/hhb.html">private training</a> at your organization, please don’t hesitate to <a href="https://voidstarsec.com/#contact">contact us</a>. We also have our only public training available this year at <a href="https://ringzer0.training/doubledown24-hardware-hacking-bootcamp/">RingZer0 DoubleDown Vegas</a></p>

<p>A big thanks goes out to Nash Reilly for his help and review of the initial hardware design; you can check out his blog <a href="https://cushychicken.github.io/">here</a> and his other two job sites below:</p>

<ul>
  <li><a href="https://fpgajobs.com/">fpgajobs.com</a></li>
  <li><a href="https://firmwarejobs.com/">firmwarejobs.com</a></li>
</ul>

<h2 id="appendix">Appendix</h2>

<h2 id="building-binutils">Building Binutils</h2>

<div><pre><code>./configure --target=arc-elf32 --disable-werror
make

</code></pre></div>


        
          <p>©&nbsp;2024&nbsp;VoidStar Security LLC
          &nbsp;
          •
          &nbsp;</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A fourteen-day free trial ain’t gonna cut it (327 pts)]]></title>
            <link>https://keygen.sh/blog/your-14-day-free-trial-aint-gonna-cut-it/</link>
            <guid>40274662</guid>
            <pubDate>Mon, 06 May 2024 13:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keygen.sh/blog/your-14-day-free-trial-aint-gonna-cut-it/">https://keygen.sh/blog/your-14-day-free-trial-aint-gonna-cut-it/</a>, See on <a href="https://news.ycombinator.com/item?id=40274662">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I've been working on Keygen for coming up on 8 years now (May 22nd, to <a href="https://github.com/keygen-sh/keygen-api/commit/84e8ccc35ea4accaf45d8bf529ba554650465644">be exact</a>).
In that time, it's an understatement to say that I've learned a lot. One of the things I've
learned is that a lot of founders, myself included, ignore some pretty crucial business
metrics. One of those metrics that we'll be talking about today is <strong>time-to-convert</strong>.</p>
<p>When I first started Keygen, I did what everybody probably does and set up a 14-day free
trial. What I quickly found is that it's very hard for a potential customer to integrate
a software licensing API into their entire stack within a 14 days timeframe.</p>
<p>So I started offering free trial extensions. I'd push this on my pricing page, in onboarding
emails, in follow up emails, etc. I wanted to make potentional customers aware that
<em>they had more time.</em></p>
<p>What I found over the next couple years was that the majority of converting customers had
asked for a free trial extension. And out those that <em>did</em> and those that <em>didn't</em>, my
conversion rate was higher when they <em>did</em> ask for one.</p>
<p>Was there a reason <em>why</em> this was the case? Possibly!</p>
<p>When I extended a trial, I would require the potential customer to put a card on file
before I extended their trial. So we go from free trial without a card, to free trial
with a card. Much better.</p>
<p>You may be thinking — what does this have to do with time-to-convert?</p>
<p>We'll get there.</p>
<p>Anyways — after discovering that free trial extensions increase conversion rate, I started
personally sending emails to potentional customers that were nearing their trial's end to
offer a trial extension. This was a pretty big success.</p>
<p>So much of a success, actually, that I stopped being so strict about requiring a card be
put on file — mainly out of laziness — because it was such an annoying back-and-forth
step to do before extending a potential customer's trial.</p>
<p>Unintuitively to what I learned prior, this didn't hurt conversion rate (so that potential
reason for a higher conversion rate was moot).</p>
<p>I chugged along manually extending trials for a couple more years.</p>
<p>Then <a href="https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/">I got fed up with limited metrics from Baremetrics and replaced it with a Rake task</a>.
I no longer use that Rake task (it didn't scale as my Stripe customer count grew), but through
that, I learned about my <strong>time-to-convert</strong>, which is a crucial business metric that remains
unknown to many, many founders (myself included at the time).</p>
<p>What is time-to-convert? It's the time it takes from a customer signing up to a customer
paying you. Pretty simple.</p>
<p>(For brevity, I'll refer to this metric as <strong>TTC</strong>.)</p>
<p>So why was this such a big deal?</p>
<p>Well, because my 14-day free trial didn't line up with the time it takes a customer to realize
value from Keygen — to get to that fork in the road where they can decide "is this worth
my money?"</p>
<p>I gave them 14 days to get to that fork.</p>
<p>But my p50 TTC is <em>41 days.</em> My p90, 130 days; p95, 198; p99, 290.</p>
<p><small>
If you want to calculate yours <a href="https://stripe.com/sigma">using Stripe Sigma</a>, try this query:
</small></p>
<pre data-torchlight-processed="3449c9e5e332f1dbb81505cd739fbf3f"><code><p><span>SELECT</span></p><p><span>  </span><span>format</span><span>(</span><span>'%d days'</span><span>, approx_percentile(time_to_convert, </span><span>0</span><span>.</span><span>5</span><span>))  </span><span>AS</span><span> time_to_convert_p50,</span></p><p><span>  </span><span>format</span><span>(</span><span>'%d days'</span><span>, approx_percentile(time_to_convert, </span><span>0</span><span>.</span><span>9</span><span>))  </span><span>AS</span><span> time_to_convert_p90,</span></p><p><span>  </span><span>format</span><span>(</span><span>'%d days'</span><span>, approx_percentile(time_to_convert, </span><span>0</span><span>.</span><span>95</span><span>)) </span><span>AS</span><span> time_to_convert_p95,</span></p><p><span>  </span><span>format</span><span>(</span><span>'%d days'</span><span>, approx_percentile(time_to_convert, </span><span>0</span><span>.</span><span>99</span><span>)) </span><span>AS</span><span> time_to_convert_p99</span></p><p><span>FROM</span><span> (</span></p><p><span>  </span><span>SELECT</span></p><p><span>    DATE_DIFF(</span><span>'day'</span><span>, </span><span>MIN</span><span>(</span><span>customers</span><span>.</span><span>created</span><span>), </span><span>MIN</span><span>(</span><span>charges</span><span>.</span><span>created</span><span>)) </span><span>AS</span><span> time_to_convert,</span></p><p><span>    </span><span>customers</span><span>.</span><span>id</span></p><p><span>  </span><span>FROM</span></p><p><span>    customers</span></p><p><span>    </span><span>INNER JOIN</span><span> charges </span><span>ON</span><span> </span><span>charges</span><span>.</span><span>customer_id</span><span> </span><span>=</span><span> </span><span>customers</span><span>.</span><span>id</span></p><p><span>  </span><span>WHERE</span></p><p><span>    </span><span>customers</span><span>.</span><span>created</span><span> </span><span>BETWEEN</span><span> DATE_ADD(</span><span>'year'</span><span>, </span><span>-</span><span>1</span><span>, CURRENT_DATE) </span><span>AND</span><span> CURRENT_DATE</span></p><p><span>    </span><span>AND</span><span> </span><span>charges</span><span>.</span><span>paid</span><span> </span><span>=</span><span> TRUE</span></p><p><span>    </span><span>AND</span><span> </span><span>charges</span><span>.</span><span>amount</span><span> </span><span>&gt;</span><span> </span><span>0</span></p><p><span>  </span><span>GROUP BY</span></p><p><span>    </span><span>customers</span><span>.</span><span>id</span></p><p><span>)</span></p></code></pre>
<p>As I mentioned, I realized that what I was <em>really doing</em> was asking people to sign up
<em>now</em> and complete a proof-of-concept integration <em>in 14 days.</em> This includes reading
documentation, onboarding, and planning and executing a proof-of-concept (PoC).</p>
<p>But my median TTC is 41 days!</p>
<p>That just doesn't work.</p>
<p>Understanding and integrating a new API can be a lot. On top of other projects, it can
end up being impossible to do in 14 days, from first discovery to being integrated
(or at least with a PoC in-hand).</p>
<p>What I was really asking potential customers to do was <em>wait</em>.</p>
<p>Wait until they're ready to start understanding the API.</p>
<p>Wait until they're ready to go through onboarding.</p>
<p>Wait until the PoC is planned.</p>
<p>Wait until dev is freed up.</p>
<p>Wait. Wait. Wait.</p>
<p>What ends up happening is that people get busy and they end up seeing that 14 day
deadline, determine that they're not ready yet, so they bounce until they <em>are</em>
ready, but then <em>they never come back.</em></p>
<p>I decided that I needed to remove that friction. I wanted to capture these leads
as soon as they decide Keygen may be the solution for them. So ultimately, I can
start nurturing these leads.</p>
<p>So I did what every bootstrapper tells you to never do…</p>
<p>I added an unlimited trial, a.k.a. <em>a free tier.</em></p>
<p>What happened next?</p>
<p>Overall sign ups increased, of course, as it always does with a free tier. But by
segmenting out users that stay on the free tier, I found paid sign ups also increased,
with conversion rate staying steady, but now with no manual work. I say that's a
win-win.</p>
<p>So, what's your TTC?</p>
<p>Until next time.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stack Overflow and OpenAI are partnering (179 pts)]]></title>
            <link>https://stackoverflow.co/company/press/archive/openai-partnership/</link>
            <guid>40274371</guid>
            <pubDate>Mon, 06 May 2024 13:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackoverflow.co/company/press/archive/openai-partnership/">https://stackoverflow.co/company/press/archive/openai-partnership/</a>, See on <a href="https://news.ycombinator.com/item?id=40274371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--[--><p><strong>NEW YORK CITY, NY and SAN FRANCISCO, CA</strong>,<strong>– May 6, 2024</strong> - Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development. </p><p>OpenAI and Stack Overflow are coming together via OverflowAPI access to provide OpenAI users and customers with the accurate and vetted data foundation that AI tools need to quickly find a solution to a problem so that technologists can stay focused on priority tasks. OpenAI will also surface validated technical knowledge from Stack Overflow directly into ChatGPT, giving users easy access to trusted, attributed, accurate, and highly technical knowledge and code backed by the millions of developers that have contributed to the Stack Overflow platform for 15 years.As part of this collaboration:</p><ul><li>OpenAI will utilize Stack Overflow’s OverflowAPI product and collaborate with Stack Overflow to improve model performance for developers who use their products. This integration will help OpenAI improve its AI models using enhanced content and feedback from the Stack Overflow community and provide attribution to the Stack Overflow community within ChatGPT to foster deeper engagement with content.</li><li>Stack Overflow will utilize OpenAI models as part of their development of <a href="https://stackoverflow.co/teams/ai/">OverflowAI</a> and work with OpenAI to leverage insights from internal testing to maximize the performance of OpenAI models. OpenAI’s partnership with Stack Overflow will help further drive its mission to empower the world to develop technology through collective knowledge, as Stack Overflow will be able to create better products that benefit the Stack Exchange community’s health, growth, and engagement.</li></ul><p>“Learning from as many languages, cultures, subjects, and industries as possible ensures that our models can serve everyone. The developer community is particularly important to both of us. Our deep partnership with Stack Overflow will help us enhance the user and developer experience on both our platforms,” said Brad Lightcap, COO at OpenAI.</p><p>“Stack Overflow is the world’s largest developer community, with more than 59 million questions and answers. Through this industry-leading partnership with OpenAI, we strive to redefine the developer experience, fostering efficiency and collaboration through the power of community, best-in-class data, and AI experiences,” said Prashanth Chandrasekar, CEO of Stack Overflow. “Our goal with OverflowAPI, and our work to advance the era of socially responsible AI, is to set new standards with vetted, trusted, and accurate data that will be the foundation on which technology solutions are built and delivered to our user.”</p><p>The first set of new integrations and capabilities between Stack Overflow and OpenAI will be available in the first half of 2024. Beyond this, OpenAI’s partnership with Stack Overflow will enable Stack Overflow to continue to reinvest in community-driven features. To learn more about Stack Overflow’s API solution and partnerships, visit <a href="https://stackoverflow.co/api-solutions/">stackoverflow.co/api-solutions/</a></p><h2>About Stack Overflow</h2><p>Across its public and private platforms, Stack Overflow empowers developer communities to discover the information, answers, and learning opportunities they need – when they need them. Millions of the world's developers and technologists visit Stack Overflow to ask questions, learn, and share technical knowledge, making it one of the most popular websites in the world. Stack Overflow’s market-leading knowledge-sharing and collaboration platform, Stack Overflow for Teams, helps more than 15,000 organizations distribute knowledge, increase efficiency, and innovate faster.</p><h2>About OpenAI</h2><p>OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.</p><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I think about debt (177 pts)]]></title>
            <link>https://collabfund.com/blog/how-i-think-about-debt/</link>
            <guid>40274158</guid>
            <pubDate>Mon, 06 May 2024 13:04:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://collabfund.com/blog/how-i-think-about-debt/">https://collabfund.com/blog/how-i-think-about-debt/</a>, See on <a href="https://news.ycombinator.com/item?id=40274158">Hacker News</a></p>
<div id="readability-page-1" class="page">
     <header data-header="">
  <nav>
    
    <a href="https://collabfund.com/blog">Blog</a>

    <ul id="desktop-nav">
      
      <li>
        <a href="https://collabfund.com/about/">About</a>
      </li>
      
      <li>
        <a href="https://collabfund.com/portfolio">Portfolio</a>
      </li>
      
      <li>
        <a href="https://collabfund.com/shared-future/">Shared Future</a>
      </li>
      
      <li>
        <a href="https://collabfund.com/sos/">SOS</a>
      </li>
      
      <li>
        <a href="https://collabfund.com/investorportal/">LP</a>
      </li>
      
      <li>
        <a href="https://collabfund.com/blog/">Blog</a>
      </li>
      
    </ul>
    
    

    
    
    
    
  </nav>
</header>  <article>
  


  <div>
          <h2>
            
              How I Think About Debt
            
          </h2>
          
        </div>


  
  
  
    
  
  
  
  
  
  

  <section>
    <p>Japan has 140 businesses that are at least 500 years old. A few <a href="https://www.nytimes.com/2020/12/02/business/japan-old-companies.html">claim</a> to have been operating continuously for more than 1,000 years.</p>

<p>It’s astounding to think what these businesses have endured – dozens of wars, emperors, catastrophic earthquakes, tsunamis, depressions, on and on, endlessly. And yet they keep selling, generation after generation.</p>

<p>These ultra-durable businesses are called “shinise,” and studies of them show they tend to share a common characteristic: they hold tons of cash, and no debt. That’s part of how they endure centuries of constant calamities.</p>

<p>I love the quote from author Kent Nerburn that, “Debt defines your future, and when your future is defined, hope begins to die.”</p>

<p>Not only does hope begin to die, but the number of outcomes you can endure does, too.</p>

<p>Let’s say this represents volatility over your life. Not just market volatility, but life world and life volatility: recessions, wars, divorces, illness, moves, floods, changes of heart, etc.</p>

<p><img src="https://collabfund.com/uploads/Screenshot%202024-04-30%20at%2012.17.40%E2%80%AFPM.png" alt="Screenshot 2024-04-30 at 12.17.40 PM.png"></p>

<p>With no debt, the number of volatile events you can withstand throughout life might fall within a range that looks like this:</p>

<p><img src="https://collabfund.com/uploads/Screenshot%202024-04-30%20at%2012.08.17%E2%80%AFPM.png" alt="Screenshot 2024-04-30 at 12.08.17 PM.png"></p>

<p>A few extreme events might do you in, but you’re pretty durable.</p>

<p>With more debt, the range of what you can endure shrinks:</p>

<p><img src="https://collabfund.com/uploads/Screenshot%202024-04-30%20at%2012.08.53%E2%80%AFPM.png" alt="Screenshot 2024-04-30 at 12.08.53 PM.png"></p>

<p>And with tons of debt, it tightens even more:</p>

<p><img src="https://collabfund.com/uploads/Screenshot%202024-04-30%20at%2012.09.26%E2%80%AFPM.png" alt="Screenshot 2024-04-30 at 12.09.26 PM.png"></p>

<p>I think this is the most practical way to think about debt: <strong>As debt increases, you narrow the range of outcomes you can endure in life.</strong></p>

<p>That’s so simple. But it’s different from how debt is typically viewed, which is a tool to pull forward demand and leverage assets, where the only downside is the cost of capital (the interest rate).</p>

<p>Two things are important when you view debt as a narrowing of endurable outcomes.</p>

<p>One is you start to ponder how common volatility is.</p>

<p>I hope to be around for another 50 years. What are the odds that during those 50 years I will experience one or more of the following: Wars, recessions, terrorist attacks, pandemics, bad political decisions, family emergencies, unforeseen health crises, career transitions, wayward children, and other mishaps?</p>

<p>One-hundred percent. <em>The odds are 100%</em>.</p>

<p>When you think of it like that, you take debt’s narrowing of survivable outcomes seriously.</p>

<p>The other is you think about the kinds of volatile events that could do you in.</p>

<p>Financial volatility is an obvious one – you find yourself unable to make your debt payments. But there’s also psychological volatility, where for whatever reason you can’t mentally endure your job any longer. There’s family volatility, which can be anything from divorce to caring for a relative. There’s child volatility, which could fill a book. Health volatility, political volatility, on and on. The world’s a wild place.</p>

<p>I’m not an anti-debt zealot. There’s a time and place, and used responsibly it’s a wonderful tool.</p>

<p>But once you view debt as narrowing what you can endure in a volatile world, you start to see it as a constraint on the asset that matters most: having options and flexibility.</p>

  </section>

  
  
  
      
  
  
</article>


  


  <!-- create 3 empty cards, data populated by JS -->
   


<div data-post-url="/blog/how-i-think-about-debt/">
        <h2>More from the blog…</h2>
      </div>

  

 
    
    

    
      

    
    
 
    
    
    
    
    
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alternative clouds are booming as companies seek cheaper access to GPUs (242 pts)]]></title>
            <link>https://techcrunch.com/2024/05/05/coreweaves-1-1b-raise-shows-the-market-for-alternative-clouds-is-booming/</link>
            <guid>40273651</guid>
            <pubDate>Mon, 06 May 2024 12:05:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/05/05/coreweaves-1-1b-raise-shows-the-market-for-alternative-clouds-is-booming/">https://techcrunch.com/2024/05/05/coreweaves-1-1b-raise-shows-the-market-for-alternative-clouds-is-booming/</a>, See on <a href="https://news.ycombinator.com/item?id=40273651">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">The appetite for alternative clouds has never been bigger.</p>
<p>Case in point: <a href="https://techcrunch.com/2023/08/03/coreweave-which-provides-cloud-infrastructure-for-ai-training-secures-2-3b-loan/">CoreWeave</a>, the GPU infrastructure provider that began life as a cryptocurrency mining operation, this week raised $1.1 billion in new funding from investors including Coatue, Fidelity and Altimeter Capital. The round brings its valuation to $19 billion post-money, and its total raised to $5 billion in debt and equity — a remarkable figure for a company that’s less than ten years old.</p>
<p>It’s not just CoreWeave.</p>
<p>Lambda Labs, which also offers an array of cloud-hosted GPU instances, in early April secured a “special purpose financing vehicle” of up to $500 million, months after closing a $320 million Series C round. The nonprofit Voltage Park, backed by crypto billionaire Jed McCaleb, last October <a href="https://techcrunch.com/2023/10/31/new-nonprofit-backed-by-crypto-billionaire-scores-ai-chips-worth-500m/">announced</a> that it’s investing $500 million in GPU-backed data centers. And <a href="https://techcrunch.com/2023/11/29/together-lands-102-5m-investment-to-grow-its-cloud-for-training-generative-ai/">Together AI</a>, a cloud GPU host that also conducts generative AI research, in March landed $106 million in a Salesforce-led round.</p>
<p>So why all the enthusiasm for — and cash pouring into — the alternative cloud space?</p>
<p>The answer, as you might expect, is generative AI.</p>
<p>As the generative AI boom times continue, so does the demand for the hardware to run and train generative AI models at scale. GPUs, architecturally, are the logical choice for training, fine-tuning and running models because they contain thousands of cores that can work in parallel to perform the linear algebra equations that make up generative models.</p>
<p>But installing GPUs is expensive. So most devs and organizations turn to the cloud instead.</p>
<p>Incumbents in the cloud computing space — Amazon Web Services (AWS), Google Cloud and Microsoft Azure — offer no shortage of GPU and specialty hardware instances optimized for generative AI workloads. But for at least some models and projects, alternative clouds can end up being cheaper — and delivering better availability.</p>
<p>On CoreWeave, renting an Nvidia A100 40GB — one popular choice for model training and inferencing — costs $2.39 per hour, which works out to $1,200 per month. On Azure, the same GPU costs $3.40 per hour, or $2,482 per month; on Google Cloud, it’s $3.67 per hour, or $2,682 per month.</p>
<p>Given generative AI workloads are usually performed on clusters of GPUs, the cost deltas quickly grow.</p>
<p>“Companies like CoreWeave participate in a market we call specialty ‘GPU as a service’ cloud providers,” Sid Nag, VP of cloud services and technologies at Gartner, told TechCrunch. “Given the high demand for GPUs, they offers an alternate to the hyperscalers, where they’ve taken Nvidia GPUs and provided another route to market and access to those GPUs.”</p>
<p>Nag points out that even some big tech firms have begun to lean on alternative cloud providers as they run up against compute capacity challenges.</p>
<p>Last June, CNBC <a href="https://www.cnbc.com/2023/06/01/microsoft-inks-deal-with-coreweave-to-meet-openai-cloud-demand.html">reported</a> that Microsoft had signed a multi-billion-dollar deal with CoreWeave to ensure that OpenAI, the maker of ChatGPT and a close Microsoft partner, would have adequate compute power to train its generative AI models. Nvidia, the furnisher of the bulk of CoreWeave’s chips, sees this as a desirable trend, perhaps for leverage reasons; it’s said to have given some alternative cloud providers <a href="https://www.theinformation.com/articles/why-nvidia-aids-cloud-rivals-of-aws-google-and-microsoft">preferential access</a> to its GPUs.</p>
<p>Lee Sustar, principal analyst at Forrester, sees cloud vendors like CoreWeave succeeding in part because they don’t have the infrastructure “baggage” that incumbent providers have to deal with.</p>
<p>“Given hyperscaler dominance of the overall public cloud market, which demands vast investments in infrastructure and range of services that make little or no revenue, challengers like CoreWeave have an opportunity to succeed with a focus on premium AI services without the burden of hypercaler-level investments overall,” he said.</p>
<p>But is this growth sustainable?</p>
<p>Sustar has his doubts. He believes that alternative cloud providers’ expansion will be conditioned by whether they can continue to bring GPUs online in high volume, and offer them at competitively low prices.</p>
<p>Competing on pricing might become challenging down the line as incumbents like Google, Microsoft and AWS ramp up investments in custom hardware to run and train models. Google offers its <a href="https://techcrunch.com/tag/tpus/">TPUs</a>; Microsoft recently unveiled two custom chips, <a href="https://techcrunch.com/2023/11/15/microsoft-looks-to-free-itself-from-gpu-shackles-by-designing-custom-ai-chips/">Azure Maia and Azure Cobalt</a>; and AWS has <a href="https://techcrunch.com/2023/11/28/amazon-unveils-new-chips-for-training-and-running-ai-models/">Trainium, Inferentia and Graviton</a>.</p>
<p>“Hypercalers will leverage their custom silicon to mitigate their dependencies on Nvidia, while Nvidia will look to CoreWeave and other GPU-centric AI clouds,” Sustar said.</p>
<p>Then there’s the fact that, while many generative AI workloads run best on GPUs, not all workloads need them — particularly if they’re aren’t time-sensitive. CPUs can run the necessary calculations, but typically slower than GPUs and custom hardware.</p>
<p>More existentially, there’s a threat that the generative AI bubble will burst, which would leave providers with mounds of GPUs and not nearly enough customers demanding them. But the future looks rosy in the short term, say Sustar and Nag, both of whom are expecting a steady stream of upstart clouds.</p>
<p>“GPU-oriented cloud startups will give [incumbents] plenty of competition, especially among customers who are already multi-cloud and can handle the complexity of management, security, risk and compliance across multiple clouds,” Sustar said. “<span>Those sorts of cloud customers are comfortable trying out a new AI cloud if it has credible leadership, solid financial backing and GPUs with no wait times.”</span></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NYU professors who defended vaping didn't disclose ties to Juul (293 pts)]]></title>
            <link>https://www.statnews.com/2024/05/06/juul-vaping-advocates-nyu-professors-non-disclosed-conflict-interest/</link>
            <guid>40273598</guid>
            <pubDate>Mon, 06 May 2024 12:01:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statnews.com/2024/05/06/juul-vaping-advocates-nyu-professors-non-disclosed-conflict-interest/">https://www.statnews.com/2024/05/06/juul-vaping-advocates-nyu-professors-non-disclosed-conflict-interest/</a>, See on <a href="https://news.ycombinator.com/item?id=40273598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<article>
			
<header>
	<div>
					<ul>
				<li><img width="80" height="80" src="https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-80x80.png" alt="Nicholas Florko" loading="lazy" sizes="(max-width: 80px) 100vw, 80px" srcset="https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-80x80.png 80w, https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-160x160.png 160w, https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small.png 300w"></li>			</ul>
			<p>May 6, 2024</p>	</div>
</header>
<section>
	<p><span><span>W</span></span>ASHINGTON – Two New York University professors collaborated directly with executives of the vaping company Juul without disclosing those relationships to academic journals or Congress, a STAT investigation reveals.</p>
<p>At the height of the youth vaping crisis, when many public health experts were calling for sweeping action that could upend the entire industry, David Abrams and Ray Niaura emerged as two authoritative voices willing to defend vaping — despite its growing popularity among youth — as an effective public health strategy to help adults cut back or quit smoking.</p>
<p>Abrams, a frequent commentator about vaping in the news media, including CBS This Morning, CNN, and The New Yorker, coordinated extensively with Juul on public messaging in 2017 and 2018, according to company emails. Abrams asked Juul officials for talking points, allowed company executives to review an academic article prior to publishing, and attended Juul scientific advisory board meetings, all without disclosing those connections to journal publishers or the public.</p>
		<div aria-labelledby="restricted-story-heading" aria-describedby="restricted-story-description" checked="false">
			<div>
				<p>STAT+ Exclusive Story</p>
				<p>Already have an account? <a href="https://www.statnews.com/login/" data-stat-login="" data-stat-paywall-cta="breaker login cta">Log in</a></p> 
			</div>
			<p><img src="https://www.statnews.com/wp-content/uploads/2022/02/stat_plus_hero_new-2048x502.png" alt="STAT+"></p><div>
				<p><span>
					<a href="https://www.statnews.com/stat-plus/">
						<img src="https://www.statnews.com/wp-content/themes/stat/images/stat-plus-logo-white.svg" alt="STAT+">
					</a>
				</span></p><h2 id="restricted-story-heading">This article is exclusive to STAT+ subscribers</h2>
				<h3 id="restricted-story-description">Unlock this article — plus in-depth analysis, newsletters, premium events, and networking platform access.</h3>
				<p>Already have an account? <a href="https://www.statnews.com/login/" data-stat-login="" data-stat-paywall-cta="breaker login cta desktop">Log in</a></p>
				<p>Already have an account? <a href="https://www.statnews.com/login/" data-stat-login="" data-stat-paywall-cta="breaker login cta mobile">Log in</a></p>
				
				<p><a href="https://www.statnews.com/stat-plus/" data-stat-paywall-cta="breaker view all plans" aria-label="View All Plans">View All Plans</a>
			</p></div>
		</div>
		
		<div>
					<p>
						Get unlimited access to award-winning journalism and exclusive events.					</p>
					<p><a href="https://www.statnews.com/stat-plus/" data-stat-paywall-cta="breaker subscribe cta 1">Subscribe</a>
									</p></div>
		</section>
		
					<div>
			<h2>About the Author							</h2>
			<div><p><img width="80" height="80" src="https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-80x80.png" alt="Nicholas Florko" loading="lazy" sizes="(max-width: 80px) 100vw, 80px" srcset="https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-80x80.png 80w, https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small-160x160.png 160w, https://www.statnews.com/wp-content/uploads/2021/02/nick-f-avatar-small.png 300w"></p><div>		<h3>
			<a href="https://www.statnews.com/staff/nicholas-florko/">Nicholas Florko</a>
		</h3>
	
			<p>Reporter, Commercial Determinants of Health</p>
				<p>Nicholas Florko reports on the commercial determinants of health.</p>
				
				
		</div></div>		</div>
						
			<p>To submit a correction request, please visit our <a href="https://www.statnews.com/contact/">Contact Us page</a>.</p>
					</article>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A free site to explore and discover 6k plants (337 pts)]]></title>
            <link>https://www.getanyplant.com/plants</link>
            <guid>40273470</guid>
            <pubDate>Mon, 06 May 2024 11:42:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.getanyplant.com/plants">https://www.getanyplant.com/plants</a>, See on <a href="https://news.ycombinator.com/item?id=40273470">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[World Food Atlas: Discover local dishes and ingredients (101 pts)]]></title>
            <link>https://www.tasteatlas.com/map</link>
            <guid>40272577</guid>
            <pubDate>Mon, 06 May 2024 08:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tasteatlas.com/map">https://www.tasteatlas.com/map</a>, See on <a href="https://news.ycombinator.com/item?id=40272577">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A useful productivity measure? (178 pts)]]></title>
            <link>https://www.jamesshore.com/v2/blog/2024/a-useful-productivity-measure</link>
            <guid>40272186</guid>
            <pubDate>Mon, 06 May 2024 07:39:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jamesshore.com/v2/blog/2024/a-useful-productivity-measure">https://www.jamesshore.com/v2/blog/2024/a-useful-productivity-measure</a>, See on <a href="https://news.ycombinator.com/item?id=40272186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In my <a href="https://www.jamesshore.com/v2/blog/2024/a-software-engineering-career-ladder">new role as VP of Engineering</a>, there was one question I was dreading more than any other: “How are you measuring productivity?”</p>

<p>I can’t fault the question. I mean, sure, I’d rather it be phrased about how I’m <em>improving</em> productivity, rather than how I’m <em>measuring</em> it, but fair enough. I need to be accountable for engineering productivity. There <em>are</em> real problems in the org, I <em>do</em> need to fix them, and I need to demonstrate that I’m doing so.</p>

<p>Just one little problem: software productivity is famously unmeasurable. Martin Fowler: “<a href="https://martinfowler.com/bliki/CannotMeasureProductivity.html">Cannot Measure Productivity</a>.” From 2003. <em>2003!</em></p>

<p>More recently, Kent Beck and Gergely Orosz tackled the same question. Kent concluded: “Measure developer productivity? Not possible.”<sup>1</sup></p>

<p><sup>1</sup>Kent and Gergely’s two-part article is excellent and worth reading. <a href="https://tidyfirst.substack.com/p/measuring-developer-productivity">Part one.</a> <a href="https://tidyfirst.substack.com/p/measuring-developer-productivity-440">Part two.</a> And <a href="https://tidyfirst.substack.com/p/productivity-measurement-as-a-tradeoff">a later followup</a>.</p>

<p>So now what do I do? That’s it, I’m screwed, make up some bullshit metric and watch my soul die, McKinsey style? Fight with my CEO about his impossible request until he gives up and fires me?</p>

<p>Maybe not. I think I’ve found another way. It’s early, but it’s working for me so far. Will it work for you? Eeehhhhh... maybe. Probably not. But maybe.</p>


<h3>My Solution</h3>

<p>It started half a year ago, in September 2023. My CEO asked me how I was measuring productivity. I told him it wasn’t possible. He told me I was wrong. I took offense. It got heated.</p>

<p>After things cooled off, he invited me to his house to talk things over in person. (We’re a fully remote company, in different parts of the country, so face time takes some arranging.) I knew I couldn’t just blow off the request, so I decided to approach the question from the standpoint of accountability. How could I demonstrate to my CEO that I was being accountable to the org?</p>

<p>We met at the CEO’s house, along with the CTO and CPO (Chief Product Officer). I led them through an exercise: “Imagine we’ve built the best product engineering organization in the world. What does that look like?” We came up with six categories of ideas. Then I asked, “Which indicators will help us understand how we’re getting closer to these ideals?” We came up with indicators in each category. Blissfully, none of those categories were “productivity.” I don’t think anyone noticed. Bullet dodged.</p>

<p>I came away feeling fairly positive about the conversation. I discussed the results with my Engineering and Product peers, we refined, and I finally presented the first “Product Engineering Accountability Review” a few weeks ago. It went well! I used the indicators to <em>support</em> a qualitative discussion of what’s happening in Engineering, rather than just reporting numbers.</p>

<p>One problem: the CEO had a scheduling conflict and couldn’t come. So I don’t know what he would have thought. But at least the CTO and CPO liked it.</p>


<h3>The Productivity OKR</h3>

<p>Meanwhile, back in January, the leadership team had established that one of our company-wide OKRs<sup>1</sup> would be to define and improve productivity metrics for each department. I was to present mine to the full Leadership team at the end of April. Crap. Bullet un-dodged.</p>

<p><sup>1</sup>“OKRs” are “Objectives and Key Results.” They’re a way of setting and tracking goals. Similar to Management by Objectives, about which <a href="https://deming.org/explore/fourteen-points/">Deming said</a>: “Eliminate management by objective. Eliminate management by numbers, numerical goals. Substitute leadership.” But that’s a rant for another day.</p>

<p>In October, we had defined six aspects of being the greatest product engineering company in the world. One of them was “profitability.” Its indicators were the most related to outcomes. If I had to measure productivity—and I did—they were the ones to use.</p>

<p>We had three indicators for profitability: actual RoI, estimated RoI, and value-add capacity. The first was best, in theory. In practice, it might be impossible to measure. Before I explain why, I need to explain how we calculate RoI.</p>


<h3>Product Bets</h3>

<p>Every engineering organization I’ve ever seen has had more demand than capacity. Prioritizing those demands is crucial. And fraught. Lots and lots of opportunity for conflict.</p>

<p>We’re no exception. To help bring order to the chaos, the VP of Product and I have introduced the idea of “Product Bets.” Each major initiative needs a Product Bet Proposal. It's a short, one-page document that explains:</p>

<ul>
	<li>What we’re going to accomplish</li>
	<li>The value it’s estimated to generate</li>
	<li>The amount we’re willing to bet</li>
	<li>The justification for the value</li>
	<li>How we’ll measure the value</li>
</ul>

<p>In order for a proposal to be accepted, a member of the Leadership team needs to sponsor it, take accountability for its success, and convince the other Leadership members that their proposal is more important than all the others.</p>

<p>In theory, anyway. I’ve tried variants of this idea before, and it’s never lasted. Turns out leadership teams like accountability more when it’s <em>other</em> people who have to be accountable.</p>

<p>But we’re trying. So far... it’s kind of working. Maybe. Too early to tell, honestly. I’ll write more after the verdict’s in.</p>


<h3>A True Measure of Productivity</h3>

<p>But if the product bet process <em>does</em> work... well. That would be cool. It would give us a true measure of productivity. We would know the value of a bet, and it’s easy to know how much we spend on a bet. Value produced over dollars spent. Boom. Productivity. Done.</p>

<p>Even better, the numbers are nice. Very nice. Each bet has a “maximum wager,” which determines how many engineer-days we’ll invest in the bet before giving up. Those wagers are based on one tenth of the expected value over five years. In other words, 10x return on investment.</p>

<p>10x return on investment is enough to make anybody take notice. But... measuring value is a problem. Sure, each bet has an section on how we’ll measure value, but can we really tease that out from sales team effort, customer success team effort, other feature changes, and changes in the market? Probably not.</p>

<p>It might not matter. We may not be able to measure the <em>actual</em> value, but every bet also has an <em>estimated</em> value attached. Combined with actual cost, that gives us a measure of estimated RoI. It may not be real RoI, but it’s good enough for understanding the productivity of the engineering team.</p>

<p>That’s our first two productivity measures: actual RoI and estimated RoI. Pretty good. Except that we don’t have any data.</p>


<h3>A Better Measure of Productivity... For Now</h3>

<p>The RoI metrics rely on us having product bets. But we don’t. Not yet. We’re still rolling them out. So, no matter how good the metrics might be, we can’t use them. No data.</p>

<p>There’s a third indicator in the “profitability” category we <em>can</em> use, though. It’s value-add capacity.</p>

<p>Like any engineering organization, we spend some percent of our time on fixing bugs, performing maintenance, and other things that are necessary but don’t add value from a customer or user perspective. The Japanese term for this is <em>muda.</em></p>

<p>If we didn’t have any muda, spent all our time on value-add work, and achieved a 10x return on each investment, our productivity would be ten: $10 for every $1 in salary (or close enough). If we spent 80% of our time on value-add work, our productivity would be eight. Twenty percent, two.</p>

<p>In other words, in the absence of RoI measures, the percent of engineering time spent on value-add activities is a pretty good proxy for productivity.</p>

<p>That’s the productivity number I reported to Leadership last week.</p>


<h3>How It Was Received</h3>

<p>It worked really well. The nice thing about reporting this number was that people were <em>already</em> frustrated with Engineering’s progress. They could see that we had capacity problems, but they didn’t know why. It was easy for them to assume that it was because people weren’t working hard, or didn’t know what they were doing.</p>

<p>I presented our metric as a single stacked bar chart. (Like a pie chart, but in a rectangle.) Muda on the bottom, value-add on the top. Then I expanded out the muda into another stacked bar chart, showing how much time was being spent across all of Engineering on deferred maintenance, bugs, on call, incident response, deployments, and so forth. Then expanded out again with more detail for the worst of those categories.</p>

<p>It completely changed the tenor of the conversation. Suddenly, the conversation shifted from, “how can we get the stuff we want sooner,” to “how can we decrease muda and spend more time on value-add work?” That’s exactly the conversation we need to be having.</p>

<p>Earlier in the week, the CEO told me that, next quarter, Leadership wants a briefing from me about how Engineering works. What my deliverables are, essentially. With the capacity measure, I have a good answer: my job is to double our value-add capacity over the next three years. Essentially, to double our output without increasing spending.</p>

<p>You know what? With my XP plans and the XP coaches I’ve hired, it’s totally doable. I think I’m being kind of conservative, actually.</p>


<h3>A Fatal Flaw</h3>

<p>So that’s my productivity measure: value-add capacity. The percentage of engineering time we spend on adding value for users and customers. Can you use it? Eehhhhh... maybe.</p>

<p>I can use value-add capacity—so far—because I’m aggressively stubborn about honest data. I refuse to skew our numbers or do worse work to make my department look good, and I’m keeping a close eye on what my teams are doing, too. This is important, because value-add capacity has a fatal flaw:</p>

<blockquote>
	<p>When a measure becomes a target, it ceases to be a good measure.</p>
	<p>Goodhart’s Law</p>
</blockquote>

<p>It’s ridiculously easy to cheat this metric. Even if you correctly categorize your muda—it’s very tempting to let edge cases slide—all you have to do is stop fixing bugs, defer some needed upgrades, ignore a security vulnerability... and poof! Happy numbers. At a horrible cost.</p>

<p>Actually, that’s the root of my org’s current capacity problems. They weren’t cheating a metric, but they <em>were</em> under pressure to deliver as much as possible. So they deferred a bunch of maintenance and took some questionable engineering shortcuts. Now they’re paying the price.</p>

<p>Unfortunately, you can get away with cheating this metric for a long time. Years, really. It’s not like you cut quality one month and then the truth comes out the next month. This is a metric that only works when people are scrupulously honest, including with themselves.</p>

<p>So, yeah, I’m not sure if this will work for you. It depends on how much ability you have to police things. The RoI indicators might not work for you either. They require product bets, or something similar, and that requires a lot of org changes. Even if they do work for me—jury’s out on that—they’re not something you can introduce overnight.</p>

<p>But, so far, value-add capacity <em>is</em> working for me, and I thought that might be interesting to you. Maybe spark some ideas. Just be cautious. Goodhart’s Law is a vengeful bastard. Remember, all this productivity metric stuff is a sideshow to what really matters:</p>

<p>Deliver valuable software. Do it often. And write it well.</p>

<p>Good luck.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Supertone Shift – AI powered Real-time voice changer (151 pts)]]></title>
            <link>https://product.supertone.ai/shift</link>
            <guid>40271706</guid>
            <pubDate>Mon, 06 May 2024 06:21:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://product.supertone.ai/shift">https://product.supertone.ai/shift</a>, See on <a href="https://news.ycombinator.com/item?id=40271706">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How LLMs Work, Explained Without Math (201 pts)]]></title>
            <link>https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math</link>
            <guid>40271457</guid>
            <pubDate>Mon, 06 May 2024 05:40:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math">https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math</a>, See on <a href="https://news.ycombinator.com/item?id=40271457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I'm sure you agree that it has become impossible to ignore <a href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence">Generative AI</a> (GenAI), as we are constantly bombarded with mainstream news about <a href="https://en.wikipedia.org/wiki/Large_language_model">Large Language Models</a> (LLMs). Very likely you have tried <a href="https://chat.openai.com/">ChatGPT</a>, maybe even keep it open all the time as an assistant.</p>
<p>A basic question I think a lot of people have about the GenAI revolution is where does the apparent intelligence these models have come from. In this article, I'm going to attempt to explain in simple terms and without using advanced math how generative text models work, to help you think about them as computer algorithms and not as magic.</p>
<h2>What Does An LLM Do?</h2>
<p>I'll begin by clearing a big misunderstanding people have regarding how Large Language Models work. The assumption that most people make is that these models can answer questions or chat with you, but in reality all they can do is take some text you provide as input and guess what the next word (or more accurately, the next <em>token</em>) is going to be. Let's start to unravel the mystery of LLMs from the tokens.</p>
<h3>Tokens</h3>
<p>A token is the basic unit of text understood by the LLM. It is convenient to think of tokens as words, but for the LLM the goal is to encode text as efficiently as possible, so in many cases tokens represent sequences of characters that are shorter or longer than whole words. Punctuation symbols and spaces are also represented as tokens, either individually or grouped with other characters.</p>
<p>The complete list of tokens used by an LLM are said to be the LLM's <em>vocabulary</em>, since it can be used to express any possible text. The <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding">byte pair encoding (BPE)</a> algorithm is commonly used by LLMs to generate a token vocabulary given an input dataset. Just so that you have some rough idea of scale, the <a href="https://github.com/openai/gpt-2">GPT-2</a> language model, which is open source and can be studied in detail, uses a vocabulary of 50,257 tokens.</p>
<p>Each token in an LLM's vocabulary is given a unique identifier, usually a number. The LLM uses a <em>tokenizer</em> to convert between regular text given as a string and an equivalent sequence of tokens, given as a list of token numbers. If you are familiar with Python and want to play with tokens, you can install the <code>tiktoken</code> package from OpenAI:</p>
<pre><code>$ pip install tiktoken
</code></pre>
<p>Then try this in a Python prompt:</p>
<pre><code>&gt;&gt;&gt; import tiktoken
&gt;&gt;&gt; encoding = tiktoken.encoding_for_model("gpt-2")

&gt;&gt;&gt; encoding.encode("The quick brown fox jumps over the lazy dog.")
[464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13]

&gt;&gt;&gt; encoding.decode([464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290, 13])
'The quick brown fox jumps over the lazy dog.'

&gt;&gt;&gt; encoding.decode([464])
'The'
&gt;&gt;&gt; encoding.decode([2068])
' quick'
&gt;&gt;&gt; encoding.decode([13])
'.'
</code></pre>
<p>You can see in this experiment that for the GPT-2 language model token 464 represents the word "The", and token 2068 represents the word " quick", including a leading space. This model uses token 13 for the period.</p>
<p>Because tokens are determined algorithmically, you may find strange things, such as these three variants of the word "the", all encoded as different tokens by GPT-2:</p>
<pre><code>&gt;&gt;&gt; encoding.encode('The')
[464]
&gt;&gt;&gt; encoding.encode('the')
[1169]
&gt;&gt;&gt; encoding.encode(' the')
[262]
</code></pre>
<p>The BPE algorithm doesn't always map entire words to tokens. In fact, words that are less frequently used do not get to be their own token and have to be encoded with multiple tokens. Here is an example of a word that this model encodes with two tokens:</p>
<pre><code>&gt;&gt;&gt; encoding.encode("Payment")
[19197, 434]

&gt;&gt;&gt; encoding.decode([19197])
'Pay'
&gt;&gt;&gt; encoding.decode([434])
'ment'
</code></pre>
<h3>Next Token Predictions</h3>
<p>Given some text, a language model maked predictions about what token will follow right after. If it helps to see this with Python pseudo-code, here is how you could run one of these models to get predictions for the next token:</p>
<pre><code>predictions = get_token_predictions(['The', ' quick', ' brown', ' fox'])
</code></pre>
<p>The function gets a list of input tokens, which are encoded from the <em>prompt</em> provided by the user. In this example I'm assuming words are all individual tokens. To keep things simple I'm using the textual representation of each token, but as you've seen before in reality each token will be passed to the model as a number.</p>
<p>The returned value of this function is a data structure that assigns each token in the vocabulary a probability to follow the input text. If this was based on GPT-2, the return value of the function would be a list of 50,257 floating point numbers, each predicting a probability that the corresponding token will come next.</p>
<p>In the example above you could imagine that a well trained language model will give the token "jumps" a high probability to follow the partial phrase "<a href="https://en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog">The quick brown fox</a>" that I used as prompt. Once again assuming a model trained appropriately, you could also imagine that the probability of a random word such as "potato" continuing this phrase is going to be much lower and close to 0.</p>
<p>To be able to produce reasonable predictions, the language model has to go through a <em>training</em> process. During training, it is presented with lots and lots of text to learn from. At the end of the training, the model is able to calculate next token probabilities for a given token sequence using data structures that it has built using all the text that it saw in training.</p>
<p>Is this different from what you expected? I hope this is starting to look less magical now.</p>
<h3>Generating Long Text Sequences</h3>
<p>Since the model can only predict what the next token is going to be, the only way to make it generate complete sentences is to run the model multiple times in a loop. With each loop iteration a new token is generated, chosen from the returned probabilities. This token is then added to the input that is given to the model on the next iteration of the loop, and this continues until sufficient text has been generated.</p>
<p>Let's look at a more complete Python pseudo-code showing how this would work:</p>
<pre><code>def generate_text(prompt, num_tokens, hyperparameters):
    tokens = tokenize(prompt)
    for i in range(num_tokens):
        predictions = get_token_predictions(tokens)
        next_token = select_next_token(predictions, hyperparameters)
        tokens.append(next_token)
    return ''.join(tokens)
</code></pre>
<p>The <code>generate_text()</code> function takes a user prompt as an argument. This could be, for example, a question.</p>
<p>The <code>tokenize()</code> helper function converts the prompt to an equivalent list of tokens, using <code>tiktoken</code> or a similar library. Inside the for-loop, the <code>get_token_predictions()</code> function is where the AI model is called to get the probabilitles for the next token, as in the previous example.</p>
<p>The job of the <code>select_next_token()</code> function is to take the next token probabilities (or predictions) and pick the best token to continue the input sequence. The function could just pick the token with the highest probability, which in machine learning is called a <em>greedy selection</em>. Better yet, it can pick a token using a random number generator that honors the probabilities returned by the model, and in that way add some variety to the generated text. This will also make the model produce different responses if given the same prompt multiple times.</p>
<p>To make the token selection process even more flexible, the probabilities returned by the LLM can be modified using <em>hyperparameters</em>, which are passed to the text generation function as arguments. The hyperparameters allow you to control the "greediness" of the token selection process. If you have used LLMs, you are likely familiar with the <code>temperature</code> hyperparameter. With a higher temperature, the token probabilities are flattened out, and this augments the chances of less likely tokens to be selected, with the end result of making the generated text look more creative or unusual. You may have also used two other hyperparameters called <code>top_p</code> and <code>top_k</code>, which control how many of the highest probable tokens are considered for selection.</p>
<p>Once a token has been selected, the loop iterates and now the model is given an input that includes the new token at the end, and one more token is generated to follow it. The <code>num_tokens</code> argument controls how many iterations to run the loop for, or in other words, how much text to generate. The generated text can (and often does) end mid-sentence, because the LLM has no concept of sentences or paragraphs, since it just works on one token at a time. To prevent the generated text from ending in the middle of a sentence, we could consider the <code>num_tokens</code> argument as a maximum instead of an exact number of tokens to generate, and in that case we could stop the loop when a period token is generated.</p>
<p>If you've reached this point and understood everything then congratulations, you now know how LLMs work at a high level. Are you interested in more details? In the next section I'll get a bit more technical, while still doing my best to avoid referencing the math that supports this technology, which is quite advanced.</p>
<h2>Model Training</h2>
<p>Unfortunately, discussing how a model is trained is actually difficult without using math. What I'm going to do is start by showing you a very simple training approach.</p>
<p>Given that the task is to predict tokens that follow other tokens, a simple way to train a model is to get all the pairs of consecutive tokens that appear in the training dataset and build a table of probabilities with them.</p>
<p>Let's do this with a short vocabulary and dataset. Let's say the model's vocabulary has the following five tokens:</p>
<pre><code>['I', 'you', 'like', 'apples', 'bananas']
</code></pre>
<p>To keep this example short and simple, I'm not going to consider spaces or punctuation symbols as tokens.</p>
<p>Let's use a training dataset that is composed of three sentences:</p>
<ul>
<li>I like apples</li>
<li>I like bananas</li>
<li>you like bananas</li>
</ul>
<p>We can build a 5x5 table and in each cell write how many times the token representing the row of the cell is followed by the token representing the column. Here is the table built from the three sentences in the dataset:</p>
<table>
<thead>
<tr>
<th>-</th>
<th>I</th>
<th>you</th>
<th>like</th>
<th>apples</th>
<th>bananas</th>
</tr>
</thead>
<tbody>
<tr>
<td>I</td>
<td></td>
<td></td>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>you</td>
<td></td>
<td></td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>like</td>
<td></td>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>apples</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>bananas</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Hopefully this is clear. The dataset has two instances of "I like", one instance of "you like", one instance of "like apples" and two of "like bananas".</p>
<p>Now that we know how many times each pair of tokens appeared in the training dataset, we can calculate the probabilities of each token following each other. To do this, we convert the numbers in each row to probabilities. For example, token "like" in the middle row of the table was followed once by "apples" and twice by "bananas". That means that "apples" follows "like" 33.3% of the time, and "bananas" follows it the remaining 66.7%.</p>
<p>Here is the complete table with all the probabilities calculated. Empty cells have a probability of 0%.</p>
<table>
<thead>
<tr>
<th>-</th>
<th>I</th>
<th>you</th>
<th>like</th>
<th>apples</th>
<th>bananas</th>
</tr>
</thead>
<tbody>
<tr>
<td>I</td>
<td></td>
<td></td>
<td>100%</td>
<td></td>
<td></td>
</tr>
<tr>
<td>you</td>
<td></td>
<td></td>
<td>100%</td>
<td></td>
<td></td>
</tr>
<tr>
<td>like</td>
<td></td>
<td></td>
<td></td>
<td>33.3%</td>
<td>66.7%</td>
</tr>
<tr>
<td>apples</td>
<td>25%</td>
<td>25%</td>
<td>25%</td>
<td></td>
<td>25%</td>
</tr>
<tr>
<td>bananas</td>
<td>25%</td>
<td>25%</td>
<td>25%</td>
<td>25%</td>
<td></td>
</tr>
</tbody>
</table>
<p>The rows for "I", "you" and "like" are easy to calculate, but "apples" and "bananas" present a problem because they have no data at all, since the dataset does not have any examples with these tokens being followed by other tokens. Here we have a "hole" in our training, so to make sure that the model produces a prediction even when lacking training, I have decided to split the probabilities for a follow-up token for "apples" and "bananas" evenly across the other four possible tokens, which could obviously generate strange results, but at least the model will not get stuck when it reaches one of these two tokens.</p>
<p>The problem of holes in training data is actually important. In real LLMs the training datasets are very large, so you would not find training holes that are so obvious as in my tiny example above. But smaller, more difficult to detect holes due to low coverage in the training data do exist and are fairly common. The quality of the token predictions the LLM makes in these poorly trained areas can be bad, but often in ways that are difficult to perceive. This is one of the reasons LLMs can sometimes <a href="https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)">hallucinate</a>, which happens when the generated text reads well, but contains factual errors or inconsistencies.</p>
<p>Using the probabilities table above, you may now imagine how an implementation of the <code>get_token_predictions()</code> function would work. In Python pseudo-code it would be something like this:</p>
<pre><code>def get_token_predictions(input_tokens):
    last_token = input_tokens[-1]
    return probabilities_table[last_token]
</code></pre>
<p>Simpler than expected, right? The function accepts a sequence of tokens, which come from the user prompt. It takes the last token in the sequence, and returns the row in the probabilities table that corresponds to that token.</p>
<p>If you were to call this function with <code>['you', 'like']</code> as input tokens, for example, the function would return the row for "like", which gives the token "apples" a 33.3% chance of continuing the sentence, and the token "bananas" the other 66.7%. With these probabilities, the <code>select_next_token()</code> function shown above should choose "apples" one out of three times.</p>
<p>When the "apples" token is selected as a continuation of "you like", the sentence "you like apples" will be formed. This is an original sentence that did not exist in the training dataset, yet it is perfectly reasonable. Hopefully you are starting to get an idea of how these models can come up with what appears to be original ideas or concepts, just by reusing patterns and stitching together different bits of what they learned in training.</p>
<h3>The Context Window</h3>
<p>The approach I took in the previous section to train my mini-language model is called a <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain</a>. </p>
<p>An issue with this technique is that only one token (the last of the input) is used to make a prediction. Any text that appears before that last token doesn't have any influence when choosing how to continue, so we can say that the <em>context window</em> of this solution is equal to one token, which is very small. With such a small context window the model constantly "forgets" its line of thought and jumps from one word to the next without much consistency.</p>
<p>To improve the model's predictions a larger probabilities table can be constructed. To use a context window of two tokens, additional table rows would have to be added with rows that represent all possible sequences of two tokens. With the five tokens I used in the example there would be 25 new rows in the probabilities table each for a pair of tokens, added to the 5 single-token rows that are already there. The model would have to be trained again, this time looking at groups of three tokens in addition to the pairs. Then in each loop iteration of the <code>get_token_predictions()</code> function the last two tokens from the input would be used when available, to find the corresponding row in the larger probabilities table.</p>
<p>But a context window of 2 tokens is still insufficient. For the generated text to be consistent with itself and make at least some basic sense, a much larger context window is needed. Without a large enough context it is impossible for newly generated tokens to relate to concepts or ideas expressed in previous tokens. So what can we do? Increasing the context window to 3 tokens would add 125 additional rows to the probabilities table, and the quality would still be very poor. How large do we need to make the context window?</p>
<p>The open source GPT-2 model from OpenAI uses a context window of 1024 tokens. To be able to implement a context window of this size using Markov chains, each row of the probabilities table would have to represent a sequence that is between 1 and 1024 tokens long. Using the above example vocabulary of 5 tokens, there are 5<sup>1024</sup> possible sequences that are 1024 tokens long. How many table rows are required to represent this? I did the calculation in a Python session (scroll to the right to see the complete number):</p>
<pre><code>&gt;&gt;&gt; pow(5, 1024)
55626846462680034577255817933310101605480399511558295763833185422180110870347954896357078975312775514101683493275895275128810854038836502721400309634442970528269449838300058261990253686064590901798039126173562593355209381270166265416453973718012279499214790991212515897719252957621869994522193843748736289511290126272884996414561770466127838448395124802899527144151299810833802858809753719892490239782222290074816037776586657834841586939662825734294051183140794537141608771803070715941051121170285190347786926570042246331102750604036185540464179153763503857127117918822547579033069472418242684328083352174724579376695971173152319349449321466491373527284227385153411689217559966957882267024615430273115634918212890625
</code></pre>
<p>That is a lot of rows! And this is only a portion of the table, since we would also need sequences that are 1023 tokens long, 1022, etc., all the way to 1, since we want to make sure shorter sequences can also be handled when not enough tokens are available in the input. Markov chains are fun to work with, but they do have a big scalability problem.</p>
<p>And a context window of 1024 tokens isn't even that great anymore. With GPT-3, the context window was increased to 2048 tokens, then increased to 4096 in GPT-3.5. GPT-4 started with 8192 tokens, later got increased to 32K, and then again to 128K (that's right, 128,000 tokens!). Models with 1M or larger context windows are starting to appear now, allowing models to have much better consistency and recall when they make token predictions.</p>
<p>In conclusion, Markov chains allow us to think about the problem of text generation in the right way, but they have big issues that prevent us from considering them as a viable solution.</p>
<h3>From Markov Chains to Neural Networks</h3>
<p>Obviously we have to forget the idea of having a table of probabilities, since a table for a reasonable context window would require an impossibly large amount of RAM. What we can do is replace the table with a function that returns an approximation of what the token probabilities would be, generated algorithmically instead of stored as a big table. This is actually something that <em>neural networks</em> can do well.</p>
<p>A neural network is a special type of function that takes some inputs, performs some calculations on them, and returns an output. For a language model the inputs are the tokens that represent the prompt, and the output is the list of predicted probabilities for the next token.</p>
<p>I said neural networks are "special" functions. What makes them special is that in addition to the function logic, the calculations they perform on the inputs are controlled by a number of externally defined <em>parameters</em>. Initially, the parameters of the network are not known, and as a result, the function produces and output that is completely useless. The training process for the neural network consists in finding the parameters that make the function perform the best when evaluated on the data from the training dataset, with the assumption that if the function works well with the training data it will work comparably well with other data.</p>
<p>During the training process, the parameters are iteratively adjusted in small increments using an algorithm called <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> which is heavy on math, so I won't discuss in this article. With each adjustment, the predictions of the neural network are expected to become a tiny bit better. The updated network is evaluated again against the training dataset, and the results inform the next round of adjustments. This process continues until the function performs good next token predictions on the training dataset.</p>
<p>To help you have an idea of the scale at which neural networks work, consider that the GPT-2 model has about 1.5 billion parameters, and GPT-3 increased the parameter count to 175 billion. GPT-4 is said to have about 1.76 trillion parameters. Training neural networks at this scale with current generation hardware takes a very long time, usually weeks or months.</p>
<p>What is interesting is that because there are so many parameters, all calculated through a lengthy iterative process without human assistance, it is difficult to understand how a model works. A trained LLM is like a black box that is extremely difficult to debug, because most of the "thinking" of the model is hidden in the parameters. Even those who trained it have trouble explaining its inner workings.</p>
<h3>Layers, Transformers and Attention</h3>
<p>You may be curious to know what mysterious calculations happen inside the neural network function that can, with the help of well tuned parameters, take a list of input tokens and somehow output reasonable probabilities for the token that follows.</p>
<p>A neural network is configured to perform a chain of operations, each called a <em>layer</em>. The first layer receives the inputs, and performs some type of transformation on them. The transformed inputs enter the next layer and are transformed once again. This continues until the data reaches the final layer and is transformed one last time, generating the output, or prediction.</p>
<p>Machine learning experts come up with different types of layers that perform mathematical transformations on the input data, and they also figure out ways to organize layers in ways that achieve a desired result. Some layers are of a general purpose, while others are designed to work on a specific type of input data, such as images or as in the case of LLMs, on tokenized text.</p>
<p>The neural network architecture that is the most popular today for text generation in large language models is called the <a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)">Transformer</a>. LLMs that use this design are said to be GPTs, or <a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer">Generative Pre-Trained Transformers</a>.</p>
<p>The distinctive characteristic of transformer models is a layer calculation they perform called <a href="https://en.wikipedia.org/wiki/Attention_(machine_learning)">Attention</a>, that allows them to derive relationships and patterns between tokens that are in the context window, which are then reflected in the resulting probabilities for the next token.</p>
<p>The Attention mechanism was initially used in language translators, as a way to find which tokens in an input sequence are the most important to extract its meaning. This mechanism gives modern translators the ability to "understand" a sentence at a basic level, by focusing (or driving "attention") to the important words or tokens.</p>
<h2>Do LLMs Have Intelligence?</h2>
<p>By now you may be starting to form an opinion on wether LLMs show some form of intelligence in the way they generate text. </p>
<p>I personally do not see LLMs as having an ability to reason or come up with original thoughts, but that does not mean to say they're useless. Thanks to the clever calculations they perform on the tokens that are in the context window, LLMs are able to pick up on patterns that exist in the user prompt and match them to similar patterns learned during training. The text they generate is formed from bits and pieces of training data for the most part, but the way in which they stitch words (tokens, really) together is highly sophisticated, in many cases producing results that feel original and useful.</p>
<p>On the other side, given the propensity of LLMs to hallucinate, I wouldn't trust any workflow in which the LLM produces output that goes straight to end users without verification by a human.</p>
<p>Will the larger LLMs that are going to appear in the following months or years achieve anything that resembles true intelligence? I feel this isn't going to happen with the GPT architecture due to its many limitations, but who knows, maybe with some future innovations we'll get there.</p>
<h2>The End</h2>
<p>Thank you for staying with me until the end! I hope I have picked your interested enough for you to decide to continue learning, and eventually facing all that scary math that you cannot avoid if you want to understand every detail. In that case, I can't recommend Andrej Karpathy's <a href="https://karpathy.ai/zero-to-hero.html">Neural Networks: Zero to Hero</a> video series enough.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Helldivers 2 PSN account linking update will not be moving forward (166 pts)]]></title>
            <link>https://twitter.com/PlayStation/status/1787331667616829929</link>
            <guid>40271104</guid>
            <pubDate>Mon, 06 May 2024 04:18:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/PlayStation/status/1787331667616829929">https://twitter.com/PlayStation/status/1787331667616829929</a>, See on <a href="https://news.ycombinator.com/item?id=40271104">Hacker News</a></p>
Couldn't get https://twitter.com/PlayStation/status/1787331667616829929: Error: Request failed with status code 400]]></description>
        </item>
    </channel>
</rss>