<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 20 Jul 2024 10:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google's shortened links will stop working next year (104 pts)]]></title>
            <link>https://www.theverge.com/2024/7/19/24201734/google-url-link-shortening-service-shut-down-support</link>
            <guid>41014089</guid>
            <pubDate>Sat, 20 Jul 2024 04:36:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/7/19/24201734/google-url-link-shortening-service-shut-down-support">https://www.theverge.com/2024/7/19/24201734/google-url-link-shortening-service-shut-down-support</a>, See on <a href="https://news.ycombinator.com/item?id=41014089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you ever used Google’s URL shortening service goo.gl before it was shut down in 2019, be warned — those links will stop working on August 25th, 2025. Google <a href="https://developers.googleblog.com/en/google-url-shortener-links-will-no-longer-be-available/">announced in a blog post</a> that “the time has come to turn off the serving portion of Google URL Shortener” and that any links in the https://goo.gl/* format will respond with a 404 error next year.</p><p>Ahead of the shutdown, goo.gl links will start showing an interstitial page on August 23rd, 2024, notifying users that “this link will no longer work in the near future.” This message will initially appear for a “percentage of existing links,’’ which will increase as the deadline draws closer. Google is encouraging developers to update impacted links as soon as possible, however, as this interstitial page may cause disruptions to link redirections.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="The interstitial page that will appear on goo.gl links after August 23rd." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/376x167/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/384x170/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/415x184/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/480x213/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/540x240/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/640x284/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/750x333/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/828x368/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/1080x479/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/1200x533/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/1440x639/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/1920x852/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/2048x909/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/2400x1065/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:820x364/2400x1065/filters:focal(410x182:411x183):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25537594/Google_url_shortener_shutdown.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Here’s the interstitial page that will start popping up on goo.gl links after August 23rd.</em></figcaption> <p><cite>Image: Google</cite></p></div></div><p>When <a href="https://www.theverge.com/2018/3/31/17184164/google-alphabet-url-shortening-service-closed">Google announced in 2018</a> that it was shutting down goo.gl, the company encouraged developers to migrate to Firebase Dynamic Links (FDL) — which has also since been <a href="https://firebase.google.com/support/dynamic-links-faq">deprecated</a>. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Doom on Playdate (110 pts)]]></title>
            <link>https://devforum.play.date/t/doom-on-playdate/852</link>
            <guid>41013159</guid>
            <pubDate>Sat, 20 Jul 2024 01:10:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devforum.play.date/t/doom-on-playdate/852">https://devforum.play.date/t/doom-on-playdate/852</a>, See on <a href="https://news.ycombinator.com/item?id=41013159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Doom on Playdate">
      
      <meta itemprop="datePublished" content="2020-05-25T21:50:30Z">
        <meta itemprop="articleSection" content="Games">
      <meta itemprop="keywords" content="">
      


          <div itemprop="text" id="post_1">
              <p>Last week end I finally started to work on porting Doom on the Playdate.</p>
<p>This is a very early result, just to run the game, but that was the hardest part for me. Dealing with makefiles and compiler is really not my cup of tea so having the game running means that now I can focus on the game control, presentation and optimization.</p>
<p><img src="https://devforum-cdn.play.date/original/1X/ad0bca29eb788fe9bfed240366cd41ee2a4639bf.gif" alt="04" data-base62-sha1="oGPRqp9vmPbukHgOoJDHnql4w8v" width="400" height="240"></p>
<p>This is a gif from the simulator but I got the game running on the hardware too.</p>
<p><img src="https://devforum-cdn.play.date/original/1X/7c0f0a9386f96b3029520f6f76648db93a399eb6.gif" alt="05" data-base62-sha1="hHtqNnHnN2GfthLDtz2yS3xf5Rk" width="400" height="225"></p>
<p>The most difficult part was to deal with the linker that was complaining about some missing references in libc. After spending two evenings chasing every libc functions that might be problematic, I found out that there is some magical linker option.</p>
<p>I've added the following line in CMakeLists.txt<br>
<code>add_link_options(-specs=nano.specs -specs=nosys.specs)</code></p>
<p>Since the linker was complaining about the symbol end missing, I've added it to the link_map.ld in the playdate SDK</p>
<pre><code>	.bss :
	{
		. = ALIGN(4);
		__bss_start__ = .;
		*(.bss*)
		*(COMMON)
		. = ALIGN(4);
		__bss_end__ = .;
		end = __bss_end__;

	} &gt; EXTRAM
</code></pre>
            </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/matt"><span itemprop="name">matt</span></a>
                (gingerbeardman)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-25T22:33:56Z">
                    May 25, 2020, 10:33pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-25T22:33:56Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Nic! You're crazy. In a good way.</p>
<p>Awesome</p>
            </div>

            

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/ast-rsk"><span itemprop="name">ast-rsk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-25T23:07:57Z">
                    May 25, 2020, 11:07pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-25T23:07:57Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>This officially makes the playdate a viable product! If it can run doom, it's a solid device <img src="https://devforum-cdn.play.date/original/1X/3c05b67d820920114bafac96e31bfbefd6a4944d.png?v=12" title=":playdate:" alt=":playdate:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/squirrelboy"><span itemprop="name">squirrelboy</span></a>
                (Jake White)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-25T23:25:39Z">
                    May 25, 2020, 11:25pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-25T23:25:39Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <p>Woah. I already wanted to make a Wolfenstein/Doom style game on this, but now even more.</p>

            

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/dustin"><span itemprop="name">dustin</span></a>
                (Dustin Mierau)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-26T00:00:20Z">
                    May 26, 2020, 12:00am
                  </time>
                  <meta itemprop="dateModified" content="2020-05-26T00:00:20Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <p><img src="https://devforum-cdn.play.date/original/1X/d04cb21f40800c547fa08bc80d3c8dff0bc580c6.png?v=12" title=":playdate_shocked:" alt=":playdate_shocked:" loading="lazy" width="20" height="20"> <img src="https://devforum-cdn.play.date/original/1X/f444a5a65c415828c203bcb1b25076709723e907.png?v=12" title=":playdate_heart:" alt=":playdate_heart:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Dreezn"><span itemprop="name">Dreezn</span></a>
                (Dries Vienne)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-26T07:30:21Z">
                    May 26, 2020,  7:30am
                  </time>
                  <meta itemprop="dateModified" content="2020-05-26T07:30:21Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <p>I love you man.<br>
This is beautiful <img src="https://devforum.play.date/images/emoji/apple/smiling_face_with_three_hearts.png?v=12" title=":smiling_face_with_three_hearts:" alt=":smiling_face_with_three_hearts:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/SamanthaZero"><span itemprop="name">SamanthaZero</span></a>
                (Samantha Kalman)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-26T08:39:28Z">
                    May 26, 2020,  8:39am
                  </time>
                  <meta itemprop="dateModified" content="2020-05-26T08:39:28Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>very cool! <img src="https://devforum.play.date/images/emoji/apple/clap.png?v=12" title=":clap:" alt=":clap:" loading="lazy" width="20" height="20"> <img src="https://devforum.play.date/images/emoji/apple/clap.png?v=12" title=":clap:" alt=":clap:" loading="lazy" width="20" height="20"> <img src="https://devforum.play.date/images/emoji/apple/clap.png?v=12" title=":clap:" alt=":clap:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Nic"><span itemprop="name">Nic</span></a>
                (Nic Magnier)
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2020-05-26T10:01:16Z">
                    May 26, 2020, 10:01am
                  </time>
                  <meta itemprop="dateModified" content="2020-05-26T10:01:16Z">
              <span itemprop="position">8</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Wow thank you all <img src="https://devforum-cdn.play.date/original/1X/f444a5a65c415828c203bcb1b25076709723e907.png?v=12" title=":playdate_heart:" alt=":playdate_heart:" loading="lazy" width="20" height="20"></p>
<p>But I have to say that this is possible mostly because the Doom engine is extremely well done and organized and can be easily ported. It is not a mystery why this is the game that is always ported everywhere.</p>
<p>Something I forgot to mention is that I used STM32Doom for the port which itself in based on chocolate doom. I will share the source when I am a bit further and after cleaning some code (If anyone want to source already, feel free to DM me).</p>

<p>For anyone interested, I also recommend the book from Fabien Sanglard which analyze the source code. That was the book that pick my interest in porting the game.<br>
<a href="https://fabiensanglard.net/gebbdoom/index.html" target="_blank" rel="noopener">https://fabiensanglard.net/gebbdoom/index.html</a></p>
            </div>

            

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Dreezn"><span itemprop="name">Dreezn</span></a>
                (Dries Vienne)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-26T12:02:57Z">
                    May 26, 2020, 12:02pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-26T12:02:57Z">
              <span itemprop="position">9</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Wow thanks for sharing!</p>
<p>I didn't know that book existed <img src="https://devforum-cdn.play.date/original/1X/3c05b67d820920114bafac96e31bfbefd6a4944d.png?v=12" title=":playdate:" alt=":playdate:" loading="lazy" width="20" height="20"> . Although I never attempted porting, I dove into the source a few times to get inspiration for various clones and such. This makes my week!</p>
<p>What next steps are you planning, now that you got it up and running?</p>
            </div>

            

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/DJLink"><span itemprop="name">DJLink</span></a>
                (David)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-29T20:39:52Z">
                    May 29, 2020,  8:39pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-29T20:39:52Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            <p>wow this is so cool, thanks for sharing</p>

            

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Nic"><span itemprop="name">Nic</span></a>
                (Nic Magnier)
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2020-05-30T17:12:32Z">
                    May 30, 2020,  5:12pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-30T17:12:32Z">
              <span itemprop="position">11</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>I was not able to work on the port so much this week. This is still a gif of the rolling demo and this is not playable yet.</p>
<p><img src="https://devforum-cdn.play.date/original/1X/45a72288f2aaca1680556bcc2edfabb22b71cd51.gif" alt="06" data-base62-sha1="9Wb1SCfukHAEAsvNGWkQLwoF6Gl" width="400" height="240"></p>
<p>This is still pretty rough. I tried to add controls but now the game crashes in the simulator when I try to launch the proper game. I also have a new crash on device, a totally different one. It will be (not) fun to track them down.</p>
<p><img src="https://devforum-cdn.play.date/original/1X/831f4a1754fb7fb0e96227829fa4be398b4e78a9.jpeg" alt="image" data-base62-sha1="iHXAkc5VIVpibnRjHfObJxDlL29" width="300" height="225"></p>
<p>At least the rendering is a bit better. I use a dithering map texture which indicate which part of the screen is blue noise, ordered of just threshold. On the long term the key will be to add contrast to make some element like enemies pop more.</p>
<p><img src="https://devforum-cdn.play.date/original/1X/bd8bb0089cf2a258971e14d7d7738d44d34cbc5e.png" alt="image" data-base62-sha1="r2NwjONof7FsOhFRe46a25dlW5U" width="320" height="200"></p>
<p>But now I went back to the blue noise rabbit hole and started to experiment generating my own blue noise textures. That will be interesting to improve the picture quality (and I have an idea that might force me to go back to my video experiments)</p>
            </div>

            

            

          </div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/donald.hays"><span itemprop="name">donald.hays</span></a>
                (Donald Hays)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-30T23:50:22Z">
                    May 30, 2020, 11:50pm
                  </time>
                  <meta itemprop="dateModified" content="2020-05-30T23:50:22Z">
              <span itemprop="position">12</span>
              </span>
            </p>
            <div itemprop="text">
              <p>That is amazingly awesome.</p>
<p>I don't want to throw extra work on your plate, but this made me think about <a href="https://forums.tigsource.com/index.php?topic=40832.msg1363742#msg1363742" rel="noopener nofollow ugc">a post about dithering in Return of the Obra Dinn</a>, and how the dither pattern was rotated with the camera. Since you're working with Doom's source directly, I would imagine this means you have easy access to the camera rotation angle, yes? If so, I wonder how easy it would be to scroll the blue noise texture correspondingly, and if it would make the scene look any better or worse?</p>
            </div>

            

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Nic"><span itemprop="name">Nic</span></a>
                (Nic Magnier)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-05-31T05:08:14Z">
                    May 31, 2020,  5:08am
                  </time>
                  <meta itemprop="dateModified" content="2020-05-31T05:08:14Z">
              <span itemprop="position">13</span>
              </span>
            </p>
            <p>That’s an excellent idea!<br>
I will look into it but it shouldn’t be too hard indeed.</p>

            

            

          </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Nic"><span itemprop="name">Nic</span></a>
                (Nic Magnier)
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2020-06-01T21:27:41Z">
                    June 1, 2020,  9:27pm
                  </time>
                  <meta itemprop="dateModified" content="2020-06-01T21:27:41Z">
              <span itemprop="position">14</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>So if you don't go on the discord you might not have seen that Poom is kind of playable. I say kind of because I still have a lot of random crashes when navigating the menus. I am waiting to be able to debug on the simulator figure out what is the issue.</p>
<p>And because of popular demand I've added using the crank to use the Gatling. <img src="https://devforum-cdn.play.date/original/1X/d04cb21f40800c547fa08bc80d3c8dff0bc580c6.png?v=12" title=":playdate_shocked:" alt=":playdate_shocked:" loading="lazy" width="20" height="20"></p>
<p><img src="https://devforum-cdn.play.date/original/1X/62f76ee198cb00799bf45990690c10531b8f6d7f.gif" alt="DoomGatlingMini.2020-06-01 23_25_12" data-base62-sha1="e7uUJNqPr1l5EejChDvwKfT8oub" width="330" height="220"></p>
<p>We also had a discussion about Chex Quest and I don't think my code can support it so I am considering switch fully to Doom Chocolate. That would be an opportunity to clean up the code I did.</p>
<p>The early results are encouraging but there is still so much to do. <img src="https://devforum-cdn.play.date/original/1X/d5fcf966698d4f0ed1188749a3aca4707508f293.png?v=12" title=":playdate_dizzy:" alt=":playdate_dizzy:" loading="lazy" width="20" height="20"></p>
            </div>

            

            

                
          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/dustin"><span itemprop="name">dustin</span></a>
                (Dustin Mierau)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-06-01T22:25:24Z">
                    June 1, 2020, 10:25pm
                  </time>
                  <meta itemprop="dateModified" content="2020-06-01T22:25:24Z">
              <span itemprop="position">15</span>
              </span>
            </p>
            <p>SO FREAKING GOOD <img src="https://devforum.play.date/images/emoji/apple/smiley.png?v=12" title=":smiley:" alt=":smiley:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/ast-rsk"><span itemprop="name">ast-rsk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-06-01T23:27:32Z">
                    June 1, 2020, 11:27pm
                  </time>
                  <meta itemprop="dateModified" content="2020-06-01T23:27:32Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Incredible progress!</p>
<p>A couple friends of mine who don't know anything about playdate or that I'm in the preview, individually shared your update tweet with me saying how cool it is and how the device is so unique and looks fun.</p>
            </div>

            

            

          </div>
          <div id="post_17" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Drarok"><span itemprop="name">Drarok</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-06-02T20:04:47Z">
                    June 2, 2020,  8:04pm
                  </time>
                  <meta itemprop="dateModified" content="2020-06-02T20:04:47Z">
              <span itemprop="position">17</span>
              </span>
            </p>
            <div itemprop="text">
              <p>This is absolutely nuts in a brilliant way.</p>
<p>How's the music sound? <img src="https://devforum.play.date/images/emoji/apple/grimacing.png?v=12" title=":grimacing:" alt=":grimacing:" loading="lazy" width="20" height="20"></p>
            </div>

            

            

          </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/Nic"><span itemprop="name">Nic</span></a>
                (Nic Magnier)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-06-02T21:11:39Z">
                    June 2, 2020,  9:11pm
                  </time>
                  <meta itemprop="dateModified" content="2020-06-02T21:11:39Z">
              <span itemprop="position">18</span>
              </span>
            </p>
            <div itemprop="text">
              <p>No sound or music yet.</p>
<p>This is not my specialty so I didn't even look at it yet. Especially since this seem to have been the least portable part of the original doom. But I will come to that [art eventually.</p>
            </div>

            

            

          </div>
          <div id="post_19" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/HaitoH3"><span itemprop="name">HaitoH3</span></a>
                (Jason A. Huff)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-07-01T05:08:37Z">
                    July 1, 2020,  5:08am
                  </time>
                  <meta itemprop="dateModified" content="2020-07-01T05:08:37Z">
              <span itemprop="position">19</span>
              </span>
            </p>
            <p>oh man so good... i'll just start over now</p>

            

            

          </div>
          <div id="post_20" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://devforum.play.date/u/spencer"><span itemprop="name">spencer</span></a>
                (spencer cap)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2020-07-21T07:33:23Z">
                    July 21, 2020,  7:33am
                  </time>
                  <meta itemprop="dateModified" content="2020-07-21T07:33:23Z">
              <span itemprop="position">20</span>
              </span>
            </p>
            <p>Great job with this! would love to try out how it feels to shoot using the crank. do you have a pdx avail to play test?</p>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Garage: Open-Source Distributed Object Storage (221 pts)]]></title>
            <link>https://garagehq.deuxfleurs.fr/</link>
            <guid>41013004</guid>
            <pubDate>Sat, 20 Jul 2024 00:40:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://garagehq.deuxfleurs.fr/">https://garagehq.deuxfleurs.fr/</a>, See on <a href="https://news.ycombinator.com/item?id=41013004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
        <h2>Our Goals</h2>
        
        <p>We made it lightweight and kept the efficiency in mind:</p>
        <ul>
          <li>
            <span>Self-contained</span>
            <p>We ship a single dependency-free binary that runs on all Linux distributions</p>
          </li>
          
          <li>
            <span>Fast to deploy, safe to operate</span>
            <p>We are sysadmins, we know the value of operator-friendly software</p>
          </li>
          
          <li>
            <span>Deploy everywhere on every machine</span>
            <p>We do not have a dedicated backbone, and neither do you,<br>
              so we made software that run over the Internet across multiple datacenters</p>
          </li>
          
          <li>
            Highly resilient
            <p><span>to network failures</span>,
              <span>network latency</span>,
              <span>disk failures</span>,
              <span>sysadmin failures</span>
            </p>
          </li>
        </ul>
      </div>

      <div>
        <h2>Keeping requirements low</h2>
        
        <p>
          We worked hard to keep requirements as low as possible:
        </p>
        <ul>
          <li>
            <p><img src="https://garagehq.deuxfleurs.fr/icons/cpu.svg" width="24">
              <span>CPU</span>
            </p>
            <span>Any x86_64 CPU from the last 10 years, ARMv7 or ARMv8</span>
          </li>
          <li>
            <p><img src="https://garagehq.deuxfleurs.fr/icons/ram.svg" width="24">
              <span>RAM</span>
            </p>
            <span>1 GB</span>
          </li>
          <li>
            <p><img src="https://garagehq.deuxfleurs.fr/icons/disk.svg" width="24">
              <span>Disk space</span>
            </p>
            <span>At least 16 GB</span>
          </li>
          <li>
            <p><img src="https://garagehq.deuxfleurs.fr/icons/network.svg" width="24">
              <span>Network</span>
            </p>
            <span>200 ms or less, 50 Mbps or more</span>
          </li>
          <li>
            <p><img src="https://garagehq.deuxfleurs.fr/icons/hardware.svg" width="24">
              <span>Heterogeneous hardware</span>
            </p>
            <span>Build a cluster with whatever second-hand machines are available</span>
          </li>
        </ul>
      </div>

      <div>
        <h2>Data resiliency for everyone</h2>
        
        <p>
          We built Garage to suit your existing infrastructure:
        </p>
        <p>
          Garage implements the Amazon S3 API<br>and thus is already compatible with many applications.
        </p>
        
      </div>

      <div>
        <h2>Standing on the shoulders of giants</h2>
        
        <p>
          Garage leverages insights from recent research in distributed systems:
        </p>
        
      </div>
    </div><div>
        <h2>Sponsors and funding</h2>
        <p>Garage has received funding from <a href="https://pointer.ngi.eu/" target="_blank">NGI POINTER</a> (3 full-time employees for one year, in 2021-2022),
          and from <a href="https://nlnet.nl/entrust/" target="_blank">NLnet / NGI0 Entrust</a> (1 full-time employee for one year, in 2023-2024).
        </p>
        <p>If you want to participate in funding Garage development,
          either through donation or support contract,
          please <a href="mailto:garagehq@deuxfleurs.fr">get in touch with us</a>.
        </p>
        <p>
          <img src="https://garagehq.deuxfleurs.fr/images/ngi-pointer-eu.png" alt="NGI Pointers">
        </p>
        <p>
         <img src="https://garagehq.deuxfleurs.fr/images/nlnet.svg" alt="NLnet logo">
         <img src="https://garagehq.deuxfleurs.fr/images/NGI0Entrust_tag.svg" alt="NGI0 Entrust logo">
        </p>
        <p>This project has received funding from the European Union's Horizon 2021 research and innovation programme
          within the framework of the NGI-POINTER Project funded under grant agreement N° 871528.</p>
        <p>This project has received funding from the NGI0
          Entrust Fund, a fund established by NLnet with financial support from the
          European Commission's Next Generation Internet programme, under the aegis of DG
          Communications Networks, Content and Technology under grant agreement No
          101069594.
        </p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I mapped almost every USA traffic death in the 21st century (501 pts)]]></title>
            <link>https://roadway.report</link>
            <guid>41012443</guid>
            <pubDate>Fri, 19 Jul 2024 23:16:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://roadway.report">https://roadway.report</a>, See on <a href="https://news.ycombinator.com/item?id=41012443">Hacker News</a></p>
Couldn't get https://roadway.report: Error: connect ECONNREFUSED 2600:3c00::f03c:94ff:fe0d:a614:443]]></description>
        </item>
        <item>
            <title><![CDATA[Multisatellite data depicts a record-breaking methane leak from a well blowout (245 pts)]]></title>
            <link>https://pubs.acs.org/doi/10.1021/acs.estlett.4c00399</link>
            <guid>41012193</guid>
            <pubDate>Fri, 19 Jul 2024 22:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pubs.acs.org/doi/10.1021/acs.estlett.4c00399">https://pubs.acs.org/doi/10.1021/acs.estlett.4c00399</a>, See on <a href="https://news.ycombinator.com/item?id=41012193">Hacker News</a></p>
Couldn't get https://pubs.acs.org/doi/10.1021/acs.estlett.4c00399: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The European Union must keep funding free software (127 pts)]]></title>
            <link>https://pad.public.cat/lettre-NCP-NGI</link>
            <guid>41010458</guid>
            <pubDate>Fri, 19 Jul 2024 19:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pad.public.cat/lettre-NCP-NGI">https://pad.public.cat/lettre-NCP-NGI</a>, See on <a href="https://news.ycombinator.com/item?id=41010458">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <nav>
    <!-- Brand and toggle get grouped for better mobile display -->
    <div>
        
        
        <p><a href="https://pad.public.cat/" title="HedgeDoc">
            <img src="https://pad.public.cat/banner/banner_h_bw.svg" alt="HedgeDoc">
            <img src="https://pad.public.cat/banner/banner_h_wb.svg" alt="HedgeDoc">
        </a></p><div>
            <ul role="menu" aria-labelledby="menu">
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/new" target="_blank" rel="noopener"><i></i> New</a>
                </li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_blank" rel="noopener"> Publish</a>
                </li>
                <li></li>
                <li>Extra</li>
                <li role="presentation"><a role="menuitem" tabindex="-1" data-toggle="modal" data-target="#revisionModal"><i></i> Revision</a>
                </li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_blank" rel="noopener"><i></i> Slide Mode</a>
                </li>
                
                <li></li>
                <li>Import</li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Dropbox</a>
                </li>
                <li role="presentation"><a role="menuitem" href="https://pad.public.cat/#" data-toggle="modal" data-target="#gistImportModal"><i></i> Gist</a>
                </li>
                
                <li role="presentation"><a role="menuitem" href="https://pad.public.cat/#" data-toggle="modal" data-target="#clipboardModal"><i></i> Clipboard</a>
                </li>
                <li></li>
                <li>Download</li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Markdown</a>
                </li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> HTML</a>
                </li>
                <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Raw HTML</a>
                </li>
                <li></li>
                <li role="presentation"><a role="menuitem" href="https://pad.public.cat/#" data-toggle="modal" data-target=".help-modal"><i></i> Help</a>
                </li>
            </ul>
            
            </div>
    </div>
    <div>
        <ul>
            
            
            <span title="Help" data-toggle="modal" data-target=".help-modal">
                <i></i>
            </span>
        </ul>
        <ul>
            <li id="online-user-list">
                <a data-toggle="dropdown">
                    <span><i></i> OFFLINE</span>
                </a>
                <ul role="menu" aria-labelledby="menu">
                </ul>
            </li>
        </ul>
        <ul>
            <li>
                <a href="https://pad.public.cat/new" target="_blank" rel="noopener">
                    <i></i> New
                </a>
            </li>
            <li>
                <a href="https://pad.public.cat/#" target="_blank" rel="noopener">
                     Publish
                </a>
            </li>
            <li>
                <a data-toggle="dropdown">
                    Menu <i></i>
                </a>
                <ul role="menu" aria-labelledby="menu">
                    <li>Extra</li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" data-toggle="modal" data-target="#revisionModal"><i></i> Revision</a>
                    </li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_blank" rel="noopener"><i></i> Slide Mode</a>
                    </li>
                    
                    <li></li>
                    <li>Import</li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Dropbox</a>
                    </li>
                    <li role="presentation"><a role="menuitem" href="https://pad.public.cat/#" data-toggle="modal" data-target="#gistImportModal"><i></i> Gist</a>
                    </li>
                    
                    <li role="presentation"><a role="menuitem" href="https://pad.public.cat/#" data-toggle="modal" data-target="#clipboardModal"><i></i> Clipboard</a>
                    </li>
                    <li></li>
                    <li>Download</li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Markdown</a>
                    </li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> HTML</a>
                    </li>
                    <li role="presentation"><a role="menuitem" tabindex="-1" href="https://pad.public.cat/#" target="_self"><i></i> Raw HTML</a>
                    </li>
                </ul>
            </li>
        </ul>
    </div>
</nav>


    
<!-- clipboard modal -->

<!-- locked modal -->

<!-- limit modal -->

<!-- message modal -->

<!-- gist import modal -->

<!-- snippet import modal -->

<!-- snippet export modal -->

<!-- delete modal -->

<!-- refresh modal -->


<!-- signin modal -->


<!-- help modal -->



<!-- revision modal -->


    








</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI paid for by Ads – the GPT-4o mini inflection point (234 pts)]]></title>
            <link>https://batchmon.com/blog/ai-cheaper-than-ads/</link>
            <guid>41010188</guid>
            <pubDate>Fri, 19 Jul 2024 19:28:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://batchmon.com/blog/ai-cheaper-than-ads/">https://batchmon.com/blog/ai-cheaper-than-ads/</a>, See on <a href="https://news.ycombinator.com/item?id=41010188">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>July 18, 2024</p></header><section itemprop="articleBody"><p>OpenAI <a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">recently announced</a> their gpt-4o mini model, at a price of $0.15 per 1 million input tokens, and $0.60 per 1 million output tokens.</p>
<p>This extremely low cost AI model has just passed an inflection point.</p>
<p>It's now possible to build dynamic, AI generated content entirely supported by ads.</p>
<center>
<blockquote><p lang="en" dir="ltr">Introducing GPT-4o mini! It’s our most intelligent and affordable small model, available today in the API. GPT-4o mini is significantly smarter and cheaper than GPT-3.5 Turbo.<a href="https://t.co/sqJsFEYHWq">https://t.co/sqJsFEYHWq</a> <a href="https://t.co/g6jMttp1mF">pic.twitter.com/g6jMttp1mF</a></p>— OpenAI Developers (@OpenAIDevs) <a href="https://twitter.com/OpenAIDevs/status/1813990748406317221?ref_src=twsrc%5Etfw">July 18, 2024</a></blockquote>
</center>
<h3>How much do publishers earn from ad impressions?</h3>
<p>The amount of money an ad impression generates varies significantly across display mediums and content categories.</p>
<p>But we can get a good heuristic from <a href="https://adsense.google.com/start/#calculator">Google's AdSense estimated revenue calculator</a>.</p>
<p>The calculator gives you an estimate for your annual ad revenue potential based upon your content category (Finance, Games, Health, etc...) and your monthly page views.</p>
<p>For example, putting in 50k page views a month, with a Finance category, gives a potential yearly earnings of $2,000.</p>
<p>I'm going to take the <strong>median</strong> across all categories, which is an estimated annual revenue of $1,550 for 50,000 monthly page views.</p>
<p>This is approximately <strong>~$0.00022 earned per page view</strong>.</p>
<h3>How much does it cost to generate AI content?</h3>
<p>Let's invent a blog that generates content in response to whatever the user types in the search bar.</p>
<p>We'll generate the article the user is looking for, on the fly. Will it be mostly nonsense? Probably. But let's go for it anyway, just to illustrate a point.</p>
<blockquote>
<p>user: "how to have my macbook audibly greet me whenever I flip it open"</p>
</blockquote>
<p>In order to facilitate this, we'll wrap the user's query around a prompt.</p>
<p>Below is the prompt we'll use.</p>
<div data-language="text"><pre><code>You are an excellent blog writer. You write blogs that rank well in search engines because you know about SEO and how to use highly relevant and popular keywords. Your blog posts are informative, and help users achieve what they are looking for.

You will receive queries from users searching for blog posts. You will create blog posts that matches their query, that are helpful, and that answer or are relevant to whatever they are searching for.

Respond with only the blog post.</code></pre></div>
<p>With this prompt, and the user query, we have <strong>119 input tokens</strong> according to <a href="https://platform.openai.com/playground/chat?models=gpt-4o-mini">OpenAI's Playground</a>.</p>
<p>The response generated by gpt4o-mini, is only <strong>829 output tokens</strong>.</p>
<div data-language="text"><pre><code># How to Make Your MacBook Audibly Greet You When You Flip It Open

If you want your MacBook to greet you with a chime or a specific sound every time you flip it open, it’s a fun way to personalize your device and make your daily interactions a bit more exciting. While macOS doesn’t come with a built-in feature to audibly greet you immediately upon opening the lid, there are a few creative workarounds to achieve a similar effect. In this blog post, we will discuss a couple of methods you can set up for your MacBook to greet you audibly.

## Method 1: Setting Up a Startup Sound

1. **System Preferences:**
   - Go to the Apple menu in the upper-left corner of your screen.
   - Select **System Preferences**.
   - Click on **Sound** and then navigate to the **Sound Effects** tab.
   
2. **Enable Startup Sound:**
   - Make sure the option “Play sound on startup” is checked. This way, your MacBook will play the selected sound every time you start it up.
   - Note: This method will only play sound when the MacBook is fully powered down and then opened again.

While this method does not greet you specifically upon opening the lid from sleep mode, it’s effective for a full startup.

## Method 2: Create an Automator App for a Custom Greeting

For more customization, you can use the Automator app to create your own greeting sound that plays when the MacBook wakes from sleep.

### Steps to Create Your Greeting:

1. **Open Automator:**
   - Search for **Automator** in Spotlight Search or find it in the Applications folder.

2. **Create New Document:**
   - Choose **New Document** and select **Application**.

3. **Use the Run Shell Script Action:**
   - In the sidebar, find **Utilities** and drag the **Run Shell Script** action to the main area.

4. **Enter the AppleScript Command:**
   - Replace the default script with the following:
     ```bash
     osascript -e 'tell app "System Events" to say "Welcome back!"'
     ```

5. **Choose Your Sound:**
   - If you want a specific sound file instead of a spoken greeting, use the following command instead:
     ```bash
     afplay /path/to/your/soundfile.mp3
     ```
   - Make sure you replace `/path/to/your/soundfile.mp3` with the actual file path of your chosen audio file.

6. **Save Your Application:**
   - Go to **File &gt; Save**, and name it something like “Greeting Sound.” Ensure it is saved in the Applications folder.

### Automating the Greeting Sound:

1. **Open System Preferences:**
   - Go to **System Preferences** and select **Users &amp; Groups**.

2. **Select Your User Account:**
   - Click on your username and select the **Login Items** tab.

3. **Add Your Automator App:**
   - Click the **“+”** button and navigate to the Greeting Sound app you created. Add it to the list.

Now, whenever your MacBook wakes from sleep, your personalized greeting sound will play.

## More Personalization Options

- **Use a Different Voice:** If you used the text-to-speech option, you can change the voice in **System Preferences** &gt; **Accessibility** &gt; **Spoken Content**.
- **Add More Sounds:** You can repeat the process for multiple sounds or greetings by creating separate Automator apps.

## Conclusion

By using the methods outlined above, you can add a personal touch to your MacBook experience. Whether you choose the simple startup sound or get creative with an Automator app, these options allow you to greet your MacBook (and yourself) every time you open it. So, go ahead and set it up, and enjoy your daily welcome back! 

Feel free to share your own unique greeting sounds or any additional tips in the comments below!</code></pre></div>
<p>Let's calculate how much we paid for this article.</p>
<table>
<thead>
<tr>
<th>Token Type</th>
<th>Number of Tokens</th>
<th>Cost per 1 Million Tokens</th>
<th>Calculated Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input Tokens</td>
<td>119</td>
<td>$0.15</td>
<td>$0.00001785</td>
</tr>
<tr>
<td>Output Tokens</td>
<td>829</td>
<td>$0.60</td>
<td>$0.0004974</td>
</tr>
<tr>
<td><strong>Total Cost</strong></td>
<td></td>
<td></td>
<td><strong>$0.00051525</strong></td>
</tr>
</tbody>
</table>
<p>The cost to generate the article was <strong>$0.00051525</strong>. And it wasn't half-bad.</p>
<h3>Ad impression vs AI cost.</h3>
<p>You can probably see where I'm going with this now.</p>
<p>For that blog post, we might earn <strong>~$0.00022</strong> for the single page impression from the user that requested it.</p>
<p>Meanwhile, the blog post itself, had a cost of <strong>$0.00051525</strong> to generate.</p>
<p>We made a net profit of $0.00022 - $0.00051525 = <strong>$-0.00029525</strong>!</p>
<p>Woohoo, we lost money! We're going to be rich!</p>
<p>Joking aside, let's imagine that blog post receives <strong>only 5 page views</strong> throughout its entire lifetime, which is a pretty conservative estimate to make.</p>
<p>Now, we'll earn $0.00022 * 5 = <strong>$0.0011</strong>.</p>
<p>Subtracting our cost, $0.0011 - $0.00051525 = <strong>$0.00058475</strong>.</p>
<p>That's <strong>5.8 hundreths of a penny</strong>. Don't go spending it all in one place.</p>
<h2>Is this going to actually happen?</h2>
<p>Will the future of the internet be entirely dynamically generated AI blogs in response to user queries?</p>
<p>I don't know. I hope not. But the internet has been on a <a href="https://en.wikipedia.org/wiki/Enshittification">downward trend for a while now</a>.</p>
<p>Most of the internet is probably already SEO content blogspam generated by cheap copywriters.</p>
<h2>Is anyone doing this now?</h2>
<p>In a fun way, yes, check out <a href="https://websim.ai/">Websim</a> which uses LLMs to dynamically generate an alternative internet. It's a "web simulator" brought to you by AI.</p>
<p>They're not making money though. There aren't any ads (yet).</p></section><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Never Update Anything (159 pts)]]></title>
            <link>https://blog.kronis.dev/articles/never-update-anything</link>
            <guid>41009942</guid>
            <pubDate>Fri, 19 Jul 2024 19:07:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kronis.dev/articles/never-update-anything">https://blog.kronis.dev/articles/never-update-anything</a>, See on <a href="https://news.ycombinator.com/item?id=41009942">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="blog-hero">
    
    <section>
        
<p>Here's a fair warning: this article is <a href="https://en.wikipedia.org/wiki/Reductio_ad_absurdum">reductio ad absurdum</a>, therefore you shouldn't take it as gospel. However, i do believe that this point of view is extreme enough that it usually gets shut down immediately, yet doesn't have any frank discussion about it, which makes it the perfect subject for me to write about! To reiterate, i'm not suggesting that you go out there after reading this and never update any of your production software, merely consider the points that are offered here.</p>
<p>So, as the article title suggests, you should never update anything. Not your OS. Not your libraries in your software project. Not your tools. What would make someone come to this controversial idea? Actually trying to do that, of course! </p>
<p>When you're telling your colleagues that you can't really work because Windows or JetBrains IDEs need to install some updates, they'll give you understanding, yet annoyed glances. When you tell clients that you cannot ship software because first you need to spend a few days or weeks refactoring software to keep up with the latest library releases, they will express their displeasure at you and will probably look elsewhere for someone who won't care about updates. When your company won't be the first to market, because about 20% of your total development capacity needs to spent on keeping up with the technical debt, which is slowly forced upon by the industry, while another 20% of the effort needs to go to writing and maintaining a test suite, the company will suffer as a result. And once you actually do get the buy-in to update the components and when it turns out that migrating from Spring to Spring Boot is actually a herculean effort that means carrying over about 50 dependencies of a legacy Java project that has about 1 million SLoC, during which you also discover that at least 20-30 of those are painfully out of date, then you'll just start writing blog posts like this.</p>
<p>My premise is that updates are a massive waste of time, most of the time. Obviously, someone will jump out and say that "Hey, if you don't update, your Windows XP installation will get added to a botnet in less than a week," and they'll also be right at the same time. </p>
<h3>Types of updates are the problem</h3>
<p>The problem here is that we never differentiate between the types of updates properly: </p>
<ul>
<li>major leaps in the development of the software which add new features</li>
<li>security updates that don't change any actual functionality apart from the security fix</li>
<li>bug fixes that should not alter any functionality in significant ways</li>
<li>small backwards compatible feature updates that are essentially opt in</li>
</ul>
<p>There are plenty of things that you might want to feasibly change and update without any of the other functionality being altered. Actually, the situation is so bad in that regard, that most if not all of our modern software only ever has feature updates which sooner or later will have breaking changes in them. Otherwise, if you wanted to eliminate the possibility of running into breaking changes entirely, the development of any library would look like this:</p>
<p><img alt="how updates would look" src="https://blog.kronis.dev/images/h/o/w/-/u/how-updates-would-look-aff7472e.jpeg"></p>
<p>In the image, we see that we have major releases (with the "V" prefix), for example, we'd have MySQL 5, that would eventually be updated to MySQL 6, MySQL 7 and MySQL 8 (which is funny, if you know anything about how that actually worked out). Esentially, you'd have a few large releases, that represent both new features being added, as well as breaking changes. Then, you have the minor versions which introduce new functionaly (with the "f" prefix) and patches (with the "s" prefix) which in this case would mean security fixes. </p>
<p>Essentially, i'm describing <a href="https://en.wikipedia.org/wiki/Software_versioning">semantic versioning</a>, where this scheme would be approximately <code>V.f.s</code>, where you have a clear distinction between the major, minor and patch versions. However, instead of abandoning minor releases, you'd have to keep them up to date, since in practice different minor releases are not always compatible. If you wanted to support all of the versions of your software without forcing your users to use the new features, it would mean maintaining a new instance of your codebase for every minor release in existence. And in this case we're also simplifying things, because we assume that the patch versions will never break anything, which would probably mean that we need to preserve non-security related bugs and only fix them across minor releases.</p>
<p>You'd have to backport any and all security fixes from your newest versions, should the older ones also be affected. For example, if you discover a problem in V5.2.15 and fix it in V5.2.16, then you'd have to port these changes back to the current V5.1.X version and V5.0.X version, which is probably doable when you have 3 releases, but less so with 30.</p>
<p>And it goes the other way around, if you discover a problem in one of your older releases and the newer ones are also affected, then you have to port the changes forwards. For example, if you discover a problem in V5.0.14 and fix it in V5.0.15, then you'd have to port these changes forwards to the current V5.1.X and V5.2.X versions, where you run into the same problem as above.</p>
<p>In practice, things almost never work like that because that necessitates too much work. If you tried doing that, your issue tracking software could look like this:</p>
<pre><code>Issue: MYSOFT-3401
Description: Security breakage in $FOO module.
Assignee: You
Status: Ready to test

Versions affected:
- V7.6.245
- V7.5.267
- ... (down to V7.0.X)
- V6.10.315
- V6.9.326
- ... (down to V6.0.X)
- V5.14.421
- V5.13.442
- ... (down to V5.0.X)

Fixed in:
- V7.6.246
- V7.5.268
- ... (down to V7.0.X)
- V6.10.316
- V6.9.327
- ... (down to V6.0.X)
- V5.14.422
- V5.13.443
- ... (down to V5.0.X)</code></pre>
<p>Of course, testing all of that would be interesting, as would fixing further issues. Imagine having to do this for every single bug report and change. You'd spend days if not weeks fixing even trivial bugs if you'd have to support every single release of your software. That's why a lot of companies just drop support for older packages and leave people with no updates at all in cases where a minor version actually does break something, which isn't as much solving the problem, as it is simply sweeping it under the rug. </p>
<p>I'm sure that some of them would perhaps want to update their older versions, but it simply isn't feasible, perhaps apart from supporting the major version as a whole and forcing people to update to the newest minor versions to keep getting support. So in reality, the list of supported versions would indeed be just the last minor releases in the first example above, which would look a bit like the following:</p>
<p><img alt="actual updates are more like" src="https://blog.kronis.dev/images/a/c/t/u/a/actual-updates-are-more-like-e7f2dfac.jpeg"></p>
<p>More doable, but still not good enough in my mind - minor versions are for new features, which you don't necessarily want. My experience shows that oftentimes these new and supposedly backwards compatible features still break old functionality. Perhaps it's due to some refactoring that was needed, other times there were bugs fixed that old code relied upon and assumed to be the right way to do things. </p>
<p>My pain is that you'll never actually know how far you can update, seeing as the breaking changes will get you sooner or later, even if it's supposed to just be a bug fix. In reality, you might find that you can only run your software with a subset of the released versions (orange being what you have now, green what you can update to without breakages, red being everything that won't work):</p>
<p><img alt="how far you can update without breakages" src="https://blog.kronis.dev/images/h/o/w/-/f/how-far-you-can-update-before-breakages-618dd6ac.jpeg"></p>
<p>Now, the understandable argument here is: "Breaking changes are inevitable, you should just update your code." which is fair, but at the same time kind of useless. The industry shows that there are still plenty of projects that are stuck with JDK 8 and MySQL 5.7, or even a better example, old PHP versions like 5.6.40 and realistically cannot be updated and eventually will receive no security updates either, because all of that is simply too hard. And good luck with trying to tell your clients that now you'll probably need to alter or rewrite a huge portion of your code that uses the now deprecated or removed packages - oftentimes they simply won't understand that code rots with time.</p>
<p>Worse yet, those that don't care about semantic versioning don't even attempt to keep track of all of this stuff - i've seen projects out there in the wild, where V6.9.0 is always followed by V7.0.0 and V7.0.1 is code for "we screwed up the previous release, so this is just a hotfix", plenty of people and orgs out there just look at version numbers like something to put in Jira and get paid for, rather than a measure of what the software is compatible with.</p>
<h3>Noone wants updates</h3>
<p>But that's just the tip of the iceberg. I think i've briefly described while backporting security fixes and such is pretty hard, even though some operating systems still try to do that. Now, here's a story about why updates are actually bad. In a word: breaking changes. In the aforementioned Spring migration, i updated the <a href="https://flywaydb.org/">Flyway</a> version and ran into the following message:</p>
<pre><code>org.flywaydb.core.internal.license.FlywayEditionUpgradeRequiredException: Flyway Teams Edition or Oracle upgrade required: Oracle OLD_VERSION is no longer supported by Flyway Community Edition, but still supported by Flyway Teams Edition.</code></pre>
<p>I think that this is the inevitable future of software. "Want support for older versions of stuff that you're stuck with because of organizational reasons beyond your control? Sure, pay us!" If you look at the pricing page, you actually see that you'd need to part with 3000 USD for that sort of a license:</p>
<p><img alt="flyway costs" src="https://blog.kronis.dev/images/f/l/w/a/y/flway-costs-0bd2cc78.jpeg"></p>
<p>Now, i'm using this as an example for intentionally breaking support for older versions in a way that will hopefully (from the company's point of view) lead to them dying off and therefore the companies won't need to explicitly support them for a long time, thus attempting to solve the problem above. However, there are also plenty of cases out there, where updates introduce other breaking changes, oftentimes being forced upon the user against their will!</p>
<p>For example, i want to use Flyway, but i don't want to be forced to use a version, which drops support for the DB that i need to use. And yet, i wasn't even consulted about this, since the newest version is mandated by Spring Boot:</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.flywaydb&lt;/groupId&gt;
    &lt;artifactId&gt;flyway-core&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
<p>There are plenty of cases out there like this as well! For example, Docker Desktop doesn't let you decide whether you want updates or not, unless you pay them:</p>
<p><img alt="docker desktop updates" src="https://blog.kronis.dev/images/d/o/c/k/e/docker-desktop-updates-6f750760.png"></p>
<p>And i'm sure that we've all also heard plenty of other horror stories of this very same trend, be it <a href="https://www.howtogeek.com/670084/what-you-need-to-know-about-snaps-on-ubuntu-20.04/">Ubuntu forcing updates with snap packages</a>, or Windows 7 forcefully upgrading to newer releases when people step away from their computers for a bit.</p>
<p>In a word, the way how companies approach updates nowadays suck, especially when they break things!</p>
<h3>Updates are bad</h3>
<p>All you need to do is go to the "Everything is Broken" section of my blog and you will see plenty of cases of updates breaking things. In the current year, it's gotten to the point where i treat every update like a possibly completely clean wipe and install from nothing. Therefore, backups are of the utmost importance and every update needs to have at least an hour or two set aside for when things will inevitably go wrong, as they oftentimes have in the past.</p>
<p>But here's the thing - if i don't want to rely on <a href="http://www.gnu.org/philosophy/who-does-that-server-really-serve.html">SaaSS</a>, then i have to host and manage my software by myself. If i want to do that, then i need to handle the updates myself as well. Every update takes a significant amount of time and potentially can break things. And, even more importantly, if there are any non-standard configuration changes done (even the theme of this very blog), then things become more likely to break and waste my time. But i don't have unlimited amounts of time. </p>
<p>Actually, i don't have enough time to do my day job, learn new technologies for when it inevitably becomes stale and would otherwise lead to my career death, to also help my aging parents around the countryside estate with various chores, at the same time educate myself on both things in the industry and news in the world, as well as spend anywhere between 1-2 hours working out every day (a weight loss and personal wellness effort which seems to be working and about which i'll write a post some day) and have any sort of enjoyment of life in general, for example, by reading a sci-fi book in the evenings.</p>
<p>Ergo, i cannot update. Ergo, companies cannot ship features AND handle all of the updates, without having enough tests to catch all of the problems, which they will never be able to do no matter how good their tests are without slowing down their development pace to the point where they are no longer competitive.</p>
<p>Breaking feature updates of any sort are a nuisance and a direct impediment to progress more often than they're not and the more updates there are to be done, the less will be done. So don't update!</p>
<p>For example, to see why we shouldn't update software, let's take a look at <a href="https://www.npmjs.com/package/react">React</a>. To date, it has over 500 versions that have been released. No, not development snapshots (even though some experimental new versions are included), publically released versions that need to be installed, managed and coped with:</p>
<p><img alt="react versions" src="https://blog.kronis.dev/images/r/e/a/c/t/react-versions-1c6d1bd1.jpeg"></p>
<p>But once again, that's not the full story. Creating a simple React app with <code>create-react-app</code> makes us fetch an absolutely absurd amount of code, files and folders under <code>node_modules</code>:</p>
<p><img alt="node-modules" src="https://blog.kronis.dev/images/n/o/d/e/-/node-modules-4f8c2cd7.jpeg"></p>
<p>The idea of anyone ever understanding what's going on in there, or even auditing the security of all of it, is simply absurd! Don't believe me? Have a look at a dependency graph of this newly created "Hello world" project:</p>
<p><img alt="dependencies for a simple project" src="https://blog.kronis.dev/images/d/e/p/e/n/dependencies-for-a-simple-app-3da0fdaf.jpeg"></p>
<p>There are almost 1500 different modules in there! Many of those will have updates eventually. Many of those will also have breaking changes. You will run into problems with that. And even if you don't, the chances of something malicious getting in there, or for the development stack to get too large for you to be able to explore it is a question of time, rather one of probability. Once again, do not update!</p>
<h3>A more stable world without updates</h3>
<p>Let's look at some software that's the exact opposite. It's stable, doesn't have many breaking changes, and comes with "batteries included". No, i'm not talking about Angular, because even that's a mess in comparison, i'm talking about the <a href="https://www.lazarus-ide.org/">Lazarus IDE</a>, the modern and perhaps the only way to write Pascal code!</p>
<p><img alt="lazarus ide" src="https://blog.kronis.dev/images/l/a/z/a/r/lazarus-ide-e66e70cb.jpeg"></p>
<p>But it's not just a tool for writing code, instead, it does something a bit more amazing and peculiar. It also includes the <a href="https://en.wikipedia.org/wiki/Lazarus_Component_Library">Lazarus Component Library</a>, a large package of components and classes that concern not only GUI development (which, by the way, is abstracted away from the platforms entirely), but also offers lots of useful functionality that would otherwise need to be installed separately in almost any other tech stack out there:</p>
<p><img alt="lazarus component library" src="https://blog.kronis.dev/images/l/a/z/a/r/lazarus-component-library-ec79c91c.png"></p>
<p>Consider a scenario in which you want a MySQL driver for your app. In npm, you install it with bunches of dependencies. In Java, you pull it down with Maven or Gradle. In Python, you probably mess around with native extensions and have to install additional packages for your OS/container for it to even work. But with Lazarus, you drop it from the component palette into your application and are on your way. More platforms should be like that! Only support a known and trusted subset of software packages, keep them in tree and update them with the larger software package, in this case, the IDE.</p>
<p>Some of you might realize that what i'm describing is actually a lot like the <a href="https://docs.freebsd.org/en/books/handbook/ports/">FreeBSD approach to packages</a> - a stable enclave of "good software", that's optionally built upon by "ports", external and less table packages which the user will have to install themselves while being aware that those aren't supported. This sort of discouragement is exactly what most of the developers behind npm should have experienced more of! Same for React, Angular and most other technologies out there!</p>
<p>What i'm saying is that most of the integrations, dependencies and other software should be kept "in-tree" for most tools and packages out there. To hell with dynamic linking, use stable and minimalistic packages where needed, much like Windows does instead of Linux. Not only that, but put anything and everything you will ever need within the standard library or one or two large additional libraries. When eventually people will want to do more, provide pushback and curb their enthusiasm, make them do less instead of more. Slow down their pace of development and therefore also updates, preferring stable and good software in 5 to 10 years, as opposed to a half baked SaaS trap in 2 years, which will stop being supported in 4. Yes, at this point i'm getting into why this probably won't be possible in our current society, but my thoughts on the subject are unchanged by this reality.</p>
<h3>It's already happening</h3>
<p>But that's not to say that large, breaking releases aren't already happening and that people aren't sticking with the more stable stuff. Just look at <a href="https://snyk.io/blog/developers-dont-want-to-leave-java-8-as-64-hold-firm-on-their-preferred-release/">JDK versions that are used</a> in the industry:</p>
<p><img alt="java versions" src="https://blog.kronis.dev/images/j/a/v/a/-/java-versions-dca7d97c.jpeg"></p>
<p>The majority of existing projects out there are stuck with JDK 8, either due to their dependencies, their requirements, the ecosystem surrounding them, people not knowing about the benefits of the newer versions or simply not caring, or maybe the whole migration process being so time consuming, complicated and expensive that most companies out there simply don't want to touch the idea of doing that with a 10 foot pole. Essentially, what i described above is happening, but for all of the wrong reasons!</p>
<p>That brings me to the next point - situations like that are unavoidable. Sooner or later, there will be a significant amount of projects out there that will be stuck on old versions. There will be plenty of .NET 2.0 projects out there that will be running on dated installations of Windows Server 2012, instead of running the latest cross platform .NET Core or nowadays just .NET 5+. There will be plenty of old Java projects out there, or old PHP 5 projects out there and so on.</p>
<p>And my argument is not that this should be the expected outcome, but rather that it's something inevitable. Therefore, we should prepare for the eventual mess of legacy software, with entire languages possibly dying out and there being <a href="https://www.shrm.org/hr-today/news/hr-news/pages/desperate-need-for-cobol-programmers-underlines-importance-of-workforce-planning.aspx">significant issues in finding developers for them</a>, once it's discovered that there's actually software that's mission critical running in some old forgotten server room. And the easier we'll make dealing with old code for ourselves, the easier our lives will be - the more focus we'll put on truly non-breaking security updates that keep your dated software alive and running well, the better our future will be.</p>
<p>To that end, it's actually imperative that we slow down our development and the speed of updates, which add new features.</p>
<h3>Forcing things to slow down</h3>
<p>It's important that code written 20 years in the future remain vaguely similar to what we have now, so that old codebases can be recognized. Think Java Streams API, over syntactic sugar that changes how the actual language works. Think more along the lines of a stable base, that's well documented, thoroughly tested and <a href="https://www.youtube.com/watch?v=lFRKrHE8oPo&amp;t=518s">helps you use it with its discoverability</a>, instead of making you do some long forgotten Maven rituals that are like something out of Warhammer 40k, because noone bothered to write documentation in the pursuit of agility.</p>
<p>Bring back the old days where we engineered software to be used long term, instead of the current day world of: "Move fast and break things... oh, and don't bother thinking about what'll happen in 10 years, because your CV will be full of bleeding edge stuff, your bank account will be loaded and the troubles with most of the projects behind you won't be the slightest of your concerns." Realistically, you probably don't care about this stuff, but on the grand scale of things, perhaps you should.</p>
<p>I don't know about you, but i think that we shouldn't even need containers for reproducible environments in the first place. We should take a page out of the BSD operating system group book, instead of the GNU/Linux distros that are patched together out of bunches of different pieces of software of vastly varying quality. We shouldn't bend to the whims of the businesses which want things done yesterday. We should strive for the standards of engineering, where we are in control of the stacks that we work with and actually know what's going on inside of them.</p>
<p>Why do we need a new Java version every year and to only support the LTS ones for 5 years? Why do we need multiple Ubuntu releases per year and to only support the LTS ones for 5 years? Why not a new release every 5 years with everything else between being just patches and non breaking changes and a new major release every 20 years instead?</p>
<p>If things don't work out that way, then eventually we'll just have bunches of clueless code monkeys that execute npm commands that they don't understand to use frameworks and mechanisms which they have no hope of understanding to create as much value as quickly possible in the short period before all of that goes to hell and there's the eventual breakdown of nothing working and noone having any idea of why. I'm exaggerating slightly, but sooner or later software projects out there will exceed the cognitive capabilities of any single person - the only question is whether that will happen in 50 or 500 years.</p>
<h3>What to actually do now?</h3>
<p>Don't choose <a href="https://vimeo.com/156706113">Clusterpoint</a> for your project, which actually died in just a few years and now needs to be maintained in one of the legacy projects that i'm stuck in. Instead, pick <a href="https://www.postgresql.org/">PostgreSQL</a> and use it for <a href="https://www.postgresql.org/docs/release/">more than 20 years</a>. Realistically, you can't avoid updates entirely, but you can at least try to decrease the frequency of them that you'll run into and will have to deal with.</p>
<p>Use self contained packages and only use them for the things that they are good for - for example, Ruby on Rails for a simple webapp will be a better choice than stitching together 20 different libraries. Having the freedom of choice in the library case will cause more problems than its worth.</p>
<p>And lastly, <a href="http://boringtechnology.club/">choose boring technology</a>. Only use software that you're sure will be supported in 10 years. Only use software, which has very few "unknown unknowns". Only use software, where the development pace has slowed down to a reasonable degree, as opposed to React pulling a sneaky on everyone and introducing hooks, which was a pretty bad move, especially if you needed to migrate to them. </p>
<p>Use maintenance mode software:</p>
<ul>
<li>Debian over Fedora</li>
<li>Docker Swarm over Kubernetes</li>
<li>Java over Go</li>
<li>Angular over React</li>
</ul>
<p>Of course, this only applies to projects that you're about to start. Chances are, that if you're working in the industry and will have to handle codebases written by others, then <a href="https://earthly.dev/blog/brown-green-language/">preferring brownfield technologies will make you less happy</a>, given that there will be more bad ones out there. Your mileage may vary and don't expect all of the answers here.</p>
<p>As for the actual updates: the above approaches should decrease the frequency at which they need to be done. That said, the title of the article is not entirely honest - do install security updates and do install updates to the LTS software that you're using, be it Ubuntu LTS, Unity LTS, Java 11, or anything else... Just be sure that you have backups that work before doing that!</p>
<h3>Update</h3>
<p>I've cleaned the text up a little bit and have decided to extract an idea about a versioning scheme out of the main body of text.</p>
<p>I believe that software could benefit from something more finely grained than semantic versioning. </p>
<p>Perhaps an alternate scheme, that goes more into detail about what's included in any given release:</p>
<ul>
<li>major new functionality changes</li>
<li>minor, backwards compatible'ish functionality additions</li>
<li>patch, bug fixes that could still break code that's written with them in mind</li>
<li>security, fixes that should not affect code bugs as long as those do not concern security exploits</li>
</ul>
<p>Maybe it would be possible to have those patch versions be globally unique, so that you'd know that your software <code>V5.152.4567.7213</code> has had 5 major versions released so far, 152 feature releases across those major versions, 4567 bug fixes to date and 7213 security fixes? Thus, you could tie them to Jira ticket numbers or what have you, though it would probably break some ordering of these versions somewhere, so i'm not entirely sure about that. Granted, i can't actually tell whether adding that sort of complexity would actually be good for anyone, seeing as people seem to have trouble keeping themselves to the standards set forth by semantic versioning already. </p>
<h3>Update #2</h3>
<p>I've actually written <a href="https://blog.kronis.dev/articles/stable-software-release-system">a separate article about how software versioning could be done</a>, with a larger focus on stability and backwards compatibility. I still think that i'm quite there yet in regards to the quality of my writing, but it should serve as a conceptual alternative to semver, maybe it's worth a look at?</p>
<p>Someone actually posted this article on Hacker News, though sadly i missed it due to being busy with my work. Nonetheless, you can go to the thread and <a href="https://bit.ly/30i6Eep">read my comment</a>, which should provide a real world example of why breaking changes and large generational shifts can be a very time consuming thing.</p>
<p>To sum up everything above in a single sentence:</p>
<blockquote>
<p>In my eyes it could be pretty nice to have a framework version that's supported for 10-20 years and is so stable that it can be used with little to no changes for the entire expected lifetime of a system.</p>
</blockquote>
    </section>
    <i id="to-start"></i>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Happened to Bert and T5? (188 pts)]]></title>
            <link>https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising</link>
            <guid>41009803</guid>
            <pubDate>Fri, 19 Jul 2024 18:54:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising">https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising</a>, See on <a href="https://news.ycombinator.com/item?id=41009803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-0370f11da47205b70fe2">
  <p>The people who worked on language and NLP about 5+ years ago are left scratching their heads about where all the encoder models went. If BERT worked so well, why not scale it? What happened to encoder-decoders or encoder-only models?&nbsp;</p><p>Today I try to unpack all that is going on, in this new era of LLMs. I Hope this post will be helpful. </p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721063358593_12105">
  <p>Few months ago I was also writing a long tweet-reply to this <a href="https://x.com/srush_nlp/status/1779938508578165198" target="_blank">tweet</a> by <a href="https://x.com/srush_nlp" target="_blank">@srush_nlp</a> at some point. Then the tweet got deleted because I closed the tab by accident.¯\_(ツ)_/¯  I promised to write it as a blog post some day. <br></p><div><p>So here it is!</p><p>This will be the first part of a series of blog posts I plan to write about model architectures in the era of LLMs (I hope).&nbsp;</p></div><h4><strong>A quick primer  (Skip connection to next section if you feel confident)</strong></h4><p>There are mainly three overarching paradigms of model architectures in the past couple of years. Encoder-only models (<em>e.g., BERT</em>), Encoder-Decoder models (<em>e.g., T5</em>) and decoder-only models (e.g., <em>GPT series</em>). People get confused a lot about this and people often have tons of misconceptions about these dichotomies and architectures so I’m hoping this post will help.</p><p>The first thing to really understand is that encoder-decoder models are actually still autoregressive models. A decoder in an encoder-decoder model is literally and fundamentally still a causal decoder. Instead of pre-filling a decoder model, some text can be offloaded to an encoder, which is then sent to the decoder via cross-attention. Yes, T5 models are also language models!</p><p>A variant of this is a Prefix Language model or PrefixLM <strong>architecture</strong>, which does almost the same thing minus the cross attention (<em>and some other small details like sharing weights between encoder/decoder plus not having no encoder bottleneck</em>). PrefixLMs are also sometimes known as non-casual decoders. In short, encoder-decoders, decoder-only models and PrefixLMs are not that different altogether!</p><p>In the latest excellent lecture by Hyung Won, he masterfully gave explanations about the relationship between these models. You can check it out <a href="https://x.com/hwchung27/status/1800676312916656592" target="_blank">here</a>. Good stuff.</p><p>Meanwhile, encoder-only models such as the OG BERT does denoising differently (i.e., in-place) and to some extent, rely on classification “task” heads to do anything useful with the base model after pretraining. Denoising objective was later adopted in models like T5 in an “adapted style” using the sequence to sequence format.</p><p>To this end, it is worth noting that denoising in T5 is not exactly a new objective function per se (in the machine learning sense) but rather a data transformation across inputs, i.e., you can also train span corruption objective with a causal decoder too by the way!</p><p>People always assume encoder decoder models have to be denoising models partly because of the <em>overly representative</em> T5 model. However, <em>this is not always true.</em> You can train an encoder-decoder with a regular language modeling task (i.e.m, CLM). Conversely you can also train a causal decoder with the span corruption task. As I’ve said earlier, this is mostly a data transformation.</p><div><p>It is also worth to note that, generally speaking, an Encoder-Decoders of 2N parameters has the same compute cost as a decoder-only model of N parameters which gives it a different FLOP to parameter count ratio. This is just like “model sparsity” that is split across inputs and targets.</p><p>This is nothing new, and I didn’t come up with anything new here. It’s already in the 2019 T5 paper and reemphasized in the UL2 paper.&nbsp;</p></div><p>For now, glad to get this out of the way. Now onto objectives.</p><h4>On the denoising objective (does it not work? does it not scale? is it too easy?)</h4><p>The denoising objective I’m referring to is any variation of the “span corruption” task. This is sometimes known as “infilling” or “fill in the blank”. There are variations on how to express it (i.e., span length, randomness, sentinel tokens etc). But you get the gist.&nbsp;</p><p>While the denoising objective in BERT style models are mostly “in-place”, (e.g., classification head on top of mask tokens), the slightly more modern way is to do it “T5-style”, <em>ala</em> data transformation that can be processed by an encoder-decoder or decoder-only model. In such a data transformation, masked tokens are just “moved to the back” for the model for prediction.</p><p>The primary goal of pretraining is to build a useful internal representation that can be aligned for downstream tasks in the most efficient and effective way possible. The better the internal representations, the easier to use these learned representations for anything useful later. The simple next word prediction&nbsp; “causal language modeling” objective is known to do this very well and has served as the bread and butter of the LLM revolution. The question now at hand is whether the denoising objective is just as good.</p><p>From publicly available information, we know that T5-11B works pretty well even after being aligned/SFT-ed (Flan-T5 XXL’s MMLU score is 55+, which is more than decent for a model of this scale and of that time). Hence, we can make some conclusion that the transfer process (pretraining -&gt; alignment) of the denoising objective works relatively reasonably well at this scale.</p><p>My take is that denoising objectives are great but pretty insufficient as a standalone objective. A big drawback is because of a reason which we could call less “loss exposure”. In denoising objectives, only a small amount of tokens are being masked and gets learned as a result (i.e., taken into account in the loss). Conversely, in regular language modeling, this is close to 100%. This makes for pretty low sample efficiency per FLOP which makes denoising objectives hugely disadvantaged on a flop-basis comparison.&nbsp;</p><p>Another drawback is that denoising objectives are more unnatural than regular language modeling since it reformats the input/output in a strange way, making them a little awkward for few-shot learning. (It’s still possible to massage these models to do reasonably okay on few-shot tasks though). Hence, I believe denoising objectives should pretty much only be used as a complementary objective to regular language modeling.</p><h4>The early days of unification and why xBERTs went extinct</h4><p>The gradual phasing out of BERT-like models was an interesting phase that not many people talk about these days. It was subtle. This could also explain why we don’t see any mega large scale BERT models running around anymore. The reason? It was largely a matter of unification and shift in task/modeling paradigms. BERT-style models are cumbersome, but the real deprecation of BERT models was because people wanted to do all tasks at once, which led to a better way of doing denoising - using autoregressive models.</p><p>During 2018-2021, there was an implicit paradigm shift of single task finetuning to massively multi-task models. This slowly gravitated us towards the unified “SFT” models that we see today that are universal and general purpose. It was simply so hard to do this with BERT. I don’t think this has anything much to do with “denoising” at all. People simply found a way to re-express denoising pretraining tasks if they wanted to use such a model (i.e., T5) which made BERT-style models pretty much deprecated at this point because there is a strictly better alternative.</p><p>To be even more concrete, encoder-decoder and decoder-only models were able to express multiple tasks at once without the need for task specific classification heads. For Encoder-Decoders, if the decoder was getting in the way, researchers and engineers also began to find out that yanking out the encoder performed just as competitive as a BERT encoder. Moreover, it also retains the same bidirectional attention benefit that made BERT competitive over GPT models at small (often production) scale.&nbsp;</p><h4>The value of denoising objectives</h4><p>Denoising pretraining objective also learns to predict the next word in a similar way to regular language modeling. However, different from regular causal language modeling, a data transformation is applied to the sequence such that the model learns to “fill in the blanks” instead of simply predicting the naturally occuring left-to-right text.&nbsp;</p><p>Notably, denoising objectives are sometimes also called “infilling tasks” that are sometimes mashed together into pretraining together with regular language modeling tasks.</p><div><p>While the exact configuration and implementation details can vary, modern LLMs today may use a combination of language modeling and infilling in some capacity. It is actually interesting how this mixture of LM + infilling seemed to have been propagated around the same time (e.g., <a href="https://arxiv.org/abs/2205.05131"><span>UL2</span></a>, <a href="https://arxiv.org/pdf/2207.14255"><span>FIM</span></a>, <a href="https://arxiv.org/abs/2210.02414"><span>GLM</span></a>, <a href="https://arxiv.org/abs/2201.07520"><span>CM3</span></a>), with many groups bringing their own flavor of this mixture in some way. On a side note, the largest publicly disclosed &amp; reported model trained in this style is likely the <a href="https://arxiv.org/abs/2305.10403"><span>PaLM-2 model</span></a>.</p><p>It is also worth noting that pretraining task mixtures could be also stacked sequentially and does not necessarily have to be mixed concurrently, i.e., Flan-T5 originally trains on 1T span corruption tokens and switches out to 100B tokens of prefix language modeling objective before flan instruction tuning. To some extent, this qualifies as a mixed denoised/LM objective model. To be clear, prefix language modeling objective (not to be confused with architecture) is simply casual language modeling with a split point randomly determined and sent to the input side (with no loss and non-casual masking). </p><p>On a side’s note, infilling could have originated from the world of code LLMs, where filling in the blank was more of a feature desired by coding applications. Meanwhile, UL2 was motivated more by unifying the class of tasks that denoising objectives and bidirectional LLMs do well on with inherently generative tasks (such as summarization or open-ended generation). An advantage of this autoregressive style of denoising “shift to the back” is that it allows the model to not only learn longer range dependencies but also implicitly benefit from <em>non-explicit</em> bidirectional attention (since you would already have seen the future in order to fill in the blank).</p><p>Anecdotal experience is that denoising objectives learn representations that are better at certain classes of tasks, sometimes in a more sample efficient way. In the <a href="https://arxiv.org/abs/2210.11399"><span>U-PaLM</span></a> paper, we showed how a small amount of span corruption up-training changes behavior and emergence on a set of BIG-Bench tasks. On top of that, finetuning models trained with this objective generally result in better supervised fine-tuning models, especially at smaller scale.</p><p>When it comes to single-task finetuning, you can see the OG <a href="https://arxiv.org/abs/2204.02311" target="_blank">PaLM-1</a> 62B model gets defeated by a much smaller T5 model. Bidirectional attention + denoising objective packs a punch at a relatively small scale! I’m sure many practitioners see this happen these days as well, especially in production.</p></div><h4>What about bidirectional attention?</h4><div><p>Bidirectional attention is an interesting “inductive bias” for language models - one that is commonly conflated with objectives and model backbones. The usefulness of inductive biases changes at different compute regions and could have different effects on scaling curves at different compute regions. That said, it could be true that bidirectional doesn’t seem to matter that much at larger scales compared to smaller scales, or have different impacts on different tasks or modalities. For instance, <a href="https://arxiv.org/abs/2407.07726v1" target="_blank">PaliGemma</a> makes use of PrefixLM architectures.</p><p>As Hyung won also points out in his <a href="https://x.com/hwchung27/status/1800676312916656592" target="_blank">lecture</a>, PrefixLM models (decoder-only models with bidirectional attention) also have an issue with caching and are an intrinsic drawback with this type of architecture. However, I think there are many ways to work around this flaw which is out of scope for this post.</p></div><h4>Pros and Cons of Encoder-Decoder architectures</h4><div><p>Encoder-decoder architectures actually have some pros vs regular decoder-only models. The first case is where the encoder side is not restricted by a causal mask. To some extent, you can go crazy with the attention layers by doing aggressive pooling or any form of linear attention without worrying about the autoregressive design restriction. This is a good way to offload not so important “context” to an encoder. You can also make the encoder smaller, which is neat. </p><p>One example of how encoder-decoder architecture was necessary was in <a href="https://arxiv.org/abs/2106.12672" target="_blank">Charformer</a>, where we could go crazy on the encoder and mitigate the speed drawbacks of byte-level models. Encoder-side innovations allow quick wins without worrying about major resigns of the causal mask.&nbsp;</p></div><p>Meanwhile, one negative point of the encoder-decoder versus PrefixLM is that inputs and targets have to have fixed allocated budgets. For instance, if the input budget is 1024 tokens, the encoder side has to be padded to this value which causes a lot of potential for wasted compute. Conversely, in PrefixLM, input and targets can just be directly concatenated which mitigates this problem.</p><h4>Relevance to models today and key takeaways</h4><p>The ability to reason with inductive biases both at architectural and from a pre-training perspective is a critical aspect of being a competent LLM researcher and practitioner today. Understanding the fundamental nuances helps one to extrapolate and continue to innovate.</p><p>Here are my key takeaways:</p><ol data-rte-list="default"><li><p>Encoder-decoder and decoder-only models are both autoregressive models that have implementation-level differences and pros/cons. They are subtly different inductive biases. Optimal usage really depends on downstream use-case and pretty much application constraints. Meanwhile, for most LLM usage and niche use-cases aside, BERT style encoder models are mostly considered deprecated.</p></li><li><p>Denoising objectives are mostly complementary to CLM. They have just found their way as “supporting objectives” in pretraining. Training CLM with denoising objectives usually helps in some way. While this happens very frequently in code models (i.e., code infilling), it is not uncommon (though not mandatory) for general purpose models today still pretrain with CLM with some denoising objective.</p></li><li><p>Bidirectional attention helps a lot at smaller scales but is generally optional at larger scales. This is mostly anecdotal. I see bidirectional attention has a form of inductive bias, just like many other types of modifications to Transformer models.</p></li></ol><p>Finally, on to recap, we don’t see any scaled up xBERTs running around: BERT models got deprecated in favor of more flexible forms of denoising (autoregressive) T5 models. This is largely due to paradigm unification where people would like to perform any task with a general purpose model (as opposed to task specific model). Meanwhile, autoregressive denoising gets sometimes folded as side objectives to casual language models.&nbsp;</p><h4>Final words &amp; Acknowledgements</h4><div><p>It’s really fun to write about model architecture. I hope to write more about LLMs and AI research in general. </p><p>I thank Hyung Won Chung and Vinh Tran for feedback on this post.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The CrowdStrike file that broke everything was full of null characters (281 pts)]]></title>
            <link>https://twitter.com/jeremyphoward/status/1814364640127922499</link>
            <guid>41009740</guid>
            <pubDate>Fri, 19 Jul 2024 18:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/jeremyphoward/status/1814364640127922499">https://twitter.com/jeremyphoward/status/1814364640127922499</a>, See on <a href="https://news.ycombinator.com/item?id=41009740">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Opinion: I'd rather have a headphone jack and a microSD slot than AI in my phone (112 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41009359</link>
            <guid>41009359</guid>
            <pubDate>Fri, 19 Jul 2024 18:14:22 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41009359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="41009454"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009454" href="https://news.ycombinator.com/vote?id=41009454&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I agree 100%. And when people inevitably claim that the reason for eliminating the headphone jack is so you could have a phone that could withstand being dropped in water, I think back to the Samsung Galaxy S5 that I bought 10 years ago. It has a headphone jack, a microSD slot, and a user-removable battery, plus an IP67 rating.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41009730"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41009730" href="https://news.ycombinator.com/vote?id=41009730&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I'll also add that the S5 was a much more convenient size than the enormous phones they make these days, some of probably wouldn't even fit in my pocket.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41011459"><td></td></tr>
            <tr id="41011425"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41011425" href="https://news.ycombinator.com/vote?id=41011425&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p><a href="http://phandroid.com/2014/04/19/galaxy-s5-water-damage/amp/" rel="nofollow">http://phandroid.com/2014/04/19/galaxy-s5-water-damage/amp/</a></p><p>&gt; The Galaxy S5 is very good about reminding you close your charger door snugly and make sure your battery cover is snapped on COMPLETELY before continuing. This is a message you shouldn’t dismiss (although it allows you to) because the reminder is a good one. I can say with confidence that during both water tests my phone back cover and battery port were completely secured.</p><p>&gt; Somehow, though, water snuck its way into my battery.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="41009607"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009607" href="https://news.ycombinator.com/vote?id=41009607&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>To offer an alternative data point, I don't really want any of the above. Just make it cheaper, smaller, and with guaranteed security updates for as long as possible.</p><p>The only wired headphones I own are high-impedance """audiophile""" headphones, that a phone couldn't really drive in the first place.</p><p>As for storage, I don't do a whole lot on my phone except for messaging and looking things up on-the-go, none of which needs much in terms of storage space. I've had my current phone (iPhone SE3, 128GB) for over 2 years, and I've never even had to delete anything (and when the day comes, I'll transfer the contents of the photo gallery over to external storage).</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010181"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41010181" href="https://news.ycombinator.com/vote?id=41010181&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>3.5mm jack, microSD and removable batteries is the holy grail.</p><p>The only reason these aren't included anymore on flagship phones is because companies think they can upsell you on BT headphones, cloud storage plans and extended warranties. They're building for shareholder value, not the customer.</p><p>Plenty of midrange and low end phones still come with the jack and microSD, but removable batteries seem to be extinct.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41013741"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41013741" href="https://news.ycombinator.com/vote?id=41013741&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>Sony is making high end phones that have all these features, like the xperia line. The UI is a little wonky, and you have to degoogle the phone, but after that its pretty solid.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010200"><td></td></tr>
                  <tr id="41012479"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41012479" href="https://news.ycombinator.com/vote?id=41012479&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Maybe we should carry our phones around less often.</p><p>I carry a media player, like an iPod. 500GB sd card, balanced and unbalanced headphone outs, and actual physical buttons and knobs for control.</p><p>Phones can do everything, but there are too many compromises. Ebook readers, and media players do one thing very well.</p><p>You also get a lot of peace when you disconnect from apps, scrolling and notifications and just enjoy your music out in the world.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010028"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41010028" href="https://news.ycombinator.com/vote?id=41010028&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I've got a Sony Xperia phone from last year. It's got a headphone jack and sdcard slot, waterproof, latest chipset etc. Plus a very close to vanilla Android. Yet they sold so few that Sony are pulling out of the US phone market. It seems to me that folks who say they want those things don't actually want them that much.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41013593"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41013593" href="https://news.ycombinator.com/vote?id=41013593&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I definitely do, I have never bought a phone without a headphone jack. I feel like that will end soon though, as the line of phones I'm using seems to be dying, and it's the last of its kind.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010951"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010951" href="https://news.ycombinator.com/vote?id=41010951&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>&gt; It seems to me that folks who say they want those things don't actually want them that much.</p><p>On the contrary, we do. There's just not enough of us.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41013010"><td></td></tr>
                  <tr id="41010197"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010197" href="https://news.ycombinator.com/vote?id=41010197&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>Sony hasn't been relevant in the phone industry since the transition to smartphones. Samsung, Huawei, Lenovo and others sell millions of phones with these features, but the flagship models still exclude them.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41010435"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41010435" href="https://news.ycombinator.com/vote?id=41010435&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>The early Sony Android phones were available in stores. I remember the first smartphone I got was a Sony, and, compared to a friend's Samsung, it was really lovely, great screen, better feeling build quality. Maybe they never competed on price? I didn't even think about the brand back then, just chose the nicest one in the store.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="41013439"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41013439" href="https://news.ycombinator.com/vote?id=41013439&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Nobody wants a high-end android cameraphone where the camera firmware self-destructs when you unlock the bootloader.</p><p>For better or for worse, the android world is reliant on custom roms if you want long-term software support. Wiping the camera firmware is unacceptable given that reality.</p><p>Again, the whole custom rom thing is a bandaid patch on a shitty, user-hostile OS model that makes it nearly impossible to perform a vital function of the computing system (updates). The inability to deliver updates effectively is itself a symptom of a product defect here.  It would be better if we could require all companies to provide useful first-party support lifecycles for the products they release.</p><p>But sony is <i>deliberately</i> gutting the device’s functionality to prevent you from unlocking it and that’s unacceptable even among android devices. <i>If</i> you’re going to do this shitty custom rom model, vendors that decide to kill even the ability to try and use that bandaid are going to suffer poor sales.</p><p>I would love a high-end cameraphone, the Xperia lineup was a serious consideration when I bought my last phone. But I could never get over the hump of buying a device that would have less than 2 years of updates by the time I got it, <i>and</i> that would deliberately self-destruct if I attempted to extend it beyond that.</p><p>I got an iPhone instead. Much less user-hostile. Forcing me to use a custom rom is already user-hostile, but to then <i>punish me for doing it</i> is unconscionable.</p><p>Oddly enough, there’s not nearly as much emphasis on banging the EU’s door down to stop that kind of waste and really honestly intentional/malicious damage, as there is about whatever apple thing people are whining about this week. Oh no the pelican case full of oem phone repair tooling that apple lets you rent (or buy) is too big/heavy… or Sony phones deliberately self-destruct themselves when you unlock the bootloader… somehow the “we can do both!” reply-guys never get around to doing both. Curious.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41011852"><td></td></tr>
                <tr id="41013297"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41013297" href="https://news.ycombinator.com/vote?id=41013297&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Ok. I paid more than that. What you're saying is I want x y and z, and also to be this cheap. But they're obviously catering for a niche market so you have to compromise and can't then just comment with "why can't they..." They would bring those features to cheaper phones if people were buying expensive phones for those features. You don't think it's worth the extra, so they don't think it's worth the effort.</p><p>I'm happy to pay a bit more, I use my phone all the time. I would like a folding phone but I don't consider those ready yet, but I'm not posting that all phones should be folding for $200 because they can do it in that model for 1800</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="41009916"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009916" href="https://news.ycombinator.com/vote?id=41009916&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>How about the option to totally remove google without installing a custom rom.</p><p>you start your brand new phone and a pop up appears:</p><p>Would you like to remove google and all the other bloatware to start with a blank phone and choose to install exactly what you need and want.</p><p>Please click here.</p><p>I would then seriously consider buying a new phone instead of slightly older phones I can install custom roms on.</p><p>now that would be a thing.</p><p>In a perfect world</p><p>I have an old Samsung S4 2013 (android 11) and an old Motorola G3 (android 11). I keep the G3 to listen to FM radio as modern phones dont have the FMradio.</p><p>My main phone is a onplus 5T with android 14. A superb phone, 8 years old and still runs better than any modern phone my friends own. Cost me £75</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010328"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41010328" href="https://news.ycombinator.com/vote?id=41010328&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>My Librem 5 has a 3.5mm jack, microSD slot, removable battery, even removable modem and smartcard, and an OS I fully control. Couldn't be happier. The only thing that bothers me is that it's soon going to be 5 years old and there's still nothing better on the market, and even though it's still usable it's at a point where I expect it to start showing its age rather sooner than later.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011467"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41011467" href="https://news.ycombinator.com/vote?id=41011467&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>My librem 5 has about 3.5mm of dust on it because the phone is unusable. I appreciate that they made a linux phone, but they didn't make a phone people would actually want to use. Abysmal battery life where "carry a 2nd battery" is actual advice for every-day use. Very slow user interface. So large and heavy that I could murder someone with it. Questionable cellular support where the modem randomly disconnecting in the middle of a phone call can happen.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011524"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41011524" href="https://news.ycombinator.com/vote?id=41011524&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>The battery lasts up to a single day, which is short but enough for me. I recognize that it's not a phone for everyone and it has its quirks, but "unusable" is not how I'd describe it after daily driving it for years. Overall I see more advantages than disadvantages when compared to mainstream devices, which is why I continue to use it.</p><p>&gt; where the modem randomly disconnecting in the middle of a phone call can happen</p><p>Fixed 1.5 years ago. It's a fun story BTW: <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-3200-universal-serial-bug-a-tale-of-spontaneous-modem-resets/" rel="nofollow">https://fosdem.org/2024/schedule/event/fosdem-2024-3200-univ...</a></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41013404"><td></td></tr>
                              <tr id="41009478"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009478" href="https://news.ycombinator.com/vote?id=41009478&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>Next you are telling me you want to go back to the time when mobiles needed a whole week to go through a charge. How outdated!</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41012474"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41012474" href="https://news.ycombinator.com/vote?id=41012474&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Not that I use android smart phones that much any more in the capacity to replace what a laptop might do, since google's ugly head all too often places too much hindrance on the apps I prefer to use, however I do still use unencrypted microSD for times when bluetooth isn't doing what it's supposed to do to transfer photos or it's just faster to put the card into  a reader and look at the contents on a laptop.</p><p>AI might seem useful - but sadly on a phone and prepackaged, I only see it becoming a <i>minder</i> in a short time - no thanks.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41011649"><td></td></tr>
                <tr id="41011833"><td></td></tr>
                  <tr id="41009639"><td></td></tr>
            <tr id="41009437"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009437" href="https://news.ycombinator.com/vote?id=41009437&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I have so many tablets and cheap phones that don't have the storage to play high-end mobile games,  it would make a difference to me if I could expand my memory easily.  (Edit: some folks got excited because I said "memory" when I meant "storage")</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41009474"><td></td></tr>
                <tr id="41009498"><td></td></tr>
                <tr id="41009561"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_41009561" href="https://news.ycombinator.com/vote?id=41009561&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>SD cards do not increase the memory available to user applications. They are storage devices, even if the technology behind them has the word memory in the name.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41009843"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_41009843" href="https://news.ycombinator.com/vote?id=41009843&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>It's not the memory that's the problem,  it's that games like FGO require 10GB or more of flash storage which is most of a 16GB device particularly when you consider overhead for software updates.  It's not like the game has high memory requirements but it sure has a lot of levels, textures and stuff.</p><p>It's amusing the the IBM Mainframe world still uses the word "storage" to describe RAM.</p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="41011054"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41011054" href="https://news.ycombinator.com/vote?id=41011054&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I love bluetooth headphones for listening to video or even talking, but it has too much latency for realtime music performance (e.g. music making apps, or using your phone as a MIDI instrument with a controller). Having the wired headphone jack without the latency that (any) wireless protocol necessarily introduces is a huge deadlbreaking feature and I never see people defending bluetooth headsets mention it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009902"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009902" href="https://news.ycombinator.com/vote?id=41009902&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>I agree, that's why I am daily driving Samsung Galaxy S10 (exynos version) on LineageOS.</p><p>I miss 2010-2015 smartphone market, it was much more innovative than it's now :(</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009578"><td></td></tr>
                <tr id="41010074"><td></td></tr>
                  <tr id="41009435"><td></td></tr>
                <tr id="41010259"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010259" href="https://news.ycombinator.com/vote?id=41010259&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Thinking like this is how we end up with gadgets that can be barely be called pocket computers.</p><p>Thank God that the computer industry came of age before iOSsification began. Need to connect to wired headphones? Buy a dongle. Need more storage? Pay for iCloud. Want to program on your iPad? Jump through a million hoops and end up using a remote desktop solution.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009512"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41009512" href="https://news.ycombinator.com/vote?id=41009512&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I can understand the upgrade required for extra storage and AI subscriptions, but what revenue is earned from the elimination of the headphone jack? I can only see the marginal costs of adding one in, but for consumers who want it, it'd be a sales tactic.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41010121"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41010121" href="https://news.ycombinator.com/vote?id=41010121&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Bluetooth earphones are devices with a really limited lifespan.</p><p>You can use like 2 charges in a day easily and that a lifespan of one to 2 years.</p><p>For a lot if vendors it isn't a notable difference, for apple with the air pods it's MASSIVE</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="41009462"><td></td></tr>
                <tr id="41009521"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41009521" href="https://news.ycombinator.com/vote?id=41009521&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I recently bought a NOS Samsung Note 10 Lite. A quarter the price of the S24, has the wonderful S-Pen and a headphone jack. And even though the battery is ostensibly not user replaceable, it is an easy job that can be done in five minutes without risking breaking anything else.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41009714"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_41009714" href="https://news.ycombinator.com/vote?id=41009714&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Similarly, I now have a Samsung Galaxy A52, which has a headphone jack and a microSD slot (but no user-replaceable battery).</p><p>I'm not particularly price conscious, so I feel like Samsung lost out on an opportunity to sell me a flagship phone because those no longer have these features I care about. Luckily, this much cheaper phone still has the two that are most important to me. When they stop offering them at all, I'll be done with Samsung.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41009809"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_41009809" href="https://news.ycombinator.com/vote?id=41009809&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>You just explained something that I've been noticing more and more lately. A decade ago, the early adopters and nerds would have the flagship phones, and everybody else would have the cheap phone. Today the power users are using the absolute cheapest phones and the general public has the flagships.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="41011789"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41011789" href="https://news.ycombinator.com/vote?id=41011789&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>My device has a headphone jack and a microSD slot and I've never used either of them.</p><p>In regards of AI I find transcription, summarization, translation and predictive text to be very useful.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010122"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41010122" href="https://news.ycombinator.com/vote?id=41010122&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>&gt; Curious how others feel about this.</p><p>I would rather have none of these things, but if I had to choose, AI sounds more useful.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41010211"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010211" href="https://news.ycombinator.com/vote?id=41010211&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>"sounds" being the operative word. I don't consider being able to erase something on a photo, or add something to be a compelling enough use case. The AI demos I've seen have been pretty pathetic relative to the hype they're trying to build.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41010272"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41010272" href="https://news.ycombinator.com/vote?id=41010272&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>I agree for the most part. I'm pretty bearish on most AI stuff, I was not interested in the Apple Intelligence stuff announced at WWDC beyond having a Siri that might be able to answer a question directly instead of sending me to a Wikipedia article.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="41009477"><td></td></tr>
                <tr id="41009562"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41009562" href="https://news.ycombinator.com/vote?id=41009562&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>This was the defining feature of the best MP3 player I ever owned. (I believe it was a Sanyo Sansa.) I wound up using it way more than the MP3 functionality. I was spoiled, living in NYC at the time, but there was/still is so much good content out there, if you spend the time to look (college, community, pirate, etc.).</p><p>It's depressing that such functionality is missing from modern devices. Entertainment value aside, it can be a lifeline in times of crisis/emergencies.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="41009484"><td></td></tr>
                <tr id="41010063"><td></td></tr>
                <tr id="41011084"><td></td></tr>
                  <tr id="41010154"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010154" href="https://news.ycombinator.com/vote?id=41010154&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>Alternative in what sense? I think most, if not all, modern Xperias have both headphone jacks and microSD slots. I'm not sure how they are when it comes to android updates though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41010956"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41010956" href="https://news.ycombinator.com/vote?id=41010956&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Worst. 2 years only with awful track record even for the security updates.</p><p>And the price is around 1400 eur.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011218"><td></td></tr>
                        <tr id="41010085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010085" href="https://news.ycombinator.com/vote?id=41010085&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>For me, the microSD slot is the important part, and the Galaxy A54 still has one.  No headphone jack, though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011037"><td></td></tr>
                <tr id="41011782"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_41011782" href="https://news.ycombinator.com/vote?id=41011782&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Huh, the reviews I read seemed to say that the camera was a huge step up.  (But maybe they were mostly comparing to the A53, which seemed uniformly to be regarded as a regression.)  If not, then I feel quite stupid for paying the extra to "upgrade" to an A54, instead of an A52, from my A50.</p><p>(Also, though it's easy for me to believe this random search result is dodgy, and with the understanding that benchmarks don't mean much, Googling around for a chip comparison turned up <a href="https://gadgetversus.com/processor/qualcomm-sm7125-snapdragon-720g-vs-samsung-exynos-1380/" rel="nofollow">https://gadgetversus.com/processor/qualcomm-sm7125-snapdrago...</a> , which seems to suggest that the Exynos 1380 in the A54 wins over the Snapdragon 720G in the A52 in many benchmarks.)</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="41009513"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009513" href="https://news.ycombinator.com/vote?id=41009513&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Headphone jack I’ve not really needed.</p><p>But I want a smartphone with a removable battery.  Same with laptops.</p><p>Let me kill the power.  Let me replace the batteries easily.</p><p>Give me thicker devices!</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010086"><td></td></tr>
            <tr id="41012068"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41012068" href="https://news.ycombinator.com/vote?id=41012068&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>"Some people say give the customers what they want, but that's not my approach. Our job is to figure out what they're going to want before they do. I think Henry Ford once said, 'If I'd ask customers what they wanted, they would've told me a faster horse.' People don't know what they want until you show it to them. That's why I never rely on market research. Our task is to read things that are not yet on the page."</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009646"><td></td></tr>
            <tr id="41010489"><td></td></tr>
            <tr id="41009445"><td></td></tr>
                <tr id="41010060"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41010060" href="https://news.ycombinator.com/vote?id=41010060&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>Sony Xperia phones have this combination, including the just released version. Just nobody buys them.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011882"><td></td></tr>
                  <tr id="41009690"><td></td></tr>
                  <tr id="41011185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41011185" href="https://news.ycombinator.com/vote?id=41011185&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>My Zenfone 9 has a headphone jack. No SD card slot though, which I don't need.</p><p>So yeah, I voted for this position with my dollars, and will continue to do so.</p><p>Any phone with mandatory AI crap is Hard Pass.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009739"><td></td></tr>
            <tr id="41011330"><td></td></tr>
            <tr id="41009464"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009464" href="https://news.ycombinator.com/vote?id=41009464&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>Yeah but how does Google/Apple make money off of cloud storage when you don't need it?</p><p>In some ways it's better to just get a usb-c fob for this functionality...have a problem with your headphone jack or microSD slot? Throw it out and replace it.</p><p>I'd rather see TB+ storage on my phone.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41010093"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41010093" href="https://news.ycombinator.com/vote?id=41010093&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>i would much rather have AI to do routine tasks on my phone for me and change settings without me having to dig through menus</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009539"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009539" href="https://news.ycombinator.com/vote?id=41009539&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>I don't know if we need 8k video, but if it's going to be a feature it sure feels like we should have sd cards. This write-up is talking about 33GB/hr. Given the dinky ass 128GB that seems to be common, and given that the base install is often 30GB+, like, yeah, we need more storage. <a href="https://www.androidauthority.com/pixel-9-8k-more-storage-3462002/" rel="nofollow">https://www.androidauthority.com/pixel-9-8k-more-storage-346...</a></p><p>MicroSD cards are fantastic &amp; I'd want them anywhere. But man it's just so preposterous that they have so drastically outpaced phone's builtin storage. 0.5 or 1TB are basically unheard of on phones, but there's plenty of whole SSDs with far more components and cost selling for $50 or less. It's wild. What a supply side economics setup, so many companies all keeping the whole mobile market back, deliberately.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41013281"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41013281" href="https://news.ycombinator.com/vote?id=41013281&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>I think Apple's aware of the storage limitations with 8k recording and so they won't bother to ship it in software for another couple years.</p><p>The utility gap between 4k and 8k video is tiny. I was eager to move from a giant 1080p TV to a giant 4k TV, but I have no desire to buy 8k.</p><p>Neither 8k TVs nor 8k monitors have occupied a meaningful amount of the market, and there appears to be not much demand for them. On the gaming side, the latest graphics cards still can't max out settings on most AAA games at 4k/60fps.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="41011469"><td></td></tr>
            <tr id="41010295"><td></td></tr>
            <tr id="41009485"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_41009485" href="https://news.ycombinator.com/vote?id=41009485&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>I'm going to side with Apple on this one. Transistors are basically free and ports are expensive and unreliable. I'm happy they've been moving to eSIMs. I'd be fine if my next iPhone only supported wireless charging.</p><p>No ports is better.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="41011147"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_41011147" href="https://news.ycombinator.com/vote?id=41011147&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div><p>I've certainly have had ports fail, but software is worse, and bluetooth is a lot of software. My spouse's phone was able to connect to our van for some time, then a phone software update broke it, and it took 3 months for them to push a new one that fixed it. If it was a wired 4-pin connection for handsfree audio and either port failed, it would probably take less time to get it fixed. (Yes, a 4-pin connection probably leaves out features from Bluetooth, but no  agency to fix problems is worse)</p><p>I've yet to have a SIM fail on me, and I don't see why I would want to lose out on the convenience of removing the SIM from old phone, and inserting it into the new one. Moving an eSIM requires interaction with the carrier as I understand it.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="41009609"><td></td></tr>
                <tr id="41009774"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_41009774" href="https://news.ycombinator.com/vote?id=41009774&amp;how=up&amp;goto=item%3Fid%3D41009359"></a></center>    </td><td><br><div>
                  <p>If they weren't burning cash on AI, they'd be burning it on something equally useless. Smartphones have been more or less feature-complete for years now.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kompute – Vulkan Alternative to CUDA (104 pts)]]></title>
            <link>https://github.com/KomputeProject/kompute</link>
            <guid>41009023</guid>
            <pubDate>Fri, 19 Jul 2024 17:43:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/KomputeProject/kompute">https://github.com/KomputeProject/kompute</a>, See on <a href="https://news.ycombinator.com/item?id=41009023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8f872dee052b7c84233f785769c7e17ccfdbff17a05ebb774c2f3755d50ebf0e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f56657273696f6e2d302e372e302d677265656e2e737667"><img src="https://camo.githubusercontent.com/8f872dee052b7c84233f785769c7e17ccfdbff17a05ebb774c2f3755d50ebf0e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f56657273696f6e2d302e372e302d677265656e2e737667" alt="GitHub" data-canonical-src="https://img.shields.io/badge/Version-0.7.0-green.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b8c3ea661caa26d6e0bad0e0cf08250dcee72f166dc0ca80005fac186c0f8e9b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f432b2b2d313425453225383025393432302d707572706c652e737667"><img src="https://camo.githubusercontent.com/b8c3ea661caa26d6e0bad0e0cf08250dcee72f166dc0ca80005fac186c0f8e9b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f432b2b2d313425453225383025393432302d707572706c652e737667" alt="GitHub" data-canonical-src="https://img.shields.io/badge/C++-14%E2%80%9420-purple.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a931e304cb2822ce527ed9230da8fed82e1f6972ff0674706ff06fe5a4ac333c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4275696c642d636d616b652d7265642e737667"><img src="https://camo.githubusercontent.com/a931e304cb2822ce527ed9230da8fed82e1f6972ff0674706ff06fe5a4ac333c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4275696c642d636d616b652d7265642e737667" alt="GitHub" data-canonical-src="https://img.shields.io/badge/Build-cmake-red.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ca62ec82651f12fc0f1cd5c027a061794b6bf2199fe9130be61cbab90ae8002e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e37254532253830253934332e392d626c75652e737667"><img src="https://camo.githubusercontent.com/ca62ec82651f12fc0f1cd5c027a061794b6bf2199fe9130be61cbab90ae8002e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e37254532253830253934332e392d626c75652e737667" alt="GitHub" data-canonical-src="https://img.shields.io/badge/Python-3.7%E2%80%943.9-blue.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/266f5c100f8205bd1421e45d36346c42927736082dc1d7b8409d0850e4764eaa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368652d626c61636b2e737667"><img src="https://camo.githubusercontent.com/266f5c100f8205bd1421e45d36346c42927736082dc1d7b8409d0850e4764eaa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368652d626c61636b2e737667" alt="GitHub" data-canonical-src="https://img.shields.io/badge/License-Apache-black.svg"></a>
<a href="https://bestpractices.coreinfrastructure.org/projects/4834" rel="nofollow"><img src="https://camo.githubusercontent.com/bd6283e527078fd79a22cbe272515776ac1c20c801ff86f65181d558cf478673/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f343833342f6261646765" alt="CII Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/4834/badge"></a></p>
<markdown-accessiblity-table><table>
<tbody><tr>
<td>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute.jpg"><img src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute.jpg"></a>
</td>
<td>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kompute</h2><a id="user-content-kompute" aria-label="Permalink: Kompute" href="#kompute"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The general purpose GPU compute framework for cross vendor graphics cards (AMD, Qualcomm, NVIDIA &amp; friends)</h3><a id="user-content-the-general-purpose-gpu-compute-framework-for-cross-vendor-graphics-cards-amd-qualcomm-nvidia--friends" aria-label="Permalink: The general purpose GPU compute framework for cross vendor graphics cards (AMD, Qualcomm, NVIDIA &amp; friends)" href="#the-general-purpose-gpu-compute-framework-for-cross-vendor-graphics-cards-amd-qualcomm-nvidia--friends"></a></p>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Blazing fast, mobile-enabled, asynchronous, and optimized for advanced GPU acceleration usecases.</h4><a id="user-content-blazing-fast-mobile-enabled-asynchronous-and-optimized-for-advanced-gpu-acceleration-usecases" aria-label="Permalink: Blazing fast, mobile-enabled, asynchronous, and optimized for advanced GPU acceleration usecases." href="#blazing-fast-mobile-enabled-asynchronous-and-optimized-for-advanced-gpu-acceleration-usecases"></a></p>
<p dir="auto">💬 <a href="https://kompute.cc/overview/community.html" rel="nofollow">Join the Discord &amp; Community Calls</a> 🔋 <a href="https://kompute.cc/" rel="nofollow">Documentation</a> 💻 <a href="https://medium.com/@AxSaucedo/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a" rel="nofollow">Blog Post</a> ⌨ <a href="#more-examples">Examples</a> 💾</p>
<hr>
<p dir="auto"><h5 tabindex="-1" dir="auto">Kompute is backed by the Linux Foundation as a <a href="https://lfaidata.foundation/blog/2021/08/26/kompute-joins-lf-ai-data-as-new-sandbox-project/" rel="nofollow">hosted project</a> by the LF AI &amp; Data Foundation.</h5><a id="user-content-kompute-is-backed-by-the-linux-foundation-as-a-hosted-project-by-the-lf-ai--data-foundation" aria-label="Permalink: Kompute is backed by the Linux Foundation as a hosted project by the LF AI &amp; Data Foundation." href="#kompute-is-backed-by-the-linux-foundation-as-a-hosted-project-by-the-lf-ai--data-foundation"></a></p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Principles &amp; Features</h2><a id="user-content-principles--features" aria-label="Permalink: Principles &amp; Features" href="#principles--features"></a></p>
<ul dir="auto">
<li><a href="#your-first-kompute-python">Flexible Python module</a> with <a href="#your-first-kompute-c">C++ SDK</a> for optimizations</li>
<li><a href="#asynchronous-and-parallel-operations">Asynchronous &amp; parallel processing</a> support through GPU family queues</li>
<li><a href="#mobile-enabled">Mobile enabled</a> with examples via Android NDK across several architectures</li>
<li>BYOV: <a href="#motivations">Bring-your-own-Vulkan design</a> to play nice with existing Vulkan applications</li>
<li>Explicit relationships for GPU and host <a href="https://kompute.cc/overview/memory-management.html" rel="nofollow">memory ownership and memory management</a></li>
<li>Robust codebase with <a href="https://kompute.cc/codecov/" rel="nofollow">90% unit test code coverage</a></li>
<li>Advanced use-cases on <a href="https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a" rel="nofollow">machine learning 🤖</a>, <a href="https://towardsdatascience.com/gpu-accelerated-machine-learning-in-your-mobile-applications-using-the-android-ndk-vulkan-kompute-1e9da37b7617" rel="nofollow">mobile development 📱</a> and <a href="https://towardsdatascience.com/supercharging-game-development-with-gpu-accelerated-ml-using-vulkan-kompute-the-godot-game-engine-4e75a84ea9f0" rel="nofollow">game development 🎮</a>.</li>
<li>Active community with <a href="https://kompute.cc/overview/community.html" rel="nofollow">monthly calls, discord chat and more</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/komputer-logos.gif"><img src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/komputer-logos.gif" alt="" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Projects using Kompute ❤️  🤖</h2><a id="user-content-projects-using-kompute-️--" aria-label="Permalink: Projects using Kompute ❤️  🤖" href="#projects-using-kompute-️--"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Below you can find a GPU multiplication example using the C++ and Python Kompute interfaces.</p>
<p dir="auto">You can <a href="https://discord.gg/MaH5Jv5zwv" rel="nofollow">join the Discord</a> for questions / discussion, open a <a href="https://github.com/KomputeProject/kompute/issues/new">github issue</a>, or read <a href="https://kompute.cc/" rel="nofollow">the documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Your First Kompute (C++)</h3><a id="user-content-your-first-kompute-c" aria-label="Permalink: Your First Kompute (C++)" href="#your-first-kompute-c"></a></p>
<p dir="auto">The C++ interface provides low level access to the native components of Kompute, enabling for <a href="https://kompute.cc/overview/async-parallel.html" rel="nofollow">advanced optimizations</a> as well as <a href="https://kompute.cc/overview/reference.html" rel="nofollow">extension of components</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
void kompute(const std::string&amp; shader) {

    // 1. Create Kompute Manager with default settings (device 0, first queue and no extensions)
    kp::Manager mgr; 

    // 2. Create and initialise Kompute Tensors through manager

    // Default tensor constructor simplifies creation of float values
    auto tensorInA = mgr.tensor({ 2., 2., 2. });
    auto tensorInB = mgr.tensor({ 1., 2., 3. });
    // Explicit type constructor supports uint32, int32, double, float and bool
    auto tensorOutA = mgr.tensorT<uint32_t>({ 0, 0, 0 });
    auto tensorOutB = mgr.tensorT<uint32_t>({ 0, 0, 0 });

    std::vector<std::shared_ptr<kp::Tensor>> params = {tensorInA, tensorInB, tensorOutA, tensorOutB};

    // 3. Create algorithm based on shader (supports buffers &amp; push/spec constants)
    kp::Workgroup workgroup({3, 1, 1});
    std::vector<float> specConsts({ 2 });
    std::vector<float> pushConstsA({ 2.0 });
    std::vector<float> pushConstsB({ 3.0 });

    auto algorithm = mgr.algorithm(params,
                                   // See documentation shader section for compileSource
                                   compileSource(shader),
                                   workgroup,
                                   specConsts,
                                   pushConstsA);

    // 4. Run operation synchronously using sequence
    mgr.sequence()
        ->record<kp::OpTensorSyncDevice>(params)
        ->record<kp::OpAlgoDispatch>(algorithm) // Binds default push consts
        ->eval() // Evaluates the two recorded operations
        ->record<kp::OpAlgoDispatch>(algorithm, pushConstsB) // Overrides push consts
        ->eval(); // Evaluates only last recorded operation

    // 5. Sync results from the GPU asynchronously
    auto sq = mgr.sequence();
    sq->evalAsync<kp::OpTensorSyncLocal>(params);

    // ... Do other work asynchronously whilst GPU finishes

    sq->evalAwait();

    // Prints the first output which is: { 4, 8, 12 }
    for (const float&amp; elem : tensorOutA->vector()) std::cout << elem << &quot;  &quot;;
    // Prints the second output which is: { 10, 10, 10 }
    for (const float&amp; elem : tensorOutB->vector()) std::cout << elem << &quot;  &quot;;

} // Manages / releases all CPU and GPU memory resources

int main() {

    // Define a raw string shader (or use the Kompute tools to compile to SPIRV / C++ header
    // files). This shader shows some of the main components including constants, buffers, etc
    std::string shader = (R&quot;(
        #version 450

        layout (local_size_x = 1) in;

        // The input tensors bind index is relative to index in parameter passed
        layout(set = 0, binding = 0) buffer buf_in_a { float in_a[]; };
        layout(set = 0, binding = 1) buffer buf_in_b { float in_b[]; };
        layout(set = 0, binding = 2) buffer buf_out_a { uint out_a[]; };
        layout(set = 0, binding = 3) buffer buf_out_b { uint out_b[]; };

        // Kompute supports push constants updated on dispatch
        layout(push_constant) uniform PushConstants {
            float val;
        } push_const;

        // Kompute also supports spec constants on initalization
        layout(constant_id = 0) const float const_one = 0;

        void main() {
            uint index = gl_GlobalInvocationID.x;
            out_a[index] += uint( in_a[index] * in_b[index] );
            out_b[index] += uint( const_one * push_const.val );
        }
    )&quot;);

    // Run the function declared above with our raw string shader
    kompute(shader);
}
"><pre><span>void</span> <span>kompute</span>(<span>const</span> std::string&amp; shader) {

    <span><span>//</span> 1. Create Kompute Manager with default settings (device 0, first queue and no extensions)</span>
    kp::Manager mgr; 

    <span><span>//</span> 2. Create and initialise Kompute Tensors through manager</span>

    <span><span>//</span> Default tensor constructor simplifies creation of float values</span>
    <span>auto</span> tensorInA = mgr.<span>tensor</span>({ <span>2</span>., <span>2</span>., <span>2</span>. });
    <span>auto</span> tensorInB = mgr.<span>tensor</span>({ <span>1</span>., <span>2</span>., <span>3</span>. });
    <span><span>//</span> Explicit type constructor supports uint32, int32, double, float and bool</span>
    <span>auto</span> tensorOutA = mgr.<span>tensorT</span>&lt;<span>uint32_t</span>&gt;({ <span>0</span>, <span>0</span>, <span>0</span> });
    <span>auto</span> tensorOutB = mgr.<span>tensorT</span>&lt;<span>uint32_t</span>&gt;({ <span>0</span>, <span>0</span>, <span>0</span> });

    std::vector&lt;std::shared_ptr&lt;kp::Tensor&gt;&gt; params = {tensorInA, tensorInB, tensorOutA, tensorOutB};

    <span><span>//</span> 3. Create algorithm based on shader (supports buffers &amp; push/spec constants)</span>
    kp::Workgroup <span>workgroup</span>({<span>3</span>, <span>1</span>, <span>1</span>});
    std::vector&lt;<span>float</span>&gt; <span>specConsts</span>({ <span>2</span> });
    std::vector&lt;<span>float</span>&gt; <span>pushConstsA</span>({ <span>2.0</span> });
    std::vector&lt;<span>float</span>&gt; <span>pushConstsB</span>({ <span>3.0</span> });

    <span>auto</span> algorithm = mgr.<span>algorithm</span>(params,
                                   <span><span>//</span> See documentation shader section for compileSource</span>
                                   <span>compileSource</span>(shader),
                                   workgroup,
                                   specConsts,
                                   pushConstsA);

    <span><span>//</span> 4. Run operation synchronously using sequence</span>
    mgr.<span>sequence</span>()
        -&gt;<span>record</span>&lt;kp::OpTensorSyncDevice&gt;(params)
        -&gt;<span>record</span>&lt;kp::OpAlgoDispatch&gt;(algorithm) <span><span>//</span> Binds default push consts</span>
        -&gt;<span>eval</span>() <span><span>//</span> Evaluates the two recorded operations</span>
        -&gt;<span>record</span>&lt;kp::OpAlgoDispatch&gt;(algorithm, pushConstsB) <span><span>//</span> Overrides push consts</span>
        -&gt;<span>eval</span>(); <span><span>//</span> Evaluates only last recorded operation</span>

    <span><span>//</span> 5. Sync results from the GPU asynchronously</span>
    <span>auto</span> sq = mgr.<span>sequence</span>();
    sq-&gt;<span>evalAsync</span>&lt;kp::OpTensorSyncLocal&gt;(params);

    <span><span>//</span> ... Do other work asynchronously whilst GPU finishes</span>

    sq-&gt;<span>evalAwait</span>();

    <span><span>//</span> Prints the first output which is: { 4, 8, 12 }</span>
    <span>for</span> (<span>const</span> <span>float</span>&amp; elem : tensorOutA-&gt;<span>vector</span>()) std::cout &lt;&lt; elem &lt;&lt; <span><span>"</span>  <span>"</span></span>;
    <span><span>//</span> Prints the second output which is: { 10, 10, 10 }</span>
    <span>for</span> (<span>const</span> <span>float</span>&amp; elem : tensorOutB-&gt;<span>vector</span>()) std::cout &lt;&lt; elem &lt;&lt; <span><span>"</span>  <span>"</span></span>;

} <span><span>//</span> Manages / releases all CPU and GPU memory resources</span>

<span>int</span> <span>main</span>() {

    <span><span>//</span> Define a raw string shader (or use the Kompute tools to compile to SPIRV / C++ header</span>
    <span><span>//</span> files). This shader shows some of the main components including constants, buffers, etc</span>
    std::string shader = (<span><span>R"(</span></span>
<span>        #version 450</span>
<span></span>
<span>        layout (local_size_x = 1) in;</span>
<span></span>
<span>        // The input tensors bind index is relative to index in parameter passed</span>
<span>        layout(set = 0, binding = 0) buffer buf_in_a { float in_a[]; };</span>
<span>        layout(set = 0, binding = 1) buffer buf_in_b { float in_b[]; };</span>
<span>        layout(set = 0, binding = 2) buffer buf_out_a { uint out_a[]; };</span>
<span>        layout(set = 0, binding = 3) buffer buf_out_b { uint out_b[]; };</span>
<span></span>
<span>        // Kompute supports push constants updated on dispatch</span>
<span>        layout(push_constant) uniform PushConstants {</span>
<span>            float val;</span>
<span>        } push_const;</span>
<span></span>
<span>        // Kompute also supports spec constants on initalization</span>
<span>        layout(constant_id = 0) const float const_one = 0;</span>
<span></span>
<span>        void main() {</span>
<span>            uint index = gl_GlobalInvocationID.x;</span>
<span>            out_a[index] += uint( in_a[index] * in_b[index] );</span>
<span>            out_b[index] += uint( const_one * push_const.val );</span>
<span>        }</span>
<span>    <span>)"</span></span>);

    <span><span>//</span> Run the function declared above with our raw string shader</span>
    <span>kompute</span>(shader);
}
</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Your First Kompute (Python)</h3><a id="user-content-your-first-kompute-python" aria-label="Permalink: Your First Kompute (Python)" href="#your-first-kompute-python"></a></p>
<p dir="auto">The <a href="https://kompute.cc/overview/python-package.html" rel="nofollow">Python package</a> provides a <a href="https://kompute.cc/overview/python-reference.html" rel="nofollow">high level interactive interface</a> that enables for experimentation whilst ensuring high performance and fast development workflows.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
from .utils import compile_source # using util function from python/test/utils

def kompute(shader):
    # 1. Create Kompute Manager with default settings (device 0, first queue and no extensions)
    mgr = kp.Manager()

    # 2. Create and initialise Kompute Tensors through manager

    # Default tensor constructor simplifies creation of float values
    tensor_in_a = mgr.tensor([2, 2, 2])
    tensor_in_b = mgr.tensor([1, 2, 3])
    # Explicit type constructor supports uint32, int32, double, float and bool
    tensor_out_a = mgr.tensor_t(np.array([0, 0, 0], dtype=np.uint32))
    tensor_out_b = mgr.tensor_t(np.array([0, 0, 0], dtype=np.uint32))

    params = [tensor_in_a, tensor_in_b, tensor_out_a, tensor_out_b]

    # 3. Create algorithm based on shader (supports buffers &amp; push/spec constants)
    workgroup = (3, 1, 1)
    spec_consts = [2]
    push_consts_a = [2]
    push_consts_b = [3]

    # See documentation shader section for compile_source
    spirv = compile_source(shader)

    algo = mgr.algorithm(params, spirv, workgroup, spec_consts, push_consts_a)

    # 4. Run operation synchronously using sequence
    (mgr.sequence()
        .record(kp.OpTensorSyncDevice(params))
        .record(kp.OpAlgoDispatch(algo)) # Binds default push consts provided
        .eval() # evaluates the two recorded ops
        .record(kp.OpAlgoDispatch(algo, push_consts_b)) # Overrides push consts
        .eval()) # evaluates only the last recorded op

    # 5. Sync results from the GPU asynchronously
    sq = mgr.sequence()
    sq.eval_async(kp.OpTensorSyncLocal(params))

    # ... Do other work asynchronously whilst GPU finishes

    sq.eval_await()

    # Prints the first output which is: { 4, 8, 12 }
    print(tensor_out_a)
    # Prints the first output which is: { 10, 10, 10 }
    print(tensor_out_b)

if __name__ == &quot;__main__&quot;:

    # Define a raw string shader (or use the Kompute tools to compile to SPIRV / C++ header
    # files). This shader shows some of the main components including constants, buffers, etc
    shader = &quot;&quot;&quot;
        #version 450

        layout (local_size_x = 1) in;

        // The input tensors bind index is relative to index in parameter passed
        layout(set = 0, binding = 0) buffer buf_in_a { float in_a[]; };
        layout(set = 0, binding = 1) buffer buf_in_b { float in_b[]; };
        layout(set = 0, binding = 2) buffer buf_out_a { uint out_a[]; };
        layout(set = 0, binding = 3) buffer buf_out_b { uint out_b[]; };

        // Kompute supports push constants updated on dispatch
        layout(push_constant) uniform PushConstants {
            float val;
        } push_const;

        // Kompute also supports spec constants on initalization
        layout(constant_id = 0) const float const_one = 0;

        void main() {
            uint index = gl_GlobalInvocationID.x;
            out_a[index] += uint( in_a[index] * in_b[index] );
            out_b[index] += uint( const_one * push_const.val );
        }
    &quot;&quot;&quot;

    kompute(shader)
"><pre><span>from</span> .<span>utils</span> <span>import</span> <span>compile_source</span> <span># using util function from python/test/utils</span>

<span>def</span> <span>kompute</span>(<span>shader</span>):
    <span># 1. Create Kompute Manager with default settings (device 0, first queue and no extensions)</span>
    <span>mgr</span> <span>=</span> <span>kp</span>.<span>Manager</span>()

    <span># 2. Create and initialise Kompute Tensors through manager</span>

    <span># Default tensor constructor simplifies creation of float values</span>
    <span>tensor_in_a</span> <span>=</span> <span>mgr</span>.<span>tensor</span>([<span>2</span>, <span>2</span>, <span>2</span>])
    <span>tensor_in_b</span> <span>=</span> <span>mgr</span>.<span>tensor</span>([<span>1</span>, <span>2</span>, <span>3</span>])
    <span># Explicit type constructor supports uint32, int32, double, float and bool</span>
    <span>tensor_out_a</span> <span>=</span> <span>mgr</span>.<span>tensor_t</span>(<span>np</span>.<span>array</span>([<span>0</span>, <span>0</span>, <span>0</span>], <span>dtype</span><span>=</span><span>np</span>.<span>uint32</span>))
    <span>tensor_out_b</span> <span>=</span> <span>mgr</span>.<span>tensor_t</span>(<span>np</span>.<span>array</span>([<span>0</span>, <span>0</span>, <span>0</span>], <span>dtype</span><span>=</span><span>np</span>.<span>uint32</span>))

    <span>params</span> <span>=</span> [<span>tensor_in_a</span>, <span>tensor_in_b</span>, <span>tensor_out_a</span>, <span>tensor_out_b</span>]

    <span># 3. Create algorithm based on shader (supports buffers &amp; push/spec constants)</span>
    <span>workgroup</span> <span>=</span> (<span>3</span>, <span>1</span>, <span>1</span>)
    <span>spec_consts</span> <span>=</span> [<span>2</span>]
    <span>push_consts_a</span> <span>=</span> [<span>2</span>]
    <span>push_consts_b</span> <span>=</span> [<span>3</span>]

    <span># See documentation shader section for compile_source</span>
    <span>spirv</span> <span>=</span> <span>compile_source</span>(<span>shader</span>)

    <span>algo</span> <span>=</span> <span>mgr</span>.<span>algorithm</span>(<span>params</span>, <span>spirv</span>, <span>workgroup</span>, <span>spec_consts</span>, <span>push_consts_a</span>)

    <span># 4. Run operation synchronously using sequence</span>
    (<span>mgr</span>.<span>sequence</span>()
        .<span>record</span>(<span>kp</span>.<span>OpTensorSyncDevice</span>(<span>params</span>))
        .<span>record</span>(<span>kp</span>.<span>OpAlgoDispatch</span>(<span>algo</span>)) <span># Binds default push consts provided</span>
        .<span>eval</span>() <span># evaluates the two recorded ops</span>
        .<span>record</span>(<span>kp</span>.<span>OpAlgoDispatch</span>(<span>algo</span>, <span>push_consts_b</span>)) <span># Overrides push consts</span>
        .<span>eval</span>()) <span># evaluates only the last recorded op</span>

    <span># 5. Sync results from the GPU asynchronously</span>
    <span>sq</span> <span>=</span> <span>mgr</span>.<span>sequence</span>()
    <span>sq</span>.<span>eval_async</span>(<span>kp</span>.<span>OpTensorSyncLocal</span>(<span>params</span>))

    <span># ... Do other work asynchronously whilst GPU finishes</span>

    <span>sq</span>.<span>eval_await</span>()

    <span># Prints the first output which is: { 4, 8, 12 }</span>
    <span>print</span>(<span>tensor_out_a</span>)
    <span># Prints the first output which is: { 10, 10, 10 }</span>
    <span>print</span>(<span>tensor_out_b</span>)

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:

    <span># Define a raw string shader (or use the Kompute tools to compile to SPIRV / C++ header</span>
    <span># files). This shader shows some of the main components including constants, buffers, etc</span>
    <span>shader</span> <span>=</span> <span>"""</span>
<span>        #version 450</span>
<span></span>
<span>        layout (local_size_x = 1) in;</span>
<span></span>
<span>        // The input tensors bind index is relative to index in parameter passed</span>
<span>        layout(set = 0, binding = 0) buffer buf_in_a { float in_a[]; };</span>
<span>        layout(set = 0, binding = 1) buffer buf_in_b { float in_b[]; };</span>
<span>        layout(set = 0, binding = 2) buffer buf_out_a { uint out_a[]; };</span>
<span>        layout(set = 0, binding = 3) buffer buf_out_b { uint out_b[]; };</span>
<span></span>
<span>        // Kompute supports push constants updated on dispatch</span>
<span>        layout(push_constant) uniform PushConstants {</span>
<span>            float val;</span>
<span>        } push_const;</span>
<span></span>
<span>        // Kompute also supports spec constants on initalization</span>
<span>        layout(constant_id = 0) const float const_one = 0;</span>
<span></span>
<span>        void main() {</span>
<span>            uint index = gl_GlobalInvocationID.x;</span>
<span>            out_a[index] += uint( in_a[index] * in_b[index] );</span>
<span>            out_b[index] += uint( const_one * push_const.val );</span>
<span>        }</span>
<span>    """</span>

    <span>kompute</span>(<span>shader</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Interactive Notebooks &amp; Hands on Videos</h3><a id="user-content-interactive-notebooks--hands-on-videos" aria-label="Permalink: Interactive Notebooks &amp; Hands on Videos" href="#interactive-notebooks--hands-on-videos"></a></p>
<p dir="auto">You are able to try out the interactive Colab Notebooks which allow you to use a free GPU. The available examples are the Python and C++ examples below:</p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto">You can also check out the two following talks presented at the FOSDEM 2021 conference.</p>
<p dir="auto">Both videos have timestamps which will allow you to skip to the most relevant section for you - the intro &amp; motivations for both is almost the same so you can skip to the more specific content.</p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architectural Overview</h2><a id="user-content-architectural-overview" aria-label="Permalink: Architectural Overview" href="#architectural-overview"></a></p>
<p dir="auto">The core architecture of Kompute includes the following:</p>
<ul dir="auto">
<li><a href="https://kompute.cc/overview/reference.html#manager" rel="nofollow">Kompute Manager</a> - Base orchestrator which creates and manages device and child components</li>
<li><a href="https://kompute.cc/overview/reference.html#sequence" rel="nofollow">Kompute Sequence</a> - Container of operations that can be sent to GPU as batch</li>
<li><a href="https://kompute.cc/overview/reference.html#algorithm" rel="nofollow">Kompute Operation (Base)</a> - Base class from which all operations inherit</li>
<li><a href="https://kompute.cc/overview/reference.html#tensor" rel="nofollow">Kompute Tensor</a> - Tensor structured data used in GPU operations</li>
<li><a href="https://kompute.cc/overview/reference.html#algorithm" rel="nofollow">Kompute Algorithm</a> - Abstraction for (shader) logic executed in the GPU</li>
</ul>
<p dir="auto">To see a full breakdown you can read further in the <a href="https://kompute.cc/overview/reference.html" rel="nofollow">C++ Class Reference</a>.</p>
<markdown-accessiblity-table><table>
<tbody><tr><th>
Full Architecture
</th>
<th>
Simplified Kompute Components
</th>
</tr><tr>
<td>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute-vulkan-architecture.jpg"><img width="100%" src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute-vulkan-architecture.jpg"></a>
<p>

(very tiny, check the <a href="https://ethicalml.github.io/vulkan-kompute/overview/reference.html" rel="nofollow">full reference diagram in docs for details</a>)
</p><p>

<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/suspicious.jfif"><img width="100%" src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/suspicious.jfif"></a></p></td>
<td>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute-architecture.jpg"><img width="100%" src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/kompute-architecture.jpg"></a>
</td>
</tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Asynchronous and Parallel Operations</h2><a id="user-content-asynchronous-and-parallel-operations" aria-label="Permalink: Asynchronous and Parallel Operations" href="#asynchronous-and-parallel-operations"></a></p>
<p dir="auto">Kompute provides flexibility to run operations in an asynrchonous way through vk::Fences. Furthermore, Kompute enables for explicit allocation of queues, which allow for parallel execution of operations across queue families.</p>
<p dir="auto">The image below provides an intuition on how Kompute Sequences can be allocated to different queues to enable parallel execution based on hardware. You can see the <a href="https://kompute.cc/overview/advanced-examples.html#parallel-operations" rel="nofollow">hands on example</a>, as well as the <a href="https://kompute.cc/overview/async-parallel.html" rel="nofollow">detailed documentation page</a> describing how it would work using an NVIDIA 1650 as an example.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/queue-allocation.jpg"><img src="https://raw.githubusercontent.com/KomputeProject/kompute/master/docs/images/queue-allocation.jpg" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mobile Enabled</h2><a id="user-content-mobile-enabled" aria-label="Permalink: Mobile Enabled" href="#mobile-enabled"></a></p>
<p dir="auto">Kompute has been optimized to work in mobile environments. The <a href="#build-overview">build system</a> enables for dynamic loading of the Vulkan shared library for Android environments, together with a working <a href="https://github.com/KomputeProject/kompute/tree/master/vk_ndk_wrapper_include">Android NDK wrapper</a> for the CPP headers.</p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">More examples</h2><a id="user-content-more-examples" aria-label="Permalink: More examples" href="#more-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simple examples</h3><a id="user-content-simple-examples" aria-label="Permalink: Simple examples" href="#simple-examples"></a></p>
<ul dir="auto">
<li><a href="https://kompute.cc/overview/advanced-examples.html#simple-shader-example" rel="nofollow">Simple multiplication example</a></li>
<li><a href="https://kompute.cc/overview/advanced-examples.html#record-batch-commands" rel="nofollow">Record batch commands with a Kompute Sequence</a></li>
<li><a href="https://kompute.cc/overview/advanced-examples.html#asynchronous-operations" rel="nofollow">Run Asynchronous Operations</a></li>
<li><a href="https://kompute.cc/overview/advanced-examples.html#parallel-operations" rel="nofollow">Run Parallel Operations Across Multiple GPU Queues</a></li>
<li><a href="https://kompute.cc/overview/advanced-examples.html#your-custom-kompute-operation" rel="nofollow">Create your custom Kompute Operations</a></li>
<li><a href="https://kompute.cc/overview/advanced-examples.html#logistic-regression-example" rel="nofollow">Implementing logistic regression from scratch</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">End-to-end examples</h3><a id="user-content-end-to-end-examples" aria-label="Permalink: End-to-end examples" href="#end-to-end-examples"></a></p>
<ul dir="auto">
<li><a href="https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a" rel="nofollow">Machine Learning Logistic Regression Implementation</a></li>
<li><a href="https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc" rel="nofollow">Parallelizing GPU-intensive Workloads via Multi-Queue Operations</a></li>
<li><a href="https://towardsdatascience.com/gpu-accelerated-machine-learning-in-your-mobile-applications-using-the-android-ndk-vulkan-kompute-1e9da37b7617" rel="nofollow">Android NDK Mobile Kompute ML Application</a></li>
<li><a href="https://towardsdatascience.com/supercharging-game-development-with-gpu-accelerated-ml-using-vulkan-kompute-the-godot-game-engine-4e75a84ea9f0" rel="nofollow">Game Development Kompute ML in Godot Engine</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python Package</h2><a id="user-content-python-package" aria-label="Permalink: Python Package" href="#python-package"></a></p>
<p dir="auto">Besides the C++ core SDK you can also use the Python package of Kompute, which exposes the same core functionality, and supports interoperability with Python objects like Lists, Numpy Arrays, etc.</p>
<p dir="auto">The only dependencies are Python 3.5+ and Cmake 3.4.1+. You can install Kompute from the <a href="https://pypi.org/project/kp/" rel="nofollow">Python pypi package</a> using the following command.</p>

<p dir="auto">You can also install from master branch using:</p>
<div data-snippet-clipboard-copy-content="pip install git+git://github.com/KomputeProject/kompute.git@master"><pre><code>pip install git+git://github.com/KomputeProject/kompute.git@master
</code></pre></div>
<p dir="auto">For further details you can read the <a href="https://kompute.cc/overview/python-package.html" rel="nofollow">Python Package documentation</a> or the <a href="https://kompute.cc/overview/python-reference.html" rel="nofollow">Python Class Reference documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">C++ Build Overview</h2><a id="user-content-c-build-overview" aria-label="Permalink: C++ Build Overview" href="#c-build-overview"></a></p>
<p dir="auto">The build system provided uses <code>cmake</code>, which allows for cross platform builds.</p>
<p dir="auto">The top level <code>Makefile</code> provides a set of optimized configurations for development as well as the docker image build, but you can start a build with the following command:</p>

<p dir="auto">You also are able to add Kompute in your repo with <code>add_subdirectory</code> - the <a href="https://github.com/KomputeProject/kompute/blob/7c8c0eeba2cdc098349fcd999102bb2cca1bf711/examples/android/android-simple/app/src/main/cpp/CMakeLists.txt#L3">Android example CMakeLists.txt file</a> shows how this would be done.</p>
<p dir="auto">For a more advanced overview of the build configuration check out the <a href="https://kompute.cc/overview/build-system.html" rel="nofollow">Build System Deep Dive</a> documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kompute Development</h2><a id="user-content-kompute-development" aria-label="Permalink: Kompute Development" href="#kompute-development"></a></p>
<p dir="auto">We appreciate PRs and Issues. If you want to contribute try checking the "Good first issue" tag, but even using Kompute and reporting issues is a great contribution!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Dev Dependencies</h4><a id="user-content-dev-dependencies" aria-label="Permalink: Dev Dependencies" href="#dev-dependencies"></a></p>
<ul dir="auto">
<li>Testing
<ul dir="auto">
<li>GTest</li>
</ul>
</li>
<li>Documentation
<ul dir="auto">
<li>Doxygen (with Dot)</li>
<li>Sphynx</li>
</ul>
</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Development</h4><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<ul dir="auto">
<li>Follows Mozilla C++ Style Guide <a href="https://www-archive.mozilla.org/hacking/mozilla-style-guide.html" rel="nofollow">https://www-archive.mozilla.org/hacking/mozilla-style-guide.html</a>
<ul dir="auto">
<li>Uses post-commit hook to run the linter, you can set it up so it runs the linter before commit</li>
<li>All dependencies are defined in vcpkg.json</li>
</ul>
</li>
<li>Uses cmake as build system, and provides a top level makefile with recommended command</li>
<li>Uses xxd (or xxd.exe windows 64bit port) to convert shader spirv to header files</li>
<li>Uses doxygen and sphinx for documentation and autodocs</li>
<li>Uses vcpkg for finding the dependencies, it's the recommended set up to retrieve the libraries</li>
</ul>
<p dir="auto">If you want to run with debug layers you can add them with the <code>KOMPUTE_ENV_DEBUG_LAYERS</code> parameter as:</p>
<div data-snippet-clipboard-copy-content="export KOMPUTE_ENV_DEBUG_LAYERS=&quot;VK_LAYER_LUNARG_api_dump&quot;"><pre><code>export KOMPUTE_ENV_DEBUG_LAYERS="VK_LAYER_LUNARG_api_dump"
</code></pre></div>
<p dir="auto"><h5 tabindex="-1" dir="auto">Updating documentation</h5><a id="user-content-updating-documentation" aria-label="Permalink: Updating documentation" href="#updating-documentation"></a></p>
<p dir="auto">To update the documentation you will need to:</p>
<ul dir="auto">
<li>Run the gendoxygen target in the build system</li>
<li>Run the gensphynx target in the build-system</li>
<li>Push to github pages with <code>make push_docs_to_ghpages</code></li>
</ul>
<p dir="auto"><h5 tabindex="-1" dir="auto">Running tests</h5><a id="user-content-running-tests" aria-label="Permalink: Running tests" href="#running-tests"></a></p>
<p dir="auto">Running the unit tests has been significantly simplified for contributors.</p>
<p dir="auto">The tests run on CPU, and can be triggered using the ACT command line interface (<a href="https://github.com/nektos/act">https://github.com/nektos/act</a>) - once you install the command line (And start the Docker daemon) you just have to type:</p>
<div data-snippet-clipboard-copy-content="$ act

[Python Tests/python-tests] 🚀  Start image=axsauze/kompute-builder:0.2
[C++ Tests/cpp-tests      ] 🚀  Start image=axsauze/kompute-builder:0.2
[C++ Tests/cpp-tests      ]   🐳  docker run image=axsauze/kompute-builder:0.2 entrypoint=[&quot;/usr/bin/tail&quot; &quot;-f&quot; &quot;/dev/null&quot;] cmd=[]
[Python Tests/python-tests]   🐳  docker run image=axsauze/kompute-builder:0.2 entrypoint=[&quot;/usr/bin/tail&quot; &quot;-f&quot; &quot;/dev/null&quot;] cmd=[]
..."><pre><code>$ act

[Python Tests/python-tests] 🚀  Start image=axsauze/kompute-builder:0.2
[C++ Tests/cpp-tests      ] 🚀  Start image=axsauze/kompute-builder:0.2
[C++ Tests/cpp-tests      ]   🐳  docker run image=axsauze/kompute-builder:0.2 entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
[Python Tests/python-tests]   🐳  docker run image=axsauze/kompute-builder:0.2 entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
...
</code></pre></div>
<p dir="auto">The repository contains unit tests for the C++ and Python code, and can be found under the <code>test/</code> and <code>python/test</code> folder.</p>
<p dir="auto">The tests are currently run through the CI using Github Actions. It uses the images found in <code>docker-builders/</code>.</p>
<p dir="auto">In order to minimise hardware requirements the tests can run without a GPU, directly in the CPU using <a href="https://github.com/google/swiftshader">Swiftshader</a>.</p>
<p dir="auto">For more information on how the CI and tests are setup, you can go to the <a href="https://kompute.cc/overview/ci-tests.html" rel="nofollow">CI, Docker and Tests Section</a> in the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivations</h2><a id="user-content-motivations" aria-label="Permalink: Motivations" href="#motivations"></a></p>
<p dir="auto">This project started after seeing that a lot of new and renowned ML &amp; DL projects like Pytorch, Tensorflow, Alibaba DNN, Tencent NCNN - among others - have either integrated or are looking to integrate the Vulkan SDK to add mobile (and cross-vendor) GPU support.</p>
<p dir="auto">The Vulkan SDK offers a great low level interface that enables for highly specialized optimizations - however it comes at a cost of highly verbose code which requires 500-2000 lines of code to even begin writing application code. This has resulted in each of these projects having to implement the same baseline to abstract the non-compute related features of the Vulkan SDK. This large amount of non-standardised boiler-plate can result in limited knowledge transfer, higher chance of unique framework implementation bugs being introduced, etc.</p>
<p dir="auto">We are currently developing Kompute not to hide the Vulkan SDK interface (as it's incredibly well designed) but to augment it with a direct focus on the Vulkan SDK's GPU computing capabilities. <a href="https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a" rel="nofollow">This article</a> provides a high level overview of the motivations of Kompute, together with a set of hands on examples that introduce both GPU computing as well as the core Kompute architecture.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A search engine by and for the federal government (159 pts)]]></title>
            <link>https://search.gov/</link>
            <guid>41009021</guid>
            <pubDate>Fri, 19 Jul 2024 17:43:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://search.gov/">https://search.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=41009021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-container">
    <main id="main-content">
    

    
    <div>
          <h4>New report — 2023 in review</h4>
          <p>
            Search.gov supports one third of federal government domains. Learn what the public was searching for on these websites last year. <a href="https://search.gov/about/updates/year-in-review/2023-year-in-review/overview.html">Read the report</a>
            <!-- <a class="usa-link" href="javascript:void(0);">Read the report.</a> -->
          </p>
        </div>

<div>
      <h2>A search engine by and for the federal government
      </h2>
      <p>Powering search results on more than 2,000 websites. Free, effective, and simple—Search.gov has all you need to get search right on your website!</p>
      <p><a href="https://search.gov/get-started/">Get started today</a>
    </p></div>

<div>
        
        <p><strong>Built for government —</strong> Secure, compliant, designed around the unique circumstances of government web publishing.</p>
        <p><strong>Highly configurable —</strong> No developers required - use our easy interface to design your search experience yourself.</p>
        <p><strong>Hands-on customer service —</strong> We're here to help you, from implementation to SEO.</p>
        <p><strong>No barriers to entry —</strong> Getting started with Search.gov is friction free.</p>
        <p><a href="https://search.gov/about/why-choose-searchgov.html">Learn more</a>
    </p></div>

<div>
    <h2><strong>How do I get search right</strong> on my website?</h2>
    <ul>
      <li>
        <div>
          
          <p>Curious about how to properly index your federal agency website? We can help you get started with our training and resources on indexing.</p>
          
        </div>
      </li>
      <li>
        <div>
          
          <p>Want to improve your results? Having trouble with results missing? Learn more about how to improve your search experience.</p>
          
        </div>
      </li>
      <li>
        <div>
          
          <p>Making improvements to your site can be exciting but also daunting. We created a guide to help you keep your search working well on the new site.</p>
          
        </div>
      </li>
    </ul>
  </div>

<div>
        <h2>How do I...</h2>
        
    </div>


    </main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CrowdStrike is not worth 83B Dollars (112 pts)]]></title>
            <link>https://old.reddit.com/r/wallstreetbets/comments/1e6ms9z/crowdstrike_is_not_worth_83_billion_dollars</link>
            <guid>41008821</guid>
            <pubDate>Fri, 19 Jul 2024 17:26:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/wallstreetbets/comments/1e6ms9z/crowdstrike_is_not_worth_83_billion_dollars">https://old.reddit.com/r/wallstreetbets/comments/1e6ms9z/crowdstrike_is_not_worth_83_billion_dollars</a>, See on <a href="https://news.ycombinator.com/item?id=41008821">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Thesis</strong>: Crowdstrike is not worth 93 billion dollars (at time of writing).</p>

<p><strong>Fear</strong>: CrowdStrike is an enterprise-grade employee spying app masquerading as a cloud application observability dashboard.</p>

<p><strong>OBSERVATIONS</strong></p>

<ul>
<li>The 75th percentile retail investor has a tenuous grasp on “Cloud”, “Software Engineering”, and “Cyber Security”.</li>
<li>The median “Cyber Security Analyst” has a tenuous grasp on “Cyber Security”</li>
<li>The median “Software Engineer” has a tenuous grasp on “Cyber Security” and “Cloud”</li>
<li>The median retail investor has a tenuous grasp on “markets” and “liquidity pools”</li>
</ul>

<p><strong>CRITIQUES</strong></p>

<ul>
<li><p>Corporations could buy CrowdStrike to spy on their own employees.</p></li>
<li><p>CrowdStrike’s utility is limited- they simply collect all of their customer’s data and display it on a dashboard. </p></li>
<li><p>CrowdStrike is dangerous in that they have root access to every device(i.e. endpoint) across thousands of firms.</p></li>
<li><p>CrowdStrike customers sign up to get their firm’s data added to a bank which CrowdStrike then has license to use for “correlation”</p></li>
<li><p>CrowdStrike is a sitting-duck datamine for the FBI/NSA to subpoena. </p></li>
<li><p>CrowdStrike could potentially behave as a propaganda arm of the US government by creating “fake hacking stories” which are un-disprovable.They are able to do this due to information asymmetries in society.</p></li>
<li><p>Properly built “cloud applications” have security baked in by virtue of separation of concerns in the "software supply chain". (e.g. containerization engine developer is different than the OS developer is different than the Cloud Infrastructure Provider). </p></li>
<li><p>CrowdStrike’s Falcon product contradicts their own guiding principle of “Zero-Trust Security”.</p></li>
</ul>

<p><strong>COMMENTARY</strong></p>

<ul>
<li>CrowdStrike’s product includes a “client” which runs on every "customer endpoint” (i.e. company issued laptop). Activity on the company issued laptop is reported to an internal dashboard which only an IT guy + a C-Suite admin have access to. They ALSO offer observability into each component of a business’s own “cloud application”.</li>
<li>These are 100% different lines of business which can be easily conflated.</li>
<li>CrowdStrike admits that they collect all of a business’ “endpoint data'' and they compare it to other data they have to "draw insights"; this means that every company that hires CrowdStrike is part of a DATA COMMUNE.</li>
<li>It’s prohibitively hard to hack into a “cloud system” due to few possible entry points</li>
<li>Exfiltrating data at scale is difficult; employees of the company pose a bigger threat than "threat-actors".</li>
<li><em>Containerize Everything</em> + <em>Microservices Architecture</em> hampers "lateral movement". </li>
<li>Is CrowdStrike compatible with companies that run their IT systems on premises?</li>
</ul>

<p><em>The CrowdStrike Story So Far…</em></p>

<p><strong>2020</strong></p>

<ul>
<li><p>“Uses cloud technology to detect and thwart attempted cybersecurity breaches”</p></li>
<li><p>“Runs on your endpoint or server or workload”</p></li>
<li><p>“Signature based technologies don’t go far enough”</p></li>
<li><p>“We collect trillions of events” </p></li>
<li><p>“There hasn’t been a salesforce of security” </p></li>
</ul>

<p>—  FAST FORWARD — </p>

<p><strong>2024</strong></p>

<ul>
<li>Palo Alto Networks(100% different business line) is being pitted against CrowdStrike in the media. </li>
<li>Crowdstrike allegedly offers a poorly differentiated suite of generically titled products: <strong>(Falcon Discover, Falcon Spotlight, Falcon Prevent, Falcon Horizon, Falcon Insight(EDR), Falcon Insight(XDR), Falcon Overwatch, Falcon Complete(MDR), Falcon Cloud Security)</strong>. There is no way to confirm unless you schedule a meeting with their team though.</li>
<li>I spoke to a “Network Engineer” at CrowdStrike. He said that he “mostly tries to get bug bounties”. </li>
<li>“CrowdStrike сustomers: 44 of 100 Fortune 100 companies, 37 of 100 top global companies, 9 of 20 major banks &amp; 7 of the TOP 10 largest energy institutions.”  This makes it a threat vector.</li>
</ul>

<p>Misleading videos on their site: </p>

<ul>
<li><a href="https://vid.crowdstrike.com/watch/P4xk1x3PaH1D6rR4MiW2F5">https://vid.crowdstrike.com/watch/P4xk1x3PaH1D6rR4MiW2F5</a>? </li>
<li><a href="https://www.youtube.com/watch?v=9x7eiznCfAg">https://www.youtube.com/watch?v=9x7eiznCfAg</a> </li>
<li><a href="https://www.crowdstrike.com/platform/cloud-security/cspm/">https://www.crowdstrike.com/platform/cloud-security/cspm/</a> </li>
</ul>

<p><strong>My Position:</strong></p>

<ul>
<li>CRWD $185 Put, 11/21/25 expiration date,.</li>
<li>5 contracts @ $7.30, up 16.85% since 06/11/24 </li>
</ul>

<p><em>First Draft/Final Draft: June 11th/July 18th</em></p>

<p>Edit: <a href="https://imgur.com/a/Q09o7iY">Gains</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playing guitar tablatures in Rust (139 pts)]]></title>
            <link>https://agourlay.github.io/ruxguitar-tablature-player/</link>
            <guid>41008488</guid>
            <pubDate>Fri, 19 Jul 2024 16:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://agourlay.github.io/ruxguitar-tablature-player/">https://agourlay.github.io/ruxguitar-tablature-player/</a>, See on <a href="https://news.ycombinator.com/item?id=41008488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>If you ever tried to learn guitar, chances are you are familiar with guitar tablatures.</p>
<p>It is a simple way to visualize music for guitar, using ASCII characters to represent strings and frets as an alternative to sheet music.</p>
<p>For instance, here are the first four measures of the song "Smoke on the Water" by Deep Purple:</p>
<pre data-lang="txt"><code data-lang="txt"><span>e|-----------------|-----------------|-----------------|-----------------|
</span><span>B|-----------------|-----------------|-----------------|-----------------|
</span><span>G|-----3---5-------|---3---6-5-------|-----3---5-----3-|-----------------|
</span><span>D|-5---3---5-----5-|---3---6-5-------|-5---3---5-----3-|---5-------------|
</span><span>A|-5-------------5-|-----------------|-5---------------|---5-------------|
</span><span>E|-----------------|-----------------|-----------------|-----------------| &lt;- top
</span></code></pre>
<p>This song is played in standard tuning (EADGBe), which is conveyed by the letters on the left indicating the tuning for each string. While the numbers indicate where to put your fingers on the fretboard.</p>
<p>Beyond the text representation, the defacto standard is the format used by the <a href="https://www.guitar-pro.com/">Guitar Pro</a> software to render and synthetize sound for the tablature.</p>
<p>Those binary files have the <code>.gp3</code>, <code>.gp4</code>, <code>.gp5</code> or <code>.gp6</code> extension depending on the software version used to produce them, and can be easily found on the internet on websites such as <a href="https://www.ultimate-guitar.com/">Ultimate Guitar</a>.</p>
<p>Although the software to play the tablature is proprietary, some versions of the file format are well documented, and there are even open-source projects that can read them.</p>
<p>The best OSS tablature player is probably <a href="https://sourceforge.net/projects/tuxguitar/">TuxGuitar</a> which is very feature-rich and a fantastic tool to learn guitar.</p>
<p>Since <code>TuxGuitar</code> appears to be unmaintained and Java based, I thought it would be a fun challenge to write my own tablature player in Rust.</p>
<h2 id="introducing-ruxguitar">Introducing Ruxguitar</h2>
<p>I named my project <code>Ruxguitar</code>, a portmanteau of <code>Rust</code> and <code>Guitar</code>.</p>
<p>The project is still in its early stages, but I believe it is now functional enough to be officially announced to the world - aka this very blog post!</p>
<p>Rather than describing what the project does, have a look at the following video which shows the tablature player in action with a song a bit more complex:</p>
<video id="myVideo" controls="" width="640" height="480">
  <source src="https://agourlay.github.io/2024-07-14/ruxguitar.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
<p>You can obviously find the source code on <a href="https://github.com/agourlay/ruxguitar">GitHub</a> with pre-built <a href="https://github.com/agourlay/ruxguitar/releases">binaries</a> available for Linux, macOS and Windows.</p>
<p>Feel free to go play with it and come back when you want to read the rest of this post which will detail various aspects of the internals.</p>
<h2 id="parsing-the-tablature">Parsing the tablature</h2>
<p>The first step in building a tablature player is to parse the binary tablature file.</p>
<p>During my research, I found a specification of the <code>.gp4</code> file format on <a href="https://dguitar.sourceforge.net/GP4format.html">dguitar</a> to get started.</p>
<p>The structure of the file is roughly the following:</p>
<ol>
<li>file version to know which version of the file format is used</li>
<li>information about the piece (e.g. title, subtitle, artist, album, etc.)</li>
<li>lyrics</li>
<li>number of measures and number of tracks</li>
<li>measures per track in the following order:
<ul>
<li>measure 1/track 1</li>
<li>measure 1/track 2</li>
<li>...</li>
<li>measure 1/track m</li>
<li>measure 2/track 1</li>
<li>measure 2/track 2</li>
<li>...</li>
<li>measure 2/track m</li>
<li>...</li>
<li>measure n/track 1</li>
<li>measure n/track 2</li>
<li>...</li>
<li>measure n/track m</li>
</ul>
</li>
<li>within each measure, we find the number of beats to read</li>
<li>within each beat, we find the beat duration and the number of notes to read</li>
<li>within each note, we find the string, the fret, the duration, the effect, etc.</li>
</ol>
<p>I decided to use the <a href="https://github.com/rust-bakery/nom">nom</a> crate to parse the tablature because I am <a href="https://github.com/agourlay/hprof-slurp">familiar</a> with it for parsing binary format.</p>
<p>Here is a quick peek at the code driving the parser so you get an idea of how it looks:</p>
<pre data-lang="rust"><code data-lang="rust"><span>pub fn </span><span>parse_gp_data</span><span>(</span><span>file_data</span><span>: &amp;[</span><span>u8</span><span>]) -&gt; Result&lt;Song, RuxError&gt; {
</span><span>    </span><span>let </span><span>(rest, base_song) = </span><span>flat_map</span><span>(parse_gp_version, |</span><span>version</span><span>| {
</span><span>        </span><span>map</span><span>(
</span><span>            </span><span>tuple</span><span>((
</span><span>                </span><span>parse_info</span><span>(version),                                     
</span><span>                </span><span>cond</span><span>(version &lt; GpVersion::</span><span>GP5</span><span>, parse_bool),              
</span><span>                </span><span>cond</span><span>(version &gt;= GpVersion::</span><span>GP4</span><span>, parse_lyrics),           
</span><span>                </span><span>cond</span><span>(version &gt;= GpVersion::</span><span>GP5_10</span><span>, </span><span>take</span><span>(</span><span>19</span><span>usize</span><span>)),       
</span><span>                </span><span>cond</span><span>(version &gt;= GpVersion::</span><span>GP5</span><span>, parse_page_setup),       
</span><span>                </span><span>cond</span><span>(version &gt;= GpVersion::</span><span>GP5</span><span>, parse_int_sized_string), 
</span><span>                parse_int,                                               
</span><span>                </span><span>cond</span><span>(version &gt; GpVersion::</span><span>GP5</span><span>, parse_bool),              
</span><span>                parse_signed_byte,                                       
</span><span>                </span><span>cond</span><span>(version &gt; GpVersion::</span><span>GP3</span><span>, parse_int),               
</span><span>                parse_midi_channels,                                     
</span><span>            )),
</span><span>            </span><span>move </span><span>|(
</span><span>                song_info,
</span><span>                triplet_feel,
</span><span>                lyrics,
</span><span>                _master_effect,
</span><span>                page_setup,
</span><span>                tempo_name,
</span><span>                tempo,
</span><span>                hide_tempo,
</span><span>                key_signature,
</span><span>                octave,
</span><span>                midi_channels,
</span><span>            )| {
</span><span>                </span><span>// init base song
</span><span>                </span><span>let</span><span> tempo = Tempo::new(tempo, tempo_name);
</span><span>                Song {
</span><span>                    version,
</span><span>                    song_info,
</span><span>                    triplet_feel,
</span><span>                    lyrics,
</span><span>                    page_setup,
</span><span>                    tempo,
</span><span>                    hide_tempo,
</span><span>                    key_signature,
</span><span>                    octave,
</span><span>                    midi_channels,
</span><span>                    measure_headers: vec![],
</span><span>                    tracks: vec![],
</span><span>                }
</span><span>            },
</span><span>        )
</span><span>    })(file_data)
</span><span>    .</span><span>map_err</span><span>(|</span><span>_err</span><span>| {
</span><span>        log::error!("</span><span>Failed to parse GP data</span><span>");
</span><span>        RuxError::ParsingError("</span><span>Failed to parse GP data</span><span>".</span><span>to_string</span><span>())
</span><span>    })?;
</span><span>    </span><span>// parse tracks &amp; measures
</span><span>    ...
</span></code></pre>
<p>The heavy lifting required to parse the tracks and the measures is done in a different function that will be skipped for brevity.</p>
<p>At some point it became quite tedious to handle the various versions of the file format and I decided to focus on the <code>.gp5</code> version which is widely used.</p>
<p>To be honest, this part was rather challenging because the file format is quite complex and the documentation is not always clear.</p>
<p>Luckily I was able to inspect the parsers from <code>TuxGuitar</code> and the <a href="https://github.com/slundi/guitarpro">guitarpro</a> crate to get a better understanding of the file format.</p>
<p>To ensure correctness, I have written a few unit tests for specific tablature files to check that the parser is working as expected.</p>
<p>This approach is useful to get started but not very scalable, so I am also validating some high level invariants of the resulting <code>Song</code> structure over a directory containing several hundred tablatures.</p>
<p>I found a few bugs in the parser this way and I am confident that the parser is working as expected.</p>
<h2 id="building-a-ui">Building a UI</h2>
<p>At this point, we have an in-memory representation of the tablature but no way to display it.</p>
<p>Not only should the user be able to see the tablature but also be able to interact with it.</p>
<p>I really wanted to use a native GUI library to ensure that the application would look and feel like a native application on all platforms.</p>
<p>The <a href="https://areweguiyet.com/">state</a> of GUI libraries in Rust required me to do some research.</p>
<p>I needed a truly event-based library to handle the synchronization during playback while also being able to draw the tablature in a custom way with some kind of canvas abstraction.</p>
<p>Based on those requirements, I decided to give <a href="https://iced.rs/">Iced</a> a spin as it checked all the boxes.</p>
<p>Spoiler alert: I am very happy with my choice so I did not try other libraries.</p>
<h2 id="iced">Iced</h2>
<p>The <code>Iced</code> library is very well written but could benefit from a bit more documentation.</p>
<p>I recommend reading the source code of the <a href="https://github.com/iced-rs/iced/tree/master/examples">examples</a> to get a better understanding of how to use the library.</p>
<p>I started with the <a href="https://github.com/iced-rs/iced/tree/master/examples/editor">text editor</a> example which I slowly adapted to my needs.</p>
<p>At some point, I ran into a bug in version <code>0.12.0</code> which forced me to upgrade to the <code>0.13.0</code> version which was not released yet.</p>
<p>This means I had to use the <code>main</code> branch of the <code>Iced</code> repository which was a bit scary but it worked out fine.</p>
<p>All the breakages I encountered were due to the <code>Iced</code> library being in active development and I am very grateful for the maintainers for their hard work.</p>
<p>The library is architectured around messages and subscriptions that trigger the update of the UI.</p>
<p>For instance, those are my messages:</p>
<pre data-lang="rust"><code data-lang="rust"><span>#[</span><span>derive</span><span>(Debug, Clone)]
</span><span>pub enum </span><span>Message {
</span><span>    OpenFile, </span><span>// open file dialog
</span><span>    FileOpened(Result&lt;(Vec&lt;</span><span>u8</span><span>&gt;, String), PickerError&gt;), </span><span>// file content &amp; file name
</span><span>    TrackSelected(TrackSelection), </span><span>// track selection
</span><span>    FocusMeasure(</span><span>usize</span><span>), </span><span>// used when clicking on measure in tablature
</span><span>    FocusTick(</span><span>usize</span><span>), </span><span>// focus on a specific tick in the tablature
</span><span>    PlayPause, </span><span>// toggle play/pause
</span><span>    StopPlayer, </span><span>// stop playback
</span><span>    ToggleSolo, </span><span>// toggle solo mode
</span><span>}
</span></code></pre>
<p>And this is the simplified application entry point:</p>
<pre data-lang="rust"><code data-lang="rust"><span>impl </span><span>RuxApplication {
</span><span>    </span><span>pub fn </span><span>start</span><span>(</span><span>args</span><span>: ApplicationArgs) -&gt; iced::Result {
</span><span>        iced::application(
</span><span>            RuxApplication::title,
</span><span>            RuxApplication::update,
</span><span>            RuxApplication::view,
</span><span>        )
</span><span>        .</span><span>subscription</span><span>(RuxApplication::subscription)
</span><span>        .</span><span>theme</span><span>(RuxApplication::theme)
</span><span>        .</span><span>font</span><span>(</span><span>ICONS_FONT</span><span>)
</span><span>        .</span><span>centered</span><span>()
</span><span>        .</span><span>antialiasing</span><span>(</span><span>true</span><span>)
</span><span>        .</span><span>run</span><span>()
</span><span>    }
</span><span>}
</span></code></pre>
<p>The application is built around functions that are orchestrated by the <code>Iced</code> engine appropriately.</p>
<p>The <code>update</code> function has for signature <code>Fn(&amp;mut State, Message) -&gt; C</code> where:</p>
<ul>
<li><code>State</code> is the application state that can be modified (here <code>RuxApplication</code>)</li>
<li><code>Message</code> is the message to process</li>
<li><code>C</code> is an output <code>Task</code> potentially producing a new <code>Message</code></li>
</ul>
<p>The <code>view</code> function has for signature <code>Fn(&amp;'a State) -&gt; Widget</code> is rendering a <code>Widget</code> based on the current <code>&amp;State</code>.</p>
<h2 id="drawing-the-tablature">Drawing the tablature</h2>
<p>I started by crafting the code which carefully draws a single measure on an <code>Iced::Canvas</code>.</p>
<p>This means:</p>
<ul>
<li>drawing each strings</li>
<li>for each beat, drawing the notes on the strings and potential beat effect (e.g. palm mute)</li>
<li>for each note, adding the potential note effect (e.g. slide, hammer-on, bend) </li>
<li>annotate the measure with additional information (e.g. measure number, tempo, part annotation, chord)</li>
</ul>
<p>It required a bit of trial and error to get the offsets right but I am happy with the result.</p>
<p><img src="https://agourlay.github.io/2024-07-14/measure.png" alt="single measure"></p>
<p>Once I have a collection of canvas measures, they are assembled in a responsive grid layout to display the whole tablature using the <code>wrap</code> widget from the <a href="https://github.com/iced-rs/iced_aw">iced-aw</a> crate.</p>
<p><img src="https://agourlay.github.io/2024-07-14/grid.png" alt="grid measures"></p>
<p>The measures can have different lengths depending on the number of beats which makes silent measures very small and crazy guitar solo measures long.</p>
<h2 id="making-sounds">Making sounds</h2>
<p>To recap, we have an in-memory representation of a tablature and we have the UI, now we need to make some sounds!</p>
<p>What we want is a way to turn each note, for each beat, for each measure, for each track into a specific sound at the <strong>right</strong> time.</p>
<p>This can be achieved using a MIDI synthesizer which is a software that can produce sounds based on MIDI events.</p>
<h2 id="synthesizing-midi-events">Synthesizing MIDI events</h2>
<p>There are different kinds of MIDI events but the most important for us are the <code>NoteOn</code> and <code>NoteOff</code> ones.</p>
<ul>
<li>Note On: Indicates that a note is being pressed. It includes the note number (pitch) and velocity (how hard the note is pressed).</li>
<li>Note Off: Indicates that a note is being released.</li>
</ul>
<p>For each note in the tablature, we can generate a pair of MIDI events annotated with:</p>
<ul>
<li>the timestamp, also referred as a tick, at which they should be executed.</li>
<li>the track to which they belong.</li>
</ul>
<pre data-lang="rust"><code data-lang="rust"><span>pub enum </span><span>MidiEventType {
</span><span>    NoteOn(</span><span>i32</span><span>, </span><span>i32</span><span>, </span><span>i16</span><span>),  </span><span>// midi channel, note, velocity
</span><span>    NoteOff(</span><span>i32</span><span>, </span><span>i32</span><span>),      </span><span>// midi channel, note
</span><span>    ...
</span><span>}
</span><span>
</span><span>pub struct </span><span>MidiEvent {
</span><span>    </span><span>pub </span><span>tick</span><span>: </span><span>usize</span><span>,
</span><span>    </span><span>pub </span><span>event</span><span>: MidiEventType,
</span><span>    </span><span>pub </span><span>track</span><span>: </span><span>usize</span><span>,
</span><span>}
</span></code></pre>
<p>All those events are pushed into a single array sorted by the event tick. </p>
<p>This approach provides an efficient way to find the next events to play at any given time via binary search later on.</p>
<p>Those <code>MidiEvents</code> can be transformed into audio waves using a synthetizer before being sent to the audio output.</p>
<p>For the synthetizer I settled on the <a href="https://github.com/sinshu/rustysynth">rustysynth</a> crate which provides a neat MIDI synthetizer.</p>
<p>Here is a simplified version of the code to play a MIDI event:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> synthesizer_settings = SynthesizerSettings::new(</span><span>SAMPLE_RATE </span><span>as </span><span>i32</span><span>);
</span><span>let mut</span><span> synthesizer = Synthesizer::new(&amp;sound_font, &amp;synthesizer_settings);
</span><span>
</span><span>let</span><span> midi_event = </span><span>// find next event to play
</span><span>match</span><span> midi_event.event {
</span><span>    MidiEventType::NoteOn(channel, key, velocity) =&gt; {
</span><span>        synthesizer.</span><span>note_on</span><span>(channel, key, velocity as </span><span>i32</span><span>);
</span><span>    }
</span><span>    MidiEventType::NoteOff(channel, key) =&gt; {
</span><span>        synthesizer.</span><span>note_off</span><span>(channel, key);
</span><span>    }
</span><span>    ...
</span><span>}                    
</span></code></pre>
<p>It is important to note that a synthetizer requires a soundfont file to produce sound.</p>
<p>For the sake of simplicity, I included the <code>TimGM6mb.sf2</code> soundfont file in the binary at compile time.</p>
<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>TIMIDITY_SOUND_FONT</span><span>: &amp;[</span><span>u8</span><span>] = include_bytes!("</span><span>../../resources/TimGM6mb.sf2</span><span>");
</span></code></pre>
<p>The trade-off is that the binary is a bit larger but the user does not have to worry about finding the soundfont file.</p>
<p>However, it is possible to provide a larger soundfont file to get better sound quality using the <code>--soundfont</code> command line argument.</p>
<p>For instance, I like to use <code>FluidR3_GM.sf2</code> which is present on most systems and easy to find online (<a href="https://musical-artifacts.com/artifacts/738">here</a> or <a href="https://member.keymusician.com/Member/FluidR3_GM/index.html">there</a>).</p>
<pre data-lang="bash"><code data-lang="bash"><span>./ruxguitar --sound-font-file</span><span> /usr/share/sounds/sf2/FluidR3_GM.sf2
</span></code></pre>
<h2 id="audio-loop">Audio loop</h2>
<p>The audio output stream is managed by a dedicated thread which will produce sound at a regular interval.</p>
<p>I picked the <a href="https://github.com/RustAudio/cpal">cpal</a> crate which is a cross-platform audio library.</p>
<p>Here is a simplified version of the code to setup an audio loop:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> host = cpal::default_host();
</span><span>let</span><span> device = host.</span><span>default_output_device</span><span>().</span><span>unwrap</span><span>();
</span><span>
</span><span>let</span><span> config = device.</span><span>default_output_config</span><span>().</span><span>unwrap</span><span>();
</span><span>let</span><span> stream_config: cpal::StreamConfig = config.</span><span>into</span><span>();
</span><span>
</span><span>let</span><span> channels_count = stream_config.channels as </span><span>usize</span><span>;
</span><span>assert_eq!(channels_count, </span><span>2</span><span>);
</span><span>
</span><span>// 4410 samples at 44100 Hz is 0.1 second
</span><span>let</span><span> mono_sample_count = </span><span>4410</span><span>;
</span><span>
</span><span>let mut</span><span> left: Vec&lt;</span><span>f32</span><span>&gt; = vec![</span><span>0_</span><span>f32</span><span>; mono_sample_count];
</span><span>let mut</span><span> right: Vec&lt;</span><span>f32</span><span>&gt; = vec![</span><span>0_</span><span>f32</span><span>; mono_sample_count];
</span><span>
</span><span>// build audio loop
</span><span>let</span><span> stream = device.</span><span>build_output_stream</span><span>(
</span><span>    &amp;stream_config,
</span><span>    </span><span>move </span><span>|output: &amp;</span><span>mut </span><span>[</span><span>f32</span><span>], _: &amp;cpal::OutputCallbackInfo| {
</span><span>        </span><span>let</span><span> midi_events = </span><span>// find events to play
</span><span>        </span><span>for</span><span> event in midi_events {
</span><span>            </span><span>// synthesize events
</span><span>            synthetizer.</span><span>process</span><span>(event)
</span><span>        }
</span><span>
</span><span>        </span><span>// Split buffer in two channels (left and right)
</span><span>        </span><span>let</span><span> channel_len = output.</span><span>len</span><span>() / channels_count;
</span><span>
</span><span>        </span><span>// Render the waveform.
</span><span>        synthesizer.</span><span>render</span><span>(&amp;</span><span>mut</span><span> left[..channel_len], &amp;</span><span>mut</span><span> right[..channel_len]);
</span><span>        
</span><span>        </span><span>// Interleave the left and right channels into the output buffer.
</span><span>        </span><span>for </span><span>(i, (l, r)) in left.</span><span>iter</span><span>().</span><span>zip</span><span>(right.</span><span>iter</span><span>()).</span><span>take</span><span>(channel_len).</span><span>enumerate</span><span>() {
</span><span>            output[i * </span><span>2</span><span>] = *l;
</span><span>            output[i * </span><span>2 </span><span>+ </span><span>1</span><span>] = *r;
</span><span>        }
</span><span>    }
</span><span>)
</span><span>// Start the stream.
</span><span>let</span><span> stream = stream.</span><span>unwrap</span><span>();
</span><span>stream.</span><span>play</span><span>().</span><span>unwrap</span><span>();
</span></code></pre>
<p>For each run of the audio loop, it is possible to compute the next window of time to process by taking into account:</p>
<ul>
<li>the current timestamp of the audio player</li>
<li>the tempo of the current measure</li>
<li>how much time has passed since the previous interval</li>
</ul>
<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>QUARTER_TIME</span><span>: </span><span>i32 </span><span>= </span><span>960</span><span>; </span><span>// 1 quarter note = 960 ticks
</span><span>
</span><span>fn </span><span>tick_increase</span><span>(</span><span>tempo_bpm</span><span>: </span><span>i32</span><span>, </span><span>elapsed_seconds</span><span>: </span><span>f64</span><span>) -&gt; </span><span>usize </span><span>{
</span><span>    </span><span>let</span><span> tempo_bps = tempo_bpm as </span><span>f64 </span><span>/ </span><span>60.0</span><span>;
</span><span>    </span><span>let</span><span> bump = </span><span>QUARTER_TIME </span><span>as </span><span>f64 </span><span>* tempo_bps * elapsed_seconds;
</span><span>    bump as </span><span>usize
</span><span>}
</span></code></pre>
<p>Using the resulting tick increase, we can efficiently query our array of MIDI events to find the next events to play using binary search.</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> tick_increase = </span><span>tick_increase</span><span>(tempo, elapsed_seconds);
</span><span>let</span><span> next_tick = </span><span>self</span><span>.current_tick + tick_increase;
</span><span>// assume we already have a cursor for the start of the events (a.k.a. the index of the last event played)
</span><span>let</span><span> start_index = </span><span>self</span><span>.current_cursor;
</span><span>let</span><span> end_index = </span><span>match</span><span> sorted_events[start_index..].</span><span>binary_search_by_key</span><span>(start_index, |</span><span>event</span><span>| event.tick)
</span><span>{
</span><span>    Ok(next_position) =&gt; start_index + next_position,
</span><span>    Err(next_position) =&gt; {
</span><span>        </span><span>if</span><span> next_position == </span><span>0 </span><span>{
</span><span>            </span><span>// no matching elements
</span><span>            </span><span>return </span><span>Some(&amp;[]);
</span><span>        }
</span><span>        </span><span>// return slice until the last event
</span><span>        start_index + next_position - </span><span>1
</span><span>    }
</span><span>};
</span><span>// return slice of events to play
</span><span>return </span><span>Some(&amp;</span><span>self</span><span>.sorted_events[start_index..=end_index])
</span></code></pre>
<p>Now that we have the audio loop running, we can focus on the integration between the audio player and the UI.</p>
<h2 id="putting-it-all-together">Putting it all together</h2>
<p>Having a perfect integration is crucial to providing a smooth user experience: </p>
<ul>
<li>
<p>when clicking on the "Play" button, the tablature cursor should start moving, the notes should be highlighted as they are played.</p>
</li>
<li>
<p>when a measure is clicked, the player should jump to the corresponding position in the tablature and the correct notes should be played.</p>
</li>
<li>
<p>when clicking on a different track, the whole tablature should be updated to show the new track and the sound should be updated accordingly.</p>
</li>
<li>
<p>when clicking on the "Solo" button, all other tracks should be muted.</p>
</li>
<li>
<p>when clicking on the "Stop" button, the tablature cursor should be reset to the beginning and the sound should stop. </p>
</li>
</ul>
<p>I think you get the idea.</p>
<p>The critical bridge between the audio player and the UI is implemented using the <code>iced::Subscription</code> mechanism.</p>
<p>Subscriptions are a way to listen to external events and publish them as messages to the application.</p>
<p>For instance, here is how the application reacts to pressing the space bar to toggle the playback:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> keyboard_subscription = keyboard::on_key_press(|</span><span>key</span><span>, </span><span>_modifiers</span><span>| </span><span>match</span><span> key.</span><span>as_ref</span><span>() {
</span><span>    keyboard::Key::Named(Space) =&gt; Some(Message::PlayPause),
</span><span>    _ =&gt; None,
</span><span>});
</span></code></pre>
<p>The update function does not care whether the message has been triggered by the keyboard or by clicking on the "Play" button.</p>
<p>Using a similar mechanism, the audio player can send messages to the application to update the UI based on the current playback position.</p>
<p>The application holds the receiving end of an <a href="https://docs.rs/tokio/latest/tokio/sync/watch/index.html">tokio::sync::watch</a> channel containing the current timestamp which is published by the audio thread.</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>audio_player_beat_subscription</span><span>(&amp;</span><span>self</span><span>) -&gt; impl Stream&lt;Item = Message&gt; {
</span><span>    </span><span>let</span><span> beat_receiver = </span><span>self</span><span>.beat_receiver.</span><span>clone</span><span>();
</span><span>    stream::channel(</span><span>1</span><span>, </span><span>move </span><span>|</span><span>mut</span><span> output| async </span><span>move </span><span>{
</span><span>        </span><span>let mut</span><span> receiver = beat_receiver.</span><span>lock</span><span>().await;
</span><span>        </span><span>loop </span><span>{
</span><span>            </span><span>// get tick from audio player
</span><span>            </span><span>let</span><span> tick = *receiver.</span><span>borrow_and_update</span><span>();
</span><span>            </span><span>// publish to UI
</span><span>            output
</span><span>                .</span><span>send</span><span>(Message::FocusTick(tick))
</span><span>                .await
</span><span>                .</span><span>expect</span><span>("</span><span>send failed</span><span>");
</span><span>            </span><span>// wait for next beat
</span><span>            receiver.</span><span>changed</span><span>().await.</span><span>expect</span><span>("</span><span>receiver failed</span><span>");
</span><span>        }
</span><span>    })
</span><span>}
</span><span>...
</span><span>// setup subscription
</span><span>Subscription::run_with_id("</span><span>audio-player-beat</span><span>", audio_player_beat_subscription));
</span></code></pre>
<p>The tablature processes the <code>FocusTick</code> message to update the current measure position and highlight the notes.</p>
<p><img src="https://agourlay.github.io/2024-07-14/measure-cursor.gif" alt="measure cursor"></p>
<p>A <strong>lot</strong> of details were required to maintain the illusion that everything is properly synchronized with the user's actions.</p>
<h2 id="future-work">Future work</h2>
<p>The current version of <code>Ruxguitar</code> is pretty much an MVP to get the project started.</p>
<p>It is nowhere near <code>TuxGuitar</code> in terms of features and usability.</p>
<p>Here are a few ideas for the future:</p>
<ul>
<li>support more file formats (currently only <code>.gp5</code> is supported)</li>
<li>display more information about the tablature (e.g. rhythm, time signature, key signature etc.)</li>
<li>support repeating measures</li>
<li>support slowing down and speeding up the playback</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I have been working on <code>Ruxguitar</code> over the past year and I am very happy with the result.</p>
<p>Not only did I learn a lot on the way but I also actually built a complex piece of software that appears to work.</p>
<p>Working on such a large project alone required a lot of discipline because there were many times when I felt like giving up, running into cryptic bugs or being stuck on a feature for weeks.</p>
<p>It would have been impossible to build <code>Ruxguitar</code> without <code>TuxGuitar</code> as a reference implementation and I am very grateful for the work done by the <code>TuxGuitar</code> team over the years.</p>
<p>After so much work on this project, it's about time I get back to playing guitar instead of writing software for it!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Later Years of Douglas Adams (112 pts)]]></title>
            <link>https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/</link>
            <guid>41008174</guid>
            <pubDate>Fri, 19 Jul 2024 16:29:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/">https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/</a>, See on <a href="https://news.ycombinator.com/item?id=41008174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
														<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/douglas-adams-inspired-hitch-hikers-guide-to-the-galaxy-h2g2/" rel="attachment wp-att-6033"><img fetchpriority="high" decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/Douglas_adams_portrait_cropped.jpg" alt="" width="333" height="386" srcset="https://www.filfre.net/wp-content/uploads/2024/07/Douglas_adams_portrait_cropped.jpg 333w, https://www.filfre.net/wp-content/uploads/2024/07/Douglas_adams_portrait_cropped-259x300.jpg 259w" sizes="(max-width: 333px) 100vw, 333px"></a></p>
<p>If God exists, he must have a sense of humor, for why else would he have strewn so many practical jokes around his creation? Among them is the uncanny phenomenon of the talented writer who absolutely hates to write.</p>
<p>Mind you, I don’t mean just the usual challenges which afflict all of us architects of sentences and paragraphs. Even after all these years of writing these pieces for you, I’m still daunted every Monday morning to face a cursor blinking inscrutably at the top of a blank page, knowing as I do that that space has to be filled with a readable, well-constructed article by the time I knock off work the following Friday evening. In the end, though, that’s the sort of thing that any working writer knows how to get through, generally by simply starting to write something — anything, even if you’re pretty sure it’s the wrong thing. Then the sentences start to flow, and soon you’re trucking along nicely, almost as if the article has started to write itself. Whatever it gets wrong about itself can always be sorted out in revision and editing.</p>
<p>No, the kind of agony which proves that God must be a trickster is far more extreme than the kind I experience every week. It’s the sort of birth pangs suffered by Thomas Harris, the conjurer of everybody’s favorite serial killer Hannibal Lecter, every time he tries to write a new novel. Stephen King — an author who most definitely does <em>not</em> have any difficulty putting pen to paper — has described the process of writing as a “kind of torment” for his friend Harris, one which leaves him “writhing on the floor in frustration.” Small wonder that the man has produced just six relatively slim novels over a career spanning 50 years.</p>
<p>Another member of this strange club of prominent writers who hate to write is the Briton <a href="https://www.filfre.net/2013/11/douglas-adams">Douglas Adams</a>, the mastermind of <em>The Hitchhiker’s Guide to the Galaxy</em>. Throughout his career, he was one of genre fiction’s most infuriating problem children, the bane of publishers, accountants, lawyers, and anyone else who ever had a stake in his actually sitting down and writing the things he had agreed to write. Given his druthers, he would prefer to sit in a warm bath, as he put it himself, enjoying the pleasant whooshing sound the deadlines made as they flew by just outside his window.</p>
<p>That said, Adams did manage to give outsiders at least the impression that he was a motivated, even driven writer over the first seven years or so of <em>Hitchhiker’s</em>, from 1978 to 1984. During that period, he scripted the twelve half-hour radio plays that were the foundation of the whole franchise, then turned them into four novels. He also assisted with a six-episode <em>Hitchhiker’s</em> television series, even co-designed a hit <a href="https://www.filfre.net/2013/11/hitchhiking-the-galaxy-infocom-style"><em>Hitchhiker’s</em> text adventure</a> with Steve Meretzky of Infocom. Adams may have hated the actual act of writing, but he very much liked the fortune and fame it brought him; the former because it allowed him to expand his collection of computers, stereos, guitars, and other high-tech gadgetry, the latter because it allowed him to expand the profile and diversity of guests whom he invited to his legendary dinner parties.</p>
<p>Still, what with fortune and fame having become something of a done deal by 1984, his instinctive aversion to the exercising of his greatest talent was by then beginning to set in in earnest. His publisher got the fourth <em>Hitchhiker’s</em> novel out of him that summer only by moving into a hotel suite with him, standing over his shoulder every day, and all but physically forcing him to write it. Steve Meretzky had to <a href="https://www.filfre.net/2013/11/the-computerized-hitchhikers">employ a similar tactic</a> to get him to buckle down and create a design document for the <em>Hitchhiker’s</em> game, which joined the fourth novel that year to become one of the final artifacts of the franchise’s golden age.</p>
<p>Adams was just 32 years old at this point, as wealthy as he was beloved within science-fiction fandom. The world seemed to be his oyster. Yet he had developed a love-hate relationship with the property that had gotten him here. Adams had been reared on classic British comedy, from Lewis Carrol to P.G. Wodehouse, <em>The Goon Show</em> to Monty Python. He felt pigeonholed as the purveyor of goofy two-headed aliens and all that nonsense about the number 42. In <em>So Long, and Thanks for All the Fish</em>, the aforementioned fourth <em>Hitchhiker’s</em> novel, he’d tried to get away from some of that by keeping the proceedings on Earth, delivering what amounted to a magical-realist romantic comedy in lieu of another zany romp through outer space. But his existing fans hadn’t been overly pleased by the change of direction; they made it clear that they’d prefer more of the goofy aliens and the stuff about 42 in the next book, if it was all the same to him. “I was getting so bloody bored with <em>Hitchhiker’s</em>,” Adams said later. “I just didn’t have anything more to say in that context.” Even as he was feeling this way, though, he was trying very hard to get Hollywood to bite on a full-fledged, big-budget <em>Hitchiker’s Guide to the Galaxy</em> feature film. Thus we have the principal paradox of his creative life: <em>Hitchiker’s</em> was both the thing he most wanted to escape and his most cherished creative comfort blanket. After all, whatever else he did or didn’t do, he knew that he would always have <em>Hitchhiker’s</em>.</p>
<p>For a while, though, Adams did make a concerted attempt to do some things that were genuinely new. He pushed Infocom into agreeing to make a game with him that was not the direct sequel to the computerized <em>Hitchhiker’s</em> that they would have preferred to make. <a href="https://www.filfre.net/2015/08/bureaucracy"><em>Bureaucracy</em></a> was rather to be a present-day social satire about, well, bureaucracy, inspired by some slight difficulties Adams had once had getting his bank to acknowledge a change-of-address form. Meanwhile he sold to his book publishers a pair of as-yet unwritten non-<em>Hitchhiker’s </em>novels, with advances that came to about $4 million combined. They were to revolve around Dirk Gently, a “holistic detective” who solved crimes by relying upon “the fundamental interconnectedness of all things” in lieu of more conventional clues. “They will be recognizably me but radically different, at least from my point of view,” he said. “The story is based on here and now, but the explanation turns out to be science fiction.”</p>
<p>Adams’s enthusiasm for both projects was no doubt authentic when he conceived them, but it dissipated quickly when the time came to follow through, setting a pattern that would persist for the rest of his life. He went completely AWOL on Infocom, leaving them stuck with a project they had never really wanted in the first place. It was finally agreed that Adams’s best mate, a fellow writer named Michael Bywater, would come in and ghost-write <em>Bureaucracy</em> on his behalf. And this Bywater did, making a pretty good job of it, all things considered. (As for the proper <em>Hitchhiker’s</em> sequel which a struggling Infocom did want to make very badly: that never happened at all, although Adams caused consternation and confusion for a while on both side of the Atlantic by <a href="https://www.filfre.net/2016/04/the-bruce-youth">proposing that he and Infocom collaborate on it</a> with a third party with which he had become enamored, the British text-adventure house Magnetic Scrolls. Perhaps fortunately under these too-many-cooks-in-the-kitchen circumstances, his follow-through here was no better than it had been on <em>Bureaucracy</em>, and the whole project died quietly after <a href="https://www.filfre.net/2016/07/going-to-california">Infocom was shut down</a> in 1989.)</p>
<p>Dirk Gently was a stickier wicket, thanks to the amount of money that Adams’s publishers had already paid for the books. They got them out of him at last using the same method that had done the trick for <em>So Long, and Thanks for All the Fish</em>: locking him in a room with a minder and not letting him leave until he had produced a novel. <em>Dirk Gently’s Holistic Detective Agency</em> was published in 1987, its sequel <em>The Long Dark Tea-Time of the Soul</em> the following year. The books had their moments, but fell a little flat for most readers. In order to be fully realized, their ambitious philosophical conceits demanded an attention to plotting and construction that was not really compatible with being hammered out under duress in a couple of weeks. They left Adams’s old fans nonplussed in much the same way that <em>So Long…</em> had done, whilst failing to break him out of the science-fiction ghetto in which he felt trapped. Having satisfied his contractual obligations in that area, he would never complete another Dirk Gently novel.</p>
<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/dirk_gently_uk_front_cover/" rel="attachment wp-att-6030"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/Dirk_Gently_UK_front_cover.jpg" alt="" width="258" height="385" srcset="https://www.filfre.net/wp-content/uploads/2024/07/Dirk_Gently_UK_front_cover.jpg 258w, https://www.filfre.net/wp-content/uploads/2024/07/Dirk_Gently_UK_front_cover-201x300.jpg 201w" sizes="(max-width: 258px) 100vw, 258px"></a></p>
<p>Then, the same year that the second Dirk Gently book was published, Adams stumbled into the most satisfying non-<em>Hitchhiker’s</em> project of his life. A few years earlier, during a jaunt to Madagascar, he had befriended a World Wildlife Federation zoologist named Mark Carwardine, who had ignited in him a passion for wildlife conservation. Now, the two hatched a scheme for a radio series and an accompanying book that would be about as different as they possibly could from the ones that had made Adams’s name: the odd couple would travel to exotic destinations in search of rare and endangered animal species and make a chronicle of what they witnessed and underwent. Carwardine would be the expert and the straight man, Adams the voice of the interested layperson and the comic relief. They would call the project <em>Last Chance to See</em>, because the species they would be seeking out might literally not exist anymore in just a few years. To his credit, Adams insisted that Carwardine be given an equal financial and creative stake. “We spent many evenings talking into the night,” remembers the latter. “I’d turn up with a list of possible endangered species, then we’d pore over a world map and talk about where we’d both like to go.”</p>
<p>They settled on the Komodo dragon of Indonesia, the Rodrigues flying fox of Mauritius, the baiji river dolphin of China, the Juan Fernández fur seal of South America’s Pacific coast, the mountain gorilla and northern white rhinoceros of East Africa, the kākāpō of New Zealand, and the Amazonian manatee of Brazil. Between July of 1988 and April of 1989, they traveled to all of these places — often as just the two of them, without any additional support staff, relying on Adams’s arsenal of gadgets to record the sights and especially the sounds. Adams came home 30 pounds lighter and thoroughly energized, eager to turn their adventures into six half-hour programs that were aired on BBC Radio later that year.</p>
<div id="attachment_6029"><p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/douglas-adams-and-mark-carwardine/" rel="attachment wp-att-6029"><img decoding="async" aria-describedby="caption-attachment-6029" src="https://www.filfre.net/wp-content/uploads/2024/07/LC.jpg" alt="" width="446" height="251" srcset="https://www.filfre.net/wp-content/uploads/2024/07/LC.jpg 446w, https://www.filfre.net/wp-content/uploads/2024/07/LC-300x169.jpg 300w" sizes="(max-width: 446px) 100vw, 446px"></a></p><p id="caption-attachment-6029">Mark Carwardine and Douglas Adams in the Juan Fernández Islands.</p></div>
<p>The book proved predictably more problematic. It was not completed on schedule, and was in a very real sense not even completed at all when it was wrenched away from its authors and published in 1990; the allegedly “finished” volume covers only five of the seven expeditions, and one of those in a notably more cursory manner than the others. Nevertheless, Adams found the project as a whole a far more enjoyable experience than the creation of his most recent novels had been. He had a partner to bounce ideas off of, making the business that much less lonely. And he wasn’t forced to invent any complicated plots from whole cloth, something for which he had arguably never been very well suited. He could just inhale his surroundings and exhale them again for the benefit of his readers, with a generous helping of the droll wit and the altogether unique perspective he could place on things. His descriptions of nature and animal life were often poignant and always delightful, as were those of the human societies he and Carwardine encountered. “Because I had an external and important subject to deal with,” mused Adams, “I didn’t feel any kind of compulsion to be funny the whole time — and oddly enough, a lot of people have said it’s the funniest book I’ve written.”</p>
<p>An example, on the subject of traffic in the fast-rising nation of China, which the pair visited just six months before <a href="https://analog-antiquarian.net/2023/01/13/chapter-26-two-miracles-and-a-massacre/">the massacre on Tienanmen Square</a> showed that its rise would take place on terms strictly dictated by the Communist Party:</p>
<blockquote><p>Foreigners are not allowed to drive in China, and you can see why. The Chinese drive, or cycle, according to laws that are simply not apparent to an uninitiated observer, and I’m thinking not merely of the laws of the Highway Code; I’m thinking of the laws of physics. By the end of our stay in China, I had learnt to accept that if you are driving along a two-lane road behind another car or truck, and there are two vehicles speeding towards you, one of which is overtaking the other, the immediate response of your driver will be to also pull out and overtake. Somehow, magically, it all works out in the end.</p>
<p>What&nbsp; I could never get used to, however, was this situation: the vehicle in front of you is overtaking the vehicle in front of him, and your driver pulls out and overtakes the overtaking vehicle, just as three other vehicles are coming towards you performing exactly the same manoeuvre. Presumably Sir Isaac Newton has long ago been discredited as a bourgeois capitalist running-dog lackey.</p></blockquote>
<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/last_chance_to_see_harmony_front/" rel="attachment wp-att-6031"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/Last_Chance_to_See_Harmony_front.jpg" alt="" width="261" height="383" srcset="https://www.filfre.net/wp-content/uploads/2024/07/Last_Chance_to_See_Harmony_front.jpg 261w, https://www.filfre.net/wp-content/uploads/2024/07/Last_Chance_to_See_Harmony_front-204x300.jpg 204w" sizes="(max-width: 261px) 100vw, 261px"></a></p>
<p>Adams insisted to the end of his days that <em>Last Chance to See</em> was the best thing he had ever written, and I’m not at all sure that I disagree with him. On the contrary, I find myself wishing that he had continued down the trail it blazed, leaving the two-headed aliens behind in favor of becoming some combination of humorist, cultural critic, and popular-science writer. “I’m full of admiration for people who make science available to the intelligent layperson,” he said. “Understanding what you didn’t before is, to me, one of the greatest thrills.” Douglas Adams could easily have become one of those people whom he so admired. It seems to me that he could have excelled in that role, and might have been a happier, more satisfied man in it to boot. But it didn’t happen, for one simple reason: as well as taking a spot in the running for the title of best book he had ever written, <em>Last Chance to See</em> became the single worst-selling one. Adams:</p>
<blockquote><p>Last Chance to See was a book I really wanted to promote as much as I could because the Earth’s endangered species is a huge topic to talk about. The thing I don’t like about doing promotion usually is that you have to sit there and whinge on about yourself. But here was a big issue I really wanted to talk about, and I was expecting to do the normal round of press, TV, and radio. But nobody was interested. They just said, “It isn’t what he normally does, so we’ll pass on this, thank you very much.” As a result, the book didn’t do very well. I had spent two years and £150,000 of my own money doing it. I thought it was the most important thing I’d ever done, and I couldn’t get anyone to pay any attention.</p></blockquote>
<p>Now, we might say at this point that there was really nothing keeping Adams from doing more projects like <em>Last Chance to See</em>. Financially, he was already set for life, and it wasn’t as if his publishers were on the verge of dropping him. He could have accepted that addressing matters of existential importance aren’t always the best way to generate high sales, could have kept at it anyway. In time, perhaps he could have built a whole new audience and authorial niche for himself.</p>
<p>Yet all of that, while true enough on the face of it, fails to address just how difficult it is for anyone who has reached the top of the entertainment mountain to accept relegation to a base camp halfway down its slope. It’s the same phenomenon that today causes Adams’s musical hero and former dinner-party guest Paul McCartney, who is now more than 80 years old, to keep trying to score one more number-one hit instead of just making the music that pleases him. Once you’ve tasted mass adulation, modest success can have the same bitter tang as abject failure. There are artists who are so comfortable in their own skin, or in their own art, or in their own something, that this truism does not apply. But Douglas Adams, a deeply social creature who seemed to need the approbation of fans and peers as much as he needed food and drink, was not one of them.</p>
<p>So, he retreated to his own comfort zone and wrote another <em>Hitchhiker’s</em> novel. At first it was to be called <em>Starship Titanic</em>, but then it became <em>Mostly Harmless</em>. The choice to name it after one of the oldest running gags in the <em>Hitchhiker’s</em> series was in some ways indicative; this was to be very much a case of trotting out the old hits for the old fans. The actual writing turned into the usual protracted war between Adams’s publisher and the author himself, who counted as his allies in the cause of procrastination the many shiny objects that were available to distract a wealthy, intellectually curious social butterfly such as him. This time he had to be locked into a room with not only a handler from his publisher but his good friend Michael Bywater, who had, since doing <em>Bureaucracy</em> for Infocom, fallen into the role of Adams’s go-to ghostwriter for many of the contracts he signed and failed to follow through on. Confronted with the circumstances of its creation, one is immediately tempted to suspect that substantial chunks of <em>Mostly Harmless</em> were actually Bywater’s work. By way of further circumstantial evidence, we might note that some of the human warmth that marked the first four <em>Hitchhiker’s</em> novels is gone, replaced by a meaner, archer style of humor that smacks more of Bywater than the Adams of earlier years.</p>
<p>It’s a strange novel — not a very good one, but kind of a fascinating one nonetheless. Karl Jung would have had a field day with it as a reflection of its author’s tortured relationship to the trans-media franchise he had spawned. There’s a petulant, begrudging air to the thing, right up until it ends in the mother of all apocalypses, as if Adams was trying to wreck his most famous creation so thoroughly that he would never, ever be able to heed its siren call again. “The only way we could persuade Douglas to finish <em>Mostly Harmless</em>,” says Michael Bywater, “was [to] offer him several convincing scenarios by which he could blow up not only this Earth but all the Earths that may possibly exist in parallel universes.” That was to be that, said Adams. No more <em>Hitchhiker’s</em>, ever; he had written the franchise into a black hole from which it could never emerge. Which wasn’t really true at all, of course. He would always be able to find some way to bring the multidimensional Earth back in the future, should he decide to, just as he had once brought the uni-dimensional Earth back from its destruction in the very first novel. Such is the advantage of being god of your own private multiverse. Indeed, there are signs that Adams was already having second thoughts before he even allowed <em>Mostly Harmless</em> to be sent to the printer. At the last minute, he sprinkled a few hints into the text that the series’s hero Arthur Dent may in fact have survived the apocalypse. It never hurts to hedge your bets.</p>
<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/mostly_harmless_harmony_front/" rel="attachment wp-att-6032"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/Mostly_Harmless_Harmony_front.jpg" alt="" width="257" height="390" srcset="https://www.filfre.net/wp-content/uploads/2024/07/Mostly_Harmless_Harmony_front.jpg 257w, https://www.filfre.net/wp-content/uploads/2024/07/Mostly_Harmless_Harmony_front-198x300.jpg 198w" sizes="(max-width: 257px) 100vw, 257px"></a></p>
<p>Published in October of 1992, <em>Mostly Harmless</em> sold better than <em>Last Chance to See</em> or the Dirk Gently novels, but not as well as the golden-age <em>Hitchhiker’s</em> books. Even the series’s most zealous fans could smell the ennui that fairly wafted up from its pages. Nevertheless, they would have been shocked if you had told them that Douglas Adams, still only 40 years old, would never finish another book.</p>
<p>The next several years were the least professionally productive of Adams’s adult life to date. This wasn’t necessarily a bad thing; there is, after all, more to life than one’s career. He had finally married his longtime off-and-on romantic partner Jane Belson in 1991, and in 1994, when the husband’s age was a thoroughly appropriate 42, the couple had their first and only child. When not doting on his baby daughter Polly, Adams amused himself with his parties and his hobbies, which mostly involved his beloved Apple Macintosh computers and, especially, music. He amassed what he believed to be the largest collection of left-handed guitars in the world. His friend David Gilmour gave him his best birthday gift ever when he allowed him to come onstage and play one of those guitars with Pink Floyd for one song on their final tour. Adams also performed as one half of an acoustic duo at an American Booksellers’ Association Conference; the duo’s other half was the author Ken Follett. He even considered trying to make an album of his own: “It will basically be something very similar to <em>Sgt. Pepper</em>, I should think.” Let it never be said that Douglas Adams didn’t aim high in his flights of fancy…</p>
<div id="attachment_6024"><p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/img19/" rel="attachment wp-att-6024"><img decoding="async" aria-describedby="caption-attachment-6024" src="https://www.filfre.net/wp-content/uploads/2024/07/Img19.jpg" alt="" width="600" height="396" srcset="https://www.filfre.net/wp-content/uploads/2024/07/Img19.jpg 600w, https://www.filfre.net/wp-content/uploads/2024/07/Img19-300x198.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-6024">Adams gives his daughter Polly some early musical instruction.</p></div>
<p>With Adams thus absent from the literary scene, his position as genre fiction’s premiere humorist was seized by <a href="https://www.filfre.net/2022/07/discworld-on-page-and-screen-part-1-serious-comedy">Terry Pratchett</a>, whose first <em>Discworld</em> novels of the mid-1980s might be not unfairly described as an attempt to ape Adams in a fantasy rather than a science-fiction setting, but who had long since come into his own. Pratchett evinced none of Adams’s fear and loathing of the actual act of writing, averaging one new novel every nine months throughout the 1990s. By way of a reward for his productivity, his wit, and his boundless willingness to take his signature series in unexpected new directions, he became the most commercially successful single British author of any sort of the entire decade.</p>
<p>A new generation of younger readers adored <em>Discworld</em> but had little if any familiarity with <em>Hitchhiker’s</em>. While Pratchett basked in entire conventions devoted solely to himself and his books, Adams sometimes failed to muster an audience of more than twenty when he did make a public appearance — a sad contrast to his book signings of the early 1980s, when his fans had lined up by the thousands for a quick signature and a handshake. A serialized graphic-novel adaption of <em>Hitchhiker’s</em>, published by DC Comics, was greeted with a collective shrug, averaging about 20,000 copies sold per issue, far below projections. Despite all this clear evidence, Adams, isolated in his bubble of rock stars and lavish parties, seemed to believe he still had the same profile he’d had back in 1983. That belief — or delusion — became the original sin of his next major creative project, which would sadly turn out to be the very last one of his life.</p>
<p>The genesis of Douglas Adams’s second or third computer game — depending on what you make of <em>Bureaucracy</em> — dates to late 1995, when he became infatuated with a nascent collective of filmmakers and technologists who called themselves The Digital Village. The artist’s colony cum corporation was the brainchild of Robbie Stamp, a former producer for Britain’s Central Television: “I was one of a then-young group of executives looking at the effects of digital technology on traditional media businesses. I felt there were some exciting possibilities opening up, in terms of people who could understand what it would mean to develop an idea or a brand across a variety of different platforms and channels.” Stamp insists that he wasn’t actively fishing for money when he described his ideas one day to Adams, who happened to be a friend of a friend of his named Richard Creasey. He was therefore flabbergasted when Adams turned to him and asked, “What would it take to buy a stake?” But he was quick on his feet; he named a figure without missing a beat. “I’m in,” said Adams. And that was that. Creasey, who had been Stamp’s boss at Central Television, agreed to come aboard as well, and the trio of co-founders was in place.</p>
<p>One senses that Adams was desperate to find a creative outlet that was less dilettantish than his musical endeavors but also less torturous than being locked into a room and ordered to write a book.</p>
<blockquote><p>When I started out, I worked on radio, I worked on TV, I worked onstage. I enjoyed and experimented with different media, working with people and, wherever possible, fiddling with bits of equipment. Then I accidentally wrote a bestselling novel, and the consequence was that I had to write another and then another. After a decade or so of this, I became a little crazed at the thought of spending my entire working life in a room by myself typing. Hence The Digital Village.</p></blockquote>
<p>The logic was sound enough when considered in the light of the kind of personality Adams was; certainly one of the reasons <em>Last Chance to See</em> had gone so well had been the presence of an equal partner to keep him engaged.</p>
<p>Still, the fact remained that it could be a little hard to figure out what The Digital Village was really supposed to <em>be</em>. Rejecting one of the hottest buzzwords of the age, Adams insisted that it was to be a “multiple media” company, not a “multimedia” one: “We’re producing CD-ROMs and other digital and online projects, but we’re also committed to working in traditional forms of media.” To any seasoned business analyst, that refusal to focus must have sounded like a recipe for trouble; “do one thing very, very well” is generally a better recipe for success in business than the jack-of-all-trades approach. And as it transpired, The Digital Village would not prove an exception to this rule.</p>
<p>Their first idea was to produce a series of science documentaries called <em>Life, the Universe, and Evolution</em>, a riff on the title of the third <em>Hitchhiker’s</em> novel; that scheme fell through when they couldn’t find a television channel that was all that interested in airing it. Their next idea was to set up <em>The Hitchhiker’s Guide to the Internet</em>, a search engine to compete with the current king of Web searching <a href="https://www.filfre.net/2022/06/a-web-around-the-world-part-11-a-zero-sum-game">Yahoo!</a>; that scheme fell through when they realized that they had neither the financial resources nor the technical expertise to pull it off. And so on and so on. “We were going to be involved in documentaries, feature films, and the Internet,” says Richard Creasey regretfully. “And bit by bit they all went away. Bit by bit, we went down one avenue which was, in the nicest possible way, a disaster.”</p>
<p>That avenue was a multimedia adventure game, a project which would come to consume The Digital Village in more ways than one. It was embarked upon for the very simple reason that it was the only one of the founders’ ideas for which they could find adequate investment capital. At the time, the culture was living through an odd echo of the <a href="https://www.filfre.net/2013/09/bookware">“bookware” scene of the mid-1980s</a>, of which Infocom’s <em>Hitchhiker’s</em> game has gone down in history as the most iconic example. A lot of big players in traditional media were once again <a href="https://www.filfre.net/2022/09/byron-preisss-games-or-the-perils-of-the-electronic-book">jumping onto the computing bandwagon</a> with more money than sense. Instead of text and text parsers, however, Bookware 2.0 was fueled by great piles of pictures and video, sound and music, with a thin skein of interactivity to join it all together. Circa 1984, the print-publishing giant Simon &amp; Schuster had <a href="https://www.filfre.net/2013/10/masters-of-the-game">tried very, very hard&nbsp; to buy Infocom</a>, a purchase that would have given them the <em>Hitchhiker’s</em> game that was then in the offing. Now, twelve years later, they finally got their consolation prize, when Douglas Adams agreed to make a game just for them. All they had to do was give him a few million dollars, an order of magnitude more than Infocom had had to put into their <em>Hitchhiker’s</em>.</p>
<p>The game was to be called <em>Starship Titanic</em>. Like perhaps too many Adams brainstorms of these latter days, it was a product of recycling. As we’ve already seen, the name had once been earmarked for the novel that became <em>Mostly Harmless</em>, but even then it hadn’t been new. No, it dated all the way back to the 1982 <em>Hitchhiker’s </em>novel <em>Life, the Universe, and Everything</em>, which had told in one of its countless digressions of a “majestic and luxurious cruise liner” equipped with a flawed prototype of an Infinite Improbability Drive, such that on its maiden voyage it had undergone “a sudden and gratuitous total existence failure.” In the game, the vessel would crash through the roof of the player’s ordinary earthly home; what could be more improbable than that? Then the player would be sucked aboard and tasked with repairing the ship’s many wildly, bizarrely malfunctioning systems and getting it warping through hyperspace on the straight and narrow once again. Whether <em>Starship Titanic</em> exists in the same universe — or rather multiverse — as <em>Hitchhiker’s</em> is something of an open question. Adams was never overly concerned with such fussy details of canon; his most devoted fans, who very much are, have dutifully inserted it into their <em>Hitchhiker’s </em>wikis and source books on the basis of that brief mention in <em>Life, the Universe, and Everything</em>.</p>
<p>Adams was often taken by a fit of almost manic enthusiasm when he first conceived of a new project, and this was definitely true of <em>Starship Titanic</em>. He envisioned another trans-media property to outdo even <em>Hitchhiker’s</em> in its prime. Naturally, there would need to be a <em>Starship Titanic</em> novel to accompany the game. Going much further, Adams pictured his new franchise fulfilling at last his fondest unrequited dream for <em>Hitchhiker’s</em>. “I’m not in a position to make any sort of formal announcement,” he told the press cagily, “but I very much hope that it will have a future as a movie as well.” There is no indication that any of the top-secret Hollywood negotiations he was not-so-subtly hinting at here ever took place.</p>
<p>In their stead, just about everything that could possibly go wrong with the whole enterprise did so. It became a veritable factory for resentments and bad feelings. Robbie Stamp and Richard Creasey, who didn’t play games at all and weren’t much interested in them, were understandably unhappy at seeing their upstart new-media collective become The Douglas Adams Computer Games Company. This created massive dysfunction in the management ranks.</p>
<p>Predictably enough, Adams brought in Michael Bywater to help him when his progress on the game’s script stalled out. Indeed, just as is the case with <em>Mostly Harmless</em>, it’s difficult to say where Douglas Adams stops and Michael Bywater begins in the finished product. In partial return for his services, Bywater believed that his friend implicitly or explicitly promised that he could write and for once put his own name onto the <em>Starship Titanic </em>novel. But this didn’t happen in the end. Instead Adams sourced it out to Robert Sheckley, his favorite old-school science-fiction writer, who was in hard financial straits and could use the work. When Sheckley repaid his charity with a manuscript that was so bad as to be unpublishable, Adams bypassed Bywater yet again, giving the contract to another friend, the Monty Python alum Terry Jones, who also did some voice acting in the game. Bywater was incensed by this demonstration of exactly where he ranked in Adams’s entourage; it seemed he was good enough to become the great author’s emergency ghostwriter whenever his endemic laziness got him into a jam, but not worthy of receiving credit as a full-fledged collaborator. The two parted acrimoniously; the friendship, one of the longest and closest in each man’s life, would never be fully mended.</p>
<p>And all over a novel which, under Jones’s stewardship, came out tortuously, exhaustingly unfunny, the very essence of trying way too hard.</p>
<blockquote><p>“Where is Leovinus?” demanded the Gat of Blerontis, Chief Quantity Surveyor of the entire North Eastern Gas District of the planet of Blerontin. “No! I do not want another bloody fish-paste sandwich!”</p>
<p>He did not exactly use the word “bloody” because it did not exist in the Blerontin language. The word he used could be more literally translated as “similar in size to the left earlobe,” but the meaning was much closer to “bloody.” Nor did he actually use the phrase “fish paste,” since fish do not exist on Blerontin in the form in which we would understand them to be fish. But when one is translating from a language used by a civilisation of which we know nothing, located as far away as the centre of the galaxy, one has to approximate. Similarly, the Gat of Blerontis was not exactly a “Quantity Surveyor,” and certainly the term “North Eastern Gas District” gives no idea at all about the magnificence and grandeur of his position. Look, perhaps I’d better start again…</p></blockquote>
<p>Oh, my. Yes, Terry, perhaps you should. Whatever else you can say about Michael Bywater, he at least knew how to ape Douglas Adams without drenching the page in flop sweat.</p>
<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/715fzh2g6jl-_sl1500_/" rel="attachment wp-att-6034"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/715fzh2g6JL._SL1500_-183x300.jpg" alt="" width="274" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/07/715fzh2g6JL._SL1500_-183x300.jpg 183w, https://www.filfre.net/wp-content/uploads/2024/07/715fzh2g6JL._SL1500_-624x1024.jpg 624w, https://www.filfre.net/wp-content/uploads/2024/07/715fzh2g6JL._SL1500_-768x1260.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/07/715fzh2g6JL._SL1500_.jpg 914w" sizes="(max-width: 274px) 100vw, 274px"></a></p>
<p>The novel came out in December of 1997, a few months before the game, sporting on its cover the baffling descriptor <em>Douglas Adams’s Starship Titanic by Terry Jones</em>. In a clear sign that Bookware 2.0 was already fading into history alongside its equally short-lived predecessor, Simon &amp; Schuster gave it virtually no promotion. Those critics who deigned to notice it at all savaged it for being exactly what it was, a slavishly belabored third-party imitation of a set of tired tropes. Adams and Jones did a short, dispiriting British book tour together, during which they were greeted with half-empty halls and bookstores; those fans who did show up were more interested in talking about the good old days of <em>Hitchhiker’s</em> and Monty Python than <em>Starship Titanic</em>. It was not a positive omen for the game.</p>
<p>At first glance, said game appears to be a typical product of the multimedia-computing boom, when lots and lots of people with a lot of half-baked highfalutin ideas about the necessary future of games suddenly rushed to start making them, without ever talking to any of the people who had already been making them for years or bothering to try to find out what the ingredients of a good, playable game might in fact be. Once you spend just a little bit of time with <em>Starship Titanic</em>, however, you begin to realize that this rush to stereotype it has done it a disservice. It is in reality uniquely awful.</p>
<p>From <a href="https://www.filfre.net/2020/02/myst-or-the-drawbacks-to-success"><em>Myst</em></a> and its many clones, it takes its first-person perspective and its system of navigation, in which you jump between static, pre-rendered nodes in a larger contiguous space. That approach is always a little unsatisfactory even at its best — what you <em>really</em> want to be doing is wandering through a seamless world, not hopping between nodes — but <em>Starship Titanic</em> manages to turn the usual Mysty frustrations into a Gordian Knot of agony. The amount of rotation you get when you click on the side of the screen to turn the view is wildly inconsistent from node to node and turn to turn, even as the views themselves seem deliberately chosen to be as confusing as possible. This is the sort of game where you can find yourself stuck for hours because you failed to spot… no, not some tiny little smear of pixels on the floor representing some obscure object, but an entire <em>door</em> that can only be seen from one fiddly angle. Navigating the spaceship is the Mount Everest of fake difficulties — i.e., difficulties that anyone who was actually <em>in</em> this environment would not be having.</p>
<p><em>Myst</em> clones usually balance their intrinsic navigational challenges with puzzles that are quite rigorously logical, being most typically of the mechanical stripe: experiment with the machinery to deduce what each button and lever does, then apply the knowledge you gain to accomplish some task. But not <em>Starship Titanic</em>. It relies on the sort of moon logic that’s more typical of the other major strand of 1990s adventure game, those that play out from a third-person perspective and foreground plot, character interaction, and the player’s inventory of objects to a much greater degree. Beyond a certain point, only the “try everything on everything” method will get you anywhere in <em>Starship Titanic</em>. This is made even more laborious by an over-baked interface in which every action takes way more clicks than it ought to. Like everything else about the game, the interface too is wildly inconsistent; sometimes you can interact with things in one way, sometimes in another, with no rhyme or reason separating the two. You just have to try everything every which way, and maybe at some point something works.</p>
<p>Having come this far, but still not satisfied with merely having combined the very worst aspects of the two major branches of contemporary adventure games, Douglas Adams looked to the past for more depths to plumb. At his insistence, <em>Starship Titanic</em> includes, of all things, a text parser — a text parser just as balky and obtuse as most of the ones from companies not named Infocom back in the early 1980s. It rears its ugly head when you attempt to converse with the robots who are the ship’s only other inhabitants. The idea is that you can type what you want to say to them in natural language, thereby to have real conversations with them. Alas, the end result is more <a href="https://www.filfre.net/2011/06/eliza-part-1"><em>Eliza</em></a> than ChatGPT. The Digital Village claimed to have recorded sixteen hours of voiced responses to your conversational sallies and inquiries. This sounds impressive — until you start to think about what it means to try to pack coherent responses to literally anything in the world the player might possibly say to a dozen or so possible interlocutors into that span of time. What you get out on the other end is lots and lots of variations on “I don’t understand that,” when you’re not being blatantly misunderstood by a parser that relies on dodgy pattern matching rather than any thoroughgoing analysis of sentence structure. Nothing illustrates more cogently how misconceived and amateurish this whole project was; these people were wasting time on <em>this</em> nonsense when the core game was still unplayable. Adams, who had been widely praised for stretching the parser in unusual, slightly postmodern directions in Infocom’s <em>Hitchhiker’s</em> game, clearly wanted to recapture that moment here. But he had no Steve Meretzky with him this time — no one at all who truly understood game design — to corral his flights of imagination and channel them into something achievable and fun. It’s a little sad to see him so mired in an unrecoverable past.</p>
<p>But if the parser is weird and sad, the weirdest and saddest thing of all about <em>Starship Titanic</em> is how thoroughly unfunny it is. Even a compromised, dashed-off Adams novel like <em>Mostly Harmless</em> still has moments which can make you smile, which remind you that, yes, this is Douglas Adams you’re reading. <em>Starship Titanic</em>, on the other hand, is comprehensively tired and tiring, boiling Adams’s previous oeuvre down to its tritest banalities — all goofy robots and aliens, without the edge of satire and the cock-eyed insights about the human condition that mark <em>Hitchhiker’s</em>. Was Adams losing his touch as a humorist? Or did his own voice just get lost amidst those of dozens of other people trying to learn on the fly how to make a computer game? It’s impossible to say. It is pretty clear, however, that he had one foot out the door of the project long before it was finished. “In the end, I think he felt quite distanced from it,” says Robbie Stamp of his partner. That sentiment applied equally to all three co-founders of the The Digital Village, who couldn’t fully work out just how their dreams and schemes had landed them here. In a very real way, no one involved with <em>Starship Titanic</em> actually wanted to make it.</p>
<p>I suppose it’s every critic’s duty to say something kind about even the worst of games. In that spirit, I’ll note that <em>Starship Titanic</em> does look very nice, with an Art Deco aesthetic that reminds me slightly of a far superior adventure game set aboard a moving vehicle, <a href="https://www.filfre.net/2023/10/the-last-express">Jordan Mechner’s <em>The Last Express</em></a>. If nothing else, this demonstrates that The Digital Village knew where to find talented visual artists, and that they were sophisticated enough to choose a look for their game and stick to it. Then, too, the voice cast the creators recruited was to die for, including not only Terry Jones and Douglas Adams himself but even John Cleese, who had previously answered every inquiry about appearing in a game with some variation of <a href="https://www.filfre.net/2022/08/discworld-on-page-and-screen-part-2-the-first-three-discworld-games">“Fuck off! I don’t do games!”</a> The music was provided by Wix Wickens, the keyboardist and musical director for Paul McCartney’s touring band. What a pity that no one from The Digital Village had a clue what to do with their pile of stellar audiovisual assets. Games were “an area about which we knew nothing,” admits Richard Creasey. That went as much for Douglas Adams as any of the rest of them; as <em>Starship Titanic’</em>s anachronistic parser so painfully showed, his picture of the ludic state of the art was more than a decade out of date.</p>
<hr>
<p><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/4163692-starship-titanic-windows-front-cover/" rel="attachment wp-att-6025"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/4163692-starship-titanic-windows-front-cover-249x300.jpg" alt="" width="374" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/07/4163692-starship-titanic-windows-front-cover-249x300.jpg 249w, https://www.filfre.net/wp-content/uploads/2024/07/4163692-starship-titanic-windows-front-cover.jpg 664w" sizes="(max-width: 374px) 100vw, 374px"></a><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/st1/" rel="attachment wp-att-6026"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/ST1-300x225.png" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/07/ST1-300x225.png 300w, https://www.filfre.net/wp-content/uploads/2024/07/ST1.png 640w" sizes="(max-width: 600px) 100vw, 600px"></a><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/st2/" rel="attachment wp-att-6027"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/ST2-300x225.png" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/07/ST2-300x225.png 300w, https://www.filfre.net/wp-content/uploads/2024/07/ST2.png 640w" sizes="(max-width: 600px) 100vw, 600px"></a><a href="https://www.filfre.net/2024/07/the-later-years-of-douglas-adams/st4/" rel="attachment wp-att-6028"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/07/ST4-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/07/ST4-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/07/ST4.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<hr>
<p><code> </code><br>
Begun in May of 1996, <em>Starship Titanic</em> shipped in April of 1998, more than six months behind schedule. Rather bizarrely, no one involved seems ever to have considered explicitly branding it as a <em>Hitchhiker’s</em> game, a move that would surely have increased its commercial potential at least somewhat. (There was no legal impediment to doing so; Adams owned the <em>Hitchhiker’s</em> franchise outright.) Adams believed that his name on the box alone could make it a hit. Some of those around him were more dubious. “I think it was a harsh reality,” says Robbie Stamp, “that Douglas hadn’t been seen to figure big financially by anyone for a little while.” But no one was eager to have that conversation with him at the time.</p>
<p>So, <em>Starship Titanic</em> was sent out to greet an unforgiving world as its own, self-contained thing, and promptly stiffed. Even the fortuitous release the previous December of James Cameron’s blockbuster film <em>Titanic</em>, which had elevated <a href="https://www.filfre.net/2022/10/titanic-visions-part-3-an-adventure-out-of-time">another adventure game</a> of otherwise modest commercial prospects to million-seller status, couldn’t save this one. Many of the gaming magazines and websites didn’t bother to review it at all, so 1996 did it feel in a brave new world where first-person shooters and real-time strategies were all the rage. Of those that did, <a href="https://www.gamespot.com/reviews/starship-titanic-review/1900-2533215/"><em>GameSpot’</em>s faint praise</a> is typically damning: “All in all, <em>Starship Titanic</em> is an enjoyable tribute to an older era of adventure gaming. It feels a bit empty at times, but Douglas Adams fans and text-adventurers will undoubtedly be able to look past its shortcomings.” This is your father’s computer game, in other words. But leave it to Charles Ardai of <em>Computer Gaming World</em> magazine to deliver a zinger worthy of Adams himself: he called <em>Starship Titanic</em> a “<em>Myst</em> opportunity.”</p>
<p>One of the great ironies of this period is that, at the same time Douglas Adams was making a bad science-fiction-comedy adventure game, his erstwhile Infocom partner Steve Meretzky was making one of his own, called <a href="https://www.filfre.net/2021/11/boffo-games"><em>The Space Bar</em></a>. Released the summer before <em>Starship Titanic</em>, it stiffed just as horribly. Perhaps if the two had found a way to reconnect and combine their efforts, they could have sparked the old magic once again.</p>
<p>As it was, though, Adams was badly shaken by the failure of <em>Starship Titanic</em>, the first creative product with his name on it to outright lose its backers a large sum of money. “Douglas’s fight had gone out of him,” says Richard Creasey. Adams found a measure of solace in blaming the audience — never an amiable road for any creator to start down, but needs must. “What we decided to do in this game was go for the non-psychopath sector of the market,” he said. “And that was a little hubristic because there really isn’t a non-psychopath sector of the market.” The 1.5 million people who were buying the non-violent <em>Myst</em> sequel <a href="https://www.filfre.net/2024/05/riven"><em>Riven</em></a> at the time might have begged to differ.</p>
<p>Luckily, Adams had something new to be excited about: in late 1997, he had signed a development deal with Disney for a “substantial” sum of money — a deal that would, if all went well, finally lead to his long-sought <em>Hitchhiker’s</em> film. Wanting to be close to the action and feeling that he needed a change of scenery, he opted to pull up stakes from the Islington suburb of London where he had lived since 1980 and move with his family to Los Angeles. A starry-eyed Adams was now nursing dreams of Hugh Laurie or Hugh Grant as Arthur Dent, Jim Carrey as the two-headed Zaphod Beeblebrox.</p>
<p>The rump of The Digital Village which he left behind morphed into <a href="https://h2g2.com/">h2g2</a>, an online compendium of user-generated knowledge, an actually extant version of the fictional <em>Hitchhiker’s Guide to the Galaxy</em>. If you’re thinking that sounds an awful lot like Wikipedia, you’re right; the latter site, which was launched two years after h2g2 made its debut in 1999, has thoroughly superseded it today. In its day, though, h2g2 was a genuinely visionary endeavor, an early taste of the more dynamic, interactive Web 2.0 that would mark the new millennium. Adams anticipated the way we live our digital lives today to an almost unnerving degree.</p>
<blockquote><p>The real change takes place [with] mobile computing, and that is beginning to arrive now. We’re beginning to get Internet access on mobile phones and personal digital assistants. That creates a sea change because suddenly people will be able to get information that is appropriate to where they are and who they are — standing outside the cinema or a restaurant or waiting for a bus or a plane. Or sitting having a cup of coffee at a café. With h2g2, you can look up where you are at that moment to see what it says, and if the information is not there you can add it yourself. For example, a remark about the coffee you’re drinking or a comment that the waiter is very rude.</p></blockquote>
<p>When not setting the agenda with prescient insights like these — he played little day-to-day role in the running of h2g2 — Adams wrote several drafts of a <em>Hitchhiker’s</em> screenplay and knocked on a lot of doors in Hollywood inquiring about the state of his movie, only to be politely put off again and again. Slowly he learned the hard lesson that many a similarly starry-eyed creator had been forced to learn before him: that open-ended deals like the one he had signed with Disney progress — or don’t progress — on their own inscrutable timeline.</p>
<p>In the meanwhile, he continued to host parties — more lavish ones than ever now after his Disney windfall — and continued being a wonderful father to his daughter. He found receptive audiences on the TED Talk circuit, full of people who were more interested in hearing his Big Ideas about science and technology than quizzing him on the minutiae of <em>Hitchhiker’s</em>. Anyone who asked him what else he was working on at any given moment was guaranteed to be peppered with at least half a dozen excited and exciting responses, from books to films, games to television, websites to radio, even as anyone who knew him well knew that none of them were likely to amount to much. Be that as it may, he seemed more or less happy when he wasn’t brooding over Disney’s lack of follow-through, which some might be tempted to interpret as karmic retribution for the travails he had put so many publishers and editors through over the years with his own lack of same. “I love the sense of space and the can-do attitude of Americans,” he said of his new home. “It’s a good place to bring up children.” Embracing the California lifestyle with enthusiasm, he lost weight, cut back on his alcohol consumption, and tried to give up cigarettes.</p>
<p>By early 2001, it looked like there was finally some movement on the <em>Hitchhiker’s</em> movie front. Director Jay Roach, hot off the success of <em>Austin Powers</em> and <em>Meet the Parents</em>, was very keen on it, enough so that Adams was motivated to revise the screenplay yet again to his specifications. On May 11 of that year, not long after submitting these revisions, Douglas Adams went to his local gym for his regular workout. After twenty minutes on the treadmill, he paused for a breather before moving on to stomach crunches. Seconds after sitting down on a bench, he collapsed to the floor, dead. Falling victim to another cosmic joke as tragically piquant as the brilliant writer who hates to write, his heart simply stopped beating, for no good reason that any coroner could divine. He was just 49 years old.</p>
<hr>
<p><code> </code><br>
<strong>Did you enjoy this article? If so, please think about pitching in to help me make many more like it. You can pledge any amount you like.</strong></p>
<p><a href="https://www.patreon.com/DigitalAntiquarian" rel="attachment wp-att-5598"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2023/04/Patreon-300x133-1.png" alt="" width="300" height="133"></a></p>
<hr>

<p><strong>Sources:</strong> The books <em>Hitchhiker: A Biography of Douglas Adams</em> by M.J. Simpson, <em>Wish You Were Here: The Official Biography of Douglas Adams</em> by Nick Webb, <em>The Frood: The Authorised and Very Official History of Douglas Adams &amp; The Hitchiker’s Guide to the Galaxy</em> by Jem Roberts, <em>The Ultimate Hitchhiker’s Guide to the Galaxy</em> by Douglas Adams, <em>Last Chance to See</em> by Douglas Adams and Mark Carwardine, and <em>Douglas Adams’s Starship Titanic</em> by Terry Jones; <em>Computer Gaming World</em> of September 1998.</p>
<p>Online sources include <a href="https://www.gamespot.com/reviews/starship-titanic-review/1900-2533215/"><em>Gamespot’</em>s vintage review</a> of <em>Starship Titanic</em>, an <a href="https://www.avclub.com/douglas-adams-1798207882"><em>AV Club</em> interview</a> with Adams from January of 1998, <a href="https://douglasadams.com/dna/makingOfStarship.html">“The Making of <em>Starship Titanic</em>“</a> from Adams’s website, <a href="http://www.tdv.com/index.html">The Digital Village’s website</a> (yes, it still exists), and <a href="https://www.theguardian.com/books/2006/nov/19/fiction.thomasharris">a <em>Guardian</em> feature</a> on Thomas Harris.</p>
<p><a href="https://www.gog.com/en/game/starship_titanic"><em>Starship</em> Titanic is available for digital purchase on GOG.com.</a><a href="https://www.gog.com/en/game/journeyman_project_1_pegasus_prime_the"><em><br>
</em></a></p>
							
							
														
													</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CrowdStrike fixes start at "reboot up to 15 times", gets more complex from there (196 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2024/07/crowdstrike-fixes-start-at-reboot-up-to-15-times-and-get-more-complex-from-there/</link>
            <guid>41007898</guid>
            <pubDate>Fri, 19 Jul 2024 16:07:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2024/07/crowdstrike-fixes-start-at-reboot-up-to-15-times-and-get-more-complex-from-there/">https://arstechnica.com/information-technology/2024/07/crowdstrike-fixes-start-at-reboot-up-to-15-times-and-get-more-complex-from-there/</a>, See on <a href="https://news.ycombinator.com/item?id=41007898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      turning it off and back on again, and again, and again    —
</h4>
            
            <h2 itemprop="description">Admins can also restore backups or manually delete CrowdStrike's buggy driver.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2019/11/bsod-800x534.jpg" alt="CrowdStrike fixes start at “reboot up to 15 times” and get more complex from there">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 107:single/related:d26d00039e6082cfcac1a0b3ae688a9b --><!-- empty -->

<p>Airlines, payment processors, 911 call centers, TV networks, and other businesses have been scrambling this morning after a buggy update to CrowdStrike's Falcon security software caused Windows-based systems to crash with a dreaded blue screen of death (BSOD) error message.</p>
<p>We're updating <a href="https://arstechnica.com/information-technology/2024/07/major-outages-at-crowdstrike-microsoft-leave-the-world-with-bsods-and-confusion/">our story about the outage</a> with new details as we have them. Microsoft and CrowdStrike <a href="https://www.crowdstrike.com/blog/statement-on-falcon-content-update-for-windows-hosts/">both say</a> that "the affected update has been pulled," so what's most important for IT admins in the short term is getting their systems back up and running again. According to guidance from Microsoft, fixes range from annoying but easy to incredibly time-consuming and complex, depending on the number of systems you have to fix and the way your systems are configured.</p>
<p>Microsoft's Azure status page outlines several fixes. The first and easiest is simply to try to reboot affected machines over and over, which gives affected machines multiple chances to try to grab CrowdStrike's non-broken update before the bad driver can cause the BSOD. Microsoft <a href="https://azure.status.microsoft/en-us/status">says</a> that some of its customers have had to reboot their systems as many as 15 times to pull down the update.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/07/Screenshot-2024-07-19-at-11.01.45%E2%80%AFAM.png" data-height="670" data-width="1444" alt="Early guidance for fixing the CrowdStrike bug is simply to reboot systems over and over again so that they can try to grab a non-broken update."><img alt="Early guidance for fixing the CrowdStrike bug is simply to reboot systems over and over again so that they can try to grab a non-broken update." src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/Screenshot-2024-07-19-at-11.01.45%E2%80%AFAM-980x455.png" width="980" height="455"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/07/Screenshot-2024-07-19-at-11.01.45%E2%80%AFAM.png" data-height="670" data-width="1444">Enlarge</a> <span>/</span> Early guidance for fixing the CrowdStrike bug is simply to reboot systems over and over again so that they can try to grab a non-broken update.</p><p>Microsoft</p></figcaption></figure>
<h2>If rebooting doesn’t work</h2>
<p>If rebooting multiple times isn't fixing your problem, Microsoft recommends restoring your systems using a backup from before 4:09 UTC on July 18 (just after midnight on Friday, Eastern time), when CrowdStrike began pushing out the buggy update. Crowdstrike says a reverted version of the file was deployed at 5:27 UTC.</p>                                                                        
                                                                                
<p>If these simpler fixes don't work, you may need to boot your machines into Safe Mode so you can manually delete the file that's causing the BSOD errors. For virtual machines, Microsoft recommends <a href="https://learn.microsoft.com/en-us/troubleshoot/azure/virtual-machines/windows/troubleshoot-recovery-disks-portal-windows">attaching the virtual disk to a known-working repair VM</a> so the file can be deleted, then reattaching the virtual disk to its original VM.</p>
<p>The file in question is a CrowdStrike driver located at <code>Windows/System32/Drivers/CrowdStrike/C<strong>-</strong>00000291*.sys</code>. Once it's gone, the machine should boot normally and grab a non-broken version of the driver.</p>
<p>Deleting that file on each and every one of your affected systems individually is time-consuming enough, but it's even&nbsp;<em>more</em> time-consuming for customers using Microsoft's BitLocker drive encryption to protect data at rest. Before you can delete the file on those systems, you'll need the recovery key that unlocks those encrypted disks and makes them readable (normally, this process is invisible, because the system can just read the key stored in a physical or virtual TPM module).</p>
<p>This can cause problems for admins who aren't using key management to store their recovery keys, since (by design!) you can't access a drive without its recovery key. If you don't have that key, Cryptography and infrastructure engineer Tony Arcieri on Mastodon <a href="https://mas.to/@bascule/112813348028513131">compared this</a> to a "self-inflicted ransomware attack," where an attacker encrypts the disks on your systems and withholds the key until they get paid.</p>
<p>And even if you do have a recovery key, your key management server <a href="https://mas.to/@pinkforest@hachyderm.io/112813354182343410">might also be affected by the CrowdStrike bug</a>.</p>
<p>We'll continue to track recommendations from <a href="https://azure.status.microsoft/en-us/status">Microsoft</a> and <a href="https://www.crowdstrike.com/blog/statement-on-falcon-content-update-for-windows-hosts/">CrowdStrike</a> about fixes as each company's respective status pages are updated.</p>
<p>"We understand the gravity of the situation and are deeply sorry for the inconvenience and disruption," <a href="https://x.com/George_Kurtz/status/1814316045185822981">wrote</a> CrowdStrike CEO George Kurtz on X, formerly Twitter. "We are working with all impacted customers to ensure that systems are back up and they can deliver the services their customers are counting on."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's not just CrowdStrike – the cyber sector is vulnerable (112 pts)]]></title>
            <link>https://www.ft.com/content/d2f529fe-3050-4ef5-a8c7-6487d533e57a</link>
            <guid>41007843</guid>
            <pubDate>Fri, 19 Jul 2024 16:02:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/d2f529fe-3050-4ef5-a8c7-6487d533e57a">https://www.ft.com/content/d2f529fe-3050-4ef5-a8c7-6487d533e57a</a>, See on <a href="https://news.ycombinator.com/item?id=41007843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page">
<div data-component="articleHeaderHeroOffer" data-component-unique-name="USD-ROW-DE"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2>To read this article for free<br><strong>Register now</strong></h2></p><div><p>Once registered, you can:</p>
<ul>
<li>Read free articles</li>
<li>Get our Editor's Digest and other newsletters</li>
<li>Follow topics and set up personalised events</li>
<li>Access Alphaville: our popular markets and finance blog</li>
</ul></div></div></div>
<div id="recommendedOffers-USD-ROW-DE" data-component="recommendedOffers" data-component-unique-name="USD-ROW-DE"><p><h2 data-tiles="" data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-offer-type="trial" data-o-grid-colspan="12" data-tile=""><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw///financial-times-financial-times.cdn.zephr.com/assets/icons/primary_product_icon_trial.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p data-offer-type="trial"><h3>Standard Digital</h3><h3>Weekend Print + Standard Digital</h3></p></div><p>Then $75 per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.</p></div><div data-offer-type="epaper" data-o-grid-colspan="12" data-tile=""><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw///financial-times-financial-times.cdn.zephr.com/assets/icons/primary_product_icon_epaper.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p data-offer-type="epaper"><h3>Standard Digital</h3><h3>Weekend Print + Standard Digital</h3></p></div><p>Today's FT newspaper for easy reading on any device. This does not include ft.com or FT App access.</p></div><div data-offer-type="standard" data-o-grid-colspan="12" data-tile=""><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw///financial-times-financial-times.cdn.zephr.com/assets/icons/primary_product_icon_standard.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p data-offer-type="standard"><h3>Standard Digital</h3><h3>Weekend Print + Standard Digital</h3></p></div><p>Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.</p></div></div></div>
<div data-component="subscriptionOptionsV2" data-component-unique-name="ARE-Print"><h2>Explore our full range of subscriptions.</h2></div>
<div data-component="whyFT" data-component-unique-name="default"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft">Find out why</a></p></div>


</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Postgres vs. Pinecone (105 pts)]]></title>
            <link>https://lantern.dev/blog/postgres-vs-pinecone</link>
            <guid>41007624</guid>
            <pubDate>Fri, 19 Jul 2024 15:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lantern.dev/blog/postgres-vs-pinecone">https://lantern.dev/blog/postgres-vs-pinecone</a>, See on <a href="https://news.ycombinator.com/item?id=41007624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="h2-1703914554" level="2" siblingcount="64">Introduction</h2>
<p>We were naturally curious when we saw Pinecone's <a href="https://www.pinecone.io/blog/pinecone-vs-pgvector/">blog post</a> comparing Postgres and Pinecone.</p>
<p>In their post on Postgres, Pinecone recognizes that Postgres is easy to start with as a vector database, since most developers are familiar with it. However, they argue that Postgres falls short in terms of quality. They describe issues with index size predictability, index creation resource intensity, metadata filtering performance, and cost.</p>
<p>This is a response to Pinecone's blog post, where we show that <strong>Postgres outperforms Pinecone in the same benchmarks with a few additional tweaks</strong>. We show that with just 20 lines of additional code, Postgres with the <code>pgvector</code> or <code>lantern</code> extension outperforms Pinecone by reaching 90% recall (compared to Pinecone's 60%) with under 200ms p95 latency.</p>
<p>In the original blog post, Pinecone sets up Postgres in a self-hosted environment. Our post can be replicated with a self-hosted setup of Postgres that has the <code>lantern</code> extension installed – see the Jupyter notebooks <a href="https://github.com/lanterndata/examples/pull/5">here</a>. Similar benefits (with some limitations) can be achieved with other hosted Postgres providers and <code>pgvector</code>. Using Lantern Cloud makes some of the steps simpler so we opted for that when running these experiments.</p>
<h2 id="h2--1963399784" level="2" siblingcount="64">HNSW and Metadata Filtering</h2>
<p><em>Pinecone's blog post points out that a single index over a vector column is not enough to get good filtered search performance. They point out that Postgres does post-filtering out of the box, which is not good enough.</em></p>
<blockquote>
<p><em>"However, this is only post-filtering, meaning the results are filtered after the search occurs. For all practical purposes, this is unusable, since there’s no guarantee about the number of results that are returned"</em></p>
</blockquote>
<p>In Postgres, we can explicitly address metadata filtering performance — add 20 lines of code to get 90% p95 recall and 200ms p95 latency. This is in contrast to at most 60% p95 recall that Pinecone achieves on the same dataset (see <a href="https://gist.github.com/var77/7b3ddb19ed82658acf6871376973cd26">steps</a> to reproduce and results in the figure later in the post).</p>
<p>To get higher recall and lower latency in Postgres, we convert some of metadata filters into separate vector indexes. The idea is to create a specialized index for each or each group of metadata values so a smaller index can be utilized when doing a metadata search, thereby increasing the chances that only relevant results are returned.</p>
<p>This might sound scary, but with the powers of Postgres and SQL, it is a matter of a couple of queries.</p>
<p>First, let’s look at the metadata tags that we run filters over. Let’s select all the tags that have at least 10K rows tagged by them.</p>
<div><pre tabindex="0"><code><span><span>SELECT</span><span> tag</span></span>
<span><span>FROM</span><span> (</span></span>
<span><span>    SELECT</span><span> unnest(metadata_tags) </span><span>AS</span><span> tag</span></span>
<span><span>    FROM</span><span> yfcc_passages</span></span>
<span><span>) </span><span>AS</span><span> tags</span></span>
<span><span>GROUP BY</span><span> tag</span></span>
<span><span>HAVING</span><span> COUNT</span><span>(</span><span>*</span><span>) </span><span>&gt;</span><span> 10000</span></span>
<span><span>ORDER BY</span><span> COUNT</span><span>(</span><span>*</span><span>) </span><span>DESC</span></span></code></pre></div>
<p>In the YFCC dataset there are about 1300 such tags.</p>
<p>Then, for each tag we create a separate filtered vector index with a query similar to the one below:</p>
<div><pre tabindex="0"><code><span><span>CREATE</span><span> INDEX</span><span> CONCURRENTLY</span><span> IF</span><span> NOT</span><span> EXISTS</span><span> hnsw_filtered_%s</span></span>
<span><span>ON</span><span> yfcc_passages</span></span>
<span><span>USING</span><span> lantern_hnsw(vector)</span></span>
<span><span>WHERE</span><span> metadata_tags @</span><span>&gt;</span><span> ARRAY</span><span>[%s]</span></span></code></pre></div>
<p>All the code is available <a href="https://github.com/lanterndata/examples/pull/5">here</a>. Note that we use <code>lantern</code> in our examples but the code has helpers to achieve similar functionality in <code>pgvector</code> as well.</p>
<p>The process of creating all ~1300 indexes completes in 80 minutes on the 10M YFCC dataset with a 32-core server. The job can be completed even more quickly when using Lantern external indexing or a temporarily scaled-up instance from another provider, be it Timescale, Neon, CrunchyData, AWS RDS, GCP Cloud SQL, etc.</p>
<p>And the result?</p>
<p>Postgres achieves over 90% tail recall with metadata filters, while staying fast (&lt;200ms tail latency)! This is a significant improvement over anything currently available via Pinecone.</p>
<p><img src="https://storage.googleapis.com/lantern-blog/postgres-vs-pinecone-latency.png" alt="Postgres vs Pinecone Latency"></p>
<p><img src="https://storage.googleapis.com/lantern-blog/postgres-vs-pinecone-recall.png" alt="Postgres vs Pinecone Recall">
å
So 20 lines of "tuning" got us what Pinecone claimed was impractical regardless of tuning:</p>
<blockquote>
<p><em>"For any non-trivial workload that requires filtering, it’s impractical to rely on Postgres, regardless of the tuning and setup."</em></p>
</blockquote>
<h2 id="h2--227768654" level="2" siblingcount="64">Slow Index Builds</h2>
<p><em>Pinecone points out that Postgres index creation performance degrades very rapidly as soon as the dataset to be indexed no longer fits in the machine’s RAM.</em></p>
<p>With Lantern Cloud, we address this issue by offloading the index-building process to a separate environment with bottomless RAM and CPUs. With Lantern’s external index creation you can improve indexing speeds by at least an order of magnitude.</p>
<p>We are working on bringing this functionality to our fork of <code>pgvector</code> as well. Sign up <a href="https://lantern.dev/auth/early-access">here</a> for early access.</p>
<p><img src="https://storage.googleapis.com/lantern-blog/external-index-creation.mp4" alt="External Index Creation"></p>
<p>Other Postgres cloud providers have addressed the <code>pgvector</code> index creation bottleneck as well. For example, Neon supports <a href="https://neon.tech/blog/pgvector-30x-faster-index-build-for-your-vector-embeddings">seamlessly scaling</a> the size of the Postgres instance to build the initial vector index more quickly and scaling it down afterwards.</p>
<p>In both approaches (Neon and Lantern), index creation is no longer limited by the RAM of our database instance.</p>
<h2 id="h2-300325404" level="2" siblingcount="64">Index Size Estimation</h2>
<p><em>Pinecone’s blog post complains that index size is not predictable, and the final index size may be surprisingly larger than the input dataset, so it is hard to plan for the amount of necessary RAM.</em></p>
<p>We were surprised by this since HNSW index sizes are quite predictable. In fact, we even built a <a href="https://lantern.dev/blog/calculator">calculator</a> that accurately predicts the amount of RAM an index would need, given its various element quantization and graph density parameters.</p>
<p>Pinecone plots “dataset expansion” - the ratio of the dataset to index - as a measure of index size predictability. They seem to assume that index size should be a function of dataset size in megabytes. This assumption is wrong, as demonstrated in the example below.</p>
<p>Consider two datasets. The first one has 1M 192 dim uint32 datapoints, the second has 250K 768 dim uint32 datapoints. Note that both datasets would weigh about 192 MB.</p>
<p>When building the HNSW graph there is usually a ~100 byte overhead per vector, regardless of the vector dimension (the exact per-vector overhead varies depending on M parameter of HNSW). So, the first dataset would have a ~100MB HNSW graph overhead, while the second one would have 25MB HNSW graph overhead. The fact that HNSW index has two distinct components of vector data and graph is clearly visible from the diagrams in our <a href="https://lantern.dev/blog/calculator">cost estimation interactive blog post</a> as well.</p>
<p>This would translate into index expansion factors of (25+192) / 192 = 1.13 and (100+192) / 192 = 1.52. The exact same dataset results in HNSW graphs of predictable size but differing expansion factors. So, expansion factor is an inappropriate measure of index size predictability.</p>
<p>We think there is another contributor to artificially inflated <code>pgvector</code> index sizes in <code>pgvector</code> benchmarks by Pinecone: YFCC and MNIST datasets (which result in most expansion in Pinecone’s benchmarks) have int8 single-byte integer vector elements. However, they likely are represented as <code>vector</code> type in <code>pgvector</code> indexes, which has 4 byte floating point elements.</p>
<p>As a result, <code>pgvector</code> indexes get 4x inflated since they store 3 needless bytes for each 1 byte of vector element. <code>pgvector</code> supports halfvec data type which is a 2 byte floating point type and would reduce the artificial inflation. While single byte vector elements are <a href="https://github.com/pgvector/pgvector/issues/521">in the works</a> in <code>pgvector</code>, Lantern has support for single byte quantized vector indexes, which we have used for the filtering experiments above.</p>
<p>In sum, index sizes in Postgres are predictable and can be space-efficient. For the chosen YFCC dataset, Lantern indexes are as space-efficient as possible, and <code>pgvector</code> indexes will soon be similarly space-efficient once single precision vector element work gets merged in.</p>
<h2 id="h2-2106349" level="2" siblingcount="64">Cost</h2>
<p><em>In the cost section Pinecone concludes that Postgres is more expensive than Pinecone.</em></p>
<p>Note, however, that Pinecone assumes an average load of 10 requests per minute. Of course Pinecone’s serverless is going to look cheap when you compare it to a setup that can support about 20000 requests per minute with no hardware upgrade.</p>
<p><img src="https://storage.googleapis.com/lantern-blog/postgres-vs-pinecone-cost.png" alt="Postgres vs Pinecone Cost"></p>
<p>Above, we plot the monthly cost of various vector databases as a function of query load. We calculate Pinecone cost assuming read-only queries. We calculate the cost of other systems by assuming enough storage for the database and 10x more inserts, and enough RAM for vector indexes (64GB RAM instance, as in Pinecone’s blog post).</p>
<p>As you can see, Pinecone costs a lot when you scale the number of queries per minute. The other systems can sustain the same number of queries per minute with a very cheap instance.
In addition, many Postgres cloud providers such as Lantern, Supabase, Neon, Tembo, … have a free tier that could easily fit the kind of load Pinecone assumes.</p>
<p>If cost becomes an issue for larger datasets, Ubicloud offers a 3-5 times cheaper hosted Postgres service. Lantern partners with Ubicloud and offers Lantern Cloud on top of the cheaper Ubicloud base Postgres machines as well, so all Lantern-specific features, such as external indexing, embedding generation, etc., are available on the budget option as well!</p>
<p>To reduce cost even further, you can opt for database instances with much smaller RAM (e.g. 8 GB) that have fast local NVMe SSD block storage. Though this increases the tail latency, the latency still stays under 200ms. For example, for the YFCC experiments above, opting for NVMe SSD drives instead of large RAM to fit the index makes the p95 latency about four times worse - p95 latency increases from 41ms to 172ms.
Instances with NVMe storage are available through Lantern on Ubicloud.</p>
<h2 id="h2-310886967" level="2" siblingcount="64">Postgres Offers More</h2>
<p><strong>Transparency:</strong> Pinecone has better defaults and fewer configuration knobs to keep track of. However, these come at the cost of transparency - it is unclear what choices have been made on the user’s behalf and often there is no way to tune them.</p>
<p>E.g., according to Pinecone <a href="https://docs.pinecone.io/guides/data/filter-with-metadata">docs</a>, Pinecone has no guarantee about the number of results that are returned in a metadata-filtered query:</p>
<blockquote>
<p>When you use a highly selective metadata filter (i.e., a filter that rejects the vast majority of records in the index), the chosen clusters may not contain enough matching records to satisfy the designated top_k.
While similar setup with no guarantees exists trivially from Postgres, unlike Pinecone, Postgres can be configured to provide better support and guarantees due to its transparency.</p>
</blockquote>
<p><strong>Inline embedding generation:</strong> Since in Postgres data and vectors generated from the data are next to each other (often, as different columns of the same table), it is very easy to manage their lifetime together, generate, and update embeddings. Lantern Cloud even offers an embedding generation service that enables automatic embedding generation and maintenance with a single click in the dashboard.</p>
<p>Supabase - another Postgres cloud provider focused on app developers, has a similar <a href="https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings">embedding generation</a> offering.</p>
<p><strong>Streaming vector indexes:</strong> Though <code>pgvector</code> does not implement it yet, Timescale’s <code>pgvectorscale</code> and Lantern have an optimization that allows streaming a variable number of vectors from a vector index, thereby making it more likely a metadata filter will get hits in post-filtering.</p>
<p>So, using Lantern (likely, also Timescale) improves recall.</p>
<h2 id="h2--1594551224" level="2" siblingcount="64">Discussion</h2>
<h3 id="h3--1318502614" level="3" index="57" siblingcount="64">Didn’t we just demonstrate that Postgres is harder to make performant with all the code we had to write?</h3>
<p>No, Postgres enables choice and versatility. Out-of-the-box, these choices are often made with extra SQL statements and functions. Cloud providers such as Lantern make many of these choices behind the scenes to provide a more seamless experience.</p>
<p>It is true that, for example, for metadata filtering, we had to create and maintain additional indexes to make queries performant in Postgres, while Pinecone came with built-in easier-to-use metadata filtering. However, with only 20 lines of additional code we got absolute control over all our metadata values in Postgres, as well as our desired recall and latency.</p>
<p>What happens if, for a particular workload that involves metadata filtering, Pinecone’s recall of 60% is not enough? In Postgres, the question has an easy answer: create the right partial index with an additional line of the <code>CREATE INDEX</code> statement.</p>
<h3 id="h3-1118423306" level="3" index="61" siblingcount="64">How should you choose?</h3>
<p>We hope this article gives you some additional relevant context you can evaluate when reading Pinecone’s blog post on Postgres.</p>
<p>Reach out to your Postgres providers and ask them about the features we highlighted in this blog post. If you don’t have a current provider or would rather choose one specialized in GenAI for your GenAI workloads, please keep in touch via <a href="mailto:support@lantern.dev">support@lantern.dev</a>. We have helped dozens of companies build RAG pipelines powered by Postgres, in Lantern Cloud, in self-hosted Lantern and in other clouds. We would love to help you too.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: Sendune – open-source HTML email designer (348 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41007403</link>
            <guid>41007403</guid>
            <pubDate>Fri, 19 Jul 2024 15:22:40 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41007403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Demo: <a href="https://designer.sendune.com/" rel="nofollow">https://designer.sendune.com/</a>
Code: <a href="https://github.com/SendWithSES/Drag-and-Drop-Email-Designer">https://github.com/SendWithSES/Drag-and-Drop-Email-Designer</a></p><p>HTML for email is probably the hardest code to write. Even a teeny-tiny deviation from the rules will break the email in untold combination of os/desktop/mobile clients.</p><p>It's mid 2024. Almost 50 years since email was invented and 35 years since HTML was born. A 'basic-open-source-HTML-email-designer' must be a solved problem, right? We thought so too.</p><p>Sadly, that's not the case.</p><p>There are a few decent open source email designers but they carry dependencies that make them cumbersome to embed within your app. That's why we decided to open source our HTML Email Designer.</p><p>The SENDUNE email designer focuses on simplicity and ease of use. It is light-weight. It does pure HTML - no intermediate code wranglers like mjml. There is no lock-in of any kind. Save HTML output as a template and use with ANY email service provider.</p><p>Feel free to fork the repository, make improvements, and submit pull requests.</p><p>AMA: hello at sendune dot com</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bangladesh is in the midst of a near-total internet shutdown (381 pts)]]></title>
            <link>https://mastodon.social/@netblocks/112808500770031751</link>
            <guid>41007396</guid>
            <pubDate>Fri, 19 Jul 2024 15:22:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@netblocks/112808500770031751">https://mastodon.social/@netblocks/112808500770031751</a>, See on <a href="https://news.ycombinator.com/item?id=41007396">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Loss of oxygen in lakes and oceans (115 pts)]]></title>
            <link>https://www.sciencedaily.com/releases/2024/07/240715135713.htm</link>
            <guid>41007196</guid>
            <pubDate>Fri, 19 Jul 2024 14:59:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedaily.com/releases/2024/07/240715135713.htm">https://www.sciencedaily.com/releases/2024/07/240715135713.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41007196">Hacker News</a></p>
Couldn't get https://www.sciencedaily.com/releases/2024/07/240715135713.htm: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[NASA's Curiosity rover discovers a surprise in a Martian rock (164 pts)]]></title>
            <link>https://www.jpl.nasa.gov/news/nasas-curiosity-rover-discovers-a-surprise-in-a-martian-rock</link>
            <guid>41006552</guid>
            <pubDate>Fri, 19 Jul 2024 13:47:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpl.nasa.gov/news/nasas-curiosity-rover-discovers-a-surprise-in-a-martian-rock">https://www.jpl.nasa.gov/news/nasas-curiosity-rover-discovers-a-surprise-in-a-martian-rock</a>, See on <a href="https://news.ycombinator.com/item?id=41006552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="zt1vd">Scientists were stunned on May 30 when a rock that NASA’s Curiosity Mars rover drove over cracked open to reveal something never seen before on the Red Planet: yellow sulfur crystals.</p><p data-block-key="cj811">Since October 2023, the rover has been exploring a region of Mars <a href="https://www.jpl.nasa.gov/news/nasas-curiosity-mars-rover-reaches-long-awaited-salty-region">rich with sulfates</a>, a kind of salt that contains sulfur and forms as water evaporates. But where past detections have been of sulfur-based minerals — in other words, a mix of sulfur and other materials — the rock Curiosity recently cracked open is made of elemental, or pure, sulfur. It isn’t clear what relationship, if any, the elemental sulfur has to other sulfur-based minerals in the area.</p><p data-block-key="mh48">While people associate sulfur with the odor from rotten eggs (the result of hydrogen sulfide gas), elemental sulfur is odorless. It forms in only a narrow range of conditions that scientists haven’t associated with the history of this location. And Curiosity found a lot of it — an entire field of bright rocks that look similar to the one the rover crushed.</p></div><div><p data-block-key="833vq">“This was not a quiet period on Mars,” said Becky Williams, a scientist with the Planetary Science Institute in Tucson, Arizona, and the deputy principal investigator of Curiosity’s Mast Camera, or <a href="https://science.nasa.gov/mission/msl-curiosity/science-instruments/#h-mastcam">Mastcam</a>. “There was an exciting amount of activity here. We’re looking at multiple flows down the channel, including energetic floods and boulder-rich flows.”</p><h3 data-block-key="b1o8c"><b>A Hole in 41</b></h3><p data-block-key="1fo2c">All this evidence of water continues to tell a more complex story than the team’s early expectations, and they’ve been eager to take a rock sample from the channel in order to learn more. On June 18, they got their chance.</p><p data-block-key="4nqk2">While the sulfur rocks were too small and brittle to be sampled with the drill, a large rock nicknamed “Mammoth Lakes” was spotted nearby. Rover engineers had to search for a part of the rock that would allow safe drilling and find a parking spot on the loose, sloping surface.</p><p data-block-key="69md5">After Curiosity bored its 41st hole using the powerful drill at the end of the rover’s 7-foot (2-meter) robotic arm, the six-wheeled scientist trickled the powderized rock into instruments inside its belly for further analysis so that scientists can determine what materials the rock is made of.</p><p data-block-key="28kmt">Curiosity has since <a href="https://science.nasa.gov/blogs/sols-4236-4238-one-more-time-for-contact-science-at-mammoth-lakes/">driven away from Mammoth Lakes</a> and is now off to see what other surprises are waiting to be discovered within the channel.</p><h3 data-block-key="1ntcr"><b>More About the Mission</b></h3><p data-block-key="a89km">Curiosity was built by NASA’s Jet Propulsion Laboratory, which is managed by Caltech in Pasadena, California. JPL leads the mission on behalf of NASA’s Science Mission Directorate in Washington.</p><p data-block-key="23pss">For more about Curiosity, visit:</p><p data-block-key="fo00b"><a href="https://science.nasa.gov/mission/msl-curiosity">science.nasa.gov/mission/msl-curiosity</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debugging an evil Go runtime bug: From heat guns to kernel compiler flags (154 pts)]]></title>
            <link>https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/</link>
            <guid>41006308</guid>
            <pubDate>Fri, 19 Jul 2024 13:24:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/">https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/</a>, See on <a href="https://news.ycombinator.com/item?id=41006308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    

<h2 id="preface">Preface</h2>

<p>I’m a big fan of <a href="https://prometheus.io/">Prometheus</a> and
<a href="https://grafana.com/">Grafana</a>. As a former SRE at Google I’ve learned to
appreciate good monitoring, and this combination has been a winner for me
over the past year. I’m using them for monitoring my personal servers (both
black-box and white-box monitoring), for the
<a href="https://encounter.eus/">Euskal Encounter</a> external and internal event infra,
for work I do professionally for clients, and more. Prometheus makes it very
easy to write custom exporters to monitor your own data, and there’s a good
chance you’ll find an exporter that already works for you out of the box.
For example, we use <a href="https://github.com/justwatchcom/sql_exporter">sql_exporter</a>
to make a pretty dashboard of attendee metrics for the Encounter events.</p>


<figure>
    <a href="https://marcan.st/posts/go_debug/euskalstats.png">
        <img src="https://marcan.st/posts/go_debug/euskalstats.png" width="640">
    </a>
    
    <figcaption>
        <h4>Event dashboard for Euskal Encounter (fake staging data)</h4>
        
    </figcaption>
    
</figure>


<p>Since it’s so easy to throw
<a href="https://github.com/prometheus/node_exporter"><code>node_exporter</code></a> onto any random
machine and have a Prometheus instance scrape it for basic system-level metrics
(CPU, memory, network, disk, filesystem usage, etc), I figured, why not also
monitor my laptop? I have a Clevo “gaming” laptop that serves as my primary
workstation, mostly pretending to be a desktop at home but also traveling with
me to big events like the Chaos Communication Congress. Since I already have a
VPN between it and one of my servers where I run Prometheus, I can just
<code>emerge prometheus-node_exporter</code>, bring up the service, and point my Prometheus
instance at it. This automatically configures alerts for it, which means my
phone will make a loud noise whenever I open way too many Chrome tabs and run
out of my 32GB of RAM. Perfect.</p>

<h2 id="trouble-on-the-horizon">Trouble on the horizon</h2>

<p>Barely an hour after setting this up, though, my phone did get a page: my
newly-added target was inaccessible. Alas, I could SSH into the laptop fine, so
it was definitely up, but <code>node_exporter</code> had crashed.</p>

<pre><code>fatal error: unexpected signal during runtime execution
[signal SIGSEGV: segmentation violation code=0x1 addr=0xc41ffc7fff pc=0x41439e]

goroutine 2395 [running]:
runtime.throw(0xae6fb8, 0x2a)
        /usr/lib64/go/src/runtime/panic.go:605 +0x95 fp=0xc4203e8be8 sp=0xc4203e8bc8 pc=0x42c815
runtime.sigpanic()
        /usr/lib64/go/src/runtime/signal_unix.go:351 +0x2b8 fp=0xc4203e8c38 sp=0xc4203e8be8 pc=0x443318
runtime.heapBitsSetType(0xc4204b6fc0, 0x30, 0x30, 0xc420304058)
        /usr/lib64/go/src/runtime/mbitmap.go:1224 +0x26e fp=0xc4203e8c90 sp=0xc4203e8c38 pc=0x41439e
runtime.mallocgc(0x30, 0xc420304058, 0x1, 0x1)
        /usr/lib64/go/src/runtime/malloc.go:741 +0x546 fp=0xc4203e8d38 sp=0xc4203e8c90 pc=0x411876
runtime.newobject(0xa717e0, 0xc42032f430)
        /usr/lib64/go/src/runtime/malloc.go:840 +0x38 fp=0xc4203e8d68 sp=0xc4203e8d38 pc=0x411d68
github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_golang/prometheus.NewConstMetric(0xc42018e460, 0x2, 0x3ff0000000000000, 0xc42032f430, 0x1, 0x1, 0x10, 0x9f9dc0, 0x8a0601, 0xc42032f430)
        /var/tmp/portage/net-analyzer/prometheus-node_exporter-0.15.0/work/prometheus-node_exporter-0.15.0/src/github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_golang/prometheus/value.go:165 +0xd0 fp=0xc4203e8dd0 sp=0xc4203e8d68 pc=0x77a980
</code></pre>

<p><code>node_exporter</code>, like many Prometheus components, is written in Go. Go is a
relatively safe language: while it allows you to shoot yourself in the foot if
you so wish, and it doesn’t have nearly as strong safety guarantees as, say,
Rust does, it is still not too easy to accidentally cause a segfault in Go.
More so, <code>node_exporter</code> is a relatively simple Go app with mostly pure-Go
dependencies. Therefore, this was an interesting crash to get. Especially since
the crash was inside <code>mallocgc</code>, which should never crash under normal
circumstances.</p>

<p>Things got more interesting after I restarted it a few times:</p>

<pre><code>2017/11/07 06:32:49 http: panic serving 172.20.0.1:38504: runtime error: growslice: cap out of range
goroutine 41 [running]:
net/http.(*conn).serve.func1(0xc4201cdd60)
        /usr/lib64/go/src/net/http/server.go:1697 +0xd0
panic(0xa24f20, 0xb41190)
        /usr/lib64/go/src/runtime/panic.go:491 +0x283
fmt.(*buffer).WriteString(...)
        /usr/lib64/go/src/fmt/print.go:82
fmt.(*fmt).padString(0xc42053a040, 0xc4204e6800, 0xc4204e6850)
        /usr/lib64/go/src/fmt/format.go:110 +0x110
fmt.(*fmt).fmt_s(0xc42053a040, 0xc4204e6800, 0xc4204e6850)
        /usr/lib64/go/src/fmt/format.go:328 +0x61
fmt.(*pp).fmtString(0xc42053a000, 0xc4204e6800, 0xc4204e6850, 0xc400000073)
        /usr/lib64/go/src/fmt/print.go:433 +0x197
fmt.(*pp).printArg(0xc42053a000, 0x9f4700, 0xc42041c290, 0x73)
        /usr/lib64/go/src/fmt/print.go:664 +0x7b5
fmt.(*pp).doPrintf(0xc42053a000, 0xae7c2d, 0x2c, 0xc420475670, 0x2, 0x2)
        /usr/lib64/go/src/fmt/print.go:996 +0x15a
fmt.Sprintf(0xae7c2d, 0x2c, 0xc420475670, 0x2, 0x2, 0x10, 0x9f4700)
        /usr/lib64/go/src/fmt/print.go:196 +0x66
fmt.Errorf(0xae7c2d, 0x2c, 0xc420475670, 0x2, 0x2, 0xc420410301, 0xc420410300)
        /usr/lib64/go/src/fmt/print.go:205 +0x5a
</code></pre>

<p>Well that’s interesting. A crash in <code>Sprintf</code> this time. What?</p>

<pre><code>runtime: pointer 0xc4203e2fb0 to unallocated span idx=0x1f1 span.base()=0xc4203dc000 span.limit=0xc4203e6000 span.state=3
runtime: found in object at *(0xc420382a80+0x80)
object=0xc420382a80 k=0x62101c1 s.base()=0xc420382000 s.limit=0xc420383f80 s.spanclass=42 s.elemsize=384 s.state=_MSpanInUse
 &lt;snip&gt;
fatal error: found bad pointer in Go heap (incorrect use of unsafe or cgo?)

runtime stack:
runtime.throw(0xaee4fe, 0x3e)
        /usr/lib64/go/src/runtime/panic.go:605 +0x95 fp=0x7f0f19ffab90 sp=0x7f0f19ffab70 pc=0x42c815
runtime.heapBitsForObject(0xc4203e2fb0, 0xc420382a80, 0x80, 0xc41ffd8a33, 0xc400000000, 0x7f0f400ac560, 0xc420031260, 0x11)
        /usr/lib64/go/src/runtime/mbitmap.go:425 +0x489 fp=0x7f0f19ffabe8 sp=0x7f0f19ffab90 pc=0x4137c9
runtime.scanobject(0xc420382a80, 0xc420031260)
        /usr/lib64/go/src/runtime/mgcmark.go:1187 +0x25d fp=0x7f0f19ffac90 sp=0x7f0f19ffabe8 pc=0x41ebed
runtime.gcDrain(0xc420031260, 0x5)
        /usr/lib64/go/src/runtime/mgcmark.go:943 +0x1ea fp=0x7f0f19fface0 sp=0x7f0f19ffac90 pc=0x41e42a
runtime.gcBgMarkWorker.func2()
        /usr/lib64/go/src/runtime/mgc.go:1773 +0x80 fp=0x7f0f19ffad20 sp=0x7f0f19fface0 pc=0x4580b0
runtime.systemstack(0xc420436ab8)
        /usr/lib64/go/src/runtime/asm_amd64.s:344 +0x79 fp=0x7f0f19ffad28 sp=0x7f0f19ffad20 pc=0x45a469
runtime.mstart()
        /usr/lib64/go/src/runtime/proc.go:1125 fp=0x7f0f19ffad30 sp=0x7f0f19ffad28 pc=0x430fe0
</code></pre>

<p>And now the garbage collector stumbled upon a problem. Yet a different crash.</p>

<p>At this point, there are two natural conclusions: either I have a severe
hardware issue, or there is a wild memory corruption bug in the binary. I
initially considered the former unlikely, as this machine has a very heavily
mixed workload and no signs of instability that can be traced back to hardware
(I have my fair share of crashing software, but it’s never <em>random</em>). Since Go
binaries like <code>node_exporter</code> are statically linked and do not depend on any other
libraries, I can download the official release binary and try that, which would
eliminate most of the rest of my system as a variable. Yet, when I did so, I
still got a crash.</p>

<pre><code>unexpected fault address 0x0
fatal error: fault
[signal SIGSEGV: segmentation violation code=0x80 addr=0x0 pc=0x76b998]

goroutine 13 [running]:
runtime.throw(0xabfb11, 0x5)
        /usr/local/go/src/runtime/panic.go:605 +0x95 fp=0xc420060c40 sp=0xc420060c20 pc=0x42c725
runtime.sigpanic()
        /usr/local/go/src/runtime/signal_unix.go:374 +0x227 fp=0xc420060c90 sp=0xc420060c40 pc=0x443197
github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_model/go.(*LabelPair).GetName(...)
        /go/src/github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_model/go/metrics.pb.go:85
github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_golang/prometheus.(*Desc).String(0xc4203ae010, 0xaea9d0, 0xc42045c000)
        /go/src/github.com/prometheus/node_exporter/vendor/github.com/prometheus/client_golang/prometheus/desc.go:179 +0xc8 fp=0xc420060dc8 sp=0xc420060c90 pc=0x76b998
</code></pre>

<p>Yet another completely different crash. At this point there was a decent chance
that there was truly an upstream problem with <code>node_exporter</code> or one of its
dependencies, so I filed an
<a href="https://github.com/prometheus/node_exporter/issues/730">issue</a> on GitHub.
Perhaps the developers had seen this before? It’s worth bringing this kind of
issue to their attention and seeing if they have any ideas.</p>



<p>Unsurprisingly, upstream’s first guess was that it was a hardware issue. This
isn’t unreasonable: after all, I’m only hitting the problem on one specific
machine. All my other machines are happily running <code>node_exporter</code>. While I had no
other evidence of hardware-linked instability on this host, I also had no other
explanation as to what was so particular about this machine that would make
<code>node_exporter</code> crash. A <a href="http://www.memtest.org/">Memtest86+</a> run never hurt
anyone, so I gave it a go.</p>

<p>And then this happened:</p>


<figure>
    <a href="https://marcan.st/posts/go_debug/memtest.png">
        <img src="https://marcan.st/posts/go_debug/memtest.png" width="640">
    </a>
    
    <figcaption>
        <h4>This is what I get for using consumer hardware</h4>
        
    </figcaption>
    
</figure>


<p>Whoops! Bad RAM. Well, to be more specific, <em>one bit</em> of bad RAM. After letting
the test run for a full pass, all I got was that single bad bit, plus a few
false positives in test 7 (which moves blocks around and so can amplify a single
error).</p>

<p>Further testing showed that Memtest86+ test #5 in SMP mode would quickly detect
the error, but usually not on the first pass. The error was always the same bit
at the same address. This suggests that the problem is a weak or leaky RAM cell.
In particular, one which gets worse with temperature. This is quite logical:
a higher temperature increases leakage in the RAM cells and thus makes it more
likely that a somewhat marginal cell will actually cause a bit flip.</p>

<p>To put this into perspective, this is one bad bit out of 274,877,906,944. That’s
actually a very good error rate! Hard disks and Flash memory have much higher
error rates - it’s just that those devices have bad blocks marked at the factory
that are transparently swapped out without the user knowing, and can
transparently mark newly discovered weak blocks as bad and relocate them to a
spare area. RAM has no such luxury, so a bad bit sticks forever.</p>

<p>Alas, this is vanishingly unlikely to be the cause of my <code>node_exporter</code> woes.
That app uses very little RAM, and so the chances of it hitting the bad bit
(repeatedly, at that) are extremely low. This kind of problem would be largely
unnoticeable, perhaps causing a pixel error in some graphics, a single letter
to flip in some text, an instruction to be corrupted that probably won’t ever
be run, and perhaps the rare segfault when something actually important does
land on the bad bit. Nonetheless, it does cause long-term reliability issues,
and this is why servers and other devices intended to be reliable must use ECC
RAM, which can correct this kind of error.</p>

<p>I don’t have the luxury of ECC RAM on this laptop. What I do have, though, is
the ability to mark the bad block of RAM as bad and tell the OS not to use it.
There is a little-known
<a href="https://www.gnu.org/software/grub/manual/grub/html_node/badram.html">feature</a>
of GRUB 2 which allows you to do just that, by changing the memory map that is
passed to the booted kernel. It’s not worth buying new RAM just for a single bad
bit (especially since DDR3 is already obsolete, and there’s a good chance new
RAM would have weak cells anyway), so this is a good option.</p>

<p>However, there’s one more thing I can do. Since the problem gets worse with
temperature, what happens if I heat up the RAM?</p>

<figure>
    <a href="https://marcan.st/posts/go_debug/badram.jpg">
        <img src="https://marcan.st/posts/go_debug/badram_s.jpg" width="400">
    </a>
    
    <figcaption>
        <h4>🔥🔥🔥memtest86+🔥🔥🔥</h4>
        
    </figcaption>
    
</figure>


<figure>
    <a href="https://marcan.st/posts/go_debug/badram_t.jpg">
        <img src="https://marcan.st/posts/go_debug/badram_ts.jpg" width="400">
    </a>
    
    <figcaption>
        <h4>A cozy 100°C</h4>
        
    </figcaption>
    
</figure>


<p>Using a heat gun set at a fairly low temperature (130°C) I warmed up two modules
at a time (the other two modules are under the rear cover, as my laptop has four
SODIMM slots total). Playing around with module order, I found three additional
weak bits only detectable at elevated temperature, and they were spread around
three of my RAM sticks.</p>

<p>I also found that the location of the errors stayed roughly consistent even as I
swapped modules around: the top bits of the address remained the same. This is
because the RAM is interleaved: data is spread over all four sticks, instead of
each stick being assigned a contiguous quarter of the available address space.
This is convenient, because I can just mask a region of RAM large enough to
cover all possible addresses for each error bit, and not have to worry that I
might swap sticks in the future and mess up the masking. I found that masking a
contiguous 128KiB area should cover all possible permutations of addresses for
each given bad bit, but, for good measure, I rounded up to 1MiB. This gave me
three 1MiB aligned blocks to mask out (one of them covers two of the bad bits,
for a total of four bad bits I wanted masked):</p>

<ul>
<li><code>0x36a700000</code> – <code>0x36a7fffff</code></li>
<li><code>0x460e00000</code> – <code>0x460efffff</code></li>
<li><code>0x4ea000000</code> – <code>0x4ea0fffff</code></li>
</ul>

<p>This can be specified using the address/mask syntax required by GRUB as follows,
in <code>/etc/default/grub</code>:</p>

<pre><code>GRUB_BADRAM="0x36a700000,0xfffffffffff00000,0x460e00000,0xfffffffffff00000,0x4ea000000,0xfffffffffff00000"
</code></pre>

<p>One quick <code>grub-mkconfig</code> later, I am down 3MiB of RAM and four dodgy bits with
it. It’s not ECC RAM, but this should increase the effective reliability of my
consumer-grade RAM, since now I know the rest of the memory is fine up to at
least 100°C.</p>

<p>Needless to say, <code>node_exporter</code> still crashed, but we knew this wasn’t the real
problem, didn’t we.</p>

<h2 id="digging-deeper">Digging deeper</h2>

<p>The annoying thing about this kind of bug is that it clearly is caused by some
kind of memory corruption that breaks code that runs later. This makes it very
hard to debug, because we can’t predict what will be corrupted (it varies), and
we can’t catch the bad code in the act of doing so.</p>

<p>First I tried some basic bisecting of available <code>node_exporter</code> releases and
enabling/disabling different collectors, but that went nowhere. I also tried
running an instance under <code>strace</code>. This seemed to stop the crashes, which
strongly points to a race-condition kind of problem. <code>strace</code> will usually wind
up serializing execution of apps to some extent, by intercepting all system
calls run by all threads. I would later find that the <code>strace</code> instance crashed
too, but it took much longer to do so. Since this seemed to be related to
concurrency, I tried setting <code>GOMAXPROCS=1</code>, which tells Go to only use a single
OS-level thread to run Go code. This also stopped the crashes, again pointing
strongly to a concurrency issue.</p>

<p>By now I had gathered quite a considerable number of crash logs, and I was
starting to notice some patterns. While there was a lot of variation in the
parts that were crashing and how, ultimately the error messages could be
categorized into different types and the same kind of error showed up more than
once. So I started Googling these errors, and this is how I stumbled upon
<a href="https://github.com/golang/go/issues/20427">Go issue #20427</a>. This was an issue
in seemingly an unrelated part of Go, but one that had caused similar segfaults
and random issues. The issue was closed with no diagnosis after it couldn’t be
reproduced with Go 1.9. Nobody knew what the root cause was, just that it had
stopped happening.</p>

<p>So I grabbed
<a href="https://github.com/golang/go/issues/20427#issuecomment-306346724">this</a> sample
code from the issue, which claimed to reproduce the problem, and ran it on my
machine. Lo and behold, it crashed within seconds. Bingo. This is a lot better
than waiting hours for <code>node_exporter</code> to crash.</p>

<p>That doesn’t get me any closer to debugging the issue from the Go side, but it
gives me a much faster way to test for it. So let’s try another angle.</p>

<h2 id="bisecting-machines">Bisecting machines</h2>

<p>I know the problem happens on my laptop, but doesn’t happen on any other of my
machines. I tried the reproducer on every other machine I have easy access to,
and couldn’t get it to crash on any of them. This tells me there’s something
special about my laptop. Since Go statically links binaries, the rest of
userspace doesn’t matter. This leaves two relevant parts: the hardware, and the
kernel.</p>

<p>I don’t have any easy way to test with various hardware other than the machines
I own, but I can play with kernels. So let’s try that. First order of business:
will it crash in a VM?</p>

<p>To test for this, I built a minimal initramfs that will allow me to very quickly
launch the reproducer in a QEMU VM without having to actually install a distro
or boot a full Linux system. My initramfs was built with Linux’s
<code>scripts/gen_initramfs_list.sh</code> and contained the following files:</p>

<pre><code>dir /dev 755 0 0
nod /dev/console 0600 0 0 c 5 1
nod /dev/null 0666 0 0 c 1 3
dir /bin 755 0 0
file /bin/busybox busybox 755 0 0
slink /bin/sh busybox 755 0 0
slink /bin/true busybox 755 0 0
file /init init.sh 755 0 0
file /reproducer reproducer 755 0 0
</code></pre>

<p><code>/init</code> is the entry point of a Linux initramfs, and in my case was a simple
shellscript to start the test and measure time:</p>

<pre><code>#!/bin/sh
export PATH=/bin

start=$(busybox date +%s)

echo "Starting test now..."
/reproducer
ret=$?
end=$(busybox date +%s)
echo "Test exited with status $ret after $((end-start)) seconds"
</code></pre>

<p><code>/bin/busybox</code> is a statically linked version of BusyBox, often used in minimal
systems like this to provide all basic Linux shell utilities (including a shell
itself).</p>

<p>The initramfs can be built like this (from a Linux kernel source tree), where
list.txt is the file list above:</p>

<pre><code>scripts/gen_initramfs_list.sh -o initramfs.gz list.txt
</code></pre>

<p>And QEMU can boot the kernel and initramfs directly:</p>

<pre><code>qemu-system-x86_64 -kernel /boot/vmlinuz-4.13.9-gentoo -initrd initramfs.gz -append 'console=ttyS0' -smp 8 -nographic -serial mon:stdio -cpu host -enable-kvm
</code></pre>

<p>This resulted in no output at all to the console… and then I realized I hadn’t
even compiled 8250 serial port support into my laptop’s kernel. D’oh. I mean, it
doesn’t have a physical serial port, right? Anyway, a quick detour to rebuild
the kernel with serial support (and crossing my fingers that didn’t change
anything important), I tried again and it successfully booted and ran the
reproducer.</p>

<p>Did it crash? Yup. Good, this means the problem is reproducible on a VM on the
same machine. I tried the same QEMU command on my home server, with its own
kernel, and… nothing. Then I copied the kernel from my laptop and booted that
and… it crashed. The kernel is what matters. It’s not a hardware issue.</p>

<h2 id="juggling-kernels">Juggling kernels</h2>

<p>At this point, I knew I was going to be compiling lots of kernels to try to
narrow this down. So I decided to move to the most powerful machine I had lying
around: a somewhat old 12-core, 24-thread Xeon (now defunct, sadly). I copied
the known-bad kernel source to that machine, built it, and tested it.</p>

<p>It didn’t crash.</p>

<p>What?</p>

<p>Some head-scratching later, I made sure the original bad kernel binary crashed
(it did). Are we back to hardware? Does it matter which machine I <em>build</em> the
kernel on? So I tried building the kernel on my home server, and that one
promptly triggered the crash. Building the same kernel on two machines yields
crashes, a third machine doesn’t. What’s the difference?</p>

<p>Well, these are all Gentoo boxes, and all Gentoo Hardened at that. But my laptop
and my home server are both <code>~amd64</code> (unstable), while my Xeon server is <code>amd64</code>
(stable). That means GCC is different. My laptop and home server were both on
<code>gcc (Gentoo Hardened 6.4.0 p1.0) 6.4.0</code>, while my Xeon was on
<code>gcc (Gentoo Hardened 5.4.0-r3 p1.3, pie-0.6.5) 5.4.0</code>.</p>

<p>But my home server’s kernel, which was nearly the same version as my laptop
(though not exactly), built with the same GCC, did not reproduce the crashes. So
now we have to conclude that <em>both</em> the compiler used to build the kernel <em>and</em>
the kernel itself (or its config?) matter.</p>

<p>To narrow things down further, I compiled the exact kernel tree from my laptop
on my home server (linux-4.13.9-gentoo), and confirmed that it indeed crashed.
Then I copied over the <code>.config</code> from my home server and compiled that, and
found that it didn’t. This means we’re looking at a kernel config difference
<em>and</em> a compiler difference:</p>

<ul>
<li>linux-4.13.9-gentoo + gcc 5.4.0-r3 p1.3 + laptop .config - no crash</li>
<li>linux-4.13.9-gentoo + gcc 6.4.0 p1.0 + laptop .config - <em>crash</em></li>
<li>linux-4.13.9-gentoo + gcc 6.4.0 p1.0 + server .config - no crash</li>
</ul>

<p>Two <code>.config</code>s, one good, and one bad. Time to diff them. Of course, the two
configs were vastly different (since I tend to tailor my kernel config to only
include the drivers I need on any particular machine), so I had to repeatedly
rebuild the kernel while narrowing down the differences.</p>

<p>I decided to start with the “known bad” <code>.config</code> and start removing things.
Since the reproducer takes a variable amount of time to crash, it’s easier to
test for “still crashes” (just wait for it to crash) than for “doesn’t crash”
(how long do I have to wait to convince myself that it doesn’t?). Over the
course of 22 kernel builds, I managed to simplify the
<a href="https://marcan.st/posts/go_debug/config">config</a> so much that the kernel had no networking
support, no filesystems, no block device core, and didn’t even support PCI
(still works fine on a VM though!). My kernel builds now took less than 60
seconds and the kernel was about 1/4th the size of my regular one.</p>

<p>Then I moved on to the “known good” <code>.config</code> and removed all the unnecessary
junk while making sure it still didn’t crash the reproducer (which was trickier
and slower than the previous test). I had a few false branches, where I changed
something that made the reproducer start crashing (but I didn’t know what), yet
I misidentified them as “no crash”, so when I got a crash I had to walk back up
the previous kernels I’d built and make sure I knew exactly where the crash was
introduced. I ended up doing 7 kernel builds.</p>

<p>Eventually, I narrowed it down to a small handful of different .config options.
A few of them stood out, in particular <code>CONFIG_OPTIMIZE_INLINING</code>. After
carefully testing them I concluded that, indeed, that option was the culprit.
Turning it <em>off</em> produced kernels that crash the reproducer testcase, while
turning it <em>on</em> produced kernels that didn’t. This option, when turned on,
allows GCC to better determine which <code>inline</code> functions really must be inlined,
instead of forcing it to inline them unconditionally. This also explains the GCC
connection: inlining behavior is likely to change between GCC versions.</p>

<pre><code>/*
 * Force always-inline if the user requests it so via the .config,
 * or if gcc is too old.
 * GCC does not warn about unused static inline functions for
 * -Wunused-function.  This turns out to avoid the need for complex #ifdef
 * directives.  Suppress the warning in clang as well by using "unused"
 * function attribute, which is redundant but not harmful for gcc.
 */
#if !defined(CONFIG_ARCH_SUPPORTS_OPTIMIZED_INLINING) ||                \
    !defined(CONFIG_OPTIMIZE_INLINING) || (__GNUC__ &lt; 4)
#define inline inline           __attribute__((always_inline,unused)) notrace
#define __inline__ __inline__   __attribute__((always_inline,unused)) notrace
#define __inline __inline       __attribute__((always_inline,unused)) notrace
#else
/* A lot of inline functions can cause havoc with function tracing */
#define inline inline           __attribute__((unused)) notrace
#define __inline__ __inline__   __attribute__((unused)) notrace
#define __inline __inline       __attribute__((unused)) notrace
#endif
</code></pre>

<p>So what next? We know that <code>CONFIG_OPTIMIZE_INLINING</code> makes the difference, but
that potentially changes the behavior of every single <code>inline</code> function across
the whole kernel. How to pinpoint the problem?</p>

<p>I had an idea.</p>

<h2 id="hash-based-differential-compilation">Hash-based differential compilation</h2>

<p>The basic premise is to compile <em>part</em> of the kernel with the option turned on,
and <em>part</em> of the kernel with the option turned off. By testing the resulting
kernel and checking whether the problem appears or not, we can deduce which
subset of the kernel compilation units contains the problem code.</p>

<p>Instead of trying to enumerate all object files and doing some kind of binary
search, I decided to go with a hash-based approach. I wrote this wrapper
script for GCC:</p>

<pre><code>#!/bin/bash
args=("$@")

doit=
while [ $# -gt 0 ]; do
        case "$1" in
                -c)
                        doit=1
                        ;;
                -o)
                        shift
                        objfile="$1"
                        ;;
        esac
        shift
done

extra=
if [ ! -z "$doit" ]; then
        sha="$(echo -n "$objfile" | sha1sum - | cut -d" " -f1)"
        echo "${sha:0:8} $objfile" &gt;&gt; objs.txt
        if [ $((0x${sha:0:8} &amp; (0x80000000 &gt;&gt; $BIT))) = 0 ]; then
                echo "[n]" "$objfile" 1&gt;&amp;2
        else
                extra=-DCONFIG_OPTIMIZE_INLINING
                echo "[y]" "$objfile" 1&gt;&amp;2
        fi
fi

exec gcc $extra "${args[@]}"
</code></pre>

<p>This hashes the object file name with SHA-1, then checks a given bit of the
hash out of the first 32 bits (identified by the <code>$BIT</code> environment variable).
If the bit is 0, it builds without <code>CONFIG_OPTIMIZE_INLINING</code>. If it is 1,
it builds with <code>CONFIG_OPTIMIZE_INLINING</code>. I found that the kernel had around
685 object files at this point (my minimization effort had paid off), which
requires about 10 bits for a unique identification. This hash-based approach
also has one neat property: I can choose to only worry about crashing outcomes
(where the bit is 0), since it is much harder to prove that a given kernel build
does not crash (as the crashes are probabilistic and can take quite a while
sometimes).</p>

<p>I built 32 kernels, one for each bit of the SHA-1 prefix, which only took 29
minutes. Then I started testing them, and every time I got a crash, I narrowed
down a regular expression of possible SHA-1 hashes to only those with zero bits
at those specific positions. At 8 crashes (and thus zero bits), I was down to 4
object files, and a couple were looking promising. Once I hit the 10th crash,
there was a single match.</p>

<pre><code>$ grep '^[0246][012389ab][0189][014589cd][028a][012389ab][014589cd]' objs_0.txt
6b9cab4f arch/x86/entry/vdso/vclock_gettime.o
</code></pre>

<p>vDSO code. Of course.</p>

<h2 id="vdso-shenanigans">vDSO shenanigans</h2>

<p>The kernel’s vDSO is not actually kernel code. vDSO is a small shared library
that the kernel places in the address space of every process, and which allows
apps to perform certain special system calls without ever leaving user mode.
This increases performance significantly, while still allowing the kernel to
change the implementation details of those system calls as needed.</p>

<p>In other words, vDSO is GCC-compiled code, built with the kernel, that ends up
being linked with every userspace app. It’s userspace code. This explains why
the kernel and its compiler mattered: it wasn’t about the kernel itself, but
about a shared library provided by the kernel! And Go uses the vDSO for
performance. Go also happens to have a (rather insane, in my opinion) policy of
reinventing its own standard library, so it does not use any of the standard
Linux glibc code to call vDSO, but rather rolls its own calls (and syscalls
too).</p>

<p>So what does flipping <code>CONFIG_OPTIMIZE_INLINING</code> do to the vDSO? Let’s look at
the assembly.</p>

<p>With <code>CONFIG_OPTIMIZE_INLINING=n</code>:</p>

<pre><code>arch/x86/entry/vdso/vclock_gettime.o.no_inline_opt:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;vread_tsc&gt;:
   0:	55                   	push   %rbp
   1:	48 89 e5             	mov    %rsp,%rbp
   4:	90                   	nop
   5:	90                   	nop
   6:	90                   	nop
   7:	0f 31                	rdtsc  
   9:	48 c1 e2 20          	shl    $0x20,%rdx
   d:	48 09 d0             	or     %rdx,%rax
  10:	48 8b 15 00 00 00 00 	mov    0x0(%rip),%rdx        # 17 &lt;vread_tsc+0x17&gt;
  17:	48 39 c2             	cmp    %rax,%rdx
  1a:	77 02                	ja     1e &lt;vread_tsc+0x1e&gt;
  1c:	5d                   	pop    %rbp
  1d:	c3                   	retq   
  1e:	48 89 d0             	mov    %rdx,%rax
  21:	5d                   	pop    %rbp
  22:	c3                   	retq   
  23:	0f 1f 00             	nopl   (%rax)
  26:	66 2e 0f 1f 84 00 00 	nopw   %cs:0x0(%rax,%rax,1)
  2d:	00 00 00 

0000000000000030 &lt;__vdso_clock_gettime&gt;:
  30:	55                   	push   %rbp
  31:	48 89 e5             	mov    %rsp,%rbp
  34:	48 81 ec 20 10 00 00 	sub    $0x1020,%rsp
  3b:	48 83 0c 24 00       	orq    $0x0,(%rsp)
  40:	48 81 c4 20 10 00 00 	add    $0x1020,%rsp
  47:	4c 8d 0d 00 00 00 00 	lea    0x0(%rip),%r9        # 4e &lt;__vdso_clock_gettime+0x1e&gt;
  4e:	83 ff 01             	cmp    $0x1,%edi
  51:	74 66                	je     b9 &lt;__vdso_clock_gettime+0x89&gt;
  53:	0f 8e dc 00 00 00    	jle    135 &lt;__vdso_clock_gettime+0x105&gt;
  59:	83 ff 05             	cmp    $0x5,%edi
  5c:	74 34                	je     92 &lt;__vdso_clock_gettime+0x62&gt;
  5e:	83 ff 06             	cmp    $0x6,%edi
  61:	0f 85 c2 00 00 00    	jne    129 &lt;__vdso_clock_gettime+0xf9&gt;
[...]
</code></pre>

<p>With <code>CONFIG_OPTIMIZE_INLINING=y</code>:</p>

<pre><code>arch/x86/entry/vdso/vclock_gettime.o.inline_opt:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;__vdso_clock_gettime&gt;:
   0:	55                   	push   %rbp
   1:	4c 8d 0d 00 00 00 00 	lea    0x0(%rip),%r9        # 8 &lt;__vdso_clock_gettime+0x8&gt;
   8:	83 ff 01             	cmp    $0x1,%edi
   b:	48 89 e5             	mov    %rsp,%rbp
   e:	74 66                	je     76 &lt;__vdso_clock_gettime+0x76&gt;
  10:	0f 8e dc 00 00 00    	jle    f2 &lt;__vdso_clock_gettime+0xf2&gt;
  16:	83 ff 05             	cmp    $0x5,%edi
  19:	74 34                	je     4f &lt;__vdso_clock_gettime+0x4f&gt;
  1b:	83 ff 06             	cmp    $0x6,%edi
  1e:	0f 85 c2 00 00 00    	jne    e6 &lt;__vdso_clock_gettime+0xe6&gt;
[...]
</code></pre>

<p>Interestingly, <code>CONFIG_OPTIMIZE_INLINING=y</code>, which is supposed to allow GCC to
inline <em>less</em>, actually resulted in it inlining <em>more</em>: <code>vread_tsc</code> is inlined in
that version, while not in the <code>CONFIG_OPTIMIZE_INLINING=n</code> version. But
<code>vread_tsc</code> isn’t marked inline at all, so GCC is perfectly within its right to
behave like this, as counterintuitive as it may be.</p>

<p>But who cares if a function is inlined? Where’s the actual problem? Well,
looking closer at the non-inline version…</p>

<pre><code>  30:	55                   	push   %rbp
  31:	48 89 e5             	mov    %rsp,%rbp
  34:	48 81 ec 20 10 00 00 	sub    $0x1020,%rsp
  3b:	48 83 0c 24 00       	orq    $0x0,(%rsp)
  40:	48 81 c4 20 10 00 00 	add    $0x1020,%rsp
</code></pre>

<p>Why is GCC allocating over 4KiB of stack? That’s not a stack allocation, that’s
a <em>stack probe</em>, or more specifically, the result of the <code>-fstack-check</code> GCC
<a href="https://gcc.gnu.org/onlinedocs/gccint/Stack-Checking.html">feature</a>.</p>

<p>Gentoo Linux enables <nobr><code>-fstack-check</code></nobr> by default on its hardened
profile. This is a mitigation for the
<a href="https://www.qualys.com/2017/06/19/stack-clash/stack-clash.txt">Stack Clash</a>
vulnerability. While <nobr><code>-fstack-check</code></nobr> is an old GCC feature and not
intended for this, it turns out it effectively mitigates the issue (I’m told
proper Stack Clash protection will be in GCC 8). As a side-effect, it causes
some fairly silly behavior, where every non-leaf function (that is, a function
that makes function calls) ends up probing the stack 4 KiB ahead of the stack
pointer. In other words, code compiled with <nobr><code>-fstack-check</code></nobr>
potentially needs at least 4 KiB of stack space, unless it is a leaf function
(or a function where every call was inlined).</p>

<p>Go loves small stacks.</p>

<pre><code>TEXT runtime·walltime(SB),NOSPLIT,$16
	// Be careful. We're calling a function with gcc calling convention here.
	// We're guaranteed 128 bytes on entry, and we've taken 16, and the
	// call uses another 8.
	// That leaves 104 for the gettime code to use. Hope that's enough!
</code></pre>

<p>Turns out 104 bytes aren’t enough for everybody. Certainly not for my kernel.</p>

<p>It’s worth pointing out that the vDSO specification makes no mention of maximum
stack usage guarantees, so this is squarely Go’s fault for making invalid
assumptions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This perfectly explains the symptoms. The stack probe is an <code>orq</code>, which is a
logical OR with 0. This is a no-op, but effectively probes the target address
(if it is unmapped, it will segfault). But we weren’t seeing segfaults in vDSO
code, so how was this breaking Go? Well, OR with 0 isn’t really a no-op. Since
<code>orq</code> is not an atomic instruction, what really happens is the CPU reads the
memory address and then writes it back. This creates a race condition. If other
threads are running in parallel on other CPUs, <code>orq</code> might effectively wind up
undoing a memory write that occurs simultaneously. Since the write was out of
the stack bounds, it was likely intruding on other threads’ stacks or random
data, and, when the stars line up, undoing a memory write. This is also why
<code>GOMAXPROCS=1</code> works around the issue, since that prevents two threads from
effectively running Go code at the same time.</p>

<p>What’s the fix? I left that up to the Go devs. Their solution ultimately was to
<a href="https://github.com/golang/go/commit/a158382b1c9c0b95a7d41865a405736be6bc585f">pivot to a larger stack</a>
before calling vDSO functions. This introduces a small speed penalty
(nanoseconds), but it’s acceptable. After building <code>node_exporter</code> with the
fixed Go toolchain, the crashes went away.</p>

    <p>2017-12-05 01:20</p>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[62 Minutes could bring your business down (103 pts)]]></title>
            <link>https://www.crowdstrike.com/en-us/#teaser-79minutes-adversary-1</link>
            <guid>41005378</guid>
            <pubDate>Fri, 19 Jul 2024 11:55:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crowdstrike.com/en-us/#teaser-79minutes-adversary-1">https://www.crowdstrike.com/en-us/#teaser-79minutes-adversary-1</a>, See on <a href="https://news.ycombinator.com/item?id=41005378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container-0306f2696d" data-cmp-is="simple-container" color-palette-background-color="#F8F8F8" data-padding-top="64" data-padding-top-tablet="64" data-padding-top-mobile="112" data-padding-bottom="120" data-padding-bottom-tablet="56" data-padding-bottom-mobile="56" data-padding-left="0" data-padding-left-tablet="0" data-padding-left-mobile="0" data-padding-right="16" data-is-transparent-header="true">
<p><span><p>CrowdStrike is continually recognized as a leader by 3rd party organizations and customers. Learn more at&nbsp;<a href="https://crowdstrike.com/leader">crowdstrike.com/leader</a>.</p>
<p>1&nbsp;Customer expectations are based on calculations made by CrowdStrike with data provided by customers or prospective customers who conduct a Business Value Realized or Business Value Assessment. Average savings are from the&nbsp;<a href="https://www.crowdstrike.com/resources/reports/total-economic-impact-of-crowdstrike-falcon-complete/">Total Economic Impact™ of CrowdStrike Falcon Complete</a>, commissioned by CrowdStrike, February 2021. Results are for a composite organization as stated in the study. Individual results may vary by customer.</p>
<p>2&nbsp;Gartner, Magic Quadrant for Endpoint Protection Platforms, Peter Firstbrook, Chris Silva, 31 December 2022.</p>
<p>Gartner is a registered trademark and service mark and Magic Quadrant is a registered trademark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and are used herein with permission. All rights reserved. This graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from CrowdStrike. Gartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner research organization and should not be construed as statements of fact. Gartner disclaims all warranties, express or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose.</p>
</span>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC votes unanimously to dramatically limit prison telecom charges (841 pts)]]></title>
            <link>https://worthrises.org/pressreleases/2024/7/18/fcc-votes-unanimously-to-significantly-lower-phone-and-video-communication-costs-after-decades-of-exploitation-by-prison-telecoms</link>
            <guid>41005181</guid>
            <pubDate>Fri, 19 Jul 2024 11:33:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worthrises.org/pressreleases/2024/7/18/fcc-votes-unanimously-to-significantly-lower-phone-and-video-communication-costs-after-decades-of-exploitation-by-prison-telecoms">https://worthrises.org/pressreleases/2024/7/18/fcc-votes-unanimously-to-significantly-lower-phone-and-video-communication-costs-after-decades-of-exploitation-by-prison-telecoms</a>, See on <a href="https://news.ycombinator.com/item?id=41005181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The new rules&nbsp;will impact the prison telecom industry deeply. Loss of revenue is expected to be in the hundreds of millions of dollars (though not equal to the savings to incarcerated people and their families as the industry's business model shifts and correctional agencies purchase security and surveillance services directly). This&nbsp;comes as the two largest market players, Aventiv and ViaPath, each navigate financial crises. Aventiv recently<a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=79823f19b8&amp;e=6c5990aeb2" target="_blank"> </a>effectively <a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=2bef16be55&amp;e=6c5990aeb2" target="_blank">defaulted on its $1.3 billion debt</a> after a year of failed refinancing efforts. ViaPath was reportedly closing in on a $1.5 billion refinancing deal until news of the <a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=2e6d95e517&amp;e=6c5990aeb2" target="_blank">regulations killed the deal</a>.&nbsp;</p><p>The FCC’s new rules also come as an increasing number of states move to make prison and jail communication free. In 2023, Massachusetts, Minnesota, and Colorado each passed legislation to make prison calls free. California made prison calls free in 2022 and Connecticut in 2021. Campaigns are currently underway in more than a dozen other states.</p><p><strong>Former FCC Acting Chairwoman of the FCC and member of the Board of Directors of the Benton Institute for Broadband &amp; Society Mignon Clyburn </strong>said,<strong>&nbsp;</strong>“Today marks a major milestone on the long road to right a market dysfunction that has wronged incarcerated persons and their loved ones for decades. &nbsp;I have nothing but praise for Chairwoman Rosenworcel and her fellow Commissioners who moved this item forward, and the hard-working FCC staff for crafting forceful rules that are faithful to the goals of the Martha Wright-Reed Just and Reasonable Communications Act.”</p><p>“Today, we cross a major milestone in the decades-long quest to prevent gauging of families when they pay to communicate with their incarcerated loved ones. With the Federal Communications Commission vote today, prices are dropping between 8 and 14 cents per minute from existing voice calling caps, and video communication will benefit from rate protections for the first time. Lower cost communication means more memories and tighter bonds, it means more opportunities to say 'I love you' and 'I miss you' at the moment they can make a huge difference in a child's life. It brings people together instead of breaking them apart under the weight of impossible financial burdens,” said <strong>Cheryl A. Leanza, policy advisor to the United Church of Christ Media Justice Ministry.</strong> “The journey to this day has been decades in the making, from Mrs. Martha Wright-Reed, who was willing to put&nbsp;her name on a lawsuit more than 20 years ago, to bi-partisan champions in Congress, hard-working agency leaders and staff, fellow advocates, and most important: the countless family members and incarcerated people who took the time to tell their stories, write postcards, contact their legislators or attend a Federal Communications Commission listening session. It all really does make a difference.”</p><p>“Today, 18 months from the passage of the Marta Wright-Reed Just and Reasonable Communications Act of 2022, the Federal Communications Commission took action to end predatory prison phone rates. After a decade of advocacy, incarcerated individuals and their loved ones will be able to communicate with each other without the barrier of burdensome fees. The absence of these predatory rates is life-changing, potentially lowering rates of depression, isolation, and loneliness incarcerated individuals experience while in prison and helping them succeed when reentering their communities,” said <strong>Koustubh “K.J.” Bagchi, Vice President of the Center for Civil Rights and Technology at The Leadership Conference on Civil and Human Rights.</strong></p><p>“Incarcerated people and their loved ones have paid an unconscionably high price for the greed of the companies who provide telecom services to prisons, jails and detention centers. Thankfully, that’s about to change,” said <strong>Heather Franklin, Internet Campaign Director at Free Press. </strong>“The ability for incarcerated people to maintain regular communication with loved ones, legal counsel and clergy is a human-rights issue. Incarcerated people should be able to connect and communicate without being subject to extortionate rates. We’re grateful for the work of FCC Chairwoman Jessica Rosenworcel, the other commissioners, agency staff, and decades of work by advocates across the country who’ve made today’s strides possible.”&nbsp;</p><p>“The FCC’s action today will help to ensure that families no longer have to pay inflated, predatory rates to speak to their incarcerated loved ones,” said <strong>Ariel Nelson, staff attorney at the National Consumer Law Center, who leads its Criminal Justice Debt &amp; Reintegration Project.</strong> “We are grateful the Commission has also put a stop to two enduring areas of consumer abuse–outrageous fees and site commissions–bringing meaningful financial relief and connection to families across the country.”</p><p>"With today’s order, the FCC affirmed what our movement has been saying for decades: The families of incarcerated people should not be shouldering the costs of their loved ones’ incarceration," said <strong>Peter Wagner, Executive Director of the Prison Policy Initiative. </strong>"Capping the costs of all phone and video calls, as the FCC has done, will bring relief to millions of families, and other provisions in its order will prevent the exploitation of consumers through fees and deceptive pricing. We are glad to see the FCC take these steps toward true consumer protection for incarcerated people."</p><p>“For years, incarcerated people unable to afford exorbitant call rates have been denied the ability to easily communicate with their loved ones, their communities, and even their attorneys. These excessive communications costs hurt incarcerated people as well as their families and communities. By requiring just and reasonable rates, the FCC is working to keep families together and to ease the return to society of incarcerated people. We commend Chairwoman Rosenworcel for her leadership in keeping incarcerated people connected and applaud the FCC for requiring reasonable rates for these vital communications,”<strong> </strong>said <strong>Al Kramer, senior fellow at Public Knowledge.&nbsp;</strong></p><p>“We applaud the leadership of Chairwoman Rosenworcel and the Federal Communications Commission for taking this important and monumental action. The FCC’s order serves as a transformative win for incarcerated peoples and their loved ones who for far too long have had to grapple with outrageous rates,” said <strong>Rebekah P. Goodheart, Jenner &amp; Block LLP, pro bono counsel to the Wright Petitioners. </strong>“Thanks to the tireless advocacy of various groups and civil rights organizations, much-needed relief will be provided.”</p><p>"It’s exciting to see that the Federal Communications Commission is taking steps to enact the Martha Wright-Reed legislation to lower the cost of prison phone calls," said&nbsp;<strong>Brandon Tucker, Senior Policy Director at Color Of Change.</strong> "This is a major step in prison justice. Phone call costs have been predatory and it has never made sense for families of incarcerated people to pay high amounts of money to stay in contact with their loved ones. The system was rooted in corporate greed and not rehabilitation. It is unacceptable that families have gone into debt accepting phone calls from jails and prison. Thank you to Chairwoman Jessica Rosenworcel and other commissioners for rectifying this misstep in our judicial system."</p></div><p><a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=132d7170b3&amp;e=6c5990aeb2" target="_blank">Worth Rises</a> is a non-profit advocacy organization dedicated to dismantling the prison industry and ending the exploitation of those it targets. Follow @WorthRises on <a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=d744a8dd14&amp;e=6c5990aeb2" target="_blank">Twitter</a>, <a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=d81a2cfc3d&amp;e=6c5990aeb2" target="_blank">Instagram</a>, and <a href="https://worthrises.us17.list-manage.com/track/click?u=d5deffca38b8d1f6cd5d6dfc9&amp;id=df14550f86&amp;e=6c5990aeb2" target="_blank">Facebook</a>.</p></div>]]></description>
        </item>
    </channel>
</rss>