<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 03 Oct 2025 22:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Offline card payments should be possible no later than 1 July 2026 (125 pts)]]></title>
            <link>https://www.riksbank.se/en-gb/press-and-published/notices-and-press-releases/press-releases/2025/offline-card-payments-should-be-possible-no-later-than-1-july-2026/</link>
            <guid>45467500</guid>
            <pubDate>Fri, 03 Oct 2025 20:36:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.riksbank.se/en-gb/press-and-published/notices-and-press-releases/press-releases/2025/offline-card-payments-should-be-possible-no-later-than-1-july-2026/">https://www.riksbank.se/en-gb/press-and-published/notices-and-press-releases/press-releases/2025/offline-card-payments-should-be-possible-no-later-than-1-july-2026/</a>, See on <a href="https://news.ycombinator.com/item?id=45467500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<article>

			    


				<p>
						<span><span></span>Press release</span>
					The Riksbank and representatives from the payment market have today reached an agreement to increase the possibility to make offline card payments for essential goods. The agreement is an important step in the work to strengthen Sweden's payment preparedness and increase resilience to disruptions in the digital payments system. The goal is for the measures to be in place no later than 1 July 2026.
				</p>



				

			<div>
				
<p>“In Sweden, we pay digitally to a large degree and the use of cash is low. The general public being able to pay by card for example for food and medicines even in the event of a serious breakdown in data communication, that is offline, is a milestone in our intensified efforts to strengthen emergency preparedness”, says Governor Erik Thedéen.</p>
<p>The agreement describes the measures that participants in Swedish card payments – card issuers, card networks, card acquirers, the retail sector and the Riksbank – will implement to increase the possibility of offline payments by card. For instance, financial agents will adapt their regulatory frameworks, and the retail trade will introduce technological solutions. The Riksbank is leading this work and is responsible for monitoring its implementation.</p>
<p>“We are very pleased that all participants involved are taking responsibility for strengthening Sweden's payment readiness. Some are covered by the Riksbank's regulations, but far from all. We regard the fact that so many are nevertheless choosing to contribute as very positive for Sweden's overall civil preparedness”, concludes Erik Thedéen.</p>
<p>The online function shall apply to physical payment cards and accompanying PIN code when purchasing essential goods such as food, medicine and fuel. The Riksbank will continue its work on enabling offline payments for other payment methods after 1 July 2026.</p>

			</div>


				

			<div>
		<p>
			Contact: <span>Press Office, tel. +46 8-7870200</span>
		</p>
	<p>
		Updated 03/10/2025
	</p>
</div>
		</article>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PEP 810 – Explicit lazy imports (206 pts)]]></title>
            <link>https://pep-previews--4622.org.readthedocs.build/pep-0810/</link>
            <guid>45466086</guid>
            <pubDate>Fri, 03 Oct 2025 18:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pep-previews--4622.org.readthedocs.build/pep-0810/">https://pep-previews--4622.org.readthedocs.build/pep-0810/</a>, See on <a href="https://news.ycombinator.com/item?id=45466086">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="pep-content">

<dl>
<dt>Author<span>:</span></dt>
<dd>Pablo Galindo &lt;pablogsal at python.org&gt;,
Germán Méndez Bravo &lt;german.mb at gmail.com&gt;,
Thomas Wouters &lt;thomas at python.org&gt;,
Dino Viehland &lt;dinoviehland at gmail.com&gt;,
Brittany Reynoso &lt;brittanyrey at gmail.com&gt;,
Noah Kim &lt;noahbkim at gmail.com&gt;,
Tim Stumbaugh &lt;me at tjstum.com&gt;</dd>
<dt>Discussions-To<span>:</span></dt>
<dd><a href="https://discuss.python.org/t/104131">Discourse thread</a></dd>
<dt>Status<span>:</span></dt>
<dd><abbr title="Proposal under active discussion and revision">Draft</abbr></dd>
<dt>Type<span>:</span></dt>
<dd><abbr title="Normative PEP with a new feature for Python, implementation change for CPython or interoperability standard for the ecosystem">Standards Track</abbr></dd>
<dt>Created<span>:</span></dt>
<dd>02-Oct-2025</dd>
<dt>Python-Version<span>:</span></dt>
<dd>3.15</dd>
<dt>Post-History<span>:</span></dt>
<dd><a href="https://discuss.python.org/t/104131" title="Discourse thread">03-Oct-2025</a></dd>
</dl>
<hr>
<section id="contents">
<details><summary>Table of Contents</summary><ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#rationale">Rationale</a><ul>
<li><a href="#other-design-decisions">Other design decisions</a></li>
</ul>
</li>
<li><a href="#specification">Specification</a><ul>
<li><a href="#grammar">Grammar</a><ul>
<li><a href="#syntax-restrictions">Syntax restrictions</a></li>
</ul>
</li>
<li><a href="#semantics">Semantics</a></li>
<li><a href="#lazy-import-mechanism">Lazy import mechanism</a></li>
<li><a href="#reification">Reification</a></li>
</ul>
</li>
<li><a href="#reference-implementation">Reference Implementation</a><ul>
<li><a href="#bytecode-and-adaptive-specialization">Bytecode and adaptive specialization</a></li>
<li><a href="#lazy-imports-filter">Lazy imports filter</a></li>
<li><a href="#global-lazy-imports-control">Global lazy imports control</a></li>
</ul>
</li>
<li><a href="#backwards-compatibility">Backwards Compatibility</a><ul>
<li><a href="#unchanged-semantics">Unchanged semantics</a></li>
<li><a href="#observable-behavioral-shifts-opt-in-only">Observable behavioral shifts (opt-in only)</a></li>
<li><a href="#thread-safety-and-reification">Thread-safety and reification</a></li>
<li><a href="#typing-and-tools">Typing and tools</a></li>
</ul>
</li>
<li><a href="#security-implications">Security Implications</a></li>
<li><a href="#how-to-teach-this">How to Teach This</a></li>
<li><a href="#faq">FAQ</a></li>
<li><a href="#alternate-implementation-ideas">Alternate Implementation Ideas</a><ul>
<li><a href="#leveraging-a-subclass-of-dict">Leveraging a subclass of dict</a></li>
<li><a href="#alternate-keyword-names">Alternate keyword names</a></li>
</ul>
</li>
<li><a href="#rejected-ideas">Rejected Ideas</a><ul>
<li><a href="#modification-of-the-dict-object">Modification of the dict object</a></li>
<li><a href="#placing-the-lazy-keyword-in-the-middle-of-from-imports">Placing the <code><span>lazy</span></code> keyword in the middle of from imports</a></li>
<li><a href="#placing-the-lazy-keyword-at-the-end-of-import-statements">Placing the <code><span>lazy</span></code> keyword at the end of import statements</a></li>
<li><a href="#returning-a-proxy-dict-from-globals">Returning a proxy dict from <code><span>globals()</span></code></a></li>
<li><a href="#reifying-lazy-imports-when-globals-is-called">Reifying lazy imports when <code><span>globals()</span></code> is called</a></li>
</ul>
</li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
<li><a href="#footnotes">Footnotes</a></li>
<li><a href="#copyright">Copyright</a></li>
</ul>
</details></section>
<section id="abstract">
<h2><a href="#abstract" role="doc-backlink">Abstract</a></h2>
<p>This PEP introduces syntax for lazy imports as an explicit language feature:</p>
<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>
<span>lazy</span> <span>from</span><span> </span><span>json</span><span> </span><span>import</span> <span>dumps</span>
</pre></div>
<p>Lazy imports defer the loading and execution of a module until the first time
the imported name is used, in contrast to ‘normal’ imports, which eagerly load
and execute a module at the point of the import statement.</p>
<p>By allowing developers to mark individual imports as lazy with explicit
syntax, Python programs can reduce startup time, memory usage, and unnecessary
work. This is particularly beneficial for command-line tools, test suites, and
applications with large dependency graphs.</p>
<p>This proposal preserves full backwards compatibility: normal import statements
remain unchanged, and lazy imports are enabled only where explicitly
requested.</p>
</section>
<section id="motivation">
<h2><a href="#motivation" role="doc-backlink">Motivation</a></h2>
<p>The dominant convention in Python code is to place all imports at the module
level, typically at the beginning of the file. This avoids repetition, makes
import dependencies clear and minimizes runtime overhead by only evaluating an
import statement once per module.</p>
<p>A major drawback with this approach is that importing the first module for an
execution of Python (the “main” module) often triggers an immediate cascade of
imports, and optimistically loads many dependencies that may never be used.
The effect is especially costly for command-line tools with multiple
subcommands, where even running the command with <code><span>--help</span></code> can load dozens of
unnecessary modules and take several seconds. This basic example demonstrates
what must be loaded just to get helpful feedback to the user on how to run the
program at all. Inefficiently, the user incurs this overhead again when they
figure out the command they want and invoke the program “for real.”</p>
<p>A somewhat common way to delay imports is to move the imports into functions
(inline imports), but this practice requires more work to implement and
maintain, and can be subverted by a single inadvertent top-level import.
Additionally, it obfuscates the full set of dependencies for a module.
Analysis of the Python standard library shows that approximately 17% of all
imports outside tests (nearly 3500 total imports across 730 files) are already
placed inside functions or methods specifically to defer their execution. This
demonstrates that developers are already manually implementing lazy imports in
performance-sensitive code, but doing so requires scattering imports
throughout the codebase and makes the full dependency graph harder to
understand at a glance.</p>
<p>The standard library provides the <a href="https://docs.python.org/3/library/importlib.html#importlib.util.LazyLoader" title="(in Python v3.13)"><code><span>LazyLoader</span></code></a> class to
solve some of these inefficiency problems. It permits imports at the module
level to work <em>mostly</em> like inline imports do. Many scientific Python
libraries have adopted a similar pattern, formalized in
<a href="https://scientific-python.org/specs/spec-0001/">SPEC 1</a>.
There’s also the third-party <a href="https://pypi.org/project/lazy_loader/">lazy_loader</a> package, yet another
implementation of lazy imports. Imports used solely for static type checking
are another source of potentially unneeded imports, and there are similarly
disparate approaches to minimizing the overhead. The various approaches used
here to defer or remove eager imports do not cover all potential use-cases for
a general lazy import mechanism. There is no clear standard, and there are
several drawbacks including runtime overhead in unexpected places, or worse
runtime introspection.</p>
<p>This proposal introduces syntax for lazy imports with a design that is local,
explicit, controlled, and granular. Each of these qualities is essential to
making the feature predictable and safe to use in practice.</p>
<p>The behavior is <strong>local</strong>: laziness applies only to the specific import marked
with the <code><span>lazy</span></code> keyword, and it does not cascade recursively into other
imports. This ensures that developers can reason about the effect of laziness
by looking only at the line of code in front of them, without worrying about
whether imported modules will themselves behave differently. A <code><span>lazy</span> <span>import</span></code>
is an isolated decision each time it is used, not a global shift in semantics.</p>
<p>The semantics are <strong>explicit</strong>. When a name is imported lazily, the binding is
created in the importing module immediately, but the target module is not
loaded until the first time the name is accessed. After this point, the
binding is indistinguishable from one created by a normal import. This clarity
reduces surprises and makes the feature accessible to developers who may not
be deeply familiar with Python’s import machinery.</p>
<p>Lazy imports are <strong>controlled</strong>, in the sense that deferred loading is only
triggered by the importing code itself. In the general case, a library will
only experience lazy imports if its own authors choose to mark them as such.
This avoids shifting responsibility onto downstream users and prevents
accidental surprises in library behavior. Since library authors typically
manage their own import subgraphs, they retain predictable control over when
and how laziness is applied.</p>
<p>The mechanism is also <strong>granular</strong>. It is introduced through explicit syntax
on individual imports, rather than a global flag or implicit setting. This
allows developers to adopt it incrementally, starting with the most
performance-sensitive areas of a codebase. As this feature is introduced to
the community, we want to make the experience of onboarding optional,
progressive, and adaptable to the needs of each project.</p>
<p>Lazy imports provide several concrete advantages:</p>
<ul>
<li>Command-line tools are often invoked directly by a user, so latency – in
particular startup latency – is quite noticeable. These programs are also
typically short-lived processes (contrasted with, e.g., a web server). With
lazy imports, only the code paths actually reached will import a module.
This can reduce startup time by 50-70% in practice, providing a significant
improvement to a common user experience and improving Python’s
competitiveness in domains where fast startup matters most.</li>
<li>Type annotations frequently require imports that are never used at runtime.
The common workaround is to wrap them in <code><span>if</span> <span>TYPE_CHECKING:</span></code> blocks
<a href="#f1" id="id1">[1]</a>. With lazy imports, annotation-only imports impose no runtime
penalty, eliminating the need for such guards and making annotated codebases
cleaner.</li>
<li>Large applications often import thousands of modules, and each module
creates function and type objects, incurring memory costs. In long-lived
processes, this noticeably raises baseline memory usage. Lazy imports defer
these costs until a module is needed, keeping unused subsystems unloaded.
Memory savings of 30-40% have been observed in real workloads.</li>
</ul>
</section>
<section id="rationale">
<h2><a href="#rationale" role="doc-backlink">Rationale</a></h2>
<p>The design of this proposal is centered on clarity, predictability, and ease
of adoption. Each decision was made to ensure that lazy imports provide
tangible benefits without introducing unnecessary complexity into the language
or its runtime.</p>
<p>It is also worth noting that while this PEP outlines one specific approach, we
list alternate implementation strategies for some of the core aspects and
semantics of the proposal. If the community expresses a strong preference for
a different technical path that still preserves the same core semantics or
there is fundamental disagreement over the specific option, we have included
the brainstorming we have already completed in preparation for this proposal
as reference.</p>
<p>The choice to introduce a new <code><span>lazy</span></code> keyword reflects the need for explicit
syntax. Import behavior is too fundamental to be left implicit or hidden
behind global flags or environment variables. By marking laziness directly at
the import site, the intent is immediately visible to both readers and tools.
This avoids surprises, reduces the cognitive burden of reasoning about
imports, and keeps lazy import semantics in line with Python’s tradition of
explicitness.</p>
<p>Another important decision is to represent lazy imports with proxy objects in
the module’s namespace, rather than by modifying dictionary lookup. Earlier
approaches experimented with embedding laziness into dictionaries, but this
blurred abstractions and risked affecting unrelated parts of the runtime. The
dictionary is a fundamental data structure in Python – literally every object
is built on top of dicts – and adding hooks to dictionaries would prevent
critical optimizations and complicate the entire runtime. The proxy approach
is simpler: it behaves like a placeholder until first use, at which point it
resolves the import and rebinds the name. From then on, the binding is
indistinguishable from a normal import. This makes the mechanism easy to
explain and keeps the rest of the interpreter unchanged.</p>
<p>Compatibility for library authors was also a key concern. Many maintainers
need a migration path that allows them to support both new and old versions of
Python at once. For this reason, the proposal includes the
<code><span>__lazy_modules__</span></code> global as a transitional mechanism. A module can
declare which imports should be treated as lazy (by listing the module names
as strings), and on Python 3.15 or later those imports will become lazy
automatically, as if they were imported with the <code><span>lazy</span></code> keyword. On earlier
versions the declaration is ignored, leaving imports eager. This gives authors
a practical bridge until they can rely on the keyword as the canonical syntax.</p>
<p>Finally, the feature is designed to be adopted incrementally. Nothing changes
unless a developer explicitly opts in, and adoption can begin with just a few
imports in performance-sensitive areas. This mirrors the experience of gradual
typing in Python: a mechanism that can be introduced progressively, without
forcing projects to commit globally from day one. Notably, the adoption can
also be done from the “outside in”, permitting CLI authors to introduce lazy
imports and speed up user-facing tools, without requiring changes to every
library the tool might use.</p>
<section id="other-design-decisions">
<h3><a href="#other-design-decisions" role="doc-backlink">Other design decisions</a></h3>
<ul>
<li>The scope of laziness is deliberately local and non-recursive. A lazy import
only affects the specific statement where it appears; it does not cascade
into other modules or submodules. This choice is crucial for predictability.
When developers read code, they can reason about import behavior line by
line, without worrying about hidden laziness deeper in the dependency graph.
The result is a feature that is powerful but still easy to understand in
context.</li>
<li>In addition, it is useful to provide a mechanism to activate or deactivate
lazy imports at a global level. While the primary design centers on explicit
syntax, there are scenarios – such as large applications, testing
environments, or frameworks – where enabling laziness consistently across
many modules provides the most benefit. A global switch makes it easy to
experiment with or enforce consistent behavior, while still working in
combination with the filtering API to respect exclusions or tool-specific
configuration. This ensures that global adoption can be practical without
reducing flexibility or control.</li>
</ul>
</section>
</section>
<section id="specification">
<h2><a href="#specification" role="doc-backlink">Specification</a></h2>
<section id="grammar">
<h3><a href="#grammar" role="doc-backlink">Grammar</a></h3>
<p>A new soft keyword <code><span>lazy</span></code> is added. A soft keyword is a context-sensitive
keyword that only has special meaning in specific grammatical contexts;
elsewhere it can be used as a regular identifier (e.g., as a variable name).
The <code><span>lazy</span></code> keyword only has special meaning when it appears before import
statements:</p>
<div><pre><span></span>import_name:
    | 'lazy'? 'import' dotted_as_names

import_from:
    | 'lazy'? 'from' ('.' | '...')* dotted_name 'import' import_from_targets
    | 'lazy'? 'from' ('.' | '...')+ 'import' import_from_targets
</pre></div>
<section id="syntax-restrictions">
<h4><a href="#syntax-restrictions" role="doc-backlink">Syntax restrictions</a></h4>
<p>The soft keyword is only allowed at the global (module) level, <strong>not</strong> inside
functions, class bodies, with <code><span>try</span></code>/<code><span>with</span></code> blocks, or <code><span>import</span> <span>*</span></code>. Import
statements that use the soft keyword are <em>potentially lazy</em>. Imports that
can’t be lazy are unaffected by the global lazy imports flag, and instead are
always eager.</p>
<p>Examples of syntax errors:</p>
<div><pre><span></span><span># SyntaxError: lazy import not allowed inside functions</span>
<span>def</span><span> </span><span>foo</span><span>():</span>
    <span>lazy</span> <span>import</span><span> </span><span>json</span>

<span># SyntaxError: lazy import not allowed inside classes</span>
<span>class</span><span> </span><span>Bar</span><span>:</span>
    <span>lazy</span> <span>import</span><span> </span><span>json</span>

<span># SyntaxError: lazy import not allowed inside try/except blocks</span>
<span>try</span><span>:</span>
    <span>lazy</span> <span>import</span><span> </span><span>json</span>
<span>except</span> <span>ImportError</span><span>:</span>
    <span>pass</span>

<span># SyntaxError: lazy import not allowed inside with blocks</span>
<span>with</span> <span>suppress</span><span>(</span><span>ImportError</span><span>):</span>
    <span>lazy</span> <span>import</span><span> </span><span>json</span>

<span># SyntaxError: lazy from ... import * is not allowed</span>
<span>lazy</span> <span>from</span><span> </span><span>json</span><span> </span><span>import</span> <span>*</span>
</pre></div>
</section>
</section>
<section id="semantics">
<h3><a href="#semantics" role="doc-backlink">Semantics</a></h3>
<p>When the <code><span>lazy</span></code> keyword is used, the import becomes <em>potentially lazy</em>.
Unless lazy imports are disabled or suppressed (see below), the module is not
loaded immediately at the import statement; instead, a lazy proxy object is
created and bound to the name. The actual module is loaded on first use of
that name.</p>
<p>Example:</p>
<div><pre><span></span><span>import</span><span> </span><span>sys</span>

<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># False - module not loaded yet</span>

<span># First use triggers loading</span>
<span>result</span> <span>=</span> <span>json</span><span>.</span><span>dumps</span><span>({</span><span>"hello"</span><span>:</span> <span>"world"</span><span>})</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># True - now loaded</span>
</pre></div>
<p>A module may contain a <code><span>__lazy_modules__</span></code> attribute, which is a
sequence of fully qualified module names (strings) to make <em>potentially lazy</em>
(as if the <code><span>lazy</span></code> keyword was used). This attribute is checked on each
<code><span>import</span></code> statement to determine whether the import should be made
<em>potentially lazy</em>. When a module is made lazy this way, from-imports using
that module are also lazy, but not necessarily imports of sub-modules.</p>
<p>The normal (non-lazy) import statement will check the global lazy imports
flag. If it is “enabled”, all imports are <em>potentially lazy</em> (except for
imports that can’t be lazy, as mentioned above.)</p>
<p>Example:</p>
<div><pre><span></span><span>__lazy_modules__</span> <span>=</span> <span>[</span><span>"json"</span><span>]</span>
<span>import</span><span> </span><span>json</span>
<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># False</span>
<span>result</span> <span>=</span> <span>json</span><span>.</span><span>dumps</span><span>({</span><span>"hello"</span><span>:</span> <span>"world"</span><span>})</span>
<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># True</span>
</pre></div>
<p>If the global lazy imports flag is set to “disabled”, no <em>potentially lazy</em>
import is ever imported lazily, and the behavior is equivalent to a regular
import statement: the import is <em>eager</em> (as if the lazy keyword was not used).</p>
<p>For a <em>potentially lazy</em> import, the lazy imports filter (if set) is called
with the name of the module doing the import, the name of the module being
imported, and (if applicable) the fromlist. If the lazy import filter returns
<code><span>True</span></code>, the <em>potentially lazy</em> import becomes a lazy import. Otherwise, the
import is <em>not</em> lazy, and the normal (eager) import continues.</p>
</section>
<section id="lazy-import-mechanism">
<h3><a href="#lazy-import-mechanism" role="doc-backlink">Lazy import mechanism</a></h3>
<p>When an import is lazy, <code><span>__lazy_import__</span></code> is called instead of
<code><span>__import__</span></code>. <code><span>__lazy_import__</span></code> has the same function signature as
<code><span>__import__</span></code>. It adds the module name to <code><span>sys.lazy_modules</span></code>, a set of
fully-qualified module names which have been lazily imported at some point
(primarily for diagnostics and introspection), and returns a “lazy module
object.”</p>
<p>The implementation of <code><span>from</span> <span>...</span> <span>import</span></code> (the <code><span>IMPORT_FROM</span></code> bytecode
implementation) checks if the module it’s fetching from is a lazy module
object, and if so, returns a lazy object for each name instead.</p>
<p>The end result of this process is that lazy imports (regardless of how they
are enabled) result in lazy objects being assigned to global variables.</p>
<p>Lazy module objects do not appear in <code><span>sys.modules</span></code>, they’re just listed in
the <code><span>sys.lazy_modules</span></code> set. Under normal operation lazy objects should only
end up stored in global variables, and the common ways to access those
variables (regular variable access, module attributes) will resolve lazy
imports (“reify”) and replace them when they’re accessed.</p>
<p>It is still possible to expose lazy objects through other means, like
debuggers. This is not considered a problem.</p>
</section>
<section id="reification">
<h3><a href="#reification" role="doc-backlink">Reification</a></h3>
<p>When a lazy object is first used, it needs to be reified. This means resolving
the import at that point in the program and replacing the lazy object with the
concrete one. Reification imports the module in the same way as it would have
been if it had been imported eagerly, barring intervening changes to the
import system (e.g. to <code><span>sys.path</span></code>, <code><span>sys.meta_path</span></code>, <code><span>sys.path_hooks</span></code> or
<code><span>__import__</span></code>).</p>
<p>Reification still calls <code><span>__import__</span></code> to resolve the import. When the module
is first reified, it’s removed from <code><span>sys.lazy_modules</span></code> (even if there are
still other unreified lazy references to it). When a package is reified and
submodules in the package were also previously lazily imported, those
submodules are <em>not</em> automatically reified but they <em>are</em> added to the reified
package’s globals (unless the package already assigned something else to the
name of the submodule).</p>
<p>If reification fails (e.g., due to an <code><span>ImportError</span></code>), the exception is
enhanced with chaining to show both where the lazy import was defined and
where it was first accessed (even though it propagates from the code that
triggered reification). This provides clear debugging information:</p>
<div><pre><span></span><span># app.py - has a typo in the import</span>
<span>lazy</span> <span>from</span><span> </span><span>json</span><span> </span><span>import</span> <span>dumsp</span>  <span># Typo: should be 'dumps'</span>

<span>print</span><span>(</span><span>"App started successfully"</span><span>)</span>
<span>print</span><span>(</span><span>"Processing data..."</span><span>)</span>

<span># Error occurs here on first use</span>
<span>result</span> <span>=</span> <span>dumsp</span><span>({</span><span>"key"</span><span>:</span> <span>"value"</span><span>})</span>
</pre></div>
<p>The traceback shows both locations:</p>
<div><pre><span></span><span>App started successfully</span>
<span>Processing data...</span>
<span>Traceback (most recent call last):</span>
  File <span>"app.py"</span>, line <span>2</span>, in <span>&lt;module&gt;</span>
<span>    </span><span>lazy</span> <span>from</span><span> </span><span>json</span><span> </span><span>import</span> <span>dumsp</span>
<span>ImportError</span>: <span>deferred import of 'json.dumsp' raised an exception during resolution</span>

<span>The above exception was the direct cause of the following exception:</span>

<span>Traceback (most recent call last):</span>
  File <span>"app.py"</span>, line <span>8</span>, in <span>&lt;module&gt;</span>
<span>    </span><span>result</span> <span>=</span> <span>dumsp</span><span>({</span><span>"key"</span><span>:</span> <span>"value"</span><span>})</span>
<span>             </span><span>^^^^^</span>
<span>ImportError</span>: <span>cannot import name 'dumsp' from 'json'. Did you mean: 'dump'?</span>
</pre></div>
<p>This exception chaining clearly shows: (1) where the lazy import was defined,
(2) that it was deferred, and (3) where the actual access happened that
triggered the error.</p>
<p>Reification does <strong>not</strong> automatically occur when a module that was previously
lazily imported is subsequently eagerly imported. Reification does <strong>not</strong>
immediately resolve all lazy objects (e.g. <code><span>lazy</span> <span>from</span></code> statements) that
referenced the module. It <strong>only</strong> resolves the lazy object being accessed.</p>
<p>Accessing a lazy object (from a global variable or a module attribute) reifies
the object. Accessing a module’s <code><span>__dict__</span></code> reifies <strong>all</strong> lazy objects in
that module. Operations that indirectly access <code><span>__dict__</span></code> (such as
<a href="https://docs.python.org/3/library/functions.html#dir" title="(in Python v3.13)"><code><span>dir()</span></code></a>) also trigger this behavior.</p>
<p>Example using <code><span>__dict__</span></code> from external code:</p>
<div><pre><span></span><span># my_module.py</span>
<span>import</span><span> </span><span>sys</span>
<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># False - still lazy</span>

<span># main.py</span>
<span>import</span><span> </span><span>sys</span>
<span>import</span><span> </span><span>my_module</span>

<span># Accessing __dict__ from external code DOES reify all lazy imports</span>
<span>d</span> <span>=</span> <span>my_module</span><span>.</span><span>__dict__</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># True - reified by __dict__ access</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>d</span><span>[</span><span>'json'</span><span>]))</span>  <span># &lt;class 'module'&gt;</span>
</pre></div>
<p>However, calling <code><span>globals()</span></code> does <strong>not</strong> trigger reification – it returns
the module’s dictionary, and accessing lazy objects through that dictionary
still returns lazy proxy objects that need to be manually reified upon use. A
lazy object can be resolved explicitly by calling the <code><span>get</span></code> method. Other,
more indirect ways of accessing arbitrary globals (e.g. inspecting
<code><span>frame.f_globals</span></code>) also do <strong>not</strong> reify all the objects.</p>
<p>Example using <code><span>globals()</span></code>:</p>
<div><pre><span></span><span>import</span><span> </span><span>sys</span>
<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span># Calling globals() does NOT trigger reification</span>
<span>g</span> <span>=</span> <span>globals</span><span>()</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># False - still lazy</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>g</span><span>[</span><span>'json'</span><span>]))</span>  <span># &lt;class 'lazy_import'&gt;</span>

<span># Explicitly reify using the get() method</span>
<span>resolved</span> <span>=</span> <span>g</span><span>[</span><span>'json'</span><span>]</span><span>.</span><span>get</span><span>()</span>

<span>print</span><span>(</span><span>type</span><span>(</span><span>resolved</span><span>))</span>  <span># &lt;class 'module'&gt;</span>
<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># True - now loaded</span>
</pre></div>
</section>
</section>
<section id="reference-implementation">
<h2><a href="#reference-implementation" role="doc-backlink">Reference Implementation</a></h2>
<p>A reference implementation is available at:
<a href="https://github.com/LazyImportsCabal/cpython/tree/lazy">https://github.com/LazyImportsCabal/cpython/tree/lazy</a></p>
<section id="bytecode-and-adaptive-specialization">
<h3><a href="#bytecode-and-adaptive-specialization" role="doc-backlink">Bytecode and adaptive specialization</a></h3>
<p>Lazy imports are implemented through modifications to four bytecode
instructions: <code><span>IMPORT_NAME</span></code>, <code><span>IMPORT_FROM</span></code>, <code><span>LOAD_GLOBAL</span></code>, and
<code><span>LOAD_NAME</span></code>.</p>
<p>The <code><span>lazy</span></code> syntax sets a flag in the <code><span>IMPORT_NAME</span></code> instruction’s oparg
(<code><span>oparg</span> <span>&amp;</span> <span>0x01</span></code>). The interpreter checks this flag and calls
<code><span>_PyEval_LazyImportName()</span></code> instead of <code><span>_PyEval_ImportName()</span></code>, creating a
lazy import object rather than executing the import immediately. The
<code><span>IMPORT_FROM</span></code> instruction checks whether its source is a lazy import
(<code><span>PyLazyImport_CheckExact()</span></code>) and creates a lazy object for the attribute
rather than accessing it immediately.</p>
<p>When a lazy object is accessed, it must be reified. The <code><span>LOAD_GLOBAL</span></code>
instruction (used in function scopes) and <code><span>LOAD_NAME</span></code> instruction (used at
module and class level) both check whether the object being loaded is a lazy
import. If so, they call <code><span>_PyImport_LoadLazyImportTstate()</span></code> to perform the
actual import and store the module in <code><span>sys.modules</span></code>.</p>
<p>This check incurs a very small cost on each access. However, Python’s adaptive
interpreter can specialize <code><span>LOAD_GLOBAL</span></code> after observing that a lazy import
has been reified. After several executions, <code><span>LOAD_GLOBAL</span></code> becomes
<code><span>LOAD_GLOBAL_MODULE</span></code>, which accesses the module dictionary directly without
checking for lazy imports.</p>
<p>Examples of the bytecode generated:</p>
<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>  <span># IMPORT_NAME with flag set</span>
</pre></div>
<p>Generates:</p>
<div><pre><span></span>IMPORT_NAME              1 (json + lazy)
</pre></div>
<div><pre><span></span><span>lazy</span> <span>from</span><span> </span><span>json</span><span> </span><span>import</span> <span>dumps</span>  <span># IMPORT_NAME + IMPORT_FROM</span>
</pre></div>
<p>Generates:</p>
<div><pre><span></span>IMPORT_NAME              1 (json + lazy)
IMPORT_FROM              1 (dumps)
</pre></div>
<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>
<span>x</span> <span>=</span> <span>json</span>  <span># Module-level access</span>
</pre></div>
<p>Generates:</p>

<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>def</span><span> </span><span>use_json</span><span>():</span>
    <span>return</span> <span>json</span><span>.</span><span>dumps</span><span>({})</span>  <span># Function scope</span>
</pre></div>
<p>Before any calls:</p>
<div><pre><span></span>LOAD_GLOBAL              0 (json)
LOAD_ATTR                2 (dumps)
</pre></div>
<p>After several calls, <code><span>LOAD_GLOBAL</span></code> specializes to <code><span>LOAD_GLOBAL_MODULE</span></code>:</p>
<div><pre><span></span>LOAD_GLOBAL_MODULE       0 (json)
LOAD_ATTR_MODULE         2 (dumps)
</pre></div>
</section>
<section id="lazy-imports-filter">
<h3><a href="#lazy-imports-filter" role="doc-backlink">Lazy imports filter</a></h3>
<p>This PEP adds two new functions to the <code><span>sys</span></code> module to manage the lazy
imports filter:</p>
<ul>
<li><code><span>sys.set_lazy_imports_filter(func)</span></code> - Sets the filter function. The
<code><span>func</span></code> parameter must have the signature: <code><span>func(importer:</span> <span>str,</span> <span>name:</span> <span>str,</span>
<span>fromlist:</span> <span>tuple[str,</span> <span>...]</span> <span>|</span> <span>None)</span> <span>-&gt;</span> <span>bool</span></code></li>
<li><code><span>sys.get_lazy_imports_filter()</span></code> - Returns the currently installed filter
function, or <code><span>None</span></code> if no filter is set.</li>
</ul>
<p>The filter function is called for every potentially lazy import, and must
return <code><span>True</span></code> if the import should be lazy. This allows for fine-grained
control over which imports should be lazy, useful for excluding modules with
known side-effect dependencies or registration patterns.</p>
<p>The filter mechanism serves as a foundation that tools, debuggers, linters,
and other ecosystem utilities can leverage to provide better lazy import
experiences. For example, static analysis tools could detect modules with side
effects and automatically configure appropriate filters. <strong>In the future</strong>
(out of scope for this PEP), this foundation may enable better ways to
declaratively specify which modules are safe for lazy importing, such as
package metadata, type stubs with lazy-safety annotations, or configuration
files. The current filter API is designed to be flexible enough to accommodate
such future enhancements without requiring changes to the core language
specification.</p>
<p>Example:</p>
<div><pre><span></span><span>import</span><span> </span><span>sys</span>

<span>def</span><span> </span><span>exclude_side_effect_modules</span><span>(</span><span>importer</span><span>,</span> <span>name</span><span>,</span> <span>fromlist</span><span>):</span>
<span>    </span><span>"""</span>
<span>    Filter function to exclude modules with import-time side effects.</span>

<span>    Args:</span>
<span>        importer: Name of the module doing the import</span>
<span>        name: Name of the module being imported</span>
<span>        fromlist: Tuple of names being imported (for 'from' imports), or None</span>

<span>    Returns:</span>
<span>        True to allow lazy import, False to force eager import</span>
<span>    """</span>
    <span># Modules known to have important import-time side effects</span>
    <span>side_effect_modules</span> <span>=</span> <span>{</span><span>'legacy_plugin_system'</span><span>,</span> <span>'metrics_collector'</span><span>}</span>

    <span>if</span> <span>name</span> <span>in</span> <span>side_effect_modules</span><span>:</span>
        <span>return</span> <span>False</span>  <span># Force eager import</span>

    <span>return</span> <span>True</span>  <span># Allow lazy import</span>

<span># Install the filter</span>
<span>sys</span><span>.</span><span>set_lazy_imports_filter</span><span>(</span><span>exclude_side_effect_modules</span><span>)</span>

<span># These imports are checked by the filter</span>
<span>lazy</span> <span>import</span><span> </span><span>data_processor</span>        <span># Filter returns True -&gt; stays lazy</span>
<span>lazy</span> <span>import</span><span> </span><span>legacy_plugin_system</span>  <span># Filter returns False -&gt; imported eagerly</span>

<span>print</span><span>(</span><span>'data_processor'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>       <span># False - still lazy</span>
<span>print</span><span>(</span><span>'legacy_plugin_system'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span> <span># True - loaded eagerly</span>

<span># First use of data_processor triggers loading</span>
<span>result</span> <span>=</span> <span>data_processor</span><span>.</span><span>transform</span><span>(</span><span>data</span><span>)</span>
<span>print</span><span>(</span><span>'data_processor'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>       <span># True - now loaded</span>
</pre></div>
</section>
<section id="global-lazy-imports-control">
<h3><a href="#global-lazy-imports-control" role="doc-backlink">Global lazy imports control</a></h3>
<p>The global lazy imports flag can be controlled through:</p>
<ul>
<li>The <code><span>-X</span> <span>lazy_imports=&lt;mode&gt;</span></code> command-line option</li>
<li>The <code><span>PYTHON_LAZY_IMPORTS=&lt;mode&gt;</span></code> environment variable</li>
<li>The <code><span>sys.set_lazy_imports(mode)</span></code> function (primarily for testing)</li>
</ul>
<p>Where <code><span>&lt;mode&gt;</span></code> can be:</p>
<ul>
<li><code><span>"default"</span></code> (or unset): Only explicitly marked lazy imports are lazy</li>
<li><code><span>"enabled"</span></code>: All module-level imports (except in <code><span>try</span></code>  or <code><span>with</span></code>
blocks and <code><span>import</span> <span>*</span></code>) become <em>potentially lazy</em></li>
<li><code><span>"disabled"</span></code>: No imports are lazy, even those explicitly marked with
<code><span>lazy</span></code> keyword</li>
</ul>
<p>When the global flag is set to <code><span>"enabled"</span></code>, all imports at the global level
of all modules are <em>potentially lazy</em> <strong>except</strong> for those inside a <code><span>try</span></code> or
<code><span>with</span></code> block or any wild card (<code><span>from</span> <span>...</span> <span>import</span> <span>*</span></code>) import.</p>
<p>If the global lazy imports flag is set to <code><span>"disabled"</span></code>, no <em>potentially
lazy</em> import is ever imported lazily, the import filter is never called, and
the behavior is equivalent to a regular <code><span>import</span></code> statement: the import is
<em>eager</em> (as if the lazy keyword was not used).</p>
</section>
</section>
<section id="backwards-compatibility">
<h2><a href="#backwards-compatibility" role="doc-backlink">Backwards Compatibility</a></h2>
<p>Lazy imports are <strong>opt-in</strong>. Existing programs continue to run unchanged
unless a project explicitly enables laziness (via <code><span>lazy</span></code> syntax,
<code><span>__lazy_modules__</span></code>, or an interpreter-wide switch).</p>
<section id="unchanged-semantics">
<h3><a href="#unchanged-semantics" role="doc-backlink">Unchanged semantics</a></h3>
<ul>
<li>Regular <code><span>import</span></code> and <code><span>from</span> <span>...</span> <span>import</span> <span>...</span></code> statements remain eager
unless explicitly made <em>potentially lazy</em> by the local or global mechanisms
provided.</li>
<li>Dynamic import APIs remain eager and unchanged: <code><span>__import__()</span></code> and
<code><span>importlib.import_module()</span></code>.</li>
<li>Import hooks and loaders continue to run under the standard import protocol
when a lazy object is reified.</li>
</ul>
</section>
<section id="observable-behavioral-shifts-opt-in-only">
<h3><a href="#observable-behavioral-shifts-opt-in-only" role="doc-backlink">Observable behavioral shifts (opt-in only)</a></h3>
<p>These changes are limited to bindings explicitly made lazy:</p>
<ul>
<li><strong>Error timing.</strong> Exceptions that would have occurred during an eager import
(for example <code><span>ImportError</span></code> or <code><span>AttributeError</span></code> for a missing member) now
occur at the first <em>use</em> of the lazy name.<div><pre><span></span><span># With eager import - error at import statement</span>
<span>import</span><span> </span><span>broken_module</span>  <span># ImportError raised here</span>

<span># With lazy import - error deferred</span>
<span>lazy</span> <span>import</span><span> </span><span>broken_module</span>
<span>print</span><span>(</span><span>"Import succeeded"</span><span>)</span>
<span>broken_module</span><span>.</span><span>foo</span><span>()</span>  <span># ImportError raised here on first use</span>
</pre></div>
</li>
<li><strong>Side-effect timing.</strong> Import-time side effects in lazily imported modules
occur at first use of the binding, not at module import time.</li>
<li><strong>Import order.</strong> Because modules are imported on first use, the order in
which modules are imported may differ from how they appear in code.</li>
<li><strong>Presence in ``sys.modules``.</strong> A lazily imported module does not appear in
<code><span>sys.modules</span></code> until first use. After reification, it must appear in
<code><span>sys.modules</span></code>. If some other code eagerly imports the same module before
first use, the lazy binding resolves to that existing (lazy) module object
when it is first used.</li>
<li><strong>Proxy visibility.</strong> Before first use, the bound name refers to a lazy
proxy. Indirect introspection that touches the value may observe a proxy
lazy object representation. After first use, the name is rebound to the real
object and becomes indistinguishable from an eager import.</li>
</ul>
</section>
<section id="thread-safety-and-reification">
<h3><a href="#thread-safety-and-reification" role="doc-backlink">Thread-safety and reification</a></h3>
<p>First use of a lazy binding follows the existing import-lock discipline.
Exactly one thread performs the import and <strong>atomically rebinds</strong> the
importing module’s global to the resolved object. Concurrent readers
thereafter observe the real object.</p>
<p>Lazy imports are thread-safe and have no special considerations for
free-threading. A module that would normally be imported in the main thread
may be imported in a different thread if that thread triggers the first access
to the lazy import. This is not a problem: the import lock ensures thread
safety regardless of which thread performs the import.</p>
<p>Subinterpreters are supported. Each subinterpreter maintains its own
<code><span>sys.lazy_modules</span></code> and import state, so lazy imports in one subinterpreter
do not affect others.</p>
</section>
<section id="typing-and-tools">
<h3><a href="#typing-and-tools" role="doc-backlink">Typing and tools</a></h3>
<p>Type checkers and static analyzers may treat <code><span>lazy</span></code> imports as ordinary
imports for name resolution. At runtime, annotation-only imports can be marked
<code><span>lazy</span></code> to avoid startup overhead. IDEs and debuggers should be prepared to
display lazy proxies before first use and the real objects thereafter.</p>
</section>
</section>
<section id="security-implications">
<h2><a href="#security-implications" role="doc-backlink">Security Implications</a></h2>
<p>There are no known security vulnerabilities introduced by lazy imports.</p>
</section>
<section id="how-to-teach-this">
<h2><a href="#how-to-teach-this" role="doc-backlink">How to Teach This</a></h2>
<p>The new <code><span>lazy</span></code> keyword will be documented as part of the language standard.</p>
<p>As this feature is opt-in, new Python users should be able to continue using
the language as they are used to. For experienced developers, we expect them
to leverage lazy imports for the variety of benefits listed above (decreased
latency, decreased memory usage, etc) on a case-by-case basis. Developers
interested in the performance of their Python binary will likely leverage
profiling to understand the import time overhead in their codebase and mark
the necessary imports as <code><span>lazy</span></code>. In addition, developers can mark imports
that will only be used for type annotations as <code><span>lazy</span></code>.</p>
<p>Below is guidance on how to best take advantage of lazy imports and how to
avoid incompatibilities:</p>
<ul>
<li>When adopting lazy imports, users should be aware that eliding an import
until it is used will result in side effects not being executed. In turn,
users should be wary of modules that rely on import time side effects.
Perhaps the most common reliance on import side effects is the registry
pattern, where population of some external registry happens implicitly
during the importing of modules, often via decorators but sometimes
implemented via metaclasses or <code><span>__init_subclass__</span></code>. Instead, registries of
objects should be constructed via explicit discovery processes (e.g. a
well-known function to call).<div><pre><span></span><span># Problematic: Plugin registers itself on import</span>
<span># my_plugin.py</span>
<span>from</span><span> </span><span>plugin_registry</span><span> </span><span>import</span> <span>register_plugin</span>

<span>@register_plugin</span><span>(</span><span>"MyPlugin"</span><span>)</span>
<span>class</span><span> </span><span>MyPlugin</span><span>:</span>
    <span>pass</span>

<span># In main code:</span>
<span>lazy</span> <span>import</span><span> </span><span>my_plugin</span>
<span># Plugin NOT registered yet - module not loaded!</span>

<span># Better: Explicit discovery</span>
<span># plugin_registry.py</span>
<span>def</span><span> </span><span>discover_plugins</span><span>():</span>
    <span>from</span><span> </span><span>my_plugin</span><span> </span><span>import</span> <span>MyPlugin</span>
    <span>register_plugin</span><span>(</span><span>MyPlugin</span><span>)</span>

<span># In main code:</span>
<span>plugin_registry</span><span>.</span><span>discover_plugins</span><span>()</span>  <span># Explicit loading</span>
</pre></div>
</li>
<li>Always import needed submodules explicitly. It is not enough to rely on a
different import to ensure a module has its submodules as attributes.
Plainly, unless there is an explicit <code><span>from</span> <span>.</span> <span>import</span> <span>bar</span></code> in
<code><span>foo/__init__.py</span></code>, always use <code><span>import</span> <span>foo.bar;</span> <span>foo.bar.Baz</span></code>, not
<code><span>import</span> <span>foo;</span> <span>foo.bar.Baz</span></code>. The latter only works (unreliably) because the
attribute <code><span>foo.bar</span></code> is added as a side effect of <code><span>foo.bar</span></code> being
imported somewhere else.</li>
<li>Users who are moving imports into functions to improve startup time, should
instead consider keeping them where they are but adding the <code><span>lazy</span></code>
keyword. This allows them to keep dependencies clear and avoid the overhead
of repeatedly re-resolving the import but will still speed up the program.<div><pre><span></span><span># Before: Inline import (repeated overhead)</span>
<span>def</span><span> </span><span>process_data</span><span>(</span><span>data</span><span>):</span>
    <span>import</span><span> </span><span>json</span>  <span># Re-resolved on every call</span>
    <span>return</span> <span>json</span><span>.</span><span>dumps</span><span>(</span><span>data</span><span>)</span>

<span># After: Lazy import at module level</span>
<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>def</span><span> </span><span>process_data</span><span>(</span><span>data</span><span>):</span>
    <span>return</span> <span>json</span><span>.</span><span>dumps</span><span>(</span><span>data</span><span>)</span>  <span># Loaded once on first call</span>
</pre></div>
</li>
<li>Avoid using wild card (star) imports, as those are always eager.</li>
</ul>
</section>
<section id="faq">
<h2><a href="#faq" role="doc-backlink">FAQ</a></h2>
<p><strong>Q: How does this differ from the rejected PEP 690?</strong></p>
<p>A: PEP 810 takes an explicit, opt-in approach instead of <a href="https://pep-previews--4622.org.readthedocs.build/pep-0690/" title="PEP 690 – Lazy Imports">PEP 690</a>’s implicit
global approach. The key differences are:</p>
<ul>
<li><strong>Explicit syntax</strong>: <code><span>lazy</span> <span>import</span> <span>foo</span></code> clearly marks which imports are
lazy.</li>
<li><strong>Local scope</strong>: Laziness only affects the specific import statement, not
cascading to dependencies.</li>
<li><strong>Simpler implementation</strong>: Uses proxy objects instead of modifying core
dictionary behavior.</li>
</ul>
<p><strong>Q: What happens when lazy imports encounter errors?</strong></p>
<p>A: Import errors (<code><span>ImportError</span></code>, <code><span>ModuleNotFoundError</span></code>, syntax errors) are
deferred until first use of the lazy name. This is similar to moving an import
into a function. The error will occur with a clear traceback pointing to the
first access of the lazy object.</p>
<p>The implementation provides enhanced error reporting through exception
chaining. When a lazy import fails during reification, the original exception
is preserved and chained, showing both where the import was defined and where
it was first used:</p>
<div><pre><span></span><span>Traceback (most recent call last):</span>
  File <span>"test.py"</span>, line <span>1</span>, in <span>&lt;module&gt;</span>
<span>    </span><span>lazy</span> <span>import</span><span> </span><span>broken_module</span>
<span>ImportError</span>: <span>deferred import of 'broken_module' raised an exception during resolution</span>

<span>The above exception was the direct cause of the following exception:</span>

<span>Traceback (most recent call last):</span>
  File <span>"test.py"</span>, line <span>3</span>, in <span>&lt;module&gt;</span>
<span>    </span><span>broken_module</span><span>.</span><span>foo</span><span>()</span>
<span>    </span><span>^^^^^^^^^^^^^</span>
  File <span>"broken_module.py"</span>, line <span>2</span>, in <span>&lt;module&gt;</span>
<span>    </span><span>1</span><span>/</span><span>0</span>
<span>ZeroDivisionError</span>: <span>division by zero</span>
</pre></div>
<p><strong>Q: How do lazy imports affect modules with import-time side effects?</strong></p>
<p>A: Side effects are deferred until first use. This is generally desirable for
performance, but may require code changes for modules that rely on import-time
registration patterns. We recommend:</p>
<ul>
<li>Use explicit initialization functions instead of import-time side effects</li>
<li>Call initialization functions explicitly when needed</li>
<li>Avoid relying on import order for side effects</li>
</ul>
<p><strong>Q: Can I use lazy imports with</strong> <code><span>from</span> <span>...</span> <span>import</span> <span>...</span></code> <strong>statements?</strong></p>
<p>A: Yes, as long as you don’t use <code><span>from</span> <span>...</span> <span>import</span> <span>*</span></code>. Both <code><span>lazy</span> <span>import</span>
<span>foo</span></code> and <code><span>lazy</span> <span>from</span> <span>foo</span> <span>import</span> <span>bar</span></code> are supported. The <code><span>bar</span></code> name will be
bound to a lazy object that resolves to <code><span>foo.bar</span></code> on first use.</p>
<p><strong>Q: Does</strong> <code><span>lazy</span> <span>from</span> <span>module</span> <span>import</span> <span>Class</span></code> <strong>load the entire module or just
the class?</strong></p>
<p>A: It loads the <strong>entire module</strong>, not just the class. This is because
Python’s import system always executes the complete module file – there’s no
mechanism to execute only part of a <code><span>.py</span></code> file. When you first access
<code><span>Class</span></code>, Python:</p>
<ol>
<li>Loads and executes the entire <code><span>module.py</span></code> file</li>
<li>Extracts the <code><span>Class</span></code> attribute from the resulting module object</li>
<li>Binds <code><span>Class</span></code> to the name in your namespace</li>
</ol>
<p>This is identical to eager <code><span>from</span> <span>module</span> <span>import</span> <span>Class</span></code> behavior. The only
difference with lazy imports is that steps 1-3 happen on first use instead of
at the import statement.</p>
<div><pre><span></span><span># heavy_module.py</span>
<span>print</span><span>(</span><span>"Loading heavy_module"</span><span>)</span>  <span># This ALWAYS runs when module loads</span>

<span>class</span><span> </span><span>MyClass</span><span>:</span>
    <span>pass</span>

<span>class</span><span> </span><span>UnusedClass</span><span>:</span>
    <span>pass</span>  <span># Also gets defined, even though we don't import it</span>

<span># app.py</span>
<span>lazy</span> <span>from</span><span> </span><span>heavy_module</span><span> </span><span>import</span> <span>MyClass</span>

<span>print</span><span>(</span><span>"Import statement done"</span><span>)</span>  <span># heavy_module not loaded yet</span>
<span>obj</span> <span>=</span> <span>MyClass</span><span>()</span>                  <span># NOW "Loading heavy_module" prints</span>
                                 <span># (and UnusedClass gets defined too)</span>
</pre></div>
<p><strong>Key point</strong>: Lazy imports defer <em>when</em> a module loads, not <em>what</em> gets
loaded. You cannot selectively load only parts of a module – Python’s import
system doesn’t support partial module execution.</p>
<p><strong>Q: What about type annotations and</strong> <code><span>TYPE_CHECKING</span></code> <strong>imports?</strong></p>
<p>A: Lazy imports eliminate the common need for <code><span>TYPE_CHECKING</span></code> guards. You
can write:</p>
<div><pre><span></span><span>lazy</span> <span>from</span><span> </span><span>collections.abc</span><span> </span><span>import</span> <span>Sequence</span><span>,</span> <span>Mapping</span>  <span># No runtime cost</span>

<span>def</span><span> </span><span>process</span><span>(</span><span>items</span><span>:</span> <span>Sequence</span><span>[</span><span>str</span><span>])</span> <span>-&gt;</span> <span>Mapping</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]:</span>
    <span>...</span>
</pre></div>
<p>Instead of:</p>
<div><pre><span></span><span>from</span><span> </span><span>typing</span><span> </span><span>import</span> <span>TYPE_CHECKING</span>
<span>if</span> <span>TYPE_CHECKING</span><span>:</span>
    <span>from</span><span> </span><span>collections.abc</span><span> </span><span>import</span> <span>Sequence</span><span>,</span> <span>Mapping</span>

<span>def</span><span> </span><span>process</span><span>(</span><span>items</span><span>:</span> <span>Sequence</span><span>[</span><span>str</span><span>])</span> <span>-&gt;</span> <span>Mapping</span><span>[</span><span>str</span><span>,</span> <span>int</span><span>]:</span>
    <span>...</span>
</pre></div>
<p><strong>Q: What’s the performance overhead of lazy imports?</strong></p>
<p>A: The overhead is minimal:</p>
<ul>
<li>Zero overhead after first use thanks to the adaptive interpreter optimizing
the slow path away.</li>
<li>Small one-time cost to create the proxy object.</li>
<li>Reification (first use) has the same cost as a regular import.</li>
<li>No ongoing performance penalty unlike <code><span>importlib.util.LazyLoader</span></code>.</li>
</ul>
<p>Benchmarking with the <a href="https://github.com/facebookexperimental/free-threading-benchmarking/blob/main/results/bm-20250922-3.15.0a0-27836e5/bm-20250922-vultr-x86_64-DinoV-lazy_imports-3.15.0a0-27836e5-vs-base.svg">pyperformance suite</a> shows the implementation is
performance neutral when lazy imports are not used.</p>
<p><strong>Q: Can I mix lazy and eager imports of the same module?</strong></p>
<p>A: Yes. If module <code><span>foo</span></code> is imported both lazily and eagerly in the same
program, the eager import takes precedence and both bindings resolve to the
same module object.</p>
<p><strong>Q: How do I migrate existing code to use lazy imports?</strong></p>
<p>A: Migration is incremental:</p>
<ol>
<li>Identify slow-loading modules using profiling tools.</li>
<li>Add <code><span>lazy</span></code> keyword to imports that aren’t needed immediately.</li>
<li>Test that side-effect timing changes don’t break functionality.</li>
<li>Use <code><span>__lazy_modules__</span></code> for compatibility with older Python versions.</li>
</ol>
<p><strong>Q: What about star imports</strong> (<code><span>from</span> <span>module</span> <span>import</span> <span>*</span></code>)?</p>
<p>A: Wild card (star) imports cannot be lazy - they remain eager. This is
because the set of names being imported cannot be determined without loading
the module. Using the <code><span>lazy</span></code> keyword with star imports will be a syntax
error. If lazy imports are globally enabled, star imports will still be eager.</p>
<p><strong>Q: How do lazy imports interact with import hooks and custom loaders?</strong></p>
<p>A: Import hooks and loaders work normally. When a lazy object is first used,
the standard import protocol runs, including any custom hooks or loaders that
were in place at reification time.</p>
<p><strong>Q: What happens in multi-threaded environments?</strong></p>
<p>A: Lazy import reification is thread-safe. Only one thread will perform the
actual import, and the binding is atomically updated. Other threads will see
either the lazy proxy or the final resolved object.</p>
<p><strong>Q: Can I force reification of a lazy import without using it?</strong></p>
<p>A: Yes, accessing a module’s <code><span>__dict__</span></code> will reify all lazy objects in that
module. Individual lazy objects can be resolved by calling their <code><span>get()</span></code>
method.</p>
<p><strong>Q: What’s the difference between</strong> <code><span>globals()</span></code> <strong>and</strong> <code><span>mod.__dict__</span></code> <strong>for lazy imports?</strong></p>
<p>A: Calling <code><span>globals()</span></code> returns the module’s dictionary without reifying lazy
imports – you’ll see lazy proxy objects when accessing them through the
returned dictionary. However, accessing <code><span>mod.__dict__</span></code> from external code
reifies all lazy imports in that module first. This design ensures:</p>
<div><pre><span></span><span># In your module:</span>
<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>g</span> <span>=</span> <span>globals</span><span>()</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>g</span><span>[</span><span>'json'</span><span>]))</span>  <span># &lt;class 'lazy_import'&gt; - your problem</span>

<span># From external code:</span>
<span>import</span><span> </span><span>sys</span>
<span>mod</span> <span>=</span> <span>sys</span><span>.</span><span>modules</span><span>[</span><span>'your_module'</span><span>]</span>
<span>d</span> <span>=</span> <span>mod</span><span>.</span><span>__dict__</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>d</span><span>[</span><span>'json'</span><span>]))</span>  <span># &lt;class 'module'&gt; - reified for external access</span>
</pre></div>
<p>This distinction means adding lazy imports and calling <code><span>globals()</span></code> is your
responsibility to manage, while external code accessing <code><span>mod.__dict__</span></code>
always sees fully loaded modules.</p>
<p><strong>Q: Why not use</strong> <code><span>importlib.util.LazyLoader</span></code> <strong>instead?</strong></p>
<p>A: <code><span>LazyLoader</span></code> has significant limitations:</p>
<ul>
<li>Requires verbose setup code for each lazy import.</li>
<li>Has ongoing performance overhead on every attribute access.</li>
<li>Doesn’t work well with <code><span>from</span> <span>...</span> <span>import</span></code> statements.</li>
<li>Less clear and standard than dedicated syntax.</li>
</ul>
<p><strong>Q: Will this break tools like</strong> <code><span>isort</span></code> <strong>or</strong> <code><span>black</span></code>?</p>
<p>A: Tools will need updates to recognize the <code><span>lazy</span></code> keyword, but the changes
should be minimal since the import structure remains the same. The keyword
appears at the beginning, making it easy to parse.</p>
<p><strong>Q: How do I know if a library is compatible with lazy imports?</strong></p>
<p>A: Most libraries should work fine with lazy imports. Libraries that might
have issues:</p>
<ul>
<li>Those with essential import-time side effects (registration,
monkey-patching).</li>
<li>Those that expect specific import ordering.</li>
<li>Those that modify global state during import.</li>
</ul>
<p>When in doubt, test lazy imports with your specific use cases.</p>
<p><strong>Q: What happens if I globally enable lazy imports mode and a library doesn’t
work correctly?</strong></p>
<p>A: <em>Note: This is an advanced feature.</em> You can use the lazy imports filter to
exclude specific modules that are known to have problematic side effects:</p>
<div><pre><span></span><span>import</span><span> </span><span>sys</span>

<span>def</span><span> </span><span>my_filter</span><span>(</span><span>importer</span><span>,</span> <span>name</span><span>,</span> <span>fromlist</span><span>):</span>
    <span># Don't lazily import modules known to have side effects</span>
    <span>if</span> <span>name</span> <span>in</span> <span>{</span><span>'problematic_module'</span><span>,</span> <span>'another_module'</span><span>}:</span>
        <span>return</span> <span>False</span>  <span># Import eagerly</span>
    <span>return</span> <span>True</span>  <span># Allow lazy import</span>

<span>sys</span><span>.</span><span>set_lazy_imports_filter</span><span>(</span><span>my_filter</span><span>)</span>
</pre></div>
<p>The filter function receives the importer module name, the module being
imported, and the fromlist (if using <code><span>from</span> <span>...</span> <span>import</span></code>). Returning <code><span>False</span></code>
forces an eager import.</p>
<p>Alternatively, set the global mode to <code><span>"disabled"</span></code> via <code><span>-X</span>
<span>lazy_imports=disabled</span></code> to turn off all lazy imports for debugging.</p>
<p><strong>Q: Can I use lazy imports inside functions?</strong></p>
<p>A: No, the <code><span>lazy</span></code> keyword is only allowed at module level. For
function-level lazy loading, use traditional inline imports or move the import
to module level with <code><span>lazy</span></code>.</p>
<p><strong>Q: What about forwards compatibility with older Python versions?</strong></p>
<p>A: Use the <code><span>__lazy_modules__</span></code> global for compatibility:</p>
<div><pre><span></span><span># Works on Python 3.15+ as lazy, eager on older versions</span>
<span>__lazy_modules__</span> <span>=</span> <span>[</span><span>'expensive_module'</span><span>,</span> <span>'expensive_module_2'</span><span>]</span>
<span>import</span><span> </span><span>expensive_module</span>
<span>from</span><span> </span><span>expensive_module_2</span><span> </span><span>import</span> <span>MyClass</span>
</pre></div>
<p>The <code><span>__lazy_modules__</span></code> attribute is a list of module name strings. When
an import statement is executed, Python checks if the module name being
imported appears in <code><span>__lazy_modules__</span></code>. If it does, the import is
treated as if it had the <code><span>lazy</span></code> keyword (becoming <em>potentially lazy</em>). On
Python versions before 3.15 that don’t support lazy imports, the
<code><span>__lazy_modules__</span></code> attribute is simply ignored and imports proceed
eagerly as normal.</p>
<p>This provides a migration path until you can rely on the <code><span>lazy</span></code> keyword. For
maximum predictability, it’s recommended to define <code><span>__lazy_modules__</span></code>
once, before any imports. But as it is checked on each import, it can be
modified between <code><span>import</span></code> statements.</p>
<p><strong>Q: How do explicit lazy imports interact with PEP-649/PEP-749</strong></p>
<p>A: If an annotation is not stringified, it is an expression that is evaluated
at a later time. It will only be resolved if the annotation is accessed. In
the example below, the <code><span>fake_typing</span></code> module is only loaded when the user
inspects the <code><span>__annotations__</span></code> dictionary. The <code><span>fake_typing</span></code> module would
also be loaded if the user uses <code><span>annotationlib.get_annotations()</span></code> or
<code><span>getattr</span></code> to access the annotations.</p>
<div><pre><span></span><span>lazy</span> <span>from</span><span> </span><span>fake_typing</span><span> </span><span>import</span> <span>MyFakeType</span>
<span>def</span><span> </span><span>foo</span><span>(</span><span>x</span><span>:</span> <span>MyFakeType</span><span>):</span>
  <span>pass</span>
<span>print</span><span>(</span><span>foo</span><span>.</span><span>__annotations__</span><span>)</span>  <span># Triggers loading the fake_typing module</span>
</pre></div>
<p><strong>Q: How do lazy imports interact with</strong> <code><span>dir()</span></code>, <code><span>getattr()</span></code>, <strong>and
module introspection?</strong></p>
<p>A: Accessing lazy imports through normal attribute access or <code><span>getattr()</span></code>
will trigger reification. Calling <code><span>dir()</span></code> on a module will reify all lazy
imports in that module to ensure the directory listing is complete. This is
similar to accessing <code><span>mod.__dict__</span></code>.</p>
<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>

<span># Before any access</span>
<span># json not in sys.modules</span>

<span># Any of these trigger reification:</span>
<span>dumps_func</span> <span>=</span> <span>json</span><span>.</span><span>dumps</span>
<span>dumps_func</span> <span>=</span> <span>getattr</span><span>(</span><span>json</span><span>,</span> <span>'dumps'</span><span>)</span>
<span>dir</span><span>(</span><span>json</span><span>)</span>
<span># Now json is in sys.modules</span>
</pre></div>
<p><strong>Q: Do lazy imports work with circular imports?</strong></p>
<p>A: Lazy imports don’t automatically solve circular import problems. If two
modules have a circular dependency, making the imports lazy might help <strong>only
if</strong> the circular reference isn’t accessed during module initialization.
However, if either module accesses the other during import time, you’ll still
get an error.</p>
<p><strong>Example that works</strong> (deferred access in functions):</p>
<div><pre><span></span><span># user_model.py</span>
<span>lazy</span> <span>import</span><span> </span><span>post_model</span>

<span>class</span><span> </span><span>User</span><span>:</span>
    <span>def</span><span> </span><span>get_posts</span><span>(</span><span>self</span><span>):</span>
        <span># OK - post_model accessed inside function, not during import</span>
        <span>return</span> <span>post_model</span><span>.</span><span>Post</span><span>.</span><span>get_by_user</span><span>(</span><span>self</span><span>.</span><span>name</span><span>)</span>

<span># post_model.py</span>
<span>lazy</span> <span>import</span><span> </span><span>user_model</span>

<span>class</span><span> </span><span>Post</span><span>:</span>
    <span>@staticmethod</span>
    <span>def</span><span> </span><span>get_by_user</span><span>(</span><span>username</span><span>):</span>
        <span>return</span> <span>f</span><span>"Posts by </span><span>{</span><span>username</span><span>}</span><span>"</span>
</pre></div>
<p>This works because neither module accesses the other at module level – the
access happens later when <code><span>get_posts()</span></code> is called.</p>
<p><strong>Example that fails</strong> (access during import):</p>
<div><pre><span></span><span># module_a.py</span>
<span>lazy</span> <span>import</span><span> </span><span>module_b</span>

<span>result</span> <span>=</span> <span>module_b</span><span>.</span><span>get_value</span><span>()</span>  <span># Error! Accessing during import</span>

<span>def</span><span> </span><span>func</span><span>():</span>
    <span>return</span> <span>"A"</span>

<span># module_b.py</span>
<span>lazy</span> <span>import</span><span> </span><span>module_a</span>

<span>result</span> <span>=</span> <span>module_a</span><span>.</span><span>func</span><span>()</span>  <span># Circular dependency error here</span>

<span>def</span><span> </span><span>get_value</span><span>():</span>
    <span>return</span> <span>"B"</span>
</pre></div>
<p>This fails because <code><span>module_a</span></code> tries to access <code><span>module_b</span></code> at import time,
which then tries to access <code><span>module_a</span></code> before it’s fully initialized.</p>
<p>The best practice is still to avoid circular imports in your code design.</p>
<p><strong>Q: Will lazy imports affect the performance of my hot paths?</strong></p>
<p>A: After first use, lazy imports have <strong>zero overhead</strong> thanks to the adaptive
interpreter. The interpreter specializes the bytecode (e.g., <code><span>LOAD_GLOBAL</span></code>
becomes <code><span>LOAD_GLOBAL_MODULE</span></code>) which eliminates the lazy check on subsequent
accesses. This means once a lazy import is reified, accessing it is just as
fast as a normal import.</p>
<div><pre><span></span><span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>def</span><span> </span><span>use_json</span><span>():</span>
    <span>return</span> <span>json</span><span>.</span><span>dumps</span><span>({</span><span>"test"</span><span>:</span> <span>1</span><span>})</span>

<span># First call triggers reification</span>
<span>use_json</span><span>()</span>

<span># After 2-3 calls, bytecode is specialized</span>
<span>use_json</span><span>()</span>
<span>use_json</span><span>()</span>
</pre></div>
<p>You can observe the specialization using <code><span>dis.dis(use_json,</span> <span>adaptive=True)</span></code>:</p>
<div><pre><span></span>=== Before specialization ===
LOAD_GLOBAL              0 (json)
LOAD_ATTR                2 (dumps)

=== After 3 calls (specialized) ===
LOAD_GLOBAL_MODULE       0 (json)
LOAD_ATTR_MODULE         2 (dumps)
</pre></div>
<p>The specialized <code><span>LOAD_GLOBAL_MODULE</span></code> and <code><span>LOAD_ATTR_MODULE</span></code> instructions
are optimized fast paths with no overhead for checking lazy imports.</p>
<p><strong>Q: What about</strong> <code><span>sys.modules</span></code>? <strong>When does a lazy import appear there?</strong></p>
<p>A: A lazily imported module does <strong>not</strong> appear in <code><span>sys.modules</span></code> until it’s
reified (first used). Once reified, it appears in <code><span>sys.modules</span></code> just like
any eager import.</p>
<div><pre><span></span><span>import</span><span> </span><span>sys</span>
<span>lazy</span> <span>import</span><span> </span><span>json</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># False</span>

<span>result</span> <span>=</span> <span>json</span><span>.</span><span>dumps</span><span>({</span><span>"key"</span><span>:</span> <span>"value"</span><span>})</span>  <span># First use</span>

<span>print</span><span>(</span><span>'json'</span> <span>in</span> <span>sys</span><span>.</span><span>modules</span><span>)</span>  <span># True</span>
</pre></div>
<p><strong>Q: Why you chose ``lazy`` as the kwyword name?</strong></p>
<p>A: Not “why”… memorize! :)</p>
</section>
<section id="alternate-implementation-ideas">
<h2><a href="#alternate-implementation-ideas" role="doc-backlink">Alternate Implementation Ideas</a></h2>
<p>Here are some alternative design decisions that were considered during the
development of this PEP. While the current proposal represents what we believe
to be the best balance of simplicity, performance, and maintainability, these
alternatives offer different trade-offs that may be valuable for implementers
to consider or for future refinements.</p>
<section id="leveraging-a-subclass-of-dict">
<h3><a href="#leveraging-a-subclass-of-dict" role="doc-backlink">Leveraging a subclass of dict</a></h3>
<p>Instead of updating the internal dict object to directly add the fields needed
to support lazy imports, we could create a subclass of the dict object to be
used specifically for Lazy Import enablement. This would still be a leaky
abstraction though - methods can be called directly such as
<code><span>dict.__getitem__</span></code> and it would impact the performance of globals lookup in
the interpreter.</p>
</section>
<section id="alternate-keyword-names">
<h3><a href="#alternate-keyword-names" role="doc-backlink">Alternate keyword names</a></h3>
<p>For this PEP, we decided to propose <code><span>lazy</span></code> for the explicit keyword as it
felt the most familar to those already focused on optimizing import overhead.
We also considered a variety of other options to support explicit lazy
imports. The most compelling alternates were <code><span>defer</span></code> and <code><span>delay</span></code>.</p>
</section>
</section>
<section id="rejected-ideas">
<h2><a href="#rejected-ideas" role="doc-backlink">Rejected Ideas</a></h2>
<section id="modification-of-the-dict-object">
<h3><a href="#modification-of-the-dict-object" role="doc-backlink">Modification of the dict object</a></h3>
<p>The initial PEP for lazy imports (PEP 690) relied heavily on the modification
of the internal dict object to support lazy imports. We recognize that this
data structure is highly tuned, heavily used across the codebase, and very
performance sensitive. Because of the importance of this data structure and
the desire to keep the implementation of lazy imports encapsulated from users
who may have no interest in the feature, we’ve decided to invest in an
alternate approach.</p>
<p>The dictionary is the foundational data structure in Python. Every object’s
attributes are stored in a dict, and dicts are used throughout the runtime for
namespaces, keyword arguments, and more. Adding any kind of hook or special
behavior to dicts to support lazy imports would:</p>
<ol>
<li>Prevent critical interpreter optimizations including future JIT
compilation.</li>
<li>Add complexity to a data structure that must remain simple and fast.</li>
<li>Affect every part of Python, not just import behavior.</li>
<li>Violate separation of concerns – the hash table shouldn’t know about the
import system.</li>
</ol>
<p>Past decisions that violated this principle of keeping core abstractions clean
have caused significant pain in the CPython ecosystem, making optimization
difficult and introducing subtle bugs.</p>
</section>
<section id="placing-the-lazy-keyword-in-the-middle-of-from-imports">
<h3><a href="#placing-the-lazy-keyword-in-the-middle-of-from-imports" role="doc-backlink">Placing the <code><span>lazy</span></code> keyword in the middle of from imports</a></h3>
<p>While we found <code><span>from</span> <span>foo</span> <span>lazy</span> <span>import</span> <span>bar</span></code> to be a really intuitive placement
for the new explicit syntax, we quickly learned that placing the <code><span>lazy</span></code>
keyword here is already syntactically allowed in Python. This is because
<code><span>from</span> <span>.</span> <span>lazy</span> <span>import</span> <span>bar</span></code> is legal syntax (because whitespace does not
matter.)</p>
</section>
<section id="placing-the-lazy-keyword-at-the-end-of-import-statements">
<h3><a href="#placing-the-lazy-keyword-at-the-end-of-import-statements" role="doc-backlink">Placing the <code><span>lazy</span></code> keyword at the end of import statements</a></h3>
<p>We discussed appending lazy to the end of import statements like such <code><span>import</span>
<span>foo</span> <span>lazy</span></code> or <code><span>from</span> <span>foo</span> <span>import</span> <span>bar,</span> <span>baz</span> <span>lazy</span></code> but ultimately decided that
this approach provided less clarity. For example, if multiple modules are
imported in a single statement, it is unclear if the lazy binding applies to
all of the imported objects or just a subset of the items.</p>
</section>
<section id="returning-a-proxy-dict-from-globals">
<h3><a href="#returning-a-proxy-dict-from-globals" role="doc-backlink">Returning a proxy dict from <code><span>globals()</span></code></a></h3>
<p>An alternative to reifying on <code><span>globals()</span></code> or exposing lazy objects would be
to return a proxy dictionary that automatically reifies lazy objects when
they’re accessed through the proxy. This would seemingly give the best of both
worlds: <code><span>globals()</span></code> returns immediately without reification cost, but
accessing items through the result would automatically resolve lazy imports.</p>
<p>However, this approach is fundamentally incompatible with how <code><span>globals()</span></code> is
used in practice. Many standard library functions and built-ins expect
<code><span>globals()</span></code> to return a real <code><span>dict</span></code> object, not a proxy:</p>
<ul>
<li><code><span>exec(code,</span> <span>globals())</span></code> requires a real dict.</li>
<li><code><span>eval(expr,</span> <span>globals())</span></code> requires a real dict.</li>
<li>Functions that check <code><span>type(globals())</span> <span>is</span> <span>dict</span></code> would break.</li>
<li>Dictionary methods like <code><span>.update()</span></code> would need special handling.</li>
<li>Performance would suffer from the indirection on every access.</li>
</ul>
<p>The proxy would need to be so transparent that it would be indistinguishable
from a real dict in almost all cases, which is extremely difficult to achieve
correctly. Any deviation from true dict behavior would be a source of subtle
bugs.</p>
</section>
<section id="reifying-lazy-imports-when-globals-is-called">
<h3><a href="#reifying-lazy-imports-when-globals-is-called" role="doc-backlink">Reifying lazy imports when <code><span>globals()</span></code> is called</a></h3>
<p>Calling <code><span>globals()</span></code> returns the module’s namespace dictionary without
triggering reification of lazy imports. Accessing lazy objects through the
returned dictionary yields the lazy proxy objects themselves. This is an
intentional design decision for several reasons:</p>
<p><strong>The key distinction</strong>: Adding a lazy import and calling <code><span>globals()</span></code> is the
module author’s concern and under their control. However, accessing
<code><span>mod.__dict__</span></code> from external code is a different scenario – it crosses
module boundaries and affects someone else’s code. Therefore, <code><span>mod.__dict__</span></code>
access reifies all lazy imports to ensure external code sees fully realized
modules, while <code><span>globals()</span></code> preserves lazy objects for the module’s own
introspection needs.</p>
<p><strong>Technical challenges</strong>: It is impossible to safely reify on-demand when
<code><span>globals()</span></code> is called because we cannot return a proxy dictionary – this
would break common usages like passing the result to <code><span>exec()</span></code> or other
built-ins that expect a real dictionary. The only alternative would be to
eagerly reify all lazy imports whenever <code><span>globals()</span></code> is called, but this
behavior would be surprising and potentially expensive.</p>
<p><strong>Performance concerns</strong>: It is impractical to cache whether a reification
scan has been performed with just the globals dictionary reference, whereas
module attribute access (the primary use case) can efficiently cache
reification state in the module object itself.</p>
<p><strong>Use case rationale</strong>: The chosen design makes sense precisely because of
this distinction: adding a lazy import and calling <code><span>globals()</span></code> is your
problem to manage, while having lazy imports visible in <code><span>mod.__dict__</span></code>
becomes someone else’s problem. By reifying on <code><span>__dict__</span></code> access but not on
<code><span>globals()</span></code>, we ensure external code always sees fully loaded modules while
giving module authors control over their own introspection.</p>
<p>Note that three options were considered:</p>
<ol>
<li>Calling <code><span>globals()</span></code> or <code><span>mod.__dict__</span></code> traverses and resolves all lazy
objects before returning.</li>
<li>Calling <code><span>globals()</span></code> or <code><span>mod.__dict__</span></code> returns the dictionary with lazy
objects present.</li>
<li>Calling <code><span>globals()</span></code> returns the dictionary with lazy objects, but
<code><span>mod.__dict__</span></code> reifies everything.</li>
</ol>
<p>We chose the third option because it properly delineates responsibility: if
you add lazy imports to your module and call <code><span>globals()</span></code>, you’re responsible
for handling the lazy objects. But external code accessing your module’s
<code><span>__dict__</span></code> shouldn’t need to know about your lazy imports – it gets fully
resolved modules.</p>
</section>
</section>
<section id="acknowledgements">
<h2><a href="#acknowledgements" role="doc-backlink">Acknowledgements</a></h2>
<p>We would like to thank Paul Ganssle, Yury Selivanov, Łukasz Langa, Lysandros
Nikolaou, Pradyun Gedam, Mark Shannon, Hana Joo and the Python Google team,
the Python team(s) @ Meta, the Python @ HRT team, the Bloomberg Python team,
the Scientific Python community, everyone who participated in the initial
discussion of <a href="https://pep-previews--4622.org.readthedocs.build/pep-0690/" title="PEP 690 – Lazy Imports">PEP 690</a>, and many others who provided valuable feedback and
insights that helped shape this PEP.</p>
</section>
<section id="footnotes">
<h2><a href="#footnotes" role="doc-backlink">Footnotes</a></h2>

</section>
<section id="copyright">
<h2><a href="#copyright" role="doc-backlink">Copyright</a></h2>
<p>This document is placed in the public domain or under the
CC0-1.0-Universal license, whichever is more permissive.</p>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE Wants to Build Out a 24/7 Social Media Surveillance Team (151 pts)]]></title>
            <link>https://www.wired.com/story/ice-social-media-surveillance-24-7-contract/</link>
            <guid>45465964</guid>
            <pubDate>Fri, 03 Oct 2025 18:13:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/ice-social-media-surveillance-24-7-contract/">https://www.wired.com/story/ice-social-media-surveillance-24-7-contract/</a>, See on <a href="https://news.ycombinator.com/item?id=45465964">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" tabindex="-1"><article lang="en-US"><div><header data-testid="SplitScreenContentHeaderWrapper"><div><div><p>Documents show that ICE plans to hire dozens of contractors to scan X, Facebook, TikTok, and other platforms to target people for deportation.</p></div><div><p><span><picture><source media="(max-width: 767px)" srcset="https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:4/w_120,c_limit/GettyImages-2216837590.jpg 120w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:4/w_240,c_limit/GettyImages-2216837590.jpg 240w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:4/w_320,c_limit/GettyImages-2216837590.jpg 320w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:4/w_640,c_limit/GettyImages-2216837590.jpg 640w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:4/w_960,c_limit/GettyImages-2216837590.jpg 960w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_120,c_limit/GettyImages-2216837590.jpg 120w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_240,c_limit/GettyImages-2216837590.jpg 240w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_320,c_limit/GettyImages-2216837590.jpg 320w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_640,c_limit/GettyImages-2216837590.jpg 640w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_960,c_limit/GettyImages-2216837590.jpg 960w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_1280,c_limit/GettyImages-2216837590.jpg 1280w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_1600,c_limit/GettyImages-2216837590.jpg 1600w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_1920,c_limit/GettyImages-2216837590.jpg 1920w, https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_2240,c_limit/GettyImages-2216837590.jpg 2240w" sizes="100vw"><img alt="ICE Wants to Build Out a 247 Social Media Surveillance Team" loading="eager" src="https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_2560%2Cc_limit/GettyImages-2216837590.jpg" data-src="https://media.wired.com/photos/68dfbf1423a810d9d7e48657/3:2/w_2560%2Cc_limit/GettyImages-2216837590.jpg"></picture></span></p></div></div><div><p><span>Photograph: Lawrey/ Getty Images</span></p></div></header></div><div data-testid="ArticlePageChunks" data-attribute-verso-pattern="article-body"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>United States immigration</span> authorities are moving to dramatically expand their <a href="https://www.wired.com/story/the-wired-guide-to-protecting-yourself-from-government-surveillance/">social media surveillance</a>, with plans to hire nearly 30 contractors to sift through posts, photos, and messages—raw material to be transformed into intelligence for deportation raids and arrests.</p><p>Federal <a data-offer-url="https://sam.gov/workspace/contract/opp/37b379dbed484281a12530cc01835e04/view" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://sam.gov/workspace/contract/opp/37b379dbed484281a12530cc01835e04/view&quot;}" href="https://sam.gov/workspace/contract/opp/37b379dbed484281a12530cc01835e04/view" rel="nofollow noopener" target="_blank">contracting records</a> reviewed by WIRED show that the agency is <a data-offer-url="https://s3.documentcloud.org/documents/26179463/rfi-erotodncatcandperc-20251002.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://s3.documentcloud.org/documents/26179463/rfi-erotodncatcandperc-20251002.pdf&quot;}" href="https://s3.documentcloud.org/documents/26179463/rfi-erotodncatcandperc-20251002.pdf" rel="nofollow noopener" target="_blank">seeking private vendors</a> to run a multiyear surveillance program out of two of its little-known targeting centers. The program envisions stationing nearly 30 private analysts at Immigration and Customs Enforcement facilities in Vermont and Southern California. Their job: Scour <a href="https://www.wired.com/tag/facebook/">Facebook</a>, <a href="https://www.wired.com/tag/tiktok/">TikTok</a>, <a href="https://www.wired.com/tag/instagram/">Instagram</a>, <a href="https://www.wired.com/tag/youtube/">YouTube</a>, and other platforms, converting posts and profiles into fresh leads for enforcement raids.</p><p>The initiative is still at the request-for-information stage, a step agencies use to gauge interest from contractors before an official bidding process. But <a data-offer-url="https://s3.documentcloud.org/documents/26179462/rfi-performanceworkstatementncatc-perc-draft-20251002.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://s3.documentcloud.org/documents/26179462/rfi-performanceworkstatementncatc-perc-draft-20251002.pdf&quot;}" href="https://s3.documentcloud.org/documents/26179462/rfi-performanceworkstatementncatc-perc-draft-20251002.pdf" rel="nofollow noopener" target="_blank">draft planning documents</a> show the scheme is ambitious: ICE wants a contractor capable of staffing the centers around the clock, constantly processing cases on tight deadlines, and supplying the agency with the latest and greatest subscription-based surveillance software.</p><p>The facilities at the heart of this plan are two of ICE’s three targeting centers, responsible for producing leads that feed directly into the agency’s enforcement operations. The National Criminal Analysis and Targeting Center sits in Williston, Vermont. It handles cases across much of the eastern US. The Pacific Enforcement Response Center, based in Santa Ana, California, oversees the western region and is designed to run 24 hours a day, seven days a week.</p><p>Internal planning documents show that each site would be staffed with a mix of senior analysts, shift leads, and rank-and-file researchers. Vermont would see a team of a dozen contractors, including a program manager and 10 analysts. California would host a larger, nonstop watch floor with 16 staff. At all times, at least one senior analyst and three researchers would be on duty at the Santa Ana site.</p><p>Together, these teams would operate as intelligence arms of ICE’s Enforcement and Removal Operations division. They will receive tips and incoming cases, research individuals online, and package the results into dossiers that could be used by field offices to plan arrests.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The scope of information contractors are expected to collect is broad. Draft instructions specify open-source intelligence: public posts, photos, and messages on platforms from Facebook to Reddit to TikTok. Analysts may also be tasked with checking more obscure or foreign-based sites, such as Russia’s VKontakte.</p><p>They would also be armed with powerful commercial databases such as <a data-offer-url="https://theintercept.com/2022/06/09/ice-lexisnexis-mass-surveillances/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://theintercept.com/2022/06/09/ice-lexisnexis-mass-surveillances/&quot;}" href="https://theintercept.com/2022/06/09/ice-lexisnexis-mass-surveillances/" rel="nofollow noopener" target="_blank">LexisNexis Accurint</a> and Thomson Reuters CLEAR, which knit together property records, phone bills, utilities, vehicle registrations, and other personal details into searchable files.</p><p>The plan calls for strict turnaround times. Urgent cases, such as suspected national security threats or people on ICE’s Top Ten Most Wanted list, must be researched within 30 minutes. High-priority cases get one hour; lower-priority leads must be completed within the workday. ICE expects at least three-quarters of all cases to meet those deadlines, with top contractors hitting closer to 95 percent.</p><p>The plan goes beyond staffing. ICE also wants algorithms, asking contractors to spell out how they might weave <a href="https://www.wired.com/tag/artificial-intelligence/">artificial intelligence</a> into the hunt—a solicitation that mirrors other recent proposals. The agency has also set aside more than a million dollars a year to arm analysts with the latest surveillance tools.</p><p>ICE did not immediately respond to a request for comment.</p><p>Earlier this year, The Intercept revealed that ICE had floated <a data-offer-url="https://theintercept.com/2025/02/11/ice-immigration-social-media-surveillance/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://theintercept.com/2025/02/11/ice-immigration-social-media-surveillance/&quot;}" href="https://theintercept.com/2025/02/11/ice-immigration-social-media-surveillance/" rel="nofollow noopener" target="_blank">plans for a system</a> that could automatically scan social media for “negative sentiment” toward the agency and flag users thought to show a “proclivity for violence.” Procurement records previously reviewed by 404 Media identified software used by the agency to <a data-offer-url="https://www.404media.co/inside-ices-database-derogatory-information-giant-oak-gost/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.404media.co/inside-ices-database-derogatory-information-giant-oak-gost/&quot;}" href="https://www.404media.co/inside-ices-database-derogatory-information-giant-oak-gost/" rel="nofollow noopener" target="_blank">build dossiers on flagged individuals</a>, compiling personal details, family links, and even using facial recognition to connect images across the web. Observers warned it was unclear how such technology could distinguish genuine threats from political speech.</p><p>ICE’s main investigative database, built by <a href="https://www.wired.com/story/palantir-what-the-company-does/">Palantir Technologies</a>, already uses algorithmic analysis to filter huge populations and generate leads. The new contract would funnel fresh social media and open-source inputs directly into that system, further automating the process.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Planning documents say some restrictions are necessary to head off abuse. Contractors are barred from creating fake profiles, interacting with people online, or storing personal data on their own networks. All analysis must remain on ICE servers. Past experience, however, shows such guardrails can be flimsy, honored more in paperwork than in practice. Other documents obtained by 404 Media this summer revealed that police in Medford, Oregon, performed license plate reader searches for ICE’s Homeland Security Investigations division, while HSI agents later ran searches in federal databases at the request of local police—<a data-offer-url="https://www.404media.co/emails-reveal-the-casual-surveillance-alliance-between-ice-and-local-police/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.404media.co/emails-reveal-the-casual-surveillance-alliance-between-ice-and-local-police/&quot;}" href="https://www.404media.co/emails-reveal-the-casual-surveillance-alliance-between-ice-and-local-police/" rel="nofollow noopener" target="_blank">an informal back-and=forth</a> that effectively gave ICE access to tools it wasn’t authorized to use.</p><p>Other surveillance contracts have raised similar alarms. In September 2024, <a href="https://www.wired.com/story/ice-paragon-solutions-contract/">ICE signed a $2 million contract with Paragon</a>, an Israeli spyware company whose flagship product, Graphite, can allegedly <a data-offer-url="https://www.forbes.com/sites/thomasbrewster/2021/07/29/paragon-is-an-nso-competitor-and-an-american-funded-israeli-surveillance-startup-that-hacks-encrypted-apps-like-whatsapp-and-signal/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.forbes.com/sites/thomasbrewster/2021/07/29/paragon-is-an-nso-competitor-and-an-american-funded-israeli-surveillance-startup-that-hacks-encrypted-apps-like-whatsapp-and-signal/&quot;}" href="https://www.forbes.com/sites/thomasbrewster/2021/07/29/paragon-is-an-nso-competitor-and-an-american-funded-israeli-surveillance-startup-that-hacks-encrypted-apps-like-whatsapp-and-signal/" rel="nofollow noopener" target="_blank">remotely hack messaging apps</a> like WhatsApp and Signal. The Biden White House <a href="https://www.wired.com/story/ice-paragon-contract-white-house-review/">quickly froze the deal</a> under an executive order restricting spyware use, but ICE reactivated it in August 2025 under the Trump administration. Last month, 404 Media <a data-offer-url="https://www.404media.co/were-suing-ice-for-its-2-million-spyware-contract/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.404media.co/were-suing-ice-for-its-2-million-spyware-contract/&quot;}" href="https://www.404media.co/were-suing-ice-for-its-2-million-spyware-contract/" rel="nofollow noopener" target="_blank">filed a freedom of information lawsuit</a> demanding ICE release the contract and related records, citing widespread concern that the tool could be used to target immigrants, journalists, and activists.</p><p>The Electronic Privacy Information Center has <a data-offer-url="https://epic.org/wp-content/uploads/2022/03/Complaint-2022.pdf#:~:text=3%209,4" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://epic.org/wp-content/uploads/2022/03/Complaint-2022.pdf#:~:text=3%209,4&quot;}" href="https://epic.org/wp-content/uploads/2022/03/Complaint-2022.pdf#:~:text=3%209,4" rel="nofollow noopener" target="_blank">similarly sued ICE</a>, calling its reliance on data brokers a “significant threat to privacy and liberty.” The American Civil Liberties Union <a href="https://www.aclu.org/news/privacy-technology/new-records-detail-dhs-purchase-and-use-of-vast-quantities-of-cell-phone-location-data">has argued</a> that buying bulk datasets—such as smartphone location trails gathered from ordinary apps—helps ICE sidestep warrant requirements and helps it pull in vast amounts of data with no clear link to its enforcement mandate.</p><p>The newly proposed social media program is only the latest in a string of surveillance contracts ICE has pursued over the past few years.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In 2020 and 2021, ICE bought access to ShadowDragon’s SocialNet, a tool that aggregates data from <a data-offer-url="https://www.404media.co/the-200-sites-an-ice-surveillance-contractor-is-monitoring/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.404media.co/the-200-sites-an-ice-surveillance-contractor-is-monitoring/&quot;}" href="https://www.404media.co/the-200-sites-an-ice-surveillance-contractor-is-monitoring/" rel="nofollow noopener" target="_blank">more than 200 social networks and services</a> into searchable maps of a person’s connections. Around the same time, the agency contracted with Babel Street for Locate X, which supplies <a data-offer-url="https://epic.org/documents/epic-v-ice-location-and-social-media-surveillance/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://epic.org/documents/epic-v-ice-location-and-social-media-surveillance/&quot;}" href="https://epic.org/documents/epic-v-ice-location-and-social-media-surveillance/" rel="nofollow noopener" target="_blank">location histories from ordinary smartphone apps</a>, letting investigators reconstruct people’s movements without a warrant. ICE also adopted LexisNexis Accurint, used by agents to look up addresses, vehicles, and associates, though the scale of spending on that service is unclear. In September, ICE signed a <a data-offer-url="http://forbes.com/sites/thomasbrewster/2025/09/08/ice-to-pay-10-million-for-clearview-facial-recognition-to-investigate-agent-assaults/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://forbes.com/sites/thomasbrewster/2025/09/08/ice-to-pay-10-million-for-clearview-facial-recognition-to-investigate-agent-assaults/&quot;}" href="http://forbes.com/sites/thomasbrewster/2025/09/08/ice-to-pay-10-million-for-clearview-facial-recognition-to-investigate-agent-assaults/" rel="nofollow noopener" target="_blank">multimillion-dollar contract with Clearview AI</a>, a facial recognition company that built its database by scraping billions of images from social media and the public web.</p><p>Throughout, ICE has leaned on Palantir’s Investigative Case Management system to combine disparate streams of data into a single investigative platform. Recent contract updates show the system lets agents <a href="https://www.wired.com/story/ice-palantir-immigrationos/">search people using hundreds of categories</a>, from immigration status and country of origin to scars, tattoos, and license-plate reader data. Each surveillance contract ICE signs adds another layer—location trails, social networks, financial records, biometric identifiers—feeding into Palantir’s hub. ICE’s new initiative is about scaling up the human side of the equation, stationing analysts around the clock to convert the firehose of data into raid-ready leads.</p><p>ICE argues it needs these tools to modernize enforcement. Its planning documents note that “previous approaches … which have not incorporated open web sources and social media information, have had limited success.” The agency suggests that tapping social media and open web data helps identify aliases, track movements, and detect patterns that traditional methods often miss.</p><p>With plenty of <a href="https://www.aclu.org/surveillance-under-the-patriot-act">historical analogs</a> to <a data-offer-url="https://scholarship.law.bu.edu/faculty_scholarship/360/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://scholarship.law.bu.edu/faculty_scholarship/360/&quot;}" href="https://scholarship.law.bu.edu/faculty_scholarship/360/" rel="nofollow noopener" target="_blank">choose from</a>, privacy advocates warn that any surveillance that starts as a method of capturing immigrants could soon be deployed <a data-offer-url="https://publicsurveillance.com/papers/IJEP.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://publicsurveillance.com/papers/IJEP.pdf&quot;}" href="https://publicsurveillance.com/papers/IJEP.pdf" rel="nofollow noopener" target="_blank">for ulterior purposes</a>. ICE’s proposal to track “negative sentiment” is a clear example of how the agency’s threat monitoring bleeds into the policing of dissent. By drawing in the online activity of not only its targets but also friends, family, and community members, ICE is certain to collect far more information outside its mandate than it is likely to publicly concede.</p></div></div></article><div><div data-testid="RowWrapper"><ul><li data-testid="LinkStackBullet"><p><strong>In your inbox:</strong> Our <a href="https://www.wired.com/newsletter/daily?sourceCode=BottomStories" target="_blank">biggest stories</a>, handpicked for you each day</p></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li></ul></div><div data-testid="RowWrapper"><p><a href="https://www.wired.com/author/dell-cameron/"><span><picture><source media="(max-width: 767px)" srcset="https://media.wired.com/photos/663fe63cf59145e49d5e32df/1:1/w_80,c_limit/undefined 80w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.wired.com/photos/663fe63cf59145e49d5e32df/1:1/w_90,c_limit/undefined 90w" sizes="100vw"><img alt="" loading="lazy" src="https://media.wired.com/photos/663fe63cf59145e49d5e32df/1:1/w_90%2Cc_limit/undefined" data-src="https://media.wired.com/photos/663fe63cf59145e49d5e32df/1:1/w_90%2Cc_limit/undefined"></picture></span></a></p><div><p><a href="https://www.wired.com/author/dell-cameron/">Dell Cameron</a> is an investigative reporter from Texas covering privacy and national security. He's the recipient of multiple Society of Professional Journalists awards and is co-recipient of an Edward R. Murrow Award for Investigative Reporting. Previously, he was a senior reporter at Gizmodo and a staff writer for the Daily ... <a href="https://www.wired.com/author/dell-cameron">Read More</a></p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ants trapped in a Soviet nuclear bunker survived for years (110 pts)]]></title>
            <link>https://www.sciencealert.com/ants-trapped-in-an-old-soviet-nuclear-bunker-survived-for-years-by-turning-on-their-own</link>
            <guid>45465091</guid>
            <pubDate>Fri, 03 Oct 2025 17:01:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencealert.com/ants-trapped-in-an-old-soviet-nuclear-bunker-survived-for-years-by-turning-on-their-own">https://www.sciencealert.com/ants-trapped-in-an-old-soviet-nuclear-bunker-survived-for-years-by-turning-on-their-own</a>, See on <a href="https://news.ycombinator.com/item?id=45465091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>Even in a hopeless place, ants will find a way. No food, no light, no escape? No problem.</p><p>In the woods of western Poland lies a dismantled Soviet nuclear base, complete with two underground bunkers where nuclear ammunition was once kept. After the military complex was abandoned, these eerie human-made caves became great roosting places for overwintering bats.</p><p>In early 2010s, volunteers started visiting the bunkers to monitor the bat population in winter, and made a discovery of a different sort: A large mass of wood ants (<em>Formica polyctena</em>) trapped on the bunker floor, surviving without a queen or any of their usual creature comforts.</p><p><span><img decoding="async" src="https://www.sciencealert.com/images/2019-11/oo_100896.jpg" alt="oo 100896" width="700" loading="lazy"><span>The bunker 'colony' with a 'cemetery' against the far wall. (Wojciech Stephan/Czechowski <em>et al., Journal of Hymenoptera Research</em>, 2016)</span></span></p><p>When it was first found in 2013, this 'colony' of underground ants already included up to a million live workers and several more million dead. They were not reproducing, though. Instead, the population was being replenished through sheer accident.</p><p>In the ceiling of the bunker sat a rusted ventilation pipe, connecting the dark cavern to the forest above. There, a giant ant colony had built a mound right above the bunker; as the metal rusted through, some of their ranks started falling into the concrete cavern below.</p><p><span><img decoding="async" src="https://www.sciencealert.com/images/2019-11/oo_351426.jpg" alt="oo 351426" width="700" loading="lazy"><span>The ventilation pipe. (Rutkowski <em>et al., Journal of Hymenoptera Research,</em> 2019)</span></span></p><p>"In total darkness, they have constructed an earthen mound, which they have maintained all-year-round by moulding it and keeping the nest entrances open," researchers wrote <a href="https://doi.org/10.3897/jhr.51.9096">in a study in 2016</a>, noting these ants are "a&nbsp;far cry from a fully functional colony".&nbsp;</p><p>Investigating the limits of ant living conditions is a subject of keen interest for some entomologists. So, for several years, researchers made repeated trips to the bunker and watched in fascination as this isolated population continued to grow and survive despite a lack of light, heat, or obvious nourishment.</p><p>Now, scientists finally know how these trapped insects pulled it off: the mass consumption of their own imprisoned nest mates.</p><p><span><img decoding="async" src="https://www.sciencealert.com/images/2019-11/oo_100894.jpg" alt="oo 100894" width="700" loading="lazy"><span>The colony built above the ventilation pipe. (Czechowski <em>et al., Journal of Hymenoptera Research,</em> 2016)</span></span></p><p>Cannibalism was obviously suspected; wood ants are, after all, the only major food source available in this tight spot, apart from the occasional dead mouse or bat. Plus, this particular species is <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3619097/">known to consume</a> their own fallen dead during territorial "<a href="http://serious-science.org/ant-wars-6652">ant wars</a>" when food is often scarce.</p><p>To confirm this hunch, a team of researchers collected corpses from several ant 'cemeteries' scattered within the bunker. Closely examining 150 dead worker ants, the team noticed the vast majority of bodies (roughly 93 percent) had gnawed holes and bite marks.</p><p>The authors say these are clear signs of mass consumption, with practically no other organism in the bunker capable of making these marks.</p><p>"The survival and growth of the bunker 'colony' through the years, without producing own offspring, was possible owing to continuous supply of new workers from the upper nest and accumulation of nestmate corpses," the researchers&nbsp;<a href="https://jhr.pensoft.net/article/38972/">concluded in their study.</a></p><p>"The corpses served as an inexhaustible source of food which substantially allowed survival of the ants trapped down in otherwise extremely unfavourable conditions."</p><p>It seems that wood ants can handle remarkable adversity in their bid for survival. Although luckily for this colony, they no longer have to turn on their own: In 2016, researchers <a href="https://jhr.pensoft.net/article/38972/element/4/43//">installed a wooden boardwalk</a>&nbsp;(below) in the bunker, connecting the ventilation pipe to the ground. Within four months, nearly all the trapped ants had deserted the bunker floor.</p><p><span><img decoding="async" src="https://www.sciencealert.com/images/2019-11/oo_351427.jpg" alt="oo 351427" width="700" loading="lazy"><span>The recently installed boardwalk. (Rutkowski<em> et al., Journal of Hymenoptera Research,</em> 2019)</span></span></p><p>Now, when any ants are unfortunate enough to fall into the dark chamber, they don't have to resort to cannibalism.&nbsp;They can just calmly walk the plank, all the way home.</p><p>The research was published in the <a href="https://jhr.pensoft.net/article/38972/"><em>Journal of Hymenoptera Research</em></a>.</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The collapse of the econ PhD job market (144 pts)]]></title>
            <link>https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job</link>
            <guid>45464984</guid>
            <pubDate>Fri, 03 Oct 2025 16:49:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job">https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job</a>, See on <a href="https://news.ycombinator.com/item?id=45464984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>For decades, a doctorate in economics was a golden ticket. It promised a path to tenure, or at worst, a lucrative role at a central bank, think tank, or tech firm.</p><p>Not anymore.</p><p>The economics job market is in freefall, and the profession’s own data proves it.</p><p>Unlike most fields, economics has a bizarrely centralized hiring ritual. Once a year, in the fall, every employer posts openings at the same time. Every candidate applies at the same time. The entire profession runs through one clearinghouse: the American Economic Association’s “Job Openings for Economists” (JOE). This makes economics PhD market uniquely measurable, and the numbers are brutal. </p><p data-attrs="{&quot;url&quot;:&quot;https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>The JOE data shows few jobs in 2022, fewer still in 2023, and fewer still in 2024. </p><p>This year’s trajectory suggests 2025 will be even worse: </p><p>Extrapolating, the 2025 market looks set to bottom out around 1,000 openings:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!f-pF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!f-pF!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 424w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 848w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 1272w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!f-pF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png" width="539" height="457.61925601750545" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/afe99765-622e-4112-a4a6-8531f4a533a2_457x388.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:388,&quot;width&quot;:457,&quot;resizeWidth&quot;:539,&quot;bytes&quot;:78973,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!f-pF!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 424w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 848w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 1272w, https://substackcdn.com/image/fetch/$s_!f-pF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafe99765-622e-4112-a4a6-8531f4a533a2_457x388.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I think my freehand projection is a very conservative approximation of reality—actual numbers may come in slightly higher or lower, of course, but this reasonably looks like what the market is on track for, barring a miracle. </p><p>Just three years ago, there were 1,477 openings. </p><p>The fall to ~1,000 this year will represent a 32% collapse.</p><p><span>Most economics PhD students aren’t looking for just any job, though, they want a tenure-track position in academia. According to </span><a href="https://www.aeaweb.org/about-aea/committees/job-market" rel="">polling data</a><span> from the 2025 </span><em>Webinar on the Economics PhD Job Market</em><span>, 94% of candidates from the past four cohorts reported being “very interested” or “somewhat interested” in becoming an assistant professor, dwarfing all non-academic options.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!FR9T!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!FR9T!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 424w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 848w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 1272w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!FR9T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png" width="987" height="649" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:649,&quot;width&quot;:987,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:199014,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!FR9T!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 424w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 848w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 1272w, https://substackcdn.com/image/fetch/$s_!FR9T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16a6b968-1eb5-433e-9f34-0f6ac503175c_987x649.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Subsetting the JOE data to permanent academic positions (tenure-track or tenured) yields a nearly identical trend: openings dropped from 631 in 2022 to about 400 in 2025, a 35% decline over three years: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!mLx4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!mLx4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 424w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 848w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 1272w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!mLx4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png" width="588" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:588,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:54275,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!mLx4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 424w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 848w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 1272w, https://substackcdn.com/image/fetch/$s_!mLx4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff48a8bde-b7fe-48e2-a1e2-a7b5a2c4332c_588x500.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Again, please forgive my Microsoft Paint skills:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ZuR_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ZuR_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 424w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 848w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 1272w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ZuR_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png" width="539" height="457.61925601750545" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:388,&quot;width&quot;:457,&quot;resizeWidth&quot;:539,&quot;bytes&quot;:78518,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ZuR_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 424w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 848w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 1272w, https://substackcdn.com/image/fetch/$s_!ZuR_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8471275-4ba1-4616-bde9-9ff3613efaac_457x388.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The JOE data is confirmed by Econ Job Market (EJM) data, a nonprofit 501(c)(3) whose stated mission is </span><em>“to improve the flow of information in the job market for academic economists, by providing a central repository for job-market materials.”</em></p><p>EJM data makes the pattern robust: nearly all interview invitations are sent out during a concentrated few weeks in December, and the volume of those invitations has collapsed from 3,835 down to 2,502… a 34.8% decline. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Kugp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Kugp!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 424w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 848w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 1272w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Kugp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png" width="506" height="511" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:511,&quot;width&quot;:506,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:55818,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Kugp!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 424w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 848w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 1272w, https://substackcdn.com/image/fetch/$s_!Kugp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb24475d-a0d3-4338-87ba-ad8e62129cae_506x511.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>As a result, the AEA’s own Job Market Committee quietly admitted in its 2025 report that last year was “challenging” for candidates.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!3BTh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!3BTh!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 424w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 848w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!3BTh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg" width="430" height="370.27777777777777" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:310,&quot;width&quot;:360,&quot;resizeWidth&quot;:430,&quot;bytes&quot;:35322,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!3BTh!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 424w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 848w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!3BTh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40d62fbd-453b-4b0b-86d1-e9d2e5af47bd_360x310.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!vLFu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!vLFu!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 424w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 848w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 1272w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!vLFu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png" width="626" height="190.8201754385965" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:139,&quot;width&quot;:456,&quot;resizeWidth&quot;:626,&quot;bytes&quot;:19974,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!vLFu!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 424w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 848w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 1272w, https://substackcdn.com/image/fetch/$s_!vLFu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe462588d-2163-4ec7-90d3-2c0e15286d79_456x139.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>EJM data show that the cumulative number of views on job ads is higher than ever, with 2025 easily on track to set a new record.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!llxk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!llxk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 424w, https://substackcdn.com/image/fetch/$s_!llxk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 848w, https://substackcdn.com/image/fetch/$s_!llxk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 1272w, https://substackcdn.com/image/fetch/$s_!llxk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!llxk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png" width="813" height="657" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:657,&quot;width&quot;:813,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!llxk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 424w, https://substackcdn.com/image/fetch/$s_!llxk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 848w, https://substackcdn.com/image/fetch/$s_!llxk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 1272w, https://substackcdn.com/image/fetch/$s_!llxk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a8dc18-3fa4-4b8e-9e93-2473f89d11fd_813x657.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>That isn’t surprising: according to the 2024 NSF Survey of Doctorate Recipients, 1,385 Americans earned economics PhDs in 2024, more than in 2023, more than in 2022, and more than in 2021. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Abv2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Abv2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 424w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 848w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 1272w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Abv2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png" width="695" height="290" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:290,&quot;width&quot;:695,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:49708,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!Abv2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 424w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 848w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 1272w, https://substackcdn.com/image/fetch/$s_!Abv2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01bdb0d4-33e3-4c44-b992-5503575b94d2_695x290.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You now have 1,385 brand-new PhDs chasing just 400 tenure-track jobs.</p><p>At first glance, that ratio might not look catastrophic. But here’s the catch: </p><p>They’re not competing only against each other. An equally large wave of international candidates floods the U.S. market every year. American universities routinely hire from London, Oxford, Cambridge, Toronto, Paris, Barcelona, and beyond.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!-aK-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!-aK-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 424w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 848w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 1272w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!-aK-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png" width="1059" height="559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:559,&quot;width&quot;:1059,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:35107,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!-aK-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 424w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 848w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 1272w, https://substackcdn.com/image/fetch/$s_!-aK-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F069e6476-6073-445a-b9f5-89c3ffe9af2e_1059x559.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Furthermore, the new graduates aren’t competing just with their own cohort. They’re thrown into the same bucket as the leftovers from every prior cycle: post-docs clinging to hope, visiting professors chasing stability, lecturers desperate to upgrade, assistant professors stranded at second-tier schools. The “new supply” is just the visible tip; the true applicant pool is a rolling backlog several times larger.</p><p>The result? According to EJM, 5,341 candidates participated in the 2024–25 market, the largest applicant pool ever recorded: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!tJVO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!tJVO!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 424w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 848w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 1272w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!tJVO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png" width="669" height="517" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:517,&quot;width&quot;:669,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:94207,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!tJVO!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 424w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 848w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 1272w, https://substackcdn.com/image/fetch/$s_!tJVO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F108ee627-50e2-4eb1-a015-dae07bf0b467_669x517.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Yet the AEA’s </span><em>Survey of the Labor Market for New Ph.D. Hires in Economics</em><span> found that only 99 fresh PhD secured a tenure-track job in America. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UA8O!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UA8O!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 424w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 848w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 1272w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!UA8O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png" width="717" height="683.7915789473684" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eb73244d-841e-4683-bdfa-607f716649ef_475x453.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:453,&quot;width&quot;:475,&quot;resizeWidth&quot;:717,&quot;bytes&quot;:53882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UA8O!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 424w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 848w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 1272w, https://substackcdn.com/image/fetch/$s_!UA8O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb73244d-841e-4683-bdfa-607f716649ef_475x453.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>That’s a ~7% placement rate for American PhD students.</p><p>Put differently: if 100 students spend six years earning an econ PhD in America (the current U.S. median time to degree is 5.8 years, not counting the growing detour of “pre-docs”), only seven will get a tenure-track job. </p><p>Even if we allow for survey response gaps and use the most charitable assumptions, the best possible placement rate for fresh Econ PhDs is likely no higher than 10–20%, maybe 25%? My methodology isn’t perfect, but no matter what, that’s still catastrophic.</p><p>And these jobs aren’t evenly distributed. A massively disproportionate share go to graduates of Harvard, MIT, Stanford, Chicago, Princeton, Yale, Berkeley, and Penn. That means for every grad student outside the top 10 programs, the odds of landing tenure track are significantly less than 5%. </p><p>Government has long been the second-largest employer of economics PhDs, traditionally offering stable if less glamorous careers at agencies like the Federal Reserve, Treasury, Bureau of Labor Statistics, or Congressional Budget Office. But even here, the number of available positions has fallen sharply. Federal hiring freezes, budget constraints, and shifting political priorities mean that many agencies are cutting back.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!AG37!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!AG37!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 424w, https://substackcdn.com/image/fetch/$s_!AG37!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 848w, https://substackcdn.com/image/fetch/$s_!AG37!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 1272w, https://substackcdn.com/image/fetch/$s_!AG37!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!AG37!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png" width="562" height="428.525" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3b54d146-152a-48d6-8fc2-50692298146c_880x671.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:671,&quot;width&quot;:880,&quot;resizeWidth&quot;:562,&quot;bytes&quot;:57016,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!AG37!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 424w, https://substackcdn.com/image/fetch/$s_!AG37!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 848w, https://substackcdn.com/image/fetch/$s_!AG37!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 1272w, https://substackcdn.com/image/fetch/$s_!AG37!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b54d146-152a-48d6-8fc2-50692298146c_880x671.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>International organizations once served as the safety net for economists who missed out on academia or Washington. The IMF, World Bank, and OECD hired tons of econ PhDs. Today, those doors are far more scarce, and the competition is global: an American graduate is just as likely to be measured against candidates from LSE, Sciences Po, or Peking University.</p><p>Oh yeah, and they have hiring freezes too: </p><p>Outside academia, government, or IGOs, the tech industry used to provide a reliable fallback. Tech giants like Amazon, Microsoft, Netflix, and Airbnb built entire teams of economists to optimize pricing, design experiments, and model consumer behavior. </p><p>That avenue, too, has begun to shrink. Tech hiring, which exploded during the pandemic, has collapsed. Today, demand is not just weak but structurally below trend, as firms automate more of the work that junior economists once did.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Cje4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Cje4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 424w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 848w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 1272w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Cje4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp" width="1080" height="482" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:482,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:34498,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Cje4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 424w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 848w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 1272w, https://substackcdn.com/image/fetch/$s_!Cje4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4afceb8-a067-44ab-8f9e-53caaeb32ad1_1080x482.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><p> ‘‘What does the modal economist, or any non CS or DS person really, have to offer to a tech firm in 2025? Not all, but many tech companies are actively downsizing and laying off tons of workers with tech experience that you have to compete against. And few firms will really care about causal inference and any other data analytics jobs can be filled by data science masters grads with deeper programming skills and cheaper salary expectations. Not to mention there is a focus on developing and using AI these days and your intro to machine learning class isn’t going to cut it.’’</p><p>— Anonymous economist</p></div><p>The only seemingly stable landing spot left for economists is in banking and finance, but even here hiring is stagnant and remains well below its pre-pandemic trend. Counterintuitively, most private-sector banks and investment firms do not rely heavily on PhDs in economics. They prefer MBAs, statisticians, or computer scientists, leaving economics doctorates as niche hires rather than a core part of the workforce.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!OQx1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!OQx1!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 424w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 848w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 1272w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!OQx1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png" width="738" height="477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:477,&quot;width&quot;:738,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!OQx1!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 424w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 848w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 1272w, https://substackcdn.com/image/fetch/$s_!OQx1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feafcfd1a-6fa2-41e3-a3e5-51814310943b_738x477.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>REASON 1: Declining undergraduate enrollment in economics</strong></p><p><a href="https://www.benjaminhansen.org/" rel="">Benjamin Hansen</a><span>, an econ professor at the University of Oregon, recently tweeted out His department’s own data show a steady fall in the number of declared majors, which has now translated into fewer degrees conferred.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!NTEv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!NTEv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 424w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 848w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 1272w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!NTEv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png" width="1206" height="804" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:804,&quot;width&quot;:1206,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:13340,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!NTEv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 424w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 848w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 1272w, https://substackcdn.com/image/fetch/$s_!NTEv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a2d477d-3a29-404f-8e80-9a11dbe91dc4_1206x804.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>National statistics confirm the trend: the number of students graduating with economics degrees is now slipping after years of steady growth. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!uMUK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!uMUK!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!uMUK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg" width="1456" height="791" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:791,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:469376,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!uMUK!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uMUK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e687c3-25ab-4542-a502-bde050e21a06_2800x1522.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Because universities hire faculty in proportion to student demand, this drop in majors eventually trickles down into fewer faculty lines. </p><p><strong>REASON 2: The looming demographic cliff</strong></p><p>The decline in majors is compounded by a larger demographic shift. The U.S. is approaching a “demographic cliff,” as the number of 18-year-olds begins to shrink in the 2020s and 2030s. Fewer college-aged students overall means fiercer competition among departments for enrollments.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5mMN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5mMN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5mMN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg" width="584" height="438" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:584,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/$s_!5mMN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!5mMN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb05462c1-8e59-4b8b-81d3-2d1cea1cb1cd_2048x1536.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>REASON 3: The rise of artificial intelligence</strong></p><p><span>Bryan Caplan, professor of economics at George Mason University, gave ChatGPT his graduate-level</span><a href="https://betonit.substack.com/p/chatgpt-takes-my-midterm-and-gets" rel=""> Labor Economics final exam</a><span>. The AI earned a “D” (this was 2 years ago), but soon enough, we all know it will be smart enough to earn an A. The technology is improving rapidly, and universities know it, and so does the private sector. Tasks once reserved for graduate students and junior faculty—data cleaning, econometric modeling, even writing referee reports—are now being automated. </span></p><p><strong>REASON 4: Lying About Inflation</strong></p><p>If you were there during the pandemic money printing, you remember the sequence all too well: first the confident insistence that government spending wouldn’t fuel inflation, then the soothing claim that inflation was merely “transitory,” and finally the outright gaslighting that prices weren’t rising at all. Each step was wrong, and each was delivered with smug certainty. Ordinary people—who watched their rent, groceries, and gas bills skyrocket—saw a profession more invested in protecting Democratic policy narratives than in telling the truth. The result is a self-inflicted torching of trust.</p><p>The answer is no. An economics PhD is no longer an investment. It is a gamble with terrible odds. A handful of winners still exist, almost all of them minted at Harvard, MIT, Princeton, or Chicago. For everyone else, the degree is a trap: six or more years of grinding work that too often ends with being overeducated, underpaid, and locked out of the profession you trained to join.</p><div><p>‘‘My advice is to do something other than go for a Ph.D in economics … In hindsight, my decision to go to graduate school was a mistake. My primary motivation was intellectual curiosity, and econ grad school worked against that.’’</p><p><span>— </span></p></div><p><span>After I wrote this entire article, I came across a similar one</span><a href="https://archive.is/8ihbb#selection-517.0-517.38" rel=""> published last month by the New York Times</a><span>: </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!P_fH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!P_fH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 424w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 848w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 1272w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!P_fH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png" width="531" height="345" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:345,&quot;width&quot;:531,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:42294,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.chrisbrunet.com/i/174414048?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!P_fH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 424w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 848w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 1272w, https://substackcdn.com/image/fetch/$s_!P_fH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b4a09-614c-4ba3-be14-e1487059b8dc_531x345.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>It essentially just blamed the ‘‘bull market for economists being over’’ on the same three core reasons as I did: </p><ul><li><p><span>‘‘Universities and nonprofits have scaled back hiring amid declining state budgets and </span><a href="https://archive.is/o/8ihbb/https://www.nytimes.com/interactive/2025/05/22/upshot/nsf-grants-trump-cuts.html" rel="">federal funding cuts</a><span>.’’</span></p></li><li><p><span>‘‘At the same time, the Trump administration has laid off government economists and </span><a href="https://archive.is/o/8ihbb/https://www.whitehouse.gov/fact-sheets/2025/04/fact-sheet-president-donald-j-trump-extends-the-hiring-freeze/" rel="">frozen hiring</a><span> for new ones.’’</span></p></li><li><p>‘‘Tech companies also have grown stingier, and their need for high-level economists — once seemingly insatiable — has waned.’’</p></li></ul><p><span>Much more interesting than the NYT article was this commentary on it from </span></p><p><span>, a PhD economist trained at UC Berkeley: </span></p><p><span>He begins by engaging with the </span><em>NYT</em><span> article, then runs through the same JOE data I did, ultimately landing on a similar diagnosis: the collapse is driven largely by federal hiring freezes and the looming demographic cliff. From there, though, his piece becomes more distinctive and interesting, exploring the social dynamics and internal hierarchies of the profession. His conclusion is bleak for the discipline itself, but notably optimistic about the future of Substack:</span></p><blockquote><p>Do I think the PhD job market will bounce back?</p><p><span>Prognosticating too eagerly is a good way to land yourself a place in the Irving Fisher Hall of Forever Being Remembered For Having Said One Stupid Thing.</span><a href="https://www.global-developments.org/p/twilight-of-the-econs#footnote-4-170289520" rel=""><sup>4</sup></a><span> A 16% fall in jobs, while devastating, is not yet apocalyptic. (By comparison, historian job ads have fallen </span><a href="https://manyheadedmonster.com/2023/03/13/historians-phds-and-jobs-in-2023/" rel="">closer to 50%</a><span> since their 2008 peak.) But for things to get better requires a causal mechanism. Reinstating science and academic funding would require either Republicans to reverse their stance on the value of higher education, or for Democrats to win back the Senate. I don’t have a great sense of if either will happen.</span><a href="https://www.global-developments.org/p/twilight-of-the-econs#footnote-5-170289520" rel=""><sup>5</sup></a></p><p>In this case, prediction may be less important than preparation. Placement chairs need to own up to the harshness of the labor market, and urge job market candidates to start prepping non-academic options. (Better yet, admissions chairs should consider paring back cohort sizes.) Candidates who would like a proper job after graduating should be networking, hard. And candidates resolutely committed to academia should steel themselves for long hibernations as post docs, to wait out the coming storm.</p><p>On second thought, I will venture one dark prediction, for at least the near future.</p><p><strong>We’re going to see a lot more Substacks.</strong></p></blockquote><p>The wager, then, is that the future of intellectual life will be increasingly decentralized. Platforms like Substack are already siphoning off the kind of energy and analysis that once flowed into journals or policy shops.</p><p>As for the economics profession, the only real fix would be radical: every PhD program would have to coordinate and act like a cartel to slash admissions to dramatically reduce supply. Without that discipline, the system will keep flooding the market with useless doctorates, a Ponzi scheme destined to collapse under its own weight.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job/comments" rel=""><span>Leave a comment</span></a></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Germany must stand firmly against client-side scanning in Chat Control [pdf] (485 pts)]]></title>
            <link>https://signal.org/blog/pdfs/germany-chat-control.pdf</link>
            <guid>45464921</guid>
            <pubDate>Fri, 03 Oct 2025 16:44:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signal.org/blog/pdfs/germany-chat-control.pdf">https://signal.org/blog/pdfs/germany-chat-control.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45464921">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Is Just Another Boring, Desperate AI Startup (189 pts)]]></title>
            <link>https://www.wheresyoured.at/sora2-openai/</link>
            <guid>45464849</guid>
            <pubDate>Fri, 03 Oct 2025 16:37:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/sora2-openai/">https://www.wheresyoured.at/sora2-openai/</a>, See on <a href="https://news.ycombinator.com/item?id=45464849">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>What <em>is</em> OpenAI?</p><p>I realize you might say "a foundation model lab" or "the company that runs ChatGPT," but that doesn't really give the full picture of everything it’s promised, or claimed, or leaked that it was or would be.</p><p>No, really, if you believe its leaks to the press...</p><ul><li>OpenAI is a social media company, this week<a href="https://www.cnet.com/tech/services-and-software/openais-video-generator-gets-new-social-media-app-with-sora-2/?ref=wheresyoured.at"> <u>launching Sora 2, a social feed entirely made up of generative video</u></a>.</li><li>OpenAI is a workplace productivity company,<a href="https://www.computerworld.com/article/4021949/openai-goes-for-microsofts-jugular-its-office-productivity-suite.html?ref=wheresyoured.at"> <u>allegedly working on its own productivity suite to compete with Microsoft</u></a>.</li><li>OpenAI is a jobs portal,<a href="https://techcrunch.com/2025/09/04/openai-announces-ai-powered-hiring-platform-to-take-on-linkedin/?ref=wheresyoured.at"> <u>announcing in September it was "developing an AI-powered hiring platform</u></a>," which it will launch 'by mid-2026.</li><li>OpenAI is an ads company, and is apparently<a href="https://searchengineland.com/openai-staffing-chatgpt-ad-platform-462554?ref=wheresyoured.at"> <u>trying to hire an an ads chief</u></a>, with the (alleged) intent to start showing ads in ChatGPT "by 2026."</li><li>OpenAI is a company that would sell AI compute like Microsoft Azure or Amazon Web Services, or at least is considering being one,<a href="https://www.bloomberg.com/news/articles/2025-08-20/openai-may-sell-infrastructure-services-to-other-firms-cfo-says?ref=wheresyoured.at"> <u>with CFO Sarah Friar telling Bloomberg in August</u></a> that it is not "actively looking" at such an effort today but will "think about it as a business down the line, for sure."</li><li>OpenAI is a fabless semiconductor design company,<a href="https://www.reuters.com/business/openai-launch-its-first-ai-chip-2026-with-broadcom-ft-reports-2025-09-05/?ref=wheresyoured.at"> <u>launching its own AI chips in, again, 2026 with Broadcom</u></a>, but only for internal use.</li><li>OpenAI is a consumer hardware company, preparing to launch a device<a href="https://siliconangle.com/2025/09/19/report-openai-poaches-dozens-apple-employees-amid-consumer-hardware-push/?ref=wheresyoured.at"> <u>by the end of 2026 or early 2027 and hiring a bunch of Apple people to work on it</u></a>, as well as considering — again, it’s just leaking random stuff at this point to pump up its value — a smart speaker, a voice recorder and AR glasses.</li><li><a href="https://www.bleepingcomputer.com/news/artificial-intelligence/openai-prepares-chromium-based-ai-browser-to-take-on-google/?ref=wheresyoured.at"><u>OpenAI is also working on its own browser</u></a>, I guess.</li></ul><p>To be clear, many of these are ideas that OpenAI has leaked specifically so the media can continue to pump up its valuation and continue to raise the money it needs — at least<a href="https://www.wheresyoured.at/openai-onetrillion/"> <u>$1 Trillion</u></a> over the next four or five years, and I don't believe the theoretical (or actual) costs of many of the things I've listed are included.</p><p>OpenAI wants you to believe it is<a href="https://www.wheresyoured.at/the-case-against-generative-ai/#:~:text=%E2%80%9C-,AI%E2%80%9D%20was%20omnipresent,-%2C%20and%20it%20eventually"> <em><u>everything</u></em></a><em>,</em><strong> </strong>because in reality it’s a company bereft of strategy, focus or vision. The GPT-5 upgrade for ChatGPT was a dud — an industry-wide embarrassment for arguably the most-hyped product in AI history, one that (<a href="https://www.wheresyoured.at/how-does-gpt-5-work/"><u>as I revealed a few months ago</u></a>) costs more to operate than its predecessor, not because of any inherent capability upgrade, but how it actually processes the prompts its user provides — and now it's unclear what it is that this company <em>does.</em>&nbsp;</p><p>Does it make hardware? Software? Ads? Is it going to lease you GPUs to use for your own AI projects?<a href="https://openai.com/index/expanding-economic-opportunity-with-ai/?ref=wheresyoured.at"> <u>Is it going to certify you as an AI expert</u></a>? Notice how I've listed a whole bunch of stuff that <em>isn't ChatGPT,</em> which will,<a href="https://www.theinformation.com/articles/openai-says-business-will-burn-115-billion-2029?ref=wheresyoured.at&amp;rc=kz8jh3"> <u>if you look at The Information's reporting</u></a> of its projections, remain the vast majority of its revenue until 2027, at which point "agents" and "new products including free user monetization" will magically kick in.</p><figure><img src="https://www.wheresyoured.at/content/images/2025/10/data-src-image-05f160ec-b9a5-4412-bf31-f46fe3822519.png" alt="" loading="lazy" width="509" height="452"></figure><h2 id="openai-is-a-boring-and-bad-business"><strong>OpenAI Is A Boring (and Bad) Business</strong></h2><p>In reality, OpenAI is an extremely boring (and bad!) software business. It makes the majority of its revenue selling subscriptions to ChatGPT, and apparently had<a href="https://www.theverge.com/openai/640894/chatgpt-has-hit-20-million-paid-subscribers?ref=wheresyoured.at"> <u>20 million paid subscribers</u></a> (as of April) and<a href="https://www.cnbc.com/2025/08/01/openai-raise-chatgpt-users.html?ref=wheresyoured.at"> <u>5 million business subscribers</u></a> (as of August,<a href="https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/#:~:text=Here%E2%80%99s%20a%20hint%20though%3A"> <u>though 500,000 of them are Cal State University seats paid at $2.50 a month</u></a>).</p><p>It also loses incredibly large amounts of money.</p><h3 id="openais-pathetic-api-sales-have-effectively-turned-it-into-any-other-ai-startup"><strong>OpenAI's Pathetic API Sales Have Effectively Turned It Into Any Other AI Startup</strong></h3><p>Yes, I realize that OpenAI also sells access to its API, but as you can see from the chart above, it is making a <em>teeny tiny sliver</em> of revenue from it in 2025, though I will also add that this chart has a little bit of green for "agent" revenue, which means it's very likely bullshit.<a href="https://www.wheresyoured.at/deep-impact/#:~:text=OpenAI%20is%20as,these%20tasks%20yourself.%22"> <u>Operator, OpenAI's so-called agent, is barely functional</u></a>, and I have no idea how anyone would even begin to charge money for it outside of "please try my broken product."</p><p>In any case, API sales appear to be a very, very small part of OpenAI's revenue stream, and that heavily suggests a lack of interest in integrating its models at scale.</p><p>Worse still, this effectively turns OpenAI <em>into an AI startup.</em></p><p>Think about it: if OpenAI can't make the majority of its money through "innovating" in the development of large language models (LLMs), then it’s just another company plugging LLMs into its software. While ChatGPT may be a very popular product, it is, by definition (and in its name!) a GPT wrapper, with the few differences being that OpenAI pays its own immediate costs, has the people necessary to continue improving its own models, and also continually makes promises to convince people it’s <strong><em>anything other than just another AI startup.</em></strong></p><p>In fact, the only<em> real</em> difference is the amount of money backing it. Otherwise, OpenAI could be literally any foundation model company, and with a lack of real innovation within those models, it’s just another startup trying to find ways to monetize generative AI,<a href="https://www.wheresyoured.at/why-everybody-is-losing-money-on-ai/"> <u>an industry that only ever seems to lose money</u></a>.</p><p>As a result, we should start <em>evaluating </em>OpenAI as just another AI startup, as its promises do not appear to mesh with any coherent strategy, other than "<a href="https://www.wheresyoured.at/openai-onetrillion/"><u>we need $1 trillion dollars</u></a>." There does not seem to be much of a plan on a day-to-day basis, nor does there seem to be one about <em>what </em>OpenAI should be, other than that OpenAI will be a consumer hardware, consumer software, enterprise SaaS and data center operator, as well as running a social network.</p><p>As I've discussed<a href="https://www.wheresyoured.at/sam-altman-fried/#:~:text=Despite%20what%20fantasists"> <u>many</u></a><a href="https://www.wheresyoured.at/godot-isnt-making-it/#:~:text=data%20(April).-,I%20shared%20concerns,-in%20July%20that"> <u>times</u></a>, LLMs are inherently flawed due to their probabilistic nature."Hallucinations" — when a model authoritatively states something is true when it isn't (or takes an action that seems the most likely course of action, even if it isn't the right one) — are a "<a href="https://www.computerworld.com/article/4059383/openai-admits-ai-hallucinations-are-mathematically-inevitable-not-just-engineering-flaws.html?ref=wheresyoured.at"><u>mathematically inevitable</u></a>" according to OpenAI's own research feature of the technology, meaning that there is <em>no fixing their most glaring, obvious problem</em>, even with "perfect data."</p><p>I'd wager the reason OpenAI is so eager to build out so much capacity while leaking so many diverse business lines is an attempt to get away from a dark truth: that when you peel away the hype, ChatGPT is a wrapper, every product it makes is a wrapper, <em>and OpenAI is pretty fucking terrible at making products.</em></p><p>Today I'm going to walk you through a fairly unique position: that OpenAI is just another boring AI startup lacking any meaningful product roadmap or strategy, using the press as a tool to pump its bags while very rarely delivering on what it’s promised. It is a company with massive amounts of cash, industrial backing, and brand recognition, and otherwise is, much like its customers, desperately trying to work out how to make money selling products built on top of Large Language Models.</p><p>OpenAI lives and dies on its mythology as the center of innovation in the world of AI, yet reality is so much more mediocre. Its revenue growth is slowing, its products are commoditized, its models are hardly state-of-the-art,<a href="https://www.wheresyoured.at/the-case-against-generative-ai/"> <u>the overall generative AI industry has lost its sheen</u></a>, and its killer app is a mythology that has converted a handful of very rich people and very few others.</p><p>OpenAI spent,<a href="https://www.theinformation.com/articles/openais-first-half-results-4-3-billion-sales-2-5-billion-cash-burn?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>according to The Information</u></a>, 150% ($6.7 billion in costs) of its H1 2025 revenue ($4.3 billion) on research and development, producing<a href="https://www.wheresyoured.at/how-does-gpt-5-work/"> <u>the deeply-underwhelming GPT-5</u></a> and Sora 2, an app that I estimate costs it upwards of $5 for each video generation,<a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/?ref=wheresyoured.at"> <u>based on Azure's published rates for the first Sora model</u></a>, though it's my belief that these rates are unprofitable, all so that it can gain a few more users.</p><p>To be clear, R&amp;D is good, and useful, and in my experience, the companies that spend deeply on this tend to be the ones that do well. The reason why Huawei has managed to outpace its American rivals in several key areas — like automotive technology and telecommunications — is because it <a href="https://www.rcrwireless.com/20250902/5g/huawei-spending?ref=wheresyoured.at"><u>spends around a quarter of its revenue</u></a> on developing new technologies and entering new markets, rather than stock buybacks and dividends.</p><p>The difference is that said R&amp;D spending is both sustainable and useful, and has led to Huawei becoming much a stronger business, even <a href="https://www.federalregister.gov/documents/2019/05/21/2019-10616/addition-of-entities-to-the-entity-list?ref=wheresyoured.at"><u>as it languishes on a Treasury Department entity list that effectively cuts it off from US-made or US-origin parts or IP</u></a>. Considering that OpenAI’s R&amp;D spending <em>was 38.28% of its cash-on-hand</em> by the end of the period (totalling $17.5bn, which we’ll get to later), and what we’ve seen as a result, it’s hard to describe it as <em>either</em> sustainable <em>or</em> useful.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>OpenAI isn't <em>innovative,</em> it’s <em>exploitative, </em>a giant multi-billion dollar grift attempting to hide how deeply <em>unexciting</em> it is, and how nonsensical it is to continue backing it<em>.</em> Sam Altman is an excellent operator, capable of spreading his mediocre, half-baked mantras about<a href="https://bsky.app/profile/politico.com/post/3m25ob7qipc2s?ref=wheresyoured.at"> <u>how 2025 was the year AI got smarter than us</u></a>, or<a href="https://www.businessinsider.com/sam-altman-ai-infrastructure-1-gw-per-week-stargate-2025-9?ref=wheresyoured.at"> <u>how we'll be building 1GW data centers each week</u></a> (something that, by my estimations, takes 2.5 years), taking advantage of how many people in the media, markets and global governments don't know a fucking <em>thing</em> about anything.</p><p>OpenAI is&nbsp; also getting desperate.</p><p>Beneath the surface of the media hype and trillion-dollar promises is a company struggling to maintain relevance, its entire existence built on top of hype and mythology.</p><p>And at this rate, I believe it’s going to miss its 2025 revenue projections, all while burning billions more than anyone has anticipated.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cancelling async Rust (138 pts)]]></title>
            <link>https://sunshowers.io/posts/cancelling-async-rust/</link>
            <guid>45464632</guid>
            <pubDate>Fri, 03 Oct 2025 16:18:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sunshowers.io/posts/cancelling-async-rust/">https://sunshowers.io/posts/cancelling-async-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=45464632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>This is an edited, written version of my RustConf 2025 talk about cancellations in async Rust. Like <a href="https://sunshowers.io/posts/beyond-ctrl-c-signals/">the written version of my RustConf 2023 talk</a>, I’ve tried to retain the feel of a talk while making it readable as a standalone blog entry. Some links:</em></p><ul><li><em><a href="https://www.youtube.com/watch?v=zrv5Cy1R7r4">Video of the talk</a> on YouTube.</em></li><li><em><a href="https://docs.google.com/presentation/u/1/d/e/2PACX-1vTMc4EdHRf6ulz-xaAhZFGZwxJ7jPQgYWczT6pEIvwfXILV4ZEgMdLuoRh70bgh9SP7mxblEnyXuZD0/pub?start=false&amp;loop=false&amp;delayms=60000">Slides</a> on Google Slides.</em></li><li><em><a href="https://github.com/sunshowers/cancelling-async-rust">Repository with links and notes</a> on GitHub.</em></li><li><em><a href="https://lwn.net/Articles/1036924/">Coverage on Linux Weekly News</a>.</em></li></ul><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/zrv5Cy1R7r4?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe></p><h2 id="introduction">Introduction<a href="#introduction" arialabel="Anchor">#</a></h2><p>Let’s start with a simple example – you decide to read from a channel in a loop and gather a bunch of messages:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span><span>rx</span><span>.</span><span>recv</span><span>().</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>msg</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>process</span><span>(</span><span>msg</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>All good, nothing wrong with this, but you realize sometimes the channel is empty for long periods of time, so you add a timeout and print a message:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span><span>timeout</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>5</span><span>),</span><span> </span><span>rx</span><span>.</span><span>recv</span><span>()).</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Ok</span><span>(</span><span>msg</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>process</span><span>(</span><span>msg</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Err</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"no messages for 5 seconds"</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>There’s nothing wrong with this code—it behaves as expected.</p><p>Now you realize you need to write a bunch of messages out to a channel in a loop:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>msg</span><span> </span><span>=</span><span> </span><span>next_message</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span><span>tx</span><span>.</span><span>send</span><span>(</span><span>msg</span><span>).</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"sent successfully"</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>But sometimes the channel gets too full and blocks, so you add a timeout and print a message:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>msg</span><span> </span><span>=</span><span> </span><span>next_message</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span><span>timeout</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>5</span><span>),</span><span> </span><span>tx</span><span>.</span><span>send</span><span>(</span><span>msg</span><span>)).</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Ok</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"sent successfully"</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Err</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"no space for 5 seconds"</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>It turns out that <em>this</em> code is often incorrect, because not all messages make their way to the channel.</p><p>Hi, I’m Rain, and this post is about cancelling async Rust. This post is split into three parts:</p><ol><li><a href="https://sunshowers.io/posts/cancelling-async-rust/#1-what-is-cancellation"><em>What is cancellation?</em></a> It’s an extremely powerful part of async Rust but also one that is very hard to reason thoroughly about.</li><li><a href="https://sunshowers.io/posts/cancelling-async-rust/#2-analyzing-cancellations"><em>Analyzing cancellations:</em></a> Going deep into their mechanics and providing some helpful ways to think about them.</li><li><a href="https://sunshowers.io/posts/cancelling-async-rust/#3-what-can-be-done"><em>What can be done?</em></a> Solutions, including practical guidance, and real bugs we’ve found and fixed in production codebases.</li></ol><p>Before we begin, I want to lay my cards on the table – I really love async Rust!</p><figure><img src="https://sunshowers.io/images/beyond-ctrl-c.jpg" alt="Me speaking at RustConf 2023. Beyond Ctrl-C: The dark corners of Unix signal handling."><figcaption>Me speaking at RustConf 2023.</figcaption></figure><ul><li><p>I gave <a href="https://sunshowers.io/posts/beyond-ctrl-c-signals/">a talk</a> at RustConf a couple years ago talking about how async Rust is a great fit for signal handling in complex applications.</p></li><li><p>I’m also the author of <a href="https://nexte.st/">cargo-nextest</a>, a next-generation test runner for Rust, where async Rust is the best way I know of to express some really complex algorithms that I wouldn’t know how to express otherwise. I wrote <a href="https://sunshowers.io/posts/nextest-and-tokio/">a blog post</a> about this a few years ago.</p></li></ul><p>Now, I work at <a href="https://oxide.computer/">Oxide Computer Company</a>, where we make <em>cloud-in-a-box computers</em>. We make vertically integrated systems where you provide power and networking on one end, and the software you want to run on the other end, and we take care of everything in between.</p><p>Of course, we use Rust everywhere, and in particular we use async Rust extensively for our higher-level software, such as <a href="https://github.com/oxidecomputer/crucible">storage</a>, <a href="https://github.com/oxidecomputer/maghemite">networking</a> and the <a href="https://github.com/oxidecomputer/omicron/">customer-facing management API</a>. But along the way we’ve encountered a number of issues around async cancellation, and a lot of this post is about what we learned along the way.</p><h2 id="1-what-is-cancellation">1. What is cancellation?<a href="#1-what-is-cancellation" arialabel="Anchor">#</a></h2><p>What does cancellation mean? Logically, a cancellation is exactly what it sounds like: you start some work, and then change your mind and decide to stop doing that work.</p><p>As you might imagine this is a useful thing to do:</p><ul><li>You may have started a large download or a long network request</li><li>Maybe you’ve started reading a file, similar to the <code>head</code> command.</li></ul><p>But then you change your mind: you want to cancel it rather than continue it to completion.</p><h3 id="cancellations-in-synchronous-rust">Cancellations in synchronous Rust<a href="#cancellations-in-synchronous-rust" arialabel="Anchor">#</a></h3><p>Before we talk about async Rust, it’s worth thinking about how you’d do cancellations in synchronous Rust.</p><p>One option is to have some kind of <em>flag</em> you periodically check, maybe stored in an atomic:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>while</span><span> </span><span>!</span><span>should_cancel</span><span>.</span><span>load</span><span>(</span><span>Ordering</span>::<span>Relaxed</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>expensive_operation</span><span>();</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><ul><li>The code that wishes to perform the cancellation can set that flag.</li><li>Then, the code which checks that flag can exit early.</li></ul><p>This approach is fine for smaller bits of code but doesn’t really scale well to large chunks of code since you’d have to sprinkle these checks everywhere.</p><p>A related option, if you’re working with a framework as part of your work, is to <em>panic with a special payload</em> of some kind.</p><ul><li>If that feels strange to you, you’re not alone! But the <a href="https://github.com/salsa-rs/salsa">Salsa</a> framework for incremental computation, used by—among other things—<a href="https://github.com/rust-lang/rust-analyzer">rust-analyzer</a>, uses this approach.</li><li>Something I learned recently was that this only works on build targets which have a notion of <a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html">panic unwinding</a>, or being able to bubble up the panic. Not all platforms support this, and in particular, <a href="https://webassembly.org/">Wasm</a> doesn’t. This means that Salsa cancellations don’t work if you build rust-analyzer for Wasm.</li></ul><p>A third option is to <em>kill the whole process</em>. This is a <em>very heavyweight</em> approach, but an effective one in case you spawn processes to do your work.</p><p>Rather than kill the whole process, can you kill a single thread?</p><ul><li>While <a href="https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-terminatethread">some OSes have APIs</a> to perform this action, they tend to warn very strongly against it. That’s because in general, most code is <a href="https://sunshowers.io/posts/nextest-process-per-test/#appendix">just not ready</a> for a thread disappearing from underneath.</li><li>In particular, thread killing is not permitted by safe Rust, since it can cause serious corruption. For example, Rust mutexes would likely stay locked forever.</li></ul><p>All of these options are suboptimal or of limited use in some way. In general, the way I think about it is that there isn’t a <em>universal protocol</em> for cancellation in synchronous Rust.</p><p>In contrast, there <em>is</em> such a protocol in async Rust, and in fact cancellations are extraordinarily easy to perform in async Rust.</p><p>Why is that so? To understand that, let’s look at what a future is.</p><h3 id="what-is-a-future">What is a future?<a href="#what-is-a-future" arialabel="Anchor">#</a></h3><p>Here’s a simple example of a future:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>// This creates a state machine.
</span></span></span><span><span><span></span><span>let</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>request</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>process</span><span>(</span><span>data</span><span>).</span><span>await</span><span>
</span></span></span><span><span><span></span><span>};</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// Nothing executes yet. `future` is just a struct in memory.
</span></span></span></code></pre></div><p>In this future, you first perform a network request which returns some data, and then you process it.</p><p>The Rust compiler looks at this future and generates a state machine, which is just a struct or enum in memory:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>// The compiler generates something like:
</span></span></span><span><span><span></span><span>enum</span> <span>MyFuture</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>Start</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>WaitingForNetwork</span><span>(</span><span>NetworkFuture</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>WaitingForProcess</span><span>(</span><span>ProcessFuture</span><span>,</span><span> </span><span>Data</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>Done</span><span>(</span><span>Result</span><span>),</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// It's just data, no running code!
</span></span></span></code></pre></div><p>If you’ve written async Rust before the <code>async</code> and <code>await</code> keywords, you’ve probably written code like it by hand. It’s basically just an enum describing all the possible states the future can be in.</p><p>The compiler also generates an implementation of <a href="https://doc.rust-lang.org/std/future/trait.Future.html">the <code>Future</code> trait</a> for this future:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>impl</span><span> </span><span>Future</span><span> </span><span>for</span><span> </span><span>MyFuture</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>poll</span><span>(</span><span>/* ... */</span><span>)</span><span> </span>-&gt; <span>Poll</span><span>&lt;</span><span>Self</span>::<span>Output</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>match</span><span> </span><span>self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>Start</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>            </span><span>WaitingForNetwork</span><span>(</span><span>fut</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>            </span><span>// etc
</span></span></span><span><span><span></span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>and when you call <code>.await</code> on the future, it gets translated down to this underlying <code>poll</code> function. It is only when <code>await</code> or this <code>poll</code> function is called that something actually happens.</p><p>Note that this is diametrically opposed to how async works in other languages like Go, JavaScript, or C#. In those languages, when you create a future to await on, it starts doing its thing, immediately, in the background:</p><div><pre tabindex="0"><code data-lang="js"><span><span><span>// JavaScript: starts running immediately
</span></span></span><span><span><span></span><span>const</span> <span>promise</span> <span>=</span> <span>fetch</span><span>(</span><span>'/api/data'</span><span>);</span>
</span></span></code></pre></div><p>That’s regardless of whether you await it or not.</p><p>In Rust, this <code>get</code> call does nothing until you actually call <code>.await</code> on it:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>// Rust: just data, does nothing!
</span></span></span><span><span><span></span><span>let</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>reqwest</span>::<span>get</span><span>(</span><span>"/api/data"</span><span>);</span><span>
</span></span></span></code></pre></div><p>I know I sound a bit like a broken record here, but if you can take away one thing from this post, it would be that futures are passive, and completely inert until awaited or polled.</p><h3 id="the-universal-protocol">The universal protocol<a href="#the-universal-protocol" arialabel="Anchor">#</a></h3><p>So what does the universal protocol to cancel futures look like? It is simply to <em>drop</em> the future, or to not await it, or poll it any more. Since a future is just a state machine, you can throw it away at any time the poll function isn’t actively being called.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>some_async_work</span><span>();</span><span>
</span></span></span><span><span><span></span><span>drop</span><span>(</span><span>future</span><span>);</span><span> </span><span>// cancelled
</span></span></span></code></pre></div><p>The upshot of all this is that any Rust future can be cancelled at any await point.</p><p>Given how hard cancellation tends to be in synchronous environments, the ability to easily cancel futures in async Rust is extraordinarily powerful—in many ways its greatest strength!</p><p>But there is a flip side, which is that cancelling futures is far, far too easy. This is for two reasons.</p><ol><li><p>First, it’s just way too easy to quietly drop a future. As we’re going to see, there are all kinds of code patterns that lead to silently dropping futures.</p></li><li><p>Now this wouldn’t be so bad, if not for the second reason: that cancellation of parent futures propagates down to child futures.</p><p>Because of Rust’s <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">single ownership model</a>, child futures are owned by parent ones. If a parent future is dropped or cancelled, the same happens to the child.</p><p>To figure out whether a child future’s cancellation can cause issues, you have to look at its parent, and grandparent, and so on. Reasoning about cancellation becomes a very complicated <em>non-local operation</em>.</p></li></ol><h2 id="2-analyzing-cancellations">2. Analyzing cancellations<a href="#2-analyzing-cancellations" arialabel="Anchor">#</a></h2><p>I’m going to cover some examples in a bit, but before we do that I want to talk about a couple terms, some of which you might have seen references to already.</p><h3 id="cancel-safety-and-cancel-correctness">Cancel safety and cancel correctness<a href="#cancel-safety-and-cancel-correctness" arialabel="Anchor">#</a></h3><p>The first term is <strong>cancel safety</strong>. You might have seen mentions of this in the Tokio documentation. Cancel safety, as generally defined, means the property of a future that can be cancelled (i.e. dropped) without any side effects.</p><p>For example, a <a href="https://docs.rs/tokio/latest/tokio/time/fn.sleep.html">Tokio sleep future</a> is cancel safe: you can just stop waiting on the sleep and it’s completely fine.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>tokio</span>::<span>time</span>::<span>sleep</span><span>();</span><span>
</span></span></span><span><span><span></span><span>drop</span><span>(</span><span>future</span><span>);</span><span> </span><span>// this has no side effects
</span></span></span></code></pre></div><p>An example of a future that is not cancel safe is <a href="https://docs.rs/tokio/latest/tokio/sync/mpsc/struct.Sender.html#method.send">Tokio’s MPSC send</a>, which sends a message over a channel:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>message</span><span> </span><span>=</span><span> </span><span>/* ... */</span><span>;</span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>sender</span><span>.</span><span>send</span><span>(</span><span>message</span><span>);</span><span>
</span></span></span><span><span><span></span><span>drop</span><span>(</span><span>future</span><span>);</span><span> </span><span>// message is lost!
</span></span></span></code></pre></div><p>If this future is dropped, the message is lost forever.</p><p>The important thing is that cancel safety is a <em>local property</em> of an <em>individual future</em>.</p><p>But cancel safety is not all that one needs to care about. What actually matters is the context the cancellation happens in, or in other words whether the cancellation actually causes some kind of larger property in the system to be violated.</p><ul><li>For example, if you drop a future which sends a message, but for whatever reason you don’t care about the message any more, it’s not really a bug!</li></ul><p>To capture this I tend to use a different term called <strong>cancel correctness</strong>, which I define as a <em>global property</em> of <em>system correctness</em> in the face of cancellations. (This isn’t a standard term, but it’s a framing I’ve found really helpful in understanding cancellations.)</p><p>When is cancel correctness violated? It requires three things:</p><ol><li><p><em>The system has a cancel-unsafe future somewhere within it.</em> As we’ll see, many APIs that are cancel-unsafe can be reworked to be cancel-safe. If there aren’t any cancel-unsafe futures in the system, then the system is cancel correct.</p></li><li><p><em>A cancel-unsafe future is actually cancelled.</em> This may sound a bit trivial, but if cancel-unsafe futures are always run to completion, then the system can’t have cancel correctness bugs.</p></li><li><p><em>Cancelling the future violates some property of a system.</em> This could be data loss as with <code>Sender::send</code>, some kind of invariant violation, or some kind of cleanup that must be performed but isn’t.</p></li></ol><p>So a lot of making Rust async robust is about trying to tackle one of these three things.</p><p>I want to zoom in for a second on invariant violations and talk about an example of a Tokio API that is very prone to cancel correctness issues: <a href="https://docs.rs/tokio/latest/tokio/sync/struct.Mutex.html">Tokio mutexes</a>.</p><h3 id="the-pain-of-tokio-mutexes">The pain of Tokio mutexes<a href="#the-pain-of-tokio-mutexes" arialabel="Anchor">#</a></h3><p>The way Tokio mutexes work is: you create a mutex, you lock it which gives you mutable access to the data underneath, and then you unlock it by releasing the mutex.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>guard</span><span> </span><span>=</span><span> </span><span>mutex</span><span>.</span><span>lock</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span></span><span>// Access guard.data, protected by the mutex...
</span></span></span><span><span><span></span><span>drop</span><span>(</span><span>guard</span><span>);</span><span>
</span></span></span></code></pre></div><p>If you look at the <a href="https://docs.rs/tokio/latest/tokio/sync/struct.Mutex.html#method.lock"><code>lock</code> function’s documentation</a>, in the “cancel safety” section it says:</p><blockquote><p>This method uses a queue to fairly distribute locks in the order they were requested. Cancelling a call to lock makes you lose your place in the queue.</p></blockquote><p>Okay, so not totally cancel safe, but the only kind of unsafety is fairness, which doesn’t sound too bad.</p><p>But the problems lie in what you actually do with the mutex. In practice, most uses of mutexes are in order to <em>temporarily violate invariants</em> that are otherwise upheld when a lock isn’t held.</p><p>I’ll use a real world example of a cancel correctness bug that we found at my job at Oxide: we had code to manage a bunch of data sent over by our computers, which we call sleds. The shared state was guarded by a mutex, and a typical operation was:</p><ol><li>Obtain a lock on the mutex.</li><li>Obtain the sled-specific data by value, moving it to an invalid <code>None</code> state.</li><li>Perform an action.</li><li>Set the sled-specific data back to the next valid state.</li></ol><p>Here’s a rough sketch of what that looks like:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>guard</span><span> </span><span>=</span><span> </span><span>mutex</span><span>.</span><span>lock</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span></span><span>// guard.data is Option&lt;T&gt;: Some to begin with
</span></span></span><span><span><span></span><span>let</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>guard</span><span>.</span><span>data</span><span>.</span><span>take</span><span>();</span><span> </span><span>// guard.data is now None
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>new_data</span><span> </span><span>=</span><span> </span><span>process_data</span><span>(</span><span>data</span><span>);</span><span>
</span></span></span><span><span><span></span><span>guard</span><span>.</span><span>data</span><span> </span><span>=</span><span> </span><span>Some</span><span>(</span><span>new_data</span><span>);</span><span> </span><span>// guard.data is Some again
</span></span></span></code></pre></div><p>This is all well and good, but the problem is that the action being performed actually had an await point within it:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>guard</span><span> </span><span>=</span><span> </span><span>mutex</span><span>.</span><span>lock</span><span>().</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span></span><span>// guard.data is Option&lt;T&gt;: Some to begin with
</span></span></span><span><span><span></span><span>let</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>guard</span><span>.</span><span>data</span><span>.</span><span>take</span><span>();</span><span> </span><span>// guard.data is now None
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>// DANGER: cancellation here leaves data in None state!
</span></span></span><span><span><span></span><span>let</span><span> </span><span>new_data</span><span> </span><span>=</span><span> </span><span>process_data</span><span>(</span><span>data</span><span>).</span><span>await</span><span>;</span><span>
</span></span></span><span><span><span></span><span>guard</span><span>.</span><span>data</span><span> </span><span>=</span><span> </span><span>Some</span><span>(</span><span>new_data</span><span>);</span><span> </span><span>// guard.data is Some again
</span></span></span></code></pre></div><p>If the code that operated on the mutex got cancelled at that await point, then the data would be stuck in the invalid <code>None</code> state. Not great!</p><p>And keep in mind the non-local reasoning aspect: when doing this analysis, you need to look at the whole chain of callers.</p><h3 id="cancellation-patterns">Cancellation patterns<a href="#cancellation-patterns" arialabel="Anchor">#</a></h3><p>Now that we’ve talked about some of the bad things that can happen during cancellations, it’s worth asking what kinds of code patterns lead to futures being cancelled.</p><p>The most straightforward example, and maybe a bit of a silly one, is that you create a future but simply forget to call <code>.await</code> on it.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>some_async_work</span><span>();</span><span> </span><span>// missing .await
</span></span></span></code></pre></div><p>Now Rust actually warns you if you don’t call <code>.await</code> on the future:</p><div><pre tabindex="0"><code data-lang="text"><span><span>warning: unused implementer of `Future` that must be used
</span></span><span><span>   |
</span></span><span><span>11 |     some_async_work();
</span></span><span><span>   |     ^^^^^^^^^^^^^^^^^
</span></span><span><span>   |
</span></span><span><span>   = note: futures do nothing unless you `.await` or poll them
</span></span></code></pre></div><p>But a code pattern I’ve sometimes made mistakes with is that the future returns a <code>Result</code>, and you want to ignore the result so you assign it to an underscore like so:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>_</span><span> </span><span>=</span><span> </span><span>some_async_work</span><span>();</span><span> </span><span>// future returns Result
</span></span></span></code></pre></div><p>If I forget to call <code>.await</code> on the future, Rust doesn’t warn me about it at all, and then I’m left scratching my head about why this code didn’t run. I know this sounds really silly and basic, but I’ve made this mistake a bunch of times.</p><p><em>(After my talk, it was pointed out to me that Clippy 1.67 and above have a <a href="https://rust-lang.github.io/rust-clippy/master/index.html#let_underscore_future"><code>let_underscore_future</code></a> warn-by-default lint for this. Hooray!)</em></p><p>Another example of futures being cancelled is <code>try</code> operations, such as Tokio’s <a href="https://docs.rs/tokio/latest/tokio/macro.try_join.html"><code>try_join</code> macro</a>. For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>async</span><span> </span><span>fn</span> <span>do_stuff_async</span><span>()</span><span> </span>-&gt; <span>Result</span><span>&lt;</span><span>(),</span><span> </span><span>&amp;</span><span>'static</span><span> </span><span>str</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// async work
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>async</span><span> </span><span>fn</span> <span>more_async_work</span><span>()</span><span> </span>-&gt; <span>Result</span><span>&lt;</span><span>(),</span><span> </span><span>&amp;</span><span>'static</span><span> </span><span>str</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>// more here
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>res</span><span> </span><span>=</span><span> </span><span>tokio</span>::<span>try_join!</span><span>(</span><span>
</span></span></span><span><span><span>    </span><span>do_stuff_async</span><span>(),</span><span>
</span></span></span><span><span><span>    </span><span>more_async_work</span><span>(),</span><span>
</span></span></span><span><span><span></span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// ...
</span></span></span></code></pre></div><p>If you call <code>try_join</code> with a bunch of futures, and all of them succeed, it’s all good. But if one of them fails, the rest simply get cancelled.</p><p>In fact, at Oxide we had a pretty bad bug around this: we had code to stop a bunch of services, all expressed as futures. We used <code>try_join</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>try_join!</span><span>(</span><span>
</span></span></span><span><span><span>    </span><span>stop_service_a</span><span>(),</span><span>
</span></span></span><span><span><span>    </span><span>stop_service_b</span><span>(),</span><span>
</span></span></span><span><span><span>    </span><span>stop_service_c</span><span>(),</span><span>
</span></span></span><span><span><span></span><span>)</span><span>?</span><span>;</span><span>
</span></span></span></code></pre></div><p>If one of these operations failed for whatever reason, we would stop running the code to wait for the other services to exit. Oops!</p><p>But perhaps the most well-known source of cancellations is Tokio’s <a href="https://docs.rs/tokio/latest/tokio/macro.select.html"><code>select</code> macro</a>. Select is this incredibly beautiful operation. It is called with a set of futures, and it drives all of them forward concurrently:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>tokio</span>::<span>select!</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>result1</span><span> </span><span>=</span><span> </span><span>future1</span><span> </span><span>=&gt;</span><span> </span><span>handle_result1</span><span>(</span><span>result1</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>result2</span><span> </span><span>=</span><span> </span><span>future2</span><span> </span><span>=&gt;</span><span> </span><span>handle_result2</span><span>(</span><span>result2</span><span>),</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Each future has a code block associated with it (above, <code>handle_result1</code> and <code>handle_result2</code>). If one of the futures completes, the corresponding code block is called. But also, all of the other futures are always cancelled!</p><p>For a variety of reasons, select statements in general, and <em>select loops</em> in particular, are particularly prone to cancel correctness issues. So a lot of the documentation about cancel safety talks about select loops. But I want to emphasize here that select is not the <em>only</em> source of cancellations, just a particularly <em>notable</em> one.</p><h2 id="3-what-can-be-done">3. What can be done?<a href="#3-what-can-be-done" arialabel="Anchor">#</a></h2><p>So, now that we’ve looked at all of these issues with cancellations, what can be done about it?</p><p>First, I want to break the bad news to you – there is <em>no general, fully reliable solution for this</em> in Rust today. But in our experience there are a few patterns that have been successful at reducing the likelihood of cancellation bugs.</p><p>Going back to our definition of cancel correctness, there are three prongs all of which come together to produce a bug:</p><ul><li>A cancel-unsafe future exists</li><li>This cancel-unsafe future is cancelled</li><li>The cancellation violates a system property</li></ul><p>Most solutions we’ve come up with try and tackle one of these prongs.</p><h3 id="making-futures-cancel-safe">Making futures cancel-safe<a href="#making-futures-cancel-safe" arialabel="Anchor">#</a></h3><p>Let’s look at the first prong: the system has a cancel-unsafe future somewhere in it. Can we use code patterns to make futures be cancel-safe? It turns out we can! I’ll give you two examples here.</p><p>The first is MPSC sends. Let’s come back to the example from earlier where we would lose messages entirely:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>msg</span><span> </span><span>=</span><span> </span><span>next_message</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span><span>timeout</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>5</span><span>),</span><span> </span><span>tx</span><span>.</span><span>send</span><span>(</span><span>msg</span><span>)).</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Ok</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"sent successfully"</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>Ok</span><span>(</span><span>Err</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"no space for 5 seconds"</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Can we find a way to make this cancel safe?</p><p>In this case, yes, and we do so by breaking up the operation into two parts:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>msg</span><span> </span><span>=</span><span> </span><span>next_message</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>match</span><span> </span><span>timeout</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>5</span><span>),</span><span> </span><span>tx</span><span>.</span><span>reserve</span><span>()).</span><span>await</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>Ok</span><span>(</span><span>Ok</span><span>(</span><span>permit</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span> </span><span>permit</span><span>.</span><span>send</span><span>(</span><span>msg</span><span>);</span><span> </span><span>break</span><span>;</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>            </span><span>Ok</span><span>(</span><span>Err</span><span>(</span><span>_</span><span>))</span><span> </span><span>=&gt;</span><span> </span><span>return</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>Err</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"no space for 5 seconds"</span><span>),</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><ul><li>The first component is the operation to <a href="https://docs.rs/tokio/latest/tokio/sync/mpsc/struct.Sender.html#method.reserve">reserve a permit</a> or slot in the channel. This is an initial async operation that’s cancel-safe.</li><li>The second is to actually <a href="https://docs.rs/tokio/latest/tokio/sync/mpsc/struct.Permit.html#method.send">send the message</a>, which is an operation that becomes infallible.</li></ul><p>(I want to put an asterisk here that reserve is not entirely cancel-safe, since Tokio’s MPSC follows a first-in-first-out pattern and dropping the future means losing your place in line. Keep this in mind for now.)</p><hr><p>The second is with <a href="https://docs.rs/tokio/latest/tokio/io/trait.AsyncWrite.html">Tokio’s <code>AsyncWrite</code></a>.</p><p>If you’ve written synchronous Rust you’re probably familiar with <a href="https://doc.rust-lang.org/std/io/trait.Write.html#method.write_all">the <code>write_all</code> method</a>, which writes an entire buffer out:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>std</span>::<span>io</span>::<span>Write</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>buffer</span>: <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span> </span><span>=</span><span> </span><span>/* ... */</span><span>;</span><span>
</span></span></span><span><span><span></span><span>writer</span><span>.</span><span>write_all</span><span>(</span><span>buffer</span><span>)</span><span>?</span><span>;</span><span>
</span></span></span></code></pre></div><p>In synchronous Rust, this is a great API. But within async Rust, the <code>write_all</code> pattern is absolutely not cancel safe! If the future is dropped before completion, you have no idea how much of this buffer was written out.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>tokio</span>::<span>io</span>::<span>AsyncWriteExt</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>buffer</span>: <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span> </span><span>=</span><span> </span><span>/* ... */</span><span>;</span><span>
</span></span></span><span><span><span></span><span>writer</span><span>.</span><span>write_all</span><span>(</span><span>buffer</span><span>).</span><span>await</span><span>?</span><span>;</span><span> </span><span>// Not cancel-safe!
</span></span></span></code></pre></div><p>But there’s an alternative API that is cancel-safe, called <a href="https://docs.rs/tokio/latest/tokio/io/trait.AsyncWriteExt.html#method.write_all_buf"><code>write_all_buf</code></a>. This API is carefully designed to enable the reporting of partial progress, and it doesn’t just accept a <em>buffer</em>, but rather something that looks like a cursor on top of it:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>tokio</span>::<span>io</span>::<span>AsyncWriteExt</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>let</span><span> </span><span>mut</span><span> </span><span>buffer</span>: <span>io</span>::<span>Cursor</span><span>&lt;&amp;</span><span>[</span><span>u8</span><span>]</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>/* ... */</span><span>;</span><span>
</span></span></span><span><span><span></span><span>writer</span><span>.</span><span>write_all_buf</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>buffer</span><span>).</span><span>await</span><span>?</span><span>;</span><span>
</span></span></span></code></pre></div><p>When part of the buffer is written out, the cursor is advanced by that number of bytes. So if you call <code>write_all_buf</code> in a loop, you’ll be resuming from this partial progress, which works great.</p><h3 id="not-cancelling-futures">Not cancelling futures<a href="#not-cancelling-futures" arialabel="Anchor">#</a></h3><p>Going back to the three prongs: the second prong is about actually cancelling futures. What code patterns can be used to not cancel futures? Here are a couple of examples.</p><p>The first one is, in a place like a select loop, resume futures rather than cancelling them each time. You’d typically achieve this by <a href="https://doc.rust-lang.org/std/pin/">pinning a future</a>, and then polling a mutable reference to that future. For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>mut</span><span> </span><span>future</span><span> </span><span>=</span><span> </span><span>Box</span>::<span>pin</span><span>(</span><span>channel</span><span>.</span><span>reserve</span><span>());</span><span>
</span></span></span><span><span><span></span><span>loop</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>tokio</span>::<span>select!</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>result</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>future</span><span> </span><span>=&gt;</span><span> </span><span>break</span><span> </span><span>result</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>_</span><span> </span><span>=</span><span> </span><span>other_condition</span><span> </span><span>=&gt;</span><span> </span><span>continue</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Coming back to our example of MPSC sends, the one asterisk with <code>reserve</code> is that cancelling it makes you lose your place in line. Instead, if you pin the <code>reserve</code> future and poll a mutable reference to it, you don’t lose your place in line.</p><p>(Does the difference here matter? It depends, but you can now have this strategy available to you.)</p><hr><p>The second example is to use tasks. I mentioned earlier that futures are Rust are diametrically opposed to similar notions in languages like JavaScript. Well, there’s an alternative in async Rust that’s much closer to the JavaScript idea, and that’s <a href="https://docs.rs/tokio/latest/tokio/task/">tasks</a>.</p><ul><li>Unlike futures which are driven by the caller, tasks are driven by the runtime (such as Tokio).</li><li>With Tokio, dropping a handle to a task does not cause it to be cancelled, which means they’re a good place to run cancel-unsafe code.</li></ul><p>A fun example is that at Oxide, we have an HTTP server called <a href="https://docs.rs/dropshot">Dropshot</a>. Previously, whenever an HTTP request came in, we’d use a future for it, and drop the future if the TCP connection was closed.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>// Before: Future cancelled on TCP close
</span></span></span><span><span><span></span><span>handle_request</span><span>(</span><span>req</span><span>).</span><span>await</span><span>;</span><span>
</span></span></span></code></pre></div><p>This was really bad because future cancellations could happen due to the behavior of not just the parent future, but of a process that was running across a network! This is a rather extreme form of non-local reasoning.</p><p>We addressed this by spinning up a task for each HTTP request, and by running the code to completion even if the connection is closed:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>// After: Task runs to completion
</span></span></span><span><span><span></span><span>tokio</span>::<span>spawn</span><span>(</span><span>handle_request</span><span>(</span><span>req</span><span>));</span><span>
</span></span></span></code></pre></div><h3 id="systematic-solutions">Systematic solutions?<a href="#systematic-solutions" arialabel="Anchor">#</a></h3><p>The last thing I want to say is that <strong>this sucks</strong>!</p><p>The promise of Rust is that you don’t need to do this kind of non-local reasoning—that you can analyze small bits of code for local correctness, and scale that up to global correctness. Almost everything in Rust, from <code>&amp;</code> and <code>&amp;mut</code> to <code>unsafe</code>, is geared towards making that possible. Future cancellations fly directly in the face of that, and I think they’re probably the <strong>least Rusty part of Rust</strong>. This is all really unfortunate.</p><p>Can we come up with something more systematic than this kind of ad-hoc reasoning?</p><p>There doesn’t exist anything in safe Rust today, but there are a few different ideas people have come up with. I wanted to give a nod to those ideas:</p><ul><li><em>Async drop</em> would let you run async code when a future is cancelled. This would handle some, though not all, of the cases we discussed today.</li><li>There’s also a couple different proposals for what are called <em>linear types</em>, where you could force some code to be run on drop, or mark a particular future as non-cancellable (once it’s been created it must be driven to completion).</li></ul><p>All of these options have really significant implementation challenges, though. This <a href="https://without.boats/blog/asynchronous-clean-up/">blog post from boats</a> covers some of these solutions, and the implementation challenges with them.</p><h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">#</a></h2><p>In this post, we:</p><ul><li>Saw that futures are passive</li><li>Introduced cancel safety and cancel correctness as concepts</li><li>Examined some bugs that can occur with cancellation</li><li>Looked at some recommendations you can use to mitigate the downsides of cancellation</li></ul><p>Some of the recommendations are:</p><ul><li>Avoid Tokio mutexes</li><li>Rewrite APIs to make futures cancel-safe</li><li>Find ways to ensure that cancel-unsafe futures are driven to completion</li></ul><p>There’s a very deep well of complexity here, a lot more than I can cover in one blog post:</p><ul><li>Why are futures passive, anyway?</li><li>Cooperative cancellation: cancellation tokens</li><li>Actor model as an alternative to Tokio mutexes</li><li>Task aborts</li><li>Structured concurrency</li><li>Relationship to panic safety and mutex poisoning</li></ul><p>If you’re curious about any of these, check out <a href="https://github.com/sunshowers/cancelling-async-rust">this link</a> where I’ve put together a collection of documents and blog posts about these concepts. In particular, I’d recommend reading these two Oxide RFDs:</p><ul><li><a href="https://rfd.shared.oxide.computer/rfd/397">RFD 397 Challenges with async/await in the control plane</a> by David Pacheco</li><li><a href="https://rfd.shared.oxide.computer/rfd/400">RFD 400 Dealing with cancel safety in async Rust</a> by myself</li></ul><p><em>Thank you for reading this post to the end! And thanks to many of my coworkers at Oxide for reviewing the talk and the RFDs linked above, and for suggestions and constructive feedback.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anduril and Palantir battlefield comms system has deep flaws: Army (189 pts)]]></title>
            <link>https://www.cnbc.com/2025/10/03/anduril-palantir-ngc2-deep-flaws-army.html</link>
            <guid>45464269</guid>
            <pubDate>Fri, 03 Oct 2025 15:46:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/10/03/anduril-palantir-ngc2-deep-flaws-army.html">https://www.cnbc.com/2025/10/03/anduril-palantir-ngc2-deep-flaws-army.html</a>, See on <a href="https://news.ycombinator.com/item?id=45464269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108047761" data-test="InlineImage"><p>Signage for Palantir is seen during the Association of the United States Army annual meeting and exposition at the Walter E. Washington Convention Center in Washington on Oct. 14, 2024.</p><p>Nathan Howard | Reuters</p></div><div><p>The much-needed modernization of the U.S. Army's battlefield communications network being undertaken by Anduril, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/PLTR/">Palantir</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>&nbsp;and others is rife with "fundamental security" problems and vulnerabilities, and should be treated as a "very high risk," according to a recent internal Army memo.</p><p>The two Silicon Valley companies, led by allies of U.S. President <a href="https://www.cnbc.com/donald-trump/">Donald Trump</a>, have gained access to the Pentagon's lucrative flow of contracts on the promise of quickly providing less expensive and more sophisticated weapons than the Pentagon's longstanding arms providers.</p><p>But the September memo from the Army's chief technology officer about the NGC2 platform that connects soldiers, sensors, vehicles and commanders with real-time data paints a bleak picture of the initial product.</p><p>"We cannot control who sees what, we cannot see what users are doing, and we cannot verify that the software itself is secure," the memo says.</p><p>Palantir and Anduril did not comment for this story.</p><p>The assessment, seen by Reuters and first reported by Breaking Defense, comes just months after defense drone and software maker Anduril was awarded a $100 million to create a prototype of NGC2 with partners including Palantir, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-3"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and several smaller contractors.</p><p>The Army should treat the NGC2 prototype version as “very high risk” because of the “likelihood of an adversary gaining persistent undetectable access," wrote Gabrielle Chiulli, the Army chief technology officer authorizing official.</p><p>Despite the early September memo's scathing critique, Leonel Garciga, Army chief information officer and Chiulli's supervisor, said in a statement to Reuters that the report was part of a process that helped in "triaging cybersecurity vulnerabilities" and mitigating them.</p><p>In March, the 4th Infantry Division used the system in live-fire artillery training at Fort Carson, Colorado, in an exercise Anduril described as demonstrating faster and more reliable performance than legacy systems.</p><p>The Army memo identifies some major security gaps.</p><p>The report says the system allows any authorized user to access all applications and data regardless of their clearance level or operational need. As a result, "Any user can potentially access and misuse sensitive" classified information, the memo states, with no logging to track their actions.</p><p>Other deficiencies highlighted in the memo include the hosting of third-party applications that have not undergone Army security assessments. One application revealed 25 high-severity code vulnerabilities. Three additional applications under review each contain over 200 vulnerabilities requiring assessment, according to the document.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Social anxiety isn't about being liked (190 pts)]]></title>
            <link>https://chrislakin.blog/p/social-anxiety</link>
            <guid>45463656</guid>
            <pubDate>Fri, 03 Oct 2025 14:51:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrislakin.blog/p/social-anxiety">https://chrislakin.blog/p/social-anxiety</a>, See on <a href="https://news.ycombinator.com/item?id=45463656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>There's this popular idea that socially anxious folks are just dying to be liked. It seems logical, right? Why else would someone be so anxious about how others see them?</p><p>And yet, being socially anxious tends to make you less likeable…they must be optimizing poorly, behaving irrationally, right?</p><p><span>Maybe not. What if social anxiety isn’t about getting people to like you? What if it's about stopping them from </span><strong>dis</strong><span>liking you?</span></p><p>Consider what can happen when someone has social anxiety (or self-loathing, self-doubt, insecurity, lack of confidence, etc.):</p><ul><li><p>They stoop or take up less space</p></li><li><p>They become less agentic</p></li><li><p>They make fewer requests of others</p></li><li><p>They maintain fewer relationships, go out less, take fewer risks…</p></li></ul><p>If they were trying to get people to like them, becoming socially anxious would be an incredibly bad strategy.</p><p>So what if they're not concerned with being likeable?</p><blockquote><p><em>To understand the object of an obscure plot, observe its consequences and ask who might have intended them… —Harry Potter and the Methods of Rationality</em></p></blockquote><p><span>What if the socially anxious were calibrating to </span><strong>avoid being DISliked?</strong></p><p>Consider: if you shrink and never make any attention-getting moves, you are less likely to dangerously disappoint others, get into risky conflicts or be seen as a failure, embarrassment, or threat.</p><p><span>Like, yeah, it's wonderful to do awesome things and have people love you. But you know what’s better than being loved? </span><em>People not hating you.</em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SxhO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SxhO!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 424w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 848w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 1272w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SxhO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png" width="514" height="342.78434065934067" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:1237376,&quot;alt&quot;:&quot;Being liked is not the goal. Spectrum: <Dislike Neutral Like>. Being not disliked is the goal.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chrislakin.blog/i/163735823?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Being liked is not the goal. Spectrum: <Dislike Neutral Like>. Being not disliked is the goal." title="Being liked is not the goal. Spectrum: <Dislike Neutral Like>. Being not disliked is the goal." srcset="https://substackcdn.com/image/fetch/$s_!SxhO!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 424w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 848w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 1272w, https://substackcdn.com/image/fetch/$s_!SxhO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73b70346-44d8-4a85-98f8-773b768ef2db_1916x1278.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>It’s not a pursuit of potential upside, but an attempt to avoid downsides.</p><p>Once you catch on to this pattern, you see it everywhere.</p><p>Two examples:</p><p><span>1) When you feel financially insecure, you’re not optimizing for windfall as much as you’re optimizing for </span><em>not going bankrupt</em><span>. You avoid risky bets with higher EV in favor of safer, more predictable options, even if they offer smaller returns. The goal is to keep you fed, not to make you rich.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!lSlA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!lSlA!,w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 424w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 848w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 1272w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!lSlA!,w_2400,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif" width="908" height="756.6666666666666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1000,&quot;width&quot;:1200,&quot;resizeWidth&quot;:908,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Risk-Averse: fewer big losses, less upside. Risk-Embracing: more big losses more upside. Bankruptcy Safety Windfall. @ChrisChipMonk chrislakin.blog/social-anxiety&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="Risk-Averse: fewer big losses, less upside. Risk-Embracing: more big losses more upside. Bankruptcy Safety Windfall. @ChrisChipMonk chrislakin.blog/social-anxiety" title="Risk-Averse: fewer big losses, less upside. Risk-Embracing: more big losses more upside. Bankruptcy Safety Windfall. @ChrisChipMonk chrislakin.blog/social-anxiety" srcset="https://substackcdn.com/image/fetch/$s_!lSlA!,w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 424w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 848w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 1272w, https://substackcdn.com/image/fetch/$s_!lSlA!,w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da363fc-ff13-4330-919e-27c5bf1d73c0_1200x1000.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>2) Reversely, countersignalling is a demonstration of safety in close relationships. In Scott Alexander’s Friendship is Countersignalling, he describes an interaction he has with a friend:</p><blockquote><p><em><strong>Becca:</strong><span> What are you doing here? I figured they’d have locked you away in the psych ward for good by now.</span></em></p><p><em><strong>Scott:</strong><span> Nope. And what are you doing here? You haven’t killed off all your patients yet?</span></em></p><p><em><strong>Becca:</strong><span> Only person in this hospital I might kill is standing right in front of me.</span></em></p><p><em><strong>Scott:</strong><span> Be careful, I’m armed and dangerous *picks up a central line placement practice set menacingly*</span></em></p></blockquote><p><span>The security of good friendship diffuses your anxiety about making a social faux pas and enables you to </span><em>take more risks</em><span>.</span></p><p><span>If you </span><em>believe</em><span> your primary goal is to "be liked" and you keep finding yourself hiding in the shadows, you'll feel like a total failure. This hurts!</span></p><p><span>But all our feelings have their own kind of logic. Even when we do things that </span><em>seem</em><span> self-sabotaging, there's usually an incentive that makes sense in that specific context – even if it maybe not the best strategy overall. </span><em><a href="https://chrislakin.blog/p/locally-optimal" rel="">Locally optimal</a><span>!</span></em></p><p><span>Consider: what if all these symptoms of social anxiety aren't failures of a system trying to be liked, but </span><strong>successes</strong><span> of a system trying to avoid being disliked?</span></p><p>What if you’ve been operating pretty rationally this whole time, but not for the outcome you thought you were optimizing for?</p><p>What if you’re not failing at being liked - you’re succeeding at avoiding being disliked?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!jkNR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!jkNR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 424w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 848w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 1272w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!jkNR!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif" width="824" height="686.6666666666666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1000,&quot;width&quot;:1200,&quot;resizeWidth&quot;:824,&quot;bytes&quot;:576564,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chrislakin.blog/i/163735823?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!jkNR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 424w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 848w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 1272w, https://substackcdn.com/image/fetch/$s_!jkNR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b044cf0-6610-4f67-aff0-dfd0628fa16a_1200x1000.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Recognize this, and you’ll be able to shift your focus to the real work: </span><strong>becoming comfortable with the worst-case scenarios your anxiety is protecting you from.</strong></p><p><span>The solution isn’t trying harder to be liked. It’s </span><strong><a href="https://chrislakin.blog/p/unlearning" rel="">unlearning</a></strong><span> your discomfort with being </span><em>dis</em><span>liked.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft CTO says he wants to swap most AMD and Nvidia GPUs for homemade chips (166 pts)]]></title>
            <link>https://www.theregister.com/2025/10/02/microsoft_maia_dc/</link>
            <guid>45463642</guid>
            <pubDate>Fri, 03 Oct 2025 14:48:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/02/microsoft_maia_dc/">https://www.theregister.com/2025/10/02/microsoft_maia_dc/</a>, See on <a href="https://news.ycombinator.com/item?id=45463642">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Microsoft buys a lot of GPUs from both Nvidia and AMD. But moving forward, Redmond's leaders want to shift the majority of its AI workloads from GPUs to its own homegrown accelerators.</p>
<p>The software titan is rather late to the custom silicon party. While Amazon and Google have been building custom CPUs and AI accelerators for years, Microsoft only <a target="_blank" rel="nofollow" href="https://www.nextplatform.com/2023/11/15/microsoft-holds-chip-makers-feet-to-the-fire-with-homegrown-cpu-and-ai-chips/">revealed</a> its Maia AI accelerators in late 2023.</p>
<p>Driving the transition is a focus on performance per dollar, which for a hyperscale cloud provider is arguably the only metric that really matters. Speaking during a <a target="_blank" rel="nofollow" href="https://www.cnbc.com/2025/10/01/microsoft-wants-to-mainly-use-its-own-ai-chips-in-the-future.html">fireside</a> chat moderated by CNBC on Wednesday, Microsoft CTO Kevin Scott said that up to this point, Nvidia has offered the best price-performance, but he's willing to entertain anything in order to meet demand.</p>

    

<p>Going forward, Scott suggested Microsoft hopes to use its homegrown chips for the majority of its datacenter workloads.</p>

        


        

<p>When asked, "Is the longer term idea to have mainly Microsoft silicon in the data center?" Scott responded, "Yeah, absolutely."</p>
<p>Later, he told CNBC, "It's about the entire system design. It's the networks and cooling, and you want to be able to have the freedom to make decisions that you need to make in order to really optimize your compute for the workload."</p>

        

<p>With its first in-house AI accelerator, the Maia 100, Microsoft was able to free up GPU capacity by shifting OpenAI's GPT-3.5 to its own silicon back in 2023. However, with just 800 teraFLOPS of BF16 performance, 64GB of HBM2e, and 1.8TB/s of memory bandwidth, the chip fell well short of competing GPUs from Nvidia and AMD.</p>
<ul>

<li><a href="https://www.theregister.com/2025/09/27/alibaba_ai_drive/">Alibaba unveils $53B global AI plan – but it will need GPUs to back it up</a></li>

<li><a href="https://www.theregister.com/2025/09/11/nvidias_graceblackwell_drives_arms_cpu/">Arm wrestles away 25% share of server market thanks to Nvidia's home-grown CPUs</a></li>

<li><a href="https://www.theregister.com/2025/06/11/sipearl_rhea1_reference_design/">SiPearl ships reference node design for Rhea1 high-spec Arm chip</a></li>

<li><a href="https://www.theregister.com/2025/04/01/arm_datacenter_cpu_market/">Arm reckons it'll own 50% of the datacenter by year's end</a></li>
</ul>
<p>Microsoft is <a target="_blank" rel="nofollow" href="https://www.theinformation.com/articles/microsoft-scales-back-ambitions-ai-chips-overcome-delays">reportedly</a> in the process of bringing a second-generation Maia accelerator to market next year that will no doubt offer more competitive compute, memory, and interconnect performance.</p>
<p>But while we may see a change in the mix of GPUs to AI ASICs in Microsoft data centers moving forward, they're unlikely to replace Nvidia and AMD's chips entirely.</p>
<p>Over the past few years, Google and Amazon have deployed tens of thousands of their TPUs and Trainium accelerators. While these chips have helped them secure some high-profile customer wins, Anthropic for <a target="_blank" href="https://www.theregister.com/2025/07/04/project_rainier_deep_dive/">example</a>, these chips are more often used to accelerate the company's own in-house workloads.</p>
<p>As such, we continue to see large-scale Nvidia and AMD GPU deployments on these cloud platforms, in part because customers still want them.</p>

        

<p>It should be noted that AI accelerators aren't the only custom chips Microsoft has been working on. Redmond also has its own CPU called <a target="_blank" rel="nofollow" href="https://www.cnbc.com/2025/10/01/microsoft-wants-to-mainly-use-its-own-ai-chips-in-the-future.html">Cobalt</a> and a whole host of platform security silicon <a target="_blank" href="https://www.theregister.com/2025/08/26/microsoft_silicon_security/">designed</a> to accelerate cryptography and safeguard key exchanges across its vast datacenter domains. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I turned the Lego Game Boy into a working Game Boy (181 pts)]]></title>
            <link>https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/</link>
            <guid>45463319</guid>
            <pubDate>Fri, 03 Oct 2025 14:18:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/">https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/</a>, See on <a href="https://news.ycombinator.com/item?id=45463319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <main>
                
<article>
    

    <figure>
        <img src="https://blog.nataliethenerd.com/content/images/2025/10/DSCF4479.jpg" alt="Lego Game Boy that actually works">
    </figure>

    <div>
        <p>Through my documentation of Game Boy boards, I have drawn up schematics of each device. I know them pretty well. Check out my board scan wiki <a href="https://wiki.nataliethenerd.com/?ref=blog.nataliethenerd.com">https://wiki.nataliethenerd.com/</a></p><p>I jokingly made this tweet when the kit was announced, but decided to actually do it.</p><figure><blockquote><p lang="en" dir="ltr">that's my opening <a href="https://t.co/hJotri3aQP?ref=blog.nataliethenerd.com">pic.twitter.com/hJotri3aQP</a></p>— natalie (@natalie_thenerd) <a href="https://twitter.com/natalie_thenerd/status/1948394081421517150?ref_src=twsrc%5Etfw&amp;ref=blog.nataliethenerd.com">July 24, 2025</a></blockquote>
</figure><div><p>I know from experience of routing Game Boy CPU PCBs that there isn't much to it. There's the RAM, CPU, some decoupling capacitors and power regulation. </p><p>Note: I went with the MGB (Pocket) CPU rather than DMG for a couple of reasons.</p></div><ul><li>They are pretty much the same </li><li>I have more of them</li><li> They are cheaper and easier to get. This opens up the project to more people </li></ul><p>The DMG CPU has external VRAM, the MGB CPU has internal VRAM and in a very space conscious build that was the biggest factor.</p><figure><img src="https://blog.nataliethenerd.com/content/images/2025/10/motherboard_marked.166d45e5f7ee217a5fa30e94871ed66232e7c6d0cc600fe0ae2835e5157ce141_hu_e5e6c7e38691613e-1.webp" alt="" loading="lazy" width="1120" height="1030" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/motherboard_marked.166d45e5f7ee217a5fa30e94871ed66232e7c6d0cc600fe0ae2835e5157ce141_hu_e5e6c7e38691613e-1.webp 600w, https://blog.nataliethenerd.com/content/images/size/w1000/2025/10/motherboard_marked.166d45e5f7ee217a5fa30e94871ed66232e7c6d0cc600fe0ae2835e5157ce141_hu_e5e6c7e38691613e-1.webp 1000w, https://blog.nataliethenerd.com/content/images/2025/10/motherboard_marked.166d45e5f7ee217a5fa30e94871ed66232e7c6d0cc600fe0ae2835e5157ce141_hu_e5e6c7e38691613e-1.webp 1120w" sizes="(min-width: 720px) 720px"><figcaption><span>DMG motherboard. Image source: Rodrigo Copetti </span><a href="https://www.copetti.org/writings/consoles/game-boy/?ref=blog.nataliethenerd.com"><span>https://www.copetti.org/writings/consoles/game-boy/</span></a></figcaption></figure><h2 id="pre-planning">Pre Planning</h2><p>I only had the press pictures to work off. I used the dimensions to scale the image on my PC and from that I got measurements for the screen inserts; since that's where I plan to put the Game Boy.</p><figure><div><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/72046_WEB_SEC05_en-gb.webp" width="800" height="450" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/72046_WEB_SEC05_en-gb.webp 600w, https://blog.nataliethenerd.com/content/images/2025/10/72046_WEB_SEC05_en-gb.webp 800w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/72046_Lifestyle_Envr_05_en-gb.webp" width="800" height="534" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/72046_Lifestyle_Envr_05_en-gb.webp 600w, https://blog.nataliethenerd.com/content/images/2025/10/72046_Lifestyle_Envr_05_en-gb.webp 800w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p dir="ltr"><span>Source: </span><a href="https://www.lego.com/en-au/product/game-boy-72046?ref=blog.nataliethenerd.com"><span>https://www.lego.com/en-au/product/game-boy-72046</span></a></p></figcaption></figure><p>I incorporated the power circuit I use for my <a href="https://nataliethenerd.com/products/safer-charge-dc?ref=blog.nataliethenerd.com" rel="noreferrer">Safer Charger boards</a>, changed the power switch to a soft latching power button, added pin outs for the button matrix and audio.</p><figure><div><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/Screenshot-2025-07-31-222906.png" width="748" height="630" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/Screenshot-2025-07-31-222906.png 600w, https://blog.nataliethenerd.com/content/images/2025/10/Screenshot-2025-07-31-222906.png 748w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/Screenshot-2025-07-31-222621.png" width="753" height="556" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/Screenshot-2025-07-31-222621.png 600w, https://blog.nataliethenerd.com/content/images/2025/10/Screenshot-2025-07-31-222621.png 753w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p dir="ltr"><span>KiCad 3D renders of the PCB</span></p></figcaption></figure><p>I didn't really know what the buttons on the Lego would be like, but the fact that they could be pressed was enough for me to know I could implement them. At the moment I have them wired up to custom 3D printed *toy brick* parts.  Same with the USB C </p><figure data-kg-thumbnail="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250929_152654298_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250929_152654298.mp4" poster="https://img.spacergif.org/v1/1080x1920/0a/spacer.png" width="1080" height="1920" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:07</span>
                        </p>
                        </div>
            </div>
            <figcaption><p dir="ltr"><span>Clicky buttons!</span></p></figcaption>
        <img src="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250929_152654298_thumb.jpg"></figure><p>I am currently working on refining the board now I have the Lego build in my hands. This project will be released in full once I am finished with it - so stay tuned!</p><figure><div><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/PXL_20250928_124849047.jpg" width="2000" height="2656" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/PXL_20250928_124849047.jpg 600w, https://blog.nataliethenerd.com/content/images/size/w1000/2025/10/PXL_20250928_124849047.jpg 1000w, https://blog.nataliethenerd.com/content/images/size/w1600/2025/10/PXL_20250928_124849047.jpg 1600w, https://blog.nataliethenerd.com/content/images/size/w2400/2025/10/PXL_20250928_124849047.jpg 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/bafkreidiqyu3q7ju7h2tghnq6uhb35yvgsqpva5f4gzt5vh5zvxvzy7m64.jpg" width="1505" height="2000" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/bafkreidiqyu3q7ju7h2tghnq6uhb35yvgsqpva5f4gzt5vh5zvxvzy7m64.jpg 600w, https://blog.nataliethenerd.com/content/images/size/w1000/2025/10/bafkreidiqyu3q7ju7h2tghnq6uhb35yvgsqpva5f4gzt5vh5zvxvzy7m64.jpg 1000w, https://blog.nataliethenerd.com/content/images/2025/10/bafkreidiqyu3q7ju7h2tghnq6uhb35yvgsqpva5f4gzt5vh5zvxvzy7m64.jpg 1505w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.nataliethenerd.com/content/images/2025/10/PXL_20250928_124051035.jpg" width="2000" height="2656" loading="lazy" alt="" srcset="https://blog.nataliethenerd.com/content/images/size/w600/2025/10/PXL_20250928_124051035.jpg 600w, https://blog.nataliethenerd.com/content/images/size/w1000/2025/10/PXL_20250928_124051035.jpg 1000w, https://blog.nataliethenerd.com/content/images/size/w1600/2025/10/PXL_20250928_124051035.jpg 1600w, https://blog.nataliethenerd.com/content/images/size/w2400/2025/10/PXL_20250928_124051035.jpg 2400w" sizes="(min-width: 720px) 720px"></p></div></figure><figure data-kg-thumbnail="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250928_121823374_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250928_121823374.mp4" poster="https://img.spacergif.org/v1/1080x1920/0a/spacer.png" width="1080" height="1920" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:21</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://blog.nataliethenerd.com/content/media/2025/10/PXL_20250928_121823374_thumb.jpg"></figure>
    </div>

    
</article>

            </main>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Webbol: A minimal static web server written in COBOL (106 pts)]]></title>
            <link>https://github.com/jmsdnns/webbol</link>
            <guid>45463251</guid>
            <pubDate>Fri, 03 Oct 2025 14:13:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jmsdnns/webbol">https://github.com/jmsdnns/webbol</a>, See on <a href="https://news.ycombinator.com/item?id=45463251">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Webbol</h2><a id="user-content-webbol" aria-label="Permalink: Webbol" href="#webbol"></a></p>
<p dir="auto">A minimal static web server written in COBOL using GnuCOBOL.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Serves static files from the current directory</li>
<li>Automatic MIME type detection for common file types</li>
<li>HTTP status codes: 200 (OK), 403 (Forbidden), 404 (Not Found), 413 (Payload Too Large)</li>
<li>Path traversal attack prevention</li>
<li>Clean request logging with full HTTP headers</li>
<li>Defaults to <code>index.html</code> for root path requests</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>GnuCOBOL (cobc) compiler</li>
<li>POSIX-compatible operating system (Linux, macOS, BSD)</li>
<li>make</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installing GnuCOBOL</h3><a id="user-content-installing-gnucobol" aria-label="Permalink: Installing GnuCOBOL" href="#installing-gnucobol"></a></p>
<p dir="auto"><strong>macOS:</strong></p>

<p dir="auto"><strong>Ubuntu/Debian:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt-get install gnucobol"><pre>sudo apt-get install gnucobol</pre></div>
<p dir="auto"><strong>Fedora/RHEL:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo dnf install gnucobol"><pre>sudo dnf install gnucobol</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">Clone or download the repository, then compile:</p>

<p dir="auto">This will compile all modules and create the <code>webserver</code> executable.</p>
<p dir="auto">To clean build artifacts:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Start the server from the directory you want to serve:</p>

<p dir="auto">The server will start on port 8080 and serve files from the current directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create a test HTML file
echo &quot;<html><body><h1>Hello from COBOL!</h1></body></html>&quot; > index.html

# Start the server
./webserver

# In another terminal, test it
curl http://localhost:8080/"><pre><span><span>#</span> Create a test HTML file</span>
<span>echo</span> <span><span>"</span>&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello from COBOL!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;<span>"</span></span> <span>&gt;</span> index.html

<span><span>#</span> Start the server</span>
./webserver

<span><span>#</span> In another terminal, test it</span>
curl http://localhost:8080/</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Accessing the Server</h3><a id="user-content-accessing-the-server" aria-label="Permalink: Accessing the Server" href="#accessing-the-server"></a></p>
<p dir="auto">Once running, you can access files via:</p>
<ul dir="auto">
<li><code>http://localhost:8080/</code> - serves <code>index.html</code> from the current directory</li>
<li><code>http://localhost:8080/filename.html</code> - serves the specified file</li>
<li><code>http://localhost:8080/path/to/file.txt</code> - serves files from subdirectories</li>
</ul>
<p dir="auto">Press <code>Ctrl+C</code> to stop the server.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">To change the server port, edit <code>config.cpy</code> and modify the <code>SERVER-PORT</code> value:</p>
<div dir="auto" data-snippet-clipboard-copy-content="01 SERVER-PORT          PIC 9(5) VALUE 8080."><pre><span>01</span> SERVER-PORT          <span>PIC 9</span>(<span>5</span>) <span>VALUE</span> <span>8080</span>.</pre></div>
<p dir="auto">Then recompile with <code>make</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="webbol/
├── Makefile              # Build configuration
├── README.md            # This file
├── config.cpy           # Server configuration
├── socket-defs.cpy      # Socket structure definitions
├── http-structs.cpy     # HTTP data structures
├── file-structs.cpy     # File handling structures
├── path-utils.cbl       # Path validation and sanitization
├── mime-types.cbl       # MIME type detection
├── file-ops.cbl         # File reading operations
├── http-handler.cbl     # HTTP request/response handling
└── webserver.cbl        # Main server program"><pre><code>webbol/
├── Makefile              # Build configuration
├── README.md            # This file
├── config.cpy           # Server configuration
├── socket-defs.cpy      # Socket structure definitions
├── http-structs.cpy     # HTTP data structures
├── file-structs.cpy     # File handling structures
├── path-utils.cbl       # Path validation and sanitization
├── mime-types.cbl       # MIME type detection
├── file-ops.cbl         # File reading operations
├── http-handler.cbl     # HTTP request/response handling
└── webserver.cbl        # Main server program
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported MIME Types</h2><a id="user-content-supported-mime-types" aria-label="Permalink: Supported MIME Types" href="#supported-mime-types"></a></p>
<ul dir="auto">
<li>HTML: <code>text/html</code></li>
<li>CSS: <code>text/css</code></li>
<li>JavaScript: <code>application/javascript</code></li>
<li>JSON: <code>application/json</code></li>
<li>XML: <code>application/xml</code></li>
<li>Plain text: <code>text/plain</code></li>
<li>PNG: <code>image/png</code></li>
<li>JPEG: <code>image/jpeg</code></li>
<li>GIF: <code>image/gif</code></li>
<li>SVG: <code>image/svg+xml</code></li>
<li>ICO: <code>image/x-icon</code></li>
<li>PDF: <code>application/pdf</code></li>
</ul>
<p dir="auto">Additional MIME types can be added by editing <code>mime-types.cbl</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security Features</h2><a id="user-content-security-features" aria-label="Permalink: Security Features" href="#security-features"></a></p>
<ul dir="auto">
<li>Path traversal prevention: Blocks requests containing <code>..</code> sequences</li>
<li>Directory access restriction: Only serves files from the current directory and subdirectories</li>
<li>Safe file handling: Validates all paths before file system access</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<ul dir="auto">
<li>Single-threaded: Handles one request at a time</li>
<li>No SSL/TLS support</li>
<li>Maximum file size: 64KB</li>
<li>Line sequential file organization only (text files)</li>
<li>No caching or compression</li>
<li>No range requests or partial content support</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto"><strong>Port already in use:</strong></p>
<div data-snippet-clipboard-copy-content="Bind failed - check if port is in use"><pre><code>Bind failed - check if port is in use
</code></pre></div>
<p dir="auto">Another process is using port 8080. Either stop that process or change the port in <code>config.cpy</code>.</p>
<p dir="auto"><strong>Permission denied:</strong>
Ensure the files you're trying to serve have read permissions and the current user can access them.</p>
<p dir="auto"><strong>File not found (404):</strong>
Verify the file exists in the current directory where the server is running. File paths are case-sensitive.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is released into the public domain. Use it however you'd like.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<p dir="auto">Built with GnuCOBOL, demonstrating that COBOL can still be used for modern systems programming tasks.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Faroes (144 pts)]]></title>
            <link>https://photoblog.nk412.com/Faroe2025/Faroes/n-cPCNFr</link>
            <guid>45462297</guid>
            <pubDate>Fri, 03 Oct 2025 12:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://photoblog.nk412.com/Faroe2025/Faroes/n-cPCNFr">https://photoblog.nk412.com/Faroe2025/Faroes/n-cPCNFr</a>, See on <a href="https://news.ycombinator.com/item?id=45462297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-layout-region="Center" data-layout-column="0" data-layout-row="main" data-layout-row-reserved="main" data-pinned-region="Header" id="sm-page-content"><div id="sm-page-widget-CsH4Rtgd" data-typeid="37955880" data-layout-column="0" data-layout-row="Q"><p id="sm-page-widget-2sSkpc4Z"><h2>The Faroes (2025)</h2>
</p></div><div id="sm-page-widget-dXZrtT99" data-typeid="37955882" data-layout-column="0" data-layout-row="J"><p><span>The Faroe Islands are like the child that Denmark and Iceland had, but forgot to tell the world about. This group of eighteen small islands receives the least amount of sunshine in the world per year. Constant rain and heavy winds have always battered these lands.</span></p><p><span>Politically part of Denmark (for now) but fiercely independent in spirit, the Faroes exist in their own bubble of Nordic culture. Here, sheep outnumber humans two to one, villages of colorful houses cling to clifftops like they're holding on for dear life, and the weather can shift from apocalyptic storms to sunny calm in the space of an hour.</span></p></div><div id="sm-page-widget-KLNM5hjr" data-typeid="37955962" data-layout-column="0" data-layout-row="F"><div><p><span>Situated between Iceland, Norway and Scotland, the Faroes face the brunt of the North Atlantic weather system. Constant storms and crashing waves have sculpted the volcanic rock over millions of years into some of the most jaw-dropping (and vertigo-inducing) coastlines on Earth. These towering basalt cliffs can reach heights of over 400 meters, dropping straight into churning seas below.</span></p><p><span>What's most striking is how abruptly the land stops. </span><span>There are no sandy beaches or gentle slopes here—the islands simply plunge headfirst into the Atlantic. One step you're on grass-covered clifftops, the next you're staring down hundreds of meters of sheer volcanic rock to where waves explode against the base far below.</span></p></div><p><span>The weather here is unpredictable, and changes faster than you can put your raincoat on—one minute you're in thick fog, the next you're hit with winds and piercing rain that'll knock you sideways, then suddenly the clouds part to reveal views that'll make your camera work overtime.&nbsp;&nbsp;</span></p></div><div id="sm-page-widget-ZH7xXVtm" data-typeid="37956016" data-layout-column="0" data-layout-row="qd"><div><p><span>Meet the true locals of the Faroes. These wooly sheep have been roaming the islands for over a thousand years, and they outnumber people on the islands. They couldn't care less about your hiking plans and will casually block paths or graze on the edge of 200-meter cliffs like it's the most natural thing in the world.</span></p><p><span id="yui_3_8_0_1_1751237474731_12967">Faroe's name comes from a combination of </span><span>fær</span><span> (sheep) and </span><span>eyjar</span><span> (islands).&nbsp;</span></p></div><p><span> Unlike their farm-bound cousins elsewhere, Faroese sheep roam completely free across the islands, somehow always managing to find the most photogenic spots for an impromptu rest.&nbsp;</span><span>This fellow right&nbsp; here is the only one that gave me any sort of attention. Otherwise, they are all busy grazing on all the grass they could ever ask for.</span></p></div><div id="sm-page-widget-sXQLR85m" data-typeid="37956238" data-layout-column="0" data-layout-row="R"><p><span>Why fight the landscape? For over a millennium, islanders have been topping their huts with birch bark and soil and let the grass grow wild. They act as insulation, and the thick roots are an excellent waterproof seal against the weather.</span></p><p><span>The grass grows quickly and does need tending every once in a while. In typical Faroese fashion, the solution is simple: put a sheep on top for an afternoon.</span></p></div><div id="sm-page-widget-MvFwhQxs" data-typeid="37956265" data-layout-column="0" data-layout-row="xx"><p><span>On the northern tip of Kalsoy lies the Kallur lighthouse. Like most regions on the islands, the land is privately owned. Hiking usually incurs a modest fee paid at the trailhead to the land owners, and the rest is up to you. Trails are just sheep paths, worn smooth by countless hooves over years rather than any official trail maintenance.</span></p><p><span>There are no guardrails, no warning signs, and definitely no liability waivers - just you, the weather, and whatever route the sheep decided made sense. The approach to Kallur is particularly gnarly, following a knife-edge ridge with steep drops on both sides before reaching the lighthouse perched dramatically on sea cliffs.&nbsp;</span></p></div><div id="sm-page-widget-vP2j2prb" data-typeid="37956732" data-layout-column="0" data-layout-row="B9"><p><span>In </span><span>No Time To Die (2021)</span><span>, </span><span>Daniel Craig's James Bond meets his end at the villain's lair, which happened to be here on Kalsoy. The Faroese then followed through with the obvious next step.</span></p>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Niri – A scrollable-tiling Wayland compositor (403 pts)]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>45461500</guid>
            <pubDate>Fri, 03 Oct 2025 11:08:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/YaLTeR/niri">https://github.com/YaLTeR/niri</a>, See on <a href="https://news.ycombinator.com/item?id=45461500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1794388/483874013-07d05cd0-d5dc-4a28-9a35-51bae8f119a0.svg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzQ4Mzg3NDAxMy0wN2QwNWNkMC1kNWRjLTRhMjgtOWEzNS01MWJhZThmMTE5YTAuc3ZnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NmJhZGU3YTI1ZWI0MTFkMDIzZTFjNGJjZGQ5ZGI2ZjI5MWMwOWI5OTBjM2U0MTU0NDNhNWMzYzI5NDk1Y2RlOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.mazit7EydfWepmNXv8wm0MO2BHcK1i4bSPgrEinCBCA"><img alt="niri" src="https://private-user-images.githubusercontent.com/1794388/483874013-07d05cd0-d5dc-4a28-9a35-51bae8f119a0.svg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzQ4Mzg3NDAxMy0wN2QwNWNkMC1kNWRjLTRhMjgtOWEzNS01MWJhZThmMTE5YTAuc3ZnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NmJhZGU3YTI1ZWI0MTFkMDIzZTFjNGJjZGQ5ZGI2ZjI5MWMwOWI5OTBjM2U0MTU0NDNhNWMzYzI5NDk1Y2RlOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.mazit7EydfWepmNXv8wm0MO2BHcK1i4bSPgrEinCBCA"></a></h2><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto">A scrollable-tiling Wayland compositor.</p>
<p dir="auto">
    <a href="https://matrix.to/#/#niri:matrix.org" rel="nofollow"><img alt="Matrix" src="https://camo.githubusercontent.com/731b82b2de55578b31ffa040566437124f80c1fa148435eea7bf30fd01cb6e49/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d61747269782d2532336e6972692d626c75653f6c6f676f3d6d6174726978" data-canonical-src="https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix"></a>
    <a href="https://github.com/YaLTeR/niri/blob/main/LICENSE"><img alt="GitHub License" src="https://camo.githubusercontent.com/315c2cf101bac2688e503e62a82183011bab1ec564832de83895ace35ccaed2d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f59614c5465522f6e697269" data-canonical-src="https://img.shields.io/github/license/YaLTeR/niri"></a>
    <a href="https://github.com/YaLTeR/niri/releases"><img alt="GitHub Release" src="https://camo.githubusercontent.com/e0c3aabb99fe3d79b34389fc2ee1007630e7c88c0c50ebaa61b0005b47da8777/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f59614c5465522f6e6972693f6c6f676f3d676974687562" data-canonical-src="https://img.shields.io/github/v/release/YaLTeR/niri?logo=github"></a>
</p>
<p dir="auto">
    <a href="https://yalter.github.io/niri/Getting-Started.html" rel="nofollow">Getting Started</a> | <a href="https://yalter.github.io/niri/Configuration%3A-Introduction.html" rel="nofollow">Configuration</a> | <a href="https://github.com/YaLTeR/niri/discussions/325" data-hovercard-type="discussion" data-hovercard-url="/YaLTeR/niri/discussions/325/hovercard">Setup&nbsp;Showcase</a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1794388/444780574-535e6530-2f44-4b84-a883-1240a3eee6e9.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzQ0NDc4MDU3NC01MzVlNjUzMC0yZjQ0LTRiODQtYTg4My0xMjQwYTNlZWU2ZTkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZmEwYzdlZmRhMzdlMTc1MjYwYjBmMjlmMWQyODg4ODdjMTA5ZWUzZTc2MWU5MjVlNTgxZjAyNWM2MDY4ZDY3MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.22YZQKfIgEnRUDhSaecZ1I2R2FCxnO8X_msyUpNU3aE"><img src="https://private-user-images.githubusercontent.com/1794388/444780574-535e6530-2f44-4b84-a883-1240a3eee6e9.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzQ0NDc4MDU3NC01MzVlNjUzMC0yZjQ0LTRiODQtYTg4My0xMjQwYTNlZWU2ZTkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZmEwYzdlZmRhMzdlMTc1MjYwYjBmMjlmMWQyODg4ODdjMTA5ZWUzZTc2MWU5MjVlNTgxZjAyNWM2MDY4ZDY3MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.22YZQKfIgEnRUDhSaecZ1I2R2FCxnO8X_msyUpNU3aE" alt="niri with a few windows open"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.</p>
<p dir="auto">Every monitor has its own separate window strip.
Windows can never "overflow" onto an adjacent monitor.</p>
<p dir="auto">Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there's always one empty workspace present all the way down.</p>
<p dir="auto">The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Built from the ground up for scrollable tiling</li>
<li><a href="https://yalter.github.io/niri/Workspaces.html" rel="nofollow">Dynamic workspaces</a> like in GNOME</li>
<li>An <a href="https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995">Overview</a> that zooms out workspaces and windows</li>
<li>Built-in screenshot UI</li>
<li>Monitor and window screencasting through xdg-desktop-portal-gnome
<ul dir="auto">
<li>You can <a href="https://yalter.github.io/niri/Configuration%3A-Window-Rules.html#block-out-from" rel="nofollow">block out</a> sensitive windows from screencasts</li>
<li><a href="https://yalter.github.io/niri/Screencasting.html#dynamic-screencast-target" rel="nofollow">Dynamic cast target</a> that can change what it shows on the go</li>
</ul>
</li>
<li><a href="https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515">Touchpad</a> and <a href="https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000">mouse</a> gestures</li>
<li>Group windows into <a href="https://yalter.github.io/niri/Tabs.html" rel="nofollow">tabs</a></li>
<li>Configurable layout: gaps, borders, struts, window sizes</li>
<li><a href="https://yalter.github.io/niri/Configuration%3A-Layout.html#gradients" rel="nofollow">Gradient borders</a> with Oklab and Oklch support</li>
<li><a href="https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e">Animations</a> with support for <a href="https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad">custom shaders</a></li>
<li>Live-reloading config</li>
<li>Works with <a href="https://yalter.github.io/niri/Accessibility.html" rel="nofollow">screen readers</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Video Demo</h2><a id="user-content-video-demo" aria-label="Permalink: Video Demo" href="#video-demo"></a></p>
<details open="">
  <summary>
    
    <span>demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1794388/324180311-bce834b0-f205-434e-a027-b373495f9729.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzMyNDE4MDMxMS1iY2U4MzRiMC1mMjA1LTQzNGUtYTAyNy1iMzczNDk1Zjk3MjkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzlhMWUwOWJlYTQ2MjIwYTA0ZDA0MmYwZGM0NzFjMGVmMGUzZDA5Y2MzMDlhZGNmNTM2MzVlOWRlOTczNzc3ZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.nkN7DD_bTVSsz4UgnIU4xDlZytQeHyzhFaeX9FT16N4" data-canonical-src="https://private-user-images.githubusercontent.com/1794388/324180311-bce834b0-f205-434e-a027-b373495f9729.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTk0OTg1MDEsIm5iZiI6MTc1OTQ5ODIwMSwicGF0aCI6Ii8xNzk0Mzg4LzMyNDE4MDMxMS1iY2U4MzRiMC1mMjA1LTQzNGUtYTAyNy1iMzczNDk1Zjk3MjkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTAwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEwMDNUMTMzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzlhMWUwOWJlYTQ2MjIwYTA0ZDA0MmYwZGM0NzFjMGVmMGUzZDA5Y2MzMDlhZGNmNTM2MzVlOWRlOTczNzc3ZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.nkN7DD_bTVSsz4UgnIU4xDlZytQeHyzhFaeX9FT16N4" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: <a href="https://youtu.be/DeYx2exm04M" rel="nofollow">Niri Is My New Favorite Wayland Compositor</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status</h2><a id="user-content-status" aria-label="Permalink: Status" href="#status"></a></p>
<p dir="auto">Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our <a href="https://matrix.to/#/#niri:matrix.org" rel="nofollow">Matrix channel</a>.</p>
<p dir="auto">Give it a try!
Follow the instructions on the <a href="https://yalter.github.io/niri/Getting-Started.html" rel="nofollow">Getting Started</a> page.
Have your <a href="https://github.com/Alexays/Waybar">waybar</a>s and <a href="https://codeberg.org/dnkl/fuzzel" rel="nofollow">fuzzel</a>s ready: niri is not a complete desktop environment.
Also check out <a href="https://github.com/Vortriz/awesome-niri">awesome-niri</a>, a list of niri-related links and projects.</p>
<p dir="auto">Here are some points you may have questions about:</p>
<ul dir="auto">
<li><strong>Multi-monitor</strong>: yes, a core part of the design from the very start. Mixed DPI works.</li>
<li><strong>Fractional scaling</strong>: yes, plus all niri UI stays pixel-perfect.</li>
<li><strong>NVIDIA</strong>: seems to work fine.</li>
<li><strong>Floating windows</strong>: yes, starting from niri 25.01.</li>
<li><strong>Input devices</strong>: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use <a href="https://opentabletdriver.net/" rel="nofollow">OpenTabletDriver</a>.
We have touchpad gestures, but no touchscreen gestures yet.</li>
<li><strong>Wlr protocols</strong>: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on <a href="https://wayland.app/" rel="nofollow">wayland.app</a> at the bottom of each protocol's page.</li>
<li><strong>Performance</strong>: while I run niri on beefy machines, I try to stay conscious of performance.
I've seen someone use it fine on an Eee&nbsp;PC&nbsp;900 from&nbsp;2008, of all things.</li>
<li><strong>Xwayland</strong>: <a href="https://yalter.github.io/niri/Xwayland.html#using-xwayland-satellite" rel="nofollow">integrated</a> via xwayland-satellite starting from niri 25.08.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Media</h2><a id="user-content-media" aria-label="Permalink: Media" href="#media"></a></p>
<p dir="auto"><a href="https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T" rel="nofollow">niri: Making a Wayland compositor in Rust</a> · <em>December 2024</em></p>
<p dir="auto">My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube's subtitle language selector.</p>
<p dir="auto"><a href="https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri" rel="nofollow">An interview with Ivan, the developer behind Niri</a> · <em>June 2025</em></p>
<p dir="auto">An interview by a German tech podcast Das Triumvirat (in English).
We talk about niri development and history, and my experience building and maintaining niri.</p>
<p dir="auto"><a href="https://lwn.net/Articles/1025866/" rel="nofollow">A tour of the niri scrolling-tiling Wayland compositor</a> · <em>July 2025</em></p>
<p dir="auto">An LWN article with a nice overview and introduction to niri.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you'd like to help with niri, there are plenty of both coding- and non-coding-related ways to do so.
See <a href="https://github.com/YaLTeR/niri/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for an overview.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inspiration</h2><a id="user-content-inspiration" aria-label="Permalink: Inspiration" href="#inspiration"></a></p>
<p dir="auto">Niri is heavily inspired by <a href="https://github.com/paperwm/PaperWM">PaperWM</a> which implements scrollable tiling on top of GNOME Shell.</p>
<p dir="auto">One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell's global window coordinate space to prevent windows from overflowing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tile Scrollably Elsewhere</h2><a id="user-content-tile-scrollably-elsewhere" aria-label="Permalink: Tile Scrollably Elsewhere" href="#tile-scrollably-elsewhere"></a></p>
<p dir="auto">Here are some other projects which implement a similar workflow:</p>
<ul dir="auto">
<li><a href="https://github.com/paperwm/PaperWM">PaperWM</a>: scrollable tiling on top of GNOME Shell.</li>
<li><a href="https://github.com/peterfajdiga/karousel">karousel</a>: scrollable tiling on top of KDE.</li>
<li><a href="https://github.com/dawsers/scroll">scroll</a> and <a href="https://spwhitton.name/tech/code/papersway/" rel="nofollow">papersway</a>: scrollable tiling on top of sway/i3.</li>
<li><a href="https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling">hyprscrolling</a> and <a href="https://gitlab.com/magus/hyprslidr" rel="nofollow">hyprslidr</a>: scrollable tiling on top of Hyprland.</li>
<li><a href="https://github.com/mogenson/PaperWM.spoon">PaperWM.spoon</a>: scrollable tiling on top of macOS.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">Our main communication channel is a Matrix chat, feel free to join and ask a question: <a href="https://matrix.to/#/#niri:matrix.org" rel="nofollow">https://matrix.to/#/#niri:matrix.org</a></p>
<p dir="auto">We also have a community Discord server: <a href="https://discord.gg/vT8Sfjy7sx" rel="nofollow">https://discord.gg/vT8Sfjy7sx</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Praise of RSS and Controlled Feeds of Information (328 pts)]]></title>
            <link>https://blog.burkert.me/posts/in_praise_of_syndication/</link>
            <guid>45459233</guid>
            <pubDate>Fri, 03 Oct 2025 05:13:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.burkert.me/posts/in_praise_of_syndication/">https://blog.burkert.me/posts/in_praise_of_syndication/</a>, See on <a href="https://news.ycombinator.com/item?id=45459233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The way we consume content on the internet is increasingly driven by walled-garden platforms and black-box feed algorithms. This shift is making our media diets miserable. Ironically, a solution to the problem predates algorithmic feeds, social media and other forms of informational junk food. It is called RSS (Really Simple Syndication) and it is beautiful.</p><p>RSS is just a format that defines how websites can publish updates (articles, posts, episodes, and so on) in a standard feed that you can subscribe to using an RSS reader (or aggregator). Don’t worry if this sounds extremely uninteresting to you; there aren’t many people that get excited about format specifications; the beauty of RSS is in its simplicity. Any content management system or blog platform supports RSS out of the box, and often enables it by default. As a result, a large portion of the content on the internet is available to you in feeds that you can tap into. But this time, you’re in full control of what you’re receiving, and the feeds are purely reverse chronological bliss. Coincidentally, you might already be using RSS without even knowing, because the whole podcasting world <a href="https://www.thepodcasthost.com/business-of-podcasting/podcasts-need-an-rss/" target="_blank" rel="noopener">runs on RSS</a>.</p><p>There are many amazing articles about the utility and elegance of RSS, and I do not think the world needs another, so I will spare you and instead focus on my personal experience and tips. If you are interested in a deeper dive, I highly recommend Molly White’s article <a href="https://www.citationneeded.news/curate-with-rss/" target="_blank" rel="noopener">Curate your own newspaper with RSS</a>. It is a convincing, well-written article that you can also listen to in Molly’s own voice if you wish to.</p><h2 id="broken-distribution-models">Broken distribution models</h2><p>Here’s a little story about the promise of social media. In 2011, my <a href="https://somnusaeternus.cz/" target="_blank" rel="noopener">band</a> was getting a little more serious and preparing to record our first album. Facebook was rapidly growing all over the world, so I created an account - mostly to manage my band’s Facebook page. Back then, social media (and Facebook in particular) felt very different: vibrant and full of promise for the brave new future of web 2.0. I looked up all my favorite bands so that every time they put out an album or tour near me, I wouldn’t miss it. Many bands either lacked proper websites or rarely updated them in a useful way, so this felt like the perfect use case for Facebook.</p><p>It didn’t take long for me to start seeing the cracks. As Facebook would push for more engagement, some bands would flood their pages with multiple posts per day, especially if they were touring or had a new release coming up. Others would be more restrained, but then their posts would often be lost in the feed. There was no way to opt in only for a certain type of updates from my followed pages, and the increasingly algorithmic feed would simply prioritize posts by engagement. I realized that I wouldn’t be able to get just the <strong>important</strong> updates; instead, I’d get a wild mish-mash of engagement-bait that I wasn’t willing to work my way through. And don’t get me started about how over time, page owners had to pay to promote their posts to get any reach on the platform - that is simply extortion.</p><p>I no longer use Facebook (or any similar social media for that matter) for many reasons, though algorithmic feeds are at the top of the list. Algorithms on social media are very unlikely to be written with your best interest in mind: The goal of social media is to keep you glued to the feed for as long as possible. It optimizes for the most time spent, for engagement, for serving the most ads. It will not necessarily optimize for keeping you well informed, showing you balanced opinions, giving you control or even showing you all the information you’d like. The misalignment of incentives has become very apparent in the last few years, but the problem goes deeper. Any type of curation (because algorithmic feeds are simply curation machines) will never be flexible enough to account for every person’s needs. The story we are sold with algorithmic curation is that it adapts to everyone’s taste and interests, but that’s only true until the interests of the advertisers enter the picture.</p><p>My RSS journey starting many moons ago with Opera and Thunderbird, continued with Google Reader (RIP) and <a href="https://www.theoldreader.com/en/" target="_blank" rel="noopener">The Old Reader</a>, and finally led me to running my own instance of <a href="https://www.freshrss.org/" target="_blank" rel="noopener">FreshRSS</a>. However, in the last year, I have read most of the content from my RSS feeds on my phone via the <a href="https://github.com/seazon/FeedMe" target="_blank" rel="noopener">FeedMe</a> app. I find that it scratches the itch of unlocking your phone and wanting to see something novel (probably gravitating towards social media). On the upside, it feeds me only articles and media that a) I have picked upfront and nothing more, b) is typically longer-form and more thoughtful than your typical social media posts.</p><p>Also, unlike algorithmic feeds, it allows me to pick what category of my interests I am in the mood for. If I’m in the mood for something lighter, I can just look into my “Fun” folder to check out new stuff from <a href="https://theoatmeal.com/" target="_blank" rel="noopener">The Oatmeal</a> or <a href="https://xkcd.com/" target="_blank" rel="noopener">xkcd</a>. If I feel like reading something more thoughtful, I’d dive into my “Reads” folder for <a href="https://www.themarginalian.org/" target="_blank" rel="noopener">The Marginalian</a> or <a href="https://sentiers.media/" target="_blank" rel="noopener">Sentiers</a>. Feeling like catching up on the newest AI research? I can browse the latest research papers from <a href="https://arxiv.org/" target="_blank" rel="noopener">arXiv</a> that have specific keywords in the abstracts (such as prompt injection). Or I could just browse everything at once to see what piques my interest. I am the master of what information I consume, how and in what order, and no one can take that away from me by rearranging my feed or tweaking the algorithm.</p><p>One of the many small advantages is the consistency of the interface and the lack of distractions when reading. Modern browsers support reader modes, but you need to enter the mode manually and some pages might not be displayed correctly. I don’t have any attention problems (that I know of), but reading articles on certain newspaper sites feels like a cruel joke: the text of the article is often drowned by ads, suggested articles, polls, and other visual smog. Not a pleasant reading experience. Your RSS reader always uses the same font, font size, screen real estate and never shows anything but the article itself.</p><p>The focused, reductive nature of RSS readers means you don’t get the full website experience, but that is arguably for the better in a lot of cases. We already mentioned the lack of suggested articles with engagement bait that could easily draw you in, but another notable omission is the comments section. It is very easy to slip into the comments section at the bottom of an article and spend far too much time reading those. You can still do that in an RSS reader by opening the article in your browser, scrolling down to the comments and diving in. At least in my case, that is a safe amount of friction to prevent me from doing it most of the time. Less is more!</p><h2 id="tips-to-get-you-going">Tips to get you going</h2><ul><li>Many of the websites you open regularly, follow on social media or get a newsletter from, likely have an RSS feed. Look out for the <a href="https://en.wikipedia.org/wiki/File:Feed-icon.svg#/media/File:Feed-icon.svg" target="_blank" rel="noopener">RSS icon</a> or the words RSS or feed. There are also tools like <a href="https://lighthouseapp.io/tools/feed-finder" target="_blank" rel="noopener">Lighthouse</a> that can sniff out the feed for you. That said, my experience is that simply adding the homepage URL of the website into an aggregator usually works.</li><li>Remember my frustration with Facebook as a source of news for new music releases? Turns out there is a much better free solution called <a href="https://muspy.com/" target="_blank" rel="noopener">Muspy</a>, where you enter all your favorite artists and it will notify you of their new releases. And guess what? You either get notified via email, or you use your personal RSS feed. Highly recommended!</li><li>Start easy with something like <a href="https://www.theoldreader.com/en/" target="_blank" rel="noopener">The Old Reader</a> or <a href="https://feedly.com/news-reader" target="_blank" rel="noopener">Feedly</a> - both offer relatively generous free tiers. And if you outgrow them or want to try something else, you simply export an <a href="https://en.wikipedia.org/wiki/OPML" target="_blank" rel="noopener">OPML</a> file with all your feeds and import them into your new RSS solution. This is the upside of open standards: freedom, ownership, and portability.</li><li>Once you have more than 5-10 feeds, start putting them into folders/categories. No need to overthink it, but doing this will help you be more selective about the content you read if you’re in a specific mood.</li><li>RSS readers can be great when traveling or whenever your internet connection might be down or spotty. You can set up your RSS client in a way that automatically fetches new content, so when you board the plane and go dark, you can still read through the already downloaded articles. (Beware, though: not all RSS feeds include full content - sometimes they’re more like teasers.)</li><li>Some websites that limit how many articles you can browse for free are actually less strict about content accessed through RSS feeds. There are obvious ethical concerns with abusing this, but it is still an upside, and you are only consuming what they provide.</li><li>If you want to tinker, you can set up an RSS aggregator like <a href="https://github.com/FreshRSS/FreshRSS" target="_blank" rel="noopener">FreshRSS</a>, <a href="https://github.com/torne/Tiny-Tiny-RSS" target="_blank" rel="noopener">tiny tiny RSS</a> or <a href="https://github.com/fossar/selfoss" target="_blank" rel="noopener">selfoss</a> on a shared web hosting service. If you want to go full self-hosted, there are <a href="https://selfh.st/alternatives/rss-readers/" target="_blank" rel="noopener">many more options available</a>.</li><li>Get a good mobile app. Try a few before you settle! This is a highly personal choice because even small UI quirks and differences may bother you. If you’re anything like me, you’ll do most of the reading on your phone, so make sure it feels good.</li><li>RSS readers/clients often have bookmarking/starring system which works much like dedicated bookmarking apps.</li><li>Bigger publications often have separate feeds for individual categories or tags - check those to avoid getting your main feed flooded.</li><li>Some websites have very elaborate RSS APIs which allow you to query for specific types of content. For example, <a href="https://info.arxiv.org/help/api/basics.html#quickstart" target="_blank" rel="noopener">arXiv</a> has a really elaborate one, allowing you to only follow specific topics. The documentation is quite complex, so here is a quick example to kick start you:<ul><li><code>https://export.arxiv.org/api/query?search_query=abs:LLM+AND+multilingual&amp;sortBy=submittedDate&amp;sortOrder=descending</code></li><li>The query searches through the most recently submitted papers with the words LLM and multilingual in the abstract.</li></ul></li><li>Do a little cleanup from time to time: unsubscribe from feeds that no longer seem to interest you. It’s fine, no one will take offense, and your attention is too precious to be wasted on stuff that is not for you.</li><li>Don’t know where to start? Check out <a href="https://themeisle.com/blog/rss-feeds-list/" target="_blank" rel="noopener">this list of 100 most popular RSS feeds</a>, <a href="https://rss.feedspot.com/best_rss_feeds/" target="_blank" rel="noopener">Feedspot’s 70 most popular feeds</a> or <a href="https://www.hostinger.com/tutorials/blog-examples" target="_blank" rel="noopener">Hostinger’s list of 55 popular blogs</a>. Apart from that, Google is your friend (especially if you start searching for specific topics or niches), and good blogs often link to other blogs - all you need to do is to follow the breadcrumbs.</li></ul><p>Happy RSS-ing!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fp8 runs ~100 tflops faster when the kernel name has "cutlass" in it (328 pts)]]></title>
            <link>https://github.com/triton-lang/triton/pull/7298</link>
            <guid>45458948</guid>
            <pubDate>Fri, 03 Oct 2025 04:21:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/triton-lang/triton/pull/7298">https://github.com/triton-lang/triton/pull/7298</a>, See on <a href="https://news.ycombinator.com/item?id=45458948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-snippet-clipboard-copy-content="ValueError('Layout mismatch in broadcast: 

SliceLayout(dim=1, parent=BlockedLayout(size_per_thread=[1, 128], threads_per_warp=[32, 1], warps_per_cta=[4, 1], order=[0, 1], ctas_per_cga=[1, 1], cta_split_num=[1, 1], cta_order=[1, 0])) 
vs 
SliceLayout(dim=1, parent=DistributedLinearLayout(reg_bases=[[0, 64], [0, 1], [0, 2], [0, 4], [0, 8], [0, 16], [0, 32]], lane_bases=[[1, 0], [2, 0], [4, 0], [8, 0], [16, 0]], warp_bases=[[32, 0], [64, 0]], block_bases=[], shape=[128, 128]))')"><pre><code>ValueError('Layout mismatch in broadcast: 

SliceLayout(dim=1, parent=BlockedLayout(size_per_thread=[1, 128], threads_per_warp=[32, 1], warps_per_cta=[4, 1], order=[0, 1], ctas_per_cga=[1, 1], cta_split_num=[1, 1], cta_order=[1, 0])) 
vs 
SliceLayout(dim=1, parent=DistributedLinearLayout(reg_bases=[[0, 64], [0, 1], [0, 2], [0, 4], [0, 8], [0, 16], [0, 32]], lane_bases=[[1, 0], [2, 0], [4, 0], [8, 0], [16, 0]], warp_bases=[[32, 0], [64, 0]], block_bases=[], shape=[128, 128]))')
</code></pre></div><p dir="auto">It seems that <code>p</code> ends up with a linear layout instead of a blocked layout. I am not sure why though -- I believe the layout inference should try a blocked layout first before falling back to linear layout.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Digital ID – The New Chains of Capitalist Surveillance (138 pts)]]></title>
            <link>https://theslowburningfuse.wordpress.com/2025/09/26/digital-id-the-new-chains-of-capitalist-surveillance/</link>
            <guid>45458909</guid>
            <pubDate>Fri, 03 Oct 2025 04:15:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theslowburningfuse.wordpress.com/2025/09/26/digital-id-the-new-chains-of-capitalist-surveillance/">https://theslowburningfuse.wordpress.com/2025/09/26/digital-id-the-new-chains-of-capitalist-surveillance/</a>, See on <a href="https://news.ycombinator.com/item?id=45458909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div>
<figure><a href="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png"><img data-attachment-id="3631" data-permalink="https://theslowburningfuse.wordpress.com/2025/09/26/digital-id-the-new-chains-of-capitalist-surveillance/crime_files__005_cbz-zip-page-28-2/" data-orig-file="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png" data-orig-size="549,513" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crime_files__005_cbz-zip-page-28" data-image-description="" data-image-caption="" data-medium-file="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png?w=300" data-large-file="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png?w=549" width="549" height="513" src="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png?w=549" alt="" srcset="https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png 549w, https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png?w=150 150w, https://theslowburningfuse.wordpress.com/wp-content/uploads/2025/09/crime_files__005_cbz-zip-page-28.png?w=300 300w" sizes="(max-width: 549px) 100vw, 549px"></a></figure></div>


<p>From <a href="https://awsm.nz/digital-id-the-new-chains-of-capitalist-surveillance/">https://awsm.nz/digital-id-the-new-chains-of-capitalist-surveillance/</a></p>



<p>The world is entering an era where identity is no longer a matter of personal relationships, lived experience, or even paperwork. Increasingly, it is reduced to biometric scans, algorithmic verification, and digital tokens. Across the globe, governments and corporations are rolling out digital identification systems, facial recognition passports, biometric driver’s licences, app-based vaccine passes, QR-coded welfare access, and unified digital wallets. The language that accompanies these projects is familiar – efficiency, convenience, modernisation, inclusion. We are told that digital ID will make life easier, reduce fraud, and open new opportunities.</p>



<p>The reality, however, is far more sinister. Identification has never been neutral, it has always been a weapon of power, wielded by states and capitalists to monitor, control, and discipline populations. From passports to colonial passbooks, from welfare cards to border regimes, the apparatus of identification has always been tied to domination. Digital ID is simply the latest iteration of this long history, but with a scale and sophistication that makes its dangers even more profound. Far from liberating us, it is forging new chains and binding us more tightly to systems of surveillance, exclusion, and exploitation.</p>



<p><strong>Identification as Domination</strong></p>



<p>To grasp what digital ID represents, we must situate it within the longer history of identification as a tool of authority. The passport, now normalised as a necessary object of travel, was originally a way for states to restrict movement. In medieval Europe, peasants and serfs required written permission to leave their estates. Colonial regimes across Africa, Asia, and the Pacific perfected these systems of control, forcing indigenous people to carry passes while settlers roamed unhindered. In apartheid South Africa, the “pass laws” criminalised Black South Africans for existing outside their assigned zones, reducing life itself to a bureaucratic calculation of permission.</p>



<p>Identification has never been about protecting the individual; it has been about protecting property relations. States have needed to know who people are in order to tax them, conscript them, and deny them rights. Employers demanded papers to guarantee that workers were legally exploitable. Landlords used identification to screen tenants, banks to gate-keep credit, police to track dissenters. The notion of “identity” under capitalism has always been bound up with surveillance and discipline.</p>



<p>Digital ID does not break from this tradition but it intensifies it. What once required a physical stamp or signature now demands a biometric scan or QR code. Where once a police officer demanded to see your papers, now an algorithm silently determines your access. The shift is not from control to freedom, but from analogue domination to digital domination.</p>



<p><strong>The Logic of Digital ID</strong></p>



<p>Behind the rhetoric of convenience lies the hard logic of capital and the state. Digital ID is not being built for us, it is being built to extend the power of those who already govern our lives.</p>



<p>At its core, digital ID represents the enclosure of access. Increasingly, the essentials of life, healthcare, housing, employment, welfare, travel, are gated behind digital checkpoints. Without the correct identification, people are excluded. This transforms existence itself into a series of permissions, each mediated by algorithmic verification. Access to food, shelter, or work becomes conditional on whether a machine recognises your fingerprint or face.</p>



<p>It also expands surveillance capitalism. Every scan, swipe, or login generates data. This data is stored, tracked, and monetised. Digital ID reduces human beings to data streams, feeding the profits of corporations like Microsoft, Mastercard, and Accenture, companies deeply embedded in global ID initiatives. Far from empowering individuals, digital ID empowers corporations by turning our lives into commodities to be sold.</p>



<p>Digital ID also disciplines labour. By tying welfare payments, work permits, or banking access to digital identity, states and corporations acquire powerful new tools to coerce populations. In India, the Aadhaar biometric system has left millions excluded from rations and pensions when fingerprints failed to scan, producing not efficiency but hunger. Migrant workers across the world are increasingly monitored through digital verification, making precarious labour even more vulnerable.</p>



<p>Perhaps most insidiously, digital ID normalises surveillance itself. By embedding digital checkpoints into daily life, whether entering a building, logging into a service, or accessing healthcare, surveillance becomes routine. What once might have provoked outrage becomes ordinary. Control does not need to be imposed violently when it is integrated seamlessly into the everyday functions of existence.</p>



<p>The consequences of digital ID are not abstract. Around the world, its implementation reveals the sharp edges of exclusion and control.</p>



<p>As already mentioned India’s Aadhaar project, the largest biometric ID system in history, covers over a billion people. It was presented as a means of reducing corruption and expanding access to welfare. In reality, it has excluded millions of poor and rural people from food rations and pensions because their fingerprints did not register. Reports have documented starvation deaths when families were denied grain for lack of proper authentication. For the poor, the system is not convenience, it is a death sentence.</p>



<p>In Europe, digital ID takes a different but equally insidious form. The EU is developing a unified “digital identity wallet” for banking, healthcare, and travel, promoted as freedom for citizens. At the same time, the Eurodac database stores the fingerprints of asylum seekers to enforce deportations and prevent secondary movement. Digital ID here is double-edged, advertised as seamless mobility for the privileged, but functioning as chains for migrants.</p>



<p>Across Africa, the World Bank and multinational corporations are funding digital ID projects under the guise of “financial inclusion.” Tied to mobile money systems, these IDs are less about inclusion than about expanding debt markets and integrating populations into circuits of extraction. They replicate colonial practices where identification was a prerequisite for resource exploitation and labour discipline.</p>



<p>In settler-colonial states like New Zealand and Australia, digital driver’s licences and facial recognition technologies are being trialled under the language of security and convenience. But both countries maintain extensive databases of their populations, and both have long histories of surveillance and repression against indigenous peoples and political activists. Digital ID here strengthens existing patterns of racialised and political control, embedding them in everyday transactions.</p>



<p><strong>The Role of the State</strong></p>



<p>For anarchists, it is no surprise that the state is at the centre of these developments. The state has never been a neutral provider of services. It is a machinery of class rule, designed to enforce property relations and maintain hierarchy. Digital ID offers the state new levels of efficiency in population management. Welfare can be rationed through digital checkpoints, ensuring that only the “deserving” poor receive aid. Policing is strengthened through biometric databases, making dissent and protest more dangerous. Borders become omnipresent, extending into every workplace, clinic, and street corner. Even the ritual of voting is increasingly tied to digital verification, further legitimising the state’s hold.</p>



<p>But the state does not act alone. The infrastructure of digital ID is outsourced to corporations, tech giants and consultancy firms whose profits depend on extracting and selling data. ID2020, the flagship global digital ID initiative, is a partnership between Microsoft, Accenture, Gavi, and Mastercard. This fusion of state power and corporate capital creates a techno-bureaucratic regime that is incredibly difficult to resist at the level of the individual. It is not simply your government demanding your data, it is a web of global corporations embedding control into the infrastructure of daily life.</p>



<p><strong>Resistance and Its Possibilities</strong></p>



<p>And yet, systems of domination are never total. The chains of digital ID can be resisted, but the struggle requires collective defiance. Individuals cannot simply opt out when access to food, housing, or healthcare is increasingly contingent on digital verification. Resistance must be social, coordinated, and rooted in solidarity.</p>



<p>It begins with exposing the lie of convenience. The marketing of digital ID depends on people believing it is in their interests. By revealing its function as surveillance, exclusion, and profit-making, we can puncture the narrative that it is a neutral technological advance. Convenience is the sugar that coats the poison pill.</p>



<p>Resistance also means standing with those most affected by exclusion. When people are denied access to food or healthcare because a machine rejects them, solidarity demands that communities step in. Mutual aid networks, food distribution, and grassroots healthcare can undermine the state’s monopoly on survival. By caring for each other without demanding documents, communities demonstrate the possibility of life beyond identification.</p>



<p>Direct action has its place as well. Surveillance infrastructure can be disrupted, whether through physical sabotage, digital hacktivism, or leaks that expose the collusion of states and corporations. Every act that slows the expansion of digital ID chips away at its inevitability.</p>



<p>Perhaps most crucially, resistance means refusing to internalise the normalisation of surveillance. We must continue to feel anger each time a new checkpoint is introduced, each time a new biometric system is trialled, each time a new database is constructed. The greatest victory of power is not when it controls us, but when it convinces us that control is natural.</p>



<p>Digital ID is not a neutral innovation. It is the frontier of capitalist surveillance and state control. It deepens exploitation, excludes the vulnerable, and integrates every aspect of life into the machinery of profit and domination. Identification has always been a tool of authority, from medieval passes to apartheid laws, and digital ID is the most sophisticated form yet.</p>



<p>The ruling class wants us to believe digital ID is inevitable. But inevitability is the language of power. Systems of domination can be resisted, sabotaged, dismantled. The struggle against digital ID is not about nostalgia for the days of paper documents; it is about defending the very possibility of living without being constantly monitored, verified, and reduced to data.</p>



<p>What is at stake is not simply privacy, but freedom itself.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blender 4.5 brings big changes (198 pts)]]></title>
            <link>https://lwn.net/Articles/1036262/</link>
            <guid>45458791</guid>
            <pubDate>Fri, 03 Oct 2025 03:52:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1036262/">https://lwn.net/Articles/1036262/</a>, See on <a href="https://news.ycombinator.com/item?id=45458791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</p></blockquote>

<p><a href="https://blender.org/">Blender</a> 4.5 LTS <a href="https://www.blender.org/download/releases/4-5/">was released</a>
on July 15, 2025, and will be supported through 2027. This is the last
feature release of the 3D graphics-creation suite's 4.x series; it
includes quality-of-life improvements, including work to bring the <a href="https://en.wikipedia.org/wiki/Vulkan">Vulkan</a> backend up to
par with the default OpenGL backend. With 4.5 released, Blender
developers are turning their attention toward Blender 5.0, planned for
release later this year. It will introduce substantial changes,
particularly in the <a href="https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/introduction.html">Geometry
Nodes</a> system, a central feature of Blender's procedural
workflows.</p>

<h4>Brief introduction</h4>

<p>Blender is an open-source creative application released under the GPLv3.
The <a href="https://www.blender.org/foundation/">Blender Foundation</a>
stewards development, with significant funding from the <a href="https://fund.blender.org/">Blender Development Fund</a> as well
as backing from individual contributors and industry sponsors. Its
code is primarily written in C and <span>C++</span>,
with Python used extensively for scripting and add-ons.</p>

<p>While Blender is often known as a 3D modeling and animation tool,
it has grown into a comprehensive open-source suite for digital
content creation. Alongside powerful 3D tools, it features
compositing, <a href="https://www.blender.org/features/video-editing/">nonlinear
video editing</a>, and 2D animation in 3D space. This integrated suite
of tools enables designers, animators, and other creators to work with
a single application across their digital pipeline. Blender also
provides access to its core functions through <a href="https://docs.blender.org/manual/en/latest/interface/controls/nodes/introduction.html">Nodes</a>,
a visual programming system that enables procedural workflows for
complex operations. The <a href="https://docs.blender.org/manual/en/latest/grease_pencil/introduction.html">Grease
Pencil tool</a>, also accessible through the Geometry Nodes system, is
used for 2D animation, cut-out animation, motion graphics, and more. Blender's procedural systems rely heavily
on these node-based graphical interfaces, and the 4.5 LTS focuses on
their continued evolution. These systems enable fully non-destructive
workflows, preserving all original data at every stage of the editing
process.</p>

<!-- middle-ad -->

<p>Blender strives to be compatible with visual-effects (VFX) industry
standards through alignment with the <a href="https://vfxplatform.com/">VFX Reference Platform</a>, which is
updated annually. This allows Blender to be run on the same systems as
other VFX software, as well as share files with them. 4.5 brings <a href="https://projects.blender.org/blender/blender/issues/136540">a
slew of library updates</a> to maintain alignment with the reference
platform.</p>

<h4>A solid foundation</h4>

<p>Historically, Blender has relied
on <a href="https://www.opengl.org/">OpenGL</a> for drawing its user
interface and powering its 3D-display capabilities. However, efforts
are underway to modernize this aspect of its core functionality
by <a href="https://developer.blender.org/docs/features/gpu/">abstracting
away the rendering backend</a>, bringing support for running on additional
graphics APIs, including Vulkan
and <a href="https://en.wikipedia.org/wiki/Metal_%28API%29">Apple's
Metal API</a>. The Vulkan API is a
low-overhead, cross-platform standard that allows applications like
Blender to communicate more directly with GPU hardware than OpenGL. Being the
final feature release of the 4.x series, this LTS brings a critical
step in the maturity of
the <a href="https://developer.blender.org/docs/release_notes/4.5/eevee/#vulkan">Vulkan
backend</a>. Though still not enabled by default due to multiple
outstanding issues, it now rivals the OpenGL backend in both features
and performance.</p>

<p>Vulkan is built on a <a href="https://docs.vulkan.org/tutorial/latest/17_Multithreading.html">parallel-execution model</a>, allowing applications to send multiple commands
to the GPU simultaneously, while OpenGL relies on a sequential
model. Vulkan's execution model makes better use of the increased number
of cores found in modern GPUs. This is a <a href="https://code.blender.org/2023/10/vulkan-project-update/">crucial
step</a> toward smoother viewport performance and more responsive
interaction with complex scenes.</p>

<p>There are <a href="https://developer.blender.org/docs/release_notes/4.5/eevee/#limitations">known
limitations</a> still blocking the new backend from being adopted as
the default. Notably, large meshes with 100-million vertices or
more are not yet supported, resulting in poor performance on the
Vulkan backend for virtual reality and other high-mesh-count
applications. Future driver updates may address some of these
issues.</p>

<p>The viewport in Blender is an interactive view space where 3D
scenes are displayed and constructed. Rendering converts 3D scenes
into 2D images or video, producing the final output with Blender's
built-in engines or third-party renderers. Rendering can also be
performed without the graphical interface by running Blender in
headless mode, both on individual systems and at scale on render
farms. The viewport and rendering upgrades in Blender 4.5 extend
beyond the improvements to its Vulkan backend. Specifically, work
continues
on <a href="https://docs.blender.org/manual/en/latest/render/eevee/introduction.html">EEVEE</a>,
the realtime rendering engine built for rapid, interactive rendering
on modern GPUs. EEVEE 2.0, also known as EEVEE Next, receives several
critical improvements focused on stability and visual
accuracy. Shadows now render more smoothly thanks to the addition
of <a href="https://projects.blender.org/blender/blender/commit/81c00bf272f22dc732b0fc8c9d7db39c5f916a07">shadow
terminator normal bias</a>. This is an area where EEVEE has struggled
to match other renderers, including Blender's
own <a href="https://www.cycles-renderer.org/">Cycles rendering
engine</a>.</p>

<p>Two settings control shadow termination bias: "Geometry Offset" and "Shading
Offset", <a href="https://docs.blender.org/manual/en/4.5/render/cycles/object_settings/object_data.html#shading">found
in the "Shading" tab</a> of the "Object Properties" panel. This gives
artists greater control over the position and angle of
shadows. However, due to the difficulties of creating shadows that work
equally well for all projects, the default for these settings is
"no bias". These visual improvements coincide with fixes for rendering
problems such as <a href="https://projects.blender.org/blender/blender/commit/b01cdf7df2ba62c66cf0fce4521d65afa46acf52">light
leaking from large light sources</a>. Light leaking is a phenomenon
where light incorrectly passes through or around solid objects,
creating unrealistic bright spots in the rendered scene. Overall,
these changes aim to bring EEVEE Next closer to parity with other
renderers.</p>

<p>Beyond rendering quality, this LTS release delivers 
improvements to workflow fluidity. Texture loading, shader
compilation, and startup times all contribute to overall performance
and user experience, and all
three <a href="https://developer.blender.org/docs/release_notes/4.5/eevee/#performance">have
been improved</a>. Textures are now loaded
using <a href="https://projects.blender.org/blender/blender/commit/1d638c0f5e8b90c41fec92147d9fcd286aec015c">a
deferred, multithreaded process</a>, resulting in more than double the
speed of the previous method. This change introduces a small CPU
overhead due to loading textures before redrawing the viewport, but
the cost is not significant enough to severely impact performance.</p>

<p>Shaders
are <a href="https://projects.blender.org/blender/blender/commit/1c47e31367b78a770d8ad5452d2e80cab5b51e94">also
now compiled in parallel</a>. Crucially, this
optimization is independent of the viewport backend in use, whether
Vulkan or OpenGL, translating to immediate benefits from these core
improvements. That said,
a <a href="https://docs.blender.org/manual/en/4.5/editors/preferences/system.html#:~:text=Shader%20Compilation-,method,-Defines%20the%20method">new
preference</a> allows users to revert to sub-process shader
calculation, if desired, which is faster but consumes more RAM. Additionally, by skipping unnecessary shading
steps during viewport initialization, startup times have been improved
significantly.</p>

<p>With ongoing efforts to improve the workspace, users can
now <a href="https://docs.blender.org/manual/en/4.5/editors/properties_editor.html#:~:text=Visible-,tabs,-Allows%20hiding%20specific">control
which tabs are visible</a> in the Properties Editor through the
right-click pop-up
menu. The <a href="https://docs.blender.org/manual/en/latest/editors/asset_browser.html">Asset
Browser</a>, used for importing and organizing assets (including
scenes, 3D objects, textures, and more), has been
continually refined throughout the 4.x series. In 4.5 LTS, it receives
some key usability enhancements, particularly in how assets are
displayed, such as wrapping long lines used for asset labels, and
making it easier to create thumbnails for assets.</p>

<h4>Nodes, Grease Pencil, and modeling polish</h4>

<p>Rather than focusing solely on fixes
and <a href="https://developer.blender.org/docs/release_notes/4.5/geometry_nodes/#performance">performance
gains</a>, this cycle emphasized tighter
integration between the various node systems in Blender. The result is
that <a href="https://docs.blender.org/manual/en/4.5/editors/shader_editor.html">Shader
Nodes</a>, <a href="http://docs.blender.org/manual/en/4.5/editors/compositor.html">Compositor
Nodes</a>,
and <a href="https://docs.blender.org/manual/en/4.5/editors/geometry_node.html">Geometry
Nodes</a> (including Grease Pencil Nodes) now share more capabilities
and have a more consistent workflow.</p>

<p>The common nodes (including mathematical operations)
and <a href="https://docs.blender.org/manual/en/4.5/render/materials/legacy_textures/introduction.html">procedural
textures</a> available with Shader Nodes and Geometry Nodes
are <a href="https://projects.blender.org/blender/blender/commit/0a80f470f8">now
available</a> for use in the Compositor. This change enables effects
such as procedurally generated visual noise or cloudiness applied to
an image or video during post-processing. Common nodes can be copied
across Shader and Geometry Node setups, further aligning node logic
and capability design across the toolset. In Geometry Nodes, the new
"Set Mesh Normal" node grants artists direct control over custom
normals, which are perpendicular vectors that are used to represent
the orientation of a surface. By allowing users to define normals via
<a href="https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/fields.html">Fields</a>,
Blender provides <a href="https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/mesh/write/set_mesh_normal.html">fine-grained
procedural controls</a> for surface shading. For instance, an animator
could drive this node with a value to simulate a material seamlessly
transitioning from a soft, smooth surface to a rough, hard-edged one,
all without the need for manually editing the mesh.</p>

<p>In
4.5, <a href="https://docs.blender.org/manual/en/latest/modeling/point_cloud/index.html">Point
Clouds</a> debut
as <a href="https://projects.blender.org/blender/blender/issues/75717">a
new object type</a>, accessible from the "Add" menu in the viewport or
through various Geometry Nodes. Point Clouds represent objects as a
group of points in 3D space and have long been used in scientific and
industrial 3D scanning. According to the Blender <a href="https://developer.blender.org/docs/features/objects/pointcloud/#point-cloud-object">developer
documentation on Point Clouds</a>, this new object
type supports motion graphics, physics simulations (including particle systems),
granular materials (such as sand and gravel), and 3D scanning. To this
end, Blender
includes <a href="https://docs.blender.org/manual/en/4.5/modeling/point_cloud/tools.html">comprehensive
tools</a>
and <a href="https://docs.blender.org/manual/en/4.5/modeling/point_cloud/editing.html">editable
object attributes</a>, including standard transformations like
rotation and scale. It
also <a href="https://developer.blender.org/docs/features/objects/pointcloud/#rendering">maintains
high rendering performance</a> through EEVEE and Cycles, putting point
clouds on par with meshes.</p>

<blockquote>
<a href="https://lwn.net/Articles/1038255/#id">
<img src="https://static.lwn.net/images/2025/BlenderClouds-sm.png" alt="[Blender showing the Point Clouds object type]" title="Blender showing the Point Clouds object type">
</a>
</blockquote>

<h4>Looking ahead</h4>

<p>With 4.5 LTS out the door, the Blender developers have shifted
focus to 5.0, the next major release, which is now
under active development. As the beginning of a new, feature-breaking series,
5.0 <a href="https://cgcookie.com/posts/blender-5-0-release-what-do-we-know-and-what-to-look-forward-to">introduces</a>
significant refinements and modernized workflows without abandoning the
<a href="https://developer.blender.org/docs/release_notes/2.80/ui/">user
interface paradigm established by Blender 2.80</a> in 2019. The <a href="https://developer.blender.org/docs/release_notes/5.0/">release
notes</a> outline several key features planned for the release. Among
these improvements is the ability to <a href="https://projects.blender.org/blender/blender/commit/ba3eaf3a841388a6e5e44677662be4bffd787e04">mark
scenes as assets</a>, allowing entire scenes with their contents and
setup to be pulled directly into the visual scene editor using the asset browser.</p>

<p>The Grease Pencil
tool in 5.0 <a href="https://projects.blender.org/blender/blender/commit/f7a000345201f259b94e754341d1b4925c25e8d1">supports</a> the <a href="https://en.wikipedia.org/wiki/Motion_blur_%28media%29">motion
blur</a> effect, controlled by the new "Motion Blur Steps" setting in
the "Grease Pencil" render panel. Linux users now benefit from <a href="https://projects.blender.org/blender/blender/issues/140277">HDR
support in the viewport</a> on Wayland when using the Vulkan
backend. Additionally, <a href="https://projects.blender.org/blender/blender/commit/59a759b98d1">a
change to the <tt>.blend</tt> file format to handle larger content</a>
allows Blender to store meshes with
more than a few hundred million vertices. This feature <a href="https://developer.blender.org/docs/release_notes/5.0/core/#large-buffers-in-blend-files">required
a change</a> to the file structure of the <tt>.blend</tt> file format, meaning
that files created in version 5.0 are incompatible with Blender 4.4
and prior releases, but can be loaded in 4.5 LTS. While the new format
supports meshes with hundreds of millions of vertices, working with
such files still demands powerful hardware, specifically large amounts
of system RAM and GPU memory.</p>

<p>Blender
5.0 <a href="https://devtalk.blender.org/t/gsoc-2025-edit-mesh-mirror-improvements/40369">improves
symmetry</a> in Edit Mode by ensuring mirrored operations no longer
fail or produce inconsistent
results. <a href="https://en.wikipedia.org/wiki/UV_mapping">UV
mapping</a>, the process of unfolding the surface of a 3D model onto a
2D image for applying textures, sees improvements in Blender 5.0
thanks to improved synchronization. This change ensures selections
remain aligned between the viewport and the UV Editor. Blender 5.0
finally resolves this longstanding limitation.</p>

<p>Those interested in downloading Blender 4.5
can <a href="https://www.blender.org/download/">get official
builds</a> from the project
web site, <a href="https://flathub.org/apps/org.blender.Blender">install
the Flatpak</a> via <a href="https://flathub.org/">Flathub</a>,
or <a href="https://snapcraft.io/blender">install the snap package</a>
from the <a href="https://snapcraft.io/">Snap Store</a>.</p>

<p><a href="https://studio.blender.org/projects/dogwalk/">DOGWALK</a>,
a game by the Blender Foundation, which was built using Blender and
the <a href="https://godotengine.org/">Godot</a> engine,
was released at the same time as 4.5. The game is
freely available for
download from <a href="https://studio.blender.org/projects/dogwalk/gallery/">Blender
Studio</a>, <a href="https://store.steampowered.com/app/3775050/DOGWALK/">Steam</a>, and <a href="https://blenderstudio.itch.io/dogwalk">Itch.io</a>.</p> 

<p>According to the release schedule, Blender 5.0 will enter beta on
October 1, 2025. Interested users can access official daily builds
from <a href="https://builder.blender.org/download/daily/">Blender's
experimental downloads page</a>. Blender's development is open to
contributors of all backgrounds; instructions on contributing <a href="https://developer.blender.org/docs/handbook/contributing/">code</a>,
<a href="https://developer.blender.org/docs/contribute/">documentation</a>,
and <a href="https://developer.blender.org/docs/handbook/new_developers/">more</a>
are available in the <a href="https://developer.blender.org/">developer portal</a>.</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Taylor_Roland">Taylor, Roland</a></td></tr>
            </tbody></table><br clear="all">
<hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stdlib: A library of frameworks, templates, and guides for technical leadership (112 pts)]]></title>
            <link>https://debuggingleadership.com/stdlib</link>
            <guid>45458249</guid>
            <pubDate>Fri, 03 Oct 2025 02:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://debuggingleadership.com/stdlib">https://debuggingleadership.com/stdlib</a>, See on <a href="https://news.ycombinator.com/item?id=45458249">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Your library of frameworks, templates, and guides for technical leadership</p><div><svg fill="currentColor" viewBox="0 0 24 24"><path d="M16 11c1.66 0 2.99-1.34 2.99-3S17.66 5 16 5c-1.66 0-3 1.34-3 3s1.34 3 3 3zm-8 0c1.66 0 2.99-1.34 2.99-3S9.66 5 8 5C6.34 5 5 6.34 5 8s1.34 3 3 3zm0 2c-2.33 0-7 1.17-7 3.5V19h14v-2.5c0-2.33-4.67-3.5-7-3.5zm8 0c-.29 0-.62.02-.97.05 1.16.84 1.97 1.97 1.97 3.45V19h6v-2.5c0-2.33-4.67-3.5-7-3.5z"></path></svg><p><span>Community-built collection with more than<span>&nbsp;1,000&nbsp;</span>resources</span></p></div></div><div><a href="https://debuggingleadership.com/stdlib/bc6ae364-eba5-4abf-9897-8db83b91e910"><div data-slot="card"><h3>The Case for Comment-Driven Development</h3><p>Why writing more comments makes you a better developer. Learn how AI-native teams use Comment Driven Development to ship maintainable code faster with AI coding agents.</p><p><span>#<!-- -->comment-driven development</span><span>#<!-- -->software engineering</span><span>#<!-- -->ai coding</span><span>#<!-- -->technical leadership</span><span>#<!-- -->code maintainability</span></p></div></a><a href="https://debuggingleadership.com/stdlib/93b6581d-666f-4a50-8492-4b9ce0a47a9c"><div data-slot="card"><h3>Distracting software engineers is more harmful than most managers think</h3><p>A brief analysis of how interrupting engineers negatively impacts productivity and team morale, especially in the AI era.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering-management</span><span>#<!-- -->productivity</span><span>#<!-- -->distraction</span><span>#<!-- -->software-engineering</span><span>#<!-- -->AI</span><span>#<!-- -->team-morale</span></p></div></a><a href="https://debuggingleadership.com/stdlib/79d5e663-4880-4a0f-a3c5-3cb18bb3ef9f"><div data-slot="card"><h3>Asked to do something illegal at work? Here's what these software engineers did</h3><p>Software engineers at FTX, Frank, and Pollen were asked to perform potentially illegal actions. The article explains how they responded, the consequences, and why engineers should push back against unethical requests.</p><div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.1 1.1"></path></svg><p>blog.pragmaticengineer.com</p></div><p><span>#<!-- -->ethics</span><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software engineering</span><span>#<!-- -->risk management</span><span>#<!-- -->compliance</span></p></div></a><a href="https://debuggingleadership.com/stdlib/7971bb3c-a35f-4ba4-8d06-5edcb80bdf6b"><div data-slot="card"><h3>Team Topologies: Organizing Business and Technology Teams for Fast Flow</h3><p>A practical guide to designing team structures that enable fast software delivery and improve organizational health.</p><p><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->team organization</span><span>#<!-- -->software architecture</span><span>#<!-- -->devops</span><span>#<!-- -->microservices</span><span>#<!-- -->organizational design</span><span>#<!-- -->agile</span></p></div></a><a href="https://debuggingleadership.com/stdlib/7d2badb8-322d-466b-8446-64ae76918a56"><div data-slot="card"><h3>Clearer delegation, smoother incidents</h3><p>A blog post discussing how clearer delegation practices can lead to smoother incident response.</p><p><span>#<!-- -->delegation</span><span>#<!-- -->incident management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->SRE</span></p></div></a><a href="https://debuggingleadership.com/stdlib/9bc4c645-ec2b-41b1-8ce5-24a49aec3965"><div data-slot="card"><h3>Strategies for Handling Unplanned Work During Sprint</h3><p>The article explores how agile teams can effectively manage unplanned work that arises during a sprint, offering practical strategies to maintain flow and delivery commitments.</p><p><span>#<!-- -->agile</span><span>#<!-- -->scrum</span><span>#<!-- -->unplanned work</span><span>#<!-- -->sprint planning</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->software development</span><span>#<!-- -->project management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/35c06497-f9eb-47ab-8d51-89a52296b288"><div data-slot="card"><h3>Engineering Process Is Overvalued</h3><p>The article argues that engineering processes are often overemphasized and highlights people, capabilities, and team dynamics as the true drivers of successful engineering teams.</p><p><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->process</span><span>#<!-- -->agile</span><span>#<!-- -->scrum</span><span>#<!-- -->team dynamics</span><span>#<!-- -->hiring</span><span>#<!-- -->product development</span><span>#<!-- -->software engineering</span><span>#<!-- -->leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/d7f74bd4-46a4-4e4a-830d-a3eae7147c7d"><div data-slot="card"><h3>Business Thinking for Tech Executives</h3><p>A concise guide that helps technology leaders adopt a business mindset to drive strategic outcomes and improve cross-functional collaboration.</p><p><span>#<!-- -->business</span><span>#<!-- -->tech leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->strategy</span><span>#<!-- -->executive</span><span>#<!-- -->decision making</span></p></div></a><a href="https://debuggingleadership.com/stdlib/20ff8ac2-6d3f-4a33-872c-b8753c60c869"><div data-slot="card"><h3>Do junior devs still have a path to senior roles in an AI age?</h3><p>LeadDev's AI Impact Report 2025 explores the challenges and opportunities for early-career engineers as AI transforms coding, mentorship, and skill development.</p><p><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->hiring</span><span>#<!-- -->AI</span><span>#<!-- -->career development</span><span>#<!-- -->junior developers</span><span>#<!-- -->senior roles</span></p></div></a><a href="https://debuggingleadership.com/stdlib/41bcde1a-a22c-477b-b6f6-565fdc997949"><div data-slot="card"><h3>Measuring team performance isn't getting any easier</h3><p>Join us to learn why 500 engineering leaders still find measuring team performance a major challenge.</p><p><span>#<!-- -->engineering leadership</span><span>#<!-- -->team performance</span><span>#<!-- -->metrics</span><span>#<!-- -->measurement</span><span>#<!-- -->software engineering</span><span>#<!-- -->management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/1515de91-03fa-4e78-9847-a3e7e8760582"><div data-slot="card"><h3>The surprising habits of high velocity engineering teams</h3><p>Working smarter, not harder, to achieve high velocity.</p><p><span>#<!-- -->engineering leadership</span><span>#<!-- -->high velocity</span><span>#<!-- -->team habits</span><span>#<!-- -->software engineering</span><span>#<!-- -->technical leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/f533a156-cee0-449b-8e27-0141ee7e7ea3"><div data-slot="card"><h3>How to train your team to say "I was wrong" without drama</h3><p>Practical rituals to normalize the awkwardness.</p><div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.1 1.1"></path></svg><p>leadthroughmistakes.substack.com</p></div><p><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->team culture</span><span>#<!-- -->psychological safety</span><span>#<!-- -->communication</span></p></div></a><a href="https://debuggingleadership.com/stdlib/90898a8f-da16-47f4-96b0-ca3dacbc2d44"><div data-slot="card"><h3>Individuals matter</h3><p>An essay explaining why treating engineers as interchangeable heads leads to flawed roadmaps, hiring decisions, and attrition, and why recognizing individual contributions is essential for effective technical leadership.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->people</span><span>#<!-- -->team dynamics</span><span>#<!-- -->budgeting</span><span>#<!-- -->attrition</span><span>#<!-- -->HR</span><span>#<!-- -->resource allocation</span></p></div></a><a href="https://debuggingleadership.com/stdlib/5ea97e0c-b89d-4f7c-9422-b6e414ef14a0"><div data-slot="card"><h3>Stop Avoiding Politics</h3><p>A short article urging technical leaders to engage with organizational politics rather than avoid it.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->politics</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->communication</span><span>#<!-- -->organization</span></p></div></a><a href="https://debuggingleadership.com/stdlib/2601c000-68c3-40f3-9f7a-2b414ecb3723"><div data-slot="card"><h3>Why Over-Engineering Happens</h3><p>An exploration of the reasons why software teams tend to over-engineer solutions and how to avoid it.</p><p><span>#<!-- -->over-engineering</span><span>#<!-- -->software architecture</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software design</span></p></div></a><a href="https://debuggingleadership.com/stdlib/237253fe-a990-4ce6-a770-11703d69bdd7"><div data-slot="card"><h3>Maintenance: Software Isn't Something You Can Be Done With</h3><p>Software needs maintenance just like your car does. With proper love and attention, it can serve you well for years to come.</p><p><span>#<!-- -->software maintenance</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->devops</span><span>#<!-- -->legacy systems</span></p></div></a><a href="https://debuggingleadership.com/stdlib/e9f5fcf6-07b7-496d-a55d-031c24805691"><div data-slot="card"><h3>Atomic Habits: Tiny Changes, Remarkable Results</h3><p>Packed with evidence-based strategies, Atomic Habits will teach you how to make small changes that will transform your habits and deliver amazing results.</p><p><span>#<!-- -->habits</span><span>#<!-- -->productivity</span><span>#<!-- -->leadership</span><span>#<!-- -->self-improvement</span><span>#<!-- -->behavioral psychology</span><span>#<!-- -->engineering management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/418eef16-3e89-4528-851f-c17baacf94d5"><div data-slot="card"><h3>The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win</h3><p>A novel that illustrates DevOps principles through the story of an IT manager tasked with rescuing a failing project and delivering business value.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->devops</span><span>#<!-- -->software engineering</span><span>#<!-- -->change management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/db6252b3-74aa-490d-9934-810c12503f4e"><div data-slot="card"><h3>Mind the Gap Model</h3><p>The Mind the Gap Model identifies three categories of challenges managers face when trying to close the gap between the current state and the desired future state.</p><p><span>#<!-- -->change management</span><span>#<!-- -->leadership</span><span>#<!-- -->management</span><span>#<!-- -->gap analysis</span><span>#<!-- -->mind the gap model</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/878b0526-f129-493a-8b62-8879a66763e7"><div data-slot="card"><h3>Authority Gradients</h3><p>Hippos, babbles and gish-gallop.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->authority</span><span>#<!-- -->management</span><span>#<!-- -->engineering</span><span>#<!-- -->technical leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/9b924d9b-6926-440b-bc8e-f71b29d1c4f4"><div data-slot="card"><h3>Increase Developer Productivity With Generative AI</h3><p>Three Toptal engineers share how they use generative AI for software development and offer actionable advice for others.</p><p><span>#<!-- -->developer productivity</span><span>#<!-- -->generative AI</span><span>#<!-- -->software engineering</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->AI tools</span><span>#<!-- -->automation</span></p></div></a><a href="https://debuggingleadership.com/stdlib/03daab6f-163d-4e8d-a10f-8a486a2a54bf"><div data-slot="card"><h3>Clean Code Handbook: Software Craftsmanship</h3><p>A practical guide that teaches software developers how to write clean, maintainable code and adopt craftsmanship principles.</p><p><span>#<!-- -->clean code</span><span>#<!-- -->software craftsmanship</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software development</span><span>#<!-- -->best practices</span></p></div></a><a href="https://debuggingleadership.com/stdlib/ff8ecef7-dff8-4b39-b642-adee51918cca"><div data-slot="card"><h3>The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win</h3><p>A novel that illustrates DevOps principles and the importance of leadership, collaboration, and process improvement in modern IT organizations.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->devops</span><span>#<!-- -->agile</span><span>#<!-- -->software development</span><span>#<!-- -->management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/7cc5a300-6a62-4d5c-b2be-4ee123d86c63"><div data-slot="card"><h3>Accelerate: Building and Scaling High Performing Technology Organizations</h3><p>Accelerate explains how technology organizations can improve software delivery performance and drive business outcomes through proven practices and metrics.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->devops</span><span>#<!-- -->software delivery</span><span>#<!-- -->performance</span><span>#<!-- -->lean</span><span>#<!-- -->agile</span><span>#<!-- -->technology</span></p></div></a><a href="https://debuggingleadership.com/stdlib/662b9a9e-bce6-4519-962e-65177b08cff4"><div data-slot="card"><h3>Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation</h3><p>Continuous Delivery provides a comprehensive guide to automating software build, test, and deployment processes to achieve reliable releases.</p><p><span>#<!-- -->continuous delivery</span><span>#<!-- -->devops</span><span>#<!-- -->software engineering</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software releases</span><span>#<!-- -->automation</span><span>#<!-- -->agile</span><span>#<!-- -->lean</span><span>#<!-- -->book</span></p></div></a><a href="https://debuggingleadership.com/stdlib/f6684d97-3a2b-4e0b-b05b-22f3110452e8"><div data-slot="card"><h3>Resource from amazon.co.uk</h3><p>A valuable resource discovered from amazon.co.uk. This content provides insights and best practices for technical leadership and engineering management.</p><p><span>#<!-- -->imported</span><span>#<!-- -->amazon</span><span>#<!-- -->leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/afa6adf6-7f50-4089-a824-7b7b5bf51c21"><div data-slot="card"><h3>Value Flywheel Effect: Accelerate Your Organization</h3><p>A practical guide that introduces the Value Flywheel concept to help organizations continuously improve and accelerate performance through systematic value creation and delivery.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->organizational development</span><span>#<!-- -->value flywheel</span><span>#<!-- -->strategy</span><span>#<!-- -->continuous improvement</span></p></div></a><a href="https://debuggingleadership.com/stdlib/3d0c1366-3678-4b1e-985f-97d337bff12a"><div data-slot="card"><h3>Team Topologies: Organizing Business and Technology</h3><p>Team Topologies provides a practical guide to structuring software teams and their interactions to enable fast flow of change and improve delivery outcomes.</p><p><span>#<!-- -->team topologies</span><span>#<!-- -->software architecture</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->organizational design</span><span>#<!-- -->devops</span></p></div></a><a href="https://debuggingleadership.com/stdlib/da4a1be7-0141-4f62-b7ae-c826a911c196"><div data-slot="card"><h3>Goal: The Process of Ongoing Improvement</h3><p>A practical guide that teaches how to embed continuous improvement into everyday work, helping technical leaders drive sustainable performance gains.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->continuous improvement</span><span>#<!-- -->process management</span><span>#<!-- -->engineering management</span><span>#<!-- -->software development</span></p></div></a><a href="https://debuggingleadership.com/stdlib/6bfb509e-0d05-4f8b-acd1-024b464a3636"><div data-slot="card"><h3>Domain-Driven Design: Tackling Complexity in the Heart of Software</h3><p>A practical guide that introduces domain-driven design principles to help engineers manage complex software projects.</p><p><span>#<!-- -->domain-driven design</span><span>#<!-- -->software architecture</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software development</span><span>#<!-- -->DDD</span><span>#<!-- -->system design</span></p></div></a><a href="https://debuggingleadership.com/stdlib/3af9d9fe-1189-4b53-9e02-a16c03aad341"><div data-slot="card"><h3>Extreme Programming Explained: Embrace Change</h3><p>A concise guide to the Extreme Programming methodology, teaching how to improve software quality and respond quickly to changing requirements.</p><p><span>#<!-- -->extreme programming</span><span>#<!-- -->agile</span><span>#<!-- -->software development</span><span>#<!-- -->technical leadership</span><span>#<!-- -->software engineering</span><span>#<!-- -->management</span><span>#<!-- -->programming</span><span>#<!-- -->methodology</span></p></div></a><a href="https://debuggingleadership.com/stdlib/7b459f0a-c345-4ec4-bee6-efbbb7b05011"><div data-slot="card"><h3>Pat Kua on Leadership, Culture and Growth</h3><p>In this InfoQ podcast episode, Pat Kua discusses how to build strong engineering culture, effective leadership practices, and strategies for growth.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->culture</span><span>#<!-- -->growth</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->software development</span><span>#<!-- -->team building</span></p></div></a><a href="https://debuggingleadership.com/stdlib/ca51aae8-7660-4e8f-8772-ae8732f84c6a"><div data-slot="card"><h3>How to practice privacy without slowing down</h3><p>Privacy principles can be integrated into lean, fast-moving startups without sacrificing speed, by treating privacy as a core design practice rather than a compliance afterthought.</p><p><span>#<!-- -->privacy</span><span>#<!-- -->security</span><span>#<!-- -->startup</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->data protection</span><span>#<!-- -->compliance</span></p></div></a><a href="https://debuggingleadership.com/stdlib/cab0b068-acfc-4cd3-8c36-67afb8ed99b6"><div data-slot="card"><h3>After the layoff: How to support your team when it just got smaller</h3><p>Leading through a layoff is one of the most challenging things you can do as a manager or HR professional. The article provides practical tips to help your team recover and stay productive.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->management</span><span>#<!-- -->layoffs</span><span>#<!-- -->team support</span><span>#<!-- -->HR</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span></p></div></a><a href="https://debuggingleadership.com/stdlib/056d261c-7734-4327-b383-2bb2d3450564"><div data-slot="card"><h3>Stories</h3><p>When and how to tell them</p><p><span>#<!-- -->leadership</span><span>#<!-- -->communication</span><span>#<!-- -->storytelling</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/5df928d2-2f9b-44b3-9d7a-73c923c99a75"><div data-slot="card"><h3>Questionable Advice: Can Engineering Productivity Be Measured?</h3><p>A brief exploration of whether engineering productivity can be accurately measured, questioning common metrics and advice.</p><p><span>#<!-- -->engineering productivity</span><span>#<!-- -->metrics</span><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software development</span><span>#<!-- -->performance measurement</span></p></div></a><a href="https://debuggingleadership.com/stdlib/22b485bf-b6fc-4c7a-b57b-d6aa23ecf0ae"><div data-slot="card"><h3>How to Clarify Your Thinking To Solve Leadership Obstacles</h3><p>A concise guide offering techniques for leaders to clarify their thinking and overcome common leadership obstacles.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->decision making</span><span>#<!-- -->problem solving</span><span>#<!-- -->clarity</span><span>#<!-- -->thinking frameworks</span></p></div></a><a href="https://debuggingleadership.com/stdlib/62f50188-25cb-4be2-afc3-3d2dd99e8c08"><div data-slot="card"><h3>The Missing Guide to Product Strategy</h3><p>This ebook demystifies product strategy, providing a solid structure, examples, resources, and guidance on making product strategy stick.</p><p><span>#<!-- -->product strategy</span><span>#<!-- -->leadership</span><span>#<!-- -->product management</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->strategy</span><span>#<!-- -->guide</span></p></div></a><a href="https://debuggingleadership.com/stdlib/8f3e00d8-f1be-4955-b50d-ddaae1c2ee27"><div data-slot="card"><h3>12 Types of Difficult Group Participants (INFOGRAPHIC)</h3><p>We know how hard it can be to have a challenging person in your groups - whether it's a workshop, webinar or group coaching session. So we created this</p><div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.1 1.1"></path></svg><p>thecoachingtoolscompany.com</p></div><p><span>#<!-- -->leadership</span><span>#<!-- -->team management</span><span>#<!-- -->group dynamics</span><span>#<!-- -->coaching</span><span>#<!-- -->facilitation</span><span>#<!-- -->workshops</span><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/24ce6652-147d-48e3-80c8-236f268d66ca"><div data-slot="card"><h3>Stop avoiding conflict on your teams</h3><p>Avoiding conflict is the death knell of organizations that leads to a lack of progress and careers that implode.</p><p><span>#<!-- -->conflict management</span><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->team dynamics</span><span>#<!-- -->feedback</span><span>#<!-- -->communication</span></p></div></a><a href="https://debuggingleadership.com/stdlib/3f1d74f0-4208-4281-a0e1-4077708cacb7"><div data-slot="card"><h3>Engineering Enablement at the Financial Times</h3><p>An article describing how the Financial Times built an engineering enablement function to improve developer productivity and delivery speed.</p><p><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->team enablement</span><span>#<!-- -->platform engineering</span><span>#<!-- -->software delivery</span><span>#<!-- -->DevOps</span><span>#<!-- -->organizational design</span></p></div></a><a href="https://debuggingleadership.com/stdlib/bd417a63-5cce-41cd-97da-89408687356c"><div data-slot="card"><h3>Failureship and Escalations</h3><p>An article that examines the concept of failureship and offers practical guidance on how technical leaders can improve escalation processes and accountability during incidents.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->incident management</span><span>#<!-- -->escalations</span><span>#<!-- -->risk management</span><span>#<!-- -->IT risk</span><span>#<!-- -->SRE</span><span>#<!-- -->postmortem</span><span>#<!-- -->failureship</span></p></div></a><a href="https://debuggingleadership.com/stdlib/29464794-0b8c-42a3-9e5e-1dcbce0f113d"><div data-slot="card"><h3>In-Depth: The Science On Sustainable Pace, Stress, And Motivation</h3><p>Scientific insights into the causes of stress and how motivation can buffer it, with five practical ways for technical leaders to reduce stress and sustain team performance.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->agile</span><span>#<!-- -->productivity</span><span>#<!-- -->stress management</span><span>#<!-- -->motivation</span><span>#<!-- -->sustainable pace</span></p></div></a><a href="https://debuggingleadership.com/stdlib/d8f0cb66-ef1f-4c38-ae1b-b84cd5c3cf85"><div data-slot="card"><h3>Five quick questions for better strategy</h3><p>A short article that proposes five practical questions leaders can ask to quickly evaluate and improve their strategic thinking.</p><p><span>#<!-- -->strategy</span><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->decision making</span><span>#<!-- -->technical leadership</span></p></div></a><a href="https://debuggingleadership.com/stdlib/d047b65d-bcee-4d61-bf39-b09861aa22f8"><div data-slot="card"><h3>Dropbox Engineering Career Framework</h3><p>A comprehensive framework outlining career progression, roles, and competencies for engineers at Dropbox.</p><p><span>#<!-- -->engineering</span><span>#<!-- -->leadership</span><span>#<!-- -->career</span><span>#<!-- -->framework</span><span>#<!-- -->technical leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software development</span><span>#<!-- -->professional growth</span></p></div></a><a href="https://debuggingleadership.com/stdlib/6788db8b-5547-4972-ab0f-ac5cacda81a2"><div data-slot="card"><h3>Peopleware: Productive Projects and Teams (3rd Edition)</h3><p>Peopleware explores how to create productive software teams by focusing on the human aspects of work, offering practical guidance for managers and leaders.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->engineering management</span><span>#<!-- -->software engineering</span><span>#<!-- -->productivity</span><span>#<!-- -->team dynamics</span><span>#<!-- -->agile</span><span>#<!-- -->peopleware</span></p></div></a><a href="https://debuggingleadership.com/stdlib/dfd179df-3e02-49e3-b662-04d570bbb333"><div data-slot="card"><h3>Elegant Puzzle: Systems Engineering Management</h3><p>A practical guide that provides a clear framework for engineering leaders to build high-performing teams and make effective technical decisions.</p><p><span>#<!-- -->engineering management</span><span>#<!-- -->technical leadership</span><span>#<!-- -->systems engineering</span><span>#<!-- -->team building</span><span>#<!-- -->software engineering</span><span>#<!-- -->career development</span></p></div></a><a href="https://debuggingleadership.com/stdlib/3249b28b-d934-460b-97f2-37b859fd0069"><div data-slot="card"><h3>Drive: The Surprising Truth About What Motivates Us</h3><p>Drive explores the science of motivation, revealing that autonomy, mastery, and purpose are the key drivers of performance and satisfaction.</p><p><span>#<!-- -->leadership</span><span>#<!-- -->motivation</span><span>#<!-- -->management</span><span>#<!-- -->psychology</span><span>#<!-- -->productivity</span><span>#<!-- -->engineering</span><span>#<!-- -->technical leadership</span></p></div></a></div><div><p>Showing </p><!-- --><p>1</p><!-- --><p>-</p><!-- --><p>48</p><!-- --><p> of </p><!-- --><p>1033</p><!-- --><p> resources</p></div><div><h4>About<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="currentColor"><g><path d="M17.44,2.065H6.56a2.507,2.507,0,0,0-2.5,2.5v14.87a2.507,2.507,0,0,0,2.5,2.5H17.44a2.5,2.5,0,0,0,2.5-2.5V4.565A2.5,2.5,0,0,0,17.44,2.065Zm1.5,17.37a1.5,1.5,0,0,1-1.5,1.5H6.56a1.5,1.5,0,0,1-1.5-1.5V6.505H18.94Z"></path><g><path d="M7.549,9.506h0a.5.5,0,0,1,0-1h8.909a.5.5,0,0,1,0,1Z"></path><path d="M7.549,12.506h0a.5.5,0,0,1,0-1h6.5a.5.5,0,0,1,0,1Z"></path><path d="M7.566,18.374h0a.5.5,0,1,1,0-1h3.251a.5.5,0,0,1,0,1Z"></path></g></g></svg><span>stdlib</span></h4><p>The stdlib collection is a community-curated library of practical, immediately useful, battle-tested resources for technical leadership. Each resource is designed to be immediately applicable to your role. New resources are added based on community feedback and emerging best practices.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FyneDesk: A full desktop environment for Linux written in Go (241 pts)]]></title>
            <link>https://github.com/FyshOS/fynedesk</link>
            <guid>45458122</guid>
            <pubDate>Fri, 03 Oct 2025 02:13:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FyshOS/fynedesk">https://github.com/FyshOS/fynedesk</a>, See on <a href="https://news.ycombinator.com/item?id=45458122">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://godoc.org/fyshos.com/fynedesk" title="GoDoc Reference" rel="nofollow"><img src="https://camo.githubusercontent.com/8a56736d8b5181d1bef15e6e9a7d935192028066f981994ae1ccfb2d71c6ace3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f676f2d646f63756d656e746174696f6e2d626c75652e7376673f7374796c653d666c6174" alt="GoDoc Reference" data-canonical-src="https://img.shields.io/badge/go-documentation-blue.svg?style=flat"></a>
  <a href="https://github.com/fyshos/fynedesk/releases/tag/v0.4.0" title="0.4.0 Release"><img src="https://camo.githubusercontent.com/348fdee8eee8a009a7af154167eed305f81157a01c090b97a8a3c363842a20c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d302e342e302d626c75652e7376673f7374796c653d666c6174" alt="0.4.0 release" data-canonical-src="https://img.shields.io/badge/version-0.4.0-blue.svg?style=flat"></a>
  <a href="http://gophers.slack.com/messages/fynedesk" rel="nofollow"><img src="https://camo.githubusercontent.com/d1f437012391d600f14a1bd2119878d85dfaf75edbde2dcf4779ffd3be9d0026/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6f696e2d75732532306f6e253230736c61636b2d677261792e7376673f6c6f6e6743616368653d74727565266c6f676f3d736c61636b26636f6c6f72423d626c7565" alt="Join us on Slack" data-canonical-src="https://img.shields.io/badge/join-us%20on%20slack-gray.svg?longCache=true&amp;logo=slack&amp;colorB=blue"></a>
  <br>
  <a href="https://goreportcard.com/report/fyshos.com/fynedesk" rel="nofollow"><img src="https://camo.githubusercontent.com/3071072613d6256ccd45c79b7383fd96b1c05d9f559217e4a3db0826fbc5610c/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f667973686f732e636f6d2f66796e656465736b" alt="Code Status" data-canonical-src="https://goreportcard.com/badge/fyshos.com/fynedesk"></a>
  <a href="https://github.com/fyshos/fynedesk/actions"><img src="https://github.com/fyshos/fynedesk/workflows/Platform%20Tests/badge.svg" alt="Build Status"></a>
  <a href="https://coveralls.io/github/fyshos/fynedesk?branch=develop" rel="nofollow"><img src="https://camo.githubusercontent.com/a72cfc5eafab6c25a1bfde487f673be0a965db97be268be569ab3d62ff6230d8/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f667973686f732f66796e656465736b2f62616467652e7376673f6272616e63683d646576656c6f70" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/fyshos/fynedesk/badge.svg?branch=develop"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About FyneDesk</h2><a id="user-content-about-fynedesk" aria-label="Permalink: About FyneDesk" href="#about-fynedesk"></a></p>
<p dir="auto">FyneDesk is an easy to use Linux/Unix desktop environment following material design.
It is built using the <a href="https://fyne.io/" rel="nofollow">Fyne</a> toolkit and is designed to be
easy to use as well as easy to develop. We use the Go language and welcome
any contributions or feedback for the project.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=82Wu5k0xZOI" rel="nofollow"><img src="https://camo.githubusercontent.com/01f8520a2c32c022283a1311aea9b453f092192a8f0327e2d9ec7d22309af00f/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f38325775356b30785a4f492f302e6a7067" alt="FyneDesk v0.4" data-canonical-src="https://img.youtube.com/vi/82Wu5k0xZOI/0.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dependencies</h2><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Compiling</h3><a id="user-content-compiling" aria-label="Permalink: Compiling" href="#compiling"></a></p>
<p dir="auto">Compiling requires the same dependencies as Fyne. See the <a href="https://developer.fyne.io/started/" rel="nofollow">Getting Started</a> documentation for installation steps.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running</h3><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">For a full desktop experience you will also need the following external tools installed:</p>
<ul dir="auto">
<li><code>arandr</code> for modifying display settings</li>
<li><code>xbacklight</code> or <code>brightnessctl</code> for laptop brightness</li>
<li><code>connman-gtk</code> is currently used for configuring Wi-Fi network settings</li>
<li><code>compton</code> for compositor support</li>
</ul>
<p dir="auto">The desktop does work without the runtime dependencies but the experience will be degraded.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Using standard Go tools you can install FyneDesk using:</p>
<div data-snippet-clipboard-copy-content="go get fyshos.com/fynedesk/cmd/fynedesk"><pre><code>go get fyshos.com/fynedesk/cmd/fynedesk
</code></pre></div>
<p dir="auto">This will add <code>fynedesk</code> to your $GOPATH (usually ~/go/bin).
You can now run the app in "preview" mode like any other Fyne app.
Doing so is not running a window manager, to do so requires another few steps:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setting up as a desktop environment</h3><a id="user-content-setting-up-as-a-desktop-environment" aria-label="Permalink: Setting up as a desktop environment" href="#setting-up-as-a-desktop-environment"></a></p>
<p dir="auto">To use this as your main desktop you can run the following commands to set up
fynedesk as a selectable desktop option in your login manager (such as LightDM for example):</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/fyshos/fynedesk
cd fynedesk
make
sudo make install"><pre><code>git clone https://github.com/fyshos/fynedesk
cd fynedesk
make
sudo make install
</code></pre></div>
<p dir="auto">You can now log out and see that it is in your desktop selection list at login.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debugging a window manager</h3><a id="user-content-debugging-a-window-manager" aria-label="Permalink: Debugging a window manager" href="#debugging-a-window-manager"></a></p>
<p dir="auto">You can also run the window manager components in an embedded X window for testing.
You will need the <code>Xephyr</code> tool installed for your platform (often installed as part of Xorg).
Once it is present you can use the following command from the same directory as above:</p>

<p dir="auto">It should look like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/FyshOS/fynedesk/blob/master/desktop-dark-current.png"><img src="https://github.com/FyshOS/fynedesk/raw/master/desktop-dark-current.png" alt="Fyne Desktop - Dark"></a>
</p>
<p dir="auto">If you run the command when there is a window manager running, or on
an operating system that does not support window managers (Windows or
macOS) then the app will start in UI test mode.
When loaded in this way you can run all of the features except the
controlling of windows - they will load on your main desktop.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Runner</h2><a id="user-content-runner" aria-label="Permalink: Runner" href="#runner"></a></p>
<p dir="auto">A desktop needs to be rock solid, and whilst we are working hard to get there,
any alpha or beta software can run into unexpected issues.
For that reason, we have included a <code>fynedesk_runner</code> utility that can help
manage unexpected events. If you start the desktop using the runner, then
if a crash occurs, it will normally recover where it left off with no loss
of data in your applications.</p>
<p dir="auto">Using standard Go tools you can install the runner using:</p>
<div data-snippet-clipboard-copy-content="go get fyshos.com/fynedesk/cmd/fynedesk_runner"><pre><code>go get fyshos.com/fynedesk/cmd/fynedesk_runner
</code></pre></div>
<p dir="auto">From then on execute that instead of the <code>fynedesk</code> command for a more
resilient desktop when testing out pre-release builds.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design</h2><a id="user-content-design" aria-label="Permalink: Design" href="#design"></a></p>
<p dir="auto">Design concepts, and the abstract wallpapers have been contributed by <a href="https://github.com/jostgrant">Jost Grant</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Shipping FyneDesk</h2><a id="user-content-shipping-fynedesk" aria-label="Permalink: Shipping FyneDesk" href="#shipping-fynedesk"></a></p>
<p dir="auto">If you are installing FyneDesk by default on a distribution, or making it available as a standard option, you should consider the following points.
You do not need to ship the library or any dependencies, but it is recommended to add the following apps as well:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>app</th>
<th>go get</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>fin</td>
<td><code>github.com/fyshos/fin</code></td>
<td>A display manager app that matches the look and feel of FyneDesk</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Please do let us know if you package FyneDesk for your system, so we can include a link from here :).</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I spent the day teaching seniors how to use an iPhone (332 pts)]]></title>
            <link>https://forums.macrumors.com/threads/i-spent-the-day-trying-to-teach-seniors-how-to-use-an-iphone-and-it-was-a-nightmare.2468117/</link>
            <guid>45457670</guid>
            <pubDate>Fri, 03 Oct 2025 01:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.macrumors.com/threads/i-spent-the-day-trying-to-teach-seniors-how-to-use-an-iphone-and-it-was-a-nightmare.2468117/">https://forums.macrumors.com/threads/i-spent-the-day-trying-to-teach-seniors-how-to-use-an-iphone-and-it-was-a-nightmare.2468117/</a>, See on <a href="https://news.ycombinator.com/item?id=45457670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
			Honestly, I think Apple really needs to simplify the iPhone for the elderly. I know there are accessibility modes, but you don’t want to have to go through all that and spend hours trying to customize the phone. Also, the whole phone setup process needs to be delayed; having to go through it for an hour puts them off from even wanting to bother. I first set the phones up to make accounts, but it turns out none of them could understand how to unlock the phone. Entering a passcode was a nightmare because they kept forgetting it, even though it was a birthday they knew, lol.</p><p>

So, I tried Touch ID and Face ID, and that was even more complicated and kept erroring out. Then, the Siri thing kept popping up on the phones with Touch ID, despite turning it off, and the whole swiping from the button kept making the screen go down to the bottom half. :/ There were too many apps; all they wanted was the phone app, but it doesn’t default to the keypad, which was too much for them to find.</p><p>


The phones are too fiddly now, and pressing random things as they try to hold the phone meant the phone got lost in a sea of opening stuff up. So, I tried the assistive access, but why isn’t this an option from the get-go? It asks you the age of setup; why not have a 65+ or something for a senior mode?</p><p>


They don’t need passcodes, accounts, and a sea of information. It’s insane, and it’s insane how fiddly these phones are. I never noticed because I’m used to it, but for these people with hands that barely move, the fake Touch ID button and the swiping from the bottom on Face ID phones seem to be the worst! I think having a proper physical button, like iPhones used to have, would have been superior. The one complaint about the fake button was that it didn’t feel like a real button, so they couldn’t gauge it.</p><p>


I left there achieving nothing because they couldn’t figure out their old Nokia phones. The unlock thing on the keypad was too difficult, and if I turned that off, they kept dialing 999 in their pockets for some reason. That’s why I was there: they were calling emergency services 100 times a day, lol.</p><p>


I think what I’ve realized is that I need to go back with flip phones that answer and hang up when you open and close them. However, the two I tried before didn’t act like that, and they had too many features. I really thought I could make the iPhone simple, but NOPE!</p><p>


Apple should work on their phones to make them more accessible and less fiddly, without having to go through a sea of menus.
		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple takes down ICE tracking apps after pressure from DOJ (595 pts)]]></title>
            <link>https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi</link>
            <guid>45457333</guid>
            <pubDate>Fri, 03 Oct 2025 00:34:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi">https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi</a>, See on <a href="https://news.ycombinator.com/item?id=45457333">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!----> <!---->  <p><strong>FIRST ON FOX:&nbsp;</strong><a href="https://www.foxnews.com/category/tech/companies/apple" target="_blank" rel="noopener">Apple</a> dropped ICEBlock, a widely used tracking tool, from its App Store on Thursday after the Department of Justice raised concerns with the big tech giant that the app put law enforcement officers at risk.</p> <p>DOJ officials, at the direction of Attorney General Pam Bondi, asked Apple to take down ICEBlock, a move that comes as Trump administration officials have claimed the tool, which allows users to anonymously report ICE agents' presence, puts agents in danger and helps shield illegal immigrants.</p><p>In a statement to Fox News Digital, Bondi confirmed the department contacted Apple to pull the app on Thursday and that the company complied.</p> <p>"We reached out to Apple today demanding they remove the ICEBlock app from their App Store — and Apple did so," Bondi said. "ICEBlock is designed to put ICE agents at risk just for doing their jobs, and violence against law enforcement is an intolerable red line that cannot be crossed. This Department of Justice will continue making every effort to protect our brave federal law enforcement officers, who risk their lives every day to keep Americans safe."</p> <p><a href="https://www.foxnews.com/politics/bondi-declares-new-era-political-violence-federal-agents-deploy-ice-facilities-nationwide" target="_blank" rel="noopener"><strong>BONDI DECLARES ‘NEW ERA’ OF POLITICAL VIOLENCE AS FEDERAL AGENTS DEPLOY TO ICE FACILITIES NATIONWIDE</strong></a></p><div><div><picture><source media="(max-width: 767px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/343/192/pam-bondi-speaking.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/686/384/pam-bondi-speaking.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/672/378/pam-bondi-speaking.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1344/756/pam-bondi-speaking.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 1024px) and (max-width: 1279px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/931/523/pam-bondi-speaking.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1862/1046/pam-bondi-speaking.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 1280px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/720/405/pam-bondi-speaking.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1440/810/pam-bondi-speaking.jpg?ve=1&amp;tl=1 2x"> <img src="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/931/523/pam-bondi-speaking.jpg?ve=1&amp;tl=1" alt="Attorney General Pam Bondi"></picture></div> <p><span>Attorney General Pam Bondi speaks during a news conference at the DEA headquarters on July 15, 2025, in Arlington, Virginia.</span><span> (Alex Wong/Getty Images / Getty Images)</span></p></div><p>Controversy surrounding ICE tracking apps intensified after last month’s deadly shooting at an ICE field office in Dallas, the latest in a series of attacks that appeared to be targeted at immigration enforcement officers.</p><p>Authorities said the suspect, Joshua Jahn, searched his phone for tracking apps, including ICEBlock, before opening fire on the facility from a rooftop. Authorities said Jahn killed one detainee and left two critically injured but that the personnel were his intended targets, not the immigrants. One of the injured, a 32-year-old husband and father of four, <a href="https://www.foxnews.com/us/second-detainee-dies-after-dallas-ice-facility-sniper-attack-family-speaks-out" target="_blank" rel="noopener">died</a> this week.</p><p>Marcos Charles, an acting director for ICE’s removal operations, said during a press conference that Jahn had intended to murder ICE employees and that attacks on them have skyrocketed.</p><p>"The evidence is clear that this was intended as an assault on ICE personnel who come to work everyday to do their job," Charles said. "Violent rhetoric has led to an over 1000% increase in assaults on ICE officers and it has to stop."</p><div><div><picture><source media="(max-width: 767px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/343/192/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/686/384/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/672/378/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1344/756/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 1024px) and (max-width: 1279px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/931/523/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1862/1046/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1 2x"> <source media="(min-width: 1280px)" srcset="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/720/405/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1, https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/1440/810/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1 2x"> <img src="https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/10/931/523/joshua-jahn-dallas-ice-shooter-bullets.jpg?ve=1&amp;tl=1" alt="Joshua Jahn"></picture></div> <p><span>Joshua Jahn allegedly shot at an ICE facility in Dallas, Texas, on Sept. 24, 2025, and the FBI said a bullet with "ANTI-ICE" on it was found at the scene.</span><span> (FBI; Contributed to Fox News)</span></p></div><p>Fox News Digital reached out to Apple and ICEBlock for comment.</p><p>Apple said in a statement it removed ICEBlock and other apps like it.</p><p>"We created the App Store to be a safe and trusted place to discover apps. Based on information we’ve received from law enforcement about the safety risks associated with ICEBlock, we have removed it and similar apps from the App Store," Apple said.</p><p>Joshua Aaron, the ICEBlock's creator, said he was "incredibly disappointed by Apple's actions today."</p><p>"Capitulating to an authoritarian regime is never the right move," Aaron said. "Apple has claimed they received information from law enforcement that ICEBlock served to harm law enforcement officers. This is patently false."</p><p><a href="https://www.foxnews.com/apps-products?pid=AppArticleLink" target="_blank" rel="noopener"><strong>CLICK HERE TO GET THE FOX NEWS APP</strong></a></p><p>Aaron said ICEBlock, which has more than 1.1 million users, functions like other mapping applications that use crowd sourcing for speed traps, citing Apple's own map service as an example.</p><p>"We are determined to fight this with everything we have," Aaron said. "Our mission has always been to protect our neighbors from the terror this administration continues to reign down on the people of this nation."</p></div></div>]]></description>
        </item>
    </channel>
</rss>