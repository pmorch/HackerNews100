<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 29 Apr 2025 17:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Firefox tab groups are here (163 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/tab-groups-community/</link>
            <guid>43834101</guid>
            <pubDate>Tue, 29 Apr 2025 15:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/tab-groups-community/">https://blog.mozilla.org/en/firefox/tab-groups-community/</a>, See on <a href="https://news.ycombinator.com/item?id=43834101">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-78908">
  

  <div>
    
<p>What happens when 4,500 people ask for the same feature? At Firefox, we build it.</p>



<figure><video controls="" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/ENG-Tab-groups-animation-v101.mp4"></video><figcaption><em>Firefox tab groups now available</em></figcaption></figure>



<p>Tab groups have long been the most <a href="https://connect.mozilla.org/t5/ideas/native-tab-grouping-more-customizable-tab-bar/idi-p/303">requested idea</a> on <a href="https://connect.mozilla.org/">Mozilla Connect</a> ‚Äì our community platform ‚Äì and thanks to thousands of votes, comments and passionate feedback, it‚Äôs finally here. üéâ</p>



<p>But this is more than just a feature launch. It‚Äôs the story of what happens when community insight, real-world pain points, and a whole lot of curiosity come together.</p>



<h3><strong>A feature the community asked for, loud and clear</strong></h3>



<p>Just one day after Mozilla Connect quietly <a href="https://blog.mozilla.org/en/firefox/about-mozilla-connect/">launched</a> in March 2022, a <a href="https://connect.mozilla.org/t5/ideas/native-tab-grouping-more-customizable-tab-bar/idi-p/303">request</a> for tab groups appeared. We hadn‚Äôt even promoted the platform. There were no announcements. But the community found Mozilla Connect and rallied behind the request for tab groups.</p>



<p>‚ÄúIt‚Äôs still the number one most upvoted post on Mozilla Connect,‚Äù said Jon Siddoway, who helps surface user insights to Firefox teams. ‚ÄúEven when the feature was in beta, people were still voting for it and saying, ‚ÄòWe want this.‚Äô‚Äù</p>



<p>At Mozilla, we work hard to make Firefox the best browser for you. Last year, we <a href="https://blog.mozilla.org/en/mozilla/heres-what-were-working-on-in-firefox/">shared</a> what we were working on ‚Äì features that help you stay organized, like our handy sidebar, <a href="https://blog.mozilla.org/en/firefox/vertical-tabs-and-the-firefox-community/">vertical tabs</a> and tab groups. As we noted then, community feedback directly shaped what came next.&nbsp;</p>



<blockquote>
<p>‚ÄúIt‚Äôs still the number one most upvoted post on Mozilla Connect.‚Äù </p>
<cite>Jon Siddoway, product manager of Mozilla Connect</cite></blockquote>



<p>That early request kicked off a collaboration between the Firefox team and community. Before any code was written, Jon summarized comments, tracked trends across 64+ pages of feedback and brought key themes to the team.</p>



<p>That enthusiasm spilled into beta testing. Before the official <a href="https://connect.mozilla.org/t5/discussions/help-shape-the-future-of-tab-groups-in-firefox/m-p/89026">invite</a> to community members went out, many of them discovered the hidden toggle in the Nightly release, turned it on themselves, and started sharing how to use it. The team watched, learned and iterated from the sidelines.</p>



<h3><strong>Listening and learning from thousands of voices</strong></h3>



<p>Stefan Smagula, product manager for the tabs group feature, didn‚Äôt just skim the posts ‚Äì he dove in.</p>



<p>‚ÄúI read Mozilla Connect every day for the first month,‚Äù he said. ‚ÄúSometimes the ideas confirmed what we were already thinking. Other times they were totally new and unexpected, like requests for nested tab groups.‚Äù</p>



<p>But with over 1,000 comments and many differing opinions, how do you make decisions?</p>



<blockquote>
<p>‚ÄúSometimes the ideas confirmed what we were already thinking. Other times they were totally new and unexpected.‚Äù</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<p>‚ÄúYou try to get to the <em>underlying needs</em> behind each request,‚Äù Stefan explained. ‚ÄúInstead of just implementing one person‚Äôs idea, you look for the broader pattern ‚Äî the thing that could help the most people.‚Äù</p>



<p>This approach helped shape a feature that balances flexibility with simplicity. With tab groups, you can drag and drop tabs into organized groups, label them by name or color, and stay focused. Whether you‚Äôre a <a href="https://blog.mozilla.org/en/firefox/firefox-tips/transform-firefox-into-minimalist-workspace/">minimalist</a> with 10 tabs or a power user juggling 10,000 (seriously ‚Äî one of our colleagues does this), tab groups can help.</p>


<div>
<figure><img decoding="async" fetchpriority="high" width="1024" height="578" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1024x578.png" alt="Browser window showing Firefox's tab grouping feature. A 'Create tab group' pop-up is open, with 'Thailand Trip' entered as the group name and a purple color selected. Tabs for 'Thailand Trip,' 'Google Flights,' 'Hotels.com,' and a 'New Tab' are visible, along with existing tab groups labeled 'Work,' 'Reading,' and 'Shopping.'" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1024x578.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-300x169.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-768x433.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1000x564.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2.png 1136w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Keep it together ‚Äî group your tabs by trip, work, or whatever you need!</em></figcaption></figure></div>


<p>‚ÄúTab groups aren‚Äôt just about decluttering,‚Äù Stefan said. ‚ÄúIt‚Äôs about reclaiming your flow and finding focus again.‚Äù</p>



<p>It also reinforced the team‚Äôs belief that done is never truly done.</p>



<blockquote>
<p>‚ÄúTab groups aren‚Äôt just about decluttering. It‚Äôs about reclaiming your flow and finding focus again.‚Äù</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<h3><strong>What‚Äôs next: Make tab groups smarter</strong></h3>



<p>Once early testers began using tab groups in <a href="https://www.mozilla.org/en-US/firefox/channel/desktop/">Firefox Nightly and Beta</a>, feedback kept rolling in ‚Äì both on Mozilla Connect and in places like <a href="https://blog.mozilla.org/en/firefox/firefox-subreddit/">Reddit</a> and X, where Stefan scouts for feedback. Many users wanted less friction and more flow when managing their tabs, which inspired the team to explore the next step: having the browser help organize things automatically.&nbsp;</p>



<p>Now, the team is experimenting with smart tab groups, a new AI-powered feature that suggests names and groups based on the tabs you have open. Other browsers might send your tab info to the cloud, but Firefox keeps it on your device. Your tabs stay private and never leave your device.</p>



<p>‚ÄúI used to have 30 windows open, each with 30 or 40 tabs. Smart tab groups changed the way I work. It made it easier to find what I need and resume tasks faster,‚Äù said Stefan.</p>



<p>It‚Äôs just the beginning of what‚Äôs possible when you pair smart tech with real human needs.</p>



<blockquote>
<p>‚ÄúI used to have 30 windows open, each with 30 or 40 tabs. Smart tab groups changed the way I work. It made it easier to find what I need and resume tasks faster.‚Äù</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<h3><strong>Thank you ‚Äì and keep the ideas coming</strong></h3>



<p>This feature wouldn‚Äôt exist without you. Your upvotes, comments, ideas and testing helped bring it to life.</p>



<p>As Stefan put it: ‚ÄúIt‚Äôs extremely motivating to know how many people want this. It makes the hard work easier and more meaningful.‚Äù</p>



<p>So if you‚Äôve ever felt tab overload ‚Äî or if you just want your browser to feel a bit more like your own ‚Äî try out tab groups. Share what you love and what you‚Äôd change.</p>



<blockquote>
<p>‚ÄúIt‚Äôs extremely motivating to know how many people want this. It makes the hard work easier and more meaningful.‚Äù</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<p>You can join the conversation anytime on <a href="https://connect.mozilla.org/">Mozilla Connect</a>. üí¨</p>



<a href="https://www.mozilla.org/en-US/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-800x800.webp" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-800x800.webp 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-150x150.webp 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Get the browser that puts your privacy first ‚Äî and always has </h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[White House slams Amazon tariff price display "hostile and political" (129 pts)]]></title>
            <link>https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report</link>
            <guid>43832588</guid>
            <pubDate>Tue, 29 Apr 2025 13:49:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report">https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report</a>, See on <a href="https://news.ycombinator.com/item?id=43832588">Hacker News</a></p>
Couldn't get https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Performance optimization is hard because it's fundamentally a brute-force task (126 pts)]]></title>
            <link>https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/</link>
            <guid>43831705</guid>
            <pubDate>Tue, 29 Apr 2025 12:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/">https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/</a>, See on <a href="https://news.ycombinator.com/item?id=43831705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><time>April 29, 2025</time><a href="https://www.reddit.com/r/programming/comments/1kam686/why_performance_optimization_is_hard_work/"> Reddit</a></p><p>I‚Äôm not talking about skill, knowledge, or convincing a world focused on radical acceleration that optimization is necessary. Performance optimization is hard because it‚Äôs fundamentally a brute-force task, and there‚Äôs nothing you can do about it.</p><p>This post is a bit of a rant on my frustrations with code optimization. I‚Äôll also try to give actionable advice, which I hope enchants your experience.</p><p>Certain optimizations can only work together, while others lead to pessimizations when combined. To be an expert means to know what optimization avenues exist; to be a master means to know which ones to choose.</p><p>I have a post on integer formatting in the works, covering a very particular algorithm design ‚Äì and I <em>still</em> haven‚Äôt finished it because there‚Äôs like five different choices to make, I have no idea how they impact each other, and I need to analyze <eq><math><msup><mn>2</mn><mn>5</mn></msup></math></eq> variants to claim which one‚Äôs the best in conscience. Several of my projects are similarly stuck because I don‚Äôt have the willpower to implement a dozen combinations.</p><p>Pruning ‚Äúobviously‚Äù suboptimal approaches is all but a heuristic. I like to think I‚Äôm more in tune with an x86-64 CPU than most people, and it still manages to surprise me from time to time. Dumb algorithms can become more applicable due to vectorization, smart code can fail due to <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch misprediction</a> or <a href="https://en.wikipedia.org/wiki/Memory_disambiguation#Store_to_load_forwarding">store-to-load forwarding</a> gone wrong.</p><p>Optimization takes a lot of trial and error. I dislike the ‚Äúintuition doesn‚Äôt work, profile your code‚Äù mantra because it seemingly says profiling is a viable replacement for theoretical calculations, which it isn‚Äôt. But I can‚Äôt argue that profiling is avoidable. I often joke that <code>perf report</code> is my go-to disassembler.</p><p>Worse yet, you can‚Äôt trust ‚Äúobviously‚Äù good code either. In <a href="https://purplesyringa.moe/blog/the-ram-myth/">a previous post</a>, I optimized a single linear pass by replacing it with a superlinear sort. This is by no means a unique experience: just yesterday, I saw someone optimize best-of-class <a href="https://en.wikipedia.org/wiki/Barrett_reduction">Barrett reduction</a> by dividing the numbers as <code>double</code>s, rounding them, and computing the reminder from the quotient. It‚Äôs so stupid that it can‚Äôt possibly work, yet it does.</p><p>The good news is that the work here can be split among multiple people trying different approaches. Open-source projects in particular benefit from this, because contributors typically have different strengths and focus on different ideas. Try to reuse work by consulting your teammates or reading about others‚Äô experiences in solving similar tasks.</p><p>A variation on this is algorithms where a <em>cut-off boundary</em> is present. You no longer choose whether to apply an optimization: you also need to select parameters via more trial and error. For example:</p><ul><li>Hybrid sorting algorithms can switch between different implementations due to high big-O constants,</li><li><a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">FFT</a> can switch between recursive and iterative approaches to better utilize processor cache.</li><li>Depending on data density, the optimal set structure might be bitsets, hash sets, or complementary hash sets.</li></ul><p>Modifying either of the alternative algorithms requires rebenchmarking to update the optimal boundary. Small modifications here can lead to <em>drastic</em> end performance changes due to interactions with CPU cache, branch and memory access prediction, the discrete nature of recursive cut-offs, and floating-point precision (for <a href="https://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm#Details">big integer multiplication via FFT</a>). Forgetting to rebenchmark and abandoning a prospective approach can easily leave <eq><math><mrow><mn>2</mn><mo>√ó</mo></mrow></math></eq> performance on the table.</p><p>For another example, consider a program that executes <eq><math><mi>n</mi></math></eq> times either action <eq><math><mi>A</mi></math></eq> or <eq><math><mi>B</mi></math></eq> depending on probability <eq><math><mi>p</mi></math></eq>. If <eq><math><mi>p</mi></math></eq> is far from <eq><math><mfrac><mn>1</mn><mn>2</mn></mfrac></math></eq>, branch prediction means it‚Äôs better to implement the switch with an <code>if</code>; if <eq><math><mi>p</mi></math></eq> is close to <eq><math><mfrac><mn>1</mn><mn>2</mn></mfrac></math></eq>, branch prediction will fail and a branchless approach will work better. Not only does the relative performance of <eq><math><mi>A</mi></math></eq> and <eq><math><mi>B</mi></math></eq> matter here, but the cost of branch misprediction matters as well, and that might depend not only on the CPU but on the precise code executed.</p><p>Ideally, you‚Äôd have a test bench that plots graphs and finds optimal parameter values automatically, even though getting this working can be draining. This way, running checks all the time becomes cheap and emotionally easier. Even if it takes half an hour, you can still work on something else in parallel.</p><p>The worst example of incompatible optimizations is those that fail due to external constraints.</p><p>One example is when two <a href="https://en.wikipedia.org/wiki/Lookup_table">LUTs</a> don‚Äôt fit in cache together, but do individually. You can sometimes fix this by splitting the computation into multiple passes, where each pass only needs to access helper data that does fit into cache. This does not necessarily mean two passes over <em>all</em> data, consuming <eq><math><mrow><mn>2</mn><mo>√ó</mo></mrow></math></eq> memory bandwidth ‚Äì you can chunk the data and apply two passes on a chunk, which increases performance if the chunk fits into, say, L3. But sometimes that doesn‚Äôt work, and then I bash my head against the wall.</p><p>Register pressure is even worse because that is only a problem because of the ISA, not the <a href="https://en.wikipedia.org/wiki/Microarchitecture">microarchitecture</a>. The hardware has enough registers, they just aren‚Äôt exposed to user code. You can try to split data between general-purpose registers and vector registers, and that works as long as you seldom cross the GPR-SIMD boundary, but at that point, you might as well <a href="https://github.com/docker/cli/issues/267#issuecomment-695149477">change your profession</a>.</p><p>It doesn‚Äôt have to be that way. <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGAs</a> enable you to design your own hardware (kind of, anyway), and alternative approaches like <a href="https://en.wikipedia.org/wiki/Interaction_nets">interaction nets</a> have a chance to make software-specified operations as optimal as operations that are usually implemented in hardware. But that‚Äôs not the world we live in, no, we live in the world where Intel keeps introducing useful instructions to AVX-512 only to abandon them later, so I need to choose between a CPU with <code>vp2intersect</code> or with <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">FP16</a>. So not only do you have to benchmark different code, you also have to test it on different CPUs to decide which EC2 instance to deploy it on.</p><p>The only advice I have for this is to try to achieve the best possible result, even if it‚Äôs worse than the theoretical optimum. Reduce the size of one of the LUTs by moving some calculations to runtime, rewrite a chunk of code in assembly to manage registers better, and when all else fails, accept that you have to make a choice.</p><p>‚ÄúCompilers are smarter than humans‚Äù is a common mantra. It couldn‚Äôt be further from the truth. Any developer can see that the following two snippets are (supposed to be) equivalent:</p><pre><code><span>let</span> <span>condition1</span> = HashSet::<span>from</span>([a, b]).<span>contains</span>(&amp;c);
<span>let</span> <span>condition2</span> = a == c || b == c;
</code></pre><p>But compilers aren‚Äôt going to optimize the former into the latter (<a href="https://4comprehension.com/the-curious-case-of-jdk9-immutable-collections/">JVM‚Äôs JIT, in some cases, excluded</a>). They don‚Äôt reason in abstractions, and they certainly don‚Äôt reason in <em>your</em> auxiliary abstractions. This doesn‚Äôt just apply to high-level code: LLVM <a href="https://godbolt.org/z/j3ehhr3KT">does not even understand</a> that bitwise AND is an intersection.</p><p>No, compilers excel at something different from optimization: they turn higher-level languages into zero-cost abstractions, but there‚Äôs no ingenuity. Compilers are optimal transpilers ‚Äì barring a few exceptions, they codegen exactly what you wrote in the source. They allow you to write assembly with the syntax and capabilities of Rust or C++, but don‚Äôt you dare forget that the <code>arr.map(|x| x / c)</code> you wrote will invoke <code>idiv</code> without performing obvious <a href="https://github.com/ridiculousfish/libdivide">libdivide</a>-style precalculations.</p><p>Sometimes I wonder if <code>-O2</code> should be renamed to <code>-fzero-cost-abstractions</code>.</p><p>This might make it sound like I‚Äôm arguing that compilers are only good at plumbing, but they aren‚Äôt even good at that. For example, they can be terrible at register allocation of all things. If a rarely executed chunk of code needs many registers, GCC satisfies that need by <a href="https://godbolt.org/z/53o1vdsfj">spilling variables accessed by the hot path</a> <em>on every iteration</em>, not only on entry to cold path. Clang handles this simple example better but fails in more complicated cases.</p><p>The lesson is never to trust the compiler blindly. Always check the disassembly, consult an instruction-level profiler like <code>perf</code>, and don‚Äôt be afraid to use this information to nudge the compiler to do the right thing if it leads to tangible improvements.</p><p>Despite obvious shortcomings, compilers don‚Äôt allow you to correct them on things they get wrong. There is no way to provide both optimized assembly and equivalent C code and let the compiler use the former in the general case and the latter in special cases. Custom calling conventions are mostly unsupported, and so is choosing between branchless and branchy code and any other assembly tricks. There are intrinsics, but LLVM and rustc <em>still</em> try to be smart and rewrite them, which sometimes causes pessimizations, leaving no alternative but to add an optimization barrier.</p><p><a href="https://egraphs-good.github.io/">e-graphs</a>, as popularized by <a href="https://cranelift.dev/">Cranelift</a>, try to tackle this problem, but to my knowledge, there hasn‚Äôt been much success in this field. I‚Äôm still hopeful, though.</p><p>For x86 processors, <a href="https://uops.info/table.html">uops.info</a> provides timing and port information for each instruction and many Intel and AMD CPUs. <a href="https://www.agner.org/optimize/">Agner Fog</a> wrote a manual on optimization for x86 processors and publishes his own tables. <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel Software Developer‚Äôs Manual</a> contains more than 5000 pages documenting not only the instruction set but many internal workings of their CPUs as well.</p><p>Apple Silicon has <em>nothing</em> like that. I have no goddamn idea how to work with M1+ processors. There‚Äôs <a href="https://dn721600.ca.archive.org/0/items/apple-silicon-cpu-optimization-guide/Apple-Silicon-CPU-Optimization-Guide.pdf">Apple Silicon CPU Optimization Guide</a>, which contains only 169 pages and reads like something people would write for novices, not experts. It reads like a tutorial you might find on HN, not something I would be interested in. It contains estimates of latencies and throughputs for some categories of instructions, but there‚Äôs frustratingly little tabular data, and it doesn‚Äôt mention <a href="https://stackoverflow.com/questions/56413517/what-is-instruction-fusion-in-contemporary-x86-processors">uop fusion</a> or provide port information. <a href="https://dougallj.github.io/applecpu/firestorm.html">Dougall Johnson‚Äôs research</a> is immensely valuable but only covers M1, not newer CPUs, and it still doesn‚Äôt answer many questions.</p><p>Even <a href="https://github.com/swiftlang/llvm-project/tree/next/llvm/lib/Target/AArch64">Apple‚Äôs LLVM fork</a> lacks scheduling annotations for Apple Silicon. How am I supposed to write efficient code when Apple doesn‚Äôt bother to tune their own compiler? Optimizing code for such a platform is 90% reverse engineering and 10% writing meaningful code ‚Äì and writing meaningful code is already hard.</p><p>The right fix for this is to commit intellectual property theft, but I‚Äôm not allowed to say that, so I won‚Äôt. Oops.</p><p>Performance optimization is hard because you have to:</p><ul><li>Explore dozens of cases manually without losing your mind.</li><li>Iterate with inadequate tooling. (Profilers and <a href="https://llvm.org/docs/CommandGuide/llvm-mca.html">MCA</a> are useful, but they‚Äôre still toys that can‚Äôt match the underlying complexity.)</li><li><s>Jam squares into round holes until they fit.</s> Merge incompatible optimizations.</li><li>Deal with both corporate greed and cultural apathy.</li></ul><p>It‚Äôs not easy by any means, but it‚Äôs still something I enjoy doing, even though people often consider anything short of radical improvements a waste of time. To me, a 10% optimization is a form of art, but it‚Äôs not just that. Small improvements compound and help form a better user experience, even if no single optimization seems valuable on its own ‚Äì much like improving data transfer rates has led to structural changes in how we process and utilize information.</p><p>Optimizations save time, and time is the one resource people don‚Äôt get enough of.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Chrome extension that will auto-reject non-essential cookies (130 pts)]]></title>
            <link>https://blog.bymitch.com/posts/reject-cookies/</link>
            <guid>43831298</guid>
            <pubDate>Tue, 29 Apr 2025 11:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.bymitch.com/posts/reject-cookies/">https://blog.bymitch.com/posts/reject-cookies/</a>, See on <a href="https://news.ycombinator.com/item?id=43831298">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><a href="https://chromewebstore.google.com/detail/bnbodofigkfjljnopfggfoecokhmhamc?utm_source=item-share-cb">Add the extension</a></p>
<p><img src="https://blog.bymitch.com/reject-cookies/reject-cookies-no.png" alt="Reject Cookies Logo" title="Logo"></p>
<h2 id="a-chrome-extension">A Chrome Extension</h2>
<p>Everyone can agree that cookie consent banners are frustrating. It might be one of the few unifying factors on the internet today. Even though it‚Äôs a couple clicks, the couple clicks are a pain, and the couple clicks can happen on many sites each day.</p>
<p>There are browser extensions out there that will auto-accept cookies like <a href="https://chromewebstore.google.com/detail/i-dont-care-about-cookies/fihnjjcciajhdojfnbdddfaoknhalnja">I don‚Äôt care about cookies</a> and it‚Äôs open source fork <a href="https://chromewebstore.google.com/detail/i-still-dont-care-about-c/edibdbjcniadpccecjdfdjjppcpchdlm">I still don‚Äôt care about cookies</a>. You can even chain this extension with another that will auto-clean up your cookies. This is an adequate solution and ascribes to <a href="https://en.wikipedia.org/wiki/Unix_philosophy">unix philosophy</a>.</p>
<p>Additionally, there are extensions like <a href="https://ublockorigin.com/">uBlock Origin</a> with additional filters to help ignore these annoying pop ups. Or <a href="https://privacybadger.org/">Privacy Badger</a> to block cookie trackers. Although there is space to provide an extension that just auto-rejects non essential cookies.</p>
<p>That‚Äôs what led to the ‚ÄúReject Cookies‚Äù chrome extension. It will first attempt to reject the cookies on the page. If that is unsuccessful, it will then attempt to close the cookie pop up or banner. To comply with the regulations governing cookies under the <a href="https://gdpr.eu/cookies/">GDPR and the ePrivacy Directive you must</a></p>
<blockquote>
<p>Receive users‚Äô consent before you use any cookies except strictly necessary cookies.</p>
</blockquote>
<p>So the omission of an acceptance should be on par with an explicit rejection. If you‚Äôre interested in how it works the code is <a href="https://github.com/mitch292/reject-cookies">open source and on github</a>, but let‚Äôs step through it at a high level.</p>
<h2 id="how-its-implemented">How it‚Äôs implemented</h2>
<p>Vibe coding is the answer. I leveraged Cursor and let it auto-select the model. This combination while extremely useful, did not serve me as well as recent past experience. On the project setup front, I had not previously written a Chrome extension. Having the Cursor agent set up the boilerplate was convenient. Although, it requested too liberal of permissions in the permissions to start and wouldn‚Äôt go and update them as the design of the app changed. Below is a snippet of the <code>manifest.json</code> to show what the permissions ended up looking like.</p>
<div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"permissions"</span>: [<span>"activeTab"</span>, <span>"sidePanel"</span>, <span>"tabs"</span>],
</span></span><span><span>  <span>"content_scripts"</span>: [
</span></span><span><span>    {
</span></span><span><span>      <span>"matches"</span>: [<span>"http://*/*"</span>, <span>"https://*/*"</span>],
</span></span><span><span>      <span>"js"</span>: [<span>"content.js"</span>]
</span></span><span><span>    }
</span></span><span><span>  ]
</span></span><span><span>}
</span></span></code></pre></div><p>Next on the implementation side of things, it started with a set of common selectors that could possibly be relevant to non-essential cookies. The problem was once again these selectors were extremely liberal things like elements with the class ‚Äúaccept‚Äù. I opted to take a more targeted approach and aim the logic at specific cookie consent vendors that most sites seem to leverage. Cursor‚Äôs agent was, as expected, not able to help much with this implementation.</p>
<p>The extension will go through the configured providers.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>findAndClickRejectButtons</span> <span>=</span> () <span>=&gt;</span> {
</span></span><span><span>	<span>commonCookiePopupChecks</span>.<span>forEach</span>(({ <span>check</span>, <span>rejectOrClose</span> }) <span>=&gt;</span> {
</span></span><span><span>	  <span>if</span> (<span>check</span>()) {
</span></span><span><span>		<span>rejectOrClose</span>();
</span></span><span><span>		<span>// assume that there is only one cookie consent provider and we can exit
</span></span></span><span><span><span></span>		<span>return</span>;
</span></span><span><span>	  }
</span></span><span><span>	});
</span></span><span><span>  }
</span></span></code></pre></div><p>A check for a provider will look for a specific element that identifies it.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>checkForOneTrust</span> <span>=</span> ()<span>:</span> <span>boolean</span> <span>=&gt;</span> <span>!!</span>document.<span>getElementById</span>(<span>'onetrust-consent-sdk'</span>);
</span></span></code></pre></div><p>Then attempt to reject the cookies and fallback to removing the consent banner or popup if it‚Äôs not able to reject the non-essential cookies.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>closeOrRejectOneTrust</span> <span>=</span> () <span>=&gt;</span> {
</span></span><span><span>  <span>const</span> <span>rejectButton</span> <span>=</span> document.<span>getElementById</span>(<span>'onetrust-reject-all-handler'</span>);
</span></span><span><span>  <span>if</span> (<span>rejectButton</span>) {
</span></span><span><span>    <span>rejectButton</span>.<span>click</span>();
</span></span><span><span>    <span>return</span> <span>true</span>;
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>const</span> <span>consentSDK</span> <span>=</span> document.<span>getElementById</span>(<span>'onetrust-consent-sdk'</span>);
</span></span><span><span>  <span>if</span> (<span>consentSDK</span>) {
</span></span><span><span>    <span>consentSDK</span>.<span>remove</span>();
</span></span><span><span>    <span>return</span> <span>true</span>;
</span></span><span><span>  }
</span></span><span><span>  <span>return</span> <span>false</span>;
</span></span><span><span>};
</span></span></code></pre></div><p>Not much more to it other than that.</p>
<p><img src="https://blog.bymitch.com/reject-cookies/reject-cookies-umbrella.png" alt="Reject Cookies Umbrella" title="Umbrella"></p>
<h2 id="help-it-get-better">Help it get better</h2>
<p><strong>Reject Cookies is still a work in progress.</strong> It can use your support to help cover more use cases and report bugs. As mentioned the design targets specific cookie consent implementations from different vendors. There are more vendors out there and different flavors of each vendors implementation. The side panel allows you to report sites where the cookie consent rejection was missed along with a place to report bugs or issues with the extension. The side panel can be accessed by clicking on the chrome extension‚Äôs menu in Chrome. You can also feel free to reach out to <a href="https://blog.bymitch.com/cdn-cgi/l/email-protection#81e8efe7eec1e3f8ece8f5e2e9afe2eeec"><span data-cfemail="5e373038311e3c2733372a3d36703d3133">[email&nbsp;protected]</span></a> with any feedback.</p>
<p><img src="https://blog.bymitch.com/reject-cookies/side-panel.png" alt="Side panel debugging screenshot" title="Side Panel"></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Heart disease deaths worldwide linked to chemical widely used in plastics (154 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html</link>
            <guid>43831142</guid>
            <pubDate>Tue, 29 Apr 2025 11:35:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html">https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html</a>, See on <a href="https://news.ycombinator.com/item?id=43831142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/detergent-bottle.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/detergent-bottle.jpg" data-sub-html="Credit: Unsplash/CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/detergent-bottle.jpg" alt="detergent bottle" title="Credit: Unsplash/CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: Unsplash/CC0 Public Domain
            </figcaption>        </figure>
    </div><p>Daily exposure to certain chemicals used to make plastic household items could be linked to more than 365,000 global deaths from heart disease in 2018 alone, a new analysis of population surveys shows.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>While the chemicals, called phthalates, are in widespread use globally, Africa, South Asia, and the Middle East populations bore a much larger share of the death toll than others‚Äîabout half the total.</p>
<p>For decades, experts have connected health problems to exposure to certain phthalates found in cosmetics, detergents, solvents, plastic pipes, bug repellents, and other products. When these chemicals break down into microscopic particles and are ingested, studies have linked them to an increased risk of conditions ranging from obesity and diabetes to fertility issues and cancer.</p>
<p>Led by researchers at NYU Langone Health, the current study focused on a kind of phthalate called di-2-ethylhexyl phthalate (DEHP), which is used to make food containers, medical equipment, and other plastic softer and more flexible. Exposure has been shown in other studies to prompt an overactive immune response (inflammation) in the heart's arteries, which, over time, is associated with an increased risk of heart attack or stroke.</p>
<p>In their new analysis, the authors estimated that DEHP exposure contributed to 368,764 deaths, or more than 10% of all global mortality from <a href="https://medicalxpress.com/tags/heart+disease/" rel="tag">heart disease</a> in 2018 among men and women aged 55 through 64. A report on the findings is published in the journal <i>eBioMedicine</i>.</p>
<p>"By highlighting the connection between phthalates and a leading cause of death across the world, our findings add to the vast body of evidence that these chemicals present a tremendous danger to human health," said study lead author Sara Hyman, BS, an associate research scientist at NYU Grossman School of Medicine.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>According to the authors, the resulting economic burden from the deaths identified in their study was estimated to be around $510 billion and may have reached as high as $3.74 trillion.</p>
<p>In a past study from 2021, the research team tied phthalates to more than 50,000 premature deaths each year, mostly from heart disease, among older Americans. Their latest investigation is believed to be the first global estimate to date of cardiovascular mortality‚Äîor indeed any health outcome‚Äîresulting from exposure to the chemicals, says Hyman, who is also a graduate student at NYU School of Public Global Health.</p>
<p>For the research, the team used health and environmental data from dozens of population surveys to estimate DEHP exposure across 200 countries and territories. The information included urine samples containing chemical breakdown products left by the plastic additive. Mortality data was obtained from the Institute for Health Metrics and Evaluation, a research group in the US that collects medical information worldwide to identify trends in public health.</p>
<p>Among the key findings, the study showed that losses in Africa and in the combined region of East Asia and the Middle East accounted, respectively, for 30% and 25% of the mortality from heart disease linked to DEHP. Specifically, India had the highest death count at 39,677 deaths, followed by Pakistan and Egypt.</p>
<p>The larger heart death risks in these populations held true even after the researchers adjusted their statistical analysis to take into account population size within the studied age group.</p>

                                                                                                                                            <p>A possible explanation, the authors say, is that these countries face higher rates of exposure to the chemicals, possibly because they are undergoing a boom in plastic production but with fewer manufacturing restrictions than other regions.</p>
<p>"There is a clear disparity in which parts of the world bear the brunt of heightened heart risks from phthalates," said study senior author Leonardo Trasande, MD, MPP.</p>
<p>"Our results underscore the urgent need for global regulations to reduce exposure to these toxins, especially in areas most affected by rapid industrialization and plastic consumption," added Trasande, the Jim G. Hendrick, MD, Professor of Pediatrics at NYU Grossman School of Medicine.</p>
<p>Trasande, who is also a professor in the Department of Population Health, cautions that the analysis was not designed to establish that DEHP directly or alone caused heart disease and that higher death risks did not take into account other types of phthalates. Nor did it include mortality among those in other age groups. As a result, the overall death toll from heart disease connected to these chemicals is likely much higher, he says.</p>
<p>Trasande says that the researchers next plan to track how reductions in <a href="https://medicalxpress.com/tags/phthalate/" rel="tag">phthalate</a> exposure may, over time, affect global mortality rates, as well as to expand the study to other health concerns posed by the chemicals, such as preterm birth. Trasande also serves as director of NYU Grossman School of Medicine's Division of Environmental Pediatrics and the Center for the Investigation of Environmental Hazards.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Phthalate exposure from plastics and cardiovascular disease: global estimates of attributable mortality and years life lost, <i>eBioMedicine</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.ebiom.2025.105730" target="_blank">DOI: 10.1016/j.ebiom.2025.105730</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Heart disease deaths worldwide linked to chemical widely used in plastics (2025, April 29)
                                                 retrieved 29 April 2025
                                                 from https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon to display tariff costs for consumers (417 pts)]]></title>
            <link>https://punchbowl.news/article/tech/amazon-display-tariff-costs/</link>
            <guid>43831027</guid>
            <pubDate>Tue, 29 Apr 2025 11:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://punchbowl.news/article/tech/amazon-display-tariff-costs/">https://punchbowl.news/article/tech/amazon-display-tariff-costs/</a>, See on <a href="https://news.ycombinator.com/item?id=43831027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                        <p><img width="1024" height="683" src="https://punchbowl.news/wp-content/uploads/GettyImages-2209820827.jpg" alt="Amazon will soon display how much of an item‚Äôs cost is derived from tariffs ‚Äî right next to the product‚Äôs total listed price." decoding="async" srcset="https://punchbowl.news/wp-content/uploads/GettyImages-2209820827.jpg 1024w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-300x200.jpg 300w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-768x512.jpg 768w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-50x33.jpg 50w" sizes="(max-width: 1024px) 100vw, 1024px">                        </p>

                        
                        
                        <div>
                                                            <p><strong>Amazon doesn‚Äôt want</strong>&nbsp;to shoulder the blame for the cost of President&nbsp;<strong>Donald Trump</strong>‚Äô<strong>s</strong>&nbsp;trade war.</p>
<p><strong>So the e-commerce giant</strong>&nbsp;will<strong>&nbsp;</strong>soon show how much Trump‚Äôs tariffs are adding to the price of each product, according to a person familiar with the plan.</p>
<p><strong>The shopping site&nbsp;</strong>will display how much of an item‚Äôs cost is derived from tariffs ‚Äì right next to the product‚Äôs total listed price.</p>
                                
                                                                                        <div>
        <p><img src="https://punchbowl.news/wp-content/themes/punchbowl-news/assets/images/tech-icon.svg" alt="Subscripion logo">
        </p>
        <h4>You're seeing a preview of our <span>Premium Policy: Tech</span> coverage. Read the full story by <a href="https://punchbowl.news/pricing">subscribing here.</a></h4>
    </div>                            
                            
                            
                        </div>
                    </div><p>Editorial photos provided by Getty Images. Political ads courtesy of AdImpact.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI is not replacing jobs or hurting wages at all, say economists (250 pts)]]></title>
            <link>https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/</link>
            <guid>43830613</guid>
            <pubDate>Tue, 29 Apr 2025 10:08:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/">https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/</a>, See on <a href="https://news.ycombinator.com/item?id=43830613">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Instead of depressing wages or taking jobs, generative AI chatbots like ChatGPT, Claude, and Gemini have had almost no wage or labor impact so far ‚Äì a finding that calls into question the huge capital expenditures required to create and run AI models.</p>
<p>In <a target="_blank" rel="nofollow" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5219933">a working paper</a> released earlier this month, economists Anders Humlum and Emilie Vestergaard looked at the labor market impact of AI chatbots on 11 occupations, covering 25,000 workers and 7,000 workplaces in Denmark in 2023 and 2024.</p>
<p>Many of these occupations have been described as being vulnerable to AI: accountants, customer support specialists, financial advisors, HR professionals, IT support specialists, journalists, legal professionals, marketing professionals, office clerks, software developers, and teachers.</p>

    

<p>Yet after Humlum, assistant professor of economics at the Booth School of Business, University of Chicago, and Vestergaard, a PhD student at the University of Copenhagen, analyzed the data, they found the labor and wage impact of chatbots to be minimal.</p>
<blockquote>

<p>AI chatbots have had no significant impact on earnings or recorded hours in any occupation</p>
</blockquote>
<p>"AI chatbots have had no significant impact on earnings or recorded hours in any occupation," the authors state in their paper.</p>
<p>The report should concern the tech industry, which has hyped AI's economic potential while plowing billions into infrastructure meant to support it. Early this year, OpenAI <a target="_blank" href="https://www.theregister.com/2025/01/06/altman_gpt_profits/">admitted</a> that it loses money per query even on its most expensive enterprise SKU, while companies like <a target="_blank" href="https://www.theregister.com/2025/04/09/microsoft_puts_more_datacenter_builds/">Microsoft</a> and <a target="_blank" href="https://www.theregister.com/2025/04/22/aws_datacenter_leases/">Amazon</a> are starting to pull back on their AI infrastructure spending in light of <a target="_blank" href="https://www.theregister.com/2025/03/14/ai_running_out_of_juice/">low</a> business adoption past a few <a target="_blank" rel="nofollow" href="https://www.wsj.com/articles/johnson-johnson-pivots-its-ai-strategy-a9d0631f">pilots</a>.</p>

        


        

<p>The problem isn't that workers are avoiding generative AI chatbots - quite the contrary. But they simply aren't yet equating to actual economic benefits.</p>
<blockquote>

<p>The adoption of these chatbots has been remarkably fast ... But then when we look at the economic outcomes, it really has not moved the needle</p>
</blockquote>
<p>"The adoption of these chatbots has been remarkably fast," Humlum told <em>The Register</em>. "Most workers in the exposed occupations have now adopted these chatbots. Employers are also shifting gears and actively encouraging it. But then when we look at the economic outcomes, it really has not moved the needle."</p>
<p>The researchers looked at the extent to which company investment in AI has contributed to worker adoption of AI tools, and also how chatbot adoption affected workplace processes.</p>
<p>While firm-led investment in AI boosted the adoption of AI tools ‚Äî saving time for 64 to 90 percent of users across the studied occupations ‚Äî chatbots had a mixed impact on work quality and satisfaction.</p>

        

<p>The economists found for example that "AI chatbots have created new job tasks for 8.4 percent of workers, including some who do not use the tools themselves."</p>
<p>In other words, AI is creating new work that cancels out some potential time savings from using AI in the first place.</p>
<p>"One very stark example that it's close to home for me is there are a lot of teachers who now say they spend time trying to detect whether their students are using ChatGPT to cheat on their homework," explained Humlum.</p>

        

<p>He also observed that a lot of workers now say they're spending time reviewing the quality of AI output or writing prompts.</p>
<p>Humlum argues that can be spun negatively, as a subtraction from potential productivity gains, or more positively, in the sense that automation tools historically have tended to generate more demand for workers in other tasks.</p>
<p>"These new job tasks create new demand for workers, which may boost their wages, if these are more high value added tasks," he said.</p>
<ul>

<li><a href="https://www.theregister.com/2025/04/28/ibm/">Artist formerly known as Indian Business Machines pledges $150B for US ops, R&amp;D</a></li>

<li><a href="https://www.theregister.com/2025/04/27/darpa_expmath_ai/">DARPA to 'radically' rev up mathematics research. And yes, with AI</a></li>

<li><a href="https://www.theregister.com/2025/04/25/google_admits_depreciation_costs_soaring/">Google admits depreciation costs are soaring amid furious bit barn build</a></li>

<li><a href="https://www.theregister.com/2025/04/24/sustainability_still_not_a_high/">Sustainability still not a high priority for datacenter industry</a></li>
</ul>
<p>But overall, the time savings from using AI was less than expected. According to the study, "users report average time savings of just 2.8 percent of work hours" from using AI tools. That's a bit more than one hour per 40 hour work week.</p>
<p>The authors note that this finding differs from other randomized controlled trials that have found productivity benefits on the order of <a target="_blank" rel="nofollow" href="https://academic.oup.com/qje/article/140/2/889/7990658">15 percent</a>. And they explain this discrepancy by saying that other studies have focused on occupations with high AI productivity potential and that real-world workers don't operate under the same conditions.</p>
<p>"So I think there are two key reasons why the real economic gains are lower than [the cited studies]," said Humlum, noting that his study relies on actual tax data.</p>
<p>"First, most tasks do not fall into that category where ChatGPT can just automate everything. And then second, we're in this middle phase where employers are still waking up to the new reality, and we're trying to figure out how to best really realize the potential in these tools. And just at this stage, it's just not been that much of a game changer."</p>
<p>Where there are productivity gains to be had, Humlum and Vestergaard estimate that only a small portion of that benefit ‚Äì between 3 and 7 percent ‚Äì gets passed through to workers in the form of higher earnings.</p>
<p>Humlum said while there are gains and time savings to be had, "there's definitely a question of who they really accrue to. And some of it could be the firms ‚Äì we cannot directly look at firm profitability. Some of it could also just be that you save some time on existing tasks, but you're not really able to expand your output and therefore earn more.</p>
<p>"So it's like it saves you time writing emails. But if you cannot really take on more work or do something else that is really valuable, then that will put a damper on how much we should actually expect those time savings to affect your earning ability, your total hours, your wages."</p>
<p>Humlum said the impact of using AI chatbots, in the form of productivity, time savings, and work quality, can be improved through company commitment to internal education and evangelism. He pointed in particular to how firm initiatives can reduce the tool-usage gender gap ‚Äì fewer women use these tools than men.</p>
<p>But doing so at this point doesn't show much promise of payoff.</p>
<p>"In terms of economic outcomes, when we're looking at hard metrics ‚Äì in the administrative labor market data on earnings, wages ‚Äì these tools have really not made a difference so far," said Humlum. "So I think that that puts in some sense an upper bound on what return we should expect from these tools, at least in the short run.</p>
<p>"My general conclusion is that any story that you want to tell about these tools being very transformative, needs to contend with the fact that at least two years after [the introduction of AI chatbots], they've not made a difference for economic outcomes." ¬Æ</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Flowcode ‚Äì Turing-complete visual programming platform (129 pts)]]></title>
            <link>https://app.getflowcode.io/playground/example1</link>
            <guid>43830193</guid>
            <pubDate>Tue, 29 Apr 2025 09:04:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.getflowcode.io/playground/example1">https://app.getflowcode.io/playground/example1</a>, See on <a href="https://news.ycombinator.com/item?id=43830193">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Try Switching to Kagi (376 pts)]]></title>
            <link>https://daringfireball.net/2025/04/try_switching_to_kagi</link>
            <guid>43829490</guid>
            <pubDate>Tue, 29 Apr 2025 07:08:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/2025/04/try_switching_to_kagi">https://daringfireball.net/2025/04/try_switching_to_kagi</a>, See on <a href="https://news.ycombinator.com/item?id=43829490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">



<p>Aaron Pressman, writing earlier this month in The Boston Globe, ‚Äú<a href="https://www.bostonglobe.com/2025/04/01/business/google-search-problems-alternatives-kagi/">Why I Abandoned Google Search After 27 Years‚Äâ‚Äî‚Äâand What I‚Äôm Using Instead</a>‚Äù:</p>

<blockquote>
  <p>The UK now requires travelers from America to obtain an electronic
travel authorization, or ETA. I wasn‚Äôt sure of the exact name of
the ETA, so I just searched ‚Äútravel to UK.‚Äù</p>

<p>The results were all about obtaining an ETA and I picked a link
that looked like the official UK government site. It was not; the
official site was lower, below an AI summary, some sponsored
links, and other junk on the results page. Luckily for me, I did
get a legitimate travel pass‚Äâ‚Äî‚Äâbut the site I picked overcharged
me by about $70.</p>
</blockquote>

<p>I don‚Äôt know what the name for this sort of thing is, but it‚Äôs like a semi-scam. There are similar services to what Pressman ran into here for expedited passport renewals, for example‚Äâ‚Äî‚Äâthird-party companies that present themselves as official partners of the government that charge you extra for a service. But they just handle for you what you could just as easily do yourself, if you found the right place on the web to do it. A complete scam would be taking your money and giving you nothing (or a bogus document) in return. These semi-scams deliver the thing they‚Äôre promising, but charge you more than you should pay.</p>

<p>I just tried searching for ‚Äúexpedited passport renewal‚Äù <a href="https://www.google.com/search?q=expedited+passport+renewal">in Google</a> and <a href="https://kagi.com/search?q=expedited+passport+renewal">in Kagi</a>. Kagi presents as its first response the US State Department‚Äôs ‚Äú<a href="https://travel.state.gov/content/travel/en/passports/get-fast.html">How to Get my U.S. Passport Fast</a>‚Äù page. Google has that same link listed 7th, below the fold even on a desktop browser window on a 27-inch display, behind four sponsored links (all of which look pretty official but aren‚Äôt), an AI Overview (which itself includes, in its own AI Overview sidebar, another link to the same ‚ÄúHow to Get my U.S. Passport Fast‚Äù page), and another U.S. State Department webpage with general instructions for applying for a passport.</p>

<blockquote>
  <p>In the second case, last week, I needed to book a hotel for a
Passover trip to my brother‚Äôs in Connecticut. I knew there was a
cool hotel we had stayed at before near his house but I couldn‚Äôt
remember the name. I asked Google for hotels in the town where my
brother lives. Sure enough, one of the top results appeared on
first glance to be the official site of the hotel I wanted to
book. It was not. Once again, somewhat nefarious search engine
optimization techniques allowed a hotel aggregation site to jump
ahead in the results. And this time my error was even more costly,
to the tune of several hundred dollars in extra charges for two
hotel rooms.</p>

<p>Google has worked hard to eliminate truly fraudulent websites from
ending up in its results, and for that I am grateful. It is
undeniable that, in both instances, I should have been a more
careful consumer. But decades of relying on Google had taught me
that I didn‚Äôt have to be.</p>

<p>After I learned my lesson, I did some research in search of better
search. People I trust on the Internet, including the <a href="https://daringfireball.net/linked/2024/01/19/bray-google-kagi">Apple
blogger John Gruber</a> and <a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/">novelist Cory Doctorow</a>,
recommended a new search engine called <a href="https://kagi.com/">Kagi</a>.</p>

<p>I gave it a few test runs. A search for ‚Äú<a href="https://kagi.com/search?q=travel+to+uk">travel to UK</a>‚Äù
brought up the UK government page to apply for an ETA as the first
result. A search for a hotel in my brother‚Äôs town was topped by
the official site of the hotel I wanted. So I switched all my
default searches to Kagi.</p>
</blockquote>

<p>I keep trying to emphasize that I recommend switching to Kagi not because it‚Äôs more private (although it clearly is), not as a protest against Google (although for some, switching could be), not as a rejection of search ads dominating the top of Google‚Äôs results (although that‚Äôs true too), but simply because Kagi‚Äôs results are clearly better.</p>

<p>Like, even if I <a href="https://udm14.com/">use the magic <code>&amp;udm=14</code> parameter</a> with Google search, <a href="https://daringfireball.net/linked/2024/05/23/udm14">to get ‚Äúdisenshittified‚Äù results from Google</a>, I find I get <em>better</em> results from Kagi. When I know there‚Äôs one right answer (say, a specific article I remember reading and want to find again), Kagi is more likely than Google to list it first. If it‚Äôs a years-old article, Kagi is <em>way</em> more likely than Google to find it at all. For me, Google (and, alas, DuckDuckGo too) have largely stopped working reliably for finding not-recent stuff on the web. Not true with Kagi.</p>

<p>I used DuckDuckGo for years as my default search, and for those years, I found it largely on par with Google. But it felt like every once in a while‚Äâ‚Äî‚Äâmaybe, say, once or twice a month‚Äâ‚Äî‚ÄâDuckDuckGo would come up dry in its results. DuckDuckGo pioneered a trick <a href="https://duckduckgo.com/bangs">they call Bangs</a>. Include <code>!g</code> to any search terms, and instead of performing the search itself, DuckDuckGo will redirect that search to Google. They have a whole bunch of these Bangs‚Äâ‚Äî‚Äâ‚Äú!a‚Äù for Amazon search, ‚Äú!nf‚Äù for Netflix. There are literally thousands of them (which of course they allow you to search for). The only one I ever really used though was <code>!g</code>, for redirecting my current search to Google because DuckDuckGo‚Äôs own results for the same terms was unsatisfying. My memory may not match with my actual usage, but like I said, I <em>feel</em> like I used this about once or twice a month for the several years I was using DuckDuckGo as my default search engine. Infrequently enough that it didn‚Äôt annoy me to the point of considering switching back to Google for default in-browser search, but frequently enough that I was annoyed enough to remember that I needed to use it at all.</p>

<p><a href="https://help.kagi.com/kagi/features/bangs.html">Kagi supports Bangs too</a>, including <code>!g</code> for Google web search. I can‚Äôt remember the last time I felt the need to try using it. It‚Äôs been months, many months. And, the last few times I‚Äôve tried it, Google‚Äôs results were no more help than Kagi‚Äôs. Your mileage may vary, of course, but for me, unlike with DuckDuckGo, I effectively <em>never</em> find myself redirecting the same search to Google because I wasn‚Äôt happy with the results from Kagi. For context on my search usage, <a href="https://daringfireball.net/misc/2025/04/kagi-usage.png">my Kagi usage report</a> shows that I perform 400‚Äì800 web searches per month. (Kagi counts how often you search, for billing purposes, but <a href="https://kagi.com/privacy">does not keep a history</a> of <em>what</em> you searched for.)</p>

<p>Paying for Kagi today feels a <em>lot</em> like paying for HBO back in the cable TV heyday. Part of the deal is that you are paying for ad-free service, yes. But you‚Äôre also paying for noticeably higher quality. There were no shows like <em>The Sopranos</em>, <em>The Wire</em>, and <em>The Larry Sanders Show</em> on ‚Äúfree‚Äù TV channels, albeit with commercial interruptions. With HBO you got commercial-free entertainment <em>and</em> higher-quality shows and movies. Kagi is like that.<sup id="fnr1-2025-04-28"><a href="#fn1-2025-04-28">1</a></sup> It‚Äôs that good. No ads, no unwanted AI (but very good AI results if you want‚Äâ‚Äî‚Äâjust end your query with a question mark), <em>and</em> better search results.</p>





 <!-- PreviousNext -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spain is about to face the challenge of a "black start" (101 pts)]]></title>
            <link>https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/</link>
            <guid>43829356</guid>
            <pubDate>Tue, 29 Apr 2025 06:46:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/">https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/</a>, See on <a href="https://news.ycombinator.com/item?id=43829356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Local conditions</h2>
<p>While the grids in Spain and Portugal are connected to each other, they have limited connections to elsewhere. The only sources of external power to the grid come from France and Morocco, which are small connections, but they could be used to help black start some plants. Both blacked-out countries have significant hydropower, with Spain seeing it cover 10 percent of its demand and Portugal 25 percent. That's useful because hydro plants need very little in the way of an external power supply to start operating.</p>
<p>Beyond that, both countries have invested heavily in renewables, with Portugal supplying about half of its power from wind and hydro, having closed its last coal plant in 2021. Spain receives about 40 percent of its power from renewables at present.</p>
<p>Solar is not an ideal power source for black-starting the grid, given that it's unavailable for a significant chunk of the day. But solar panels produce direct current, with electronic systems matching it to the alternating current of the grid. With the right electronics, it can play a key role in keeping frequencies stable as grid segments are repowered. In productive areas, wind can provide black start power to other plants and doesn't need much external power to begin operations. It's unclear, however, whether the local wind hardware is equipped for black starts or if the local weather will cooperate (a quick check of the weather in various cities suggests it's relatively calm there).</p>
<p>Batteries have the potential to be incredibly helpful, since they also provide direct current that can be converted to any frequency needed, and so used for both starting up power plants or for frequency stabilization as segments of the grid are brought back online. Unfortunately, neither country has installed much grid-scale battery hardware yet. That's expected to change over the next few years in parallel with dramatically expanded solar power. But, at the moment, batteries will not be a huge help.</p>
<p>Regardless of how precisely the grid operators manage to handle this task in Spain and Portugal, they face a monumental challenge at the moment. If you're seeing estimates of several days for the restoration of power, it's because failing to meet this challenge will leave things back in the state they're in now.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dear "Security Researchers" (161 pts)]]></title>
            <link>https://ftp.bit.nl/pub/debian/</link>
            <guid>43829080</guid>
            <pubDate>Tue, 29 Apr 2025 05:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ftp.bit.nl/pub/debian/">https://ftp.bit.nl/pub/debian/</a>, See on <a href="https://news.ycombinator.com/item?id=43829080">Hacker News</a></p>
<div id="readability-page-1" class="page">
<span>Dear "Security Researchers",<p>

Welcome to our *PUBLIC* OPEN SOURCE SOFTWARE MIRROR SERVER.<br>
Please DO NOT report this under our responsible disclosure policy.<br>
This is a PUBLIC service, with OPEN SOURCE SOFTWARE, and NOT a security threat to our company.<br>
There is NO SENSITIVE INFORMATION on this server.</p><p>

Thanks.</p></span>
<hr>
  <table>
   <tbody><tr><th><img src="https://ftp.bit.nl/icons/blank.gif" alt="[ICO]"></th><th><a href="https://ftp.bit.nl/pub/debian/?C=N;O=D">Name</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=M;O=A">Last modified</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=S;O=A">Size</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="5"><hr></th></tr>
<tr><td><img src="https://ftp.bit.nl/icons/back.gif" alt="[PARENTDIR]"></td><td><a href="https://ftp.bit.nl/pub/">Parent Directory</a></td><td>&nbsp;</td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/hand.right.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/README">README</a></td><td>2025-03-15 09:29  </td><td>1.2K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/unknown.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.CD-manufacture">README.CD-manufacture</a></td><td>2010-06-26 11:52  </td><td>1.3K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.html">README.html</a></td><td>2025-03-15 09:29  </td><td>2.9K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.mirrors.html">README.mirrors.html</a></td><td>2017-03-04 21:08  </td><td>291 </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.mirrors.txt">README.mirrors.txt</a></td><td>2017-03-04 21:08  </td><td> 86 </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/dists/">dists/</a></td><td>2025-03-15 09:29  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/doc/">doc/</a></td><td>2025-04-29 03:52  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/unknown.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/extrafiles">extrafiles</a></td><td>2025-04-29 04:27  </td><td>201K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/indices/">indices/</a></td><td>2025-04-29 04:26  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/compressed.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/ls-lR.gz">ls-lR.gz</a></td><td>2025-04-29 04:18  </td><td> 15M</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/pool/">pool/</a></td><td>2022-10-05 19:09  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/project/">project/</a></td><td>2008-11-18 00:05  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/tools/">tools/</a></td><td>2012-10-10 18:29  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/zzz-dists/">zzz-dists/</a></td><td>2023-10-07 13:07  </td><td>  - </td><td>&nbsp;</td></tr>
   <tr><th colspan="5"><hr></th></tr>
</tbody></table>



  <title>Debian Archive</title>
  <meta name="Modified" content="2025-03-15">



<h2>Debian Archive</h2>

<p>See <a href="https://www.debian.org/">https://www.debian.org/</a>
for information about Debian GNU/Linux.</p>

<h2>Current Releases</h2>

<p>Four Debian releases are available on the main site:</p>

<blockquote>
<dl>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/buster/">Debian 10.13, or buster</a></dt>
<dd>Debian 10.13 was released Saturday, 10th September 2022.
<a href="https://www.debian.org/releases/buster/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/buster/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/bullseye/">Debian 11.11, or bullseye</a></dt>
<dd>Debian 11.11 was released Saturday, 31st August 2024.
<a href="https://www.debian.org/releases/bullseye/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/bullseye/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/bookworm/">Debian 12.10, or bookworm</a></dt>
<dd>Debian 12.10 was released Saturday, 15th March 2025.
<a href="https://www.debian.org/releases/bookworm/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/bookworm/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/testing/">Testing, or trixie</a></dt>
<dd>The current tested development snapshot is named trixie.<br>
Packages which have been tested in unstable and passed automated
tests propagate to this release.<br>
<a href="https://www.debian.org/releases/testing/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/unstable/">Unstable, or sid</a></dt>
<dd>The current development snapshot is named sid.<br>
Untested candidate packages for future releases.<br>
<a href="https://www.debian.org/releases/unstable/">More information</a>
</dd>
</dl>
</blockquote>

<h2>Old Releases</h2>

<p>Older releases of Debian are at
<a href="http://archive.debian.org/debian-archive/">http://archive.debian.org/debian-archive</a>
<br>
<a href="https://www.debian.org/distrib/archive">More information</a>
</p>

<h2>CDs</h2>

<p>For more information about Debian CDs, please see
<a href="https://ftp.bit.nl/pub/debian/README.CD-manufacture">README.CD-manufacture</a>.
<br>
<a href="https://www.debian.org/CD/">Further information</a>
</p>

<h2>Mirrors</h2>

<p>For more information about Debian mirrors, please see
<a href="https://ftp.bit.nl/pub/debian/README.mirrors.html">README.mirrors.html</a>.
<br>
<a href="https://www.debian.org/mirror/">Further information</a>
</p>

<h2>Other directories</h2>

<table summary="Other directories">
<tbody><tr><td><a href="https://ftp.bit.nl/pub/debian/doc/">doc</a></td>          <td>Debian documentation.</td></tr>
<tr><td><a href="https://ftp.bit.nl/pub/debian/indices/">indices</a></td>  <td>Various indices of the site.</td></tr>
<tr><td><a href="https://ftp.bit.nl/pub/debian/project/">project</a></td>  <td>Experimental packages and other miscellaneous files.</td></tr>
</tbody></table>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[LibreLingo ‚Äì FOSS Alternative to Duolingo (567 pts)]]></title>
            <link>https://librelingo.app</link>
            <guid>43829035</guid>
            <pubDate>Tue, 29 Apr 2025 05:45:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://librelingo.app">https://librelingo.app</a>, See on <a href="https://news.ycombinator.com/item?id=43829035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="LibreLingo Mascot" src="https://librelingo.app/images/mascot-jetpack-noshadow.svg" data-test="mascot-jetpack"> </p> <p><h2><span data-tkey="index.subtitle">an experiment to create a community-driven language-learning platform</span></h2> </p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A single line of code cost $8000 (204 pts)]]></title>
            <link>https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000</link>
            <guid>43829006</guid>
            <pubDate>Tue, 29 Apr 2025 05:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000">https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000</a>, See on <a href="https://news.ycombinator.com/item?id=43829006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2 id="6229ad4c359d4dbf908c56b33a98c24c">TLDR</h2></p><div><p>Due to a bug, our screen recorder app - <a target="_blank" href="http://screen.studio/">screen.studio</a> app kept downloading the auto-update file repeatedly, every 5 minutes for every single user. The update file is approximately 250MB. This resulted in <b>9 million file downloads and more than 2 petabytes (2,000,000 gigabytes)</b> of traffic on Google Cloud.</p></div><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkZlMjZiZThjNS05ZDcxLTRmYTgtODBlYS1iNDdiNmNmNTg3Y2ElMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9NzNkMzk3N2YtNjJhNy00MmQ1LTk2ZTQtNThiYmQwMDc5NzMyJmNhY2hlPXYyJndpZHRoPTE2NzQuOTY4NzU="></p></div></figure><div><p>This screenshot might not look so scary at first, but take a look at the scale of it. For over a month, we generated at least 100Mib/s (a second!) and, at times, almost 1GiB/s of traffic (every single second!)</p></div><hr><div><p>That bug was painfully simple and stupid.</p></div><div><p>Screen Studio is a screen recorder for macOS. It is desktop app. It means we need some auto-updater to allow users to install the latest app version easily.</p></div><div><p>The app checks for the update every 5 minutes or when the user activates the app.</p></div><div><p>Normally, when the app detected the update - it downloaded it and stopped the 5 minutes interval until the user installed it and restarted it.</p></div><p><h2 id="86e96dd5a9a64f7eb2a3408771948538">Tragic refactor</h2></p><div><p>The problem with the auto-updater we had was that it would prompt the user to update the app as soon as it became available. This resulted in a popup appearing while users were recording the screen, which obviously provided a bad experience as it interrupted the recording the user was making.</p></div><div><p>While refactoring it, <b>I forgot to add the code to stop the 5-minute interval after the new version file was available and downloaded.</b></p></div><div><p>It meant <b>the app was downloading the same 250MB file, over and over again, every 5 minutes.</b></p></div><p><h2 id="8bc5a4ebee2d4a2387cb4af3e66bda00">Tragic context - app running in the background for weeks</h2></p><div><p>It turns out thousands of our users had the app running in the background, even though they were not using it or checking it <b>for weeks</b> (!). It meant thousands of users had auto-updater constantly running and downloading the new version file (250MB) over and over again every 5 minutes</p></div><p><h2 id="0c7c00acd73e4f7ba7a05ffd8ee2f5bf">The math</h2></p><div><p>Let‚Äôs do some quick math here.</p></div><ul><li>Doing something every 5 minutes means doing it approximately <b>288 times a day</b>.</li></ul><ul><li>The update file is about 250 MB, meaning <b>72 GB of downloads per user daily</b>.</li></ul><ul><li>We had this situation happening for <b>over a month before we noticed it</b>.</li></ul><ul><li>We had at least a <b>thousand such app instances running</b> in the background at any moment.</li></ul><ul><li><b>250 MB * 288 downloads per day * 30 days * 1000 users:</b></li></ul><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkY1Y2FlZmVkYS0wMDFjLTQ2NDktODM2Zi1lMTI0MzM0NDRjMGUlMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9M2FjZmFjNzAtOTc2ZC00ZmI4LTkwYTgtMzU5NmQzMTFkZGFlJmNhY2hlPXYyJndpZHRoPTE2NzQuOTg0Mzc1"></p></div></figure><ul><li><b>2 000 000 gigabytes, </b></li></ul><ul><li><b>or 2 000 terabytes </b></li></ul><ul><li><b>or 2 petabytes of traffic.</b></li></ul><p><h2 id="b0ab8050379441e89f1489895de53ae8">Series of bad mistakes</h2></p><div><p><b>We did not have cost alerts on Google Cloud</b>. Before this situation occurred, we were paying at most $300 a month.</p></div><div><p>We were also not regularly checking the situation as it just worked.</p></div><div><p>We noticed it because my credit card started to block the transaction due to limits I had set on it (lucky me!).</p></div><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkYxMWRhNDI1YS05YWU0LTRiZTgtOGIzNi1hMzc3MmQwOTdjMTElMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9NmE3M2JhYzgtZWMwYi00ZmJiLWJjOTctNzEyYjk4NDM3YmM4JmNhY2hlPXYyJndpZHRoPTI0MDA="></p></div></figure><p><h2 id="1bf63d5f09bb48f9a25dc3820bb49e03">Consequences for the users</h2></p><div><p>It was not only bad for us but even worse for some of the users.</p></div><div><p>As mentioned, the app was generating so much traffic. <b>It means it was their machine generating network traffic on their home router and their internet provider.</b></p></div><div><p>One of our users, who lived in a house, had their internet provider cancel their contract due to enormous traffic generated during a month. It was extremely problematic as there was no other internet provider available around.</p></div><div><p>We decided to take responsibility and offer to cover all the costs related to this situation.</p></div><div><p>Luckily, it was not needed as the person could figure out the situation with the provider without bigger problems.</p></div><div><p>That was, however, quite a terrible experience for that person and me. As a designer, I value the experience product I create provides to the users. And this was not even a bad experience; it was actually harmful.</p></div><p><h2 id="cba99c00ddec4d4890f45cf68e515c40">Summarising</h2></p><ul><li><b>Set alerts</b> on your cloud at all times.</li></ul><ul><li>Write your auto-updater code very carefully.</li></ul><ul><li>Actually, <b>write any code that has the potential to generate costs carefully</b>.</li></ul><ul><li>Add special signals you can change on your server, which the app will understand, such as a <b>forced update</b> that will install without asking the user.</li></ul><ul><li>Regularly check your cloud.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle engineers caused five days software outage at U.S. hospitals (160 pts)]]></title>
            <link>https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html</link>
            <guid>43828915</guid>
            <pubDate>Tue, 29 Apr 2025 05:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html">https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html</a>, See on <a href="https://news.ycombinator.com/item?id=43828915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108079907" data-test="InlineImage"><p>Larry Ellison, co-founder and executive chairman of Oracle Corp., speaks during the Oracle OpenWorld 2018 conference in San Francisco, California, U.S., on Monday, Oct. 22, 2018.</p><p>David Paul Morris | Bloomberg | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/ORCL/">Oracle</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> engineers mistakenly triggered a five-day software outage at a number of Community Health Systems hospitals, causing the facilities to temporarily return to paper-based patient records.</p><p>CHS told CNBC that the outage involving Oracle Health, the company's electronic health record (EHR) system, affected "several" hospitals, leading them to activate "downtime procedures." Trade publication Becker's Hospital Review reported that 45 hospitals were hit.</p><p>The outage began on April 23, after engineers conducting maintenance work mistakenly deleted critical storage connected to a key database, a CHS spokesperson said in a statement. The outage was resolved on Monday, and was not related to a cyberattack or other security incident.</p><p>CHS is based in Tennessee and includes 72 hospitals in 14 states, according to the medical system's website.</p><p>"Despite this being a major outage, our hospitals were able to maintain services with no&nbsp;material impact," the spokesperson said. "We are proud of our clinical and support teams who worked through the multi-day outage with professionalism and a commitment to delivering high-quality, safe care for&nbsp;patients."&nbsp;</p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Oracle stock this year</p></div><div><p>Oracle didn't immediately respond to CNBC's request for comment.</p><p>An EHR is a digital version of a patient's medical history that's updated by doctors and nurses. It's crucial software within the U.S. health-care system, and outages can cause serious disruptions to patient care. Oracle acquired EHR vendor Cerner in 2022 for $28.3 billion, becoming the second-biggest player in the market, behind Epic Systems.</p><p>Now that Oracle's systems are back online, CHS said that the impacted hospitals&nbsp;are working to "re-establish full functionality and return to normal operations and procedures."</p><p>Oracle's CHS error comes weeks after the company's federal electronic health record experienced a <a href="https://www.cnbc.com/2025/03/06/oracles-federal-electronic-health-record-suffered-nation-wide-outage-.html">nationwide outage</a>. Oracle has struggled with a thorny, years-long EHR rollout with the Department of Veterans Affairs, marred by patient safety concerns. The agency launched a&nbsp;<a href="https://news.va.gov/press-room/va-announces-strategic-review-of-electronic-health-record-modernization-program/" target="_blank">strategic review</a>&nbsp;of Cerner in 2021, before Oracle's acquisition, and it temporarily&nbsp;<a href="https://digital.va.gov/ehr-modernization/ehr-deployment-schedule/" target="_blank">paused deployment</a>&nbsp;of the software in 2023.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2025/02/20/oracle-ceo-safra-catz-being-number-one-is-very-important.html">Interview with Oracle CEO Safra Catz</a></p></div><div id="Placeholder-ArticleBody-Video-108105025" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000367188" aria-labelledby="Placeholder-ArticleBody-Video-108105025"><p><img src="https://image.cnbcfm.com/api/v1/image/108105026-17400675801740067576-38548750502-1080pnbcnews.jpg?v=1740067578&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Oracle CEO Safra Catz: Being number one is very important"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowledge-based society, my ass (322 pts)]]></title>
            <link>https://mihaiolteanu.me/knowledge-based-society-my-ass</link>
            <guid>43828713</guid>
            <pubDate>Tue, 29 Apr 2025 04:33:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mihaiolteanu.me/knowledge-based-society-my-ass">https://mihaiolteanu.me/knowledge-based-society-my-ass</a>, See on <a href="https://news.ycombinator.com/item?id=43828713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="contents">

            

            <p>
            Right after I get admitted, I inform Professor that I also have a full-time
            job. He insists that we must start working right away. I quit as a result and
            instantly breathe a refined air. I am now a scientist! A week later I approach
            Professor and let him know I'm ready for work.
            </p>

            <p>
            "Ready for what?" he greets me as though our previous conversation didn't
            happen. I remind him that he's my PhD supervisor and that, at his proposal, we
            are studying the effects of electromagnetic fields on patients with carotid
            stent implants. "There is nothing for you to do at the University, you can
            stay home for now," he tells me. Is he really serious? Does he want me to do
            research from bed? I insist on reading materials related to our field of
            research. I want to start right away. But he can't recommend any.
            </p>

            <p>
            My first day of research is over. It's autumn 2009. I spend the following days
            of my academic life oversleeping and strolling the city parks. I actually
            enjoy this newfound freedom from the alarm clock. I think, not without a
            certain longing, of my former factory colleagues. How we used to laugh at the
            stupidest of things, how it all felt like a big family. But I have a new life
            now. An intellectual one.
            </p>

            <p>
            A few weeks go by. No word from Professor. It's exhausting to conduct research
            like this. I need some color. I approach Professor again and ask for basic
            research equipment, "I need an office, Professor," I begin, and, after a short
            while, I raise my stakes, "And a computer, too!"  I've gone too
            far. "Everybody is happy around here, except you!!!" he snaps at me. I get a
            feeling that I'm going nowhere with Professor.
            </p>

            <p>
            I approach the Head of Department. The Head listens carefully for my
            complaints and kindly informs me he doesn't mingle in Professor's business. It
            is up to my advisor to decide where the resources are allocated within his
            team. A nice way of deflecting responsibility.
            </p>

            <p>
            The Faculty's Dean doesn't give a damn either but I think he wants to avoid
            even more troubles seeing that I'm so stubborn. I soon receive an email from
            Professor as a result. He decides to offer me an office and a computer. Two
            months wasted. Even so, I celebrate my first academic victory.
            </p>

            <p>
            "Grab a computer and follow me," Professor instructs me a few days later. I
            can barely hide my enthusiasm. We take the stairs to the first floor. Then
            ground floor. Then basement. "Almost there," I hear Professor in the
            darkness. After two more turns he opens a big door and hands me over the
            keys. My office is a rather spacious but austere room in the University's
            basement. My initial enthusiasm is fading. There's a simple desk with a basic
            chair at one end and a small, too high to reach window at the other. The walls
            are immaculately white. A hospital-style metal locker where Professor keeps his
            valuables under key completes the picture. 
            </p>

            <p>
            "Doctoral Studies in Engineering Sciences for Developing the Knowledge-Based
            Society" is the name of our project. It pays me, and approximately one hundred
            other colleagues of mine, all PhD candidates, our ‚Ç¨500/month scholarships, or
            about the average wage. It's one project from among the four thousand projects
            sponsored by the European Union's "Operational Program for Human Resources
            Development." This grandiose program, with an available budget of ‚Ç¨5 billion,
            aims to "develop the human capital and increase competitiveness by bringing
            education and life-long learning in sync with a modern, flexible and inclusive
            labor market and increase future opportunities for 1.650.000 people." Yes,
            those are millions, 15.000 of which are to become PhD students! The Government
            says so, I it as fact.
            </p>

            <p>
            For my part, I have to publish at least three scientific papers, present my
            research at one international conference and successfully defend my thesis in
            public. I have exactly three years at my disposal. If I fail, I have to return
            my scholarship in full. It's also up to me to rejoin the labor market and take
            care of my future, possibly as a teaching assistant here, at the
            University. So I take things seriously and go to work each morning. I learn
            and labor as hard as I can.
            </p>

            <p>
            I begin with the documentation phase and I read, among others, a very detailed
            series of experiments: human subjects placed in anechoic chambers with all
            kinds of electromagnetic fields directed at them. They measure changes in
            sweat rate, breathing rate, exhaled humidity, body temperatures, blood
            pressure and everything one can imagine. They try to figure out how the body
            responds and adapts to such an external stimulus.
            </p>

            <p>
            I, for my side, have to see what happens inside the human neck artery when an
            implanted stent heats up under the influence of electromagnetic fields. How
            does the body react and compensate for such a temperature increase, if there
            is one? I have things to discover. But I also have zero lab equipment. Not
            even a digital thermometer, let alone medical equipment of the kind I would
            need. The whole medical engineering's lab, the one I took my computer from, is
            a room twice the size of my basement with ten desktop computers in it, a
            blackboard, a small window blocked by another building and an extra door for a
            special room: Professor's own office.
            </p>

            <p>
            Critically, I do not even get to see or touch a real stent. We don't have
            any. There are no interactions with patients, no collaboration with doctors
            and no conversations with other engineers from our University. I'm alone in my
            office. I'm not sure what people do around here. When the whole Department
            gathers around, I hear professors complaining about "kids these days" but zero
            technical discussions and hardly any interest in scientific topics. We are
            one-man teams, each working in their only little basements, so to speak.
            </p>

            <p>
            Professor reassures me that computer simulations are enough for our study. So
            I try to find software licenses plus realistic computer models for my stents
            and human heads. They all cost money and are hard to find. To develop them
            from scratch is outside my specialty. Ideally, I should understand a bit of
            human biology, too, but that's again outside my specialty. I wonder at this
            point if I actually have a specialty. What makes me qualified to approach
            these issues? Why would my "discoveries", born out of such meager
            possibilities, have any relevance for science?
            </p>

            <p>
            I don't lack motivation, though. I try to get a license for the ‚Ç¨20k per year
            software we're using. It proves to be another catacombic adventure. The
            company offers two free licenses per public institution. I ask Professor for a
            license, but "There aren't any left," he informs me. "Don't we have two?" I
            insist. "Well, yes, but one license is on my laptop, which I always carry with
            me, and the other is on my office computer," he replies. I ask permission to
            his office to run some simulations from time to time, but "No, my office is
            closed and only I have the key." I conclude Professor has a terrible fondness
            for locks and keys. I drop it. I'm not sure what he does with two
            licenses. Maybe he sells them on the black market? Maybe Professor is a
            gangster? Who knows.
            </p>

            <p>
            One of my colleagues who is pursuing his PhD in the same Department under a
            different professor and a similar area of research, with whom I only cross
            paths when our blood pressure runs too high, happens to also work for a public
            institution. He applies for the two free licenses and is generous enough to
            offer me one.
            </p>

            <p>
            Another victory. But I'm fed up with these victories. It's exhausting to fight
            all these absurd battles. My time is running out. I have to write some papers
            soon. I accept my fate. I accept I'm not gonna be a scientist the way I've
            imagined more than a year ago. I don't see any future for me here at the
            University. As a result, I simplify things tremendously. I draw a big sphere
            and pretend it's a human head, I place a long metallic cylinder inside it and
            pretend it's a real stent and I place a simple antenna close by. Anything more
            complicated than this crashes my toy computer. I soon realize that I play
            scientist like kids play cop with water pistols.
            </p>

            <p>
            I get to publish my first paper in this way. I'm actually quite proud of it,
            given the circumstances. I actually start to enjoy writing. I put down my
            colleague as a co-author as a thank you for lending me the license. We've
            learned this trick from the professors who do it all the time with their
            books, papers and conferences. They are required, just as we are, to publish
            and look active in the community per their contract with the University.
            </p>
            
            <p>
            Out of curiosity, I start reading our school's newspaper, as my colleague
            calls our University's scientific journal. I soon spot inconsistencies. The
            wording is in plain, boring language with long introductions repeating the
            same generalities and facts known to all. But the style changes unexpectedly
            sometimes. I search these peculiar phrases online and my intuition is
            confirmed. Unacknowledged commandeering of intellectual labor via
            indiscriminate copy and paste practices. Plagiarism, in short. I find dozens
            of such instances. I see the name of our Head in there, too. I try to raise
            awareness for a month or two. Nobody gives a damn.
            </p><p>

            I stop reading the school's newspaper and concentrate on publishing my other
            papers instead. They are nothing more than variations on the first paper with
            different titles and different pictures. I let my computer run overnight and
            invent slightly different simulation scenarios and I underline different
            aspects of my results in each paper. After this, I take a more relaxed
            approach regarding my scientific pursuits, enjoy the show around me
            instead and stop giving a damn about Professor from now on.
            </p>
            
            <p>
            I notice the Head is emphasizing the "academic dress code" all the time. He
            even publishes an official Department guideline on this topic pressing us all
            to read it. I notice professors are always addressing each other formally even
            in informal settings, though they've been acquainted for years. This title
            caries great importance here. I myself make a blunder in this respect when I
            visit Professor's office one day for some official papers. I ask if he's
            around but I refer to him by his family name only. I get admonished for
            skipping the "professor" part. I apologies, add the missing title and address
            the question again. "No, Professor is not here!" comes the reply abruptly.
            </p>

            <p>
            Our Head both informs and threatens us, "Per the Department guidelines, every
            PhD candidate is required to teach for one semester. Find yourselves a seminar
            or a lab or I'll pick one for you." It so happens that I get friendly with an
            electronics department's professor. He asks me to be his teaching assistant. I
            inform the Head with great pleasure about this development and he, in turn,
            informs me with great satisfaction that "I do not give this position to PhD
            candidates." I insist, but in vain. I get used to insisting in vain. I get
            used to failing to figure out how this whole clusterfuck works. One colleague
            is appointed to teach C++ by the Head. "You know C++?" I ask enthusiastically,
            as I am looking to become a software engineer myself at this point. "I don't,"
            she informs me, "but there's enough time until Monday to learn it." It's
            Friday, the last day of my teaching career.
            </p>

            <p>
            Professor becomes my hero for a short time during a Department meeting. He
            insists that the design of high-voltage power lines is not actually a subject
            for his medical students. He wants more biology and medical related courses,
            instead. I truly believe in his vision. My mouth is wide open. But the Head
            again masterfully defends his position insisting on the necessity of assigning
            the minimum required number of hours per semester to each member of our
            Department, per the University guidelines. Nobody backs up my hero, not even
            he himself. The next topic on the agenda is the training of all our staff in
            the arts of digital blackboards "to help improve the teaching experience."
            </p>

            <p>
            I'm sinfully enjoying myself. What else do they do around here? Mrs. S. is our
            Department's team assistant. She's near retirement age and lives up in the
            attic. We visit her monthly to physically sign our presence in the attendance
            register. Sometimes she scolds us for signing in the wrong place, "That was a
            public holiday! You didn't work then, did you?!" There is no "Sir" nor
            "professor" with her. We are inhabiting a prestigious institution of higher
            learning, otherwise she would certainly call us morons. I'm wondering at the
            inefficiency on relying on handwritten notebooks for timekeeping. This
            Technical University has a Computer Science department, after all. But things
            are as they should be around here. There are many advantages to the analog
            methods. For instance, we avoid software bugs so this method is more precise,
            it fosters social interactions so it is more humane, we avoid proprietary
            software so users have complete control to modify the source code. We turn up
            once a month, sign and then we're free to do whatever. The Professor has given
            me the correct advice on that first day.
            </p>

            <p>
            The only constant human presence in the whole building during the warm summer
            days is the cleaning lady. I befriend her and we talk each morning. She
            provides me with paper towels and liquid soap for "When you might need it."
            Summer is vacation for both students and teachers, after all. From time to
            time I meet a stray professor in the hallways and they tell me I do a good
            job, always working, always studying, always present. Then, they excuses
            themselves with "I have to change my car's windshield" and other such
            important matters and then disappear for days or weeks on end.
            </p>

            <p>
            There's a big park with a lake nearby and a small river passes just behind the
            building. I often take small brakes from my academic life and stroll
            aimlessly. I sometimes watch the little fishes from the nearby bridge
            gathering in the shade of the willow trees. A kid approaches me one day, "Did
            you see the big one?" We chat a little. That's how I spend my
            days.
            </p>

            <p>
            With three months left, I send Professor my thesis. Days later, he warmly
            congratulates me, "You are an embarrassment to our city!" I stand
            alarmed. "Yes, you are ruining the prestige of our University!" I move closer.
            He points out a paragraph in my thesis where "almost impossible" is heavily
            underlined in red. "Something is either possible or impossible," he mocks me
            with a noticeable grin on his face. I update the offending sentence. I also
            fix a few typos in the following week and rephrase some paragraphs which were
            not to his liking. He eventually approves it. I present it in front of the
            whole Department, the last step before facing the official commission. It gets
            approved.
            </p>

            <p>
            My celebration is cut short a few days later. For some reason, it is of the
            utmost importance to have an actual, real-life experiment to confirm our
            theoretical results. "We can't present a theoretical thesis, we're a Technical
            University," Professor accuses me. I actually agree with him, though I have no
            soul left in this endeavor. How did he come up with this idea? I don't
            know. He probably got admonished by some higher-up. It was fine without it,
            the Department approved it, the Head approved it, it was ready for
            defending. Now it isn't. I shrug and accept it as another fact I can't
            understand nor influence.
            </p>

            <p>
            Professor finds a public institution to lend us their watermelon-sized
            anechoic chamber for two hours. We visit the supermarket one morning to buy
            pork chops for the human head. I want to bring to Professor's attention that
            we're studying a dynamic system and not dead meat. But it's autumn 2012
            already and the parks are in full color. It's way too late for any dialogue. I
            pull out a small plastic bag with a few miniature temperature sensors I bought
            the other day. Professor glues them to a metallic cylinder and inserts it in
            "the head." I see Professor was inspired by my way of handling the lack of
            real stents. I think it is a nail or wire of some sort but I'm not
            sure. Professor handles all the "sensitive equipment" himself. I take pictures
            and write down the results in a notebook. For the next two hours we gather
            temperature readings. I publish a paper with our findings shortly after,
            attach his name to it, update my thesis and everything is good again. I start
            to develop a faint feeling that I sleep better at night when I play along and
            nod approvingly to things I don't actually agree with instead of being
            pigheaded.
            </p>

            <p>
            The final day is approaching. Mrs. B., from the Department of Doctoral
            Studies, informs me that I personally have to prepare and bring in food,
            drinks and coffee for the commission when I defend my thesis. I refuse. She
            insists. I point out that the University charges ‚Ç¨1000 per student for the
            final show, that each member of the commission is actually getting paid for
            their trouble and that all these expenses plus transport and accommodation are
            already sponsored by our project. She shows signs of slowly winning back her
            memory. Mrs. B. also informs me that I won't be able to hold back my tears
            upon successfully defending my thesis in front of family, friends and
            colleagues. I successfully defend my thesis a few days later and I refuse her
            that pleasure, too.
            </p>

            <p>
            We celebrate at a local restaurant with the whole Department and the
            commission of five professors that evening. I join out from politeness. There
            is not much science to celebrate. After dinner I shake hands with Professor
            and the Head. "He did make a lot of noise around here but he did a great job
            and has very nice results," the Professor praises me in front of the Head. I
            smile without saying anything. I leave the place and begin to think about the
            years in front of me. But Professor catches up with me. He is a changed man,
            "Let's keep working together!" He is brimming with enthusiasm. I refuse him
            politely but he keeps talking as though my previous answer carries no weight
            with him, as he always does. "Yes, let's keep cooperating on new projects
            together," he goes on and on. I don't know what's gotten into him. Maybe he
            likes his name on new papers too much? He begins to get on my nerves. I answer
            respectfully with simple no's to all of his questions and proposals. I
            eventually say my goodbyes to him and turn my back. I leave Professor in the
            dark alley and my basement behind for good.
            </p>

            <p>
                ¬© Mihai Olteanu, 2025
            </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Congress passes Take It Down act despite major flaws (215 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</link>
            <guid>43828568</guid>
            <pubDate>Tue, 29 Apr 2025 03:57:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws">https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</a>, See on <a href="https://news.ycombinator.com/item?id=43828568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
        <div>
            <article role="article">
  
  
  <div><p>Today the U.S. House of Representatives passed the <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">TAKE IT DOWN</a> Act<span>, giving the powerful a dangerous new route to manipulate platforms&nbsp;into removing&nbsp;lawful&nbsp;speech that&nbsp;they&nbsp;simply don't like.&nbsp;President Trump himself has said that <a href="https://www.eff.org/deeplinks/2025/03/trump-calls-congress-pass-overbroad-take-it-down-act-so-he-can-use-it-censor">he would use</a> the law to censor his critics. The bill passed the Senate&nbsp;<a href="https://www.eff.org/deeplinks/2025/02/senate-passed-take-it-down-act-threatening-free-expression-and-due-process">in February</a>,&nbsp;and it now heads to the president's&nbsp;desk.&nbsp;</span></p>
<p><span>The takedown provision in TAKE IT DOWN applies to a much broader category of content‚Äîpotentially any images involving intimate or sexual content‚Äîthan the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Services will rely on automated filters, which are infamously blunt tools.&nbsp;They frequently flag legal content, from fair-use commentary to news reporting.&nbsp;The law‚Äôs tight time frame requires that apps and websites remove speech within 48 hours, rarely enough time to verify whether the speech is actually illegal. As a result, online service providers, particularly smaller ones, will likely choose to avoid the onerous legal risk by simply depublishing the speech rather than even attempting to verify it.<br></span></p>
<p>Congress is&nbsp;using the wrong approach to helping people whose intimate images are shared without their consent.&nbsp;TAKE IT DOWN pressures platforms to actively monitor speech, including speech that is presently encrypted. The law thus presents a huge threat to security and privacy online. While the bill is meant to address a serious problem, good intentions alone are not enough to make good policy.<span>&nbsp;</span>Lawmakers should be strengthening and enforcing existing legal protections for victims, rather than inventing new takedown regimes that are ripe for abuse.&nbsp;</p>

</div>

          </article>
    </div>
<div>
          <h2>Related Issues</h2>
            </div>

<div>
          <h2>Join EFF Lists</h2>
        
    </div>
<div>
          <h2>Related Updates</h2>
        <div>
        
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/texass-war-abortion-now-war-free-speech" rel="bookmark">Texas‚Äôs War on Abortion Is Now a War on Free Speech</a></h3>
            
    </header>
  
  
  <div><p><strong>Once again, the Texas legislature is coming after the most common method of safe and effective abortion today‚Äîmedication abortion.</strong><a href="https://capitol.texas.gov/tlodocs/89R/billtext/pdf/SB02880I.pdf#navpanes=0">Senate Bill (S.B.) 2880</a>* seeks to prevent the sale and distribution of abortion pills‚Äîbut it doesn‚Äôt stop there. By restricting access to certain information online, the bill tries to keep people...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/digital-identities-and-future-age-verification-europe" rel="bookmark">Digital Identities and the Future of Age Verification in Europe</a></h3>
            
    </header>
  
  
  <div><p><i>This is the first part of a three-part series about age verification in the European Union. In this blog post, we give an overview of the political debate around age verification and explore the age verification proposal introduced by the European Commission, based on digital identities. Part two takes a</i>...</p></div>

          </article>
  </div>
  
  
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-joins-7amleh-campaign-reconnectgaza" rel="bookmark">EFF Joins 7amleh Campaign to #ReconnectGaza</a></h3>
            
    </header>
  
  
  <div><p>In times of conflict, the internet becomes more than just a tool‚Äîit is a lifeline, connecting those caught in chaos with the outside world. It carries voices that might otherwise be silenced, bearing witness to suffering and survival. Without internet access, communities become isolated, and the flow of critical information...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-stands-perkins-coie-and-rule-law" rel="bookmark">EFF Stands with Perkins Coie and the Rule of Law </a></h3>
            
    </header>
  
  
  <div><p>As a legal organization that has fought in court to defend the rights of technology users for almost 35 years, including numerous legal challenges to federal government overreach, Electronic Frontier Foundation unequivocally supports Perkins Coie‚Äôs challenge to the Trump administration‚Äôs shocking, vindictive, and unconstitutional <a href="https://www.whitehouse.gov/presidential-actions/2025/03/addressing-risks-from-perkins-coie-llp/" target="_blank" rel="noopener noreferrer">Executive Order</a>....</p></div>

          </article>
  </div>
    </div>    </div>
      </div>

      <div><h2>Related Issues</h2></div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why did Windows 7 log on slower for months if you had a solid color background? (445 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</link>
            <guid>43827214</guid>
            <pubDate>Mon, 28 Apr 2025 23:27:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121">https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</a>, See on <a href="https://news.ycombinator.com/item?id=43827214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-111121">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>Personally, I use a solid color background. It was the default in Windows 95,¬π and I‚Äôve stuck with that bluish-green background color ever since. It‚Äôs sort of like my comfort food.</p>
<p>Imagine my surprise when someone pointed me to a support article titled ‚Äú<a title="The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2" href="https://support.microsoft.com/en-us/topic/the-welcome-screen-may-be-displayed-for-30-seconds-during-the-logon-process-after-you-set-a-solid-color-as-the-desktop-background-in-windows-7-or-in-windows-server-2008-r2-b4565ced-703a-cc85-bf9c-6b3d586d6421">The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2</a>.‚Äù Why is logon slower with a solid background?</p>
<p>After your logon has been authenticated, Windows sets up your desktop. There are a lot of things going on. The taskbar gets created. The components that are responsible for various system services are loaded and initialized. The desktop window is created and filled with icons. And the desktop background window loads up the desktop wallpaper and paints it to the screen.</p>
<p>The logon system waits for all of these pieces to report that they are ready, and when the all-clear signal is received from everybody, or when 30 seconds have elapsed, the logon system switches away from the Welcome screen.</p>
<p>Given that design, you can imagine the reason for the 30-second delay: It means that one of the pieces failed to report. Perhaps it was written like this:</p>
<pre>InitializeWallpaper()
{
    if (wallpaper bitmap defined)
    {
        LoadWallpaperBitmap();
    }
}

LoadWallpaperBitmap()
{
    locate the bitmap on disk
    load it into memory
    paint it on screen
    Report(WallpaperReady);
}
</pre>
<p>The code to report that the wallpaper is ready was inside the wallpaper bitmap code, which means that if you don‚Äôt have a wallpaper bitmap, the report is never made, and the logon system waits in vain for a report that will never arrive.</p>
<p>Later in the article, it notes a related article that calls out that if you have the ‚ÄúHide desktop icons‚Äù group policy enabled, then you might also suffer from the 30-second delay.</p>
<p>Group policies are susceptible to this problem because they tend to be bolted on after the main code is written. When you have to add a group policy, you find the code that does the thing, and you put a giant ‚Äúif policy allows‚Äù around it.</p>
<pre>// Original code
InitializeDesktopIcons()
{
    bind to the desktop folder
    enumerate the icons
    add them to the screen
    Report(DesktopIconsReady);
}

// Updated with group policy support

InitializeDesktopIcons()
{
    <span>if (desktop icons allowed by policy)</span>
    <span>{                                   </span>
        bind to the desktop folder
        enumerate the icons
        add them to the screen
        Report(DesktopIconsReady);
    <span>}                                   </span>
}
</pre>
<p>Oops, the scope of the ‚Äúif‚Äù block extended past the report call, so if the policy is enabled, the icons are never reported as ready, and the logon system stays on the Welcome screen for the full 30 seconds.</p>
<p>Note that in both of these cases, it‚Äôs not that the logon is extended by 30 seconds. Rather, the Welcome screen stays on for the full 30 seconds rather than the actual time it took for all systems to report ready (which could be 5 seconds, or it could be 25 seconds, depending on your system‚Äôs performance).</p>
<p>If you look at the timestamps on the articles, you can see that the problem was fixed in November 2009, just a few months after Windows 7 was released in July 2009.</p>
<p>¬π Originally, I avoided bitmap backgrounds because they took up a lot of memory, and when you had only 4 or 8 megabytes of memory, eating three quarters of a megabyte of memory just for wallpaper was not a good return on investment.</p>
<p>Also, I tend to stick with default configurations because it makes bug filing easier. If the repro instructions are ‚Äúinstall a system from scratch, then perform these steps‚Äù, you‚Äôre more likely to get traction than if you say ‚Äúinstall a system from scratch, change these 50 settings from their defaults, and then perform these additional steps.‚Äù It‚Äôs much easier to justify a bug fix that affects the default configuration than a bug fix that requires that the user have changed settings from the default, particularly if those settings are obscure.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 12-bit rainbow palette (302 pts)]]></title>
            <link>https://iamkate.com/data/12-bit-rainbow/</link>
            <guid>43827108</guid>
            <pubDate>Mon, 28 Apr 2025 23:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamkate.com/data/12-bit-rainbow/">https://iamkate.com/data/12-bit-rainbow/</a>, See on <a href="https://news.ycombinator.com/item?id=43827108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>
        I designed the 12-bit rainbow palette for use on <a href="https://grid.iamkate.com/">National Grid: Live</a>. It consists of twelve colours chosen with consideration for how we perceive luminance, chroma, and hue:
      </p>
      <figure>
        <svg viewBox="0 0 480 40" width="480" height="40">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The palette uses a 12-bit colour depth, so each colour requires only four characters when specified as a hexadecimal colour code in a <abbr>CSS</abbr> or <abbr>SVG</abbr> file:
      </p>
      <div id="palette">
        <p><span>#817</span></p>
        <p><span>#a35</span></p>
        <p><span>#c66</span></p>
        <p><span>#e94</span></p>
        <p><span>#ed0</span></p>
        <p><span>#9d5</span></p>
        <p><span>#4d8</span></p>
        <p><span>#2cb</span></p>
        <p><span>#0bc</span></p>
        <p><span>#09c</span></p>
        <p><span>#36b</span></p>
        <p><span>#639</span></p>
      </div>
      <h2>
        Designing the palette
      </h2>
      <p>
        Computers define colours in terms of red, green, and blue components, which are treated equally. However, we perceive these components as having differing luminance: compared to a pure red, a pure green looks much brighter and a pure blue looks much darker. As a result, a simple <abbr>RGB</abbr> rainbow palette has large changes in luminance between neighbouring colours. This can be seen by converting colours to greys of equal perceived luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#ff00ff" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#ff0080" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#ff0000" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#ff8000" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ffff00" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#80ff00" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#00ff00" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#00ff80" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#00ffff" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#0080ff" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#0000ff" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#8000ff" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#696969" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5b5b5b" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#4c4c4c" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#e2e2e2" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#bcbcbc" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#969696" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#a4a4a4" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#b3b3b3" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#686868" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#1d1d1d" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#434343" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The <abbr>LCH</abbr> colour space is an alternative to the <abbr>RGB</abbr> colour space that defines colours in terms of luminance, chroma, and hue components. These components are perceptually uniform, which means that a change by a particular numerical amount will be perceived similarly for any colour.
      </p>
      <p>
        An <abbr>LCH</abbr> rainbow colour palette can be created by choosing fixed chroma and luminance values and varying the hue. However, the resulting palette looks unpleasant because yellow is darkened to brown, red is lightened to pink, and blue becomes very pale.
      </p>
      <p>
        A better approach is to allow the luminance to vary, but in a controlled way. Yellow is given the highest luminance, as it only looks yellow when bright. After choosing two other colours ‚Äî a red and a blue in this case ‚Äî the luminance can then be calculated for the other hues.
      </p>
      <p>
        Using a 12-bit colour depth limits the available colours, so slight changes to luminance, chroma, and hue must be made, but these are small enough not to be noticeable. The resulting palette has evenly-spaced hues, only small variations in chroma, and smoothly increasing and decreasing luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#404040" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5c5c5c" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#848484" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#a9a9a9" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#c9c9c9" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#b9b9b9" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#a6a6a6" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#858585" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#717171" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#606060" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#4e4e4e" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The One-Person Framework in Practice (323 pts)]]></title>
            <link>https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</link>
            <guid>43826584</guid>
            <pubDate>Mon, 28 Apr 2025 21:58:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o">https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</a>, See on <a href="https://news.ycombinator.com/item?id=43826584">Hacker News</a></p>
Couldn't get https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3: Think deeper, act faster (780 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen3/</link>
            <guid>43825900</guid>
            <pubDate>Mon, 28 Apr 2025 20:44:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen3/">https://qwenlm.github.io/blog/qwen3/</a>, See on <a href="https://news.ycombinator.com/item?id=43825900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-banner.png" alt="Qwen3 Main Image" width="100%"></figure><p><a href="https://chat.qwen.ai/" target="_blank">QWEN CHAT</a>
<a href="https://github.com/QwenLM/Qwen3" target="_blank">GitHub</a>
<a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f" target="_blank">Hugging Face</a>
<a href="https://modelscope.cn/collections/Qwen3-9743180bdc6b48" target="_blank">ModelScope</a>
<a href="https://www.kaggle.com/models/qwen-lm/qwen-3" target="_blank">Kaggle</a>
<a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo" target="_blank">DEMO</a>
<a href="https://discord.gg/yPEP2vHTu4" target="_blank">DISCORD</a></p><h2 id="introduction">Introduction</h2><p>Today, we are excited to announce the release of <strong>Qwen3</strong>, the latest addition to the Qwen family of large language models. Our flagship model, <strong>Qwen3-235B-A22B</strong>, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, <strong>Qwen3-30B-A3B</strong>, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.</p><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg" width="100%"></figure><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg" width="100%"></figure><p>We are open-weighting two MoE models: <strong>Qwen3-235B-A22B</strong>, a large model with 235 billion total parameters and 22 billion activated parameters, and <strong>Qwen3-30B-A3B</strong>, a smaller MoE model with 30 billion total parameters and 3 billion activated parameters. Additionally, six dense models are also open-weighted, including <strong>Qwen3-32B</strong>, <strong>Qwen3-14B</strong>, <strong>Qwen3-8B</strong>, <strong>Qwen3-4B</strong>, <strong>Qwen3-1.7B</strong>, and <strong>Qwen3-0.6B</strong>, under Apache 2.0 license.</p><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th>Tie Embedding</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-0.6B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-1.7B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-4B</td><td>36</td><td>32 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-8B</td><td>36</td><td>32 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-14B</td><td>40</td><td>40 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-32B</td><td>64</td><td>64 / 8</td><td>No</td><td>128K</td></tr></tbody></table><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th># Experts (Total / Activated)</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-30B-A3B</td><td>48</td><td>32 / 4</td><td>128 / 8</td><td>128K</td></tr><tr><td>Qwen3-235B-A22B</td><td>94</td><td>64 / 4</td><td>128 / 8</td><td>128K</td></tr></tbody></table><p>The post-trained models, such as <strong>Qwen3-30B-A3B</strong>, along with their pre-trained counterparts (e.g., <strong>Qwen3-30B-A3B-Base</strong>), are now available on platforms like <strong>Hugging Face</strong>, <strong>ModelScope</strong>, and <strong>Kaggle</strong>. For deployment, we recommend using frameworks like <strong>SGLang</strong> and <strong>vLLM</strong>. For local usage, tools such as <strong>Ollama</strong>, <strong>LMStudio</strong>, <strong>MLX</strong>, <strong>llama.cpp</strong>, and <strong>KTransformers</strong> are highly recommended. These options ensure that users can easily integrate Qwen3 into their workflows, whether in research, development, or production environments.</p><p>We believe that the release and open-sourcing of Qwen3 will significantly advance the research and development of large foundation models. Our goal is to empower researchers, developers, and organizations around the world to build innovative solutions using these cutting-edge models.</p><p>Feel free to try Qwen3 out in Qwen Chat Web (<a href="https://chat.qwen.ai/">chat.qwen.ai</a>) and mobile APP!</p><h2 id="key-features">Key Features</h2><ul><li><strong>Hybrid Thinking Modes</strong></li></ul><p>Qwen3 models introduce a hybrid approach to problem-solving. They support two modes:</p><ol><li>Thinking Mode: In this mode, the model takes time to reason step by step before delivering the final answer. This is ideal for complex problems that require deeper thought.</li><li>Non-Thinking Mode: Here, the model provides quick, near-instant responses, suitable for simpler questions where speed is more important than depth.</li></ol><p>This flexibility allows users to control how much ‚Äúthinking‚Äù the model performs based on the task at hand. For example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without delay. Crucially, the integration of these two modes greatly enhances the model‚Äôs ability to implement stable and efficient thinking budget control. As demonstrated above, Qwen3 exhibits scalable and smooth performance improvements that are directly correlated with the computational reasoning budget allocated. This design enables users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost efficiency and inference quality.</p><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/thinking_budget.png" width="100%"></figure><ul><li><strong>Multilingual Support</strong></li></ul><p>Qwen3 models are supporting <strong>119 languages and dialects</strong>. This extensive multilingual capability opens up new possibilities for international applications, enabling users worldwide to benefit from the power of these models.</p><table><thead><tr><th>Language Family</th><th>Languages &amp; Dialects</th></tr></thead><tbody><tr><td>Indo-European</td><td>English, French, Portuguese, German, Romanian, Swedish, Danish, Bulgarian, Russian, Czech, Greek, Ukrainian, Spanish, Dutch, Slovak, Croatian, Polish, Lithuanian, Norwegian Bokm√•l, Norwegian Nynorsk, Persian, Slovenian, Gujarati, Latvian, Italian, Occitan, Nepali, Marathi, Belarusian, Serbian, Luxembourgish, Venetian, Assamese, Welsh, Silesian, Asturian, Chhattisgarhi, Awadhi, Maithili, Bhojpuri, Sindhi, Irish, Faroese, Hindi, Punjabi, Bengali, Oriya, Tajik, Eastern Yiddish, Lombard, Ligurian, Sicilian, Friulian, Sardinian, Galician, Catalan, Icelandic, Tosk Albanian, Limburgish, Dari, Afrikaans, Macedonian, Sinhala, Urdu, Magahi, Bosnian, Armenian</td></tr><tr><td>Sino-Tibetan</td><td>Chinese (Simplified Chinese, Traditional Chinese, Cantonese), Burmese</td></tr><tr><td>Afro-Asiatic</td><td>Arabic (Standard, Najdi, Levantine, Egyptian, Moroccan, Mesopotamian, Ta‚Äôizzi-Adeni, Tunisian), Hebrew, Maltese</td></tr><tr><td>Austronesian</td><td>Indonesian, Malay, Tagalog, Cebuano, Javanese, Sundanese, Minangkabau, Balinese, Banjar, Pangasinan, Iloko, Waray (Philippines)</td></tr><tr><td>Dravidian</td><td>Tamil, Telugu, Kannada, Malayalam</td></tr><tr><td>Turkic</td><td>Turkish, North Azerbaijani, Northern Uzbek, Kazakh, Bashkir, Tatar</td></tr><tr><td>Tai-Kadai</td><td>Thai, Lao</td></tr><tr><td>Uralic</td><td>Finnish, Estonian, Hungarian</td></tr><tr><td>Austroasiatic</td><td>Vietnamese, Khmer</td></tr><tr><td>Other</td><td>Japanese, Korean, Georgian, Basque, Haitian, Papiamento, Kabuverdianu, Tok Pisin, Swahili</td></tr></tbody></table><ul><li><strong>Improved Agentic Capabilities</strong></li></ul><p>We have optimized the Qwen3 models for coding and agentic capabilities, and also we have strengthened the support of MCP as well. Below we provide examples to show how Qwen3 thinks and interacts with the environment.</p><h2 id="pre-training">Pre-training</h2><p>In terms of pretraining, the dataset for Qwen3 has been significantly expanded compared to Qwen2.5. While Qwen2.5 was pre-trained on 18 trillion tokens, Qwen3 uses nearly twice that amount, with approximately 36 trillion tokens covering 119 languages and dialects. To build this large dataset, we collected data not only from the web but also from PDF-like documents. We used Qwen2.5-VL to extract text from these documents and Qwen2.5 to improve the quality of the extracted content. To increase the amount of math and code data, we used Qwen2.5-Math and Qwen2.5-Coder to generate synthetic data. This includes textbooks, question-answer pairs, and code snippets.</p><p>The pre-training process consists of three stages. In the first stage (S1), the model was pretrained on over 30 trillion tokens with a context length of 4K tokens. This stage provided the model with basic language skills and general knowledge. In the second stage (S2), we improved the dataset by increasing the proportion of knowledge-intensive data, such as STEM, coding, and reasoning tasks. The model was then pretrained on an additional 5 trillion tokens. In the final stage, we used high-quality long-context data to extend the context length to 32K tokens. This ensures the model can handle longer inputs effectively.</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-base.jpg" width="100%"></figure><p>Due to advancements in model architecture, increase in training data, and more effective training methods, the overall performance of Qwen3 dense base models matches that of Qwen2.5 base models with more parameters. For instance, Qwen3-1.7B/4B/8B/14B/32B-Base performs as well as Qwen2.5-3B/7B/14B/32B/72B-Base, respectively. Notably, in areas like STEM, coding, and reasoning, Qwen3 dense base models even outperform larger Qwen2.5 models. For Qwen3-MoE base models, they achieve similar performance to Qwen2.5 dense base models while using only 10% of the active parameters. This results in significant savings in both training and inference costs.</p><h2 id="post-training">Post-training</h2><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png" width="100%"></figure><p>To develop the hybrid model capable of both step-by-step reasoning and rapid responses, we implemented a four-stage training pipeline. This pipeline includes: (1) long chain-of-thought (CoT) cold start, (2) reasoning-based reinforcement learning (RL), (3) thinking mode fusion, and (4) general RL.</p><p>In the first stage, we fine-tuned the models using diverse long CoT data, covering various tasks and domains such as mathematics, coding, logical reasoning, and STEM problems. This process aimed to equip the model with fundamental reasoning abilities. The second stage focused on scaling up computational resources for RL, utilizing rule-based rewards to enhance the model‚Äôs exploration and exploitation capabilities.</p><p>In the third stage, we integrated non-thinking capabilities into the thinking model by fine-tuning it on a combination of long CoT data and commonly used instruction-tuning data. This data was generated by the enhanced thinking model from the second stage, ensuring a seamless blend of reasoning and quick response capabilities. Finally, in the fourth stage, we applied RL across more than 20 general-domain tasks to further strengthen the model‚Äôs general capabilities and correct undesired behaviors. These tasks included instruction following, format following, and agent capabilities, etc.</p><h2 id="develop-with-qwen3">Develop with Qwen3</h2><p>Below is a simple guide for you to use Qwen3 on different frameworks. First of all, we provide an standard example of using Qwen3-30B-A3B in Hugging Face transformers:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>modelscope</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>model_name</span> <span>=</span> <span>"Qwen/Qwen3-30B-A3B"</span>
</span></span><span><span>
</span></span><span><span><span># load the tokenizer and the model</span>
</span></span><span><span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span>
</span></span><span><span>    <span>model_name</span><span>,</span>
</span></span><span><span>    <span>torch_dtype</span><span>=</span><span>"auto"</span><span>,</span>
</span></span><span><span>    <span>device_map</span><span>=</span><span>"auto"</span>
</span></span><span><span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># prepare the model input</span>
</span></span><span><span><span>prompt</span> <span>=</span> <span>"Give me a short introduction to large language model."</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>prompt</span><span>}</span>
</span></span><span><span><span>]</span>
</span></span><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>True</span> <span># Switch between thinking and non-thinking modes. Default is True.</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>model_inputs</span> <span>=</span> <span>tokenizer</span><span>([</span><span>text</span><span>],</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span><span>.</span><span>to</span><span>(</span><span>model</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># conduct text completion</span>
</span></span><span><span><span>generated_ids</span> <span>=</span> <span>model</span><span>.</span><span>generate</span><span>(</span>
</span></span><span><span>    <span>**</span><span>model_inputs</span><span>,</span>
</span></span><span><span>    <span>max_new_tokens</span><span>=</span><span>32768</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>output_ids</span> <span>=</span> <span>generated_ids</span><span>[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>model_inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span> 
</span></span><span><span>
</span></span><span><span><span># parsing thinking content</span>
</span></span><span><span><span>try</span><span>:</span>
</span></span><span><span>    <span># rindex finding 151668 (&lt;/think&gt;)</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>len</span><span>(</span><span>output_ids</span><span>)</span> <span>-</span> <span>output_ids</span><span>[::</span><span>-</span><span>1</span><span>]</span><span>.</span><span>index</span><span>(</span><span>151668</span><span>)</span>
</span></span><span><span><span>except</span> <span>ValueError</span><span>:</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span><span>thinking_content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[:</span><span>index</span><span>],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span><span>content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[</span><span>index</span><span>:],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>print</span><span>(</span><span>"thinking content:"</span><span>,</span> <span>thinking_content</span><span>)</span>
</span></span><span><span><span>print</span><span>(</span><span>"content:"</span><span>,</span> <span>content</span><span>)</span>
</span></span></code></pre></div><p>To disable thinking, you just need to make changes to the argument <code>enable_thinking</code> like the following:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>False</span>  <span># True is the default value for enable_thinking.</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><p>For deployment, you can use <code>sglang&gt;=0.4.6.post1</code> or <code>vllm&gt;=0.8.4</code> to create an OpenAI-compatible API endpoint:</p><ul><li><p>SGLang:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3
</span></span></code></pre></div></li><li><p>vLLM:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1
</span></span></code></pre></div></li></ul><p>If you use it for local development, you can use ollama by running a simple command <code>ollama run qwen3:30b-a3b</code> to play with the model, or you can use LMStudio or llama.cpp and ktransformers to build locally.</p><h3 id="advanced-usages">Advanced Usages</h3><p>We provide a soft switch mechanism that allows users to dynamically control the model‚Äôs behavior when enable_thinking=True. Specifically, you can add /think and /no_think to user prompts or system messages to switch the model‚Äôs thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.</p><p>Here is an example of a multi-turn conversation:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>QwenChatbot</span><span>:</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>model_name</span><span>=</span><span>"Qwen/Qwen3-30B-A3B"</span><span>):</span>
</span></span><span><span>        <span>self</span><span>.</span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span> <span>=</span> <span>[]</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>generate_response</span><span>(</span><span>self</span><span>,</span> <span>user_input</span><span>):</span>
</span></span><span><span>        <span>messages</span> <span>=</span> <span>self</span><span>.</span><span>history</span> <span>+</span> <span>[{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>}]</span>
</span></span><span><span>
</span></span><span><span>        <span>text</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>            <span>messages</span><span>,</span>
</span></span><span><span>            <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>            <span>add_generation_prompt</span><span>=</span><span>True</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>inputs</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>(</span><span>text</span><span>,</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span>
</span></span><span><span>        <span>response_ids</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>generate</span><span>(</span><span>**</span><span>inputs</span><span>,</span> <span>max_new_tokens</span><span>=</span><span>32768</span><span>)[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span>
</span></span><span><span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>response_ids</span><span>,</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># Update history</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>})</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>})</span>
</span></span><span><span>
</span></span><span><span>        <span>return</span> <span>response</span>
</span></span><span><span>
</span></span><span><span><span># Example Usage</span>
</span></span><span><span><span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
</span></span><span><span>    <span>chatbot</span> <span>=</span> <span>QwenChatbot</span><span>()</span>
</span></span><span><span>
</span></span><span><span>    <span># First input (without /think or /no_think tags, thinking mode is enabled by default)</span>
</span></span><span><span>    <span>user_input_1</span> <span>=</span> <span>"How many r's in strawberries?"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_1</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_1</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Second input with /no_think</span>
</span></span><span><span>    <span>user_input_2</span> <span>=</span> <span>"Then, how many r's in blueberries? /no_think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_2</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_2</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_2</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_2</span><span>}</span><span>"</span><span>)</span> 
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Third input with /think</span>
</span></span><span><span>    <span>user_input_3</span> <span>=</span> <span>"Really? /think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_3</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_3</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_3</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_3</span><span>}</span><span>"</span><span>)</span>
</span></span></code></pre></div><h3 id="agentic-usages">Agentic Usages</h3><p>Qwen3 excels in tool calling capabilities. We recommend using <a href="https://github.com/QwenLM/Qwen-Agent">Qwen-Agent</a> to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.</p><p>To define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>qwen_agent.agents</span> <span>import</span> <span>Assistant</span>
</span></span><span><span>
</span></span><span><span><span># Define LLM</span>
</span></span><span><span><span>llm_cfg</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>'model'</span><span>:</span> <span>'Qwen3-30B-A3B'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Use the endpoint provided by Alibaba Model Studio:</span>
</span></span><span><span>    <span># 'model_type': 'qwen_dashscope',</span>
</span></span><span><span>    <span># 'api_key': os.getenv('DASHSCOPE_API_KEY'),</span>
</span></span><span><span>
</span></span><span><span>    <span># Use a custom endpoint compatible with OpenAI API:</span>
</span></span><span><span>    <span>'model_server'</span><span>:</span> <span>'http://localhost:8000/v1'</span><span>,</span>  <span># api_base</span>
</span></span><span><span>    <span>'api_key'</span><span>:</span> <span>'EMPTY'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Other parameters:</span>
</span></span><span><span>    <span># 'generate_cfg': {</span>
</span></span><span><span>    <span>#         # Add: When the response content is `&lt;think&gt;this is the thought&lt;/think&gt;this is the answer;</span>
</span></span><span><span>    <span>#         # Do not add: When the response has been separated by reasoning_content and content.</span>
</span></span><span><span>    <span>#         'thought_in_content': True,</span>
</span></span><span><span>    <span>#     },</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span># Define Tools</span>
</span></span><span><span><span>tools</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>'mcpServers'</span><span>:</span> <span>{</span>  <span># You can specify the MCP configuration file</span>
</span></span><span><span>            <span>'time'</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>'command'</span><span>:</span> <span>'uvx'</span><span>,</span>
</span></span><span><span>                <span>'args'</span><span>:</span> <span>[</span><span>'mcp-server-time'</span><span>,</span> <span>'--local-timezone=Asia/Shanghai'</span><span>]</span>
</span></span><span><span>            <span>},</span>
</span></span><span><span>            <span>"fetch"</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>"command"</span><span>:</span> <span>"uvx"</span><span>,</span>
</span></span><span><span>                <span>"args"</span><span>:</span> <span>[</span><span>"mcp-server-fetch"</span><span>]</span>
</span></span><span><span>            <span>}</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>  <span>'code_interpreter'</span><span>,</span>  <span># Built-in tools</span>
</span></span><span><span><span>]</span>
</span></span><span><span>
</span></span><span><span><span># Define Agent</span>
</span></span><span><span><span>bot</span> <span>=</span> <span>Assistant</span><span>(</span><span>llm</span><span>=</span><span>llm_cfg</span><span>,</span> <span>function_list</span><span>=</span><span>tools</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># Streaming generation</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[{</span><span>'role'</span><span>:</span> <span>'user'</span><span>,</span> <span>'content'</span><span>:</span> <span>'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'</span><span>}]</span>
</span></span><span><span><span>for</span> <span>responses</span> <span>in</span> <span>bot</span><span>.</span><span>run</span><span>(</span><span>messages</span><span>=</span><span>messages</span><span>):</span>
</span></span><span><span>    <span>pass</span>
</span></span><span><span><span>print</span><span>(</span><span>responses</span><span>)</span>
</span></span></code></pre></div><h2 id="friends-of-qwen">Friends of Qwen</h2><p>Thanks to the support of so many friends. Qwen is nothing without its friends! We welcome more people or organizations to join our community and help us become better!</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-logo.png" width="100%"></figure><h2 id="future-work">Future Work</h2><p>Qwen3 represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages, enhancing global accessibility.</p><p>Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures and training methodologies to achieve several key objectives: scaling data, increasing model size, extending context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We believe we are transitioning from an era focused on training models to one centered on training agents. Our next iteration promises to bring meaningful advancements to everyone‚Äôs work and life.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Million Chessboards (297 pts)]]></title>
            <link>https://eieio.games/blog/one-million-chessboards/</link>
            <guid>43825336</guid>
            <pubDate>Mon, 28 Apr 2025 19:52:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eieio.games/blog/one-million-chessboards/">https://eieio.games/blog/one-million-chessboards/</a>, See on <a href="https://news.ycombinator.com/item?id=43825336">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><a href="https://eieio.games/blog/one-million-chessboards/"></a><div><p>a million chessboards that anyone can play on</p><p>Apr 28, 2025</p></div></div>
<p>I made a website. It‚Äôs called <a href="https://onemillionchessboards.com/">One Million Chessboards</a>. It has one million chessboards on it.</p>
<p>Moving a piece moves it for everyone, instantly. There are no turns. You can move between boards.</p>
<div><video controls="" playsinline="" poster="https://eieio.games/images/one-million-chessboards/gameplay-firstframe.png" width="2136" height="1708" preload="metadata" alt="Gameplay from One Million Chessboards. The player moves a queen around on a grid of a million boards as pieces move around him."><p>Loading...</p></video><p>moving some pieces</p></div>
<!-- -->
<h2 id="toc:what">What</h2>
<p>Well last year I made this game called <a href="https://eieio.games/blog/one-million-checkboxes">One Million Checkboxes</a>.</p>
<p>It was a pretty fun time! So I thought I‚Äôd do something like this again.</p>
<p>I worked really hard on this one. I hope you like it.</p>
<h2 id="toc:how">How</h2>
<p>This was the most technically challenging thing that I‚Äôve worked on in a long time. I‚Äôm going to save a full technical writeup until I see how my decisions pan out, since I think there‚Äôs a decent chance I‚Äôll need to make a lot of changes.</p>
<p>But I‚Äôll summarize a few things for you.</p>
<ul>
<li>Unlike One Million Checkboxes, I designed this for scale</li>
<li>The game runs on a single server (!)</li>
<li>The board is stored fully in-memory; it‚Äôs a 2D array of 64 million uint64s</li>
<li>The backend is written in go. This is my first go project.</li>
<li>I use a single writer thread, tons of reader threads, and coordinate access to the board with a mutex</li>
<li>The frontend optimistically applies all moves you make immediately. It then builds up a dependency graph of the moves you‚Äôve made, and backs them out if it receives a conflicting update before the server acks your move.</li>
<li>The server ships zstd-compressed protobufs to the clients over websockets for state snapshots (approximately a 100x100 square around the client), move and capture updates, and acks/rejections for moves</li>
<li>Clients are grouped into 50x50 ‚Äúzones‚Äù and only receive moves for zones adjacent to their current zone</li>
<li>Clients fetch global data (game stats, the minimap, etc) by polling via GET; data is cached in Cloudflare with a low TTL so this is much cheaper than shipping it over every websocket</li>
</ul>
<p>That last part - optimistic move application with what games people sometimes call ‚Äúrollback‚Äù - is about 1,600 lines of code that took me a ~7 days of fulltime work to write. I don‚Äôt remember the last time I wrestled with a problem that hard!</p>
<p>As of 8 PM, 8 hours after launch, players have made about 1.3 million moves and there are about 400 concurrent users most of the time. Load on my server is neglibible!</p>
<h2 id="toc:can-i-play">Can I play</h2>
<p>Yes! <a href="https://onemillionchessboards.com/">Play it here</a>.</p>
<p>I really hope you like this one. More updates to come :)</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Migrating Away from Rust (660 pts)]]></title>
            <link>https://deadmoney.gg/news/articles/migrating-away-from-rust</link>
            <guid>43824640</guid>
            <pubDate>Mon, 28 Apr 2025 18:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deadmoney.gg/news/articles/migrating-away-from-rust">https://deadmoney.gg/news/articles/migrating-away-from-rust</a>, See on <a href="https://news.ycombinator.com/item?id=43824640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When I started building <strong>Architect of Ruin </strong>in December 2023 I chose to build it in the <a href="https://bevyengine.org/" target="_blank">Bevy</a>&nbsp;game engine. My choice was motivated by a personal interest in <a href="https://www.rust-lang.org/" target="_blank">Rust</a>&nbsp;-- a language I derive a lot of joy in using. This was furthered by <a href="https://bevyengine.org/learn/quick-start/getting-started/ecs/" target="_blank">Bevy's ECS</a> model which I also find fun to work with and the openness of Bevy's community which I have a genuine appreciation for.</p><center><iframe width="500" height="282" src="https://www.youtube.com/embed/vCEbQXeGc3U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Bevy Rap by Tantan"></iframe></center><p>So, it came as a surprise that in&nbsp;January of 2025 we transitioned the game away from Rust and Bevy. I spent about six weeks rewriting the game entirely in C# and we have been using Unity for the past three months.</p><p>Switching engines is a classic project killer. Productivity can nosedive, regressions inevitably emerge, and every step forward seems to lead to three steps back. Not to mention that domain expertise built up in one language and engine doesn't cleanly transfer to a new language and engine.</p><p>But I bit the bullet and I want to explain why.</p><h3>The Bevy Journey</h3><p>A lot of good work was accomplished in Bevy. The tilemap, most of my approach to composing the scene, and a large amount of character and gameplay logic were implemented in Bevy. I learned about the guts of Spine and skeletal animation by tearing apart Rust <a href="https://github.com/jabuwu/rusty_spine" target="_blank">transpiles</a>&nbsp;of the spine runtime. I learned a lot about custom render pipelines by implementing my own rendering features in Bevy's render world. Bevy's pure ECS was a joy to work with and Rust's compile-time checks meant I could refactor large swathes of code quickly and with confidence.</p><p>The Bevy community was also an active source of inspiration - not just ideas about how to use the engine, but a positive community of builders and contributors. This community is very good at being excited about game development and being energetic about debate.</p><p>I had the opportunity to contribute features and fixes to a number of community crates, although most of those contributions were small and were focused on work that moved my own goals forward.</p><p>Despite these positive experiences and the progress made, practical challenges emerged as development continued.</p><h3>Emergent Problems</h3><p>I want to begin by stating that I anticipated many of these challenges before they manifested. I knew that using a game engine early in its development lifecycle would pose unique risks and costs. I considered those costs to be likely worthwhile and surmountable. My love of Rust and Bevy meant that I would be willing to bear some pain that other game developers might choose to avoid. I didn't walk blindly into these specific problems, but they bit harder than I was expecting.</p><p><strong>Collaboration </strong>- I started this project with my brother. While he's sharp and eager, he's new to coding. Onboarding him directly into game dev while simultaneously navigating Rust's unique aspects proved challenging. We found ourselves with a steeper learning curve that slowed his ability to contribute effectively to gameplay logic.</p><center></center><p><strong>Abstraction</strong> - While my initial motivation was the enjoyment of Rust, the project's bottleneck increasingly became the rapid iteration of higher-level gameplay mechanics. As the codebase grew, we found that translating gameplay ideas into code was less direct than we hoped. Rust's (powerful) low-level focus didn't always lend itself to a flexible high-level scripting style needed for rapid prototyping within our specific gameplay architecture. I found that my motivation to build and ship fun gameplay was stronger than my desire to build with Rust.</p><p>I had anticipated that this was going to be a thing, but I wasn't calibrated to the degree it would start to annoy me and slow the project down.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/bevyskeleverbose.png" alt="Rust can be verbose."></p><center><em>(A relatively simple gameplay function signature.)</em></center><center><em></em></center><center><em></em></center><p><strong>Migration&nbsp;</strong>- Bevy is young and changes quickly. Each update brought with it incredible features, but also a substantial amount of API thrash. As the project grew in size, the burden of update migration also grew. Minor regressions were common in core Bevy systems (such as sprite rendering), and these led to moments of significant friction and unexpected debugging effort.</p><p>This came to a head on one specific day where I was frustrated with a sprite rendering issue that had emerged in a new release. Blake had run into the same problem at the same time and our shared frustration boiled over into a kind of table flip moment. He turned to me and said something along the lines of "this shouldn't happen, this kind of thing should just be solved" and that triggered the conversation that led to a re-evaluation.</p><p>The point isn't that specific sprite problem, but that because all systems in Bevy are open to tinkering and improvement, all systems were potentially subject to regressions.</p><p><strong>Learning </strong>- Over the past year my workflow has changed immensely, and I regularly use AI to learn new technologies, discuss methods and techniques, review code, etc. The maturity and vast amount of stable historical data for C# and the Unity API mean that tools like Gemini consistently provide highly relevant guidance. While Bevy and Rust evolve rapidly - which is exciting and motivating - the pace means AI knowledge lags behind, reducing the efficiency gains I have come to expect from AI assisted development. This could change with the introduction of more modern tool-enabled models, but I found it to be a distraction and an unexpected additional cost.</p><p><strong>Modding </strong>- Modding means a lot to me. <a href="https://web.archive.org/web/20160306093336/http://orangesmoothie.org/" target="_blank">I got my start in the industry as a modder</a>&nbsp;and I want my game to be highly moddable. Over time, as I learned more about how to realize this goal, I came to understand many inherent limitations in Rust and Bevy that would make the task more difficult. Lack of a clear solution to scripting and an unstable ABI (application binary interface) raised concerns. I am not an expert in this area, perhaps these are all easily surmounted. I can only say that I did not find a path (after much searching) that I felt confident trusting.</p><p>These factors combined - the desire for a smoother workflow across experience levels, the need for a high-level abstraction for gameplay, optimizing productivity, and modding - pointed towards a re-evaluation of the project's next phase.</p><h3>The Switch</h3><p>To be honest, I completely disregarded Unity when I started the project.</p><p>Some of this stemmed from unforced errors on the part of Unity. They had just gone through a crisis of pricing that culminated in the resignation of their CEO and they seemed out of touch with indie developers.&nbsp;I also made several assumptions. I felt sick of coding in the outdated form of C++ that pervades older game engines and assumed I'd feel similarly about C#. I figured that since Unreal doesn't offer much for 2D render pipelines that Unity wouldn't either. This led me to fail to give serious thought to using Unity in 2023.</p><p>In the first week of January of 2025, Blake and I decided to do a cost-benefit analysis. We wrote down all the options: Unreal, Unity, Godot, continuing in Bevy, or rolling our own. We wrote extensive pros and cons, emphasizing how each option fared by the criteria above: Collaboration, Abstraction, Migration, Learning, and Modding.</p><p>Having some experience with the other options, I decided I needed to understand Unity better. An afternoon's research led me to conclude that it seemed to score high on the pros over the cons.</p><p>We had a team meeting where I laid out the trade-offs. Ulrick pointed out that a bunch of unknowns, like particles, would just be solved in a packaged engine. Blake pointed out that if things went well, and a new engine meant faster gameplay development, we could end up ahead of schedule.</p><h3>10% for 90%</h3><p>The team decided to invest in an experiment. I would pick three core features and see how difficult they would be to implement in Unity. We would spend no more than 3 weeks on the task.  We would invest 10% of effort to see if we should invest the other 90% in a full port.</p><p><strong>Tilemap</strong> - I figured this one would be straightforward, since the basic logic is simple. It would require implementing custom shaders. We wouldn't be using the built in Unity Tilemap because our needs were specific and well-known to us. This was foundational to the game scene and I had a good mental model for how long it took me to write the first time in Rust.</p><p><strong>Characters </strong>- Our characters use Spine and have unique customization requirements and features. This gave me a lot of trouble in Rust, so I figured it would be a good point of comparison in C#.</p><p><strong>UI</strong> - I wanted UI to be easy to build, fast to iterate, and moddable. This was an area where we learned a lot in Rust and again had a good mental model for comparison. Some research led me to conclude that <a href="https://www.noesisengine.com/" target="_blank">Noesis</a>&nbsp;would be a good fit because of its emphasis on data-driven XAML and the fact that the WPF model is very well documented. Even if I didn't know WPF, I knew I could learn it quickly with AI assistance.</p><p>The first two tasks: Tilemap and Characters, were chosen because they were fundamental, but also because let me check my time-expectations against reality on an easy task and a hard task. This would allow me to project the workload of future tasks and the port more broadly. The UI task was chosen because our game is UI heavy and any significant speed improvement in iterating on UI would have compounding returns on future development.</p><p>We finished all three tasks in 3 days!</p><p>Commit 1 was on Jan 8th and the Tilemap was done the same day.&nbsp;</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/tasklog1.png" alt=""></p><p>While I implemented the tilemap, Blake wrote the camera system. This demonstrated a significant boost in his ability to contribute when the technical framework was more scrutable. It was also a huge boost to his confidence and contributed to a new feeling of momentum. I should point out that Blake had never written C# before.</p><p>I implemented the Tilemap shader in Unity Shader Graph, thinking this would be easier for Ulrick to play with. This wasn't the last Shader Graph I wrote, but ultimately, I decided that visual shader creation and iteration was too slow, and refactoring was much slower as well. I now write all shaders in HLSL.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/tilemapshader.png" alt=""></p><p>On Jan 10th we had figured out the basics of building UI in Noesis. Blake wrote a few simple UI widgets and then built the main menu and I built the first part of the game HUD, the toolbar.</p><p>The work went far more smoothly than I expected, and nothing was left on the cutting room floor. The tilemap took a day, a basic panel in Noesis was an afternoon including hooking up the plugin. The rest of the time was on wiring up characters. To be clear, I didn't port the entire UI in an afternoon or implement our equipment system. What we did have were customizable character bodies, a fully ported tilemap, some basic menus and enough knowledge to make projections on how long the rest of the port would take.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/initialport.png" alt="Very representative of the end of that first week."></p><p><em>This image is very representative of where we were at the end of the first week of porting, although this one is actually from a few days later after items had gone in.</em></p><p>At the end of the week, we convened to discuss what we had learned and made the decision to move ahead with the full port.</p><p>The following six weeks were dedicated to rewriting the remaining systems and content from the Bevy version into Unity/C#. The overall process largely validated the findings from our three-day test. Gameplay systems with the same number of features could be implemented with less verbosity.&nbsp;</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/longerconvo.png"></p><center><em>This conversation dates March 4, 2025.</em></center><p>Code size shrank substantially, massively improving maintainability. As far as I can tell, most of this savings was just in the elimination of ECS boilerplate.</p><p>Everything felt tighter and more straightforward. Update migration anxiety was gone and while it was replaced with "we gotta get this done" anxiety, that dissipated quickly as progress was constant.</p><h3>Life Since the Switch</h3><p>We've now been developing <strong>Architect of Ruin</strong> exclusively in Unity for the past three months. The shift has measurably improved our day-to-day development. Iteration feels faster, allowing ideas to flow into the game more easily. We've also been able to leverage ecosystem tools like the <a href="https://arongranberg.com/astar/" target="_blank">AStar Pathfinding Project</a>.</p><p>One area that isn't solved and which will likely cost us some pain is localization. In Rust, the <a href="https://github.com/projectfluent/fluent" target="_blank">Fluent</a>&nbsp;project is excellent and exactly what we needed -- I haven't yet found a comparable solution in Unity.</p><p>I plan to discuss specific elements of the game's implementation in Unity and the porting process in future posts. The goal of today's post was only to explain the reasoning that led us to our current position.</p><p>A few conclusions stand out.</p><p><strong>I failed to fairly evaluate my options at the start of the project. </strong>Rust is great and I love it, but I didn't give alternatives a fair shake. In particular, I didn't spend time examining the differences between Unreal and Unity more closely.</p><p><strong>Sometimes you have to burn time to earn time. </strong>I think we are way ahead of where we would have been had we stuck with Bevy. Our agility in implementing rendering features while also pushing gameplay forward is much higher.</p><p>Rust remains a language I deeply enjoy, and Bevy is an exciting engine with a fantastic community -- I have immense respect for both and may well use them again for different projects. For <strong>Architect of Ruin</strong>, however, the needs for accessible collaboration, rapid gameplay iteration, and leveraging a stable ecosystem pointed towards an alternative.</p><p>It was a difficult decision, one that felt counter to my instincts, but ultimately it put us in a much stronger position to realize our vision for the game.</p>
  
<p>
  <strong>
    Stay in the Loop&nbsp;üó°Ô∏è
  </strong>
  If you‚Äôve read this far and want to watch our sword-and-sorcery colony grow,
  <a href="https://deadmoney.gg/#block_6802c2b072638302caf714e7" target="_blank" rel="noopener">
    join the newsletter
  </a>
  to get dev updates&nbsp;&amp; first-look builds.
</p>
<center><video controls="controls" autoplay="autoplay" muted="muted" loop="loop" playsinline="playsinline" src="https://manakeep.us-east-1.linodeobjects.com/devlog/videos/2025/4/23/y379zowPZHtDvSKp/lutfix.mp4"></video></center></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reports of the death of California High-Speed Rail have been greatly exaggerated (199 pts)]]></title>
            <link>https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated</link>
            <guid>43824544</guid>
            <pubDate>Mon, 28 Apr 2025 18:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated">https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated</a>, See on <a href="https://news.ycombinator.com/item?id=43824544">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If there is one subject liberals and conservatives can agree on, it might be their shared hatred for California High-Speed Rail. Today, the project is <a href="https://apnews.com/article/california-high-speed-rail-trump-investigation-5b4d6494a8cdd9a3fe3b8949bb5b1bba">under investigation</a> by the Trump administration and is facing a possible withdrawal of federal funds. Even California Democrats seem disinclined to put up a fight. In Ezra Klein and Derek Thompson‚Äôs <em>Abundance</em>, it is the example par excellence of blue states‚Äô failure to build, a casualty (if it ever lived) of environmental proceduralism, prohibitive regulatory processes, a bloated bureaucracy, and general infrastructural incompetence. &nbsp;</p><p>All of these challenges are real. What critics miss is that many of them have already been overcome. What they ignore is the reason they exist in the first place. The story of CAHSR is not about a state trying and failing to overcome its own bureaucracy and broken political process. It‚Äôs about a state that barely tried.</p><p>In 2008, when the state originally put Prop 1A to voters to build a high-speed rail between Los Angeles and San Francisco, the expectation was that the $9.95 billion in state bonds voters approved would be matched or exceeded by federal funding (as is normally the case for highway projects), and perhaps further complemented by private funding (as with the Brightline West project between Las Vegas and Los Angeles). It passed with 52.6% of the vote.&nbsp;</p></div><div><p>It took four years to even begin work, but not solely because of permitting ‚Äî release of the funds was delayed until 2012. And they were held up further by a series of court cases that prevented the state from selling the bonds allocated by 1A until it identified the source of the rest of the project‚Äôs funding. During this time, the project received around $3 billion in federal funds from the Obama-era American Recovery and Reinvestment Act of 2009, which came with requirements to match federal funds and to begin work in disadvantaged areas of the Central Valley.</p><p>The result was that work on the Central Valley segment‚Äôs initial 120 miles was delayed for several years. The first major construction contract, Construction Package 1, was <a href="https://www.railwaygazette.com/high-speed/california-high-speed-rail-authority-invites-interest-in-second-construction-package/38771.article">issued in June 2013</a>. In the meantime, then-Governor Jerry Brown and the legislature worked to grant CAHSR what would be its sole ongoing funding source. In June 2014, the project was awarded a 15% allocation of the revenue from sales in California's cap-and-trade carbon auctions, which in recent years have raised between $3 and $4.7 billion a year. In 2017, this allocation was extended until 2030. With this funding secure, contracts were finally issued for Construction Package 2-3 in 2015 and Construction Package 4 in 2016.&nbsp;</p><p>But the delays in issuing these contracts started a vicious cycle. At multiple points in the rail‚Äôs history, approvals and construction plans already started for utility reconstructions, interactions with and crossings of existing freight lines, grade separations, and so on were left incomplete. This led to pauses in work and further delays so that plans could catch up to the ground already broken. The lack of continuity between planning and construction ‚Äî changes in contractors, personnel, and others with expertise ‚Äî made necessary change orders that only drove the cost up higher.&nbsp;</p><p>Through Trump‚Äôs first term, the initial portion of bond funding, combined with funding from the cap-and-trade fund allocation, was enough to keep <em>some</em> progress moving forward in the Central Valley under rail authority CEO Brian Kelly. Concrete viaducts and grade separations began to rise as visible signs of the work in progress. However, there were strict limits on what could be accomplished because of the piecemeal disbursement of cash. The sum of these funds, the only source of persistent cash flow, was generally about a billion dollars a year. They also varied each year due to the fluctuation in the cap-and-trade auction system. As a result, yearly funds couldn‚Äôt be reliably planned against, nor could they be borrowed against. Thus, even when work was finally underway, progress was slower than hoped, as change orders resulting from delayed property acquisition and permitting interactions with freight railroads and local municipalities increased costs and complexity.&nbsp;</p><p>To put this into perspective: Brightline West, the high-speed rail project between Los Angeles and Las Vegas, is hoping to spend the $12 billion they have raised in just over four years. It has taken many times as long for California High-Speed Rail to have their first $12 billion <em>in hand</em>. &nbsp;</p><p>Gavin Newsom‚Äôs election as governor in 2018 introduced further problems for the project that continue to plague it today. ‚ÄúThere simply isn‚Äôt a path to get from Sacramento to San Diego, let alone from San Francisco to LA,‚Äù he claimed. ‚ÄúI wish there were.‚Äù Instead, he directed the project to focus on the 172-mile stretch between Merced and Bakersfield, through which an eventual route from San Francisco to Los Angeles might run. Crucially, Newsom also cut funding that should have gone to the geological surveys needed for designing the tunnels required to punch through the Diablo range south of San Francisco and San Gabriel Mountains north of Los Angeles ‚Äî thereby fulfilling his own prophecy.</p><p>Initially, Newsom also didn‚Äôt put political capital to work to push for more funding for the project. Indeed, for the first few years of his tenure, $4.1 billion in Prop 1A bond funds remained unallocated by the state legislature and thus unavailable for the project to use. It wasn‚Äôt until 2021, as debates about Biden-era federal infrastructure funding began, that Newsom finally began to pressure the legislature to release these funds to the project in hopes of attracting new federal matching funds. The legislature released the remaining bond funds in 2022, and that renewed state investment may indeed have played a role in the <a href="https://pelosi.house.gov/news/press-releases/pelosi-announces-landmark-3-billion-federal-investment-california-high-speed">award of $3.07 billion in federal infrastructure funds in the fall of 2023</a>.</p><p>With all this in mind, we can start to look at common criticisms of California High-Speed Rail in a different light. These critiques ‚Äî maybe you‚Äôve seen them on Twitter ‚Äî generally glibly identify solutions or alternatives that are insufficient to address the rail‚Äôs real issues, and focus attention on the wrong problems.</p><p>&nbsp;One regular snipe is that it‚Äôs ‚Äúeasier to build rail in Morocco than in California.‚Äù This critique stems from the fact that the French national railroad company, SNCF, which participated early in the planning process before 1A passed, also helped design the Moroccan Al Boraq high-speed rail service. Such critics often note that the Al Boraq service is operational today and claim that the relative failure of the California High-Speed Rail ‚Äúboondoggle‚Äù represents the political dysfunction of either California, the United States, or the West as a whole. This appears to be based entirely on one quote in the <em>New York Times</em>,<em> </em>from an SNCF project manager, that the company left for Morocco, ‚Äúwhich was less politically dysfunctional.‚Äù In fact, SNCF has employees in 120 countries and has projects in Israel, Taiwan, and South Korea, among others.</p><p>This criticism also misunderstands one of the main challenges that CAHSR has faced. Al Boraq had full funding lined up before the project began. CAHSR did not. This led to delays that reduced support and encouraged critics, which starved it of funding commitments and thus led to further delays. California undermined CAHSR from the start.&nbsp;</p><p>Another common criticism, as laid out in <a href="https://benjaminschneider.substack.com/p/california-high-speed-rails-original">an article by Benjamin Schneider</a>, is that California High-Speed Rail is built in the wrong place, to the wrong standards, and with the wrong goals ‚Äî and that‚Äôs why it failed. The argument goes like this: The currently planned alignment through the Central Valley makes building unnecessarily complicated. Because it goes through major population centers ‚Äî Bakersfield, Merced, Fresno ‚Äî it introduces the necessity of grade separations (bridges or tunnels built so that trains and vehicles pass over or under each other) and requires complex property acquisitions. The right place to build the rail alignment is a direct route between Los Angeles and San Francisco paralleling Interstate 5.&nbsp;</p><p>This was, in fact, the route proposed by SNCF prior to Prop 1A‚Äôs passing. The I-5 alignment would save mileage, reduce grade separations and utility relocations, and use property already under the control of the state‚Äôs department of transportation. These cities could then perhaps be connected with branch lines to the high-speed rail trunk, establishing a line through the Central Valley with a faster build out and lower cost compared with the more expensive ‚Äúpolitical‚Äù route directly through Central Valley cities and towns.</p><p>&nbsp;Although it has intuitive appeal, this proposal suffers from major issues. First, the I-5 route avoids every major population center in the Central Valley, bypassing more than a million people who would be unserved. The only way to connect them to the line would be through stub-end branch lines. Building these lines would add the same kinds of costs as the as-built line directly through the Central Valley cities while offering them worse service. Second, it‚Äôs quite possible the I-5 alignment would never have been popular enough to pass as a ballot proposition. The Central Valley population areas only narrowly voted in favor of 1A. Had the original proposal outlined in the ballot initiative offered a different route from which Central Valley residents would not benefit, it‚Äôs possible it would not have passed at all.<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>Third, much has been made of the fact that construction has begun on the middle section of the alignment rather than in Los Angeles or San Francisco. This is, in fact, standard practice in building high-speed rail around the world. The route alignment as selected means that even if the Central Valley portion of the rail is all that operates within the next decade, it will still see service, as it will replace the existing Amtrak line that already carries a million riders a year between the Central Valley population centers. Only if the Central Valley alignment had been selected would CAHSR actually the ‚Äútrain to nowhere‚Äù that critics deride it as.&nbsp;</p><p>&nbsp;Perhaps most importantly, critics appear to forget that the Central Valley alignment, political or not, overambitious or not, <em>is nearly built</em>. The property is acquired and cleared, embankments are under construction, and many viaducts and bridges have been completed. Abandoning it in the current state and switching to I-5 would almost certainly cost more than finishing the current alignment.</p><p>And this alignment isn‚Äôt the real problem, anyway. The true cost driver for CAHSR isn‚Äôt the difference between I-5 and the Central Valley, but access <em>into</em> Los Angeles and San Francisco. There, the challenge is not permits or politics but geology. While rail services like Metrolink‚Äôs Antelope Valley commuter line in Los Angeles and the Altamont Corridor Express in San Francisco do already cross the mountains, these are slow trains ‚Äî necessarily so, because of the tortuous route demanded by the terrain. According to the 2024 California High-Speed Rail business plan, the total cost of the three major required tunnels is expected to make up approximately half of the total project cost. The Central Valley‚Äôs 172 miles under construction and advanced planning are estimated to cost up to $33 billion. The total to get from the Central Valley into the Los Angeles region is expected to be $34 billion, while at the north end of the Central Valley, the link from the Central Valley to the San Francisco Bay region is expected to cost $20 billion, including the tunnel and improvements along existing rail corridors from San Jose to Gilroy. These costs can‚Äôt be blamed on Californian political dysfunction: These are tunnels on the scale of the Gotthard Base Tunnel through the Alps in Switzerland, which had a similar cost-per-mile.&nbsp;</p><p>A second line of criticism comes from the abundance movement. <a href="https://archive.ph/pYBxj">Critics like Ezra Klein emphasize</a> the problems created by environmental permitting and cooperating with utilities, and other existing interests like the freight railroads and (mostly Republican) landowners. All of these are real problems, and each has been a factor in delaying CAHSR. Environmental review has taken over a decade. Breaking ground sometimes uncovered new lawsuits. The entire project has been negotiated and renegotiated, inflating prices at each step. But every single one of these problems is also faced by other infrastructure projects ‚Äî new bridges and highways in particular ‚Äî that manage to proceed in spite of regulatory difficulties. &nbsp;</p><p>One major reason that highway infrastructure succeeds where CAHSR has failed is that such projects are routine. Highways have assured funding from federal and state sources. They also have significant political support from state and federal officials. More to the point, there is an industry of professionals experienced in both building roads and navigating the red tape necessary to make doing so possible. The equivalent network for American high-speed rail does exist ‚Äî yet.&nbsp; This is part of the reason that high-speed rail costs many times as much in the United States as it does in European countries. Unless we actually commit to building <em>and finishing</em> high-speed rail, that network will never form.</p><p>Many commentators have suggested the project cut its losses and bow out. But one piece missing from the discourse is an accurate understanding of what the project has cost to date and what it needs to be completed. This problem dates to the earliest days of the project. If the CAHSR has an original sin, it is that the bond issue that went before voters didn‚Äôt ask for enough money. Early business plans in 2008 expected a total budget of $33 billion to be sufficient, approximately $50 billion today with inflation. Because the expectation was that federal government or private investment would bear much of this cost, the bond issue requested less than a third of the amount needed even in these early estimates.<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>It was only in 2011, once the project was able to finalize more of the route plan in detail, that the projected price rose to $65 billion. Inflation adjusted, that is $94 billion today ‚Äî close to the base-cost estimate of $106 billion from the 2024 business plan that so many have critiqued. As many critics have rightfully and fairly noted, this is a higher cost-per-mile of track than in many countries that routinely build high-speed rail. But America, of course, does not routinely build high-speed rail, and the project remains only slightly more expensive than it was forecasted to be 13 years ago. Most important, to date, CAHSR has spent only about $15 billion, which has limited the ability to proceed with extensive planning beyond the Central Valley. It has also stopped the award of any new heavy construction contracts since the initial 119 miles of Construction Packages 1 through 4. Work has begun on the next 50 miles of civil construction to bring tracks to Merced, where they will connect with ACE and San Joaquins train services to San Francisco and Sacramento, and to Bakersfield, where connections are available via Amtrak Thruway bus service into Los Angeles. Contracts are also intended to be issued this year for the tracks, overhead electrical system, and trains to run the initial segments.&nbsp;</p><p>This money has also paid for contributions to the electrification of Caltrain in San Francisco, grade separations removing freight crossings from streets in Los Angeles, and the complete environmental clearance and basic geotechnical design of the entire route from Los Angeles to San Francisco. Completing the Central Valley segment will cost between $4 and $7 billion.&nbsp;</p><p>The additional funding required to reach San Francisco and Los Angeles to complete the core route will be approximately $80 billion. This is a lot of money, but as inflation-adjusted estimates show, it is not due purely to incompetence and cost overruns. More to the point, California can afford projects on a similar scale. The recent BART extension to San Jose is expected to cost $12.75 billion, and Caltrans receives a budget of $15 billion a year. California has had substantial budget surpluses in the past decade. In 2022 alone, the surplus totaled nearly $100 billion (although the budget is now roughly balanced). As a matter of practical economics, the project could be paid for. The question now is if the political will is there to fund it either in whole or in some revised form.&nbsp;</p><p>Despite more than a decade of predictions of its failure, the project has persevered ‚Äî even if its completion is in limbo. The initial operating segment between Merced and Bakersfield is projected to begin operating in 2030. Progress is invisible to those in San Francisco and Los Angeles, and it can‚Äôt be seen just driving along I-5. But everything from satellite imagery to drone footage to a drive along State Route 43 reveals the progress being made along the 119 miles of construction underway in the Central Valley. The 22 miles making up Construction Package 4 are effectively complete, from the massive Wasco Viaduct, where the high-speed rail rises to cross over Burlington Northern and Santa Fe freight railroad tracks, to the numerous smaller-grade separation structures rising from the valley floor.</p><p>A ceremony was held in January 2025 to mark the beginning of work on the ‚Äúconstruction railhead,‚Äù where 10 miles of freight rail yard will be built to support track laying and the erection of overhead wires in coming years. This will also include some of the first permanent high-speed tracks to be laid on the alignment. Of the 81 structures planned between Construction Packages 1-3, all but seven are underway. Seventeen structures are planned to be completed in 2025, including rail viaducts over low-lying swamps and rivers, and underpasses and overpasses that will remove grade crossings with urban streets in Fresno.&nbsp;</p><p>While no final track has yet been laid, this constitutes the vast majority of the work to prepare the route. For comparison, were this project a highway, at this stage it would need only paving and striping. If funding holds from the state, contracts for track laying and the purchase of the first train sets should go out this year. Work is also proceeding on the remainder of the route: Design work and property acquisition are underway for the next 50 miles of right-of-way extending to Merced and Bakersfield, this time phased to allow utility relocations and other local interference to be cleared ahead of construction on the main structures. All of the environmental permits are complete for extending the tunnels through Pacheco Pass to Gilroy and up to San Francisco and from Bakersfield south to Palmdale and Los Angeles. The only thing holding back construction is money.</p><p>Watching the progress has converted some former skeptics. Kings County Supervisor Doug Verboon was once a plaintiff in one of the lawsuits seeking to stop the project in its tracks. As of this year, he‚Äôs expressed support for finishing the sections of the project already underway. In an article in the <em>Hanford Sentinel </em>from December 2024, he expressed that, as chair of the San Joaquin Valley Rail Commission, he now wants to see the structures completed to make use of the investment.&nbsp;</p><p>For those who can see every day the tangible progress of the project, opposition has evolved into something quite different: doubt about whether the funding can be provided to finish the job. The dream of a complete line from San Francisco to Los Angeles remains as popular as it did when 1A first passed with 52% of the vote in 2008. <a href="https://ktla.com/news/california/majority-of-californians-still-support-high-speed-rail-project-polling-shows/">An Emerson College poll commissioned by KTLA in February</a> found that 54% of Californians still support the project. When Trump‚Äôs secretary of transportation, Sean Duffy, came to Los Angeles to announce the administration was investigating the project, he was met by a large crowd of protestors chanting ‚Äúbuild the rail‚Äù loud enough to drown him out on press microphones.</p><p>The next four years of the second Trump administration will prove a crucial test of support from the state government. Even before Trump threatened to cut off the awarded federal funding, the Office of the Inspector General raised the possibility that the project could be between $3 and $6.5 billion short of completing the 172 miles from Merced to Bakersfield, depending on the variation in state cap-and-trade auction revenue. The project has sufficient California funds only to last through the Trump administration, complete and electrify the existing 120 miles, purchase train sets, and begin construction of the Merced and Bakersfield extensions ‚Äî but not fully complete them. &nbsp;</p><p>This is not an easy project. But exaggerating the difficulties of completing it can blind us to both the possibilities and the reasons the project was ‚Äî and remains ‚Äî popular. A high-speed rail connection in San Jose would place the Central Valley a mere 30-45 minutes away, opening up options for new housing and commercial opportunities. Effectively, it would make something like the ‚ÄúCalifornia Forever‚Äù plan possible in a different region of the state, complete with high-speed rail connections directly to Silicon Valley. Long term, connecting Los Angeles to San Francisco by high-speed rail would be time competitive with flying and several times faster than driving.&nbsp;</p><p>If California politicians match action to desires, it is within California‚Äôs capability to fund the project itself. Governor Newsom and the California legislature have hinted at such a possibility. Rather than buying into the narratives of predetermined failure pushed by the project‚Äôs longtime opposition, Californian citizens and politicians should push for the project‚Äôs continuation ‚Äî and for as much support as the state can give.&nbsp;</p></div></div>]]></description>
        </item>
    </channel>
</rss>