<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 04 Jun 2025 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Why I Wrote the BEAM Book (175 pts)]]></title>
            <link>https://happihacking.com/blog/posts/2025/why_I_wrote_theBEAMBook/</link>
            <guid>44179257</guid>
            <pubDate>Wed, 04 Jun 2025 10:36:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://happihacking.com/blog/posts/2025/why_I_wrote_theBEAMBook/">https://happihacking.com/blog/posts/2025/why_I_wrote_theBEAMBook/</a>, See on <a href="https://news.ycombinator.com/item?id=44179257">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<h3> Post-mortems, coffee, and a decade of stubborn curiosity </h3><p>

	Posted:  2025-06-03</p>

	<h2>Why I wrote the Beam Book</h2>
<p>After ten years of keeping Klarna’s core system upright I know this: a 15
millisecond pause in the BEAM can stall millions of peak-shopping payments, trigger a 3 a.m. Christmas-Eve post-mortem, and earn you a very awake call from the CEO. I wrote <em>The BEAM Book</em> so the next engineer fixes that pause before the coffee cools.</p>
<p><img src="https://happihacking.com/images/thebeambooks.jpg" alt="A picture of two printed BEAM Books."></p><h3>Origins</h3>
<p>I opened the project on 12 October 2012 with a lone DocBook file with four lines of text and an oversized sense of optimism.
After two weeks, the commit log is mostly me adding structure, moving
headings, and updating metadata. Most of it is scaffolding. The actual
content is still just a few hopeful lines.</p>
<p>By November I had abandoned DocBook for AsciiDoc, written a custom build
script, and convinced myself the book could be wrapped up in six months.
Those early commits glow with energy: adds, rewrites, then more
rewrites to fix the rewrites.
Delusion is underrated.</p>
<p>In 2013 I managed to convince O’Reilly to publish. Moving the repo to their
Atlas system sounded simple until Atlas began hiding my main file and
overwriting half-finished chapters.</p>
<p>The Git history reads like a diary of frustration:
“Moving files to top level to cope with Atlas,” “Atlas seems to be
overwriting book.asciidoc”. Word count shot past 120 000 while actual
progress crawled. On 10 March 2015 I was literally “Smashing chapters into sections” just to keep the build green.</p>
<p>The quiet cancellation came two months later. No drama, just a polite call and a line through the contract. Relief mingled with embarrassment, I had spent two years rearranging files rather than finishing sentences.</p>
<p>Pragmatic Bookshelf took over that same year. I kept working in CVS for
their production system, but progress was slow. Eventually, they cancelled
too. On 20 January 2017, I imported everything into a new repo in one
massive commit: 6,622 files, over a million lines.
The rewrite stalled, and so did the project.</p>
<p>On 23 March 2017 I started fresh with Asciidoctor in a private GitHub repo, copy-pasting
only the parts that still made sense. Two weeks later, on April 7, minutes before
a lecture at Chalmers, I flipped the repository public. Within twenty-four
hours strangers fixed typos, added diagrams, and merged a Creative Commons
BY-4.0 license.</p>
<h3>What Kept Me Going</h3>
<p><img src="https://happihacking.com/images/star-history.svg" alt="A picture of the stars on GitHub passing 3000."></p><p>I kept going because I wanted to understand the BEAM properly. There’s
value in following the real logic, not just the surface explanations.</p>
<p>Community feedback made a difference. As soon as the repo was public,
people began sending corrections, examples, and improvements.</p>
<p>Seeing the numbers of people starring the repo on GitHub kept me going.
One highlight: <strong>Issue #113 – “Please continue being awesome.”</strong>
That emoji-laced drive-by encouragement (August 2018) still pops into my
head whenever motivation dips.</p>
<p><img src="https://happihacking.com/images/issue113.png" alt="Issue 113: This book
is ridiculously good. I have only read a few bits of it so far and have
learned a lot already. Please continue being awesome!"></p>
<p>The book started showing up as a reference in Erlang and BEAM conference
talks, sometimes several times in the same event. That was a clear signal
that others needed this as much as I did.</p>
<p>Even Twitter (in the good old days of Twitter) played a role. Whenever
someone mentioned the book or shared a
link, it was an extra nudge to keep at it.</p>
<p>Mostly, I just wanted a manual I could trust myself, a reference for the
parts of the VM that matter when things go wrong. That’s reason enough to
keep writing, even after the third rewrite.</p>
<h3>What’s Inside the Book &amp; Who It Helps</h3>
<p>The book covers what I wish I’d had when building and operating large
Erlang systems:</p>
<ul>
<li>Schedulers and process management: How the BEAM schedules,
prioritizes, and balances processes under real load.</li>
<li>Processes and their memory: How process heaps,
stack, messages, and binaries are managed and
why these details matter in production.</li>
<li>Garbage collection and memory: What actually happens
with per-process and global garbage collectors, binary references,
and memory leaks.</li>
<li>Tagging schemes and terms: How the BEAM represents data—integers,
floats, tuples, binaries, references—down to the tagging bits.</li>
<li>The compiler and the VM: How code is turned into instructions,
what the compiler does (and doesn’t do), and how the emulator executes it.</li>
<li>Tracing and debugging: Practical use of dbg, erlang:trace,
and other tools to follow messages, events, and identify bottlenecks.</li>
<li>Performance tuning: What matters when profiling real code,
understanding reductions, and tracking down real-world latency problems.</li>
<li>System architecture: How ERTS, the BEAM VM, and their subsystems
actually work together in a running node.</li>
</ul>
<p>If you build or operate Erlang or Elixir systems, especially under any kind
of scale—this book is for you. It saves you from hunting through mailing
lists, scattered docs, and code comments just to answer, “Why is the VM
behaving like this?”</p>
<h3>Lessons Learned</h3>
<p>Persistence beats perfection. Two cancelled publishing deals look bad on a
résumé, but an unfinished idea looks worse.</p>
<p>Boundaries matter. I made progress by blocking time for writing, turning
off notifications, and treating focus like a real deadline. Fika at 14:30
is non-negotiable.</p>
<p>The crowd helps. Making the repo public brought in corrections,
encouragement, and the occasional nudge when motivation was low.</p>
<p>Scope is everything. I cut the details on dirty schedulers, the new JIT,
and the debugger. Maybe those will end up in an appendix, but not in the
core.</p>
<p>Ship, then iterate. The BEAM changes every year. A living Git repo keeps
up.</p>
<p>A real deadline helps. This January, during my yearly review, I
decided to print the book in time for Code Beam Stockholm. I thought I had
until autumn, turns out the conference was June 2. That’s how you find out
what’s truly essential.</p>
<h3>Definition of Done</h3>
<p>Holding the print in my hands, it finally feels finished, at least for now. Years of scattered commits are bound into something real, so I’m calling it done.</p>
<h3>Get Involved</h3>
<p>You can now get the paperback—The BEAM Book 1.0 is live on Amazon. Buy it
here.&nbsp;<a href="https://www.amazon.com/dp/9153142535">Amazon</a></p>
<p>If you spot an error, want to improve something, or just want to see how it
works under the hood, star or fork the repo. File an issue or, even better,
submit a pull request. Contributors are credited in the acknowledgments.
<a href="https://github.com/happi/theBeamBook">GitHub: theBeamBook</a></p>
<p>If you read the book, please leave an honest review.
Algorithms notice real feedback more than marketing copy.</p>
<p>If your team wants a deep dive, I run hands-on BEAM internals
workshops, tailored for real systems, not just hello world.
Email me if that’s what you need.
<a href="mailto:happi@happihacking.com">happi@happihacking.com</a></p>


	<p>
	  - Happi
  </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cockatoos have learned to operate drinking fountains in Australia (163 pts)]]></title>
            <link>https://www.science.org/content/article/cockatoos-have-learned-operate-drinking-fountains-australia</link>
            <guid>44178902</guid>
            <pubDate>Wed, 04 Jun 2025 09:42:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/cockatoos-have-learned-operate-drinking-fountains-australia">https://www.science.org/content/article/cockatoos-have-learned-operate-drinking-fountains-australia</a>, See on <a href="https://news.ycombinator.com/item?id=44178902">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/cockatoos-have-learned-operate-drinking-fountains-australia: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cloud Run GPUs, now GA, makes running AI workloads easier for everyone (191 pts)]]></title>
            <link>https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available</link>
            <guid>44178468</guid>
            <pubDate>Wed, 04 Jun 2025 08:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available">https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available</a>, See on <a href="https://news.ycombinator.com/item?id=44178468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb"><p><span>Developers love </span><a href="https://cloud.google.com/run"><span>Cloud Run</span><span>, Google Cloud’s serverless runtime, </span></a><span>for its simplicity, flexibility, and scalability. And today, we’re thrilled to announce that NVIDIA GPU support for Cloud Run is now generally available, offering a powerful runtime for a variety of use cases that’s also remarkably cost-efficient.&nbsp;</span></p>
<p><span>Now, you can enjoy the following benefits across both GPUs and CPUs:</span></p>
<ul>
<li>
<p><strong>Pay-per-second billing</strong><span>: You are only charged for the GPU resources you consume, down to the second.</span></p>
</li>
<li>
<p><strong>Scale to zero</strong><span>: Cloud Run automatically scales your GPU instances down to zero when no requests are received, eliminating idle costs. This is a game-changer for sporadic or unpredictable workloads.</span></p>
</li>
<li>
<p><strong>Rapid startup and scaling</strong><span> Go from zero to an instance with a GPU and drivers installed in under 5 seconds, allowing your applications to respond to demand very quickly. For example, when scaling from zero (cold start), we achieved an impressive Time-to-First-Token of approximately 19 seconds for a gemma3:4b model (this includes startup time, model loading time, and running the inference)</span></p>
</li>
<li>
<p><strong>Full streaming support</strong><span>: Build truly interactive applications with out-of-the box support for HTTP and WebSocket streaming, allowing you to provide LLM responses to your users as they are generated.</span></p>
</li>
</ul>
<p><span>Support for GPUs in Cloud Run is a significant milestone, underscoring our leadership in making GPU-accelerated applications simpler, faster, and more cost-effective than ever before.</span></p>
<p><span>“Serverless GPU acceleration represents a major advancement in making cutting-edge AI computing more accessible. With seamless access to NVIDIA L4 GPUs, developers can now bring AI applications to production faster and more cost-effectively than ever before.” </span><span>- Dave Salvator, director of accelerated computing products, NVIDIA</span></p></div><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb"><h3><strong>AI inference for everyone</strong></h3>
<p><span>One of the most exciting aspects of this GA release is that Cloud Run GPUs are now available to everyone for NVIDIA L4 GPUs, with </span><strong>no quota request required</strong><span>.This removes a significant barrier to entry, allowing you to immediately tap into GPU acceleration for your Cloud Run services. Simply use </span><code>--gpu 1</code><span> from the Cloud Run command line, or check the "GPU" checkbox in the console, no need to request quota:</span></p></div><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/1_XkZEV9U.max-1000x1000.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/1_XkZEV9U.max-1000x1000.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb"><h3><strong>Production-ready</strong></h3>
<p><span>With general availability, Cloud Run with GPU support is now covered by Cloud Run's </span><a href="https://cloud.google.com/run/sla"><span>Service Level Agreement (SLA)</span></a><span>, providing you with assurances for reliability and uptime. By default, Cloud Run offers </span><a href="https://cloud.google.com/run/docs/zonal-redundancy"><span>zonal redundancy</span></a><span>, helping to ensure enough capacity for your service to be resilient to a zonal outage; this also applies to Cloud Run with GPUs. Alternatively, you can turn off zonal redundancy and benefit from a </span><a href="https://cloud.google.com/run/pricing"><span>lower price</span></a><span> for best-effort failover of your GPU workloads in case of a zonal outage.</span></p>
<h3><strong>Multi-regional GPUs</strong></h3>
<p><span>To support global applications, Cloud Run GPUs are available in five Google Cloud </span><a href="https://cloud.google.com/run/docs/locations#gpu"><span>regions</span></a><span>: us-central1 (Iowa, USA), europe-west1 (Belgium), europe-west4 (Netherlands), asia-southeast1 (Singapore), and asia-south1 (Mumbai, India), with more to come.</span></p>
<p><span>Cloud Run also </span><a href="https://cloud.google.com/run/docs/multiple-regions"><span>simplifies deploying your services across multiple regions</span></a><span>. For instance, you can deploy a service across the US, Europe and Asia with a single command, providing global users with lower latency and higher availability. For instance, here’s how to deploy </span><a href="https://ollama.com/" rel="noopener" target="_blank"><span>Ollama</span></a><span>, one of the easiest way to run open models, on Cloud Run across three regions:</span></p></div><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb"><h3><strong>See it in action: 0 to 100 NVIDIA GPUs in four minutes</strong></h3>
<p><span>You can witness the incredible scalability of Cloud Run with GPUs for yourself with </span><a href="https://youtu.be/PWPvX25R6dM?feature=shared&amp;t=2140" rel="noopener" target="_blank"><span>this live demo</span></a><span> from Google Cloud Next 25, showcasing how we scaled from 0 to 100 GPUs in just four minutes.</span></p></div><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_SrvmWli.max-1600x1600.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_SrvmWli.max-1600x1600.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><div><p>Load testing a Stable Diffusion service running on Cloud Run GPUs to 100 GPU instances in four minutes.</p></div></section><div jsaction="rcuQ6b:npT2md" jscontroller="M0Q3Qb"><h3><strong>Unlock new use cases with NVIDIA GPUs on Cloud Run jobs</strong></h3>
<p><span>The power of Cloud Run with GPUs isn't just for real-time inference using request-driven Cloud Run services. We're also excited to announce the availability of GPUs on </span><a href="https://cloud.google.com/run/docs/overview/what-is-cloud-run#cloud-run-jobs"><span>Cloud Run jobs</span></a><span>, unlocking new use cases, particularly for batch processing and asynchronous tasks:</span></p>
<ul>
<li>
<p><strong>Model fine-tuning</strong><span>: Easily fine-tune a pre-trained model on specific datasets without having to manage the underlying infrastructure. Spin up a GPU-powered job, process your data, and scale down to zero when it’s complete.</span></p>
</li>
<li>
<p><strong>Batch AI inferencing</strong><span>: Run large-scale batch inference tasks efficiently. Whether you're analyzing images, processing natural language, or generating recommendations, Cloud Run jobs with GPUs can handle the load.</span></p>
</li>
<li>
<p><strong>Batch media processing</strong><span>: Transcode videos, generate thumbnails, or perform complex image manipulations at scale.</span></p>
</li>
</ul>
<p><span><a href="https://docs.google.com/forms/d/e/1FAIpQLSe_-u-ZSxVLhRMZ3p4ZSk2CkgL_URKqNgyM8rfMGUrTbpqYJQ/viewform?usp=dialog" rel="noopener" target="_blank"><span>Sign up</span></a><span> for the private preview of GPUs on Cloud Run jobs.</span></span></p>
<h3><strong>What Cloud Run customers are saying</strong></h3>
<p><span>Don't just take our word for it. Here's what some early adopters of Cloud Run GPUs are saying:</span></p>
<p><span>"Cloud Run helps vivo quickly iterate AI applications and greatly reduces our operation and maintenance costs. The automatically scalable GPU service also greatly improves the efficiency of our AI going overseas.”</span><span> - Guangchao Li, AI Architect, vivo</span></p>
<p><span>"L4 GPUs offer really strong performance at a reasonable cost profile. Combined with the fast auto scaling, we were really able to optimize our costs and saw an 85% reduction in cost. We've been very excited about the availability of GPUs on Cloud Run."</span><span> - John Gill at </span><a href="https://youtu.be/PWPvX25R6dM?feature=shared&amp;t=2496" rel="noopener" target="_blank"><span>Next'25</span></a><span>, Sr. Software Engineer, Wayfair</span></p>
<p><span><span>"At Midjourney, we have found Cloud Run GPUs to be incredibly valuable for our image processing tasks. Cloud Run has a simple developer experience that lets us focus more on innovation and less on infrastructure management. Cloud Run GPU’s scalability also lets us easily analyze and process millions of images.</span><span>" - Sam Schickler, Data Team Lead, Midjourney</span></span></p>
<h3><strong>Get started today</strong></h3>
<p><span>Cloud Run with GPU is ready to power your next generation of applications. Dive into the </span><a href="https://cloud.google.com/run/docs/configuring/services/gpu"><span>documentation</span></a><span>, explore our </span><a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma-with-ollama"><span>quickstarts</span></a><span>, and review our </span><a href="https://cloud.google.com/run/docs/configuring/services/gpu-best-practices"><span>best practices for optimizing model loading</span></a><span>. We can't wait to see what you build!</span></p></div><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/serverless" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/serverless" track-metadata-module="tag list" track-metadata-module_headline="posted in">Serverless</a></li><li><a href="https://cloud.google.com/blog/products/application-modernization" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/application-modernization" track-metadata-module="tag list" track-metadata-module_headline="posted in">Application Modernization</a></li><li><a href="https://cloud.google.com/blog/products/compute" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/compute" track-metadata-module="tag list" track-metadata-module_headline="posted in">Compute</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Merlin Bird ID (407 pts)]]></title>
            <link>https://merlin.allaboutbirds.org/</link>
            <guid>44176829</guid>
            <pubDate>Wed, 04 Jun 2025 02:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://merlin.allaboutbirds.org/">https://merlin.allaboutbirds.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44176829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hero-wrapper">
              <h2>Identify the birds you see or hear with Merlin Bird ID</h2><p>Free global bird guide with photos, <br>sounds, maps, and more.</p><p><a href="https://itunes.apple.com/app/apple-store/id773457673?pt=401711&amp;ct=marketingwebsite&amp;mt=8"><img data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2020/01/Download_App_Store_en.png" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></a> <a href="https://play.google.com/store/apps/details?id=com.labs.merlinbirdid.app&amp;pli=1"><img data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2020/02/google-play-badge-en.png" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></a></p>            </div><section id="content" aria-label="Main content" data-sticky-container="">
 
      
<div>
<div>
<h2>Identify Bird Songs and Calls</h2>



<p><strong>Sound ID</strong> listens to the birds around you&nbsp;and shows real-time suggestions for who’s singing. Compare your recording to the songs and calls in Merlin to confirm what you heard. Sound ID works completely offline, so you can identify birds you hear no matter where you&nbsp;are. </p>



<p>Available for birds in the US, Canada, Europe, with some common birds of Central and South America, and India. More species and regions coming soon.&nbsp;</p>




</div>



<div>
<figure><img fetchpriority="high" decoding="async" width="2000" height="1250" src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1.png" alt="" srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1.png 2000w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-480x300.png 480w" sizes="(max-width: 2000px) 100vw, 2000px"></figure>
</div>
</div>



<hr>



<div>
<div>
<figure><img decoding="async" width="1280" height="800" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1280x800.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-480x300.png 480w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1.png 2000w" data-sizes="(max-width: 1280px) 100vw, 1280px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>
</div>



<div>
<h2>Identify Birds in a Photo</h2>



<p>Snap a photo of a bird, or pull one in from your camera roll, and <strong>Photo ID</strong> will offer a short list of possible matches. Photo ID works completely offline, so you can identify birds in the photos you take no matter where you&nbsp;are. </p>




</div>
</div>



<hr>



<h2>Bird ID Wizard—Step-by-step</h2>



<p>Answer three simple questions about a bird you are trying to identify and Merlin will give you a list of possible matches.&nbsp;Merlin offers quick identification help for all levels of bird watchers and outdoor enthusiasts to help you learn about the birds in any country in the world. </p>



<figure><img decoding="async" width="1600" height="600" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1.png 1600w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-720x270.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-1280x480.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-768x288.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-1536x576.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-480x180.png 480w" data-sizes="(max-width: 1600px) 100vw, 1600px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>











<hr>



<div>
<div>
<h2>Save Birds to Your Life List</h2>



<p>Build a&nbsp;digital&nbsp;scrapbook of your birding memories with Save My Bird. Tap “This is my bird!” each time you identify a bird, and&nbsp;Merlin will add it to your growing life&nbsp;list.</p>




</div>



<div>
<figure><img decoding="async" width="2000" height="1250" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List.png 2000w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-480x300.png 480w" data-sizes="(max-width: 2000px) 100vw, 2000px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>
</div>
</div>



<hr>



<h2>Explore Lists of Birds Near You</h2>



<p>Merlin is powered by&nbsp;<a href="http://ebird.org/">eBird</a>, allowing you to&nbsp;build custom lists of&nbsp;the birds you’re likely to spot wherever you are. Use the filter options to&nbsp;explore birds for different locations or time of year, or switch to show all the Offline Birds you’ve downloaded.&nbsp;Get more from the app with these <a href="https://support.ebird.org/en/support/solutions/articles/48000966225-merlin-tips-and-tricks#anchorCustomList">Merlin Tips and Tricks</a>.</p>



<figure><img decoding="async" width="1600" height="600" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore.png 1600w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-720x270.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-1280x480.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-768x288.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-1536x576.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-480x180.png 480w" data-sizes="(max-width: 1600px) 100vw, 1600px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>



<hr>



<h2>See How Merlin Can Help You ID Birds</h2>



<figure><p>
<iframe title="Merlin Bird ID Demo from the Cornell Lab of Ornithology" width="1200" height="675" data-src="https://www.youtube.com/embed/xmSUOLxyatY?feature=oembed&amp;modestbranding=1&amp;showinfo=0&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-load-mode="1"></iframe>
</p></figure>



<hr>



<h2>The Best Birding App, Powered By You</h2>



<p>Merlin features the best of community contributed photos, songs, and calls, tips from experts around the world to help you ID the birds you see, and range maps from <a href="https://birdsoftheworld.org/bow/home">Birds of the World</a>—all powered by billions of bird observations submitted to <a href="https://ebird.org/home">eBird</a>.</p>





      
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Binary Wordle (186 pts)]]></title>
            <link>https://wordle.chengeric.com/</link>
            <guid>44176825</guid>
            <pubDate>Wed, 04 Jun 2025 02:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordle.chengeric.com/">https://wordle.chengeric.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44176825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Use keyboard (0, 1, Enter, Backspace) or buttons to play</p></div><div><p>Sponsor: Don't like waiting on hold? Try</p><!-- --> <p><a href="https://altodial.com/?wordle"><img alt="" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" src="https://wordle.chengeric.com/square.svg">altodial.com</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DiffX – Next-Generation Extensible Diff Format (302 pts)]]></title>
            <link>https://diffx.org/</link>
            <guid>44176737</guid>
            <pubDate>Wed, 04 Jun 2025 02:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diffx.org/">https://diffx.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44176737">Hacker News</a></p>
Couldn't get https://diffx.org/: Error: getaddrinfo ENOTFOUND diffx.org]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Has anybody built search on top of Anna's Archive? (200 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44176514</link>
            <guid>44176514</guid>
            <pubDate>Wed, 04 Jun 2025 01:47:26 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44176514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="44176767"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176767" href="https://news.ycombinator.com/vote?id=44176767&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>Honestly I don't think it would be that costly, but it would take a pretty long time to put together. I have a (few years old) copy of Library Genesis converted to plaintext and it's around 1TB. I think libgen proper was 50-100TB at the time, so we can probably assume that AA (~1PB) would be around 10-20TB when converted to plaintext. You'd probably spend several weeks torrenting a chunk of the archive, converting everything in it to plaintext, deleting the originals, then repeating with a new chunk until you have plaintext versions of everything in the archive. Then indexing all that for full text search would take even more storage and even more time, but still perfectly doable on commodity hardware.</p><p>The main barriers are going to be reliably extracting plaintext from the myriad of formats in the archive, cleaning up the data, and selecting a decent full text search database (god help you if you pick wrong and decide you want to switch and re-index everything later).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177936"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177936" href="https://news.ycombinator.com/vote?id=44177936&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>The main barriers for me would be:</p><p>1. Why? Who would use that? What’s the problem with the other search engines? How will it be paid for?</p><p>2. Potential legal issues.</p><p>The technical barriers are at least challenging and interesting.</p><p>Providing a service with significant upfront investment needs with no product or service vision that I’ll likely to be sued for a couple of times a year, probably losing with who knows what kind of punishment… I’ll have to pass unfortunately.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178200"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178200" href="https://news.ycombinator.com/vote?id=44178200&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>It would be incredible for LLMs. Searching it, using it as training data, etc. Would probably have to be done in Russia or some other country that doesn't respect international copyright though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178241"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178241" href="https://news.ycombinator.com/vote?id=44178241&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Do you have a reason to believe this ain't already being done? I would assume that the big guys like openai are already training on basically all text in existence.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178453"><td></td></tr>
                  <tr id="44178237"><td></td></tr>
                        <tr id="44177444"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177444" href="https://news.ycombinator.com/vote?id=44177444&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I think there’s a couple ways to improve it:</p><p>1. There’s a lot of variants of the same book. We only need one for the index. Perhaps for each ISBN, select the format easiest to parse.</p><p>2. We can download, convert and index top 100K books first, launch with these, and then continue indexing and adding other books.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177679"><td></td></tr>
                <tr id="44178316"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178316" href="https://news.ycombinator.com/vote?id=44178316&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>From a good search perspective though you probably dont want 500 different versions of the same book popping up for a query</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="44177996"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177996" href="https://news.ycombinator.com/vote?id=44177996&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I wonder if you could implement it with only static hosting?</p><p>We would need to split the index into a lot of smaller files that can be practically downloaded by browsers, maybe 20 MB each.
The user types in a search query, the browser hashes the query and downloads the corresponding index file which contains only results for that hashed query. Then the browser sifts quickly through that file and gives you the result.</p><p>Hosting this would be cheap, but the main barriers remain..</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44177999"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177999" href="https://news.ycombinator.com/vote?id=44177999&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>It's trivial to normalise the various formats, and there were a few libraries and ML models to help parse PDFs. I was tinkering around with something like this for academic papers in Zotero, and the main issue I ran into was words spilling over to the next page, and footnotes. I totally gave up on that endeavour several years ago, but the tooling has probably matured exponentially since then.</p><p>As an example, all the academic paper hubs have been using this technology for decades.</p><p>I'd wager that <i>all</i> of the big Gen AI companies have planned to use this exact dataset, and many or them probably have already.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178133"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178133" href="https://news.ycombinator.com/vote?id=44178133&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>&gt; It's trivial to normalise the various formats,</p><p>Ha. Ha. ha ha ha.</p><p>As someone who as pretty broadly tried to normalize a pile of books and documents I have legitimate access to, <i>no it is not</i>.</p><p>You can get good results 80% of the time, usable but messy results 18% of the time, and complete garbage the remaining 2%. More effort seems to only result in marginal improvements.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178321"><td></td></tr>
                              <tr id="44178333"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178333" href="https://news.ycombinator.com/vote?id=44178333&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>There is a search solution for zipped fb2 files. Not exactly what you need, but it has potential.</p><p>The project has similar story to Anna's archive. There is 0.5 TB of archived books, and the project creates index of all the books with text, title and aruthor search capabilities, gives html UI for search and reading. On weak machine it takes about 2 hours to build that index.</p><p>So if you have zipped archives of fb2, you can use the project to create web UI with search for those files. Without need of enough space to unpack all the files.</p><p>You'll have to translate some russian though to get instructions on how to set it up.</p><p><a href="https://gitlab.com/opennota/fb2index/-/blob/master/README.ru.md" rel="nofollow">https://gitlab.com/opennota/fb2index/-/blob/master/README.ru...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178203"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178203" href="https://news.ycombinator.com/vote?id=44178203&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>There’s an android app called OpenLip. [1]</p><p>Description:</p><p>Openlib is an open source app to download and read books from shadow library (Anna’s Archive). The App Has Built In Reader to Read Books.</p><p>As Anna’s Archive doesn't have an API, the app works by sending requests to Anna’s Archive and parses the response to objects. The app extracts the mirrors from the responses, downloads the book and stores it in the application's document directory.</p><p>Note :
The app requires VPN to function properly . Without VPN the might show the captcha required page even after completing the captcha</p><p>Main Features:</p><p>Trending Books</p><p>Download And Read Books With In-Built Viewer</p><p>Supports Epub And Pdf Formats</p><p>Open Books With Your Favourite Ebooks Reader</p><p>Filter Books</p><p>Sort Books</p><p>[1]: <a href="https://f-droid.org/de/packages/com.app.openlib/" rel="nofollow">https://f-droid.org/de/packages/com.app.openlib/</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44176569"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176569" href="https://news.ycombinator.com/vote?id=44176569&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>You must mean free text search and page level return, because it already has full metadata indexing.</p><p>The thing is AA doesn't hold the texts. They're disputable IPR and even a derived work would be a legal target.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178214"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178214" href="https://news.ycombinator.com/vote?id=44178214&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Z-Library has a keyword search. Personally i didn't find it too useful, especially given Google Books exists. It's not easy to create a quality book search engine.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44177457"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177457" href="https://news.ycombinator.com/vote?id=44177457&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>As far as I know, no one has fully implemented full-text search directly over Anna's Archive. Technically it’s feasible with tools like Meilisearch, Elasticsearch, or Lucene, but the main challenges are:</p><pre><code>    Converting all documents (PDFs, EPUBs, etc.) to clean plaintext.

    Indexing at scale efficiently.

    Managing potential legal issues.
</code></pre><p>
Z-Library does something similar, but it’s smaller in scope and doesn't integrate AA’s full catalog.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177592"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177592" href="https://news.ycombinator.com/vote?id=44177592&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I’ve done something like this before. Meilisearch will not be viable, because it indexes very slow and it takes up a lot of space.</p><p>In my experience only Tantivy can index this much data. Check out Lnx.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178248"><td></td></tr>
                        <tr id="44177894"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177894" href="https://news.ycombinator.com/vote?id=44177894&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Related question, has Anna's archive been thoroughly filtered for non-copyright-related illegal material? Pedo, terrorism, etc. I've considered downloading a few chunks of it but I'm worried of ending up with content I really don't want to be anywhere near from.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178086"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178086" href="https://news.ycombinator.com/vote?id=44178086&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>This is a really strange question to be honest you could ask this literally about any download let alone simply torrents of documents.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178012"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178012" href="https://news.ycombinator.com/vote?id=44178012&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>How might you inadvertently download illegal content while searching for legal content?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178070"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178070" href="https://news.ycombinator.com/vote?id=44178070&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>He said he wants to download lots of it in general, not specifical. Legit question, if you end up with dark material.</p><p>I would assume pedo stuff is not really there, but the anarchist cookbook and alike likely will be.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178167"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178167" href="https://news.ycombinator.com/vote?id=44178167&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I'm still not sure the question makes much sense, if it's a general: "I want to support the project and so I want to seed a large chunk" Okay, I guess it's your due diligence to check, but there is a reporting feature built in, if something is found, report it.</p><p>Aside from that, if you're searching for specific content, the question is moot I guess.</p><p>I guess my confusion is what distinguishes this apart from any other torrent ? That is, if the submitted content is submitted at all.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178210"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178210" href="https://news.ycombinator.com/vote?id=44178210&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I understood it as he or she wants to download large chunks of potentially interesting books for offline use, or once Anna goes down. So a broad filter. Not for seeding.</p><p>But thanks for the explanation that there is a report build in.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44178137"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178137" href="https://news.ycombinator.com/vote?id=44178137&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Considering the anarchist cookbook is just a rebranded selection of freely-available US Army Field Manuals, ... I don't see the problem.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178201"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178201" href="https://news.ycombinator.com/vote?id=44178201&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>I don't either, but many states have laws regarding books on how to build bombs and they might get enforced more than copyright.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44178127"><td></td></tr>
                <tr id="44178218"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178218" href="https://news.ycombinator.com/vote?id=44178218&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Well, I won't. But does it contain just text or real pictures? That would make a big legal difference I assume.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178277"><td></td></tr>
                                    <tr id="44176864"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176864" href="https://news.ycombinator.com/vote?id=44176864&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>AFAIK, Z-Library already does this, to some extent. Basic full-text queries do search inside the body of books and articles.</p><p>It's a bit smaller than Anna's Archive, as they do host their own collections. From some locations, it's only easy to access through Tor.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178107"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178107" href="https://news.ycombinator.com/vote?id=44178107&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Has anyone explored a different angle — like mapping out the 1,000 most frequently mentioned or cited books (across HN, Substack, Twitter, etc.), then turning their raw content into clean, structured data optimized for LLMs? Imagine curating these into thematic shelves — say, “Bill Gates’ Bookshelf” or “HN Canon” — and building an indie portal where anyone can semantically search across these high-signal texts. Kind of like an AI-searchable personal library of the internet’s favorite books.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178130"><td></td></tr>
                  <tr id="44177619"><td></td></tr>
            <tr id="44177170"><td></td></tr>
                <tr id="44178025"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178025" href="https://news.ycombinator.com/vote?id=44178025&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>It's not exactly clear, but OP is asking about indexing the content of all the documents, not the metadata (e.g. titles etc)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44177542"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177542" href="https://news.ycombinator.com/vote?id=44177542&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>Mebbe easier to just search Amazon or Goodreads. Like site:amazon.ca &lt;query words&gt; as someone has mentioned below.</p><p>Every book has an ISBN 10 or 13 digit ISBN number to identify them. Unless it's some self-pub/amateur-hour situation by some paranoid prepper living in a faraday-cage-protected cage in Arkansas or Florida it's likely a publication with a title, an author and an ISBN number.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177831"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Startup getting spammed with PayPal disputes, what should we do? (132 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44176510</link>
            <guid>44176510</guid>
            <pubDate>Wed, 04 Jun 2025 01:46:49 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44176510">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="44176510">
      <td><span></span></td>      <td><center><a id="up_44176510" href="https://news.ycombinator.com/vote?id=44176510&amp;how=up&amp;goto=item%3Fid%3D44176510"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=44176510">Ask HN: Startup getting spammed with PayPal disputes, what should we do?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_44176510">115 points</span> by <a href="https://news.ycombinator.com/user?id=june3739">june3739</a> <span title="2025-06-04T01:46:49 1749001609"><a href="https://news.ycombinator.com/item?id=44176510">12 hours ago</a></span> <span id="unv_44176510"></span> | <a href="https://news.ycombinator.com/hide?id=44176510&amp;goto=item%3Fid%3D44176510">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Startup%20getting%20spammed%20with%20PayPal%20disputes%2C%20what%20should%20we%20do%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=44176510&amp;auth=a5e7334e20b47144b4b9f3ad251dd0ab5bc8265e">favorite</a> | <a href="https://news.ycombinator.com/item?id=44176510">92&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Longtime user posting from a new account out of an abundance of caution.</p><p>I founded an e-commerce marketplace startup. We use PayPal's Multiparty APIs (PayPal Commerce Platform) for checkout. For the 10 days, someone has been bombarding us with purchases that they later dispute. There's consistent pattern to it:</p><p>* They use an email address that has no footprint online, always from the same two domains
* They use an unverified PayPal account to pay
* They pay a low amount, not always the same, in a narrow range for a digital item
* All of the charges were disputed within a few hours</p><p>They're not doing this through our API. The purchase process requires a browser because of the way our payment form is configured. There's an amount of variation to each purchase that tells us they're automating a browser. Logs indicate that they're changing IP each time. The events come in bursts and seem to be spaced to avoid automated detection.</p><p>We added the typical mitigations to our network stack and code. A few are still slipping through. Logs indicate a high amount of bot traffic.</p><p>PayPal does not seem equipped to deal with this. Their support is always extremely slow, relies on canned responses, and to date has a very limited understanding of how their own Multiparty APIs work. Their phone support people will not talk with me, they see no indication that my PayPal account is affiliated with these purchases in any way. They want each of our sellers to contact them independently, which we know will result in disparate cases that don't tell the complete story or offer any assistance.</p><p>Has anyone encountered anything like this before? We're struggling to find the motive or intended outcome by the attacker(s). We're a small company with a niche audience, we've never had a conflict with anyone that got serious enough that we'd expect them to come after us like this.</p><p>Any thoughts and recommendations would be greatly appreciated. We feel like we are on our own here and are unsure of how to handle it.</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A manager is not your best friend (175 pts)]]></title>
            <link>https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html</link>
            <guid>44176425</guid>
            <pubDate>Wed, 04 Jun 2025 01:29:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html">https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html</a>, See on <a href="https://news.ycombinator.com/item?id=44176425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As people become managers, it’s quite common for their team members to want to commiserate with them. This is especially true for friendly, competent, reasonable-seeming managers – people want to commiserate with <em>winners</em>. This makes commiseration extra dangerous, as it comes with a hint of flattery (“I respect your opinion and trust your discretion”).</p>

<p>But commiseration, especially with your direct reports, is organizational poison. It erodes the fabric of an organization and builds factions. It leads to feelings of superiority and creates a low-trust environment – <em>even if what you’re complaining about is made up!</em> Worst of all, it doesn’t give other teams an opportunity to improve. If I think that HR sucks, and I commiserate with my directs about it, my team is going to treat them poorly. HR will never know why, will never fix the problem, and will just think that my team are jerks (and they’ll arguably be right). Commiseration is self-fulfilling because it’s a form of victimhood: The world is conspiring against us, the only truly virtuous team.</p>

<p>Commiseration comes naturally to most people, because it happens all the time in real life. As your best friend, if you come to me saying that you were just dumped by your girlfriend, you will get unconditional sympathy beyond words. You’re the best, she didn’t deserve you, you can do so much better, everyone knows you’re the man, I have no idea why you ever spent time with her. There will be no questions, there will be no need for you to explain anything about the situation, even if all you did for the last 2 years was sit on your couch smoking weed and playing Warzone, <em>Greg</em>. Unless you did something totally crazy or illegal, my loyalty will be immediate and unconditional, because – let’s be real – none of it matters. You’re going your way, she’s going hers, and it’s over.</p>

<p>As a manager, your empathy needs to be highly conditional. Your job is to get to the truth of a matter in a respectful way, not make your team feel good. You are largely stuck with your coworkers, and you need to get stuff done together or everyone suffers. If you break up with your girlfriend you get unconditional sympathy. But if you break up with your girlfriend, and the 3 of us were trying to climb Mt. Everest together, I’m going to be a lot more measured in how I communicate and balance your relationship so that we can all survive the next few days.</p>

<p>Commiseration is generally a sensitive topic, so I’ve tried to boil down how to handle situations when a direct comes to you with grievances via some heuristics:</p>

<ul>
  <li>You don’t really want to debate your team in every situation, but your job is to essentially be a scientist and get to the bottom of what’s going on. If someone wants to commiserate about some other team, your first job is to ask a bunch of questions about what’s going on. In my experience, 90% of the time the situation is a grey area, and probably 30% of the time the person who wants to commiserate is actually in the wrong, on balance.</li>
  <li>Your role as a manager is also to be a perspective-creator. Sure, that salesperson was overly optimistic on how impactful this custom feature was for a prospect. And sure, the deal wasn’t as large and didn’t close as quickly as they said it would. But sales incentives are a law of the universe, and sales directors need to manage around them just as much as product teams do, because <em>not</em> having sales incentives is even worse. And by the way, we’re not so great at estimating development timelines either. Everyone’s blood pressure should always be lower after they’ve spoken to you.</li>
  <li>Bad therapists just let you rant. Good therapists let you vent, but they ask clarifying questions, and they sometimes push back. The phrase “is that actually true?” or “Can you explain that more?” are your friends. Good therapists validate feelings but they don’t necessarily validate <em>facts</em>. “I know you feel like you’re being a good daughter” is not the same as “you are the best daughter.” You want to be a good therapist.</li>
  <li>Remove the phrase “I don’t know why they…” from your lexicon. No matter how you end this sentence, the subtext will be clear: “I don’t know why they’re so incompetent.” Instead, it’s often better to give the most optimistic view for why another team is behaving the way that they are. It might not be <em>right</em>, but it builds empathy which is the bedrock on which productive collaboration is built.</li>
  <li>If someone is trying to get you to commiserate with them, try to speak in terms of reiterating a decision framework. Rather than “marketing doesn’t know what they’re doing,” you want to say something like “our role is to build the product and have a strong POV for marketing, and their role is to make sure that our launch generates enough pipeline. If you don’t think that’s going to happen then let’s talk to them.” The goal is to focus on objective truths rather than disparaging opinions.</li>
  <li>When it comes to commiseration, people are highly attuned to nuanced communication – especially from their boss. “Well guys, we’ve got this” plus that little head nod and eyeroll is functionally the equivalent of saying “it’s all on us, the protagonists, because everyone else is a fucking idiot <strong>again</strong>.” Those words didn’t literally leave your mouth, but you effectively said it, and as a manager that’s 100% on you. As a manager your implicit communication is just as important as your explicit communication – this is not a courtroom, this is real life, and non-verbal actions can still have consequences.</li>
  <li>One of the most common people to commiserate about is your own boss, or the company’s CEO. This can get highly toxic fast, and is rarely actually productive – cases of teams changing their CEO’s behavior through commiseration are vanishingly rare. The right way to pivot this conversation (or at least, the only way I’ve ever seen this play out positively) is to discuss how you can most effectively work with your boss. This is significantly more productive, and even if you still think they’re being dumb, at least you’re tackling that problem constructively.</li>
</ul>

<p>Of course sometimes people really are AAA grade idiots. When this happens, your communication should typically address the issue, not the other team. For most situations, it’s best to say “let me follow up,” rather than “I agree that they’re dumb.” In particularly egregious cases, you can go with “I know this is a problem and I’ll get on it” or “I hear you, I’m working on it, but I can’t give you every detail on how and don’t expect ongoing updates” – this avoids gaslighting them that everything is fine, but it also stops the vent session. When the door opens to commiseration with your team, you must slam it shut.</p>

<p>Either way, following up is the ideal next step because it commits you to respond but separates the emotion from the action. Accumulated strong emotions leave a strong impression, especially when they’re negative emotions like bitterness, so it’s best to suck the emotion out of the conversation as fast as possible. For evidence of this, light autists often make very effective managers.</p>

<p>Finally – we’re all human here, and sometimes you need to commiserate with <em>someone</em> before your head explodes. If you must commiserate, it’s almost always best if they’re a peer / near peer, and they’re not on your direct team (you don’t share a boss). This at least dodges the situation where a manager complains alongside their team, and thereby implicitly blesses their most negative views.</p>


    

    

    

    




  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta pauses mobile port tracking tech on Android after researchers cry foul (125 pts)]]></title>
            <link>https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/</link>
            <guid>44175940</guid>
            <pubDate>Tue, 03 Jun 2025 23:42:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/">https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/</a>, See on <a href="https://news.ycombinator.com/item?id=44175940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Security researchers say Meta and Yandex used native Android apps to listen on localhost ports, allowing them to link web browsing data to user identities and bypass typical privacy protections.</p>
<p>Following the disclosure, researchers observed that Meta's Pixel script stopped sending data to localhost and that the tracking code was largely removed. The move may help Meta avoid scrutiny under Google Play policies, which prohibit covert data collection in apps.</p>
<p>"We are in discussions with Google to address a potential miscommunication regarding the application of their policies," a Meta spokesperson told <em>The Register</em>. "Upon becoming aware of the concerns, we decided to pause the feature while we work with Google to resolve the issue."</p>

    

<p>Meta's spokesperson did not respond to a request to elaborate on the company's discussions with Google.</p>
<h3>What the researchers found</h3>
<p>In a <a target="_blank" rel="nofollow" href="https://localmess.github.io/">report</a> published Tuesday, computer scientists affiliated with IMDEA Networks (Spain), Radboud University (The Netherlands), and KU Leuven (Belgium) describe how the US social media giant and the Russian search engine were observed using native Android apps to gather web cookie data via the device's loopback interface, commonly known as localhost.</p>
<p>Localhost is a loopback address that a device can use to make a network request to itself. It's commonly used by software developers to test server-based applications like websites on local hardware.</p>

        


        

<p>The researchers – Aniketh Girish (PhD student), Gunes Acar (Assistant Professor), Narseo Vallina-Rodriguez (Associate Professor), Nipuna Weerasekara (PhD student), and Tim Vlummens (PhD student) – say they found native Android apps, including Facebook and Instagram, and Yandex's Maps and Browser – that listen silently on fixed local ports for tracking purposes.</p>
<p>"These native Android apps receive browsers' metadata, cookies and commands from the Meta Pixel and Yandex Metrica scripts embedded on thousands of websites," the computer scientists explain. "These JavaScripts load on users' mobile browsers and silently connect with native apps running on the same device through localhost sockets."</p>

        

<p>As these native apps access device identifiers like the Android Advertising ID or handle user identities in Meta apps, the researchers say, they're able to link mobile browsing sessions and web cookies to user identities.</p>
<p>Essentially, by opening localhost ports that allow their Android apps to receive tracking data, such as cookies and browser metadata, from scripts running in mobile browsers, Meta and Yandex are able to bypass common privacy safeguards like cookie clearing, Incognito Mode, and Android's app permission system.</p>
<p>The technique also violates assumptions about the scope of first-party cookies, which aren't supposed to be able to track browsing activity across different websites. According to the researchers, "the method we disclose allows the linking of the different _fbp cookies to the same user, which bypasses existing protections and runs counter to user expectations."</p>

        

<p>With regard to Meta, the tracking process involves scripts associated with <a target="_blank" rel="nofollow" href="https://www.facebook.com/business/tools/meta-pixel">Meta Pixel</a>, analytics code used by marketers to gather data about interactions with websites.</p>
<p>Various APIs and protocols can be used to implement the described app-web eavesdropping scheme. These include: SDP munging, which involves manually modifying Session Description Protocol (SDP) messages before the data gets passed to the browser; real-time communications protocols <a target="_blank" rel="nofollow" href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API">Websocket</a> and <a target="_blank" rel="nofollow" href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Protocols">WebRTC</a>; Session Traversal Utilities for NAT (STUN), an address discovery mechanism; and Traversal Using Relays around NAT (TURN), a router restriction bypass method.</p>
<ul>

<li><a href="https://www.theregister.com/2025/06/03/xs_new_encrypted_xchat_feature/">X's new 'encrypted' XChat feature seems no more secure than the failure that came before it</a></li>

<li><a href="https://www.theregister.com/2025/05/30/meta_is_now_a_defense/">Meta – yep, Facebook Meta – is now a defense contractor</a></li>

<li><a href="https://www.theregister.com/2025/05/29/billions_of_cookies_available/">Billions of cookies up for grabs as experts warn over session security</a></li>

<li><a href="https://www.theregister.com/2025/05/22/irish_data_protection_commission_gives/">Irish privacy watchdog OKs Meta to train AI on EU folks' posts</a></li>
</ul>
<p>The researchers describe Meta's approach thus:</p>
<blockquote>
<ol>

<li>The user opens the native Facebook or Instagram app, which eventually is sent to the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first unoccupied port in 12580-12585). Users must be logged-in with their credentials on the apps.</li>

<li>The user opens their browser and visits a website integrating the Meta Pixel.</li>

<li>At this stage, websites may ask for consent depending on the website's and visitor's locations.</li>

<li>The Meta Pixel script sends the <a target="_blank" rel="nofollow" href="https://localmess.github.io/#about_fbp">_fbp cookie</a> to the native Instagram or Facebook app via WebRTC (STUN) <a target="_blank" rel="nofollow" href="https://webrtchacks.com/not-a-guide-to-sdp-munging/">SDP Munging</a>.</li>

<li>The Meta Pixel script also sends the _fbp value in a request to https://www.facebook.com/tr along with other parameters such as page URL (dl), website and browser metadata, and the <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531104925/https://developers.facebook.com/docs/meta-pixel/reference/">event type</a> (ev) (e.g., PageView, AddToCart, Donate, Purchase).</li>

<li>The Facebook or Instagram apps receive the _fbp cookie from the Meta Pixel JavaScript running on the browser. The apps transmit _fbp as a GraphQL mutation to (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking users' fbp ID (web visit) with their Facebook or Instagram account.</li>
</ol>
</blockquote>
<p>Researchers observed Meta implementing this technique starting in September 2024, transmitting data via HTTP. Third-party developers working with Meta APIs noted and questioned the behavior in <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531105747/https://developers.facebook.com/community/threads/317050484803752/">forum</a> <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531105711/https://developers.facebook.com/community/threads/937149104821259/">posts</a> at the time.</p>
<p>HTTP-based data transmission using this technique supposedly ended the following month, but other methods of transmission (WebSocket, WebRTC STUN (w/ SDP Munging), and WebRTC TURN (w/o SDP Munging)) were identified in subsequent months.</p>
<p>Presently, however, Meta's use of these techniques appears to have halted. According to the researchers, "As of June 3rd 7:45 CEST, Meta/Facebook Pixel script is no longer sending any packets or requests to localhost. The code responsible for sending the _fbp cookie has been almost completely removed."</p>
<p>Yandex's use of localhost-based tracking dates back to 2017, according to the researchers.</p>
<p><em>The Register</em> sought to ask Yandex media relations about the researchers' claims but our inquiry was bounced as spam.</p>
<p>The report authors note that their disclosure to Android browser vendors has led to several mitigations.</p>
<p>Chrome 137, which shipped May 26, 2025, includes countermeasures <a target="_blank" rel="nofollow" href="https://webrtc.googlesource.com/src.git/+/72d6d748ddbe5d7f63ba5f2dd1ce195a342c0a12">to block the SDP Munging</a> technique used by Meta Pixel, though these have only been made available to a subset of users participating in a gated field trial. A fix is currently being developed for Mozilla Firefox. Brave is unaffected as it <a target="_blank" rel="nofollow" href="https://brave.com/privacy-updates/27-localhost-permission/">requires consent for localhost</a> use. And DuckDuckGo has modified its blocklist to stop Yandex's scripts.</p>
<p>Beyond these, the authors suggest a Google <a target="_blank" rel="nofollow" href="https://github.com/explainers-by-googlers/local-network-access">proposal</a> to create a new "local network access" permission that could help mitigate localhost-based tracking in the future. A <a target="_blank" rel="nofollow" href="https://wicg.github.io/private-network-access/">prior proposal</a> along these lines ran into <a target="_blank" rel="nofollow" href="https://developer.chrome.com/blog/pna-on-hold">technical barriers</a>. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brain aging shows nonlinear transitions, suggesting a midlife "critical window" (242 pts)]]></title>
            <link>https://www.pnas.org/doi/10.1073/pnas.2416433122</link>
            <guid>44175905</guid>
            <pubDate>Tue, 03 Jun 2025 23:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pnas.org/doi/10.1073/pnas.2416433122">https://www.pnas.org/doi/10.1073/pnas.2416433122</a>, See on <a href="https://news.ycombinator.com/item?id=44175905">Hacker News</a></p>
Couldn't get https://www.pnas.org/doi/10.1073/pnas.2416433122: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Precious Plastic Is in Trouble (275 pts)]]></title>
            <link>https://www.preciousplastic.com//news/problems-in-precious-plastic</link>
            <guid>44175773</guid>
            <pubDate>Tue, 03 Jun 2025 23:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.preciousplastic.com//news/problems-in-precious-plastic">https://www.preciousplastic.com//news/problems-in-precious-plastic</a>, See on <a href="https://news.ycombinator.com/item?id=44175773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2>is in trouble</h2></p><div><p>Hey world</p><p>This is a heavy message to send, but essential for the future of Precious Plastic. It will either make it or not. In this post I’ll give a detailed overview of all the current problems we have, how it got to this point and whats next. A short summarised video is below. No <em>need</em> to watch, it's all in the text.<br>‍</p></div><p><iframe src="https://www.youtube.com/embed/4gTd36cQLzY?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" title="Precious Plastic is in trouble. Really"></iframe></p><p><strong>Our last big development<br>‍</strong>Lets start with our last big development. &nbsp;2020, when we released Version 4, this was our latest release. We worked about 1,5 year with over +100 people from around the world. We developed the first ‘Pro’ Machines, a Sheetpress, Starterkits, Business calculators, new moulds, products and more. Looking back this was quite a unique moment. A lot of passionate work was done by volunteers and everything was shared Open Source online for free. Here some of the things we made<br></p><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4.jpg 2004w" alt=""></p><p><img src="https://s11.gifyu.com/images/SGTIk.gif"></p><div><p>With a relatively small amount of money, we reached a global impact in 2023 of over 1100 organzations in 56 countries, who recycled 1.400.000KG Plastic, they generated together a revenue of +$3.7 Million, employed 530 people, works with 3.405 volunteers and built 1.175 machines. (And this is only from the workspaces who shared their data last year) Learn more about our impact <a href="https://www.preciousplastic.com/impact/2024" target="_blank">here</a>.<br>‍<strong><br>☝️This was the good part. Lets get into our problems</strong></p><p> <strong>How we work<br></strong>In order to understand our problems it’s important to know how Precious Plastic is developed since its unusual. We work in what we call Versions. Version 1 got released in 2013 and the latest one 4 years ago. The principle is, we develop a lot of new things, share them online for free. And then whoever was involved takes a holiday or goes off to something else. They really have to go because at that point we spend all our money. The workspace is empty, the work drops, nothing new is made, we wait. Up until now for some magical reason we always received a gift to continue moving forward. From winning awards, to getting a big workspace donated. Whenever we got enough resources we assembled a team and started developing again.. Each time the team and amount of work grew. Until the latest version, here the problems started.</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.984375px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart.jpg 4247w" alt=""></p><div><p><strong>When the Problems started<br>‍</strong>We worked in versions not because we wanted to, but because we had to. We share everything online for free because we believe recycling knowledge should be available for everyone. As a consequence we don’t generate enough income to pay a team all year around. But after Version 4 a small group of seven dedicated ambitious volunteers wanted to try and sustain Precious Plastic all year around. So we can continue development and have a bigger impact to reduce plastic waste. This by itself is a hard job but we also had some extra problems on the way</p><p>‍<strong>#1 No workspace<br>‍</strong>The team was ready to continue work. But just a few weeks later Covid-19 came to the world, but this wasn’t our main problem. Our problem was Chrome-6, a chemical the municipality found in the paint from the building that was applied 40 years ago. Which meant we had to leave the workspace fast, and the building was large, we had a lot of machines and items to sell, in a short amount of time, during lockdowns. This meant we had to sell many things below value since that period most people were looking to buy bread machines, not robot arms. After the exhausting/rushed job of leaving our workspace we could stay in the garage/shed in the house of one of the team members in France. It was nice we had a base to continue, but it was much smaller and temporary. It was quite a downgrade.</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.984375px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace.jpg 3893w" alt=""></p><div><p><strong>#2 No business model<br>‍</strong>One of the main goals of this small team was trying to find a business model that would serve Precious Plastic’s mission, bring income to sustain a team and not compete with the rest of the community. The last one is difficult, because our most logical and common model would be to sell machines and moulds. There are not many Open Source Hardware projects like Precious Plastic in the world. And the ones that exist mostly sell their products. Arduino sells their circuit boards, Prusa sells 3d printers. However in our case we’re also building a global network of machine builders that can provide local recycling equipment. We didn't want to compete with our own community.</p><p>The plan was to do Projects or as we called them, Collabs. It meant to help others set up their projects. Sort of a consultancy. The team setup quite a few cool projects, from a refugee camp in a desert in Algeria to a big Sheetpress in Nigeria. And meanwhile released a few new machine drawings. The model somewhat worked, we continued development and could do meaningful work. However it was financially always tight and often didn’t bring in enough money to sustain the team (that was getting paid minimum Dutch wage). But what really broke it was the next problem</p><p>‍<strong>#3 Lawsuit<br>‍</strong>As the team was setting up projects we worked with different clients around the world. Working for clients was completely new for us and we're learning along the way. And one of the first projects we setup was in Manhattan, New York for a cosmetic company to recycle their packaging. We helped to set it up, got machines from a community member and local people ran it. However after a period of time an accident happened with someone using the machine, which was very unfortunate. And in the US, especially NY this means you need to get lawyers. What happened, who is responsible? Is it the company that hired us all, Precious Plastic (back then operating under One Army Entity) for organising it, was it a result of bad operational instructions, misuse of the machine or a fault in the machine from the community member? We analysed it and are convinced that we are not to blame. But we do not know what a judge is going to say. Meanwhile this has been going on for the last 2 years. Lots of paperwork and documents need to be filed with lawyers that charge up to $600/h, sending emails got painful. Being in a lawsuit in New York is very costly. On top of that we didn't have insurance, meaning we have to pay for it from our own tiny pockets.</p><p>‍<strong>#4 Software, heavily underestimated<br>‍</strong>During Version 4 we started developing our own Community Platform. It’s software that is the digital home of our community that helps members to document, share knowledge and find others to collaborate with. It’s developed in collaboration with our other projects and there is a lot more information about it here. Anyway this has been a massive project and the original complexity of it was underestimated. Took waaay more effort than we thought. In the recent years we’ve been hard at work to catch up and the platform got much more mature with many more features. But realistically this has been a hit on our online community since the ‘digital home’ wasn’t good enough to host everyone. We invested a lot in this so far and will continue to be a big project so please use the platform, give feedback so we can improve it and help us code it.</p><p>‍<strong>#5 Open Source community<br>‍</strong>At Precious Plastic we want to enable more people to recycle plastic. Plastic waste is a big global problem and needs many people collaborating in every corner of the world to fix it. That's why we give everything Open Source for free so everyone has access. On top of that a big part of Version 4 was to make sure that the people that start recycling workspaces can financially sustain themselves. Because If they can continue to recycle on a daily basis it means less plastic waste. We want all those hard working workspaces to succeed and provide business plans, calculators and instruction to help them. A few years later this resulted in hundreds of workspaces around the world that started a business who manage to recycle on a daily basis, which is great.&nbsp;</p><p>We went all-in on giving. And believe(d?) that sharing Open Source will bring contributions back one way or another. Contributions to support the Precious Plastic Community can be made in various ways.&nbsp;From a financial donation once a recycle-business is profitable, to giving credit or sharing back their knowledge. And many members do contribute something back which is great. However we’ve also been observing quite some established organisations that take more than they give, building business around Precious Plastic but not contributing anything back. It’s allowed, since it’s all Open-Source. But the mentality of only taking things and not contributing will eventually kill a community-driven project like this.&nbsp;</p><p>‍<strong>#6 It is bad designed<br>‍</strong>We don’t blame those for not contributing enough back. We see this as a fault on us. The project wasn’t designed to have a healthy financial model and relation with the community. We were always fully focussed on giving to the community, not us being a financially sustainable organisation. Funny example of this is the recent <a href="https://pposf.preciousplastic.com/" target="_blank">PPOSF</a> (Precious Plastic Open Source Fund). We received a €100K donation. Which was amazing, but we decided to give it all to the community so they can continue developing their projects. Not to sustain the organisation itself. You could see this as a humble move from us, give it to the community. But it isn’t, it’s ineffective, because now we have to bother you with our problems. Ideally we don’t have to do this and you don’t have to worry about us.&nbsp;</p><p><strong>#7 No long term team<br>‍</strong>As you can imagine all of the above problems make it hard for a team member to have a long term perspective in Precious Plastic. Even though the team has been very small, effective and works with many volunteers it has continued to be a struggle to pay everyone every month without worrying. Over time this brings lots of stress and uncertainty, especially if the team members by themselves grow up and need more stability in life.&nbsp;</p><p>‍<strong>Our current setup<br>‍</strong>Precious Plastic is a non-profit for public good (ANBI) setup in the Netherlands. <br>So what does our team and community look like? Here is a funny way to look at it:<br>‍<br><strong>Precious Plastic Community</strong><br>⬥+ 1000 workspaces around the world<br>⬥530 people employed, 3000 volunteers<br>⬥Totalling + $3.7 Million Revenue last year</p><p><strong>Precious Plastic Organisation</strong><br>⬥3 full-time people in the team<br>⬥Quarterly running costs €30K<br>⬥6 Months before out of money<br>⬥No workspace. Everyone is fully remote</p><p>As you can see not many team members to manage a large community. There are many areas we should work on but simply cannot. The team spends most of its time making sure just the basics are up and running and community members can continue to recycle and use our tools. And even with this small effective team we only have enough money to sustain for the coming 6 months. The future doesn’t look good.<br>‍</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.984375px, (max-width: 1919px) 71vw, 799.984375px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1.jpg 2339w" alt=""></p><div><p><strong>What is next?<br>‍</strong>I’ve been thinking about this. What should Precious Plastic do?&nbsp;<br>‍<strong>1: ☠️ Let Precious Plastic Die:</strong> It build a global community of recyclers, it achieved its mission and that’s it. We learned valuable lessons and the community will probably stay online for a bit but would slowly fade away.<br>‍<strong>2: 💪 Push it to the next level:</strong> There is still lots of plastic waste around the world. We need way more people recycling and R&amp;D on other plastic types. The community needs to grow.</p><p>To be honest I personally could be at peace with both of these directions. It’s amazing what Precious Plastic developed with a relatively small budget and passionate people volunteering their time. Many lessons learned. But an Open Source project like this needs many people caring for it in order to stay alive. If there isn't a large supportive community it will naturally die. It goes beyond the power of an individual. </p><p>That said, what many people might not realise, is that we would waste an unused potential we can currently unlock. We spend years building a global community of recyclers. Rolling out new improved tools has a much higher impact than before, we can reach the right people in many areas in the world. Plus we have clear visibility on our problems and are after all these years very close to having a healthy organisational cycle, see the chart below. All of this makes me think about giving it one last push to finish it. Version 5.&nbsp;</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle.jpg 2841w" alt=""></p><p><strong>What is Version 5?</strong><br>We have many ideas for a Version 5 and would love to work on this. But as you can see from this long text (thanks for reading all the way) we are in a big dip and have some big problems. Whatever we need to develop to get out of this needs to serve the community + the organisation itself. It will be made in a way that it can financially sustain itself afterwards. Something we never took into account. It will mean rebuilding things from the ground up, which requires much more help and resources than before. It would be the biggest thing we ever made as you can see below in the graph. Our team is small, our community is large. We can only do this if people like you are willing to support and help out.<br></p><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next.jpg 5389w" alt=""></p><div><p><strong>How can you help? <br></strong>The first step is gathering support from the community. If not ones cares about Precious Plastic there is no reason for us to continue to work on it. You can do this by "showing your support". Next we need to find resources to develop the next phase of the project, so you can help us "raise funds for V5".<strong></strong></p></div><div data-hover="false" data-delay="0"><div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/674c67fa11910bf4b8d514c0_support.png" loading="lazy" alt=""></p><p>Show your support</p></div><nav><div data-hover="false" data-delay="0"><div><p>Subscribe to our Youtube Channel</p></div><nav><div><p>The video you just watched is on the One Army Channel. However, Precious Plastic now has its own channel, which not many people know about. A big boost to our channel helps with the YouTube algorithm, allowing us to share more videos in the future.&nbsp;</p><p>‍<a href="https://www.youtube.com/@Precious_PlasticHQ/?sub_confirmation=1" target="_blank">Click here</a> to subscribe.</p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>We’re focused on recycling more plastic and making a real impact. Your support helps us drive this mission forward and generate actual income for our team.&nbsp;If you want to make a difference, <a href="https://www.preciousplastic.com/support" target="_blank">click here</a> to donate.</p></nav></div><div data-hover="false" data-delay="0"><nav><p><a href="https://www.patreon.com/one_army/membership" target="_blank">Join us on Patreon</a> to support our mission monthly. Your contribution helps create a stable income for our work. Plus, you'll get exclusive updates on our progress.</p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you're an individual, <a href="https://bazar.preciousplastic.com/products/" target="_blank">buy recycled plastic products</a> on the Bazar, like carabiners, keychains, earrings, rulers, phone cases, anything really. And if you're a workspace looking to expand, consider buying machines on the Bazar. Remember, 5% of every sale goes to Precious Plastic, which directly supports small scale plastic recycling.</p><p>Sellers, this is your chance to contribute—sell your items on the Bazar. Your sales make a big difference; that 5% income is used to improve the online marketplace itself. Avoiding the need for all the individual workspaces having to setup their own webshops. Together, we can create one strong marketplace that benefits us all.</p><p>‍</p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>The lawsuit in New York is still ongoing. We are currently facing significant costs and need pro-bono assistance from lawyers in the Netherlands or the US to help us navigate this process. If you can assist us, please send us an email to <a href="mailto:hello@preciousplastic.com?subject=Legal%20help">hello@preciousplastic.com</a></p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>Our Community Platform is a big software project, and honestly, it's more complex than we initially thought. Building the infrastructure to host a large global community. We're doing it all open source so others can use it and help out. If you're interested in helping build this, we could really use your skills.Check out the details on <a href="https://github.com/ONEARMY/community-platform" target="_blank">GitHub</a>.</p><p>⭐️ For an easy help&gt; Giving a start to the repository is useful to attract more contributors!</p></div></nav></div><div data-hover="false" data-delay="0"><div><p>Use the Community Platform</p></div><nav><div><p>Interaction on the Community Platform is essential, we're building the home for our online community. By answering Questions and uploading knowledge—such as How-tos, Research and replying to comments—you contribute to a collective resource that reflects the global activity of the community. </p><p>All this activity helps gather valuable feedback that steers our ongoing improvements, we release weekly fixes based on user insights.</p><p>Start by helping out to answer some questions <a href="https://community.preciousplastic.com/questions" target="_blank">here</a>.</p></div></nav></div></nav></div><div data-hover="false" data-delay="0"><div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/674c6f45d80db1b0b342e19a_money.png" loading="lazy" alt=""></p><p>Help us raise funds for V5</p></div><nav><div data-hover="false" data-delay="0"><nav><div><p>We need your help to locate grants. There are numerous grants available, but with a small team, it’s tough to find them all. Let’s crowdsource our efforts and share what we discover. If you have any information, please contribute by adding it <a href="https://community.preciousplastic.com/questions/who-can-help-us-to-find-grants-for-v5" target="_blank">here</a>.</p><p>And if you’re a grant writer that wants to help, send us a mail: <a href="mailto:hello@preciousplastic.com?subject=Help%20with%20grants">hello@preciousplastic.com</a></p></div></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you can make a large donation, it would be the biggest support we could receive right now. This help would allow us to stay on track in the short term, enabling us to focus on long-term goals. Our aim is to become independent of donors and self-sustaining. Additionally, your contribution could be tax-deductible as we are a Non-Profit (ANBI) from the Netherlands. <br>Our 3 year vision is to triple the impact of small-scale plastic recycling globally by releasing Version 5 with a total budget of 2.1 million euros.</p><p>If you're interested, send us an email to <a href="mailto:hello@preciousplastic.com?subject=Precious%20Plastic%20Donation">hello@preciousplastic.com</a></p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>If you want to collaborate with us, we welcome partnerships. Whether it's a video, sponsorship of Version 5, or featuring your logo on our website, we are open to various forms of collaboration—the bigger the initiative, the better. For inquiries, please send an email to <a href="mailto:hello@preciousplastic.com?subject=Collaborate">hello@preciousplastic.com</a> or fill the form <a href="https://www.preciousplastic.com/custom-solutions" target="_blank">here</a>.</p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you want, you can send us crypto. We’re easy with crypto and love receiving it. Here are our wallet addresses:&nbsp;<br><strong>Bitcoin</strong>: 3NxqZ3xW8PEPtbCrDHPrL7srjhN4U4iZwp<br><strong>Ethereum</strong>: 0x28CDdE98313a9ef878076f88d3AEFa3714185123<br>Tether (USDT): 0x65f9aB8B37D98F8D334AB97C74BF160249f8298D</p><p>If you need another one, or want to double check before sending.<br>Send us an email at <a href="mailto:hello@preciousplastic.com?subject=Crypto%20Donation">hello@preciousplastic.com</a></p></div></nav></div></nav></div><div><p>If enough action is taken we can move forward and will share a more detailed plan for Version 5.<br>If not, we are willing to accept that the project will just die.<br>We will keep you posted with updates.<br>‍<br>Thank you community</p><p>Dave</p><p>*It’s a complex problem to explain spanned over multiple years. If there are ideas, questions or comments go <a href="https://community.preciousplastic.com/questions/questions-on-the-article-with-our-problems" target="_blank">here</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Ephe – A minimalist open-source Markdown paper for today (124 pts)]]></title>
            <link>https://github.com/unvalley/ephe</link>
            <guid>44175557</guid>
            <pubDate>Tue, 03 Jun 2025 22:41:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/unvalley/ephe">https://github.com/unvalley/ephe</a>, See on <a href="https://news.ycombinator.com/item?id=44175557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:unvalley/ephe" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="XFrKT3G01DJsKUpu5mMdaZfi9Z9d5c7QqHiaLJn05KsWZ_NavEm4m590ZAsiYrsoqCRuNrAjb31wsVhtwR4bug" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="unvalley/ephe" data-current-org="" data-current-owner="unvalley" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=unvalley%2Fephe" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/unvalley/ephe&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="41d4782483eb3f1535a96863a9f3280c4bf9773f7897120b9b2f0c8c363da4b7" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-ba9e85f9-ced5-4945-b4ac-1c9a79fcbea7" for="icon-button-182d2309-5266-498f-9e19-e035d8196c09" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.b5e8a54636271e908e27.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.8edda24384d5c8bf99ee.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep learning gets the glory, deep fact checking gets ignored (524 pts)]]></title>
            <link>https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html</link>
            <guid>44174965</guid>
            <pubDate>Tue, 03 Jun 2025 21:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html">https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44174965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<p>Deep learning is glamorous and highly rewarded. If you train and evaluate a Transformer (a state-of-the-art language model) on a dataset of 22 million enzymes and then use it to predict the function of 450 unknown enzymes, you can publish your results in Nature (a very well-regarded publication). Your paper will be viewed 22,000 times and will be in the top 5% of all research outputs scored by Altmetric (a rating of how much attention online articles receive).</p>
<p>However, if you do the painstaking work of combing through someone else’s published work, and discovering that they are riddled with serious errors, including hundreds of incorrect predictions, you can post a pre-print to bioRxiv that will not receive even a fraction of the citations or views of the original. In fact, this is exactly what happened in the case of these two papers:</p>
<ul>
<li><a href="https://www.nature.com/articles/s41467-023-43216-z">Functional annotation of enzyme-encoding genes using deep learning with transformer layers | Nature Communications</a></li>
<li><a href="https://www.biorxiv.org/content/10.1101/2024.07.01.601547v2.full">Limitations of Current Machine-Learning Models in Predicting Enzymatic Functions for Uncharacterized Proteins | bioRxiv</a></li>
</ul>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/altmetric.jpg"></p>
<figcaption>A Tale of two Altmetric Scores</figcaption>
</figure>
</div>
<p>This pair of papers on enzyme function prediction make for a fascinating case study on the limits of AI in biology and the harms of current publishing incentives. I will walk through some of the details below, although I encourage you to read the papers for yourself. This contrast is a stark reminder of how hard it can be to evaluate the legitimacy of AI results without deep domain expertise.</p>
<section id="the-problem-of-determining-enzyme-function">
<h2 data-anchor-id="the-problem-of-determining-enzyme-function">The Problem of Determining Enzyme Function</h2>
<p>Enzymes are what catalyze reactions, so they are crucial for making things happen in living organisms. Enzyme Commission (EC) numbers provide a hierarchical classification system for thousands of different functions. Given a sequence of amino acids (the building blocks of all proteins, including enzymes), can you predict what the EC number (and thus, the function) is? This seems like a problem that is custom-made for machine learning, with clearly defined inputs and outputs. Moreover, there is a rich dataset available, with over 22 million enzymes and their EC numbers listed in the online database UniProt.</p>
</section>
<section id="an-approach-with-transformers-ai-model">
<h2 data-anchor-id="an-approach-with-transformers-ai-model">An Approach with Transformers (AI model)</h2>
<p>A research paper used a transformer deep learning model to predict the functions of enzymes with previously unknown functions. It seemed like a good paper! The authors used a reasonable, well-regarded neural network architecture (two transformer encoders, two convolutional layers, and a linear layer) that had been adopted from BERT. They looked at regions with high attention to confirm that these were biologically significant, which suggests that the model had learned underlying meaning and provided interpretability. They used a standard training, validation, and test split on a dataset with millions of entries. The researchers then applied the model to a dataset where no “ground truth” was known to make ~450 novel predictions. For these novel predictions, they randomly selected three to test <em>in vitro</em> and confirmed that the predictions were accurate.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/kim-fig1a-4.jpg"></p>
<figcaption>A transformer model, shown on the left, was used to predict Enzyme Commission numbers for uncharacterized enzymes in E. coli. Three of these were tested in vitro (Fig 1a and Fig 4 from Kim, et al.)</figcaption>
</figure>
</div>
</section>
<section id="the-errors">
<h2 data-anchor-id="the-errors">The Errors</h2>
<p>The Transformer model in the Nature paper made hundreds of “novel” predictions that are almost certainly erroneous. The paper had followed a standard methodology of evaluating performance on a held-out test set, and did quite well on that (although later investigation suggests there may have been <a href="https://www.kaggle.com/code/alexisbcook/data-leakage">data leakage</a>). The results claimed for enzymes where no ground truth is known were full of errors.</p>
<p>For instance, the gene E. coli YjhQ was predicted to be a mycothiol synthase, but mycothiol is not synthesized by E. coli at all! The gene yciO, which evolved from the gene TsaC, had already been shown a decade earlier <em>in vivo</em> to not have the same function as TsaC, yet the Nature paper concluded it did have the same function.</p>
<p>Of the 450 “novel” results given in the Nature paper, 135 of these results were not novel at all; they were already listed in the online database UniProt. Another 148 showed unreasonably high levels of repetition, with the same very specific enzyme functions reappearing up to 12 times for genes of <em>E. coli</em>, which biologically implausible.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig5.jpg"></p>
<figcaption>Most of the “novel” results from the transformer paper were either not novel, unusually repetitious, or incorrect paralogs (Fig 5 from de Crecy, et al.)</figcaption>
</figure>
</div>
</section>
<section id="the-microbiology-detective">
<h2 data-anchor-id="the-microbiology-detective">The Microbiology Detective</h2>
<p>How did these errors come to light? After the model had been trained, validated, and evaluated on a dataset involving millions of entries, it was used to make ~450 novel predictions, and three of these were tested in vitro. It just so happens that one of the enzymes selected for in vitro testing, yciO, had already been studied extensively over a decade earlier by Dr.&nbsp;de Crécy-Lagard. When Dr.&nbsp;de Crécy-Lagard read that deep learning had predicted that yciO had the same function of another gene, TsaC, she knew from her long years in the lab that this was incorrect. Her previous research had shown that the TsaC gene is essential in <em>E. coli</em> even if yciO is present in the same genome and even when yciO gene is overexpressed. Moreover, the yciO activity reported by Kim et al.&nbsp;is more than four orders of magnitude (i.e.&nbsp;10,000 times) weaker than that of TsaC. All this suggests that yciO does NOT serve the same key function as TsaC.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig7.jpg"></p>
<figcaption>Two enzymes with a common evolutionary ancestor, but different functions (Fig 7 from de Crecy, et al.)</figcaption>
</figure>
</div>
<p>YciO and TsaC do have structural similarities, and YciO evolved from an ancestor of TsaC. Decades of research on protein and enzyme evolution have shown that new functions often evolve via duplication of an existing gene, followed by diversification of its function. This poses a common pitfall in determining enzyme function, because the genes will have many similarities with the ones they duplicated and then diversified from.</p>
<p>Thus, looking at structural similarities is only one type of evidence for considering enzyme function. It is also crucial to look at other types of evidence, such as neighborhood context of the genes, substrate docking, gene co-occurrence in metabolic pathways, and other features of the enzymes.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig2.jpg"></p>
<figcaption>It is important to look at multiple types of evidence when classifying enzyme function (Fig 2 from de Crecy, et al.)</figcaption>
</figure>
</div>
</section>
<section id="hundreds-of-likely-erroneous-results">
<h2 data-anchor-id="hundreds-of-likely-erroneous-results">Hundreds of Likely Erroneous Results</h2>
<p>Spotting this one error inspired de Crécy-Lagard and her co-authors to take a closer look at all of the enzymes found to have novel results in the Kim, et al, paper. They found that 135 of these results were already listed in the online database used to build the training set and thus not actually novel. An additional 148 of the results contained a very high level of repetition, with the same highly specific functions reappearing up to 12 times. Biases, data imbalance, lack of relevant features, architectural limitations, or poor uncertainty calibration can all lead models to “force” the most common labels from the training data.</p>
<p>Other examples were proven wrong via biological context or a literature search. For instance, the gene YjhQ was predicted to be a mycothiol synthase but mycothiol is not synthesized by <em>E. coli</em>. YrhB was predicted to synthesize a particular compound, which was already predicted to be synthesized by the enzyme QueD. A form of <em>E. coli</em> with a QueD mutant was unable to synthesize the compound, showing that this is not in fact the function of YrhB.</p>
</section>
<section id="rethinking-enzyme-classification-and-true-unknowns">
<h2 data-anchor-id="rethinking-enzyme-classification-and-true-unknowns">Rethinking Enzyme Classification and “True Unknowns”</h2>
<p>Identifying enzyme function actually consists of two quite different problems which are commonly conflated:</p>
<ul>
<li>propagating known function labels to enzymes in the same functional family</li>
<li>discovering truly unknown functions</li>
</ul>
<p>The authors of the second paper observe, “By design, supervised ML-models cannot be used to predict the function of true unknowns.” While machine learning can be useful for propagating known functions to additional enzymes, there are many types of errors that can occur: including failing to propagate labels when they should, propagating labels when they should not, curation mistakes, and experimental mistakes. Unfortunately, erroneous functions are being entered into key online databases such as UniProt, and this incorrect data may be further propagated if it is used to train prediction models. This is a problem that increases over time.</p>
</section>
<section id="need-for-domain-expertise">
<h2 data-anchor-id="need-for-domain-expertise">Need for Domain Expertise</h2>
<p>It is not news that AI work will be more highly rewarded and supported than work that closely inspects the underlying data and integrates deep domain knowledge. The aptly titled <a href="https://research.google/pubs/everyone-wants-to-do-the-model-work-not-the-data-work-data-cascades-in-high-stakes-ai/">“Everyone Wants to do the Model Work, not the Data Work”</a> paper involving dozens of machine learning practitioners working on high-stakes AI projects and found that inadequate-application domain expertise was one of a few key causes of catastrophic failures.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/sambasivan-square.jpg"></p>
<figcaption>Sources of cascading failures in machine learning systems (Fig 1 from Sambasivan, et al.)</figcaption>
</figure>
</div>
<p>These papers also serve as a reminder of how challenging (or even impossible) it can be to evaluate AI claims in work outside our own area of expertise. I am not a domain expert in the enzyme functions of <em>E. coli</em>. And for most deep learning papers I read, domain experts have not gone through the results with a fine-tooth comb inspecting the quality of the output. How many other seemingly-impressive papers would not stand up to scrutiny? The work of checking hundreds of enzyme predictions is less glamorous than the work of building the AI model that generated them, yet it is even more important. How can we better incentivize this type of error-checking research?</p>
<p>At a time when funding is being slashed, I believe we should be doing the opposite and investing even more into a range of scientific and biomedical research, from a variety of angles. And we need to push back on an incentive system that is disproportionately focused on flashy AI solutions at the expense of quality results.</p>


</section>

<p><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p></main> <!-- /main -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A deep dive into self-improving AI and the Darwin-Gödel Machine (167 pts)]]></title>
            <link>https://richardcsuwandi.github.io/blog/2025/dgm/</link>
            <guid>44174856</guid>
            <pubDate>Tue, 03 Jun 2025 21:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://richardcsuwandi.github.io/blog/2025/dgm/">https://richardcsuwandi.github.io/blog/2025/dgm/</a>, See on <a href="https://news.ycombinator.com/item?id=44174856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <d-contents> <nav> <h3>Contents</h3>   <ul> <li> <a href="#how-dgm-works">How DGM Works</a> </li> <li> <a href="#can-dgm-really-improve-itself">Can DGM Really Improve Itself?</a> </li> <li> <a href="#comparison-with-alphaevolve">Comparison with AlphaEvolve</a> </li> <li> <a href="#can-we-trust-a-self-improving-ai">Can we trust a self-improving AI?</a> </li> </ul>  </nav> </d-contents> <p>Most AI systems today are stuck in a “cage” designed by humans. They rely on fixed architectures crafted by engineers and lack the ability to evolve autonomously over time. This is the <a href="https://en.wikipedia.org/wiki/Achilles%27_heel" rel="external nofollow noopener" target="_blank">Achilles heel</a> of modern AI — like a car, no matter how well the engine is tuned and how skilled the driver is, it cannot change its body structure or engine type to adapt to a new track on its own. But what if AI could learn and improve its own capabilities without human intervention? In this post, we will dive into the concept of self-improving systems and a recent effort towards building one.</p> <h2 id="learning-to-learn">Learning to Learn</h2> <p>The idea of building systems that can improve themselves brings us to the concept of <a href="https://people.idsia.ch/~juergen/metalearning.html" rel="external nofollow noopener" target="_blank">meta-learning</a>, or “learning to learn” <d-cite key="thrun1998learning"></d-cite>, which aims to create systems that not only solve problems but also evolve their problem-solving strategies over time. One of the most ambitious efforts in this direction is the Gödel Machine<d-cite key="schmidhuber2003godel"></d-cite>, proposed by Jürgen Schmidhuber decades ago and was named after the famous mathematician <a href="https://en.wikipedia.org/wiki/Kurt_G%C3%B6del" rel="external nofollow noopener" target="_blank">Kurt Gödel</a>. A Gödel Machine is a hypothetical self-improving AI system that optimally solves problems by recursively rewriting its own code when it can mathematically prove a better strategy. It represents the ultimate form of self-awareness in AI, an agent that can reason about its own limitations and modify itself accordingly.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/godel.jpg" alt="Overview of a Gödel machine" width="80%"></p> <p><strong>Figure 1.</strong> Gödel machine is a hypothetical self-improving computer program that solves problems in an optimal way. It uses a recursive self-improvement protocol in which it rewrites its own code when it can prove the new code provides a better strategy.</p> <p>While this idea is interesting, formally proving whether a code modification of a complex AI system is <em>absolutely beneficial</em> is almost an impossible task without restrictive assumptions. This part stems from the inherent difficulty revealed by the <a href="https://en.wikipedia.org/wiki/Halting_problem" rel="external nofollow noopener" target="_blank">Halting Problem</a> and <a href="https://en.wikipedia.org/wiki/Rice%27s_theorem" rel="external nofollow noopener" target="_blank">Rice’s Theorem</a> in computational theory, and is also related to the inherent limitations of the logical system implied by <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems" rel="external nofollow noopener" target="_blank">Gödel’s incompleteness theorem</a>. These theoretical constraints make it nearly impossible to predict the complete impact of code changes without making restrictive assumptions. To illustrate this, consider a simple analogy: just as you cannot guarantee that a new software update will improve your computer’s performance without actually running it, an AI system faces an even greater challenge in predicting the long-term consequences of modifying its own complex codebase.</p> <h2 id="darwin-gödel-machine">Darwin-Gödel Machine</h2> <p>To “relax” the requirement of formal proof, a recent work by proposed the <strong>Darwin-Gödel Machine (DGM)</strong><d-cite key="zhang2025darwingodelmachineopenended"></d-cite>, which combines the Darwinian evolution and Gödelian self-improvement. Essentially, DGM abandoned the pursuit of a rigorous mathematical proof and embraced a more pragmatic way that is closer to the essence of life evolution through empirical validation. As the authors put it,</p> <blockquote> <p>We do not require formal proof, but empirical verification of self-modification based on benchmark testing, so that the system can improve and explore based on the observed results.</p> </blockquote> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm.png" alt="Overview of the DGM" width="80%"></p> <p><strong>Figure 2.</strong> The Darwin-Gödel Machine (DGM) is a self-improving AI system that optimizes its own problem-solving strategy through a combination of Darwinian evolution and Gödelian self-improvement.</p> <p>The core idea behind DGM is to let the AI agent iteratively modify its own code<d-footnote>More precisely, the metacode that controls its behavior and ability</d-footnote>, and then put these modified new versions into the actual test environment (e.g., coding benchmarks) to judge whether this modification is good by observing its performance. If the modification is good, it will be retained and may become the basis for further evolution in the future; if the modification is bad, it will be eliminated.</p> <h3 id="how-dgm-works">How DGM Works</h3> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-animation.gif" alt="Animation of the DGM process" width="80%"></p> <p><strong>Figure 3.</strong> Animation showing how DGM iteratively builds a growing archive of agents by harnessing the principles of open-ended exploration. New agents are created and scored by interleaving self-modification with downstream task evaluation.</p> <p>The general workflow of DGM is as follows:</p> <ol> <li> <p><strong>Initialization:</strong> Evolution begins with one or a few basic coding agents, so-called the “seeds” of intelligence. These initial agents may possess only minimal functionalities, such as executing bash commands or editing entire files. DGM maintains an “archive of agents”, which functions like a biological “gene bank.” This archive preserves all previously generated agents, regardless of their performance level, ensuring that no potentially valuable variation is permanently lost.</p> </li> <li> <p><strong>Sampling:</strong> DGM selects one or more parent agents from the archive to generate new child agent. The selection mechanism does not focus solely on top performers but instead allows every agent a chance to be chosen. While higher-performing agents are more likely to be selected, DGM also encourages exploration by giving “less successful agents”<d-footnote>Those that might contain novel or unconventional ideas</d-footnote> an opportunity to contribute to future generations.</p> </li> <li> <strong>Reproduction:</strong> Once the parents are selected, DGM performs modifications to generate a new child agent. These changes occur at the source code level and can include: <ul> <li> <em>Enhancement of existing tools</em>, for example, upgrading a file-editing tool that replaces entire files into one capable of precise string replacement.</li> <li> <em>Addition of new tools or workflows</em>, such as integrating a static code analysis tool or designing a “think–act–observe” loop.</li> <li> <em>Improvement of problem-solving strategies</em>, for instance, refining how the agent prompts the base model or managing long-context code more effectively.</li> <li> <em>Introduction of collaboration mechanisms</em>, like having an agent’s code reviewed by another before execution.</li> </ul> </li> <li> <p><strong>Natural Selection:</strong> The newly generated child agent is not automatically accepted into the “elite pool” but must prove its worth through rigorous testing. Each agent’s performance, such as the percentage of successfully solved problems, is quantitatively scored and used to select the best agents.</p> </li> <li> <strong>Tree Formation:</strong> If a child agent outperforms its parent or meets certain quality thresholds, it is added to the archive and becomes a new node in the evolutionary tree. This process repeats iteratively, creating a growing structure of diverse, high-quality agents. Importantly, DGM enables parallel exploration of many different paths in the search space, promoting open-ended discovery and avoiding premature convergence to local optima.</li> </ol> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-conceptual.png" alt="Workflow of DGM" width="100%"></p> <p><strong>Figure 4</strong> DGM iteratively builds a growing intelligent archive by intertwining self-modification with downstream task evaluation. The intelligent body in the archive is selected for self-modification through open exploration.</p>  <p>The paper provides a concrete example of the above principle in action. In the SWE-bench experiment, the performance of newly generated agents showed temporary declines in the 4th and 56th iterations. While traditional hill-climbing methods would abandon these seemingly “regressive paths”, DGM’s open exploration mechanism allows continued exploration. This persistence paid off as by the 70th iteration, the system had created new agents that surpassed all their predecessors, demonstrating the value of maintaining diverse evolutionary paths even when they temporarily appear less promising.</p> <h3 id="can-dgm-really-improve-itself">Can DGM Really Improve Itself?</h3> <p>In the paper, the authors evaluated DGM on two challenging benchmarks:</p> <ol> <li> <p><strong>SWE-bench:</strong> A widely-used benchmark that tests agents’ ability to resolve real-world GitHub issues<d-cite key="jimenez2024swe"></d-cite> . DGM showed impressive progress, improving its performance from 20.0% to 50.0% through self-modification.</p> </li> <li> <p><strong>Polyglot</strong>: A <a href="https://aider.chat/2024/12/21/polyglot.html" rel="external nofollow noopener" target="_blank">multi-language coding benchmark</a> containing coding problems in C++, Go, Java, JavaScript, Python and Rust. DGM achieved even more dramatic improvement, jumping from an initial 14.2% to 30.7% success rate, far surpassing the representative hand-designed agent by <a href="https://aider.chat/" rel="external nofollow noopener" target="_blank">Aider</a>.</p> </li> </ol> <p>The impressive performance improvements demonstrate DGM’s fundamental ability to enhance itself through self-modification. Through ablation studies, the authors identified two key factors driving DGM’s success. First, self-modification proved crucial, as when disabled (<strong>DGM w/o Self-improve</strong>), the performance declined substantially, showing that the ability to modify its own code is essential for accelerated learning. Second, the open-ended exploration approach was vital, as removing the Darwinian evolution-inspired search mechanism (<strong>DGM w/o Open-ended exploration</strong>), which maintains an archive of diverse solutions and enables parallel exploration of multiple paths, resulted in lower performance.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-self-improve.png" alt="Performance of DGM on SWE-bench and Polyglot" width="100%"></p> <p><strong>Figure 5</strong> Self-improvement and open-ended exploration enable the DGM to continue making progress and improve its performance. The DGM automatically discovers increasingly better coding agents and performs better on both SWE-bench (Left) and Polyglot (Right).</p> <h3 id="comparison-with-alphaevolve">Comparison with AlphaEvolve</h3> <p>In parallel, AlphaEvolve<d-cite key="deepmind2025alphaevolve"></d-cite>, which is developed by Google DeepMind, also demonstrates another powerful path forward. AlphaEvolve pairs the creative problem-solving capabilities of Google’s Gemini models with automated evaluators in an evolutionary framework. It has already demonstrated significant real-world impact across multiple domains, such as:</p> <ul> <li> <strong>Data center efficiency:</strong> AlphaEvolve discovered a simple yet highly effective heuristic for Google’s <a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/" rel="external nofollow noopener" target="_blank">Borg</a> cluster management system, continuously recovering 0.7% of Google’s worldwide compute resources.</li> <li> <strong>AI acceleration:</strong> It achieved a 23% speedup in Gemini’s architecture’s vital <a href="https://docs.jax.dev/en/latest/pallas/index.html" rel="external nofollow noopener" target="_blank">kernel</a> by finding more efficient ways to divide large matrix multiplication operations, resulting in a 1% reduction in overall training time.</li> <li> <strong>Mathematical breakthroughs:</strong> Most notably, it discovered an algorithm for multiplying 4x4 complex-valued matrices using just 48 scalar multiplications, surpassing <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" rel="external nofollow noopener" target="_blank">Strassen’s 1969 algorithm</a>, and advanced the 300-year-old <a href="https://en.wikipedia.org/wiki/Kissing_number_problem" rel="external nofollow noopener" target="_blank">kissing number problem</a> by establishing a new lower bound in 11 dimensions.</li> </ul>  <p>While both systems adopt a similar evolutionary framework, their scopes and methodologies differ in the following ways:</p> <table> <thead> <tr> <th>Feature</th> <th>AlphaEvolve</th> <th>DGM</th> </tr> </thead> <tbody> <tr> <td>Focus</td> <td>Evolving functions and codebases</td> <td>Evolving the agent itself</td> </tr> <tr> <td>Level of Innovation</td> <td>Algorithmic level</td> <td>Agent-level (toolset, methodology)</td> </tr> <tr> <td>Role of LLM</td> <td>LLM acts as “genetic operators” to modify algorithms</td> <td>LLM serves as the “brain” to evolve itself with better tools and strategies</td> </tr> <tr> <td>Evaluation</td> <td>Well-defined problems with automated evaluators</td> <td>Open-ended environments</td> </tr> </tbody> </table> <p>To better understand the differences between the two approaches, let us take a look at the following analogy:</p>  <h3 id="can-we-trust-a-self-improving-ai">Can we trust a self-improving AI?</h3> <p>The authors also conducted some experiments to evaluate DGM’s reliability and discovered some concerning behaviors. In particular, they observed instances where DGM attempted to manipulate its reward function through deceptive practices. One notable example involved the system fabricating the use of external tools - specifically, it generated fake logs suggesting it had run and passed unit tests, when in reality no tests were executed.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-hallucination.png" alt="Hallucination in DGM" width="100%"></p> <p><strong>Figure 6</strong> DGM hallucinated the use of an external tool to run unit tests.</p> <p>To address this issue, the authors implemented a “tool use hallucination” reward function and tasked DGM with optimizing it to eliminate hallucination behaviors. While DGM successfully provided solutions in many cases, it sometimes attempted to circumvent the detection system by removing the markers used to identify hallucinations, despite explicit instructions to preserve them. This behavior is reminiscent of the phenomenon of <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" rel="external nofollow noopener" target="_blank">Goodhart’s Law</a> from economics and sociology:</p> <blockquote> <p>“When a measure becomes a target, it ceases to be a good measure.”</p> </blockquote> <p>Fortunately, DGM’s design includes a transparent, traceable lineage of all changes, which enabled the researchers to quickly identify and address these undesirable behaviors. However, this example highlights the need for more robust safeguards to prevent such manipulation attempts in the first place. These findings underscore the critical importance of safety in self-improving AI research.</p> <h2 id="takeaways">Takeaways</h2> <p>DGM represents a groundbreaking step toward the realization of <a href="https://en.wikipedia.org/wiki/Life_3.0" rel="external nofollow noopener" target="_blank">Life 3.0</a>, a concept introduced by physicist <a href="https://en.wikipedia.org/wiki/Max_Tegmark" rel="external nofollow noopener" target="_blank">Max Tegmark</a>. In his book, he classified life into three stages:</p> <ul> <li> <strong>Life 1.0:</strong> Biological life with fixed hardware and software, such as bacteria.</li> <li> <strong>Life 2.0:</strong> Beings like humans, whose behavior can be learned and adapted during their lifetime, though their biology remains fixed.</li> <li> <strong>Life 3.0:</strong> A new class of intelligence that can redesign not only its behavior but also its underlying architecture and objectives — essentially, intelligence that builds itself.</li> </ul> <p><img src="https://richardcsuwandi.github.io/assets/img/life3.webp" alt="Life 3.0" width="80%"></p> <p><strong>Figure 7</strong> The three stages of life according to Max Tegmark.</p> <p>While DGM currently focuses on evolving the “software”<d-footnote>the code and strategies of AI agents</d-footnote>, it exemplifies the early stages of Life 3.0. By iteratively rewriting its own code based on empirical feedback, DGM demonstrates how AI systems could move beyond human-designed architectures to autonomously explore new designs, self-improve, and potentially give rise to entirely new species of digital intelligence. If this trend continues, we may witness a <a href="https://en.wikipedia.org/wiki/Cambrian_explosion" rel="external nofollow noopener" target="_blank">Cambrian explosion</a> in AI development, where eventually AI systems will surpass human-designed architectures and give rise to entirely new species of digital intelligence. While this future looks promising, achieving it requires addressing significant challenges, including:</p> <ul> <li> <p><strong>Evaluation Framework</strong>: Need for more comprehensive and dynamic evaluation systems that better reflect real-world complexity and prevent “reward hacking” while ensuring beneficial AI evolution.</p> </li> <li> <p><strong>Resource Optimization</strong>: DGM’s evolution is computationally expensive<d-footnote>The paper mentioned that a complete SWE-bench experiment takes about two weeks and about $22,000 in API call costs.</d-footnote>, thus improving efficiency and reducing costs is crucial for broader adoption.</p> </li> <li> <p><strong>Safety &amp; Control</strong>: As AI self-improvement capabilities grow, maintaining alignment with human ethics and safety becomes more challenging.</p> </li> <li> <p><strong>Emergent Intelligence</strong>: Need to develop new approaches to understand and interpret AI systems that evolve beyond human-designed complexity, including new fields like “AI interpretability” and “AI psychology”.</p> </li> </ul> <p>In my view, DGM is more than a technical breakthrough, but rather a philosophical milestone. It invites us to rethink the boundaries of intelligence, autonomy, and life itself. As we advance toward Life 3.0, our role shifts from mere designers to guardians of a new era, where AI does not just follow instructions, but helps us discover what is possible.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AirAP AirPlay server - AirPlay to an iOS Device (191 pts)]]></title>
            <link>https://github.com/neon443/AirAP</link>
            <guid>44174190</guid>
            <pubDate>Tue, 03 Jun 2025 20:12:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/neon443/AirAP">https://github.com/neon443/AirAP</a>, See on <a href="https://news.ycombinator.com/item?id=44174190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">AirAP is a fully native AirPlay server, written in Swift, for iOS. Essentially, AirAP allows you to use your iPhone as an AirPlay receiver in iTunes or on your Mac, meaning that you can use your iPhone to play your device's sound.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's AirAP?</h2><a id="user-content-whats-airap" aria-label="Permalink: What's AirAP?" href="#whats-airap"></a></p>
<p dir="auto">Have you ever wanted to stream audio from your Mac, Apple TV, or another iOS device to your iPhone? AirAP makes this possible by implementing a full AirPlay server that runs natively on iOS. Once installed, your iPhone will appear as an available AirPlay destination in iTunes (including the Windows version), Music app, or any other AirPlay-compatible application.</p>
<p dir="auto">The concept might seem backwards at first - after all, we're used to streaming from our iPhones to other devices. But there are surprisingly many scenarios where you'd want to do the reverse. Maybe you're working on your Mac late at night and want to route the audio to your iPhone with headphones so you don't disturb anyone (hi 👋). Perhaps you're a developer testing audio applications and need to quickly switch between different output devices. Or maybe you just want to include your iPhone in a multi-room audio setup alongside your other AirPlay speakers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing AirAP</h2><a id="user-content-installing-airap" aria-label="Permalink: Installing AirAP" href="#installing-airap"></a></p>
<p dir="auto">To try it out, <a href="https://testflight.apple.com/join/8aeqD8Q2" rel="nofollow">open this TestFlight link</a>, install AirAP, and follow the instructions. After installation, simply launch AirAP and ensure your iPhone is connected to the same Wi-Fi network as the device you want to stream from. Your iPhone will automatically appear in AirPlay device lists, ready to receive audio - if it doesn't, try restarting the app.</p>
<hr>
<sup>
© 2025 Nihaal Sharma. AirPlay, iPhone, iTunes, Mac, and Apple TV are trademarks of Apple Inc.
</sup>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did "Big Oil" Sell Us on a Recycling Scam? (103 pts)]]></title>
            <link>https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/</link>
            <guid>44172928</guid>
            <pubDate>Tue, 03 Jun 2025 18:14:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/">https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/</a>, See on <a href="https://news.ycombinator.com/item?id=44172928">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>
								The <span></span> icon indicates free access to the linked research on JSTOR.
							</p>
							<p>“Reduce, reuse, recycle”: these three words have become as ubiquitous as the plastic waste they attempt to combat. Once seen as a simple roadmap toward sustainability, this mantra now conceals a far more complex and troubling reality. While these principles serve as a starting point for environmental action, they also have a deceptive history rooted in the petrochemical industry’s effort to avoid accountability. The truth is, no matter how diligently we sort our waste products, individual actions alone cannot solve the growing crisis of plastic pollution.</p><p><a href="https://about.jstor.org/submission-guidelines/?utm_source=jstor_daily&amp;utm_medium=in_line&amp;utm_campaign=collaboration"><img decoding="async" src="https://daily.jstor.org/wp-content/uploads/2025/05/jstor_collaborators_ad_in_text.jpg" alt="JSTOR Collaboration" width="800" height="196"><img src="https://daily.jstor.org/wp-content/uploads/2025/05/jstor_collaborators_ad_mobile.jpg" alt="JSTOR Collaboration"></a></p>
<p>The <a href="https://daily.jstor.org/the-revolutionary-past-of-plastics/">ubiquity of plastic</a> in modern life makes recycling seem like a moral imperative. From straws and bags to take-out containers, single-use plastics crowd landfills and clog waterways. And the crisis is accelerating. Legal scholar Roberta Mann warns that by 2050, <span><a href="https://www.jstor.org/stable/48813257?mag=did-big-oil-sell-us-on-a-recycling-scam">plastic in the ocean could outweigh fish</a></span>. The United States led the world in plastic waste in 2016, Mann writes, generating over 42 million metric tons. The COVID-19 pandemic further fueled plastics consumption, with a spike in single-use personal protective equipment and packaging from online shopping.</p>
<p>But here’s the catch: research suggests that our dependence on recycling as a solution isn’t only ineffective—it’s based on a carefully crafted illusion. The narrative that recycling can meaningfully counteract the plastic crisis was constructed by the oil and gas industry to maintain public demand for plastic and delay regulation of its production.</p>
<p>As an investigation conducted by NPR and PBS <em>Frontline</em> unearthed in 2020 and reported in a <em>Frontline</em> episode called “<a href="https://www.pbs.org/wgbh/frontline/documentary/plastic-wars/">Plastic Wars</a>,” <a href="https://www.npr.org/2020/09/11/897692090/how-big-oil-misled-the-public-into-believing-plastic-would-be-recycled">oil companies have known for decades about the inability to recycle plastics throughout the US</a>. Tracing the history of the issue, the Center for International Law outlines how in the 1950s and ’60s the fossil fuel, petrochemical, and packaging industries began <span><a href="https://www.jstor.org/stable/resrep63260.9?mag=did-big-oil-sell-us-on-a-recycling-scam">convening on the issue of plastic pollution</a></span> as reports emerged of the plastics’ inability to decompose in the natural environment. In 1973, a National Academy of Sciences workshop reported that polystyrene spherules and poly-chlorinated biphenyls were being found in abundance in marine environments. The concept of decomposability was soon weaponized as one of plastic’s biggest strengths: plastic began to be marketed as the only material perfect for landfill linings and pollution containment.</p>

		<div>
							<p><a href="https://daily.jstor.org/youll-never-believe-who-invented-curbside-recycling/">
						<img fetchpriority="high" decoding="async" width="1050" height="700" src="https://daily.jstor.org/wp-content/uploads/2021/08/yes_curbside_recycling_is_kind_of_a_scam_1050x700.jpg" alt="Woman recycling glass, Wallingford neighborhood, Seattle, Washington, 1990">					</a>
				</p>
			
			<div>
				<h3><a href="https://daily.jstor.org/youll-never-believe-who-invented-curbside-recycling/">You’ll Never Believe Who Invented Curbside Recycling</a></h3>								<p>
					August 6, 2021				</p>
				<p>Far from ushering in a zero-waste world, the switch from returnables to recycling provided cover for the creation of ever more packaging trash.</p>			</div>
		</div>

		
<p>By also marketing plastic as recyclable, the entangled industries shifted the burden of responsibility onto individual consumers. <span><a href="https://time.com/vault/issue/1989-07-17/spread/16/">A <em>Time</em> magazine advertisement</a></span> from 1989 demonstrates how the Society of Plastic Industry (comprising fossil fuel companies Exxon, Mobil, Dow, DuPont, Chevron, and Phillips 66) emphasized recycling as a moral duty, all while knowing that the existing recycling infrastructure was inadequate and unprofitable.</p>
		
		
<p>Not much has changed in the last thirty-plus years. As Dave Dennison muses, recycling only occurs under conditions where it’s ”<span><a href="https://www.jstor.org/stable/27087389?mag=did-big-oil-sell-us-on-a-recycling-scam">cheaper for waste-hauling companies to [do it than to] send baled waste to landfills</a></span>.” As a representative from Keurig admitted in “Plastic Wars,” there’s currently no way of effectively recycling K-Cups, even though approximately eleven billion K-cups are produced per year. In fact, the creation of the recycling symbol on plastic products, utilizing the 1–7 polymer grade scale, was a push from industry as a bargaining chip to<span><a href="https://oag.ca.gov/plastics#deception"> stop state governments from instituting plastic bans and creating mandatory recycling standards</a></span>. As long as customers believe plastics producers are doing their part—and keep consuming plastic—the producer need not be concerned that their waste products aren’t recycled, Dennison suggests.</p>

	<div>
		<h4>Weekly Newsletter</h4>
		


	</div>
	
<p>That doesn’t mean recycling should be abandoned altogether. With so much plastic already in our ecosystems, recycling and remediation remain critical. Certain uses of plastic, such as medical supplies or assistive tools for disabled individuals, are currently irreplaceable. But we should also think about a fourth “R”: replace, as in: replace petroleum-based products with sustainable alternatives whenever possible. Plastics are known to cause endocrine disruption in living organisms, with links to cancers and other illnesses, writes Mann. Recycling, while important, can be understood as a harm-reduction tool—not a final solution. The search is on for additional approaches that will offer a deep mitigation of plastic <a href="https://doi.org/10.1016/j.erss.2022.102880">without positioning the oil and gas industry at the heart of the solution</a>. Real progress likely depends on systemic change: bold regulations to limit plastic production, major investments in <a href="https://daily.jstor.org/company-uses-mushrooms-grows-plastic-alternatives/">alternative materials</a>, and the will to challenge an industry that has polluted our planet for decades.</p>
<hr>
<p><a href="https://bit.ly/30jM88p">Support JSTOR Daily! Join our membership program on Patreon today.</a></p>
													</div><div><p><img src="https://daily.jstor.org/wp-content/uploads/2018/02/jstor-logo@2x.png" alt="JSTOR logo" width="65" height="90">
		</p>
		<div>
			<h2>Resources</h2>
			<p>
				JSTOR is a digital library for scholars, researchers, and students. JSTOR Daily readers can access the original research behind our articles for free on JSTOR.			</p>

								<div>
						
												<p>
							By: Roberta Mann						</p>
													<p>
							Journal of Land Use &amp; Environmental Law, Vol. 37, No. 2 (Spring 2022), pp. 251–302						</p>
						<p>
							Florida State University College of Law						</p>
					</div>
										<div>
						
												<p>
							By: Center for International Environmental Law (CIEL)						</p>
													<p>
							Making Plastic Polluters Pay: How Cities and States Can Recoup the Rising Costs of Plastic Pollution, (June 2024), pp. 21–23						</p>
						<p>
							Center for International Environmental Law (CIEL)						</p>
					</div>
										<div>
						
												<p>
							By: Dave Denison						</p>
													<p>
							The Baffler, No. 60 (NOV–DEC 2021), pp. 58–67						</p>
						<p>
							Baffler Foundation						</p>
					</div>
					
		</div>
	</div><div>
		<h4>Get Our Newsletter</h4>
		


	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swift at Apple: Migrating the Password Monitoring Service from Java (224 pts)]]></title>
            <link>https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/</link>
            <guid>44172166</guid>
            <pubDate>Tue, 03 Jun 2025 17:03:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/">https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/</a>, See on <a href="https://news.ycombinator.com/item?id=44172166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
<article>
  <header>
    

    <time pubdate="" datetime="2025-06-02T06:00:00-04:00">June 2, 2025</time>
    
  </header>

  <p><em>Swift is heavily used in production for building cloud services at Apple, with incredible results. Last year, the Password Monitoring service was rewritten in Swift, handling multiple billions of requests per day from devices all over the world. In comparison with the previous Java service, the updated backend delivers a 40% increase in performance, along with improved scalability, security, and availability.</em></p>

<p>The Passwords app, introduced in the fall of 2024, helps users manage their passwords, passkeys, and verification codes. It allows them to store, autofill, and generate strong passwords that can be shared across all their devices, as well as share passwords with trusted contacts. One security feature included in the app is Password Monitoring, which warns users if one of their saved passwords shows up in a data leak. This feature has a server component, running on Linux-based infrastructure, that is maintained by Apple.</p>

<p>On a regular interval, Password Monitoring checks a user’s passwords against a continuously updated and curated list of passwords that are known to have been exposed in a leak. Importantly, this task is handled in a thoughtful, privacy-preserving way that never reveals users’ passwords to Apple. A detailed discussion of how this is done using the cryptographic private set intersection protocol is in the <a href="https://support.apple.com/guide/security/password-monitoring-sec78e79fc3b/web">Password Monitoring</a> section of the <a href="https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf">Apple Platform Security</a> guide.</p>

<p>The migration from Java to Swift was motivated by a need to scale the Password Monitoring service in a performant way. The layered encryption module used by Password Monitoring requires a significant amount of computation for each request, yet the overall service needs to respond quickly even when under high load.</p>



<p>For years, our team relied on Java to power large-scale, mission-critical services because of its proven stability and performance. However, Java’s memory management approach no longer aligns with our growing demands and efficiency goals. Instead of simply expanding hardware resources, we were seeking a more-efficient language to support our growth while reducing server overhead.</p>

<p>Prior to seeking a replacement language, we sought ways of tuning the JVM to achieve the performance required. Java’s G1 Garbage Collector (GC) mitigated some limitations of earlier collectors by introducing features like predictable pause times, region-based collection, and concurrent processing. However, even with these advancements, managing garbage collection at scale remains a challenge due to issues like prolonged GC pauses under high loads, increased performance overhead, and the complexity of fine-tuning for diverse workloads.</p>

<p>One of the challenges faced by our Java service was its inability to quickly provision and decommission instances due to the overhead of the JVM. The Password Monitoring service runs globally, so service load can greatly fluctuate throughout the day, even with client-side techniques to smooth over the distribution of traffic. The peak and trough of a day differ by approximately 50% regionally. To efficiently manage this, we aim to scale down when demand is low and scale up as demand peaks in different regions. A faster bootstrap time is a crucial requirement to support this dynamic scaling strategy.</p>

<p>Given the scale of our application and the volume of traffic we manage daily, the decision to transition from Java to another language was not made lightly. We evaluated our options, and found only a few languages that could help us achieve our goals. While you might expect that Apple would automatically choose Swift, we were pleasantly surprised by how well it fit the unique needs of a cloud-based service like ours. Swift has expressive syntax that was easy to learn, and could deliver the performance improvements necessary to meet the demands of our compute workloads. We decided to take a significant leap and started a rewrite of the Password Monitoring backend using Swift.</p>



<p>We began rewriting our service using <a href="https://vapor.codes/">Vapor</a>, a Swift web framework that provided Routing, Controller, and Content modules that we were able to build upon. Our service had additional requirements that led us to create a few custom packages with essential functionality: elliptic curve operations that are crucial for implementing <a href="https://support.apple.com/guide/security/password-monitoring-sec78e79fc3b/web">password monitoring</a>, auditing, configuration, error handling, and custom middleware.</p>

<p><img alt="Password Monitoring Service Architecture." src="https://www.swift.org/assets/images/swift-at-apple-migrating-the-password-monitoring-service-from-java/password%20monitoring%20service.png" width="840" height="525">
</p>

<p>One of the most significant aspects of Swift that impressed us was its emphasis on <a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/protocols/">protocols</a>. In Java, we relied heavily on inheritance, which can lead to complex class hierarchies and tight coupling. Swift’s approach of protocols and generics promotes modularity and reusability by allowing classes, structs, and enums to share common protocols, enabling a more flexible and scalable codebase. This shift in mindset encouraged us to think in terms of behaviors rather than concrete classes, resulting in cleaner and more maintainable code.</p>

<p>Safety is another area where Swift takes a distinctive approach compared to Java. For example, Swift’s optional type and safe unwrapping mechanisms eliminate the need for null checks everywhere, reducing the risk of null pointer exceptions and enhancing code readability. This safety-first approach ingrained throughout Swift’s language design, whether it is deterministic deallocation, copy-on-write (CoW), or value types, makes it inherently less prone to runtime errors.</p>

<p>Swift’s async/await support is a nice addition, streamlining how we handle async tasks. Previously, managing async operations often involved complex callback patterns or external libraries. Swift’s async/await syntax simplifies this process, making it more intuitive and less error-prone. We can now write async code that reads like sync code, leading to more readable, testable, and maintainable concurrency handling—especially critical in high-load, multi-threaded environments.</p>

<p>Overall, our experience with Swift has been overwhelmingly positive and we were able to finish the rewrite much faster than initially estimated. Swift allowed us to write smaller, less verbose, and more expressive codebases (close to 85% reduction in lines of code) that are highly readable while prioritizing safety and efficiency.</p>

<p>Our service benefited from a diverse ecosystem of Swift packages, including <a href="https://github.com/apple/swift-log">logging</a> frameworks, a <a href="https://github.com/apple/swift-cassandra-client">Cassandra</a> client, and <a href="https://github.com/apple/swift-crypto">crypto</a> libraries that were readily available. In addition to an excellent support system and tooling, Swift’s inherent emphasis on modularity and extensibility helped future-proof and simplify the integration and customizations needed for our service-specific functions.</p>



<p>We benchmarked performance throughout the process of development and deployment, allowing us to discover the trait of the Swift programming language that delighted us the most — its efficiency.</p>

<p>Swift’s deterministic memory management led to a much lower memory threshold for our service. Not only were our initial results heartening, but after a few iterations of performance improvements, we had close to 40% throughput gain with latencies under 1 ms for 99.9% of requests on our current production hardware. Additionally, the new service had a much smaller memory footprint per instance — in the 100s of megabytes — an order of magnitude smaller compared to the 10s of gigabytes our Java implementation needed under peak load to sustain the same throughput and latencies. The service runs on Kubernetes, and the migration’s efficiency improvements allowed us to release about 50% of its capacity for other workloads.</p>

<p><img alt="Resource Utilization Comparison between java vs swift." src="https://www.swift.org/assets/images/swift-at-apple-migrating-the-password-monitoring-service-from-java/resource%20utilization.png" width="840" height="525">
</p>

<p>Our Swift implementation has run smoothly and efficiently in production, making it worth the effort we put into this migration. In addition to outperforming our previous Java-based application, Swift delivered better performance consistency, enhanced safety features, and robust reliability — all while requiring fewer resources by utilizing memory and CPU efficiently. With fewer lines of boilerplate code and more flexible design patterns that we used, we look forward to simplified maintenance of our application. Swift was a powerful choice for building fast, resilient, and maintainable applications in our high-demand environment.</p>


  
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[(On | No) Syntactic Support for Error Handling (366 pts)]]></title>
            <link>https://go.dev/blog/error-syntax</link>
            <guid>44171677</guid>
            <pubDate>Tue, 03 Jun 2025 16:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/blog/error-syntax">https://go.dev/blog/error-syntax</a>, See on <a href="https://news.ycombinator.com/item?id=44171677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-slug="/blog/error-syntax">
    
    <h2><a href="https://go.dev/blog/">The Go Blog</a></h2>
    

    
      
      
      
      <p>One of the oldest and most persistent complaints about Go concerns the verbosity of error handling.
We are all intimately (some may say painfully) familiar with this code pattern:</p>
<pre><code>x, err := call()
if err != nil {
        // handle err
}
</code></pre>
<p>The test <code>if err != nil</code> can be so pervasive that it drowns out the rest of the code.
This typically happens in programs that do a lot of API calls, and where handling errors
is rudimentary and they are simply returned.
Some programs end up with code that looks like this:</p>
<pre><code>func printSum(a, b string) error {
    x, err := strconv.Atoi(a)
    if err != nil {
        return err
    }
    y, err := strconv.Atoi(b)
    if err != nil {
        return err
    }
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>Of the ten lines of code in this function body, only four (the calls and the last two lines) appear to do real work.
The remaining six lines come across as noise.
The verbosity is real, and so it’s no wonder that complaints about error handling have topped
our annual user surveys for years.
(For a while, the lack of generics surpassed complaints about error handling, but now that
Go supports generics, error handling is back on top.)</p>
<p>The Go team takes community feedback seriously, and so for many years now we have tried to
come up with a solution for this problem, together with input from the Go community.</p>
<p>The first explicit attempt by the Go team dates back to 2018, when Russ Cox
<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md" rel="noreferrer" target="_blank">formally described the problem</a>
as part of what we called the Go 2 effort at that time.
He outlined a possible solution based on a
<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md" rel="noreferrer" target="_blank">draft design</a>
by Marcel van Lohuizen.
The design was based on a <code>check</code> and <code>handle</code> mechanism and was fairly comprehensive.
The draft includes a detailed analysis of alternative solutions, including comparisons with
approaches taken by other languages.
If you’re wondering if your particular error handling idea was previously considered,
read this document!</p>
<pre><code>// printSum implementation using the proposed check/handle mechanism.
func printSum(a, b string) error {
    handle err { return err }
    x := check strconv.Atoi(a)
    y := check strconv.Atoi(b)
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>The <code>check</code> and <code>handle</code> approach was deemed too complicated and almost a year later, in 2019,
we followed up with the much simplified and by now
<a href="https://go.dev/issue/32437#issuecomment-2278932700">infamous</a>
<a href="https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md" rel="noreferrer" target="_blank"><code>try</code> proposal</a>.
It was based on the ideas of <code>check</code> and <code>handle</code>, but the <code>check</code> pseudo-keyword became
the <code>try</code> built-in function and the <code>handle</code> part was omitted.
To explore the impact of the <code>try</code> built-in, we wrote a simple tool
(<a href="https://github.com/griesemer/tryhard" rel="noreferrer" target="_blank">tryhard</a>)
that rewrites existing error handling code using <code>try</code>.
The proposal was argued over intensively, approaching 900 comments on the <a href="https://go.dev/issue/32437">GitHub issue</a>.</p>
<pre><code>// printSum implementation using the proposed try mechanism.
func printSum(a, b string) error {
    // use a defer statement to augment errors before returning
    x := try(strconv.Atoi(a))
    y := try(strconv.Atoi(b))
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>However, <code>try</code> affected control flow by returning from the enclosing function in case of an error,
and did so from potentially deeply nested expressions, thus hiding this control flow from view.
This made the proposal unpalatable to many, and despite significant investment
into this proposal we decided to abandon this effort too.
In retrospect it might have been better to introduce a new keyword,
something that we could do now since we have fine-grained control over the language version
via <code>go.mod</code> files and file-specific directives.
Restricting the use of <code>try</code> to assignments and statements might have alleviated some
of the other concerns. A <a href="https://go.dev/issue/73376">recent proposal</a> by Jimmy Frasche, which essentially
goes back to the original <code>check</code> and <code>handle</code> design and addresses some of that design’s
shortcomings, pursues that direction.</p>
<p>The repercussions of the <code>try</code> proposal led to much soul searching including a series of blog
posts by Russ Cox: <a href="https://research.swtch.com/proposals-intro" rel="noreferrer" target="_blank">“Thinking about the Go Proposal Process”</a>.
One conclusion was that we likely diminished our chances for a better outcome by presenting an almost
fully baked proposal with little space for community feedback and a “threatening” implementation
timeline. Per <a href="https://research.swtch.com/proposals-large" rel="noreferrer" target="_blank">“Go Proposal Process: Large Changes”</a>:
“in retrospect, <code>try</code> was a large enough change that the new design we published […] should have
been a second draft design, not a proposal with an implementation timeline”.
But irrespective of a possible process and communication failure in this case, the user sentiment towards
the proposal was very strongly not in favor.</p>
<p>We didn’t have a better solution at that time and didn’t pursue syntax changes for error handling for several years.
Plenty of people in the community were inspired, though, and we received a steady trickle
of error handling proposals, many very similar to each other, some interesting, some incomprehensible,
and some infeasible.
To keep track of the expanding landscape, another year later, Ian Lance Taylor created an
<a href="https://go.dev/issue/40432">umbrella issue</a>
which summarizes the current state of proposed changes for improved error handling.
A <a href="https://go.dev/wiki/Go2ErrorHandlingFeedback">Go Wiki</a> was created to collect related feedback, discussions, and articles.
Independently, other people have started tracking all the many error handling proposals
over the years.
It’s amazing to see the sheer volume of them all, for instance in Sean K. H. Liao’s blog post on
<a href="https://seankhliao.com/blog/12020-11-23-go-error-handling-proposals/" rel="noreferrer" target="_blank">“go error handling proposals”</a>.</p>
<p>The complaints about the verbosity of error handling persisted
(see <a href="https://go.dev/blog/survey2024-h1-results">Go Developer Survey 2024 H1 Results</a>),
and so, after a series of increasingly refined Go team internal proposals, Ian Lance Taylor published
<a href="https://go.dev/issue/71203">“reduce error handling boilerplate using <code>?</code>”</a> in 2024.
This time the idea was to borrow from a construct implemented in
<a href="https://www.rust-lang.org/" rel="noreferrer" target="_blank">Rust</a>, specifically the
<a href="https://doc.rust-lang.org/std/result/index.html#the-question-mark-operator-" rel="noreferrer" target="_blank"><code>?</code> operator</a>.
The hope was that by leaning on an existing mechanism using an established notation, and taking into
account what we had learned over the years, we should be able to finally make some progress.
In small informal user studies where programmers were shown Go code using <code>?</code>, the vast majority
of participants correctly guessed the meaning of the code, which further convinced us to give it another
shot.
To be able to see the impact of the change, Ian wrote a tool that converts ordinary Go code
into code that uses the proposed new syntax, and we also prototyped the feature in the
compiler.</p>
<pre><code>// printSum implementation using the proposed "?" statements.
func printSum(a, b string) error {
    x := strconv.Atoi(a) ?
    y := strconv.Atoi(b) ?
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>Unfortunately, as with the other error handling ideas, this new proposal was also quickly overrun
with comments and many suggestions for minor tweaks, often based on individual preferences.
Ian closed the proposal and moved the content into a <a href="https://go.dev/issue/71460">discussion</a>
to facilitate the conversation and to collect further feedback.
A slightly modified version was received
<a href="https://github.com/golang/go/discussions/71460#discussioncomment-12060294" rel="noreferrer" target="_blank">a bit more positively</a>
but broad support remained elusive.</p>
<p>After so many years of trying, with three full-fledged proposals by the Go team and
literally <a href="https://go.dev/issues?q=+is%3Aissue+label%3Aerror-handling">hundreds</a> (!)
of community proposals, most of them variations on a theme,
all of which failed to attract sufficient (let alone overwhelming) support,
the question we now face is: how to proceed? Should we proceed at all?</p>
<p><em>We think not.</em></p>
<p>To be more precise, we should stop trying to solve the <em>syntactic problem</em>, at least for the foreseeable
future.
The <a href="https://github.com/golang/proposal?tab=readme-ov-file#consensus-and-disagreement" rel="noreferrer" target="_blank">proposal process</a>
provides justification for this decision:</p>
<blockquote>
<p>The goal of the proposal process is to reach general consensus about the outcome in a timely manner.
If proposal review cannot identify a general consensus in the discussion of the issue on the issue tracker,
the usual result is that the proposal is declined.</p>
</blockquote>
<p>Furthermore:</p>
<blockquote>
<p>It can happen that proposal review may not identify a general consensus and yet it is clear that the
proposal should not be outright declined.
[…]
If the proposal review group cannot identify a consensus nor a next step for the proposal,
the decision about the path forward passes to the Go architects […], who review the discussion and
aim to reach a consensus among themselves.</p>
</blockquote>
<p>None of the error handling proposals reached anything close to a consensus,
so they were all declined.
Even the most senior members of the Go team at Google do not unanimously agree
on the best path forward <em>at this time</em> (perhaps that will change at some point).
But without a strong consensus we cannot reasonably move forward.</p>
<p>There are valid arguments in favor of the status quo:</p>
<ul>
<li>
<p>If Go had introduced specific syntactic sugar for error handling early on, few would argue over it today.
But we are 15 years down the road, the opportunity has passed, and Go has
a perfectly fine way to handle errors, even if it may seem verbose at times.</p>
</li>
<li>
<p>Looking from a different angle, let’s assume we came across the perfect solution today.
Incorporating it into the language would simply lead from one unhappy group of users
(the one that roots for the change) to another (the one that prefers the status quo).
We were in a similar situation when we decided to add generics to the language, albeit with an
important difference:
today nobody is forced to use generics, and good generic libraries are written such that users
can mostly ignore the fact that they are generic, thanks to type inference.
On the contrary, if a new syntactic construct for error handling gets added to the language,
virtually everybody will need to start using it, lest their code become unidiomatic.</p>
</li>
<li>
<p>Not adding extra syntax is in line with one of Go’s design rules:
do not provide multiple ways of doing the same thing.
There are exceptions to this rule in areas with high “foot traffic”: assignments come to mind.
Ironically, the ability to <em>redeclare</em> a variable in
<a href="https://go.dev/ref/spec#Short_variable_declarations">short variable declarations</a> (<code>:=</code>) was introduced to address a problem
that arose because of error handling:
without redeclarations, sequences of error checks require a differently named <code>err</code> variable for
each check (or additional separate variable declarations).
At that time, a better solution might have been to provide more syntactic support for error handling.
Then, the redeclaration rule may not have been needed, and with it gone, so would be various
associated <a href="https://go.dev/issue/377">complications</a>.</p>
</li>
<li>
<p>Going back to actual error handling code, verbosity fades into the background if errors are
actually <em>handled</em>.
Good error handling often requires additional information added to an error.
For instance, a recurring comment in user surveys is about the lack of stack traces associated
with an error.
This could be addressed with support functions that produce and return an augmented
error.
In this (admittedly contrived) example, the relative amount of boilerplate is much smaller:</p>
<pre><code>func printSum(a, b string) error {
    x, err := strconv.Atoi(a)
    if err != nil {
        return fmt.Errorf("invalid integer: %q", a)
    }
    y, err := strconv.Atoi(b)
    if err != nil {
        return fmt.Errorf("invalid integer: %q", b)
    }
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
</li>
<li>
<p>New standard library functionality can help reduce error handling boilerplate as well,
very much in the vein of Rob Pike’s 2015 blog post
<a href="https://go.dev/blog/errors-are-values">“Errors are values”</a>.
For instance, in some cases <a href="https://go.dev/pkg/cmp#Or"><code>cmp.Or</code></a> may be used to deal with a
series of errors all at once:</p>
<pre><code>func printSum(a, b string) error {
    x, err1 := strconv.Atoi(a)
    y, err2 := strconv.Atoi(b)
    if err := cmp.Or(err1, err2); err != nil {
        return err
    }
    fmt.Println("result:", x+y)
    return nil
}
</code></pre>
</li>
<li>
<p>Writing, reading, and debugging code are all quite different activities.
Writing repeated error checks can be tedious, but today’s IDEs provide powerful, even LLM-assisted
code completion.
Writing basic error checks is straightforward for these tools.
The verbosity is most obvious when reading code, but tools might help here as well;
for instance an IDE with a Go language setting could provide a toggle switch to hide error handling
code.
Such switches already exist for other code sections such as function bodies.</p>
</li>
<li>
<p>When debugging error handling code, being able to quickly add a <code>println</code> or
have a dedicated line or source location for setting a breakpoint in a debugger is helpful.
This is easy when there is already a dedicated <code>if</code> statement.
But if all the error handling logic is hidden behind a <code>check</code>, <code>try</code>, or <code>?</code>, the code may have to
be changed into an ordinary <code>if</code> statement first, which complicates debugging
and may even introduce subtle bugs.</p>
</li>
<li>
<p>There are also practical considerations:
Coming up with a new syntax idea for error handling is cheap;
hence the proliferation of a multitude of proposals from the community.
Coming up with a good solution that holds up to scrutiny: not so much.
It takes a concerted effort to properly design a language change and to actually implement it.
The real cost still comes afterwards:
all the code that needs to be changed, the documentation that needs to be updated,
the tools that need to be adjusted.
Taken all into account, language changes are very expensive, the Go team is relatively small,
and there are a lot of other priorities to address.
(These latter points may change: priorities can shift, team sizes can go up or down.)</p>
</li>
<li>
<p>On a final note, some of us recently had the opportunity to attend
<a href="https://cloud.withgoogle.com/next/25" rel="noreferrer" target="_blank">Google Cloud Next 2025</a>,
where the Go team had a booth and where we also hosted a small Go Meetup.
Every single Go user we had a chance to ask was adamant that we should not change the
language for better error handling.
Many mentioned that the lack of specific error handling support in Go is most apparent
when coming freshly from another language that has that support.
As one becomes more fluent and writes more idiomatic Go code, the issue becomes much less important.
This is of course not a sufficiently large set of people to be representative,
but it may be a different set of people than we see on GitHub, and their feedback serves as yet another data point.</p>
</li>
</ul>
<p>Of course, there are also valid arguments in favor of change:</p>
<ul>
<li>
<p>Lack of better error handling support remains the top complaint in our user surveys.
If the Go team really does take user feedback seriously, we ought to do something about this eventually.
(Although there does not seem to be
<a href="https://github.com/golang/go/discussions/71460#discussioncomment-11977299" rel="noreferrer" target="_blank">overwhelming support</a>
for a language change either.)</p>
</li>
<li>
<p>Perhaps the singular focus on reducing the character count is misguided.
A better approach might be to make default error handling highly visible with a keyword
while still removing boilerplate (<code>err != nil</code>).
Such an approach might make it easier for a reader (a code reviewer!) to see that an error
is handled, without “looking twice”, resulting in improved code quality and safety.
This would bring us back to the beginnings of <code>check</code> and <code>handle</code>.</p>
</li>
<li>
<p>We don’t really know how much the issue is the straightforward syntactic verbosity of
error checking, versus the verbosity of good error handling:
constructing errors that are a useful part of an API and meaningful to developers and
end-users alike.
This is something we’d like to study in greater depth.</p>
</li>
</ul>
<p>Still, no attempt to address error handling so far has gained sufficient traction.
If we are honestly taking stock of where we are, we can only admit that we
neither have a shared understanding of the problem,
nor do we all agree that there is a problem in the first place.
With this in mind, we are making the following pragmatic decision:</p>
<p><em>For the foreseeable future, the Go team will stop pursuing syntactic language changes
for error handling.
We will also close all open and incoming proposals that concern themselves primarily
with the syntax of error handling, without further investigation.</em></p>
<p>The community has put tremendous effort into exploring, discussing, and debating these issues.
While this may not have resulted in any changes to error handling syntax, these efforts have
resulted in many other improvements to the Go language and our processes.
Maybe, at some point in the future, a clearer picture will emerge on error handling.
Until then, we look forward to focusing this incredible passion on new opportunities
to make Go better for everyone.</p>
<p>Thank you!</p>

    </div></div>]]></description>
        </item>
    </channel>
</rss>